<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="作者: 李金洪出版社: 机械工业出版社副标题: 入门、原理与进阶实战出版年: 2018-3-1ISBN: 9787111590057 配套学习资源本书提供了配套的超值学习资料，下面分别介绍。 1．同步配套教学视频   作者按照图书的内容和结构，录制了同步对应的《深度学习之TensorFlow：入门、原理与进阶实战》系列教学视频，如图1所示。    图1 《深度学习之TensorFlow——入门、原">
<meta name="keywords" content="机器学习,计算机,人工智能,TensorFlow,自评,books,更毕,深度学习,AI,豆瓣8,Programming">
<meta property="og:type" content="article">
<meta property="og:title" content="book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪">
<meta property="og:url" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/index.html">
<meta property="og:site_name" content="Hac_lang">
<meta property="og:description" content="作者: 李金洪出版社: 机械工业出版社副标题: 入门、原理与进阶实战出版年: 2018-3-1ISBN: 9787111590057 配套学习资源本书提供了配套的超值学习资料，下面分别介绍。 1．同步配套教学视频   作者按照图书的内容和结构，录制了同步对应的《深度学习之TensorFlow：入门、原理与进阶实战》系列教学视频，如图1所示。    图1 《深度学习之TensorFlow——入门、原">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00000.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00001.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00002.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00003.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00004.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00005.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00006.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00007.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00008.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00009.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00010.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00011.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00012.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00013.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00015.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00016.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00017.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00018.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00019.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00020.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00021.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00022.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00023.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00024.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00025.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00026.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00027.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00028.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00029.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00030.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00031.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00032.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00033.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00034.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00035.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00036.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00037.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00038.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00039.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00040.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00041.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00042.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00043.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00044.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00045.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00046.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00047.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00048.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00039.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00049.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00051.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00052.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00053.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00054.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00055.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00056.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00057.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00058.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00059.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00060.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00061.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00062.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00063.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00064.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00065.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00066.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00067.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00068.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00069.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00070.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00071.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00072.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00073.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00074.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00075.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00076.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00077.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00078.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00079.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00080.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00081.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00082.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00083.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00084.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00085.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00086.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00087.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00088.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00089.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00090.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00091.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00092.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00093.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00094.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00095.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00096.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00097.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00098.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00099.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00100.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00101.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00102.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00103.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00104.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00105.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00106.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00107.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00108.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00109.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00110.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00111.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00112.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00113.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00114.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00115.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00116.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00117.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00118.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00119.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00120.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00121.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00122.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00123.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00124.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00125.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00126.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00127.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00128.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00129.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00130.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00131.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00132.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00133.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00134.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00135.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00136.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00137.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00138.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00139.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00140.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00141.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00142.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00143.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00144.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00145.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00146.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00147.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00148.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00149.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00150.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00151.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00152.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00153.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00154.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00155.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00156.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00157.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00158.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00159.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00160.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00161.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00162.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00163.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00164.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00165.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00166.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00167.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00168.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00169.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00170.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00171.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00172.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00173.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00174.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00175.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00176.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00177.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00178.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00179.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00180.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00181.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00182.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00183.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00184.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00185.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00186.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00187.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00188.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00189.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00190.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00191.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00192.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00193.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00194.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00195.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00196.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00197.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00198.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00199.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00200.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00201.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00202.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00203.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00204.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00205.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00206.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00207.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00208.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00209.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00210.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00211.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00212.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00213.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00214.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00215.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00216.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00217.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00218.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00219.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00220.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00221.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00222.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00223.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00224.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00225.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00226.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00227.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00228.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00229.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00230.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00231.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00232.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00233.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00234.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00235.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00236.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00237.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00238.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00239.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00240.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00241.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00242.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00243.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00244.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00245.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00246.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00247.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00248.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00249.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00250.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00251.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00252.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00253.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00254.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00255.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00256.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00257.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00255.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00256.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00257.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00261.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00262.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00263.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00264.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00265.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00266.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00267.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00268.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00269.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00270.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00271.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00272.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00273.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00274.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00275.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00276.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00277.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00278.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00279.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00280.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00281.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00282.jpg">
<meta property="og:updated_time" content="2020-08-14T15:43:08.362Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪">
<meta name="twitter:description" content="作者: 李金洪出版社: 机械工业出版社副标题: 入门、原理与进阶实战出版年: 2018-3-1ISBN: 9787111590057 配套学习资源本书提供了配套的超值学习资料，下面分别介绍。 1．同步配套教学视频   作者按照图书的内容和结构，录制了同步对应的《深度学习之TensorFlow：入门、原理与进阶实战》系列教学视频，如图1所示。    图1 《深度学习之TensorFlow——入门、原">
<meta name="twitter:image" content="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/Image00000.jpg">





  
  
  <link rel="canonical" href="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪 | Hac_lang</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hac_lang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">小白hac_lang的笔记，涉及内容包含但不限于：人工智能   基因工程    信息安全   软件工程   嵌入式   天文物理</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-news">

    
    
      
    

    

    <a href="/news/" rel="section"><i class="menu-item-icon fa fa-fw fa-rss"></i> <br>news</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    
  
  

  

  <a href="https://github.com/HACLANG" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://haclang.github.io/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="hac_lang">
      <meta itemprop="description" content="小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hac_lang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-03-26 19:39:05" itemprop="dateCreated datePublished" datetime="2018-03-26T19:39:05+08:00">2018-03-26</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者: 李金洪<br>出版社: 机械工业出版社<br>副标题: 入门、原理与进阶实战<br>出版年: 2018-3-1<br>ISBN: 9787111590057</p>
<h1 id="配套学习资源"><a href="#配套学习资源" class="headerlink" title="配套学习资源"></a>配套学习资源</h1><p>本书提供了配套的超值学习资料，下面分别介绍。</p>
<p>1．同步配套教学视频  </p>
<p>作者按照图书的内容和结构，录制了同步对应的《深度学习之TensorFlow：入门、原理与进阶实战》系列教学视频，如图1所示。  </p>
<p><img src="Image00000.jpg" alt></p>
<p>图1 《深度学习之TensorFlow——入门、原理与进阶实战》系列教学视频</p>
<p>2．书中的实例源文件  </p>
<p>本书提供了书中涉及的所有实例源文件，共计123段代码，如图2所示。读者可以一边阅读本书，一边参照源文件动手练习，这样不仅提高了学习效率，而且可以对书中的内容有更加直观的认识，从而逐渐培养自己的编码能力。</p>
<p><img src="Image00001.jpg" alt></p>
<p>图2 本书实例源文件</p>
<p>3．书中实例用到的素材和样本</p>
<p>本书提供了书中实例用到的全部素材和样本。读者可以采用这些素材和样本，完全再现书中的实例效果。  </p>
<p><img src="Image00002.jpg" alt></p>
<p>图3 本书实例用到的素材和样本</p>
<p>4．配套学习资源获取方式  </p>
<p>本书提供的配套学习资源需要读者自行下载。有以下两种途径：  </p>
<p>（1）登录机械工业出版社华章公司的网站<a href="http://www.hzbook.com" target="_blank" rel="noopener">www.hzbook.com</a> ，然后搜索到本书页面，找到下载模块下载即可。</p>
<p>（2）扫描图4所示的二维码，关注并访问微信公众号xiangyuejiqiren，在公众号中回复“深1”得到相关资源的下载链接。</p>
<p><img src="Image00003.jpg" alt></p>
<p>图4 微信公众号xiangyuejiqiren二维码</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近，人工智能话题热度不减，IT领域甚至言必称之。</p>
<p>从人工智能的技术突破看，在语音和图像识别等方面，在特定领域和特定类别下，计算机的处理能力已经接近甚至超过人类。此外，人工智能在人们传统认为很难由机器取得成功的认知领域也有所突破。</p>
<p>我国目前在人工智能技术研究方面已经走在了世界前列，人工智能应用领域已经非常宽广，涵盖了从智能机器人到智能医疗、智能安防、智能家居和智慧城市，再到语音识别、手势控制和自动驾驶等领域。</p>
<p>百度CEO李彦宏判断：人工智能是一个非常大的产业，会持续很长时间，在未来的20年到50年间都会是快速发展的。</p>
<p>人工智能“火”起来主要有3个原因：互联网大量的数据、强大的运算能力、深度学习的突破。其中，深度学习是机器学习方法之一，是让计算机从周围世界或某个特定方面的范例中进行学习从而变得更加智能的一种方式。</p>
<p>面对人工智能如火如荼的发展趋势，IT领域也掀起了一波深度学习热潮，但是其海量的应用数学术语和公式，将不少爱好者拒之门外。本书由浅入深地讲解了深度学习的知识体系，将专业性较强的公式和理论转化成通俗易懂的简单逻辑描述语言，帮助非数学专业的爱好者搭上人工智能的“列车”。</p>
<h4 id="本书特色"><a href="#本书特色" class="headerlink" title="本书特色"></a>本书特色</h4><p>1．配教学视频</p>
<p>为了让读者更好地学习本书内容，作者对每一章内容都录制了教学视频。借助这些视频，读者可以更轻松地学习。</p>
<p>2．大量的典型应用实例，实战性强，有较高的应用价值</p>
<p>本书提供了96个深度学习相关的网络模型实例，将原理的讲解最终都落实到了代码实现上。而且这些实例会随着图书内容的推进，不断趋近于工程化的项目，具有很高的应用价值和参考性。</p>
<p>3．完整的源代码和训练数据集</p>
<p>书中所有的代码都提供了免费下载途径，使读者学习更方便。另外，读者可以方便地获得书中案例的训练数据集。如果数据集是来源于网站，则提供了有效的下载链接；如果是作者制作的，在随书资源中可直接找到。</p>
<p>4．由浅入深、循序渐进的知识体系，通俗易懂的语言</p>
<p>本书按照读者的接受度搭建知识体系，由浅入深、循序渐进，并尽最大可能地将学术语言转化为容易让读者理解的语言。</p>
<p>5．拒绝生僻公式和符号，落地性强</p>
<p>在文字表达上，本书也尽量使用计算机语言编写的代码来表述对应的数学公式，这样即使不习惯用数学公式的读者，也能够容易地理解。</p>
<p>6．内容全面，应用性强</p>
<p>本书提供了从单个神经元到对抗神经网络，从有监督学习到半监督学习，从简单的数据分类到语音、语言、图像分类乃至样本生成等一系列前沿技术，具有超强的实用性，读者可以随时查阅和参考。</p>
<p>7．大量宝贵经验的分享</p>
<p>授之以鱼不如授之以渔。本书在讲解知识点的时候，更注重方法与经验的传递。全书共有几十个“注意”标签，其中内容都是“含金量”很高的成功经验分享与易错事项总结，有关于理论理解的，有关于操作细节的。这些内容可以帮助读者在学习的路途上披荆斩棘，快速融会贯通。</p>
<h4 id="本书内容"><a href="#本书内容" class="headerlink" title="本书内容"></a>本书内容</h4><p>第1篇 深度学习与TensorFlow基础（第1～5章）</p>
<p>第1章快速了解人工智能与TensorFlow，主要介绍了以下内容：</p>
<p>（1）人工智能、深度学习、神经网络三者之间的关系，TensorFlow软件与深度学习之间的关系及其特点；</p>
<p>（2）其他主流深度学习框架的特点；</p>
<p>（3）一些关于如何学习深度学习和使用本书的建议。</p>
<p>第2章搭建开发环境，介绍了如何搭建TensorFlow开发环境。具体包括：</p>
<p>（1）TensorFlow的下载及在不同平台上的安装方法；</p>
<p>（2）TensorFlow开发工具（本书用的是Anaconda开发工具）的下载、安装和使用。</p>
<p>如要安装GPU版的TensorFlow，书中也详细介绍了如何安装CUDA驱动来支持GPU运算。</p>
<p>第3章TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例，首先是一个案例，有一组数据，通过TensorFlow搭配模型并训练模型，让模型找出其中y≈2x的规律。在这个案例的基础上，引出了在神经网络中“模型”的概念，并介绍了TensorFlow开发一个模型的基本步骤。</p>
<p>第4章TensorFlow编程基础，主要介绍了TensorFlow框架中编程的基础知识。具体包括：</p>
<p>（1）编程模型的系统介绍；</p>
<p>（2）TensorFlow基础类型及操作函数；</p>
<p>（3）共享变量的作用及用法；</p>
<p>（4）与“图”相关的一些基本操作；</p>
<p>（5）分布式配置TensorFlow的方法。</p>
<p>第5章识别图中模糊的手写数字（实例21），是一个完整的图像识别实例，使用TensorFlow构建并训练了一个简单的神经网络模型，该模型能识别出图片中模糊的手写数字5、0、4、1。通过这个实例，读者一方面可以巩固第4章所学的TensorFlow编程基础知识，另一方面也对神经网络有一个大体的了解，并掌握最简单的图像识别方法。</p>
<p>第2篇 深度学习基础——神经网络中（第6～10章）</p>
<p>第6章单个神经元，介绍了神经网络中最基础的单元。首先讲解了神经元的拟合原理，然后分别介绍了模型优化所需的一些关键技术：</p>
<p>·激活函数——加入非线性因素，解决线性模型缺陷；</p>
<p>·softmax算法——处理分类问题；</p>
<p>·损失函数——用真实值与预测值的距离来指导模型的收敛方向；</p>
<p>·梯度下降——让模型逼近最小偏差；</p>
<p>·初始化学习参数。</p>
<p>最后还介绍了在单个神经元基础上扩展的网络——Maxout。</p>
<p>第7章多层神经网络——解决非线性问题，先通过两个例子（分辨良性与恶性肿瘤、将数据按颜色分为3类）来说明线性问题，进而引出非线性问题。然后介绍了如何使用多个神经元组成的全连接网络进行非线性问题的分类。最后介绍了全连接网络在训练中常用的优化技巧：正则化、增大数据集和Dropout等。</p>
<p>第8章卷积神经网络——解决参数太多问题，通过分析全连接网络的局限性，引出卷积神经网络。首先分别介绍了卷积神经网络的结构和函数，并通过一个综合的图片分类实例介绍了卷积神经网络的应用。接着介绍了反卷积神经网络的原理，并通过多个实例介绍了反卷积神经网络的应用。最后通过多个实例介绍了深度学习中模型训练的一些技巧。</p>
<p>第9章循环神经网络——具有记忆功能的网络，本章先解释了人脑记忆，从而引出了机器学习中具有类似功能的循环神经网络，介绍了循环神经网络（RNN）的工作原理，并通过实例介绍了简单RNN的一些应用。接着介绍了RNN的一些改进技术，如LSTM、GRU和BiRNN等，并通过大量的实例，介绍了如何通过TensorFlow实现RNN的应用。从9.5节起，用了大量的篇幅介绍RNN在语音识别和语言处理方面的应用，先介绍几个案例——利用BiRNN实现语音识别、利用RNN训练语言模型及语言模型的系统学习等，然后将前面的内容整合成一个功能更完整的机器人，它可以实现中英文翻译和聊天功能。读者还可以再扩展该机器人的功能，如实现对对联、讲故事、生成文章摘要等功能。</p>
<p>第10章自编码网络——能够自学习样本特征的网络，首先从一个最简单的自编码网络讲起，介绍其网络结构和具体的代码实现。然后分别介绍了去噪自编码、栈式自编码、变分自编码和条件变分自编码等网络结构，并且在讲解每一种结构时都配有对应的实例。</p>
<p>第3篇 深度学习进阶（第11、12章）</p>
<p>第11章深度神经网络，从深度神经网络的起源开始，逐步讲解了深度神经网络的历史发展过程和一些经典模型，并分别详细介绍了这些经典模型的特点及内部原理。接着详细介绍了使用slim图片分类模型库进行图像识别和图像检测的两个实例。最后介绍了实物检测领域的其他一些相关模型。</p>
<p>第12章对抗神经网络，从对抗神经网络（GAN）的理论开始，分别介绍了DCGAN、AEGAN、InfoGAN、ACGAN、WGAN、LSGAN和SRGAN等多种GAN的模型及应用，并通过实例演示了生成指定模拟样本和超分辨率重建的过程。</p>
<h4 id="本书读者对象"><a href="#本书读者对象" class="headerlink" title="本书读者对象"></a>本书读者对象</h4><p>·深度学习初学者；</p>
<p>·人工智能初学者；</p>
<p>·深度学习爱好者；</p>
<p>·人工智能工程师；</p>
<p>·TensorFlow初级开发人员；</p>
<p>·需要提高动手能力的深度学习技术人员；</p>
<p>·名大院校的相关学生。</p>
<h4 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h4><p>本书由李金洪主笔编写。其他参与本书编写的人员还有马峰、孙朝晖、郑一友、王其景、张弨、白林、彭咏文、宋文利。</p>
<p>另外，吴宏伟先生也参与了本书后期的编写工作，为本书做了大量的细节调整。因为有了他的逐字推敲和一丝不苟，才使得本书行文更加通畅和通俗易懂。在此表示深深的感谢！</p>
<p>虽然我们对书中所述内容都尽量核实，并多次进行了文字校对，但因时间所限，加之水平所限，书中疏漏和错误在所难免，敬请广大读者批评指正。联系我们可以加入本书讨论QQ群40016981，也可发E-mail到hzbook2017@163.com。</p>
<h1 id="第1篇-深度学习与TensorFlow基础"><a href="#第1篇-深度学习与TensorFlow基础" class="headerlink" title="第1篇 深度学习与TensorFlow基础"></a>第1篇 深度学习与TensorFlow基础</h1><p>本篇将介绍人工智能与TensorFlow的基本概念、如何搭建TensorFlow的开发环境、TensorFlow的基本开发步骤、TensorFlow编程基础，并通过一个识别图中模糊手写数字的实例，使读者巩固TensorFlow的编程基础知识，并对神经网络有个大体的了解，为后面的学习打好基础。</p>
<p>第1章 快速了解人工智能与TensorFlow</p>
<p>第2章 搭建开发环境</p>
<p>第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例</p>
<p>第4章 TensorFlow编程基础</p>
<p>第5章 识别图中模糊的手写数字（实例21）</p>
<h2 id="第1章-快速了解人工智能与TensorFlow"><a href="#第1章-快速了解人工智能与TensorFlow" class="headerlink" title="第1章 快速了解人工智能与TensorFlow"></a>第1章 快速了解人工智能与TensorFlow</h2><p>本章是一个相对比较轻松的开篇，这里不会介绍太深的知识，而是普及一下什么是TensorFlow，什么是深度学习，深度学习与TensorFlow的关系，以及当今都有哪些与TensorFlow同级的开源框架，它们之间都是什么关系，各有什么特点和阅读本书的建议。本章的内容，就好比通往深度学习领域的大门。快来打开它，开始你的TensorFlow学习之旅吧。</p>
<p>本章含有教学视频共17分钟。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，包括深度学习与人工智能的关系、TersonFlow与其他深度学习框架的优劣特性比较，以及如何利用本书学好深度学习这门学科（重点是要用对深度学习的热情火焰，烧出足以融化沙漠的温度，将这本入门书籍“化为灰烬”）。</p>
<p><img src="Image00004.jpg" alt></p>
<h3 id="1-1-什么是深度学习"><a href="#1-1-什么是深度学习" class="headerlink" title="1.1 什么是深度学习"></a>1.1 什么是深度学习</h3><p>提到人工智能，人们往往会想到深度学习，然而，深度学习不像人工智能那样容易从字面上理解。这是因为深度学习是从内部机理来阐述的，而人工智能是从其应用的角度来阐述的，即深度学习是实现人工智能的一种方法。</p>
<p>人工智能领域，起初是进行神经网络的研究。但神经网络发展到一定阶段后，模型越来越庞大，结构也越来越复杂，于是人们将其命名为“深度学习”。可以这样理解——深度学习属于后神经网络时代。</p>
<p>深度学习近年来的发展突飞猛进，越来越多的人工智能应用得以实现。其本质为一个可以模拟人脑进行分析、学习的神经网络，它模仿人脑的机制来解释数据（如图像、声音和文本），通过组合低层特征，形成更加抽象的高层特征或属性类别，来拟合人们日常生活中的各种事情。</p>
<p>深度学习被广泛用于与人们生活息息相关的各种领域，可以实现机器翻译、人脸识别、语音识别、信号恢复、商业推荐、金融分析、医疗辅助和智能交通等。</p>
<p>在国内乃至世界，越来越多的资金涌向人工智能领域，人工智能领域新成立的创业公司每年呈递增趋势，越来越多的学校也开始开设与深度学习相关的课程。这个时代，正像是移动互联网的前夜。如果你也感觉到了，那么现在正是时候，一起加入进来，通过系统的学习，将自己打造成为一名深度学习的专业人才吧。</p>
<h3 id="1-2-TensorFlow是做什么的"><a href="#1-2-TensorFlow是做什么的" class="headerlink" title="1.2 TensorFlow是做什么的"></a>1.2 TensorFlow是做什么的</h3><p>TensorFlow是Google开源的第二代用于数字计算的软件库。起初，它是Google大脑团队为了研究机器学习和深度神经网络而开发的，但后来发现这个系统足够通用，能够支持更加广泛的应用，就将其开源贡献了出来。</p>
<p>概括地说，TensorFlow可以理解为一个深度学习框架，里面有完整的数据流向与处理机制，同时还封装了大量高效可用的算法及神经网络搭建方面的函数，可以在此基础之上进行深度学习的开发与研究。本书是基于TensorFlow来进行深度学习研究的。</p>
<p>TensorFlow是当今深度学习领域中最火的框架之一。在GitHub上，TensorFlow的受欢迎程度目前排名第一（如图1-1所示），以3倍左右的数量遥遥领先于第二名。</p>
<p><img src="Image00005.jpg" alt></p>
<p>图1-1 GitHub上TensorFlow受欢迎程度排名第一</p>
<p>图1-1来源于地址<a href="https://github.com/hunkim/DeepLearningStars" target="_blank" rel="noopener">https://github.com/hunkim/DeepLearningStars</a> 。</p>
<p>选择TensorFlow进行学习的优势是，在深度学习道路上不会孤单，会有大于同等框架几倍的资料可供学习，以及更多的爱好者可以相互学习、交流。更重要的是，目前越来越多的学术论文都更加倾向于在TensorFlow上开发自己的示例原型。这一得天独厚的优势，可以让学习者在同步当今最新技术的过程中，省去不少时间。</p>
<h3 id="1-3-TensorFlow的特点"><a href="#1-3-TensorFlow的特点" class="headerlink" title="1.3 TensorFlow的特点"></a>1.3 TensorFlow的特点</h3><p>TensorFlow是用C++语言开发的，支持C、Java、Python等多种语言的调用，目前主流的方式通常会使用Python语言来驱动应用。这一特点也是其能够广受欢迎的原因。利用C++语言开发可以保证其运行效率，Python作为上层应用语言，可以为研究人员节省大量的开发时间。</p>
<p>TensorFlow相对于其他框架有如下特点。</p>
<p>1．灵活</p>
<p>TensorFlow与CNTK、MXNET、Theano同属于符号计算构架，允许用户在不需要使用低级语言（如在Caffe中）实现的情况下，开发出新的复杂层类型。基于图运算是其基本特点，通过图上的节点变量可以控制训练中各个环节的变量，尤其在需要对底层操作时，TensorFlow要比其他框架更容易。当然它也有缺点，灵活的操作会增加使用复杂度，从而在一定程度上增加了学习成本。</p>
<p>2．便捷、通用</p>
<p>作为主流的框架，TensorFlow生成的模型，具有便捷、通用的特点，可以满足更多使用者的需求。TensorFlow可以适用于Mac、Linux、Windows系统上开发。其编译好的模型几乎适用于当今所有的平台系统，并提满足“开箱即用”的模型使用理念，使模型应用起来更简单。</p>
<p>3．成熟</p>
<p>由于TensorFlow被使用的情况最多，所以其框架的成熟度绝对是第一的。在Google的白皮书上写道，Google内部有大量的产品几乎都用到了TensorFlow，如搜索排序、语音识别、谷歌相册和自然语言处理等。有这么多在该框架上的成功案例，先不说能够提供多少经验技巧，至少可以确保学习者在研究的道路上，遇到挫折时不会怀疑是框架的问题。</p>
<p>4．超强的运算性能</p>
<p>虽然TensorFlow在大型计算机集群的并行处理中，运算性能仅略低于CNTK，但是，其在个人机器使用场景下，会根据机器的配置自动选择CPU或GPU来运算，这方面做得更加友好与智能化。</p>
<h3 id="1-4-其他深度学习框架特点及介绍"><a href="#1-4-其他深度学习框架特点及介绍" class="headerlink" title="1.4 其他深度学习框架特点及介绍"></a>1.4 其他深度学习框架特点及介绍</h3><p>下面再来了解一下深度学习领域中的其他常见框架。</p>
<p>·Theano：是一个十余年的Python深度学习和机器学习框架，用来定义、优化和模拟数学表达式计算，用于高效地解决多维数组的计算问题，有较好的扩展性。</p>
<p>·Torch：同样具有很好的扩展性，但某些接口不够全面，如WGAN-GP这样的网络需要手动来修改梯度就没有对应的接口。其最大的缺点是，需要LuaJIT的支持，用于Lua语言，在Python为王的今天，通用性方面显得较差。</p>
<p>·Keras：可以理解为一个Theano框架与TensorFlow前端的一个组合。其构建模型的API调用方式逐渐成为主流，包括TensorFlow、CNTK、MXNet等知名框架，都提供对Keras调用语法的支持。可以说，使用Keras编写的代码，会有更好的可移值性。</p>
<p>·DeepLearning4j：是基于Java和Scala语言开发的，应用在Hadoop和Spark系统之上的深度学习软件。</p>
<p>·Caffe：当年深度学习的老大。最初是一个强大的图像分类框架，是最容易测试评估性能的标准深度学习框架，并且提供很多预训练模型，尤其该模型的复用价值在其他框架的学习中都会出现，大大提升了现有模型的训练时间。但是现在的Caffe似乎停滞不前，没有更新。尽管Caffe又重新掘起，从架构上看更像是TensorFlow，而且与原来的Caffe也不在一个工程里，可以独立成一个框架来看待，与原Caffe关系不大。但仍不建议使用。</p>
<p>·MXNet：是一个可移植的、可伸缩的深度学习库，具有Torch、Theano、Chainer和Caffe的部分特性。不同程度的支持Python、R、Scala、Julia和C<br>++语言，也是目前比较热门的主流框架之一。</p>
<p>·CNTK：是一个微软开发的深度学习软件包，以速度快著称，有其独有的神经网络配置语言Brain Script，大大降低了学习门槛。有微软作为后盾，CNTK成为了最具有潜力与Tensor Flow争夺天下的框架。但目前其成熟度要比Tensor Flow差太多，即便是发行的版本也会有大大小小的bug。与其他框架一样，CNTK具有文档资料不足的特点。但其与Visual Studio的天生耦合，以及其特定的MS编程风格，使得熟悉Visual Studio工具的小伙伴们从代码角度极易上手。另外，CNTK目前还不支持Mac操作系统。</p>
<h3 id="1-5-如何通过本书学好深度学习"><a href="#1-5-如何通过本书学好深度学习" class="headerlink" title="1.5 如何通过本书学好深度学习"></a>1.5 如何通过本书学好深度学习</h3><p>从小老师就教导我们，做事情要讲究方法，一个好的学习方法能带给你事半功倍的效果。对于深度学习也一样，如果之前是因为没有一本系统的教材，让你对深度学习毫无头绪的话，那么现在机会来了。通过本书的指引，你将会通过实例由浅入深逐步上手，直到最终掌握深度学习的相关知识。下面就来说下如何通过本书来学习深度学习。</p>
<h4 id="1-5-1-深度学习怎么学"><a href="#1-5-1-深度学习怎么学" class="headerlink" title="1.5.1 深度学习怎么学"></a>1.5.1 深度学习怎么学</h4><p>这个问题完全是主观回答，因为不同的人有不同的领悟。所以笔者也只能聊聊自己对学习深度学习方法的理解。</p>
<p>举个例子，在笔者的家乡有练武术的习惯，平时有人找老师傅学拳时，一般老师傅都会先了解他学拳的目的是什么，然后再根据他的目的来选择需要教哪些内容。</p>
<p>·对于只为了打架能赢的人，老师傅会先以力量和重拳的训练开始，中间穿插点对抗，一般1个月左右对付2、3个普通人没什么问题。</p>
<p>·对于想集训打比赛的人，老师傅会以体能、力量、抗击打等身体素质训练为主，配合大量的对抗练习刺激反应，起码上场要保证能够打完全程。</p>
<p>·对于爱好武学想系统学习的人，则需要从步伐、拳、腿一点一点练习。然后再加上摔法，对抗之类的技巧，同时配合阵图、战机等理论。</p>
<p>·笔者觉得用这个例子来类比深度学习非常恰当。</p>
<p>·假如你手里有短期任务，想快速用深度学习解决某一个功能，那么就针对该领域找现成的例子，扫清例子中的盲点，快速熟悉并修改、使用。</p>
<p>·假如想近期提升一下自己，应对跳槽，挑战工作等，那就需要将主干知识点记住并能说出来，然后亲自演练每个领域的例子，保证自己知道其原理。</p>
<p>·如果想在这条路上一直走下去，而眼前并没有紧急要应对的事情，那么可以一步一步地学，通过“努力+时间”的积累，得到的才是功夫。</p>
<p>如同学拳一样，拳击训练是必不可少的，出过百万次拳的水平跟出过1万次拳的水平绝对是不一样的。同理，编写代码也是必不可少的。有过百万行代码编写经验的水平也远远胜过1万行代码编写经验的水平。时间在你努力的期间起到催化剂的作用，在空余时间多去思考，多尝试用自己的思维和角度去理解你所接触的相对生僻的事情，这个习惯不仅会使你学习深度学习变得容易，还会使你对它越学越有兴趣，而且这个习惯也适用于其他领域。</p>
<h4 id="1-5-2-如何学习本书"><a href="#1-5-2-如何学习本书" class="headerlink" title="1.5.2 如何学习本书"></a>1.5.2 如何学习本书</h4><p>前面的道理懂了之后，我们就来看看如何学习本书。针对与前面讲述的3个场景，可以在本书中依次找到对应关系。书中的每一节都由理论+实例的结构组成。针对三种场景可以有如下策略。</p>
<p>1．短期任务</p>
<p>快速定位你手中的任务所需要的知识点，依次在本书中找到最匹配的例子，按照步骤一步一步实现它。细节原理可以先不去管，主要把数据源即数据流向和知识结构弄清楚即可。按照例子做完之后，相信你会有个大概的感觉，然后再应用里面的知识着手去做自己的任务。</p>
<p>2．应对挑战突击</p>
<p>这个策略需要将书中的文字理论部分快速读完，并且理解、记住。对于实例代码，可以大致过一遍，但需要注意的提示内容必须要看，并且记住，这些提示内容会使你给人留下一种很有经验的印象。</p>
<p>3．踏实学习</p>
<p>按照本书的章节一步一步地学习，该学理论学理论，该做配套的例子做例子。因为本书的知识结构并不是按照知识面的属性排列的，而是考虑到读者的接受程度排列的，例如对属于第3章的某个知识点，考虑到刚学习的读者接受起来会很费劲，而且短时期用不到这个知识，那么就将其移到第5章，需要用到这个知识点时再介绍。假设读者是从第1章学过来的，那么学到第5章时，对于这个知识点已经可以很轻松地理解了。</p>
<p>另外，本书尽可能地不用学术术语及公式来描述理论，但由于无法预知读者在学习此书时的知识基础与接受程度，难免在阅读时会遇到没有接触过的生僻术语及理论，此时可以自己多上网查阅相关资料，或给笔者发邮件，只要有时间笔者都会认真回复。</p>
<h2 id="第2章-搭建开发环境"><a href="#第2章-搭建开发环境" class="headerlink" title="第2章 搭建开发环境"></a>第2章 搭建开发环境</h2><p>本章将进入本书的入门阶段，先从环境的搭建开始。虽然TensorFlow支持CPU运行，但是也会有一些实例只能在GPU上运行。所以很有必要在学习本书之前购买一个带有GPU显卡的计算机。</p>
<p>本书使用的是Python 3.5开发环境，开发工具使用Anaconda，操作系统使用Windows 10。TensorFlow的学习中与操作系统无关，读者可以使用Linux或Mac，也可以使用其他操作系统。如果读者对安装过程已经掌握了，可以跳过本章。</p>
<p>本章含有教学视频共6分52秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，包括关于TersonFlow的开发环境和GTX显卡驱动部分的介绍（重点是TersonFlow的完整安装）。</p>
<p><img src="Image00006.jpg" alt></p>
<h3 id="2-1-下载及安装Anaconda开发工具"><a href="#2-1-下载及安装Anaconda开发工具" class="headerlink" title="2.1 下载及安装Anaconda开发工具"></a>2.1 下载及安装Anaconda开发工具</h3><p>下面介绍Anaconda的下载及安装方法。</p>
<p>（1）通过百度找到Anaconda官网，单击第一个链接，如图2-1所示。或者直接访问网站<a href="http://www.anaconda.com" target="_blank" rel="noopener">http://www.anaconda.com</a> 。</p>
<p>（2）进入Anaconda官网，单击右上角的DOWNLOAD按钮，如图2-2所示。</p>
<p>（3）将屏幕拉到下面，单击最右测的链接Packages Included in Anaconda，如图2-3所示。</p>
<p><img src="Image00007.jpg" alt></p>
<p>图2-1 找到Anaconda官网</p>
<p><img src="Image00008.jpg" alt></p>
<p>图2-2 Anaconda首页</p>
<p><img src="Image00009.jpg" alt></p>
<p>图2-3 DOWNLOAD选项</p>
<p>（4）进入Packages Included in Anaconda页面，单击图中最后一行的package repository链接，如图2-4所示。</p>
<p>（5）进入Package repository页面，如图2-5所示。最后一行是下载裁剪后的版本。如果硬盘足够大，建议选倒数第二行的链接下载。</p>
<p>（6）进入完全版本的安装，如图2-6所示。这里有Linux、Windows、Mac OSX的各种版本，可以任意选择。</p>
<p><img src="Image00010.jpg" alt></p>
<p>图2-4 conda安装包</p>
<p><img src="Image00011.jpg" alt></p>
<p>图2-5 下载链接</p>
<p><img src="Image00012.jpg" alt></p>
<p>图2-6 下载列表</p>
<p>注意： Anaconda的不同版本默认支持的Python版本是不一样的。对于支持Python 2的版本，统一以Anaconda 2为开头来命名；对于支持Python 3的版本，统一以Anaconda 3为开头来命名。当前最新的版本为5.0.0。可以支持Python 3.6版本。</p>
<p>TensorFlow中的1.3以前的版本不支持Python 3.6版本。为了更好地兼容，不建议下载最新的Anaconda 3版本，而是推荐使用Anaconda 3中支持Python 3.5的版本。例如：4.1.1、4.2.0等。</p>
<p>本书中使用的是Python 3.5版本，全文以该版本为例。</p>
<p>下面以Windows为例，来介绍具体的安装步骤。</p>
<p>以Anaconda 3-4.1.1版本（默认使用Python 3.5）为例，下载地址为<a href="https://repo.continuum.io/%20archive/Anaconda3-4.1.1-Windows-x86_64.exe" target="_blank" rel="noopener">https://repo.continuum.io/ archive/Anaconda3-4.1.1-Windows-x86_64.exe</a> 。</p>
<p>假设安装位置为C：\local\Anaconda3-4.1.1-Windows-x86_64，安装好之后自动带有pip软件，可以通过pip安装其他软件。</p>
<h3 id="2-2-在Windows平台下载及安装TensorFlow"><a href="#2-2-在Windows平台下载及安装TensorFlow" class="headerlink" title="2.2 在Windows平台下载及安装TensorFlow"></a>2.2 在Windows平台下载及安装TensorFlow</h3><p>首先来到<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a> ，在该页面中有安装文件的下载地址，如图2-7所示。</p>
<p><img src="Image00013.jpg" alt></p>
<p>图2-7 TensorFlow安装文件</p>
<p>1．在线安装nightly包</p>
<p>nightly安装包是TensorFlow团队2017年下半年推出的安装模式。适用于在一个全新的环境下进行TensorFlow的安装。在安装TensorFlow的同时，默认会把需要依赖的库也一起装上，是非常方便、快捷的安装方式。</p>
<p>按照图2-7中的方法直接使用命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tf-nightly</span><br></pre></td></tr></table></figure>
<p>即可下载并安装TensorFlow的最新CPU版本。若要安装最新的GPU版本可以使用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tf-nightly-gpu</span><br></pre></td></tr></table></figure>
<p>2．安装纯净的TensorFlow</p>
<p>如果想安装纯净的TensorFlow版本，直接输入下面命令即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure>
<p>上面是CPU版本，GPU版本的安装命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-gpu</span><br></pre></td></tr></table></figure>
<p><img src="Image00014.jpg" alt> 注意： 在网速不稳定的情况下，在线安装有时会因为无法成功下载到完整的安装包而导致安装失败。可以通过重复执行安装命令或采用离线安装的方式来解决。</p>
<p>3．更新安装TensorFlow</p>
<p>如果本地已经装有TensorFlow，需要升级为新版本的TensorFlow，只需要将原有版本卸载，再次安装即可。卸载命令如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall &lt;安装时的TensorFlow 名称&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>4．离线安装</p>
<p>有时由于网络环境的因素，无法实现在线安装，需要在网络环境好的地方提前将安装包下载下来进行离线安装。</p>
<p>（1）下载安装包。</p>
<p>可以访问以下网站来查找TensorFlow的发布版本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://storage.googleapis.com/tensorflow/</span><br></pre></td></tr></table></figure>
<p>该网站内容是以XML方式提供的，查找起来不是很方便。可以通过地址加上指定的文件名方式进行下载。例如，一个TensorFlow 1.4.0的CPU版本安装包下载路径为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.4.0-cp35-cp35m-win_amd64.whl</span><br></pre></td></tr></table></figure>

</details>

<p>TensorFlow1.4.0的GPU版本安装包下载路径为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.4.0-cp35-cp35m-win_amd64.whl</span><br></pre></td></tr></table></figure>

</details>

<p>如果要下载1.3.0的版本，直接将上面链接中的1.4.0改成1.3.0即可。</p>
<p>（2）安装安装包。</p>
<p>下载完TensorFlow二进制文件后，假设使用CPU版本并且安装在D：\tensorflow下。选择“开始”|“运行”命令，在弹出的窗口中输入cmd，打开命令行窗口，然后输入如下命令来安装TensorFlow二进制文件。</p>
<p>C：\Users\Administrator&gt;D：</p>
<p>D：>cd tensorflow</p>
<p>D：\tensorflow&gt;</p>
<p>D：\tensorflow&gt;pip install tensorflow-1.1.0-cp35-cp35m-win_amd64.whl</p>
<h3 id="2-3-GPU版本的安装方法"><a href="#2-3-GPU版本的安装方法" class="headerlink" title="2.3 GPU版本的安装方法"></a>2.3 GPU版本的安装方法</h3><p>如果使用GPU版本，在执行pip之后，还需要安装CUDA和CuDNN。</p>
<h4 id="2-3-1-安装CUDA软件包"><a href="#2-3-1-安装CUDA软件包" class="headerlink" title="2.3.1 安装CUDA软件包"></a>2.3.1 安装CUDA软件包</h4><p>首先来到CUDA官方网站<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a> ，单击Windows按钮后，如图2-8所示。</p>
<p><img src="Image00015.jpg" alt></p>
<p>图2-8 CUDA页面</p>
<p>根据自己的环境选择对应的版本，.exe安装文件分为网络版和本地版。网络版安装包比较小，执行安装时再去下载需要的安装包；本地版安装包是直接下载完整的安装包。下载完成后正常安装就可以了。</p>
<p><img src="Image00014.jpg" alt> 注意： CUDA软件包也有很多个版本，必须与TensorFlow的版本对应才行。比如TensorFlow 1.0以后，直到TensorFlow 1.5的版本只支持CUDA 8.0。在本书中也是使用的CUDA 8.0版本来做演示的。可以根据链接<a href="https://developer.nvidia.%20com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia. com/cuda-toolkit-archive</a> 找到更多版本。</p>
<h4 id="2-3-2-安装cuDNN库"><a href="#2-3-2-安装cuDNN库" class="headerlink" title="2.3.2 安装cuDNN库"></a>2.3.2 安装cuDNN库</h4><p>输入<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn</a> 网址来到下载页面，需要注册并填一些问卷才能下载这个安装包。</p>
<p>cuDNN的版本选择也是有规定的。以Windows 10操作系统为例，TensorFlow 1.0到TensorFlow 1.2版本使用的是cuDNN的5.1版本（安装包文件为cudnn-8.0-windows10-x64-v5.1-zip），从TensorFlow 1.3版本之后使用的是cuDNN的6.0版本（cudnn-8.0-windows10-x64-v6.0.zip）。</p>
<p>得到相关包后解压，直接复制到cuda路径对应的文件夹下面就行，如图2-9所示。</p>
<p><img src="Image00016.jpg" alt></p>
<p>图2-9 安装cuDNN</p>
<h4 id="2-3-3-测试显卡"><a href="#2-3-3-测试显卡" class="headerlink" title="2.3.3 测试显卡"></a>2.3.3 测试显卡</h4><p>这里再额外介绍两个小命令，它可以检测出在安装过程中产生的问题。</p>
<p>1．使用nvidia-smi命令查看显卡信息</p>
<p>nvidia-smi指的是NVIDIA System Management Interface。在安装完成NVIDIA显卡驱动之后，对于Windows用户而言，cmd命令行界面还无法识别nvidia-smi命令，需要将相关环境变量添加进去。如果将NVIDIA显卡驱动安装在默认位置，nvidia-smi命令所在的完整路径应为：</p>
<p>C：\Program Files\NVIDIA Corporation\NVSMI</p>
<p>将上述路径添加进Path系统环境变量中。之后在cmd中运行nvidia-smi命令，可以看到显卡信息如图2-10所示。</p>
<p><img src="Image00017.jpg" alt></p>
<p>图2-10 显卡信息</p>
<p>图2-10中第1行是笔者的驱动信息，第3行是笔者的显卡信息GeForce GTX 1070。第4行和第5行是当前使用显卡的进程。</p>
<p>这些信息都存在了，表明笔者的安装是正确的。</p>
<p>2．查看CUDA的版本</p>
<p>同样在cmd中使用命令nvcc –V，显示如图2-11所示。</p>
<p><img src="Image00018.jpg" alt></p>
<p>图2-11 查看CUDA版本</p>
<p>3．在Linux和Mac平台上安装</p>
<p>关于在Linux和Mac上安装TensorFlow的方法，可以参考网址<a href="http://www.tensorfly.%20cn/tfdoc/%20get_started/%20os_setup.html" target="_blank" rel="noopener">http://www.tensorfly. cn/tfdoc/ get_started/ os_setup.html</a> ，这里不再展开讲述。</p>
<p>4．问题处理</p>
<p>如果遇到问题的话，可以尝试下面的解决办法：</p>
<p>在命令行里输入where MSVCP140.DLL看看本机是否有MSVCP140.DLL，如果没有可以按照如下网址安装Visual C++ Redistributable 2015。</p>
<p>安装Visual C++ Redistributable 2015 x64（操作系统Windows10 64位），下载地址如下：</p>
<p><a href="https://www.microsoft.com/en-us/download/details.aspx%EF%BC%9Fid=53587" target="_blank" rel="noopener">https://www.microsoft.com/en-us/download/details.aspx？id=53587</a>  </p>
<h3 id="2-4-熟悉Anaconda-3开发工具"><a href="#2-4-熟悉Anaconda-3开发工具" class="headerlink" title="2.4 熟悉Anaconda 3开发工具"></a>2.4 熟悉Anaconda 3开发工具</h3><p>在本书中使用到的开发环境是Anaconda 3，在Anaconda 3里常用的有两个工具，即Spyder和Jupyter Notebook，它们的位置在开始菜单的Anaconda 3（64-bit）目录下，如图2-12所示。</p>
<p><img src="Image00019.jpg" alt></p>
<p>图2-12 Spyder和Jupyter Notebook的安装目录</p>
<h4 id="2-4-1-快速了解Spyder"><a href="#2-4-1-快速了解Spyder" class="headerlink" title="2.4.1 快速了解Spyder"></a>2.4.1 快速了解Spyder</h4><p>本书推荐使用Spyder作为编译器的原因是它比较方便，从安装到使用都做了相关的集成，只下载一个安装包即可，省去了大量的搭建环境时间。另外，Spyder的IDE功能也很强大，基本上可以满足日常需要。下面通过几个常用的功能来介绍下其使用细节。</p>
<p>1．面板介绍</p>
<p>如图2-13所示，Spyder启动后可以分为7个区域。</p>
<p><img src="Image00020.jpg" alt></p>
<p>图2-13 Spyder面板</p>
<p>·菜单栏：放置所有的功能。</p>
<p>·快捷菜单栏：是菜单栏的快捷方式，其上面需要放置哪些快捷菜单，可以通过菜单栏中View的Toolbars的复选框来勾选，如图2-14所示。</p>
<p>·工作区：就是代码要写的地方。</p>
<p>·属性页的标题栏：可以显示当前代码的名字及位置。</p>
<p>·查看栏：可以查看文件、调试时的对象及变量。</p>
<p>·输出栏：可以看到程序的输出信息，也可以作为shell终端来输入Python语句。</p>
<p>·状态栏：用来显示当前文件权限、编码，光标指向位置和系统内存。</p>
<p>2．注释功能</p>
<p>注释功能为编写代码中很常用的功能，下面介绍Spyder的批量注释功能，在图2-14中，勾选Edit toolbar复选框，会看到如图2-15所示的注释按钮。</p>
<p><img src="Image00021.jpg" alt></p>
<p>图2-14 快捷菜单设置</p>
<p><img src="Image00022.jpg" alt></p>
<p>图2-15 注释按钮</p>
<p>当选中几行代码之后，单击该按钮即可对代码进行注释，再次单击为取消注释。该按钮右边两个按钮是代码缩进与不缩进按钮，不常用。可以通过Tab键与Shift+Tab键来实现。</p>
<p>3．运行程序功能</p>
<p>如图2-16中，标注1按钮为运行当前工作区内的Python文件，单击2按钮会弹出一个Run settings对话框，可以输入启动程序的参数，如图2-16中标注框所示。</p>
<p><img src="Image00023.jpg" alt></p>
<p>图2-16 运行程序</p>
<p>4．调试功能</p>
<p>如图2-16中右侧的按钮为调试功能的按钮，Python在运行中同样可以通过设置断点来进行调试。</p>
<p>5．Source操作</p>
<p>当同时打开多个代码时，有时想回到刚刚看的代码的位置，Spyder中有一个功能可以实现，在图2-14中，勾选Source toolbar复选框会看到如图2-17所示按钮，左边第一个按钮为建立书签，第二个按钮为回退上次的代码位置，第三个按钮为前进到下次代码位置。</p>
<p><img src="Image00024.jpg" alt></p>
<p>图2-17 Source</p>
<p>以上都是关于Spyder的常用操作。当然Spyder还有很多功能这里就不一一介绍了。</p>
<h4 id="2-4-2-快速了解Jupyter-Notebook"><a href="#2-4-2-快速了解Jupyter-Notebook" class="headerlink" title="2.4.2 快速了解Jupyter Notebook"></a>2.4.2 快速了解Jupyter Notebook</h4><p>在深度学习中，有好多代码都被做成扩展名为ipynb的文件，这是一个关于Jupyter Notebook的文件，可以既当说明文档，又能运行Python代码的文件。Anaconda中也集成了这个软件。在图2-12中找到Jupyter Notebook项，单击即可看到如图2-18所示界面。</p>
<p><img src="Image00025.jpg" alt></p>
<p>图2-18 Jupyter界面</p>
<p>该程序是B/S结构，会先启动一个Web服务器，然后再启动一个浏览器，通过浏览器来访问本机的服务。在这里面可以上传、下载，并编写自己的ipynb文件代码。</p>
<p>关于Jupyter Notebook工具的具体使用，这里不做过多介绍。有兴趣的读者可以参考网络上的众多使用教程。</p>
<h2 id="第3章-TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例"><a href="#第3章-TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例" class="headerlink" title="第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例"></a>第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例</h2><p>环境搭建好之后，读者一定迫不及待地想试试深度学习的程序了吧。本章就直接将一个例子拿出来，在没有任何基础的前提下，一步一步实现一个简单的神经网络。通过这个实例来理解模型，并了解TensorFlow开发的基本步骤。</p>
<p>本章含有教学视频共3分51秒。</p>
<p>作者按照本章的内容，讲解了一个使用神经网络拟合简单算式的例子，并借助这个例子介绍了TersonFlow的基本开发步骤（重点为了解基本开发步骤部分）。</p>
<p><img src="Image00026.jpg" alt></p>
<h3 id="3-1-实例1：从一组看似混乱的数据中找出y≈2x的规律"><a href="#3-1-实例1：从一组看似混乱的数据中找出y≈2x的规律" class="headerlink" title="3.1 实例1：从一组看似混乱的数据中找出y≈2x的规律"></a>3.1 实例1：从一组看似混乱的数据中找出y≈2x的规律</h3><p>本节通过一个简单的逻辑回归实例为读者展示深度学习的神奇。通过对代码的具体步骤，让读者对深度学习有一个直观的印象。</p>
<p>实例描述</p>
<p>假设有一组数据集，其x和y的对应关系为y≈2x。</p>
<p>本实例就是让神经网络学习这些样本，并能够找到其中的规律，即让神经网络能够总结出y≈2x这样的公式。</p>
<p>深度学习大概有如下4个步骤：</p>
<p>（1）准备数据。</p>
<p>（2）搭建模型。</p>
<p>（3）迭代训练。</p>
<p>（4）使用模型。</p>
<p>准备数据阶段一般就是把任务的相关数据收集起来，然后建立网络模型，通过一定的迭代训练让网络学习到收集来的数据特征，形成可用的模型，之后就是使用模型来为我们解决问题。</p>
<h4 id="3-1-1-准备数据"><a href="#3-1-1-准备数据" class="headerlink" title="3.1.1 准备数据"></a>3.1.1 准备数据</h4><p>这里使用y=2x这个公式来做主体，通过加入一些干扰噪声让它的“等号”变成“约等于”。</p>
<p>具体代码如下：</p>
<p>·导入头文件，然后生成-1～1之间的100个数作为x，见代码第1～5行。</p>
<p>·将x乘以2，再加上一个[-1，1]区间的随机数×0.3。即，y=2×x+a×0.3（a属于[-1，1]之间的随机数），见代码第6行。</p>
<p>代码3-1 线性回归</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">     import numpy as np</span><br><span class="line">     import matplotlib.pyplot as plt</span><br><span class="line">     </span><br><span class="line">     train_X = np.linspace(-1, 1, 100)</span><br><span class="line">     train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3 # y=2x，</span><br><span class="line">       但是加入了噪声</span><br><span class="line">     #显示模拟数据点</span><br><span class="line">     plt.plot(train_X, train_Y,</span><br><span class="line">       &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">     plt.legend()</span><br><span class="line">     plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： np.random.randn（*train_X.shape）这个代码如果看起来比较奇怪，现在给出解释—它等同于np.random. randn（100）</p>
<p>运行上面代码，显示结果如图3-1所示。</p>
<p><img src="Image00027.jpg" alt></p>
<p>图3-1 准备好的线性回归数据集</p>
<h4 id="3-1-2-搭建模型"><a href="#3-1-2-搭建模型" class="headerlink" title="3.1.2 搭建模型"></a>3.1.2 搭建模型</h4><p>现在开始进行模型搭建。模型分为两个方向：正向和反向。</p>
<p>1．正向搭建模型</p>
<p>（1）了解模型及其公式</p>
<p>在具体操作之前，先来了解一下模型的样子。神经网络是由多个神经元组成的，单个神经元的网络模型如图3-2所示。</p>
<p><img src="Image00028.jpg" alt></p>
<p>图3-2 神经元模型</p>
<p>其计算公式见式（3-1）：</p>
<p><img src="Image00029.jpg" alt></p>
<p>式中，z为输出的结果，x为输入，w为权重，b为偏执值。</p>
<p>z的计算过程是将输入的x与其对应的w相乘，然后再把结果相加上偏执b。</p>
<p>例如，有3个输入x1 ，x2 ，x3 ，分别对应w1 ，w2 ，w3 ，则，z=x1 ×w1 +x2 ×w2 +x3 ×w3<br>+b。这一过程中，在线性代数中正好可以用两个矩阵来表示，于是就可以写成（矩阵W）×（矩阵X）+b。矩阵相乘的展开如式（3-2）：</p>
<p><img src="Image00030.jpg" alt></p>
<p>上面的算式（3-2）表明：形状为1行3列的矩阵与3行1列的矩阵相乘，结果的形状为1行1列的矩阵，即（1，3）×（3，1）=（1，1）</p>
<p><img src="Image00014.jpg" alt> 注意： 这里有个小窍门，如果想得到两个矩阵相乘后的形状，可以将第一个矩阵的行与第二个矩阵的列组合起来，就是相乘后的形状。</p>
<p>在神经元中，w和b可以理解为两个变量。模型每次的“学习”都是调整w和b以得到一个更合适的值。最终，有这个值配合上运算公式所形成的逻辑就是神经网络的模型。</p>
<p>（2）创建模型</p>
<p>下面的代码演示了如何创建图3-2中的模型。</p>
<p>代码3-1 线性回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 创建模型</span><br><span class="line"># 占位符</span><br><span class="line">X = tf.placeholder(&quot;float&quot;)</span><br><span class="line">Y = tf.placeholder(&quot;float&quot;)</span><br><span class="line"># 模型参数</span><br><span class="line">W = tf.Variable(tf.random_normal([1]), name=&quot;weight&quot;)</span><br><span class="line">b = tf.Variable(tf.zeros([1]), name=&quot;bias&quot;)</span><br><span class="line"># 前向结构</span><br><span class="line">z = tf.multiply(X, W)+ b</span><br></pre></td></tr></table></figure>

</details>

<p>下面解说一下代码。</p>
<p>（1）X和Y：为占位符，使用了placeholder函数进行定义。一个代表x的输入，一个代表对应的真实值y。占位符的意思后面再解释。</p>
<p>（2）W和b：就是前面说的参数。W被初始化成[-1，1]的随机数，形状为一维的数字，b的初始化为0，形状也是一维的数字。</p>
<p>（3）Variable：定义变量，在3.3节会有详细介绍。</p>
<p>（4）tf.multiply：是两个数相乘的意思，结果再加上b就等于z了。</p>
<p>2．反向搭建模型</p>
<p>神经网络在训练的过程中数据的流向有两个方向，即先通过正向生成一个值，然后观察其与真实值的差距，再通过反向过程将里面的参数进行调整，接着再次正向生成预测值并与真实值进行比对，这样循环下去，直到将参数调整为合适值为止。</p>
<p>正向相对比较好理解，反向传播会引入一些算法来实现对参数的正确调整。</p>
<p>下面先看一下反向优化的相关代码。</p>
<p>代码3-1 线性回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> #反向优化</span><br><span class="line">cost = tf.reduce_mean(tf.square(Y -z))</span><br><span class="line">learning_rate = 0.01</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize </span><br><span class="line">  (cost)  #梯度下降</span><br></pre></td></tr></table></figure>

</details>

<p>代码说明如下：</p>
<p>（1）第21行定义一个cost，它等于生成值与真实值的平方差。</p>
<p>（2）第22行定义一个学习率，代表调整参数的速度。这个值一般是小于1的。这个值越大，表明调整的速度越大，但不精确；值越小，表明调整的精度越高，但速度慢。这就好比生物课上的显微镜调试，显微镜上有两个调节焦距的旋转钮，分为粗调和细调。</p>
<p>（3）第23行GradientDescentOptimizer函数是一个封装好的梯度下降算法，里面的参数learning_rate叫做学习率，用来指定参数调节的速度。如果将“学习率”比作显微镜上不同档位的“调节钮”，那么梯度下降算法也可以理解成“显微镜筒”，它会按照学习参数的速度来改变显微镜上焦距的大小。</p>
<h4 id="3-1-3-迭代训练模型"><a href="#3-1-3-迭代训练模型" class="headerlink" title="3.1.3 迭代训练模型"></a>3.1.3 迭代训练模型</h4><p>迭代训练的代码分成两步来完成：</p>
<p>1．训练模型</p>
<p>建立好模型后，可以通过迭代来训练模型了。TensorFlow中的任务是通过session来进行的。</p>
<p>下面的代码中，先进行全局初始化，然后设置训练迭代的次数，启动session开始运行任务。</p>
<p>代码3-1 线性回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#初始化所有变量</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">#定义参数</span><br><span class="line">training_epochs = 20</span><br><span class="line">display_step = 2</span><br><span class="line"></span><br><span class="line">#启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    plotdata=&#123;&quot;batchsize&quot;:[],&quot;loss&quot;:[]&#125; #存放批次值和损失值</span><br><span class="line">    #向模型输入数据</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        for (x, y) in zip(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line"></span><br><span class="line">        #显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            loss = sess.run(cost,feed_dict=&#123;X:train_X,Y:train_Y&#125;)</span><br><span class="line">            print (&quot;Epoch:&quot;, epoch+1,&quot;cost=&quot;, loss,&quot;W=&quot;,sess.run(W), </span><br><span class="line">              &quot;b=&quot;, sess.run(b))</span><br><span class="line">            if not (loss == &quot;NA&quot; ):</span><br><span class="line">                plotdata[&quot;batchsize&quot;].append(epoch)</span><br><span class="line">                plotdata[&quot;loss&quot;].append(loss)</span><br><span class="line"></span><br><span class="line">    print (&quot; Finished!&quot;)</span><br><span class="line">    print (&quot;cost=&quot;, sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;), </span><br><span class="line">      &quot;W=&quot;, sess.run(W), &quot;b=&quot;, sess.run(b))</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码中迭代次数设置为20次，通过sess.run来进行网络节点的运算，通过feed机制将真实数据灌到占位符对应的位置（feed_dict={X： x，Y： y}），同时，每执行一次都会将网络结构中的节点打印出来。</p>
<p>运行代码，输出信息如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 1 cost= 0.714926 W= [ 0.71911603] b= [ 0.40933588]</span><br><span class="line">Epoch: 3 cost= 0.114213 W= [ 1.63318455] b= [ 0.17000227]</span><br><span class="line">Epoch: 5 cost= 0.0661118 W= [ 1.88165665] b= [ 0.0765276]</span><br><span class="line">Epoch: 7 cost= 0.0633376 W= [ 1.94610846] b= [ 0.05182607]</span><br><span class="line">Epoch: 9 cost= 0.0632785 W= [ 1.96277654] b= [ 0.0454303]</span><br><span class="line">Epoch: 11 cost= 0.0633072 W= [ 1.96708632] b= [ 0.04377643]</span><br><span class="line">Epoch: 13 cost= 0.0633176 W= [ 1.96820116] b= [ 0.04334867]</span><br><span class="line">Epoch: 15 cost= 0.0633205 W= [ 1.96848941] b= [ 0.04323809]</span><br><span class="line">Epoch: 17 cost= 0.0633212 W= [ 1.9685632] b= [ 0.04320973]</span><br><span class="line">Epoch: 19 cost= 0.0633214 W= [ 1.96858287] b= [ 0.04320224]</span><br><span class="line"> Finished!</span><br><span class="line">cost= 0.0633215 W= [ 1.96858633] b= [ 0.04320095]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出，cost的值在不断地变小，w和b的值也在不断地调整。</p>
<p>2．训练模型可视化</p>
<p>上面的数值信息理解起来还是比较抽象。为了可以得到更直观的表达，下面将模型中的两个信息可视化出来，一个是生成的模型，另一个是训练中的状态值。具体代码如下：</p>
<p>代码3-1 线性回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#图形显示</span><br><span class="line">    plt.plot(train_X, train_Y, &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label </span><br><span class="line">      =&apos;Fittedline&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    plotdata[&quot;avgloss&quot;] = moving_average(plotdata[&quot;loss&quot;])</span><br><span class="line">    plt.figure(1)</span><br><span class="line">    plt.subplot(211)</span><br><span class="line">    plt.plot(plotdata[&quot;batchsize&quot;], plotdata[&quot;avgloss&quot;], &apos;b--&apos;)</span><br><span class="line">    plt.xlabel(&apos;Minibatch number&apos;)</span><br><span class="line">    plt.ylabel(&apos;Loss&apos;)</span><br><span class="line">    plt.title(&apos;Minibatch run vs. Training loss&apos;)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>这段代码中引入了一个变量和一个函数，可以在代码的最顶端定义它们，见如下代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plotdata = &#123; &quot;batchsize&quot;:[], &quot;loss&quot;:[] &#125;</span><br><span class="line">def moving_average(a, w=10):</span><br><span class="line">    if len(a) &lt; w: </span><br><span class="line">        return a[:]    </span><br><span class="line">    return [val if idx &lt; w else sum(a[(idx-w):idx])/w for idx, val in </span><br><span class="line">    enumerate(a)]</span><br></pre></td></tr></table></figure>

</details>

<p>现在所有的代码都准备好了，运行程序，生成如图3-3和图3-4所示两幅图。</p>
<p>图3-3中所示的斜线，是模型中的参数w和b为常量所组成的关于x与y的直线方程。可以看到是一条几乎y=2x的直线（W=1.96858633接近于2，b=0.04320095接近于0）。</p>
<p>在图3-4中可以看到刚开始损失值一直在下降，直到6次左右趋近平稳。</p>
<p><img src="Image00031.jpg" alt></p>
<p>图3-3 可视化模型</p>
<p><img src="Image00032.jpg" alt></p>
<p>图3-4 可视化训练loss</p>
<h4 id="3-1-4-使用模型"><a href="#3-1-4-使用模型" class="headerlink" title="3.1.4 使用模型"></a>3.1.4 使用模型</h4><p>模型训练好后，用起来就比较容易了，往里面传一个0.2（通过feed_dict={X：0.2}），然后使用sess.run来运行模型中的z节点，见如下代码第64行，看看它生成的值。</p>
<p>代码3-1 线性回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">￼64 print (&quot;x=0.2，z=&quot;, sess.run(z, feed_dict=&#123;X: 0.2&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>将上述代码加到代码文件“3-1线性回归.py”的最后一行，运行后可以得到如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x=0.2，z= [ 0.4324449]</span><br></pre></td></tr></table></figure>

</details>

<p>训练好的模型，可以根据已有数据的规律推算出输入值0.2对应的z值。</p>
<p><img src="Image00014.jpg" alt> 注意： 读者在自己的计算机上运行该程序，得到的z值与书上的会不一样。这是因为b和w不一样。神经网络学习的是一种规律，能表示这一种规律的b和w会有很多值，即模型学出来的并非是唯一值。</p>
<h3 id="3-2-模型是如何训练出来的"><a href="#3-2-模型是如何训练出来的" class="headerlink" title="3.2 模型是如何训练出来的"></a>3.2 模型是如何训练出来的</h3><p>在上面的例子中仅仅迭代了20次就得到了一个可以拟合y≈2x的模型。下面来具体了解一下模型是如何得来的。</p>
<h4 id="3-2-1-模型里的内容及意义"><a href="#3-2-1-模型里的内容及意义" class="headerlink" title="3.2.1 模型里的内容及意义"></a>3.2.1 模型里的内容及意义</h4><p>一个标准的模型结构分为输入、中间节点、输出三大部分，而如何让这三个部分连通起来学习规则并可以进行计算，则是框架TensorFlow所做的事情。</p>
<p>TensorFlow将中间节点及节点间的运算关系（OPS）定义在自己内部的一个“图”上，全通过一个“会话（session）”进行图中OPS的具体运算。</p>
<p>可以这样理解：</p>
<p>·“图”是静态的，无论做任何加、减、乘、除，它们只是将关系搭建在一起，不会有任何运算。</p>
<p>·“会话”是动态的，只有启动会话后才会将数据流向图中，并按照图中的关系运算，并将最终的结果从图中流出。</p>
<p>TensorFlow用这种方式分离了计算的定义和执行，“图”类似于施工图（blueprint），而“会话”更像施工地点。</p>
<p>构建一个完整的图一般需要定义3种变量，如图3-5所示。</p>
<p>·输入节点：即网络的入口。</p>
<p>·用于训练的模型参数（也叫学习参数）：是连接各个节点的路径。</p>
<p>·模型中的节点（OP）：最复杂的就是OP。OP可以用来代表模型中的中间节点，也可以代表最终的输出节点，是网络中的真正结构。</p>
<p>如图3-5所示为这3种变量放在图中所组成的网络静态模型。在实际训练中，通过动态的会话将图中的各个节点按照静态的规则运算起来，每一次的迭代都会对图中的学习参数进行更新调整，通过一定次数的迭代运算之后最终所形成的图便是所要的“模型”。而在会话中，任何一个节点都可以通过会话的run函数进行计算，得到该节点的真实数值。</p>
<p><img src="Image00033.jpg" alt></p>
<p>图3-5 模型中的图</p>
<h4 id="3-2-2-模型内部的数据流向"><a href="#3-2-2-模型内部的数据流向" class="headerlink" title="3.2.2 模型内部的数据流向"></a>3.2.2 模型内部的数据流向</h4><p>模型内部的数据流向分为正向和反向。</p>
<p>1．正向</p>
<p>正向，是数据从输入开始，依次进行各节点定义的运算，一直运算到输出，是模型最基本的数据流向。它直观地表现了网络模型的结构，在模型的训练、测试、使用的场景中都会用到。这部分是必须要掌握的。</p>
<p>2．反向</p>
<p>反向，只有在训练场景下才会用到。这里使用了一个叫做反向链式求导的方法，即先从正向的最后一个节点开始，计算此时结果值与真实值的误差，这样会形成一个用学习参数表示误差的方程，然后对方程中的每个参数求导，得到其梯度修正值，同时反推出上一层的误差，这样就将该层节点的误差按照正向的相反方向传到上一层，并接着计算上一层的修正值，如此反复下去一步一步地进行转播，直到传到正向的第一个节点。</p>
<p>这部分原理TensorFlow已经实现好了，读者简单理解即可，应该把重点放在使用什么方法来计算误差，使用哪些梯度下降的优化方法，如何调节梯度下降中的参数（如学习率）问题上。</p>
<h3 id="3-3-了解TensorFlow开发的基本步骤"><a href="#3-3-了解TensorFlow开发的基本步骤" class="headerlink" title="3.3 了解TensorFlow开发的基本步骤"></a>3.3 了解TensorFlow开发的基本步骤</h3><p>通过上面的例子，现在将TensorFlow开发的基本步骤总结如下：</p>
<p>（1）定义TensorFlow输入节点。</p>
<p>（2）定义“学习参数”的变量。</p>
<p>（3）定义“运算”。</p>
<p>（4）优化函数，优化目标。</p>
<p>（5）初始化所有变量。</p>
<p>（6）迭代更新参数到最优解。</p>
<p>（7）测试模型。</p>
<p>（8）使用模型。</p>
<p>下面进行逐项介绍。</p>
<h4 id="3-3-1-定义输入节点的方法"><a href="#3-3-1-定义输入节点的方法" class="headerlink" title="3.3.1 定义输入节点的方法"></a>3.3.1 定义输入节点的方法</h4><p>TensorFlow中有如下几种定义输入节点的方法。</p>
<p>·通过占位符定义：一般使用这种方式。</p>
<p>·通过字典类型定义：一般用于输入比较多的情况。</p>
<p>·直接定义：一般很少使用。</p>
<p>本章开篇的第一个例子“3-1线性回归.py”就是通过占位符来定义输入节点的，具体使用了tf.placeholder函数，见如下代码。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = tf.placeholder(&quot;float&quot;)</span><br><span class="line">Y = tf.placeholder(&quot;float&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>下面介绍“通过字典定义”与“直接定义”的方法。</p>
<h4 id="3-3-2-实例2：通过字典类型定义输入节点"><a href="#3-3-2-实例2：通过字典类型定义输入节点" class="headerlink" title="3.3.2 实例2：通过字典类型定义输入节点"></a>3.3.2 实例2：通过字典类型定义输入节点</h4><p>实例描述</p>
<p>在代码“3-1线性回归.py”文件的基础上，使用字典占位符来代替用占位符定义的输入。</p>
<p>通过字典定义的方式和第一种比较像，只不过是堆叠到了一起。具体代码如下：</p>
<p>代码3-2 通过字典类型定义输出节点</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">￼……</span><br><span class="line"># 占位符</span><br><span class="line">inputdict = &#123;</span><br><span class="line">    &apos;x&apos;: tf.placeholder(&quot;float&quot;),</span><br><span class="line">    &apos;y&apos;: tf.placeholder(&quot;float&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>

<h4 id="3-3-3-实例3：直接定义输入节点"><a href="#3-3-3-实例3：直接定义输入节点" class="headerlink" title="3.3.3 实例3：直接定义输入节点"></a>3.3.3 实例3：直接定义输入节点</h4><p>实例描述</p>
<p>在代码“3-1线性回归.py”文件的基础上，使用直接定义法来代替用占位符定义的输入。</p>
<p>直接定义，就是将定义好的Python变量直接放到OP节点中参与输入的运算，将模拟数据的变量直接放到模型中进行训练。代码如下：</p>
<p>代码3-3 直接定义输入节点</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">￼……</span><br><span class="line"> </span><br><span class="line">#生成模拟数据</span><br><span class="line">train_X =np.float32( np.linspace(-1, 1, 100))</span><br><span class="line">train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3 # y=2x，但是加入了噪声</span><br><span class="line">#图形显示</span><br><span class="line">plt.plot(train_X, train_Y, &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"># 模型参数</span><br><span class="line">W = tf.Variable(tf.random_normal([1]), name=&quot;weight&quot;)</span><br><span class="line">b = tf.Variable(tf.zeros([1]), name=&quot;bias&quot;)</span><br><span class="line"># 前向结构</span><br><span class="line">z = tf.multiply(W, train_X)+ b</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 提示： 上面只列出了3种方法中的关键代码，全部的代码在本书的配套代码可以中找到。</p>
<h4 id="3-3-4-定义“学习参数”的变量"><a href="#3-3-4-定义“学习参数”的变量" class="headerlink" title="3.3.4 定义“学习参数”的变量"></a>3.3.4 定义“学习参数”的变量</h4><p>学习参数的定义与输入的定义很像，分为直接定义和字典定义两部分。这两种都是常见的使用方式，只不过在深层神经网络里由于参数过多，普遍都会使用第二种情况。</p>
<p>在前面“3-1线性回归.py”的例子中使用的就是第一种方法，通过tf.Variable可以对参数直接定义。代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 模型参数</span><br><span class="line">W = tf.Variable(tf.random_normal([1]), name=&quot;weight&quot;)</span><br><span class="line">b = tf.Variable(tf.zeros([1]), name=&quot;bias&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>下面通过例子演示使用字典定义学习参数。</p>
<h4 id="3-3-5-实例4：通过字典类型定义“学习参数”"><a href="#3-3-5-实例4：通过字典类型定义“学习参数”" class="headerlink" title="3.3.5 实例4：通过字典类型定义“学习参数”"></a>3.3.5 实例4：通过字典类型定义“学习参数”</h4><p>实例描述</p>
<p>在代码“3-1线性回归.py”文件的基础上，使用字典的方式来定义学习参数。</p>
<p>通过字典的方式定义和直接定义比较相似，只不过是堆叠到了一起。修改“3-1线性回归.py”例子代码如下。</p>
<p>代码3-4 通过字典类型定义学习参数</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">￼……</span><br><span class="line"> </span><br><span class="line"># 模型参数</span><br><span class="line">paradict = &#123;</span><br><span class="line">    &apos;w&apos;: tf.Variable(tf.random_normal([1])),</span><br><span class="line">    &apos;b&apos;: tf.Variable(tf.zeros([1]))</span><br><span class="line">&#125;</span><br><span class="line"># 前向结构</span><br><span class="line">z = tf.multiply(X, paradict[&apos;w&apos;])+ paradict[&apos;b&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码同样只是列出了关键部分，全部的代码都可以在本书的配套代码中找到。</p>
<h4 id="3-3-6-定义“运算”"><a href="#3-3-6-定义“运算”" class="headerlink" title="3.3.6 定义“运算”"></a>3.3.6 定义“运算”</h4><p>定义“运算”的过程是建立模型的核心过程，直接决定了模型的拟合效果，具体的代码演示在前面也介绍过了。这里主要阐述一下定义运算的类型，以及其在深度学习中的作用。</p>
<p>1．定义正向传播模型</p>
<p>在前面“3-1线性回归.py”的例子中使用的网络结构很简单，只有一个神经元。在后面会学到多层神经网络、卷积神经网、循环神经网络及更深层的GoogLeNet、Resnet等，它们都是由神经元以不同的组合方式组成的网络结构，而且每年还会有很多更高效且拟合性更强的新结构诞生。</p>
<p>2．定义损失函数</p>
<p>损失函数主要是计算“输出值”与“目标值”之间的误差，是配合反向传播使用的。为了在反向传播中可以找到最小值，要求该函数必须是可导的。</p>
<p><img src="Image00014.jpg" alt> 提示： 损失函数近几年来没有太大变化。读者只需要记住常用的几种，并能够了解内部原理就可以了，不需要掌握太多细节，因为TensorFlow框架已经为我们做好了。</p>
<h4 id="3-3-7-优化函数，优化目标"><a href="#3-3-7-优化函数，优化目标" class="headerlink" title="3.3.7 优化函数，优化目标"></a>3.3.7 优化函数，优化目标</h4><p>在有了正向结构和损失函数后，就是通过优化函数来优化学习参数了，这个过程也是在反向传播中完成的。</p>
<p>反向传播过程，就是沿着正向传播的结构向相反方向将误差传递过去。这里面涉及的技术比较多，如L1、L2正则化、冲量调节、学习率自适应、adm随机梯度下降算法等，每一个技巧都代表一个时代。</p>
<p><img src="Image00014.jpg" alt> 提示： 随着深度学习的飞速发展，反向传播过程的技术会达到一定程度的瓶颈，更新并不如网络结构变化得那么快，所以读者也只需将常用的几种记住即可。</p>
<h4 id="3-3-8-初始化所有变量"><a href="#3-3-8-初始化所有变量" class="headerlink" title="3.3.8 初始化所有变量"></a>3.3.8 初始化所有变量</h4><p>初始化所有变量的过程，虽然只有一句代码，但也是一个关键环节，所以特意将其列出来。</p>
<p>在session创建好了之后，第一件事就是需要初始化。还以“3-1线性回归.py”举例，代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"># 启动Session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 使用tf.global_variables_initializer函数初始化所有变量的步骤，必须在所有变量和OP定义完成之后。这样才能保证定义的内容有效，否则，初始化之后定义的变量和OP都无法使用session中的run来进行算值。</p>
<h4 id="3-3-9-迭代更新参数到最优解"><a href="#3-3-9-迭代更新参数到最优解" class="headerlink" title="3.3.9 迭代更新参数到最优解"></a>3.3.9 迭代更新参数到最优解</h4><p>在迭代训练环节，都是需要通过建立一个session来完成的，常用的是使用with语法，可以在session结束后自行关闭，当然还有其他方法，第4章会详细介绍。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br></pre></td></tr></table></figure>

</details>

<p>前面说过，在session中通过run来运算模型中的节点，在训练环节也是如此，只不过run里面放的是优化操作的OP，同时会在外层加上循环次数。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for epoch in range(training_epochs):</span><br><span class="line">        for (x, y) in zip(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br></pre></td></tr></table></figure>

</details>

<p>真正使用过程中会引入一个叫做MINIBATCH概念进行迭代训练，即每次取一定量的数据同时放到网络里进行训练，这样做的好处和意义会在后面详细介绍。</p>
<h4 id="3-3-10-测试模型"><a href="#3-3-10-测试模型" class="headerlink" title="3.3.10 测试模型"></a>3.3.10 测试模型</h4><p>测试模型部分已经不是神经网络的核心环节了，同归对评估节点的输出，得到模型的准确率（或错误率）从而来描述模型的好坏，这部分很简单没有太多的技术，在“3-1线性回归.py”中可以找到如下代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print (&quot;cost=&quot;, sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;), &quot;W=&quot;, </span><br><span class="line">sess.run(W), &quot;b=&quot;, sess.run(b))</span><br></pre></td></tr></table></figure>

</details>

<p>当然这句话还可以改写成以下这样：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print (&quot;cost:&quot;,cost.eval(&#123;X: train_X, Y: train_Y&#125;))</span><br></pre></td></tr></table></figure>

</details>

<h4 id="3-3-11-使用模型"><a href="#3-3-11-使用模型" class="headerlink" title="3.3.11 使用模型"></a>3.3.11 使用模型</h4><p>使用模型也与测试模型类似，只不过是将损失值的节点换成输出的节点即可。在“3-1线性回归.py”例子中也有介绍。</p>
<p>这里要说的是，一般会把生成的模型保存起来，再通过载入已有的模型来进行实际的使用。关于模型的载入和读取，后面章节会有介绍。</p>
<h2 id="第4章-TensorFlow编程基础"><a href="#第4章-TensorFlow编程基础" class="headerlink" title="第4章 TensorFlow编程基础"></a>第4章 TensorFlow编程基础</h2><p>本章主要介绍TensorFlow的基础语法及功能函数。学完本章后，TensorFlow代码对读者来说将不再陌生，读者可以很轻易看懂网上和书中例子的代码，并可以尝试写一些简单的模型或算法。</p>
<p>学习一个开发环境，应先从其内部入手，这样会起到事半功倍的效果。本章先从编程模型开始了解其运行机制，然后再介绍TensorFlow常用操作及功能函数，最后是共享变量、图和分布式部署。</p>
<p>本章含有教学视频共12分39秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，包括基本的模型工作机制、基础类型及操作、共享变量、图、分布式部署等内容（其中，共享变量是本章的重点和难点）。</p>
<p><img src="Image00034.jpg" alt></p>
<h3 id="4-1-编程模型"><a href="#4-1-编程模型" class="headerlink" title="4.1 编程模型"></a>4.1 编程模型</h3><p>TensorFlow的命名来源于本身的运行原理。Tensor（张量）意味着N维数组，Flow（流）意味着基于数据流图的计算。TensorFlow是张量从图像的一端流动到另一端的计算过程，这也是TensorFlow的编程模型。</p>
<h4 id="4-1-1-了解模型的运行机制"><a href="#4-1-1-了解模型的运行机制" class="headerlink" title="4.1.1 了解模型的运行机制"></a>4.1.1 了解模型的运行机制</h4><p>TensorFlow的运行机制属于“定义”与“运行”相分离。从操作层面可以抽象成两种：模型构建和模型运行。</p>
<p>在模型构建过程中，需要先了解几个概念，如表4-1所示。</p>
<p>表4-1 模型构建中的概念</p>
<p><img src="Image00035.jpg" alt></p>
<p>表4-1中定义的内容都是在一个叫做“图”的容器中完成的。关于“图”，有以下几点需要理解。</p>
<p>·一个“图”代表一个计算任务。</p>
<p>·在模型运行的环节中，“图”会在会话（session）里被启动。</p>
<p>·session将图的OP分发到如CPU或GPU之类的设备上，同时提供执行OP的方法。这些方法执行后，将产生的tensor返回。在Python语言中，返回的tensor是numpy ndarray对象；在C和C++语言中，返回的tensor是TensorFlow：：Tensor实例。</p>
<p>如图4-1所示为session与图的工作关系。</p>
<p><img src="Image00036.jpg" alt></p>
<p>图4-1 session与图的关系</p>
<p>在实际环境中，这种运行情况会有3种应用场景，分别是训练场景、测试场景与使用场景。在训练场景下图的运行方式与其他两种不同，具体介绍如下。</p>
<p>（1）训练场景：是实现模型从无到有的过程，通过对样本的学习训练，调整学习参数，形成最终的模型。其过程是将给定的样本和标签作为输入节点，通过大量的循环迭代，将图中的正向运算（从输入的样本通过OP运算得到输出的方向）得到的输出值，再进行反向运算（从输出到输入的方向），以更新模型中的学习参数，最终使模型产生的正向结果最大化地接近样本标签。这样就得到了一个可以拟合样本规律的模型。</p>
<p>（2）测试场景和使用场景：测试场景是利用图的正向运算得到的结果与真实值进行比较的差别；使用场景也是利用图的正向运算得到结果，并直接使用。所以二者的运算过程是一样的。对于该场景下的模型与正常编程用到的函数特别相似。在函数中，可以分为实参、形参、函数体与返回值。同样在模型中，实参就是输入的样本，形参就是占位符，运算过程就相当于函数体，得到的结果相当于返回值。</p>
<p>另外，session与图的交互过程中还定义了以下两种数据的流向机制。</p>
<p>·注入机制（feed）：通过占位符向模式中传入数据。</p>
<p>·取回机制（fetch）：从模式中得到结果。</p>
<p>下面通过实例逐个演示session在各种情况下的用法。先从session的建立开始，接着演示session与图的交互机制，最后演示如何在session中指定GPU运算资源。</p>
<h4 id="4-1-2-实例5：编写hello-world程序演示session的使用"><a href="#4-1-2-实例5：编写hello-world程序演示session的使用" class="headerlink" title="4.1.2 实例5：编写hello world程序演示session的使用"></a>4.1.2 实例5：编写hello world程序演示session的使用</h4><p>下面先从一个hello world开始来理解session的作用。</p>
<p>实例描述</p>
<p>建立一个session，在session中输出hello，TensorFlow。</p>
<p>代码4-1 sessionhello</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">hello = tf.constant(&apos;Hello, TensorFlow!&apos;)  #定义一个常量</span><br><span class="line">sess = tf.Session()                        #建立一个session</span><br><span class="line">print (sess.run(hello))                   #通过session里面run函数来运行结果</span><br><span class="line">sess.close()                                #关闭session</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码4-1会得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b&apos;Hello, TensorFlow!&apos;</span><br></pre></td></tr></table></figure>

</details>

<p>tf.constant定义的是一个常量，hello的内容只有在session的run内才可以返回。</p>
<p>可以试着在2和3行之间加入print（hello）看一下效果，这时并不能输出hello的内容。</p>
<p>接下来换种写法，使用with语法来开启session。</p>
<h4 id="4-1-3-实例6：演示with-session的使用"><a href="#4-1-3-实例6：演示with-session的使用" class="headerlink" title="4.1.3 实例6：演示with session的使用"></a>4.1.3 实例6：演示with session的使用</h4><p>with session的用法是最常见的，它沿用了Python中with的语法，即当程序结束后会自动关闭session，而不需要再去写close。代码如下。</p>
<p>实例描述</p>
<p>使用with session方法建立session，并在session中计算两个变量（3和4）的相加与相乘值。</p>
<p>代码4-2 with session</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.constant(3)                    #定义常量3</span><br><span class="line">b = tf.constant(4)                   #定义常量4</span><br><span class="line">with tf.Session() as sess:          #建立session</span><br><span class="line">    print (&quot;相加: %i&quot; % sess.run(a+b))</span><br><span class="line">    print( &quot;相乘: %i&quot; % sess.run(a*b))</span><br></pre></td></tr></table></figure>

</details>

<p>运行后得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">相加: 7</span><br><span class="line">相乘: 12</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-1-4-实例7：演示注入机制"><a href="#4-1-4-实例7：演示注入机制" class="headerlink" title="4.1.4 实例7：演示注入机制"></a>4.1.4 实例7：演示注入机制</h4><p>扩展上面代码：使用注入机制，将具体的实参注入到相应的placeholder中。feed只在调用它的方法内有效，方法结束后feed就会消失。</p>
<p>实例描述</p>
<p>定义占位符，使用feed机制将具体数值（3和4）通过占位符传入，并进行相加和相乘运算。</p>
<p>代码4-3 withsessionfeed</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.placeholder(tf.int16)</span><br><span class="line">b = tf.placeholder(tf.int16)</span><br><span class="line">add = tf.add(a, b)</span><br><span class="line">mul = tf.multiply(a, b)                  #a与b相乘</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    #计算具体数值</span><br><span class="line">    print (&quot;相加: %i&quot; % sess.run(add, feed_dict=&#123;a: 3, b: 4&#125;))</span><br><span class="line">    print (&quot;相乘: %i&quot; % sess.run(mul, feed_dict=&#123;a: 3, b: 4&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">相加:7</span><br><span class="line">相乘:12</span><br></pre></td></tr></table></figure>

</details>

<p>标记的方法是：使用tf.placeholder为这些操作创建占位符，然后使用feed_dict把具体的值放到占位符里。</p>
<p><img src="Image00014.jpg" alt> 注意： 关于feed中的feed_dict还有其他的方法，如update等，在后面的例子中用到时还会介绍，这里只是介绍最常用的方法。</p>
<h4 id="4-1-5-建立session-的其他方法"><a href="#4-1-5-建立session-的其他方法" class="headerlink" title="4.1.5 建立session 的其他方法"></a>4.1.5 建立session 的其他方法</h4><p>建立session还有以下两种方式。</p>
<p>·交互式session方式：一般在Jupyter环境下使用较多，具体用法与前面的with session类似。代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>

</details>

<p>·使用Supervisor方式：该方式会更高级一些，使用起来也更加复杂，可以自动来管理session中的具体任务，例如，载入/载出检查点文件、写入TensorBoard等，另外该方法还支持分布式训练的部署（在本书的后面会有介绍）。</p>
<h4 id="4-1-6-实例8：使用注入机制获取节点"><a href="#4-1-6-实例8：使用注入机制获取节点" class="headerlink" title="4.1.6 实例8：使用注入机制获取节点"></a>4.1.6 实例8：使用注入机制获取节点</h4><p>在实例7中，其实还可以一次将多个节点取出来。例如，在最后一句可以加上以下代码（见代码4-3）：</p>
<p>实例描述</p>
<p>使用fetch机制将定义在图中的节点数值算出来。</p>
<p>代码4-3 withsessionfeed（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">mul = tf.multiply(a, b)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    #将op运算通过run打印出来</span><br><span class="line">    print (&quot;相加: %i&quot; % sess.run(add, feed_dict=&#123;a: 3, b: 4&#125;))</span><br><span class="line">      #将add节点打印出来</span><br><span class="line">    print (&quot;相乘: %i&quot; % sess.run(mul, feed_dict=&#123;a: 3, b: 4&#125;))</span><br><span class="line">    print (sess.run([mul, add], feed_dict=&#123;a: 3, b: 4&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">相加: 7</span><br><span class="line">相乘: 12</span><br><span class="line">[12, 7]</span><br></pre></td></tr></table></figure>

</details>




<h4 id="4-1-7-指定GPU运算"><a href="#4-1-7-指定GPU运算" class="headerlink" title="4.1.7 指定GPU运算"></a>4.1.7 指定GPU运算</h4><p>如果下载的是GPU版本，在运行过程中TensorFlow能自动检测。如果检测到GPU，TensorFlow会尽可能地利用找到的第一个GPU来执行操作。</p>
<p>如果机器上有超过一个可用的GPU，除第一个之外的其他GPU默认是不参与计算的。为了让TensorFlow使用这些GPU，必须将OP明确指派给它们执行。with……device语句能用来指派特定的CPU或GPU执行操作：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">  with tf.device(&quot;/gpu:1&quot;):</span><br><span class="line">    a = tf.placeholder(tf.int16)</span><br><span class="line">b = tf.placeholder(tf.int16)</span><br><span class="line">add = tf.add(a, b)</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure>

</details>

<p>设备用字符串进行标识。目前支持的设备包括以下几种。</p>
<p>·cpu：0：机器的CPU。</p>
<p>·gpu：0：机器的第一个GPU，如果有的话。</p>
<p>·gpu：1：机器的第二个GPU，依此类推。</p>
<p>类似的还有通过tf.ConfigProto来构建一个config，在config中指定相关的GPU，并且在session中传入参数config=”自己创建的config”来指定GPU操作。</p>
<p>tf.ConfigProto函数的参数如下。</p>
<p>·log_device_placement=True：是否打印设备分配日志。</p>
<p>·allow_soft_placement=True：如果指定的设备不存在，允许TF自动分配设备。</p>
<p>使用举例：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto(log_device_placement=True,allow_soft_placement</span><br><span class="line">=True)</span><br><span class="line">session = tf.Session(config=config, ...)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-1-8-设置GPU使用资源"><a href="#4-1-8-设置GPU使用资源" class="headerlink" title="4.1.8 设置GPU使用资源"></a>4.1.8 设置GPU使用资源</h4><p>上文的tf.ConfigProto函数生成config之后，还可以设置其属性来分配GPU的运算资源。如下代码就是按需分配的意思：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.gpu_options.allow_growth = True</span><br></pre></td></tr></table></figure>

</details>

<p>使用allow_growth option，刚开始会分配少量的GPU容量，然后按需慢慢地增加，由于不会释放内存，所以会导致碎片。</p>
<p>同样，上述代码也可以放在config创建的时指定，例如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(allow_growth=True)</span><br><span class="line">config=tf.ConfigProto(gpu_options=gpu_options)</span><br></pre></td></tr></table></figure>

</details>

<p>以下代码还可以给GPU分配固定大小的计算资源。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)</span><br></pre></td></tr></table></figure>

</details>

<p>代表分配给tensorflow的GPU显存大小为：GPU实际显存×0.7。</p>
<p>（该方法暂时用不到，读者在以后遇到这样的代码时明白是什么意思即可）</p>
<h4 id="4-1-9-保存和载入模型的方法介绍"><a href="#4-1-9-保存和载入模型的方法介绍" class="headerlink" title="4.1.9 保存和载入模型的方法介绍"></a>4.1.9 保存和载入模型的方法介绍</h4><p>一般而言，训练好的模型都需要保存。下面将举例演示如何保存和载入模型。</p>
<p>1．保存模型</p>
<p>首先需要建立一个saver，然后在session中通过saver的save即可将模型保存起来。代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#之前是各种构建模型graph的操作(矩阵相乘，sigmoid等)</span><br><span class="line">saver = tf.train.Saver()                           #生成saver</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer()) #先对模型初始化</span><br><span class="line">     #然后将数据丢入模型进行训练blablabla</span><br><span class="line">     #训练完以后，使用saver.save 来保存</span><br><span class="line">    saver.save(sess, &quot;save_path/file_name&quot;)</span><br><span class="line">#file_name如果不存在，会自动创建</span><br></pre></td></tr></table></figure>

</details>

<p>2．载入模型</p>
<p>将模型保存好以后，载入也比较方便。在session中通过调用saver的restore（）函数，会从指定的路径找到模型文件，并覆盖到相关参数中。代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line"> </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    #参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的</span><br><span class="line">      值给覆盖</span><br><span class="line">    sess.run(tf.global_variables_initializer())     </span><br><span class="line">    saver.restore(sess, &quot;save_path/file_name&quot;) #会将已经保存的变量值resotre到变量中。</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-1-10-实例9：保存-载入线性回归模型"><a href="#4-1-10-实例9：保存-载入线性回归模型" class="headerlink" title="4.1.10 实例9：保存/载入线性回归模型"></a>4.1.10 实例9：保存/载入线性回归模型</h4><p>实例描述</p>
<p>在代码“3-1线性回归.py”文件的基础上，添加模型的保存及载入功能。</p>
<p>通过扩展上一章的例子，来演示一下模型的保存及载入。在代码“3-1线性回归.py”文件中生成模拟数据之后，加入对图变量的重置，在session创建之前定义saver及保存路径，在session中训练结束后，保存模型。</p>
<p>代码4-4 线性回归模型保存及载入</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">  import tensorflow as tf</span><br><span class="line">  import numpy as np</span><br><span class="line">  import matplotlib.pyplot as plt</span><br><span class="line">  </span><br><span class="line">  #模拟数据</span><br><span class="line">  ……</span><br><span class="line">  plt.plot(train_X, train_Y, &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">  plt.legend()</span><br><span class="line">  plt.show()</span><br><span class="line">  </span><br><span class="line">  #重置图</span><br><span class="line">  tf.reset_default_graph()</span><br><span class="line">  </span><br><span class="line">  #初始话等操作</span><br><span class="line">  ……</span><br><span class="line">  display_step = 2</span><br><span class="line">  </span><br><span class="line">  saver = tf.train.Saver()                            #生成saver</span><br><span class="line">  savedir = &quot;log/&quot;                                     #生成模型的路径</span><br><span class="line">  </span><br><span class="line">  #启动session</span><br><span class="line">  with tf.Session() as sess:</span><br><span class="line">      sess.run(init)</span><br><span class="line">      #在这里添加Sess中的训练代码</span><br><span class="line">  ……</span><br><span class="line">      print (&quot; Finished!&quot;)</span><br><span class="line">      saver.save(sess, savedir+&quot;linermodel.cpkt&quot;) #保存模型</span><br><span class="line">￼28      print (&quot;cost=&quot;, sess.run(cost, feed_dict=</span><br><span class="line">        &#123;X: train_X, Y: train_Y&#125;), </span><br><span class="line">        &quot;W=&quot;, sess.run(W), &quot;b=&quot;, sess.run(b))</span><br><span class="line">  #其他代码</span><br><span class="line">  ……</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码可以看到，在代码的同级目录下log文件夹里生成了几个文件，如图4-2所示。</p>
<p><img src="Image00037.jpg" alt></p>
<p>图4-2 模型文件</p>
<p>再重启一个session，并命名为sess2，在代码里通过使用saver的restore函数将模型载入。</p>
<p>代码4-4 线性回归模型保存及载入（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session()as sess2:</span><br><span class="line">   sess2.run(tf.global_variables_initializer()) </span><br><span class="line">   saver.restore(sess2,savedir+&quot;linermodel. </span><br><span class="line">     cpkt&quot;)</span><br><span class="line">   print (&quot;x=0.2，z=&quot;, sess2.run(z, feed_dict=&#123;X: 0.2&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>为了测试效果，可以将前面一个session注释掉，运行之后可以看到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Restoring parameters from log/linermodel.cpkt</span><br><span class="line">x=0.2，z= [ 0.42615247]</span><br></pre></td></tr></table></figure>

</details>

<p>表明模型已经成功载入，并计算出正确的值了。</p>
<h4 id="4-1-11-实例10：分析模型内容，演示模型的其他保存方法"><a href="#4-1-11-实例10：分析模型内容，演示模型的其他保存方法" class="headerlink" title="4.1.11 实例10：分析模型内容，演示模型的其他保存方法"></a>4.1.11 实例10：分析模型内容，演示模型的其他保存方法</h4><p>下面再来详细介绍下关于模型保存的其他细节。</p>
<p>实例描述</p>
<p>将4.1.10节生成的模型里面的内容打印出来，观察其存放的具体数据方式。同时演示如何将指定内容保存到模型文件中。</p>
<p>1．模型内容</p>
<p>虽然模型已经保存了，但是仍然对我们不透明。下面通过编写代码将模型里的内容打印出来，看看到底保存了哪些东西，都是什么样的。</p>
<p>代码4-5 模型内容</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.python.tools.inspect_checkpoint import print_tensors_ </span><br><span class="line">  in_checkpoint_file</span><br><span class="line">savedir = &quot;log/&quot;</span><br><span class="line">print_tensors_in_checkpoint_file(savedir+&quot;linermodel.cpkt&quot;, None, True)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，打印如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor_name:  bias</span><br><span class="line">[ 0.01919404]</span><br><span class="line">tensor_name:  weight</span><br><span class="line">[ 2.03479218]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，tensor_name：后面跟的就是创建的变量名，接着是它的数值。</p>
<p>2．保存模型的其他方法</p>
<p>前面的例子中Saver的创建比较简单，其实tf.train.Saver函数里面还可以放参数来实现更高级的功能，可以指定存储变量名字与变量的对应关系。可以写成这样：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver(&#123;&apos;weight&apos;: W, &apos;bias&apos;: b&#125;)</span><br></pre></td></tr></table></figure>

</details>

<p>代表将w变量的值放到weight名字中。类似的写法还有以下两种：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver([W, b])                     #放到一个list里</span><br><span class="line">saver = tf.train.Saver(&#123;v.op.name: v for v in [W, b]&#125;) #将op的名字当作key</span><br></pre></td></tr></table></figure>

</details>

<p>下面扩展上述的例子，给b和w分别指定一个固定值，并将它们颠倒放置。</p>
<p>代码4-5 模型内容（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">W = tf.Variable(1.0, name=&quot;weight&quot;)</span><br><span class="line">b = tf.Variable(2.0, name=&quot;bias&quot;)</span><br><span class="line"></span><br><span class="line">#放到一个字典里</span><br><span class="line">saver = tf.train.Saver(&#123;&apos;weight&apos;: b, &apos;bias&apos;: W&#125;)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    saver.save(sess, savedir+&quot;linermodel.cpkt&quot;)</span><br><span class="line"></span><br><span class="line">print_tensors_in_checkpoint_file(savedir+&quot;linermodel.cpkt&quot;, None, True)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，输出如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor_name:  bias</span><br><span class="line">1.0</span><br><span class="line">tensor_name:  weight</span><br><span class="line">2.0</span><br></pre></td></tr></table></figure>

</details>

<p>例子中，W值设为1.0，b的值设为2.0。在创建saver时将它们颠倒，保存的模型打印出来之后可以看到，bias变成了1.0，而weight变成了2.0。</p>
<h4 id="4-1-12-检查点（Checkpoint）"><a href="#4-1-12-检查点（Checkpoint）" class="headerlink" title="4.1.12 检查点（Checkpoint）"></a>4.1.12 检查点（Checkpoint）</h4><p>保存模型并不限于在训练之后，在训练之中也需要保存，因为TensorFlow训练模型时难免会出现中断的情况。我们自然希望能够将辛苦得到的中间参数保留下来，否则下次又要重新开始。</p>
<p>这种在训练中保存模型，习惯上称之为保存检查点。</p>
<h4 id="4-1-13-实例11：为模型添加保存检查点"><a href="#4-1-13-实例11：为模型添加保存检查点" class="headerlink" title="4.1.13 实例11：为模型添加保存检查点"></a>4.1.13 实例11：为模型添加保存检查点</h4><p>实例描述</p>
<p>为一个线性回归任务的模型添加“保存检查点”功能。通过该功能，可以生成载入检查点文件，并能够指定生成检测点文件的个数。</p>
<p>该例与保存模型的功能类似，只是保存的位置发生了些变化，我们希望在显示信息时将检查点保存起来，于是就将保存位置放在了迭代训练中的打印信息后面。</p>
<p>另外，本例用到了saver的另一个参数——max_to_keep=1，表明最多只保存一个检查点文件。在保存时使用了如下代码传入了迭代次数。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver.save(sess, savedir+&quot;linermodel.cpkt&quot;, global_step=epoch)</span><br></pre></td></tr></table></figure>

</details>

<p>TensorFlow会将迭代次数一起放在检查点的名字上，所以在载入时，同样也要指定迭代次数。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver.restore(sess2, savedir+&quot;linermodel.cpkt-&quot; + str(load_epoch))</span><br></pre></td></tr></table></figure>

</details>

<p>完整的代码如下：</p>
<p>代码4-6 保存检查点</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"> </span><br><span class="line">#定义生成loss可视化的函数</span><br><span class="line">plotdata = &#123; &quot;batchsize&quot;:[], &quot;loss&quot;:[] &#125;</span><br><span class="line">def moving_average(a, w=10):</span><br><span class="line">    if len(a) &lt; w: </span><br><span class="line">        return a[:]    </span><br><span class="line">    return [val if idx &lt; w else sum(a[(idx-w):idx])/w for idx, val in </span><br><span class="line">    enumerate(a)]</span><br><span class="line"> </span><br><span class="line">#生成模拟数据</span><br><span class="line">train_X = np.linspace(-1, 1, 100)</span><br><span class="line">train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3 # y=2x，但是加入了噪声</span><br><span class="line">#图形显示</span><br><span class="line">plt.plot(train_X, train_Y, &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"> </span><br><span class="line"># 创建模型</span><br><span class="line"># 占位符</span><br><span class="line">X = tf.placeholder(&quot;float&quot;)</span><br><span class="line">Y = tf.placeholder(&quot;float&quot;)</span><br><span class="line"># 模型参数</span><br><span class="line">W = tf.Variable(tf.random_normal([1]), name=&quot;weight&quot;)</span><br><span class="line">b = tf.Variable(tf.zeros([1]), name=&quot;bias&quot;)</span><br><span class="line"># 前向结构</span><br><span class="line">z = tf.multiply(X, W)+ b</span><br><span class="line"> </span><br><span class="line">#反向优化</span><br><span class="line">cost =tf.reduce_mean( tf.square(Y -z))</span><br><span class="line">learning_rate = 0.01</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize </span><br><span class="line">(cost) #梯度下降</span><br><span class="line"> </span><br><span class="line"># 初始化所有变量</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"># 定义学习参数</span><br><span class="line">training_epochs = 20</span><br><span class="line">display_step = 2</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1) # 生成saver</span><br><span class="line">savedir = &quot;log/&quot;</span><br><span class="line"># 启动图</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    # 向模型中输入数据</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        for (x, y) in zip(train_X, train_Y):</span><br><span class="line">            sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line"> </span><br><span class="line">        #显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            loss = sess.run(cost,feed_dict=&#123;X: train_X,Y:train_Y&#125;)</span><br><span class="line">         print (&quot;Epoch:&quot;,epoch+1,&quot;cost=&quot;,loss,&quot;W=&quot;,sess.run(W), &quot;b=&quot;, </span><br><span class="line">         sess.run(b))</span><br><span class="line">            if not (loss == &quot;NA&quot; ):</span><br><span class="line">                plotdata[&quot;batchsize&quot;].append(epoch)</span><br><span class="line">                plotdata[&quot;loss&quot;].append(loss)</span><br><span class="line">            saver.save(sess, savedir+&quot;linermodel.cpkt&quot;, global_step=epoch)</span><br><span class="line">                </span><br><span class="line">    print (&quot; Finished!&quot;)</span><br><span class="line">    </span><br><span class="line">    print (&quot;cost=&quot;,sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;), </span><br><span class="line">    &quot;W=&quot;, sess.run(W), &quot;b=&quot;, sess.run(b))</span><br><span class="line"> </span><br><span class="line">    #显示模型</span><br><span class="line">    plt.plot(train_X, train_Y, &apos;ro&apos;, label=&apos;Original data&apos;)</span><br><span class="line">    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=&apos;Fitted </span><br><span class="line">    Wline&apos;)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    plotdata[&quot;avgloss&quot;] = moving_average(plotdata[&quot;loss&quot;])</span><br><span class="line">    plt.figure(1)</span><br><span class="line">    plt.subplot(211)</span><br><span class="line">    plt.plot(plotdata[&quot;batchsize&quot;], plotdata[&quot;avgloss&quot;], &apos;b--&apos;)</span><br><span class="line">    plt.xlabel(&apos;Minibatch number&apos;)</span><br><span class="line">    plt.ylabel(&apos;Loss&apos;)</span><br><span class="line">    plt.title(&apos;Minibatch run vs. Training loss&apos;)</span><br><span class="line">     </span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">#重启一个session  ，载入检查点  </span><br><span class="line">load_epoch=18    </span><br><span class="line">with tf.Session() as sess2:</span><br><span class="line">    sess2.run(tf.global_variables_initializer())</span><br><span class="line">    saver.restore(sess2, savedir+&quot;linermodel.cpkt-&quot; + str(load_epoch))</span><br><span class="line">    print (&quot;x=0.2，z=&quot;, sess2.run(z, feed_dict=&#123;X: 0.2&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码运行完后，会看到在log文件夹下多了几个linermodel.cpkt-18*文件，就是检查点文件。</p>
<p>这里使用tf.train.Saver（max_to_keep=1）代码创建saver时传入的参数max_to_keep=1代表：在迭代过程中只保存一个文件。这样，在循环训练过程中，新生成的模型就会覆盖以前的模型。</p>
<p><img src="Image00014.jpg" alt> 注意： 如果觉得通过指定迭代次数比较麻烦，还有一个好方法可以快速获取到检查点文件。示例代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ckpt = tf.train.get_checkpoint_state(ckpt_dir)</span><br><span class="line">if ckpt and ckpt.model_checkpoint_path:</span><br><span class="line">    saver.restore(sess, ckpt.model_checkpoint_path)</span><br></pre></td></tr></table></figure>

</details>

<p>还可以再简洁一些，写成以下这样：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kpt = tf.train.latest_checkpoint(savedir)</span><br><span class="line">    if kpt!=None:</span><br><span class="line">        saver.restore(sess, kpt)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-1-14-实例12：更简便地保存检查点"><a href="#4-1-14-实例12：更简便地保存检查点" class="headerlink" title="4.1.14 实例12：更简便地保存检查点"></a>4.1.14 实例12：更简便地保存检查点</h4><p>本例中介绍另一种更简便地保存检查点功能代码的方法——tf.train.MonitoredTraining Session函数。该函数可以直接实现保存及载入检查点模型的文件。与前面的方式不同，本例中并不是按照循环步数来保存，而是按照训练时间来保存的。通过指定save_checkpoint_secs参数的具体秒数，来设置每训练多久保存一次检查点。</p>
<p>实例描述</p>
<p>演示使用MonitoredTrainingSession函数来自动管理检查点文件。</p>
<p>具体代码如下：</p>
<p>代码4-7 trainMonitored</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">global_step = tf train.get_or_create_global_step()</span><br><span class="line">step = tf.assign_add(global_step, 1)</span><br><span class="line">#设置检查点路径为log/checkpoints</span><br><span class="line">with tf.train.MonitoredTrainingSession(checkpoint_dir=&apos;log/checkpoints&apos;, save_checkpoint_secs  = 2) as sess:</span><br><span class="line">    print(sess.run([global_step]))</span><br><span class="line">    while not sess.should_stop(): #启用死循环，当sess不结束时就不停止</span><br><span class="line">        i = sess.run( step)</span><br><span class="line">        print( i)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">12851</span><br><span class="line">12852</span><br><span class="line">12853</span><br><span class="line">12854</span><br><span class="line">12855</span><br><span class="line">12856</span><br></pre></td></tr></table></figure>

</details>

<p>将程序停止，可以看到log/checkpoints下面生成了检测点文件model.ckpt-8968.meta。再次运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">8969</span><br><span class="line">8970</span><br><span class="line">8971</span><br></pre></td></tr></table></figure>

</details>

<p>可见，程序自动载入检查点文件是从第8969次开始运行的。</p>
<p><img src="Image00014.jpg" alt> 注意：<br>（1）如果不设置save_checkpoint_secs参数，默认的保存时间间隔为10分钟。这种按照时间保存的模式更适用于使用大型数据集来训练复杂模型的情况。</p>
<p>（2）使用该方法时，必须要定义global_step变量，否则会报错误。</p>
<h4 id="4-1-15-模型操作常用函数总结"><a href="#4-1-15-模型操作常用函数总结" class="headerlink" title="4.1.15 模型操作常用函数总结"></a>4.1.15 模型操作常用函数总结</h4><p>下面将模型操作的相关函数进行系统的介绍，如表4-2所示。</p>
<p>表4-2 模型操作相关函数</p>
<p><img src="Image00038.jpg" alt></p>
<p><img src="Image00039.jpg" alt></p>
<h4 id="4-1-16-TensorBoard可视化介绍"><a href="#4-1-16-TensorBoard可视化介绍" class="headerlink" title="4.1.16 TensorBoard可视化介绍"></a>4.1.16 TensorBoard可视化介绍</h4><p>TensorFlow还提供了一个可视化工具TensorBoard。它可以将训练过程中的各种绘制数据展示出来，包括标量（Scalars）、图片（Images）、音频（Audio）、计算图（Graph）、数据分布、直方图（Histograms）和嵌入式向量。可以通过网页来观察模型的结构和训练过程中各个参数的变化。</p>
<p>当然，TensorBoard不会自动把代码展示出来，其实它是一个日志展示系统，需要在session中运算图时，将各种类型的数据汇总并输出到日志文件中。然后启动TensorBoard服务，TensorBoard读取这些日志文件，并开启6006端口提供Web服务，让用户可以在浏览器中查看数据。</p>
<p>TensorFlow提供了一系列API来生成这些数据，具体如表4-3所示。</p>
<p>表4-3 模型操作相关函数</p>
<p><img src="Image00040.jpg" alt></p>
<h4 id="4-1-17-实例13：线性回归的TensorBoard可视化"><a href="#4-1-17-实例13：线性回归的TensorBoard可视化" class="headerlink" title="4.1.17 实例13：线性回归的TensorBoard可视化"></a>4.1.17 实例13：线性回归的TensorBoard可视化</h4><p>下面举例演示TensorBoard的可视化效果。</p>
<p>实例描述</p>
<p>为“3-1线性回归.py”代码文件添加支持输出TensorBoard信息的功能，演示通过TensorBoard来观察训练过程。</p>
<p>本例还是以“3-1线性回归.py”文件的代码为原型，在上面添加支持TensorBoard的功能。该例子中，通过添加一个标量数据和一个直方图数据到log里，然后通过TensorBoard显示出来。代码改动量非常小，第一步加入到summary，第二步写入文件。</p>
<p>将模型的生成值加入到直方图数据中，将损失值加入到标量数据中，代码如下：</p>
<p>代码4-8 线性回归的TensorBoard可视化</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">……</span><br><span class="line"># 前向结构</span><br><span class="line">z = tf.multiply(X, W)+ b</span><br><span class="line">tf.summary.histogram(&apos;z&apos;,z)                  #将预测值以直方图形式显示</span><br><span class="line">#反向优化</span><br><span class="line">cost =tf.reduce_mean( tf.square(Y -z))</span><br><span class="line">tf.summary.scalar(&apos;loss_function&apos;, cost)  #将损失以标量形式显示</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>给直方图起名仍然叫z，标量的名字叫loss_function。</p>
<p>下面的代码是在启动session之后加入代码，创建一个summary_writer，在迭代中将summary的值运行生成出来，同时添加到文件里。</p>
<p>代码4-8 线性回归的 TensorBoard可视化（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">  # 启动session</span><br><span class="line">  with tf.Session() as sess:</span><br><span class="line">     sess.run(init)</span><br><span class="line">  </span><br><span class="line">     merged_summary_op = tf.summary.merge_all()#合并所有summary</span><br><span class="line">     #创建summary_writer，用于写文件</span><br><span class="line">     summary_writer = </span><br><span class="line">  tf.summary.FileWriter(&apos;log/mnist_with_summaries&apos;,sess.graph)</span><br><span class="line">  </span><br><span class="line">     # 向模型中输入数据</span><br><span class="line">     for epoch in range(training_epochs):</span><br><span class="line">       for(x, y)in zip(train_X,train_Y):</span><br><span class="line">         sess.run(optimizer, feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">         </span><br><span class="line">      #生成summary</span><br><span class="line">      summary_str = sess.run(merged_summary_op,feed_dict=&#123;X: x, Y: y&#125;);</span><br><span class="line">      summary_writer.add_summary(summary_str, epoch);#将summary 写入文件</span><br><span class="line"></span><br><span class="line">￼41      ……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，显示的内容和以前一样没什么变化，来到生成的路径下可以看到多了一个文件，如图4-3所示。</p>
<p><img src="Image00041.jpg" alt></p>
<p>图4-3 summary文件</p>
<p>然后单击“开始”|“运行”，输入cmd，启动“命令行”窗口。首先来到summary日志的上级路径下，输入如下命令：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir D:\python\log/mnist_with_summaries</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图4-4所示。</p>
<p><img src="Image00042.jpg" alt></p>
<p>图4-4 启动TensorBoard</p>
<p>接着打开Chrome浏览器，输入<a href="http://127.0.0.1:6006" target="_blank" rel="noopener">http://127.0.0.1:6006</a> ，会看到如图4-5所示界面。单击SCALARS，会看到之前创建的loss_fuction。这个loss_fuction也是可以点开的，点开后可以看到损失值随迭代次数的变化情况，如图4-6所示。</p>
<p>在图4-6中可以调节平滑数来改变右边标量的曲线。类似的还可以点开图4-5中的GRAPHS看看神经网络的内部结构，还可以点开图4-5中的HISTOGRAMS来看例子中的另一个显示值z。</p>
<p><img src="Image00043.jpg" alt></p>
<p>图4-5 TensorBoard界面</p>
<p><img src="Image00044.jpg" alt></p>
<p>图4-6 TensorBoard标量</p>
<p><img src="Image00014.jpg" alt> 注意： 在显示TensorBoard界面的过程中，下面两点需要强调一下。</p>
<p>·浏览器最好要使用Chrome。</p>
<p>·在命令行里启动TensorBoard时，一定要先进入到日志所在的上级路径下，否则打开的页面里找不到创建好的信息。</p>
<h3 id="4-2-TensorFlow基础类型定义及操作函数介绍"><a href="#4-2-TensorFlow基础类型定义及操作函数介绍" class="headerlink" title="4.2 TensorFlow基础类型定义及操作函数介绍"></a>4.2 TensorFlow基础类型定义及操作函数介绍</h3><p>下面介绍TensorFlow的基础类型、基础函数。这部分学完，读者将会对TensorFlow的基础语法有了系统的了解，为后面学习写代码或读代码扫清障碍。</p>
<p>本节表格中的示例代码前面默认都有以下代码。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br></pre></td></tr></table></figure>

</details>

<p>代码中的tf代表tensorflow库，np代表numpy库。</p>
<h4 id="4-2-1-张量及操作"><a href="#4-2-1-张量及操作" class="headerlink" title="4.2.1 张量及操作"></a>4.2.1 张量及操作</h4><p>张量可以说是TensorFlow的标志，因为整个框架的名称TensorFlow就是张量流的意思。下面来一起全面地认识一下张量。</p>
<p>1．张量介绍</p>
<p>TensorFlow程序使用tensor数据结构来代表所有的数据。计算图中，操作间传递的数据都是Tensor。</p>
<p>可以把tensor看为一个n维的数组或列表，每个tensor中包含了类型（type）、阶（rank）和形状（shape）。</p>
<p>（1）tensor类型</p>
<p>为了方便理解，这里将tensor的类型与Python的类型放在一起做个比较，如表4-4所示。</p>
<p>表4-4 张量类型</p>
<p><img src="Image00045.jpg" alt></p>
<p>（2）rank（阶）</p>
<p>rank（阶）指的就是维度。但张量的阶和矩阵的阶并不是同一个概念，主要是看有几层中括号。例如，对于一个传统意义上的3阶矩阵a=[[1，2，3]，[4，5，6]，[7，8，9]]来讲，在张量中的阶数表示为2阶（因为它有两层中括号）。</p>
<p>表4-5列出了标量、向量、矩阵的阶数。</p>
<p>表4-5 标量向量和矩阵的阶数</p>
<p><img src="Image00046.jpg" alt></p>
<p>（3）shape（形状）</p>
<p>shape（形状）用于描述张量内部的组织关系。“形状”可以通过Python中的整数列表或元组（int list或tuples）来表示，也可以用TensorFlow中的相关形状函数来表示。</p>
<p>举例：一个二阶张量a=[[1，2，3]，[4，5，6]]形状是两行三列，描述为（2，3）。</p>
<p>2．张量相关操作</p>
<p>张量的相关操作包括类型转换、数值操作、形状变换和数据操作。</p>
<p>（1）类型转换</p>
<p>类型转换的相关函数如表4-6所示。</p>
<p>表4-6 类型变换相关函数</p>
<p><img src="Image00047.jpg" alt></p>
<p>（2）数值操作</p>
<p>数值操作的相关函数如表4-7所示。</p>
<p>表4-7 类型变换相关函数</p>
<p><img src="Image00048.jpg" alt></p>
<p><img src="Image00039.jpg" alt></p>
<p>（3）形状变换</p>
<p>形状变换的相关函数如表4-8所示。</p>
<p>表4-8 形状变换的相关函数</p>
<p><img src="Image00049.jpg" alt></p>
<p><img src="Image00050.jpg" alt></p>
<p><img src="Image00051.jpg" alt></p>
<p>（4）数据操作</p>
<p>数据操作的相关函数如表4-9所示。</p>
<p>表4-9 数据操作相关函数</p>
<p><img src="Image00052.jpg" alt></p>
<p><img src="Image00053.jpg" alt></p>
<p><img src="Image00054.jpg" alt></p>
<p><img src="Image00014.jpg" alt> 注意： TensorFlow开头的代码都不能直接运行，必须放到session里面才可以。例如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf </span><br><span class="line"></span><br><span class="line">x = tf.constant(2)</span><br><span class="line">y = tf.constant(5)</span><br><span class="line">def f1(): return tf.multiply(x, 17)</span><br><span class="line">def f2(): return tf.add(y, 23)</span><br><span class="line">r = tf.cond(tf.less(x, y), f1, f2)</span><br><span class="line">print(r) #这样是错的</span><br><span class="line"></span><br><span class="line">#生成两行三列的张量，值为1</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print(sess.run( r  )) #这样才可以</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-2-2-算术运算函数"><a href="#4-2-2-算术运算函数" class="headerlink" title="4.2.2 算术运算函数"></a>4.2.2 算术运算函数</h4><p>如表4-10中列出了TensorFlow关于算术运算方面的函数。</p>
<p>表4-10 算术操作</p>
<p><img src="Image00055.jpg" alt></p>
<p><img src="Image00056.jpg" alt></p>
<h4 id="4-2-3-矩阵相关的运算"><a href="#4-2-3-矩阵相关的运算" class="headerlink" title="4.2.3 矩阵相关的运算"></a>4.2.3 矩阵相关的运算</h4><p>矩阵相关的操作函数如表4-11所示。</p>
<p>表4-11 矩阵操作函数</p>
<p><img src="Image00057.jpg" alt></p>
<p><img src="Image00058.jpg" alt></p>
<h4 id="4-2-4-复数操作函数"><a href="#4-2-4-复数操作函数" class="headerlink" title="4.2.4 复数操作函数"></a>4.2.4 复数操作函数</h4><p>关于复数的操作函数如表4-12所示。</p>
<p>表4-12 复数操作函数</p>
<p><img src="Image00059.jpg" alt></p>
<p><img src="Image00060.jpg" alt></p>
<h4 id="4-2-5-规约计算"><a href="#4-2-5-规约计算" class="headerlink" title="4.2.5 规约计算"></a>4.2.5 规约计算</h4><p>规约计算的操作都会有降维的功能，在所有reduce_xxx系列操作函数中，都是以xxx的手段降维，每个函数都有axis这个参数，即沿某个方向，使用xxx方法对输入的Tensor进行降维。</p>
<p><img src="Image00014.jpg" alt> 提示： axis的默认值是None，即把input_tensor降到0维，即一个数。</p>
<p>对于二维input_tensor而言：axis=0，则按列计算；axis=1，则按行计算。</p>
<p>参数reduction_indices是为了兼容以前的版本与axis保证相同的含义。如表4-13所示为规约计算函数及其说明。</p>
<p>表4-13 规约计算函数</p>
<p><img src="Image00061.jpg" alt></p>
<p><img src="Image00062.jpg" alt></p>
<h4 id="4-2-6-分割"><a href="#4-2-6-分割" class="headerlink" title="4.2.6 分割"></a>4.2.6 分割</h4><p>分割操作是TensorFlow不常用的操作，在复杂的网络模型里偶尔才会用到。如表4-14所示为分割操作的相关函数。</p>
<p>表4-14 分割相关函数</p>
<p><img src="Image00063.jpg" alt></p>
<p><img src="Image00064.jpg" alt></p>
<h4 id="4-2-7-序列比较与索引提取"><a href="#4-2-7-序列比较与索引提取" class="headerlink" title="4.2.7 序列比较与索引提取"></a>4.2.7 序列比较与索引提取</h4><p>对于序列和数组的操作，是本书中常用的方法，具体的函数如表4-15所示。</p>
<p>表4-15 序列比较与索引提取相关函数</p>
<p><img src="Image00065.jpg" alt></p>
<h4 id="4-2-8-错误类"><a href="#4-2-8-错误类" class="headerlink" title="4.2.8 错误类"></a>4.2.8 错误类</h4><p>作为一个完整的框架，有它自己的错误处理。TensorFlow中的错误类如表4-16所示，该部分不常用，可以作为工具，使用时查询一下即可。</p>
<p>表4-16 错误类</p>
<p><img src="Image00066.jpg" alt></p>
<h3 id="4-3-共享变量"><a href="#4-3-共享变量" class="headerlink" title="4.3 共享变量"></a>4.3 共享变量</h3><p>下面来到本章的重点——共享变量。共享变量在复杂的网络中用处非常之广泛，所以读者一定要学好。</p>
<h4 id="4-3-1-共享变量用途"><a href="#4-3-1-共享变量用途" class="headerlink" title="4.3.1 共享变量用途"></a>4.3.1 共享变量用途</h4><p>在构建模型时，需要使用tf.Variable来创建一个变量（也可以理解成节点）。例如代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">biases = tf.Variable(tf.zeros([2]), name=&quot; biases&quot;)    #创建一个偏执的学习参数，在训练时，这个变量不断地更新</span><br></pre></td></tr></table></figure>

</details>

<p>但在某种情况下，一个模型需要使用其他模型创建的变量，两个模型一起训练。比如，对抗网络中的生成器模型与判别器模型（后文12章会有详细讲解）。如果使用tf.Variable，将会生成一个新的变量，而我们需要的是原来的那个biases变量。这时怎么办呢？</p>
<p>这时就是通过引入get_variable方法，实现共享变量来解决这个问题。这个种方法可以使用多套网络模型来训练一套权重。</p>
<h4 id="4-3-2-使用get-variable获取变量"><a href="#4-3-2-使用get-variable获取变量" class="headerlink" title="4.3.2 使用get-variable获取变量"></a>4.3.2 使用get-variable获取变量</h4><p>get_variable一般会配合variable_scope一起使用，以实现共享变量。variable_scope的意思是变量作用域。在某一作用域中的变量可以被设置成共享的方式，被其他网络模型使用。后文的4.3.4节中会有共享变量的实例。下面先介绍下get_variable的详细使用。</p>
<p>get_variable函数的定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.get_variable(&lt;name&gt;, &lt;shape&gt;, &lt;initializer&gt;)</span><br></pre></td></tr></table></figure>

</details>

<p>在TensorFlow里，使用 get_variable生成的变量是以指定的name属性为唯一标识，并不是定义的变量名称。使用时一般通过name属性定位到具体变量，并将其共享到其他模型中。</p>
<p>下面通过两个例子来深入介绍。</p>
<h4 id="4-3-3-实例14：演示get-variable和Variable的区别"><a href="#4-3-3-实例14：演示get-variable和Variable的区别" class="headerlink" title="4.3.3 实例14：演示get_variable和Variable的区别"></a>4.3.3 实例14：演示get_variable和Variable的区别</h4><p>实例描述</p>
<p>分别使用Variable定义变量和使用get_variable来定义变量。请读者仔细观察它们的用法区别。</p>
<p>1．Variable的用法</p>
<p>首先先来看一下Variable的用法。</p>
<p>代码4-9 get_variable和Variable的区别</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">var1 = tf.Variable(1.0 , name=&apos;firstvar&apos;)</span><br><span class="line">print (&quot;var1:&quot;,var1.name)</span><br><span class="line">var1 = tf.Variable(2.0 , name=&apos;firstvar&apos;)</span><br><span class="line">print (&quot;var1:&quot;,var1.name)</span><br><span class="line">var2 = tf.Variable(3.0 )</span><br><span class="line">print (&quot;var2:&quot;,var2.name)</span><br><span class="line">var2 = tf.Variable(4.0 )</span><br><span class="line">print (&quot;var1:&quot;,var2.name)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(&quot;var1=&quot;,var1.eval())</span><br><span class="line">    print(&quot;var2=&quot;,var2.eval())</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码运行后输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var1: firstvar:0</span><br><span class="line">var1: firstvar_1:0</span><br><span class="line">var2: Variable:0</span><br><span class="line">var1: Variable_1:0</span><br><span class="line">var1= 2.0</span><br><span class="line">var2= 4.0</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中定义了两次var1，可以看到在内存中生成了两个var1（因为它们的name不一样），对于图来讲后面的var1是生效的（var1=2.0）。</p>
<p>var2表明了：Variable定义时没有指定名字，系统会自动给加上一个名字Variable：0。</p>
<p>2．get_variable用法演示</p>
<p>接着上面的代码，使用get_variable添加get_var1变量。</p>
<p>代码4-9 get_variable和Variable的区别（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> get_var1 = tf.get_variable(&quot;firstvar&quot;,[1], initializer=tf.constant_</span><br><span class="line">initializer(0.3))</span><br><span class="line"> print (&quot;get_var1:&quot;,get_var1.name)</span><br><span class="line"> </span><br><span class="line"> get_var1 = tf.get_variable(&quot;firstvar&quot;,[1], initializer=tf.constant_</span><br><span class="line">initializer(0.4))</span><br><span class="line"> print (&quot;get_var1:&quot;,get_var1.name)</span><br></pre></td></tr></table></figure>

</details>

<p>代码运行之后结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">var1: firstvar:0</span><br><span class="line">var1: firstvar_1:0</span><br><span class="line">var2: Variable:0</span><br><span class="line">var1: Variable_1:0</span><br><span class="line">var1= 2.0</span><br><span class="line">var2= 4.0</span><br><span class="line">get_var1: firstvar_2:0</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，程序在定义第2个get_var1时发生崩溃了。这表明，使用get_variable只能定义一次指定名称的变量。同时由于变量firstvar在前面使用Variable函数生成过一次，所以系统自动变成了firstvar_2：0。</p>
<p>如果将崩溃的句子改成下面的样子：</p>
<p>代码4-9 get_variable和Variable的区别（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> get_var1 = tf.get_variable(&quot;firstvar&quot;,[1], initializer=tf.constant_</span><br><span class="line">initializer(0.3))</span><br><span class="line"> print (&quot;get_var1:&quot;,get_var1.name)</span><br><span class="line"> </span><br><span class="line"> get_var1 = tf.get_variable(&quot;firstvar1&quot;,[1], initializer=tf.constant_</span><br><span class="line">initializer(0.4))</span><br><span class="line"> print (&quot;get_var1:&quot;,get_var1.name)</span><br><span class="line"> </span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     sess.run(tf.global_variables_initializer())</span><br><span class="line">     print(&quot;get_var1=&quot;,get_var1.eval())</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下：（部分内容）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">get_var1: firstvar_2:0</span><br><span class="line">get_var1: firstvar1:0</span><br><span class="line">get_var1= [ 0.40000001]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，这次仍然是又定义了一个get_var1，不同的是改变了它的名字firstvar1，这样就没有问题了。同样，新的get_var1会在图中生效，所以它的输出值是4.0而不是3.0。</p>
<h4 id="4-3-4-实例15：在特定的作用域下获取变量"><a href="#4-3-4-实例15：在特定的作用域下获取变量" class="headerlink" title="4.3.4 实例15：在特定的作用域下获取变量"></a>4.3.4 实例15：在特定的作用域下获取变量</h4><p>实例描述</p>
<p>在作用域下，使用get_variable，以及嵌套variable_scope。</p>
<p>在前面的例子中，大家已经知道使用get_variable创建两个同样名字的变量是行不通的，如下代码会报错。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var1 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)   </span><br><span class="line">var2 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p>如果真的想要那么做，可以使用variable_scope将它们隔开，代码如下。</p>
<p>代码4-10 get_variable配合variable_scope</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">with tf.variable_scope(&quot;test1&quot;, ):     #定义一个作用域test1</span><br><span class="line">    var1 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">    </span><br><span class="line">with tf.variable_scope(&quot;test2&quot;):</span><br><span class="line">    var2 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">        </span><br><span class="line">print (&quot;var1:&quot;,var1.name)</span><br><span class="line">print (&quot;var2:&quot;,var2.name)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var1: test1/firstvar:0</span><br><span class="line">var2: test2/firstvar:0</span><br></pre></td></tr></table></figure>

</details>

<p>var1和var2都使用firstvar的名字来定义。通过输出可以看出，其实生成的两个变量var1和var2是不同的，它们作用在不同的scope下，这就是scope的作用。</p>
<p>scope还支持嵌套，将上面代码中的第二个scope缩进一下，得到如下代码：</p>
<p>代码4-11 get_variable配合variable_scope2</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line"></span><br><span class="line">with tf.variable_scope(&quot;test1&quot;, ):</span><br><span class="line">    var1 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">    </span><br><span class="line">    with tf.variable_scope(&quot;test2&quot;):</span><br><span class="line">        var2 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">        </span><br><span class="line">print (&quot;var1:&quot;,var1.name)</span><br><span class="line">print (&quot;var2:&quot;,var2.name)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var1: test1/firstvar:0</span><br><span class="line">var2: test1/test2/firstvar:0</span><br></pre></td></tr></table></figure>

</details>

<h4 id="4-3-5-实例16：共享变量功能的实现"><a href="#4-3-5-实例16：共享变量功能的实现" class="headerlink" title="4.3.5 实例16：共享变量功能的实现"></a>4.3.5 实例16：共享变量功能的实现</h4><p>实例描述</p>
<p>使用作用域中的reuse参数来实现共享变量功能。</p>
<p>费了这么大的劲来使用get_variable，目的其实是为了要通过它实现共享变量的功能。</p>
<p>variable_scope里面有个reuse=True属性，表示使用已经定义过的变量。这时get_variable将不会再创建新的变量，而是去图（一个计算任务）中get_variable所创建过的变量中找与name相同的变量。</p>
<p>在上文代码中再建立一个同样的scope，并且设置reuse=True，实现共享firstvar变量。</p>
<p>代码4-11 get_variable配合variable_scope2（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">with tf.variable_scope(&quot;test1&quot;,reuse=True ):</span><br><span class="line">    var3= tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">    with tf.variable_scope(&quot;test2&quot;):</span><br><span class="line">        var4 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">print (&quot;var3:&quot;,var3.name)</span><br><span class="line">print (&quot;var4:&quot;,var4.name)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var1: test1/firstvar:0</span><br><span class="line">var2: test1/test2/firstvar:0</span><br><span class="line">var3: test1/firstvar:0</span><br><span class="line">var4: test1/test2/firstvar:0</span><br></pre></td></tr></table></figure>

</details>

<p>var1和var3的输出名字是一样的，var2和var4的名字也是一样的。这表明var1和var3共用了一个变量，var2和var4共用了一个变量，这就实现了共享变量。在实际应用中，可以把var1和var2放到一个网络模型里去训练，把var3和var4放到另一个网络模型里去训练，而两个模型的训练结果都会作用于一个模型的学习参数上。</p>
<p><img src="Image00014.jpg" alt> 注意： 如果读者使用的是Anaconda工具包里面的Spyder工具（第2章介绍过）运行，该代码只能运行一次，第二次会报错。</p>
<p>解决办法：需要在Anacondad的Consoles菜单里退出当前的kernel，再重新进入一下。再运行才不会报错。否则会提示已经有这个变量了。</p>
<p>为什么会这样呢？</p>
<p>tf.get_variable在创建变量时，会去检查图（一个计算任务）中是否已经创建过该变量。如果创建过并且本次调用时没有被设为共享方式，则会报错。</p>
<p>明白原理后可以加一条语句tf.reset_default_graph（），将图（一个计算任务）里面的变量清空，就可以解决这个问题了。图（一个计算任务）的更多内容将在后面章节介绍。</p>
<h4 id="4-3-6-实例17：初始化共享变量的作用域"><a href="#4-3-6-实例17：初始化共享变量的作用域" class="headerlink" title="4.3.6 实例17：初始化共享变量的作用域"></a>4.3.6 实例17：初始化共享变量的作用域</h4><p>实例描述</p>
<p>演示variable_scope中get_variable初始化的继承功能，以及嵌套variable_scope的继承功能。</p>
<p>variable_scope和get_variable都有初始化的功能。在初始化时，如果没有对当前变量初始化，则TensorFlow会默认使用作用域的初始化方法对其初始化，并且作用域的初始化方法也有继承功能。下面演示代码。</p>
<p>代码4-12 共享变量的作用域与初始化</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">with tf.variable_scope(&quot;test1&quot;, initializer=tf.constant_initializer </span><br><span class="line">  (0.4) ):</span><br><span class="line">  var1 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">  </span><br><span class="line">  with tf.variable_scope(&quot;test2&quot;):</span><br><span class="line">   var2 = tf.get_variable(&quot;firstvar&quot;,shape=[2],dtype=tf.float32)</span><br><span class="line">   var3 = tf.get_variable(&quot;var3&quot;,shape=[2],initializer=tf.constant_ </span><br><span class="line">  initializer (0.3))</span><br><span class="line">      </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  print(&quot;var1=&quot;,var1.eval())     #作用域test1下的变量</span><br><span class="line">  print(&quot;var2=&quot;,var2.eval())     #作用域test2下的变量，继承test1初始化</span><br><span class="line">  print(&quot;var3=&quot;,var3.eval())     #作用域test2下的变量</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码大致操作如下：</p>
<p>·将test1作用域进行初始化为4.0，见代码第3行。</p>
<p>·var1没有初始化，见代码第4行。</p>
<p>·嵌套的test2作用域也没有初始化，见代码第6行。</p>
<p>·test2下的var3进行了初始化，见代码第8行。</p>
<p>运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var1= [ 0.40000001  0.40000001]</span><br><span class="line">var2= [ 0.40000001  0.40000001]</span><br><span class="line">var3= [ 0.30000001  0.30000001]</span><br></pre></td></tr></table></figure>

</details>

<p>var1数组值为0.4，表明继承了test1的值；var2数组值为0.4，表明其所在的作用域test2也继承了test1的初始化；变量var3在创建时同步指定了初始化操作，所以数组值为0.3。</p>
<p><img src="Image00014.jpg" alt> 注意： 在多模型训练中，常常会使用variable_scope对模型间的张量进行区分。同时，统一为学习参数进行默认的初始化。在变量共享方面，还可以使用 tf.AUTO_REUSE来为reuse属性赋值。tf.AUTO_REUSE可以实现第一次调用variable_scope时，传入的reuse值是False；再次调用variable_scope时，传入reuse的值就会自动变为True。</p>
<h4 id="4-3-7-实例18：演示作用域与操作符的受限范围"><a href="#4-3-7-实例18：演示作用域与操作符的受限范围" class="headerlink" title="4.3.7 实例18：演示作用域与操作符的受限范围"></a>4.3.7 实例18：演示作用域与操作符的受限范围</h4><p>实例描述</p>
<p>演示variable_scope的as用法，以及对应的作用域。</p>
<p>variable_scope还可以使用with variable_scope（”name”）as xxxscope的方式定义作用域，当使用这种方式时，所定义的作用域变量xxxscope将不再受到外围的scope所限制。看下面的例子。</p>
<p>代码4-13 作用域与操作符的受限范围</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">with tf.variable_scope(&quot;scope1&quot;) as sp:</span><br><span class="line">     var1 = tf.get_variable(&quot;v&quot;, [1])</span><br><span class="line"></span><br><span class="line">print(&quot;sp:&quot;,sp.name)              #作用域名称 </span><br><span class="line">print(&quot;var1:&quot;,var1.name)      </span><br><span class="line"></span><br><span class="line">with tf.variable_scope(&quot;scope2&quot;):</span><br><span class="line">    var2 = tf.get_variable(&quot;v&quot;, [1])</span><br><span class="line">    </span><br><span class="line">    with tf.variable_scope(sp) as sp1:</span><br><span class="line">        var3 = tf.get_variable(&quot;v3&quot;, [1])</span><br><span class="line">          </span><br><span class="line">print(&quot;sp1:&quot;,sp1.name)  </span><br><span class="line">print(&quot;var2:&quot;,var2.name)</span><br><span class="line">print(&quot;var3:&quot;,var3.name)</span><br></pre></td></tr></table></figure>

</details>

<p>例子中定义了作用域scope1 as sp（见代码第3行），然后将sp放在作用域scope2中，并as成sp1（见代码第12行）。运行代码输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sp: scope1</span><br><span class="line">var1: scope1/v:0</span><br><span class="line">sp1: scope1</span><br><span class="line">var2: scope2/v:0</span><br><span class="line">var3: scope1/v3:0</span><br></pre></td></tr></table></figure>

</details>

<p>sp和var1的输出前面已经交代过。sp1在scope2下，但是输出仍是scope1，没有改变。在它下面定义的var3的名字是scope1/v3：0，表明也在scope1下，再次说明sp没有受到外层的限制。</p>
<p>另外再介绍一个操作符的作用域tf.name_scope，如下所示。操作符不仅受到tf.name_scope作用域的限制，同时也受到tf.variable_scope作用域的限制。</p>
<p>代码4-13 作用域与操作符的受限范围（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> with tf.variable_scope(&quot;scope&quot;):</span><br><span class="line">     with tf.name_scope(&quot;bar&quot;):</span><br><span class="line">         v = tf.get_variable(&quot;v&quot;, [1])    #v为一个变量</span><br><span class="line">         x = 1.0 + v                          # x为一个op，实现1.0+v操作</span><br><span class="line"> print(&quot;v:&quot;,v.name)  </span><br><span class="line"> print(&quot;x.op:&quot;,x.op.name)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码运行后输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v: scope/v:0</span><br><span class="line">x.op: scope/bar/add</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，虽然v和x都在scope的bar下面，但是v的命名只受到scope的限制，tf.name_scope只能限制op，不能限制变量的命名。</p>
<p>在tf.name_scope函数中，还可以使用空字符将作用域返回到顶层。</p>
<p>下面举例来比较tf.name_scope与variable_scope在空字符情况下的处理：</p>
<p>·在代码第28行var3的定义之后添加空字符的variable_scope。</p>
<p>·定义var4，见代码第31行。</p>
<p>代码4-13 作用域与操作符的受限范围（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">with tf.variable_scope(&quot;scope2&quot;):</span><br><span class="line">    var2 = tf.get_variable(&quot;v&quot;, [1])</span><br><span class="line">    </span><br><span class="line">    with tf.variable_scope(sp) as sp1:</span><br><span class="line">        var3 = tf.get_variable(&quot;v3&quot;, [1])</span><br><span class="line">          </span><br><span class="line">        with tf.variable_scope(&quot;&quot;) :</span><br><span class="line">            var4 = tf.get_variable(&quot;v4&quot;, [1])</span><br></pre></td></tr></table></figure>

</details>

<p>在x = 1.0 + v之后添加空字符的tf.name_scope，并定义y。代码如下：</p>
<p>代码4-13 作用域与操作符的受限范围（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">with tf.variable_scope(&quot;scope&quot;):</span><br><span class="line">    with tf.name_scope(&quot;bar&quot;):</span><br><span class="line">        v = tf.get_variable(&quot;v&quot;, [1])</span><br><span class="line">        x = 1.0 + v</span><br><span class="line">        with tf.name_scope(&quot;&quot;):</span><br><span class="line">            y = 1.0 + v</span><br></pre></td></tr></table></figure>

</details>

<p>将var4和y的值打印出来，得出如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var4: scope1//v4:0</span><br><span class="line">y.op: add</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，y变成顶层了，而var4多了一个空层。</p>
<h3 id="4-4-实例19：图的基本操作"><a href="#4-4-实例19：图的基本操作" class="headerlink" title="4.4 实例19：图的基本操作"></a>4.4 实例19：图的基本操作</h3><p>前面接触了一些图（一个计算任务）的概念，这里来系统地了解一下TensorFlow中的图可以做哪些事情。</p>
<p>实例描述</p>
<p>（1）本例演示使用3种方式来建立图，并依次设置为默认图，使用get_default_graph（）方法来获取当前默认图，验证默认图的设置生效。</p>
<p>（2）演示获取图中相关内容的操作。</p>
<p>一个TensorFlow程序默认是建立一个图的，除了系统自动建图以外，还可以手动建立，并做一些其他的操作。</p>
<h4 id="4-4-1-建立图"><a href="#4-4-1-建立图" class="headerlink" title="4.4.1 建立图"></a>4.4.1 建立图</h4><p>可以在一个TensorFlow中手动建立其他的图，也可以根据图里的变量获得当前的图。</p>
<p>下面代码演示了使用tf.Graph函数建立图，使用tf.get_default_graph函数获得图，以及使用reset_default_graph的过程来重置图的过程。</p>
<p>代码4-14 图的基本操作</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf </span><br><span class="line">c = tf.constant(0.0)</span><br><span class="line"></span><br><span class="line">g = tf.Graph()</span><br><span class="line">with g.as_default():</span><br><span class="line">  c1 = tf.constant(0.0)</span><br><span class="line">  print(c1.graph)</span><br><span class="line">  print(g)</span><br><span class="line">  print(c.graph)</span><br><span class="line"></span><br><span class="line">g2 =  tf.get_default_graph()</span><br><span class="line">print(g2)</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">g3 =  tf.get_default_graph()</span><br><span class="line">print(g3)</span><br></pre></td></tr></table></figure>

</details>

<p>代码运行结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;tensorflow.python.framework.ops.Graph object at 0x000000000B854940&gt;</span><br><span class="line">&lt;tensorflow.python.framework.ops.Graph object at 0x000000000B854940&gt;</span><br><span class="line">&lt;tensorflow.python.framework.ops.Graph object at 0x000000000923CCF8&gt;</span><br><span class="line">&lt;tensorflow.python.framework.ops.Graph object at 0x000000000923CCF8&gt;</span><br><span class="line">&lt;tensorflow.python.framework.ops.Graph object at 0x000000000B8546D8&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出。</p>
<p>（1）c是在刚开始的默认图中建立的，所以图的打印值就是原始的默认图的打印值923CCF8。</p>
<p>（2）然后使用tf.Graph函数建立了一个图B854940（见代码第5行），并且在新建的图里添加变量，可以通过变量的“.graph”获得所在的图。</p>
<p>（3）在新图B854940的作用域外，使用tf.get_default_graph函数又获得了原始的默认图923CCF8（见代码第12行）。接着又使用tf.reset_default_graph函数（见代码第15行），相当于重新建了一张图来代替原来的默认图，这时默认的图变成了B8546D8。</p>
<p><img src="Image00014.jpg" alt> 注意： 在使用tf.reset_default_graph函数时必须保证当前图的资源已经全部释放，否则会报错。例如，在当前图中使用tf.InteractiveSession函数建立了一个会话，在会话结束时却没有调用close进行关闭，那么再执行tf.reset_default_graph函数时，就会报错。</p>
<h4 id="4-4-2-获取张量"><a href="#4-4-2-获取张量" class="headerlink" title="4.4.2 获取张量"></a>4.4.2 获取张量</h4><p>在图里面可以通过名字得到其对应的元素，例如，get_tensor_by_name可以获得图里面的张量。在上个实例中添加如下代码。</p>
<p>代码4-14 图的基本操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(c1.name)</span><br><span class="line">t = g.get_tensor_by_name(name = &quot;Const:0&quot;)</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure>

</details>

<p>该部分代码运行结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Const:0</span><br><span class="line">Tensor(&quot;Const:0&quot;, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure>

</details>

<p>常量c1是在一个子图g中建立的。with tf.Graph（） as default代码表示使用tf.Graph函数来创建一个图，并在其上面定义OP，见代码第5、6行。</p>
<p>接着演示了如何访问该图中的变量：将c1的名字放到get_tensor_by_name里来反向得到其张量（见代码第19行），通过对t的打印可以看到所得的t就是前面定义的张量c1。</p>
<p><img src="Image00014.jpg" alt> 注意： 不必花太多精力去关注TensorFlow中默认的命名规则。一般在需要使用名字时，都会在定义的同时为它指定好固定的名字。如果真的不清楚某个元素的名字，可将其打印出来，回填到代码中，再次运行即可。</p>
<h4 id="4-4-3-获取节点操作"><a href="#4-4-3-获取节点操作" class="headerlink" title="4.4.3 获取节点操作"></a>4.4.3 获取节点操作</h4><p>获取节点操作OP的方法和获取张量的方法非常类似，使用的方法是get_operation_ by_name。下面将获取张量和获取OP的例子放在一起比较一下，具体代码如下。</p>
<p>代码4-14 图的基本操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[1.0, 2.0]])</span><br><span class="line">b = tf.constant([[1.0], [3.0]])</span><br><span class="line"></span><br><span class="line">tensor1 = tf.matmul(a, b, name=&apos;exampleop&apos;)</span><br><span class="line">print(tensor1.name,tensor1) </span><br><span class="line">test = g3.get_tensor_by_name(&quot;exampleop:0&quot;)</span><br><span class="line">print(test)</span><br><span class="line"></span><br><span class="line">print(tensor1.op.name)</span><br><span class="line">testop = g3.get_operation_by_name(&quot;exampleop&quot;)</span><br><span class="line">print(testop)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    test =  sess.run(test)</span><br><span class="line">    print(test) </span><br><span class="line">    test = tf.get_default_graph().get_tensor_by_name(&quot;exampleop:0&quot;)</span><br><span class="line">    print (test)</span><br></pre></td></tr></table></figure>

</details>

<p>上面示例中，先将张量及其名字打印出来，然后使用g3图的get_tensor_by_name函数又获得了该张量，此时test和tensor1是一样的。为了证明这一点，直接把test放到session的run里，发现它运行后也能得到正确的结果。</p>
<p><img src="Image00014.jpg" alt> 注意： 使用默认的图时，也可以用上述代码中的tf.get_default_graph函数获取当前图，然后可以调用get_tensor_by_name函数获取元素。</p>
<p>上面代码运行后会显示如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">exampleop:0 Tensor(&quot;exampleop:0&quot;, shape=(1, 1), dtype=float32)</span><br><span class="line">Tensor(&quot;exampleop:0&quot;, shape=(1, 1), dtype=float32)</span><br><span class="line">exampleop</span><br><span class="line">name: &quot;exampleop&quot;</span><br><span class="line">op: &quot;MatMul&quot;</span><br><span class="line">input: &quot;Const&quot;</span><br><span class="line">input: &quot;Const_1&quot;</span><br><span class="line">attr &#123;</span><br><span class="line">  key: &quot;T&quot;</span><br><span class="line">  value &#123;</span><br><span class="line">    type: DT_FLOAT</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">attr &#123;</span><br><span class="line">  key: &quot;transpose_a&quot;</span><br><span class="line">  value &#123;</span><br><span class="line">    b: false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">attr &#123;</span><br><span class="line">  key: &quot;transpose_b&quot;</span><br><span class="line">  value &#123;</span><br><span class="line">    b: false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[[ 7.]]</span><br><span class="line">Tensor(&quot;exampleop:0&quot;, shape=(1, 1), dtype=float32)</span><br></pre></td></tr></table></figure>

</details>

<p>再仔细看上例中的OP，通过打印tensor1.op.name的信息，获得了OP的名字，然后通过get_operation_by_name函数获得了相同的OP，可以看出OP与tensor1之间的对应关系。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里之所以要放在一起举例，原因就是OP和张量在定义节点时很容易被混淆。上例中的tensor1 = tf.matmul（a，b，name=’exampleop’）并不是OP，而是张量。OP其实是描述张量中的运算关系，是通过访问张量的属性找到的。</p>
<h4 id="4-4-4-获取元素列表"><a href="#4-4-4-获取元素列表" class="headerlink" title="4.4.4 获取元素列表"></a>4.4.4 获取元素列表</h4><p>如果想看一下图中的全部元素，可以使用get_operations函数来实现。具体代码如下。</p>
<p>代码4-14 图的基本操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tt2 = g.get_operations()</span><br><span class="line">print(tt2)</span><br></pre></td></tr></table></figure>

</details>

<p>运行后显示如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;tf.Operation &apos;Const&apos; type=Const&gt;]</span><br></pre></td></tr></table></figure>

</details>

<p>由于g里面只有一个常量，所以打印了一条信息。</p>
<h4 id="4-4-5-获取对象"><a href="#4-4-5-获取对象" class="headerlink" title="4.4.5 获取对象"></a>4.4.5 获取对象</h4><p>前面是根据名字来获取元素，还可以根据对象来获取元素。使用tf.Graph.as_ graph_element（obj，allow_tensor=True，allow_operation=True）函数，即传入的是一个对象，返回一个张量或是一个OP。该函数具有验证和转换功能，在多线程方面会偶尔用到。举例如下。</p>
<p>代码4-14 图的基本操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tt3 = g.as_graph_element(c1)</span><br><span class="line">print(tt3)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor(&quot;Const:0&quot;, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码通过对tt3的打印可以看到，变量tt3所指的张量名字为Const0，而在4.4.2节中可以看到量名c1所指向的真实张量名字也为Const0。这表明：函数as_graph_element 获得了c1的真实张量对象，并赋给了变量tt3。</p>
<p><img src="Image00014.jpg" alt> 备注： 这里只是介绍了图中比较简单的操作，图的操作还有很多，有的还很常用。但考虑到初学者的接受程度，更复杂的图操作（如冻结图，将一个图导入另一个图中等）将会在后面的章节中进行介绍。</p>
<h4 id="4-4-6-练习题"><a href="#4-4-6-练习题" class="headerlink" title="4.4.6 练习题"></a>4.4.6 练习题</h4><p>试试将tf.get_default_graph函数放在with tf.Graph（）.as_default（）：作用域里，看看会得到什么，是全局的默认图，还是tf.Graph函数新建的图？（示例代码在“代码4-14图的基本操作”中）</p>
<h3 id="4-5-配置分布式TensorFlow"><a href="#4-5-配置分布式TensorFlow" class="headerlink" title="4.5 配置分布式TensorFlow"></a>4.5 配置分布式TensorFlow</h3><p>在大型的数据集上进行神经网络的训练，往往需要更大的运算资源，而且还要耗费若干天才能完成运算量。</p>
<p>TensorFlow提供了一个可以分布式部署的模式，将一个训练任务拆成多个小任务，分配到不同的计算机上来完成协同运算，这样使用计算机群运算来代替单机计算，可以使训练时间大大缩短。</p>
<h4 id="4-5-1-分布式TensorFlow的角色及原理"><a href="#4-5-1-分布式TensorFlow的角色及原理" class="headerlink" title="4.5.1 分布式TensorFlow的角色及原理"></a>4.5.1 分布式TensorFlow的角色及原理</h4><p>要想配置TensorFlow为分布训练，需要先了解TensorFlow中关于分布式的角色分配。</p>
<p>·ps：作为分布式训练的服务端，等待各个终端（supervisors）来连接。</p>
<p>·worker：在TensorFlow的代码注释中被称为supervisors，作为分布式训练的运算终端。</p>
<p>·chief supervisors：在众多运算终端中必须选择一个作为主要的运算终端。该终端是在运算终端中最先启动的，它的功能是合并各个终端运算后的学习参数，将其保存或载入。</p>
<p>每个具体角色网络标识都是唯一的，即分布在不同IP的机器上（或者同一个机但不同的端口）。</p>
<p>在实际运行中，各个角色的网络构建部分代码必须100%的相同。三者的分工如下：</p>
<p>·服务端作为一个多方协调者，等待各个运算终端来连接。</p>
<p>·chief supervisors会在启动时统一管理全局的学习参数，进行初始化或从模型载入。</p>
<p>·其他的运算终端只是负责得到其对应的任务并进行计算，并不会保存检查点，用于TensorBoard可视化中的summary日志等任何参数信息。</p>
<p>整个过程都是通过RPC协议来通信的。</p>
<h4 id="4-5-2-分布部署TensorFlow的具体方法"><a href="#4-5-2-分布部署TensorFlow的具体方法" class="headerlink" title="4.5.2 分布部署TensorFlow的具体方法"></a>4.5.2 分布部署TensorFlow的具体方法</h4><p>配置过程中，首先需要建一个server，在server中会将ps及所有worker的IP端口准备好。接着，使用tf.train.Supervisor中的managed_session来管理一个打开的session。session中只是负责运算，而通信协调的事情就都交给supervisor来管理了。</p>
<h4 id="4-5-3-实例20：使用TensorFlow实现分布式部署训练"><a href="#4-5-3-实例20：使用TensorFlow实现分布式部署训练" class="headerlink" title="4.5.3 实例20：使用TensorFlow实现分布式部署训练"></a>4.5.3 实例20：使用TensorFlow实现分布式部署训练</h4><p>下面开始实现一个分布式训练的网络模型。本例以“代码4-8线性回归的TensorBoard可视化.py”为原型，在其中添加代码将其改成分布式。</p>
<p>实例描述</p>
<p>在本机通过3个端口来建立3个终端，分别是一个ps，两个worker，实现TensorFlow的分布式运算。</p>
<p>具体步骤如下。</p>
<p>1．为每个角色添加IP地址和端口，创建server</p>
<p>在一台机器上开3个不同的端口，分别代表ps、chief supervisors 和worker。角色的名称用strjob_name表示。以ps为例，代码如下：</p>
<p>代码4-15 ps</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> #定义IP和端口 </span><br><span class="line"> strps_hosts=&quot;localhost:1681&quot;</span><br><span class="line"> strworker_hosts=&quot;localhost:1682,localhost:1683&quot;</span><br><span class="line"> </span><br><span class="line"> #定义角色名称</span><br><span class="line"> strjob_name = &quot;ps&quot;</span><br><span class="line"> task_index = 0</span><br><span class="line"> #将字符串转成数组</span><br><span class="line"> ps_hosts = strps_hosts.split(&apos;,&apos;)</span><br><span class="line"> worker_hosts = strworker_hosts.split(&apos;,&apos;)</span><br><span class="line"> cluster_spec = tf.train.ClusterSpec(&#123;&apos;ps&apos;: ps_hosts,&apos;worker&apos;: worker_</span><br><span class="line">hosts&#125;)</span><br><span class="line"> #创建server</span><br><span class="line"> server = tf.train.Server(</span><br><span class="line">                     &#123;&apos;ps&apos;: ps_hosts,&apos;worker&apos;: worker_hosts&#125;,</span><br><span class="line">                     job_name=strjob_name,</span><br><span class="line">                     task_index=task_index)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 没有网络基础的读者可能看不明白localhost，说好的IP地址呢？localhost即是本机域名的写法，等同于127.0.0.1（本机IP）。如果是跨机器来做分布式训练，直接写成对应机器的IP地址即可。</p>
<p>2．为ps角色添加等待函数</p>
<p>ps角色使用server.join函数进行线程挂起，开始接收连接消息。</p>
<p>代码4-15 ps（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#ps角色使用join进行等待</span><br><span class="line">if strjob_name == &apos;ps&apos;:</span><br><span class="line">  print(&quot;wait&quot;)</span><br><span class="line">  server.join()</span><br></pre></td></tr></table></figure>

</details>

<p>3．创建网络结构</p>
<p>与正常的程序不同，在创建网络结构时，使用tf.device函数将全部的节点都放在当前任务下。</p>
<p>在tf.device函数中的任务是通过tf.train.replica_device_setter来指定的。</p>
<p>在tf.train.replica_device_setter中使用worker_device来定义具体任务名称；使用cluster的配置来指定角色及对应的IP地址，从而实现管理整个任务下的图节点。代码如下：</p>
<p>代码4-15 ps（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(tf.train.replica_device_setter(</span><br><span class="line">               worker_device=&quot;/job:worker/task:%d&quot; % task_index,</span><br><span class="line">               cluster=cluster_spec)):</span><br><span class="line">    X = tf.placeholder(&quot;float&quot;)</span><br><span class="line">    Y = tf.placeholder(&quot;float&quot;)</span><br><span class="line">    # 模型参数</span><br><span class="line">    W = tf.Variable(tf.random_normal([1]), name=&quot;weight&quot;)</span><br><span class="line">    b = tf.Variable(tf.zeros([1]), name=&quot;bias&quot;)</span><br><span class="line">    </span><br><span class="line">    global_step = tf.train.get_or_create_global_step() #获得迭代次数</span><br><span class="line">    </span><br><span class="line">    # 前向结构</span><br><span class="line">    z = tf.multiply(X, W)+ b</span><br><span class="line">    tf.summary.histogram(&apos;z&apos;,z)                    #将预测值以直方图显示</span><br><span class="line">    #反向优化</span><br><span class="line">    cost =tf.reduce_mean( tf.square(Y -z))</span><br><span class="line">    tf.summary.scalar(&apos;loss_function&apos;, cost)    #将损失以标量显示</span><br><span class="line">    learning_rate = 0.01</span><br><span class="line">    optimizer = tf.train.GradientDescentOptimizer(learning_rate).</span><br><span class="line">   minimize(cost,global_step=global_step) #梯度下降</span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line">    merged_summary_op = tf.summary.merge_all()  #合并所有summary</span><br><span class="line">   </span><br><span class="line">    init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure>

</details>

<p>为了使载入检查点文件时能够同步循环次数，这里加了一个global_step变量，并将其放到优化器中。这样，每次运行一次优化器，global_step就会自动获得当期迭代的次数。</p>
<p><img src="Image00014.jpg" alt> 注意： init = tf.global_variables_initializer（）这个代码是将其前面的变量全部初始化，如果后面再有变量，则不会被初始化。所以，一般要将init = tf.global_variables_ initializer（）这个代码放在最后。这是个很容易出错的地方，常常令开发者找不到头绪。读者也可以试着在最前面运行，看看会发生什么。</p>
<p>4．创建Supervisor，管理session</p>
<p>代码4-15 ps（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 定义参数</span><br><span class="line">training_epochs = 2200</span><br><span class="line">display_step = 2</span><br><span class="line"></span><br><span class="line">sv = tf.train.Supervisor(is_chief=(task_index == 0),#0号worker为chief</span><br><span class="line">                             logdir=&quot;log/super/&quot;,</span><br><span class="line">                             init_op=init,</span><br><span class="line">                             summary_op=None,</span><br><span class="line">                             saver=saver,</span><br><span class="line">                             global_step=global_step,</span><br><span class="line">                             save_model_secs=5)</span><br><span class="line"></span><br><span class="line">#连接目标角色创建session</span><br><span class="line">with sv.managed_session(server.target) as sess:</span><br></pre></td></tr></table></figure>

</details>

<p>在tf.train.Supervisor函数中，is_chief表明了是否为chief supervisors角色。这里将task_index=0的worker设置成chief supervisors。</p>
<p>logdir为检查点文件和summary文件保存的路径。</p>
<p>init_op表示使用初始化变量的函数。</p>
<p>saver需要将保存检查点的saver对象传入，supervisor就会自动保存检查点文件。如果不想自动保存，可以设为None。</p>
<p>同理，summary_op也是自动保存summary文件。这里设为None，表示不自动保存。</p>
<p>save_model_secs为保存检查点文件的时间间隔。这里设为5，表示每5秒自动保存一次检查点文件。以上代码，为了让分布运算的效果明显一些，将迭代次数改成了2200，使其运算时间变长。</p>
<p>5．迭代训练</p>
<p>session中的内容与以前一样，直接迭代训练即可。由于使用了supervisor管理session，将使用sv.summary_computed函数来保存summary文件。同样，如想要手动保存检测点文件，也可以使用sv.saver.save。代码如下：</p>
<p>代码4-15 ps（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;sess ok&quot;)</span><br><span class="line">    print(global_step.eval(session=sess))</span><br><span class="line">    </span><br><span class="line">    for epoch in range(global_step.eval(session=sess),training_</span><br><span class="line">   epochs*len(train_X)):</span><br><span class="line">    </span><br><span class="line">        for (x, y) in zip(train_X, train_Y):</span><br><span class="line">            _, epoch = sess.run([optimizer,global_step] ,feed_dict=&#123;X: </span><br><span class="line">           x, Y: y&#125;)</span><br><span class="line">            #生成summary</span><br><span class="line">            summary_str = sess.run(merged_summary_op,feed_dict=&#123;X: x, </span><br><span class="line">           Y: y&#125;);</span><br><span class="line">            #将summary 写入文件</span><br><span class="line">            sv.summary_computed(sess, summary_str,global_step=epoch)</span><br><span class="line">            if epoch % display_step == 0:</span><br><span class="line">                loss = sess.run(cost, feed_dict=&#123;X: train_X, Y:train_Y&#125;)</span><br><span class="line">                print (&quot;Epoch:&quot;, epoch+1, &quot;cost=&quot;, loss,&quot;W=&quot;, sess.run(W), </span><br><span class="line">               &quot;b=&quot;, sess.run(b))</span><br><span class="line">                if not (loss == &quot;NA&quot; ):</span><br><span class="line">                    plotdata[&quot;batchsize&quot;].append(epoch)</span><br><span class="line">                    plotdata[&quot;loss&quot;].append(loss)</span><br><span class="line">                </span><br><span class="line">    print (&quot; Finished!&quot;)</span><br><span class="line">    sv.saver.save(sess,&quot;log/mnist_with_summaries/&quot;+&quot;sv.cpk&quot;,global_</span><br><span class="line">   step=epoch)</span><br><span class="line"></span><br><span class="line">sv.stop()</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： （1）在设置自动保存检查点文件后，手动保存仍然有效。</p>
<p>（2）在运行一半后终止，再运行supervisor时会自动载入模型的参数，不需要手动调用saver.restore。</p>
<p>（3）在session中，不需要再运行tf.global_variables_initializer函数。原因是supervisor在建立时会调用传入的init_op进行初始化，如果加了sess.run（tf.global_ variables_initializer（）），则会导致所载入模型的变量被二次清空。</p>
<p>6．建立worker文件</p>
<p>将文件复制两份，分别起名为“4-16 worker.py”与“4-17 worker2.py”，将角色名称修改成worker，并将“4-16 worker2.py”中的task_index设为1。</p>
<p>代码4-16 worker</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">#定义角色名称</span><br><span class="line">strjob_name = &quot;worker&quot;</span><br><span class="line">task_index = 0</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>代码4-17 worker2</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">#定义角色名称</span><br><span class="line">strjob_name = &quot;worker&quot;</span><br><span class="line">task_index = 1</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 这个例子中使用了summary的一些方法将运行时态的数据保存起来，以便于使用TensorBoard进行查看（见4.1.16节）。但在分布式部署时，使用该功能还需要注意以下几点：</p>
<p>（1）不能使用sv.summary_computed，因为worker2不是chief supervisors，在worker2中是不会为supervisor对象构造默认summary_writer的（所有的summary信息都要通过该对象进行写入），所以即使调用summary_computed也无法执行下去，程序会报错。</p>
<p>（2）手写控制summary与检查点文件保存时，需要将chief supervisors以外的worker全部去掉才可以。可以使用supervisor按时间间隔保存的形式来管理，这样用一套代码就可以解决了。</p>
<p>7．部署运行</p>
<p>（1）在Spyder中先将“4-15 ps.py”文件运行起来，选择菜单Consoles|Open an IPython console命令，新打开一个Consoles，如图4-7所示。</p>
<p><img src="Image00067.jpg" alt></p>
<p>图4-7 Consoles菜单</p>
<p>（2）在Spyder面板的右下角（见图2-13中的输出栏），可以看到在原有标题为“Console 1/A”标签旁边又多了一个“Console 2/A”标签（如图4-8所示），单击该标签，使其处于激活状态。</p>
<p><img src="Image00068.jpg" alt></p>
<p>图4-8 Consoles 2/A标签</p>
<p>（3）运行4-17 worker2.py文件。最后按照“4-17worker2.py”文件启动的方式，启动4-16 worker.py”文件，这时3个窗口的显示内容分别如下：</p>
<p>·“4-16worker.py”文件对应窗口显示正常的训练信息。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Epoch: 8000 cost= 0.0754263 W= [ 2.01029539] b= [-0.00388618]</span><br><span class="line">Epoch: 8002 cost= 0.074845 W= [ 2.00651097] b= [ 0.00453186]</span><br><span class="line">Epoch: 8003 cost= 0.0748089 W= [ 2.00529122] b= [ 0.00281144]</span><br><span class="line">Epoch: 8005 cost= 0.0747555 W= [ 2.00324082] b= [ 0.00635108]</span><br><span class="line">Epoch: 8007 cost= 0.075026 W= [ 2.00662613] b= [-0.00956773]</span><br><span class="line">Epoch: 8009 cost= 0.0749311 W= [ 2.00585985] b= [-0.006533]</span><br><span class="line">Epoch: 8010 cost= 0.0748186 W= [ 2.00469637] b= [-0.00152527]</span><br><span class="line">Epoch: 8011 cost= 0.0750369 W= [ 2.0065136] b= [-0.02676161]</span><br><span class="line">Epoch: 8012 cost= 0.0758979 W= [ 2.0068512] b= [-0.02852018]</span><br><span class="line">Epoch: 8013 cost= 0.0759059 W= [ 2.00671506] b= [-0.02870713]</span><br><span class="line">Epoch: 8015 cost= 0.0753608 W= [ 2.0055182] b= [-0.01959283]</span><br><span class="line">Epoch: 8018 cost= 0.0760464 W= [ 2.00559783] b= [-0.03230772]</span><br><span class="line">Epoch: 8021 cost= 0.0758819 W= [ 2.00522184] b= [-0.02836083]</span><br><span class="line">Epoch: 8023 cost= 0.0758949 W= [ 2.00778055] b= [-0.01191433]</span><br><span class="line">Epoch: 8026 cost= 0.0752242 W= [ 2.00646138] b= [-0.01574964]</span><br><span class="line">Epoch: 8028 cost= 0.0751021 W= [ 2.00708318] b= [-0.01172168]</span><br><span class="line">Epoch: 8030 cost= 0.0749788 W= [ 2.0083425] b= [-0.00503741]</span><br><span class="line">Epoch: 8034 cost= 0.0750521 W= [ 2.00837708] b= [-0.0084667]</span><br><span class="line">Epoch: 8035 cost= 0.0750075 W= [ 2.01157689] b= [ 0.00467709]</span><br><span class="line">Epoch: 8037 cost= 0.0751661 W= [ 2.01191807] b= [ 0.0159377]</span><br><span class="line">Epoch: 8038 cost= 0.0750556 W= [ 2.01164842] b= [ 0.01059892]</span><br><span class="line">Epoch: 8040 cost= 0.0753085 W= [ 2.01313496] b= [ 0.01954099]</span><br><span class="line">Epoch: 8042 cost= 0.0753466 W= [ 2.01260543] b= [ 0.02123925]</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到循环的次数并不是连续的，跳过的步骤被分配到worker2中去运算了。</p>
<p>·“4-17worker2.py”文件对应窗口显示的信息如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:</span><br><span class="line">None, ready: Variables not initialized: weight, bias, global_step</span><br><span class="line">INFO:tensorflow:Starting queue runners.</span><br><span class="line">……</span><br><span class="line">Epoch: 8003 cost= 0.0977818 W= [ 2.00529122] b= [ 0.00281144]</span><br><span class="line">Epoch: 8005 cost= 0.0979236 W= [ 2.00324082] b= [ 0.00635108]</span><br><span class="line">Epoch: 8007 cost= 0.0978101 W= [ 2.0065136] b= [-0.01009204]</span><br><span class="line">Epoch: 8012 cost= 0.0985371 W= [ 2.00671506] b= [-0.02870713]</span><br><span class="line">Epoch: 8015 cost= 0.0981559 W= [ 2.0055182] b= [-0.01959283]</span><br><span class="line">Epoch: 8017 cost= 0.0986897 W= [ 2.00519013] b= [-0.02992464]</span><br><span class="line">Epoch: 8018 cost= 0.0987787 W= [ 2.00559783] b= [-0.03128441]</span><br><span class="line">Epoch: 8020 cost= 0.0988223 W= [ 2.00550485] b= [-0.02906012]</span><br><span class="line">Epoch: 8022 cost= 0.0985962 W= [ 2.00522184] b= [-0.02918861]</span><br><span class="line">Epoch: 8024 cost= 0.0982481 W= [ 2.00616717] b= [-0.02256276]</span><br><span class="line">Epoch: 8025 cost= 0.0977918 W= [ 2.00778055] b= [-0.01191433]</span><br><span class="line">Epoch: 8026 cost= 0.0979684 W= [ 2.00646138] b= [-0.01574964]</span><br><span class="line">Epoch: 8028 cost= 0.0978234 W= [ 2.00708318] b= [-0.01172168]</span><br><span class="line">Epoch: 8030 cost= 0.0976372 W= [ 2.00842071] b= [-0.00485691]</span><br><span class="line">Epoch: 8031 cost= 0.0976208 W= [ 2.00859952] b= [-0.00408681]</span><br><span class="line">Epoch: 8032 cost= 0.0976431 W= [ 2.0083425] b= [-0.00503741]</span><br><span class="line">Epoch: 8034 cost= 0.097557 W= [ 2.01164842] b= [ 0.01059892]</span><br><span class="line">Epoch: 8039 cost= 0.0975473 W= [ 2.01065278] b= [ 0.00720035]</span><br><span class="line">Epoch: 8040 cost= 0.0977502 W= [ 2.01313496] b= [ 0.01954099]</span><br><span class="line">Epoch: 8042 cost= 0.0978443 W= [ 2.01260543] b= [ 0.02123925]</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>显示结果中有警告输出，这是因为在构建supervisor时没有填写local_init_op参数，该参数的意思是在创建worker实例时，初始化本地变量。由于例子中没有填，系统就会自动初始化，并给出警告提示。</p>
<p>从日志中可以看到worker2 与chief supervisors的迭代序号近似互补，为什么没有绝对互补呢？可能与supervisor中的同步算法有关。</p>
<p>分布运算目的是为了提高整体运算速度，如果同步epoch的准确度需要以牺牲总体运算速度为代价，自然很不合适。所以更合理的推断是因为单机单次的运算太快迫使算法使用了更宽松的同步机制。</p>
<p>重要的一点是对于指定步数的学习参数b和w是一致的（如第8040步，学习参数是相同的，都为W= [ 2.01313496] b= [ 0.01954099]），这表明两个终端是在相同的起点上进行运算的。</p>
<p>·对于4-15ps.py文件，其对应窗口则是一直静默着只显示打印的那句wait，因为它只负责连接不参与运算。</p>
<h3 id="4-6-动态图（Eager）"><a href="#4-6-动态图（Eager）" class="headerlink" title="4.6 动态图（Eager）"></a>4.6 动态图（Eager）</h3><p>动态图是相对于静态图而言的。所谓的动态图是指在Python中代码被调用后，其操作立即被执行的计算。其与静态图最大的区别是不需要使用session来建立会话了。即，在静态图中，需要在会话中调用run方法才可以获得某个张量的具体值；而在动态图中，直接运行就可以或得到具体值了。</p>
<p>动态图是在TensorFlow 1.3版本之后出现的。它使TensorFlow 的入门变得更简单，也使研发更直观。</p>
<p>启用动态图只需要在程序的最开始处加上两行代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow.contrib.eager as tfe</span><br><span class="line">tfe.enable_eager_execution()</span><br></pre></td></tr></table></figure>

</details>

<p>这两行代码的作用就是开启动态图计算功能。例如，调用tf.matmul时，将会立即计算两个数相乘的值，而不是一个op。</p>
<p>Eager还处于一个试用阶段，也是TensorFlow大力推广的新特性，未来或许会成为趋势。想了解更多内容，可以参考如下网址：</p>
<p><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager。</a>  </p>
<p>在创建动态图的过程中，默认也建立了一个session。所有的代码都在该session中进行，而且该session具有进程相同的生命周期。这表明一旦使用动态图就无法实现静态图中关闭session的功能。这便是动态图的不足之处：无法实现多session操作。如果当前代码只需要一个session来完成的话，建议优先选择动态图Eager来实现。</p>
<h3 id="4-7-数据集（tf-data）"><a href="#4-7-数据集（tf-data）" class="headerlink" title="4.7 数据集（tf.data）"></a>4.7 数据集（tf.data）</h3><p>TensorFlow中有3种数据输入模式：</p>
<p>·直接使用feed_dict利用注入模式进行数据输入（见4.1.4节），适用于少量的数据集输入；</p>
<p>·使用队列式管道（见11.5.3节），适用于大量的数据集输入；</p>
<p>·性能更高的输入管道，适用于TensorFlow 1.4之后的版本，是为动态图（见4.6节）功能提供的大数据集输入方案（动态图的数据集输入只能使用该方法），当然也支持静态图。</p>
<p>关于第3种方式的更多介绍，请参考以下链接：</p>
<p><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md#input-pipelines" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md#input-pipelines</a>  </p>
<h2 id="第5章-识别图中模糊的手写数字（实例21）"><a href="#第5章-识别图中模糊的手写数字（实例21）" class="headerlink" title="第5章 识别图中模糊的手写数字（实例21）"></a>第5章 识别图中模糊的手写数字（实例21）</h2><p>本章中将训练一个能够识别图片中手写数字的机器学习模型。这个模型很简单，仅使用了一个神经元——Softmax Regression。</p>
<p>学完本章，读者一方面可以巩固第4章所学的TensorFlow编程基础知识，另一方面对神经网络也有了一个大体的了解，还掌握了最简单的图像识别方法。</p>
<p>本章含有教学视频共13分14秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，详细讲解了一个识别模糊手写数字图片的完整例子（重点是能够理解例子中的全部代码）。</p>
<p><img src="Image00069.jpg" alt></p>
<p>本章实例中所用的图片来源于一个开源的训练数据集——MNIST。</p>
<p>实例描述</p>
<p>从MNIST数据集中选择一幅图，这幅图上有一个手写的数字，让机器模拟人眼来区分这个手写数字到底是几。</p>
<p>首先来介绍一下编写代码的相关步骤。</p>
<p>（1）导入NMIST数据集。</p>
<p>（2）分析MNIST样本特点定义变量。</p>
<p>（3）构建模型。</p>
<p>（4）训练模型并输出中间状态参数。</p>
<p>（5）测试模型。</p>
<p>（6）保存模型。</p>
<p>（7）读取模型。</p>
<p>下面我们就来一一操作。</p>
<h3 id="5-1-导入图片数据集"><a href="#5-1-导入图片数据集" class="headerlink" title="5.1 导入图片数据集"></a>5.1 导入图片数据集</h3><p>首先来看看数据集是什么样的。</p>
<p>MNIST是一个入门级的计算机视觉数据集。当我们开始学习编程时，第一件事往往是学习打印Hello World。在机器学习入门的领域里，我们会用MNIST数据集来实验各种模型。</p>
<h4 id="5-1-1-MNIST数据集介绍"><a href="#5-1-1-MNIST数据集介绍" class="headerlink" title="5.1.1 MNIST数据集介绍"></a>5.1.1 MNIST数据集介绍</h4><p>MNIST里包含各种手写数字图片，如图5-1所示。</p>
<p><img src="Image00070.jpg" alt></p>
<p>图5-1 MNIST中的数字</p>
<p>它也包含每一张图片对应的标签，告诉我们这个是数字几。例如，上面这4张图片的标签分别是5、0、4、1。</p>
<p>MNIST数据集的官网是<a href="http://yann.lecun.com/exdb/%20mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/ mnist/</a> ，读者可以在这里面手动下载数据集，如图5-2所示。</p>
<p><img src="Image00071.jpg" alt></p>
<p>图5-2 MNIST数据集下载</p>
<h4 id="5-1-2-下载并安装MNIST数据集"><a href="#5-1-2-下载并安装MNIST数据集" class="headerlink" title="5.1.2 下载并安装MNIST数据集"></a>5.1.2 下载并安装MNIST数据集</h4><p>介绍完MNIST数据集后，下面来演示一下如何通过代码来对其操作。</p>
<p>1．利用TensorFlow代码下载MNIST</p>
<p>TensorFlow提供了一个库，可以直接用来自动下载与安装MNIST，见如下代码：</p>
<p>代码5-1 MNIST数据集</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，会自动下载数据集并将文件解压到当前代码所在同级目录下的MNIST_data文件夹下。</p>
<p><img src="Image00014.jpg" alt> 注意： 代码中的one_hot=True，表示将样本标签转化为one_hot编码。</p>
<p>举例来解释one_hot编码：假如一共10类。0的one_hot为1000000000，1的one_hot为0100000000，2的one_hot为0010000000，3的one_hot为0001000000……依此类推。只有一个位为1，1所在的位置就代表着第几类。</p>
<p>MNIST数据集中的图片是28×28 Pixel，所以，每一幅图就是1行784（28×28）列的数据，括号中的每一个值代表一个像素。</p>
<p>·如果是黑白的图片，图片中黑色的地方数值为0；有图案的地方，数值为0～255之间的数字，代表其颜色的深度。</p>
<p>·如果是彩色的图片，一个像素会由3个值来表示RGB（红、黄、蓝）。在后面讲解其他数据集时会具体讲到。</p>
<p>接下来通过几行代码将MNIST里面的信息打印出来，看看它的具体内容。</p>
<p>代码5-1 MNIST数据集（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print (&apos;输入数据:&apos;,mnist.train.images)</span><br><span class="line">print (&apos;输入数据打shape:&apos;,mnist.train.images.shape)</span><br><span class="line">import pylab</span><br><span class="line">im = mnist.train.images[1]</span><br><span class="line">im = im.reshape(-1,28)</span><br><span class="line">pylab.imshow(im)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，输出信息如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Extracting MNIST_data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">输入数据: [[ 0.  0.  0. ...,  0.  0.  0.]</span><br><span class="line">￼ [ 0.  0.  0. ...,  0.  0.  0.]</span><br><span class="line"> [ 0.  0.  0. ...,  0.  0.  0.]</span><br><span class="line"> ……</span><br><span class="line"> [ 0.  0.  0. ...,  0.  0.  0.]</span><br><span class="line"> [ 0.  0.  0. ...,  0.  0.  0.]</span><br><span class="line"> [ 0.  0.  0. ...,  0.  0.  0.]]</span><br><span class="line">输入数据打shape: (55000, 784)</span><br></pre></td></tr></table></figure>

</details>

<p>输出结果如图5-3所示</p>
<p><img src="Image00072.jpg" alt></p>
<p>图5-3 输出结果</p>
<p>刚开始的打印信息是解压数据集的意思。如果是第一次运行，还会显示下载数据的相关信息。</p>
<p>接着打印出来的是训练集的图片信息，是一个55000行、784列的矩阵。即，训练集里有55000张图片。</p>
<p>2．MNIST数据集组成</p>
<p>在MNIST训练数据集中，mnist.train.images是一个形状为[55000，784]的张量。其中，第1个维度数字用来索引图片，第2个维度数字用来索引每张图片中的像素点。此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0～255之间。</p>
<p>MNIST里包含3个数据集：第一个是训练数据集，另外两个分别是测试数据集（mnist.test）和验证数据集（mnist.validation）。可使用如下命令查看里面的数据信息：</p>
<p>代码5-1 MNIST数据集（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print (&apos;输入数据打shape:&apos;,mnist.test.images.shape)</span><br><span class="line">print (&apos;输入数据打shape:&apos;,mnist.validation.images.shape)</span><br></pre></td></tr></table></figure>

</details>

<p>运行完上面的命令，可以发现在测试数据集里有10000条样本图片，验证数据集里有5000个图片。</p>
<p>在实际的机器学习模型设计时，样本一般分为3部分：</p>
<p>·一部分用于训练；</p>
<p>·一部分用于评估训练过程中的准确度（测试数据集）；</p>
<p>·一部分用于评估最终模型的准确度（验证数据集）。</p>
<p>训练过程中，模型并没有遇到过验证数据集中的数据，所以利用验证数据集可以评估出模型的准确度。这个准确度越高，代表模型的泛化能力越强。</p>
<p>另外，这3个数据集还有分别对应的3个文件（标签文件），用来标注每个图片上的数字是几。把图片和标签放在一起，称为“样本”。通过样本来就可以实现一个有监督信号的深度学习模型。</p>
<p>相对应的，MNIST数据集的标签是介于0～9之间的数字，用来描述给定图片里表示的数字。标签数据是“one-hot vectors”：一个one-hot向量，除了某一位的数字是1外，其余各维度数字都是0。例如，标签0将表示为（[1，0，0，0，0，0，0，0，0，0，0]）。因此，mnist.train.labels是一个[55000，10]的数字矩阵。</p>
<h3 id="5-2-分析图片的特点，定义变量"><a href="#5-2-分析图片的特点，定义变量" class="headerlink" title="5.2 分析图片的特点，定义变量"></a>5.2 分析图片的特点，定义变量</h3><p>由于输入图片是个550000×784的矩阵，所以先创建一个[None，784]的占位符x和一个[None，10]的占位符y，然后使用feed机制将图片和标签输入进去。具体代码如下。</p>
<p>代码5-2 MNIST分类</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf  # 导入tensorflow库</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</span><br><span class="line">import pylab</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"># 定义占位符</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # MNIST数据集的维度是</span><br><span class="line"> 28×28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10])  # 数字0～9 ，共10个类别</span><br></pre></td></tr></table></figure>

</details>

<p>代码中第8行的None，表示此张量的第一个维度可以是任何长度的。x就代表能够输入任意数量的MNIST图像，每一张图展平成784维的向量。</p>
<h3 id="5-3-构建模型"><a href="#5-3-构建模型" class="headerlink" title="5.3 构建模型"></a>5.3 构建模型</h3><p>样本完成后就可以构建模型了。下面列出了构建模型的相关步骤。</p>
<h4 id="5-3-1-定义学习参数"><a href="#5-3-1-定义学习参数" class="headerlink" title="5.3.1 定义学习参数"></a>5.3.1 定义学习参数</h4><p>模型也需要权重值和偏置量，它们被统一叫做学习参数。在TensorFlow里，使用Variable来定义学习参数。</p>
<p>一个Variable代表一个可修改的张量，定义在TensorFlow的图（一个执行任务）中，其本身也是一种变量。使用Variable定义的学习参数可以用于计算输入值，也可以在计算中被修改。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W = tf.Variable(tf.random_normal(([784,10]))</span><br><span class="line">b = tf.Variable(tf.zeros([10]))</span><br></pre></td></tr></table></figure>

</details>

<p>在这里赋予tf.Variable不同的初值来创建不同的参数。一般将W设为一个随机值，将b设为0。</p>
<p><img src="Image00014.jpg" alt> 注意： W的维度是[784，10]，因为想要用784维的图片向量乘以它，以得到一个10维的证据值向量，每一位对应不同数字类。b的形状是[10]，所以可以直接把它加到输出上面。</p>
<h4 id="5-3-2-定义输出节点"><a href="#5-3-2-定义输出节点" class="headerlink" title="5.3.2 定义输出节点"></a>5.3.2 定义输出节点</h4><p>有了输入和模型参数，接着便可以将它们串起来构建成真正的模型。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax分类</span><br></pre></td></tr></table></figure>

</details>

<p>首先，用tf.matmul（x，W）表示x乘以W，这里x是一个二维张量，拥有多个输入。然后再加上b，把它们的和输入到tf.nn.softmax函数里。</p>
<p>至此就构建好了正向传播的结构。也就是表明，只要模型中的参数合适，通过具体的数据输入，就能得到我们想要的分类。</p>
<h4 id="5-3-3-定义反向传播的结构"><a href="#5-3-3-定义反向传播的结构" class="headerlink" title="5.3.3 定义反向传播的结构"></a>5.3.3 定义反向传播的结构</h4><p>下面定义一个反向传播的结构，编译训练模型，以得到合适的参数。</p>
<p>这里涉及一个“学习率”的概念。学习率，是指每次改变学习参数的大小。在这里读者只要先有个概念即可，后面章节还会详细介绍。</p>
<p>先看下面代码。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 损失函数</span><br><span class="line">cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))</span><br><span class="line"></span><br><span class="line"># 定义参数</span><br><span class="line">learning_rate = 0.01</span><br><span class="line"># 使用梯度下降优化器</span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码可以这样来理解：</p>
<p>（1）将生成的pred与样本标签y进行一次交叉熵的运算，然后取平均值。</p>
<p>（2）将这个结果作为一次正向传播的误差，通过梯度下降的优化方法找到能够使这个误差最小化的b和W的偏移量。</p>
<p>（3）更新b和W，使其调整为合适的参数。</p>
<p>整个过程就是不断地让损失值（误差值cost）变小。因为损失值越小，才能表明输出的结果跟标签数据越相近。当cost小到我们的需求时，这时的b和W就是训练出来的合适值。</p>
<h3 id="5-4-训练模型并输出中间状态参数"><a href="#5-4-训练模型并输出中间状态参数" class="headerlink" title="5.4 训练模型并输出中间状态参数"></a>5.4 训练模型并输出中间状态参数</h3><p>现在开始真正地训练模型了，先定义训练相关的参数。</p>
<p>下面代码中，第20行中，training_epochs代表要把整个训练样本集迭代25次；第21行中，batch_size代表在训练过程中一次取100条数据进行训练；第22行中，display_step代表每训练一次就把具体的中间状态显示出来。</p>
<p><img src="Image00014.jpg" alt> 注意： batch_size参数代表的意义很关键，在深度学习中，都是将数据按批次地向里面放的。在后面章节中还会详细介绍这么做的目的。</p>
<p>参数定义好后，启动一个session就可以开始训练过程了。session中有两个run，第一个run是运行初始化，第二个run是运行具体的运算模型。模型运算之后便将里面的状态打印出来。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">training_epochs = 25</span><br><span class="line">batch_size = 100</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())# Initializing OP</span><br><span class="line"></span><br><span class="line">    # 启动循环开始训练</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        # 循环所有数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # 运行优化器</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs,</span><br><span class="line">                                                          y: batch_ys&#125;)</span><br><span class="line">            # 计算平均loss值</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if (epoch+1) % display_step == 0:</span><br><span class="line">            print (&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1), &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.</span><br><span class="line">           format(avg_cost))</span><br><span class="line"></span><br><span class="line">    print( &quot; Finished!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，会输出如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 9.923389743</span><br><span class="line">Epoch: 0002 cost= 4.695022035</span><br><span class="line">Epoch: 0003 cost= 3.076164273</span><br><span class="line">Epoch: 0004 cost= 2.417567778</span><br><span class="line">Epoch: 0005 cost= 2.052902991</span><br><span class="line">Epoch: 0006 cost= 1.816404106</span><br><span class="line">Epoch: 0007 cost= 1.649224558</span><br><span class="line">Epoch: 0008 cost= 1.523894480</span><br><span class="line">Epoch: 0009 cost= 1.425924496</span><br><span class="line">Epoch: 0010 cost= 1.346838083</span><br><span class="line">Epoch: 0011 cost= 1.281203090</span><br><span class="line">Epoch: 0012 cost= 1.225851107</span><br><span class="line">Epoch: 0013 cost= 1.178292338</span><br><span class="line">Epoch: 0014 cost= 1.136689923</span><br><span class="line">Epoch: 0015 cost= 1.100095906</span><br><span class="line">Epoch: 0016 cost= 1.067396342</span><br><span class="line">Epoch: 0017 cost= 1.038121746</span><br><span class="line">Epoch: 0018 cost= 1.011435861</span><br><span class="line">Epoch: 0019 cost= 0.987299248</span><br><span class="line">Epoch: 0020 cost= 0.965228878</span><br><span class="line">Epoch: 0021 cost= 0.944723253</span><br><span class="line">Epoch: 0022 cost= 0.925947570</span><br><span class="line">Epoch: 0023 cost= 0.908483106</span><br><span class="line">Epoch: 0024 cost= 0.892120825</span><br><span class="line">Epoch: 0025 cost= 0.877055534</span><br><span class="line">Finished!</span><br></pre></td></tr></table></figure>

</details>

<p>这里输出的中间状态是cost损失值。读者也可以把自己关心的内容打印出来。可以看到，从第1次迭代到第25次迭代的损失值在逐渐减小，最终的误差只有0.8。</p>
<h3 id="5-5-测试模型"><a href="#5-5-测试模型" class="headerlink" title="5.5 测试模型"></a>5.5 测试模型</h3><p>还记得MNIST里面有测试数据吗？现在我们使用测试数据来测试一下训练完的模型吧。</p>
<p>与前面的过程类似，也是先将计算测试的网络结构建立起来，然后通过最终节点的eval将测试值运算出来。</p>
<p><img src="Image00014.jpg" alt> 注意： 这个过程仍然是在session里进行的。</p>
<p>测试错误率的算法是：直接判断预测的结果与真实的标签是否相同，如是相同的就表明是正确的，如是不相同的就表示是错误的。然后将正确的个数除以总个数，得到的值即为正确率。由于是onehot编码，这里使用了tf.argmax函数返回onehot编码中数值为1的那个元素的下标。下面是具体代码。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 测试 model</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line">    # 计算准确率</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    print (&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, y: mnist.</span><br><span class="line">   test.labels&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码执行后，显示信息如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0.8316</span><br></pre></td></tr></table></figure>

</details>

<p>测试正确率的算法与损失值的算法略有差别，但代表的意义却很类似。当然，也可以直接拿计算损失值的交叉熵结果来代表模型测试的错误率。</p>
<p><img src="Image00014.jpg" alt> 注意：<br>（1）并不是所有模型的测试错误率和训练时的最后一次损失值都很接近，这取决于训练样本和测试样本的分布情况，也取决于模型本身的拟合质量。关于拟合质量问题，将在后面章节详细介绍。</p>
<p>（2）读者自己运行时，得到的值可能和本书中的值不一样。甚至每次运行时，得到的值也不一样。原因是每次初始的权重w都是随机的。由于初始权重不同，而且每次训练的批次数据也不同，所以最终生成的模型也不会完全相同。但如果核心算法保持一致，则会保证最终的结果不会有太大的偏差。</p>
<h3 id="5-6-保存模型"><a href="#5-6-保存模型" class="headerlink" title="5.6 保存模型"></a>5.6 保存模型</h3><p>下面开始讲解如何保存模型。</p>
<p>首先要建立一个saver和一个路径，然后通过调用save，自动将session中的参数保存起来，见如下代码。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 保存模型</span><br><span class="line">save_path = saver.save(sess, model_path)</span><br><span class="line">print(&quot;Model saved in file: %s&quot; % save_path)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码的作用是保存模型，并将模型保存的路径打印出来。当然，在这段代码运行之前，需要添加saver和model_path的定义。来到前面代码段的第30行（也就是session创建之前）添加如下代码：</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line">model_path = &quot;log/521model.ckpt&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>执行上述的全部代码后，会在代码文件的同级目录下找到log文件夹，其中有4个文件，如图5-4所示。</p>
<p><img src="Image00073.jpg" alt></p>
<p>图5-4 模型文件位置</p>
<h3 id="5-7-读取模型"><a href="#5-7-读取模型" class="headerlink" title="5.7 读取模型"></a>5.7 读取模型</h3><p>将模型存储好后，下面来做一个实验：读取模型并将两张图片放进去让模型预测结果，然后将两张图片极其对应的标签一并显示出来。</p>
<p>在整个代码执行过程中，对于网络模型的定义不变，只是重新建立一个session而已，所有的操作都在这个新的session中完成。具体细节见代码。</p>
<p>代码5-2 MNIST分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;Starting 2nd session...&quot;)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    # 初始化变量</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    # 恢复模型变量</span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    </span><br><span class="line">     # 测试 model</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line">    # 计算准确率</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    print (&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, y: mnist.</span><br><span class="line">     test.labels&#125;))</span><br><span class="line">    </span><br><span class="line">    output = tf.argmax(pred, 1)</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(2)</span><br><span class="line">    outputval,predv = sess.run([output,pred], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">    print(outputval,predv,batch_ys)</span><br><span class="line"></span><br><span class="line">    im = batch_xs[0]</span><br><span class="line">    im = im.reshape(-1,28)</span><br><span class="line">    pylab.imshow(im)</span><br><span class="line">    pylab.show()</span><br><span class="line">    </span><br><span class="line">    im = batch_xs[1]</span><br><span class="line">    im = im.reshape(-1,28)</span><br><span class="line">    pylab.imshow(im)</span><br><span class="line">    pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>以上代码可以替代原来的session（从第30行到最后），也可以直接放到代码后面，将前面的session注释掉。</p>
<p>运行后可以看到如下信息，结果如图5-5所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0. 8316</span><br><span class="line">[5 3]</span><br><span class="line">[[  3.26058798e-05   3.89398069e-09   2.60637262e-06   2.67529134e-02</span><br><span class="line">    6.77738354e-09   9.70463872e-01   1.54175677e-08   6.38231169e-04</span><br><span class="line">    1.79426873e-03   3.15453537e-04]</span><br><span class="line"> [  3.65457054e-10   9.57760785e-04   5.34406379e-02   8.83626580e-01</span><br><span class="line">    5.11178478e-05   1.06539410e-05   7.34308742e-06   1.40240220e-02</span><br><span class="line">    1.56633689e-07   4.78818417e-02]] </span><br><span class="line">[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]</span><br><span class="line"> [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00074.jpg" alt></p>
<p>图5-5 运行结果</p>
<p>第一行是模型的准确率，接下来是3个数组。</p>
<p>·第一个数组是输出的预测结果。</p>
<p>·第二个大的数组比较大，是预测出来的真实输出值。</p>
<p>·第三个大的数组元素都是0和1，是标签值onehot编码表示的5和3。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里是恰巧举了一个全部正确的例子，因为还有0.17的错误率，所以有时也会有预测错误的情况。</p>
<p>到此我们已经通过两个模型的例子，大体了解了神经网络的作用。那么为什么神经网络会产生这样的效果呢？具体的原理将在后面的章节中一一介绍。</p>
<h1 id="第2篇-深度学习基础——神经网络"><a href="#第2篇-深度学习基础——神经网络" class="headerlink" title="第2篇 深度学习基础——神经网络"></a>第2篇 深度学习基础——神经网络</h1><p>本篇将从神经网络中的最基础单元——单个神经元开始，由浅入深地分别介绍各种类型的神经网络，包括多层神经网络、卷积神经网络、循环神经网络和自编码网络。</p>
<p>第6章 单个神经元</p>
<p>第7章 多层神经网络——解决非线性问题</p>
<p>第8章 卷积神经网络——解决参数太多问题</p>
<p>第9章 循环神经网络——具有记忆功能的网络</p>
<p>第10章 自编码网络——能够自学习样本特征的网络</p>
<h2 id="第6章-单个神经元"><a href="#第6章-单个神经元" class="headerlink" title="第6章 单个神经元"></a>第6章 单个神经元</h2><p>前面的章节中介绍了TensorFlow框架的基本使用方法。从本章开始，我们将真正进入深度学习理论知识系统。神经网络是由多个神经元组成，所以本章先从一个神经元开始讲起。一个神经元由以下几个关键知识点组成：</p>
<p>·激活函数；</p>
<p>·损失函数；</p>
<p>·梯度下降。</p>
<p>本章含有教学视频共14分56秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，特别是对单个神经元的各个组成部分，以及每个部分的具体实现方法进行了重点讲解（掌握二分类、多分类及非互斥的多分类的实现方法为本章的重点）。</p>
<p><img src="Image00075.jpg" alt></p>
<p>在详细介绍之前，有必要先讲讲神经元的拟合原理。</p>
<h3 id="6-1-神经元的拟合原理"><a href="#6-1-神经元的拟合原理" class="headerlink" title="6.1 神经元的拟合原理"></a>6.1 神经元的拟合原理</h3><p>在第5章的代码“5-2 MNIST分类.py”文件中，建立的模型是一个单个神经元组成的网络模型。单个神经元的网络模型如图6-1所示。</p>
<p><img src="Image00076.jpg" alt></p>
<p>图6-1 单个神经元网络模型</p>
<p>其计算公式如式（6-1）所示。</p>
<p><img src="Image00077.jpg" alt></p>
<p>式（6-1）中：z为输出的结果；x为输入；w为权重；b为偏执值。w和b可以理解为两个变量。</p>
<p>模型每次的学习都是为了调整w和b从而得到一个合适的值，最终由这个值配合运算公式所形成的逻辑就是神经网络的模型。</p>
<p>其实这个模型是根据仿生学得来的。我们看一下大脑细胞里的神经突出如图6-2所示。</p>
<p><img src="Image00078.jpg" alt></p>
<p>图6-2 神经细胞</p>
<p>是不是与我们建立的模型有点神似？</p>
<p>（1）大脑神经细胞是靠生物电来传递信号的，可以理解成经过模型里的具体数值。</p>
<p>（2）仔细观察发现神经细胞相连的连接树突有粗有细，显然通过不同粗细连接的生物电信号，也会有不同的影响。这就好比权重w，因为每个输入节点都会与相关连接的w相乘，也就实现了对信号的放大、缩小处理。</p>
<p>（3）这里唯独不透明的就是中间的细胞体，于是我们将所有输入的信号经过w变换之后，再添加一个额外的偏执量b，把它们加在一起求合，然后再选择一个模拟细胞体处理的函数来实现整个过程的仿真。这个函数称其为激活函数。</p>
<p>我们把w和b赋予合适的值时，再配合合适的激活函数，就会发现它可以产生很好的拟合效果。</p>
<h4 id="6-1-1-正向传播"><a href="#6-1-1-正向传播" class="headerlink" title="6.1.1 正向传播"></a>6.1.1 正向传播</h4><p>前文描述的过程过程叫做正向传播，数据是从输入到输出的流向传递过来的。当然，它是在一个假设有合适的w和b的基础上，才可以实现对现实环境的正确拟合。但是，在实际过程中我们无法得知w和b的值具体是多少才算是正常的。</p>
<p>于是我们加入了一个训练过程，通过反向误差传递的方法让模型自动来修正，最终产生一个合适的权重。</p>
<h4 id="6-1-2-反向传播"><a href="#6-1-2-反向传播" class="headerlink" title="6.1.2 反向传播"></a>6.1.2 反向传播</h4><p>反向传播的意义很明确——告诉模型我们需要将w和b调整到多少。在刚开始没有得到合适的权重时，正向传播生成的结果与实际的标签是有误差的，反向传播就是要把这个误差传递给权重，让权重做适当地调整来达到一个合适的输出。</p>
<p>在实际训练过程中，很难一次将其调整到位，而是通过多次迭代一点一点的将其修正，最终直到模型的输出值与实际标签值的误差小于某个阀值为止。</p>
<p>如何将输出的误差转化为权重的误差，这里面使用的就是BP算法。</p>
<p>1．BP算法介绍</p>
<p>本书不阐述过多的算法，只讲原理，读者理解道理即可。</p>
<p>BP算法又称“误差反向传播算法”。我们最终的目的，是要让正向传播的输出结果与标签间的误差最小化，这就是反向传播的核心思想。</p>
<p>正向传播的模型是清晰的，所以很容易得出一个关于由b和w组成的对于输出的表达式。接着，也可以得出一个描述损失值的表达式（将输出值与标签直接相减，或是做平方差等运算）。</p>
<p>为了要让这个损失值变得最小化，我们运用数学知识，选择一个损失值的表达式让这个表达式有最小值，接着通过对其求导的方式，找到最小值时刻的函数切线斜率（也就是梯度），从而让w和b的值沿着这个梯度来调整。</p>
<p>至于每次调整多少，我们引入一个叫做“学习率”的参数来控制，这样通过不断的迭代，使误差逐步接近最小值，最终达到我们的目标。</p>
<h3 id="6-2-激活函数——加入非线性因素，解决线性模型缺陷"><a href="#6-2-激活函数——加入非线性因素，解决线性模型缺陷" class="headerlink" title="6.2 激活函数——加入非线性因素，解决线性模型缺陷"></a>6.2 激活函数——加入非线性因素，解决线性模型缺陷</h3><p>激活函数的主要作用就是用来加入非线性因素的，以解决线性模型表达能力不足的缺陷，在整个神经网络里起到至关重要的作用。</p>
<p>因为神经网络的数学基础是处处可微的，所以选取的激活函数要能保证数据输入与输出也是可微的。</p>
<p>在神经网络里常用的激活函数有Sigmoid、Tanh和relu等，下面逐一介绍。</p>
<h4 id="6-2-1-Sigmoid函数"><a href="#6-2-1-Sigmoid函数" class="headerlink" title="6.2.1 Sigmoid函数"></a>6.2.1 Sigmoid函数</h4><p>Sigmoid是常见的激活函数，一起看看它的样子。</p>
<p>1．函数介绍</p>
<p>Sigmoid是常用的非线性的激活函数，其数学形式见式（6-2）。</p>
<p><img src="Image00079.jpg" alt></p>
<p>Sigmoid函数曲线如图6-3所示，其中，x可以是正无穷到负无穷，但是对应的y却只有0～1的范围，所以，经过Sigmoid函数输出的函数都会落在0～1的区间里，即Sigmoid函数能够把输入的值“压缩”到0～1之间。</p>
<p><img src="Image00080.jpg" alt></p>
<p>图6-3 Sigmoid函数曲线</p>
<p>2. 在TensorFlow中对应的函数</p>
<p>在TensorFlow中对应的函数为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.sigmoid(x, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>从图像上看，随着x趋近正负无穷大，y对应的值越来越接近1或-1，这种情况叫做饱和。处于饱和态的激活函数意味着，当x =100和x =1000时的反映都是一样的，这样的特性转换相当于将1000大于100十倍这个信息给丢失了。</p>
<p>所以，为了能有效使用Sigmoid函数，从图6-3中看其极限也只能是-6～6之间，而在-3～3之间应该会有比较好的效果。</p>
<h4 id="6-2-2-Tanh函数"><a href="#6-2-2-Tanh函数" class="headerlink" title="6.2.2 Tanh函数"></a>6.2.2 Tanh函数</h4><p>Tanh函数可以说是Sigmoid函数的值域升级版，由Sigmoid函数的0～1之间升级到-1～1。但是Tanh函数也不能完全替代Sigmoid函数，在某些输出需要大于0的情况下，还是要用Sigmoid函数。</p>
<p>1．函数介绍</p>
<p>Tanh函数也是常用的非线性激活函数，其数学形式见式（6-3）。</p>
<p><img src="Image00081.jpg" alt></p>
<p>Tanh函数曲线如图6-4所示，其x取值也是从正无穷到负无穷，对应的y值变为-1～1之间，相对于Sigmoid函数有更广的值域。</p>
<p><img src="Image00082.jpg" alt></p>
<p>图6-4 Tanh函数曲线</p>
<p>2．在TensorFlow中对应的函数</p>
<p>在TensorFlow中对应的函数</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.tanh(x, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>显而易见，Tanh函数跟Sigmoid函数有一样的缺陷，也是饱和问题，所以在使用Tanh函数时，要注意输入值的绝对值不能过大，否则模型无法训练。</p>
<h4 id="6-2-3-ReLU函数"><a href="#6-2-3-ReLU函数" class="headerlink" title="6.2.3 ReLU函数"></a>6.2.3 ReLU函数</h4><p>1. 函数介绍</p>
<p>除了前面介绍的Sigmoid函数和Tanh函数之外，还有一个更为常用的激活函数（也称为Rectifier）。其数学形式见式（6-4）。</p>
<p><img src="Image00083.jpg" alt></p>
<p>该式非常简单，大于0的留下，否则一律为0，具体的图像如图6-5所示。ReLU函数应用的广泛性与它的优势是分不开的，这种对正向信号的重视，忽略了负向信号的特性，与我们人类神经元细胞对信号的反映极其相似。所以在神经网络中取得了很好的拟合效果。</p>
<p>另外由于ReLU函数运算简单，大大地提升了机器的运行效率，也是Relu函数一个很大的优点。</p>
<p><img src="Image00084.jpg" alt></p>
<p>图6-5 ReLU函数和SoftPlus函数曲线</p>
<p>与ReLU函数类似的还有Softplus函数，如图6-5所示。二者的区别在于：Softplus函数会更加平滑，但是计算量很大，而且对于小于0的值保留的相对更多一点。Softplus函数公式见式（6-5）。</p>
<p><img src="Image00085.jpg" alt></p>
<p>虽然ReLU函数在信号响应上有很多优势，但这仅仅在正向传播方面。由于其对负值的全部舍去，因此很容易使模型输出全零从而无法再进行训练。例如，随机初始化的w加入值中有个值是负值，其对应的正值输入值特征也就被全部屏蔽了，同理，对应负值输入值反而被激活了。这显然不是我们想要的结果。于是在基于ReLU的基础上又演化出了一些变种函数，举例如下：</p>
<p>·Noisy relus：为max中的x加了一个高斯分布的噪声，见式（6-6）。</p>
<p><img src="Image00086.jpg" alt></p>
<p>·Leaky relus：在ReLU基础上，保留一部分负值，让x为负时乘0.01，即Leaky relus对负信号不是一味地拒绝，而是缩小。其数学形式见式（6-7）。</p>
<p><img src="Image00087.jpg" alt></p>
<p>·再进一步让这个0.01作为参数可调，于是，当x小于0时，乘以a，a小于等于1。其数学形式见式（6-8）。</p>
<p><img src="Image00088.jpg" alt></p>
<p>得到Leaky relus的公式max（x，ax）</p>
<p>·Elus：当x小于0时，做了更复杂的变换，见式（6-9）。</p>
<p><img src="Image00089.jpg" alt></p>
<p>Elus函数激活函数与ReLU函数一样都是不带参数的，而且收敛速度比ReLU函数更快，使用Elus函数时，不使用批处理比使用批处理能够获得更好的效果，同时Elus函数不使用批处理的效果比ReLU函数加批处理的效果要好。</p>
<p>2．在TensorFlow中对应的函数</p>
<p>在TensorFlow中，关于ReLU函数的实现，有以下两个对应的函数：</p>
<p>·tf.nn.relu（features，name=None） ：是一般的ReLU函数，即max（features，0）；</p>
<p>·tf.nn.relu6（features，name=None）：是以6为阈值的ReLU函数，即min（max（features，0），6）。</p>
<p><img src="Image00014.jpg" alt> 注意： relu6存在的原因是防止梯度爆炸，当节点和层数特别多而且输出都为正时，它们的加和会是一个很大的值，尤其在经历几层变换之后，最终的值可能会离目标值相差太远。误差太大，会导致对参数调整修正值过大，这会导致网络抖动得较厉害，最终很难收敛。</p>
<p>在TensorFlow中，Softplus函数对应的函数如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.softplus(features, name=None);</span><br></pre></td></tr></table></figure>

</details>

<p>在TensorFlow中，Elus函数对应的函数如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.elu(features, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>在TensorFlow中，Leaky relus公式没有专门的函数，不过可以利用现有函数组成而得到：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.maximum(x, leak*x, name = name) #leak 为传入的参数，可以设为0.01 等</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-4-Swish函数"><a href="#6-2-4-Swish函数" class="headerlink" title="6.2.4 Swish函数"></a>6.2.4 Swish函数</h4><p>Swish函数是谷歌公司发现的一个效果更优于Relu的激活函数。经过测试，在保持所有的模型参数不变的情况下，只是把原来模型中的 ReLU 激活函数修改为 Swish 激活函数，模型的准确率均有提升。其公式见式6-10</p>
<p><img src="Image00090.jpg" alt></p>
<p>其中β为x的缩放参数，一般情况取默认值1即可。在使用了BN算法（见8.9.3节）的情况下，还需要对x的缩放值β进行调节。</p>
<p>在TensorFlow的低版本中，没有单独的Swish函数，可以手动封装，代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def Swish(x，beta=1):</span><br><span class="line">return x * tf.nn.sigmoid(x*beta)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-5-激活函数总结"><a href="#6-2-5-激活函数总结" class="headerlink" title="6.2.5 激活函数总结"></a>6.2.5 激活函数总结</h4><p>神经网络中，运算特征是不断进行循环计算，所以在每代循环过程中，每个神经元的值也是在不断变化的。这就导致了Tanh函数在特征相差明显时的效果会很好，在循环过程中其会不断扩大特征效果并显示出来。</p>
<p>但有时当计算的特征间的相差虽比较复杂却没有明显区别，或是特证间的相差不是特别大时，就需要更细微的分类判断，这时Sigmoid函数的效果就会更好一些。</p>
<p>后来出现的ReLU激活函数的优势是，经过其处理后的数据有更好的稀疏性。即，将数据转化为只有最大数值，其他都为0。这种变换可以近似程度地最大保留数据特征，用大多数元素为0的稀疏矩阵来实现。</p>
<p>实际上，神经网络在不断反复计算中，就变成了ReLU函数在不断尝试如何用一个大多数为0的矩阵来表达数据特征。以稀疏性数据来表达原有数据特征的方法，使得神经网络在迭代运算中能够取得又快又好的效果，所以目前大多用max（0，x）来代替Sigmod函数。</p>
<h3 id="6-3-softmax算法——处理分类问题"><a href="#6-3-softmax算法——处理分类问题" class="headerlink" title="6.3 softmax算法——处理分类问题"></a>6.3 softmax算法——处理分类问题</h3><p>softmax基本上可以算是分类任务的标配。在本节中需要学会softmax为什么能分类，以及如何使用softmax来分类。如果需要比较哪个更重要，当然是学会如何使用会更重要。</p>
<h4 id="6-3-1-什么是softmax"><a href="#6-3-1-什么是softmax" class="headerlink" title="6.3.1 什么是softmax"></a>6.3.1 什么是softmax</h4><p>对于前面讲的激活函数，其输出值只有两种（0、1，或-1、1，或0、x），而现实生活中需要对某一问题进行多种分类，例如前面的图片分类例子，这时就需要使用softmax算法。</p>
<p>softmax，看名字就知道，就是如果判断输入属于某一个类的概率大于属于其他类的概率，那么这个类对应的值就逼近于1，其他类的值就逼近于0。该算法的主要应用就是多分类，而且是互斥的，即只能属于其中的一个类。与sigmoid类的激活函数不同的是，一般的激活函数只能分两类，所以可以理解成Softmax是Sigmoid类的激活函数的扩展，其算法见式（6-11）。</p>
<p><img src="Image00091.jpg" alt></p>
<p>把所有值用e的n次方计算出来，求和后算每个值占的比率，保证总和为1，一般就可以认为softmax得出的就是概率。</p>
<p>这里的exp（logits）指的就是elogits 。</p>
<p><img src="Image00014.jpg" alt> 注意： 对于要生成的多个类任务中不是互斥关系的任务，一般会使用多个二分类来组成。</p>
<h4 id="6-3-2-softmax原理"><a href="#6-3-2-softmax原理" class="headerlink" title="6.3.2 softmax原理"></a>6.3.2 softmax原理</h4><p>softmax原理很简单，如图6-6所示为一个简单的Softmax网络模型，输入X1 和X2 ，要准备生成Y1 、Y2 和Y3 三个类。</p>
<p><img src="Image00092.jpg" alt></p>
<p>图6-6 softmax网络模型</p>
<p>对于属于y1 类的概率，可以转化成输入x1 满足某个条件的概率，与x2 满足某个条件的概率的乘积。</p>
<p>在网络模型里把等式两边都取ln。这样，ln后的属于y1类的概率就可以转化成，ln后的x1 满足某个条件的概率加上ln后的x2 满足某个条件的概率。这样y1 =x1 w11 +x2 w12 =ln后y1 的概率了。这也是softmax公式中要进行一次e的logits次方的原因。</p>
<p><img src="Image00014.jpg" alt> 注意： 等式两边取ln是神经网络中常用的技巧，主要用来将概率的乘法转变成加法，即ln（x*y）=lnx+lny。然后在后续计算中再将其转为e的x次方，还原成原来的值。</p>
<p>了解完e的n次方的意义后，softmax就变得简单至极了。</p>
<p>举例：某个样本经过生成的值y1 为5，y2 为3，y3 为2。那么对应的概率就为y1 =5/10=0.5，y2 =3/10 ，y3 =2/10，于是取最大的值y1为最终的分类。</p>
<p>softmax在机器学习中有非常广泛的应用，前面介绍过MNIST的每一张图片都表示一个数字，从0到9。我们希望得到给定图片代表每个数字的概率。例如，训练的模型可能推测一张包含9的图片代表数字9的概率是80%，但是判断它是8的概率是5%（因为8和9都有上半部分相似的小圆），判断它代表其他数字的概率值更小。于是取最大概率的对应数值，就是这个图片的分类了。这是一个使用softmax回归（softmax regression）模型的经典案例。</p>
<p><img src="Image00014.jpg" alt> 注意： 在实际使用中，softmax伴随的分类标签都为one_hot编码，而且这里还有个小技巧，在softmax时需要将目标分成几类，就在最后这层放几个节点。</p>
<h4 id="6-3-3-常用的分类函数"><a href="#6-3-3-常用的分类函数" class="headerlink" title="6.3.3 常用的分类函数"></a>6.3.3 常用的分类函数</h4><p>如表6-1中列出了常用的分类函数。</p>
<p>表6-1 常用的分类函数</p>
<p><img src="Image00093.jpg" alt></p>
<h3 id="6-4-损失函数——用真实值与预测值的距离来指导模型的收敛方向"><a href="#6-4-损失函数——用真实值与预测值的距离来指导模型的收敛方向" class="headerlink" title="6.4 损失函数——用真实值与预测值的距离来指导模型的收敛方向"></a>6.4 损失函数——用真实值与预测值的距离来指导模型的收敛方向</h3><p>损失函数是绝对网络学习质量的关键。在学到后面章节就会发现，无论什么样的网络结构，如果使用的损失函数不正确，最终都将难以训练出正确的模型。这里先介绍几个常见的loss函数，针对不同的网络结构还会有更多的loss函数，在后面章节会伴随不同的网络模型来介绍。</p>
<h4 id="6-4-1-损失函数介绍"><a href="#6-4-1-损失函数介绍" class="headerlink" title="6.4.1 损失函数介绍"></a>6.4.1 损失函数介绍</h4><p>损失函数的作用前面已经说过了，用于描述模型预测值与真实值的差距大小。一般有两种比较常见的算法——均值平方差（MSE）和交叉熵。下面来分别介绍每个算法的具体内容。</p>
<p>1．均值平方差</p>
<p>均值平方差（Mean Squared Error，MSE），也称“均方误差”，在神经网络中主要是表达预测值与真实值之间的差异，在数理统计中，均方误差是指参数估计值与参数真值之差平方的期望值。公式定义见式（6-12），主要是对每一个真实值与预测值相减的平方取平均值：</p>
<p><img src="Image00094.jpg" alt></p>
<p>均方误差的值越小，表明模型越好。类似的损失算法还有均方根误差RMSE（将MSE开平方）、平均绝对值误差MAD（对一个真实值与预测值相减的绝对值取平均值）等。</p>
<p><img src="Image00014.jpg" alt> 注意： 在神经网络计算时，预测值要与真实值控制在同样的数据分布内，假设将预测值经过Sigmoid激活函数得到取值范围在0～1之间，那么真实值也归一化成0～1之间。这样在做loss计算时才会有较好的效果。</p>
<p>2．交叉熵</p>
<p>交叉熵（crossentropy）也是loss算法的一种，一般用在分类问题上，表达的意识为预测输入样本属于某一类的概率 。其表达式见式（6-13），其中y代表真实值分类（0或1），a代表预测值。</p>
<p><img src="Image00095.jpg" alt></p>
<p>交叉熵也是值越小，代表预测结果越准。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里用于计算的a也是通过分布统一化处理的（或者是经过Sigmoid函数激活的），取值范围在0～1之间。如果真实值和预测值都是1，前面一项y<em>ln（a）就是1</em>ln（1）等于0，后一项（1-y）<em>ln（1-a）也就是0</em>ln（0）等于0，loss为0，反之loss函数为其他数。</p>
<p>3．总结：损失算法的选取</p>
<p>损失函数的选取取决于输入标签数据的类型：如果输入的是实数、无界的值，损失函数使用平方差；如果输入标签是位矢量（分类标志），使用交叉熵会更适合。</p>
<h4 id="6-4-2-TensorFlow中常见的loss函数"><a href="#6-4-2-TensorFlow中常见的loss函数" class="headerlink" title="6.4.2 TensorFlow中常见的loss函数"></a>6.4.2 TensorFlow中常见的loss函数</h4><p>下面看看TensorFlow中都有哪些常见的loss函数。</p>
<p>1．均值平方差</p>
<p>在TensorFlow没有单独的MSE函数，不过由于公式比较简单，往往开发者都会自己组合，而且也可以写出n种写法，例如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MSE=tf.reduce_mean(tf.pow(tf.sub(logits, outputs), 2.0))</span><br><span class="line">MSE=tf.reduce_mean(tf. square(tf.sub(logits, outputs)))</span><br><span class="line">MSE=tf.reduce_mean(tf. square(logits-outputs))</span><br></pre></td></tr></table></figure>

</details>

<p>代码中logits代表标签值，outputs代表预测值。</p>
<p>同样也可以组合其他类似loss，例如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Rmse= tf.sqrt(tf.reduce_mean(tf.pow(tf.sub(logits, outputs), 2.0)))</span><br><span class="line">mad= tf.reduce_mean (tf.complex_abs(tf.sub(logits, outputs))</span><br></pre></td></tr></table></figure>

</details>

<p>2．交叉熵</p>
<p>在TensorFlow中常见的交叉熵函数有：</p>
<p>·Sigmoid交叉熵；</p>
<p>·softmax交叉熵；</p>
<p>·Sparse交叉熵；</p>
<p>·加权Sigmoid交叉熵。</p>
<p>在TensorFlow里常用的损失函数如表6-2所示。</p>
<p>表6-2 TensorFlow中的交叉熵</p>
<p><img src="Image00096.jpg" alt></p>
<p>当然，也可以像MSE那样使用自己组合的公式计算交叉熵，举例，对于softmax后的结果logits我们可以对其使用公式-tf.reduce_sum（labels*tf.log（logits），1），就等同于softmax_cross_entropy_with_logits得到的结果。</p>
<h3 id="6-5-softmax算法与损失函数的综合应用"><a href="#6-5-softmax算法与损失函数的综合应用" class="headerlink" title="6.5 softmax算法与损失函数的综合应用"></a>6.5 softmax算法与损失函数的综合应用</h3><p>在神经网络中使用softmax计算loss时对于初学者常常会犯很多错误，下面通过具体的实例代码来演示需要注意的关键地方与具体的用法。</p>
<h4 id="6-5-1-实例22：交叉熵实验"><a href="#6-5-1-实例22：交叉熵实验" class="headerlink" title="6.5.1 实例22：交叉熵实验"></a>6.5.1 实例22：交叉熵实验</h4><p>交叉熵这个比较生僻的术语，在深度学习领域中却是最常见的。由于其常用性，在TensorFlow中会被封装成多个版本，有的公式里直接带了交叉熵，有的需要自己单独求出，而在构建模型时，如果读者对这块知识不扎实，出现问题时会很难分析是模型的问题还是交叉熵的使用问题。因此这里有必要通过几个小实例将其弄得更明白一些。</p>
<p>实例描述</p>
<p>下面一段代码，假设有一个标签labels和一个网络输出值logits。</p>
<p>这个实例就是以这两个值来进行以下3次实验。</p>
<p>（1）两次softmax实验：将输出值logits分别进行1次和2次softmax，观察两次的区别及意义。</p>
<p>（2）观察交叉熵：将步骤（1）中的两个值分别进行softmax_cross_entropy_with_logits，观察它们的区别。</p>
<p>（3）自建公式实验：将做两次softmax的值放到自建组合的公式里得到正确的值。</p>
<p>代码6-1 softmax应用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> import tensorflow as tf</span><br><span class="line"> </span><br><span class="line"> labels = [[0,0,1],[0,1,0]]</span><br><span class="line"> logits = [[2,  0.5,6],</span><br><span class="line">           [0.1,0,  3]]</span><br><span class="line"> logits_scaled = tf.nn.softmax(logits)</span><br><span class="line"> logits_scaled2 = tf.nn.softmax(logits_scaled)</span><br><span class="line"> </span><br><span class="line"> result1 = tf.nn.softmax_cross_entropy_with_logits(labels=labels,</span><br><span class="line">  logits=logits)</span><br><span class="line"> result2 = tf.nn.softmax_cross_entropy_with_logits(labels=labels,</span><br><span class="line">   logits=logits_scaled)</span><br><span class="line"> result3 = -tf.reduce_sum(labels*tf.log(logits_scaled),1)</span><br><span class="line"> </span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     print (&quot;scaled=&quot;,sess.run(logits_scaled))    </span><br><span class="line">     print (&quot;scaled2=&quot;,sess.run(logits_scaled2))</span><br><span class="line">#经过第二次的softmax后，分布概率会有变化</span><br><span class="line">         </span><br><span class="line">     print (&quot;rel1=&quot;,sess.run(result1),&quot;\n&quot;) #正确的方式</span><br><span class="line">     print (&quot;rel2=&quot;,sess.run(result2),&quot;\n&quot;)</span><br><span class="line">#如果将softmax变换完的值放进去会，就相当于算第二次softmax的loss，所以会出错</span><br><span class="line">     print (&quot;rel3=&quot;,sess.run(result3))</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scaled= [[ 0.01791432  0.00399722  0.97808844]</span><br><span class="line"> [ 0.04980332  0.04506391  0.90513283]]</span><br><span class="line">scaled2= [[ 0.21747023  0.21446465  0.56806517]</span><br><span class="line"> [ 0.2300214   0.22893383  0.54104471]]</span><br><span class="line">rel1= [ 0.02215516  3.09967351] </span><br><span class="line">rel2= [ 0.56551915  1.47432232] </span><br><span class="line">rel3= [ 0.02215518  3.09967351]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到：logits里面的值原本加和都是大于1的，但是经过softmax之后，总和变成了1。样本中第一个是跟标签分类相符的，第二与标签分类不符，所以第一个的交叉熵比较小，是0.02215516，而第二个比较大，是3.09967351。</p>
<p>下面开始验证下前面所说的实验：</p>
<p>·比较scaled和scaled2可以看到：经过第二次的softmax后，分布概率会有变化，而scaled才是我们真实转化的softmax值。</p>
<p>·比较rel1和rel2可以看到：传入softmax_cross_entropy_with_logits的logits是不需要进行softmax的。如果将softmax后的值scaled传入softmax_cross_entropy_with_ logits就相当于进行了两次的softmax转换。</p>
<p>对于已经用softmax转换过的scaled，在计算loss时就不能在用TensorFlow里面的softmax_cross_entropy_with_logits了。读者可以自己写一个loss函数，参见rel3的生成，通过自己组合的函数实现了softmax_cross_entropy_with_logits一样的结果。</p>
<h4 id="6-5-2-实例23：one-hot实验"><a href="#6-5-2-实例23：one-hot实验" class="headerlink" title="6.5.2 实例23：one_hot实验"></a>6.5.2 实例23：one_hot实验</h4><p>输入的标签也可以不是标准的one-hot。下面用一组总和也是1但是数组中每个值都不等于0或1的数组来代替标签，看看效果。</p>
<p>实例描述</p>
<p>对非one-hot编码为标签的数据进行交叉熵的计算，比较其与one-hot编码的交叉熵之间的差别。</p>
<p>接上述代码，将标签换为[[0.4，0.1，0.5]，[0.3，0.6，0.1]]与原始的[[0，0，1]，[0，1，0]]代表的分类意义等价，将这个标签代入交叉熵。</p>
<p>代码6-1 softmax应用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> #标签总概率为1</span><br><span class="line"> labels = [[0.4,0.1,0.5],[0.3,0.6,0.1]]</span><br><span class="line"> result4 = tf.nn.softmax_cross_entropy_with_logits(labels=labels, </span><br><span class="line">logits=logits)</span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     print (&quot;rel4=&quot;,sess.run(result4),&quot;\n&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，生成结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rel4= [ 2.17215538  2.76967359]</span><br></pre></td></tr></table></figure>

</details>

<p>比较前面的rel1发现，对于正确分类的交叉熵和错误分类的交叉熵，二者的结果差别没有标准one-hot那么明显。</p>
<h4 id="6-5-3-实例24：sparse交叉熵的使用"><a href="#6-5-3-实例24：sparse交叉熵的使用" class="headerlink" title="6.5.3 实例24：sparse交叉熵的使用"></a>6.5.3 实例24：sparse交叉熵的使用</h4><p>下面再举个例子看一下sparse_softmax_cross_entropy_with_logits函数的用法，它需要使用非one-hot的标签，所以，要把前面的标签换成具体数值[2，1]，具体代码如下。</p>
<p>实例描述</p>
<p>使用sparse_softmax_cross_entropy_with_logits函数，对非one-hot的标签进行交叉熵计算，比较其与one-hot标签在使用上的区别。</p>
<p>代码6-1 softmax应用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> #sparse 标签</span><br><span class="line"> labels = [2,1] #表明labels中总共分为3个类： 0 、1、 2。[2,1]等价于onehot</span><br><span class="line">编码中的001与010</span><br><span class="line"> result5 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,</span><br><span class="line">logits=logits)</span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     print (&quot;rel5=&quot;,sess.run(result5),&quot;\n&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，生成结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rel5= [ 0.02215516  3.09967351]</span><br></pre></td></tr></table></figure>

</details>

<p>发现rel5与前面的rel1结果完全一样。</p>
<h4 id="6-5-4-实例25：计算loss值"><a href="#6-5-4-实例25：计算loss值" class="headerlink" title="6.5.4 实例25：计算loss值"></a>6.5.4 实例25：计算loss值</h4><p>在真正的神经网络中，得到代码6-1中的一个数组并不能满足要求，还需要对其求均值，使其最终变成一个具体的数值。</p>
<p>实例描述</p>
<p>演示通过分别对前面交叉熵结果result1与softmax后的结果logits_scaled计算loss，验证如下结论：</p>
<p>（1）对于softmax_cross_entropy_with_logits后的结果求loss直接取均值。</p>
<p>（2）对于softmax后的结果使用-tf.reduce_sum（labels * tf.log（logits_scaled））求loss。</p>
<p>（3）对于softmax后的结果使用-tf.reduce_sum（labels*tf.log（logits_scaled），1）等同于softmax_cross_entropy_with_logits结果。</p>
<p>（4）由（1）和（3）可以推出对（3）进行求均值也可以得出正确的loss值，合并起来的公式为：tf.reduce_sum（-tf.reduce_sum（labels*tf.log（logits_scaled），1））=loss（该结论是由前面的验证推导出来，有兴趣的读者可以自行验证）</p>
<p>代码6-1 softmax应用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss=tf.reduce_sum(result1)</span><br><span class="line">     with tf.Session() as sess:</span><br><span class="line">         print (&quot;loss=&quot;,sess.run(loss))</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，生成结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss= 3.12183</span><br></pre></td></tr></table></figure>

</details>

<p>这便是我们最终要得到的损失值了。</p>
<p>而对于rel3这种已经求得softmax的情况求loss，可以把公式进一步简化成：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss2 = -tf.reduce_sum(labels * tf.log(logits_scaled))</span><br></pre></td></tr></table></figure>

</details>

<p>接着添加示例代码。</p>
<p>代码6-1 softmax应用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">labels = [[0,0,1],[0,1,0]]    </span><br><span class="line">loss2 = -tf.reduce_sum(labels * tf.log(logits_scaled))</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print (&quot;loss2=&quot;,sess.run(loss2))</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss2= 3.12183</span><br></pre></td></tr></table></figure>

</details>

<p>与loss的值完全吻合。</p>
<h4 id="6-5-5-练习题"><a href="#6-5-5-练习题" class="headerlink" title="6.5.5 练习题"></a>6.5.5 练习题</h4><p>试着将上一章的代码（5-2minist分类.py）改成使用sparse_softmax_cross_entropy_with_ logits函数来运算交叉熵。</p>
<p>答案请参考本书源代码中的代码“6-2 sparesoftmaxwithminist.py”。</p>
<h3 id="6-6-梯度下降——让模型逼近最小偏差"><a href="#6-6-梯度下降——让模型逼近最小偏差" class="headerlink" title="6.6 梯度下降——让模型逼近最小偏差"></a>6.6 梯度下降——让模型逼近最小偏差</h3><p>前面的例子中都提到了梯度下降，但不系统。本节将更详细地介绍梯度下降的作用及常用技巧。</p>
<h4 id="6-6-1-梯度下降的作用及分类"><a href="#6-6-1-梯度下降的作用及分类" class="headerlink" title="6.6.1 梯度下降的作用及分类"></a>6.6.1 梯度下降的作用及分类</h4><p>梯度下降法是一个最优化算法，通常也称为最速下降法，常用于机器学习和人工智能中递归性地逼近最小偏差模型，梯度下降的方向也就是用负梯度方向为搜索方向，沿着梯度下降的方向求解极小值。</p>
<p>在训练过程中，每次的正向传播后都会得到输出值与真实值的损失值，这个损失值越小，代表模型越好，于是梯度下降的算法就用在这里，帮助寻找最小的那个损失值，从而可以反推出对应的学习参数b和w，达到优化模型的效果。</p>
<p>常用的梯度下降方法可以分为：批量梯度下降、随机梯度下降和小批量梯度下降。</p>
<p>·批量梯度下降：遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度和更新梯度。这种方法每更新一次参数，都要把数据集里的所有样本看一遍，计算量大，计算速度慢，不支持在线学习，称为Batch gradient descent，批梯度下降。</p>
<p>·随机梯度下降：每看一个数据就算一下损失函数，然后求梯度更新参数，这称为stochastic gradient descent，随机梯度下降。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，命中不到最优点。两次参数的更新也有可能互相抵消，造成目标函数震荡比较剧烈。</p>
<p>·小批量梯度下降：为了克服上面两种方法的缺点，一般采用一种折中手段——小批的梯度下降。这种方法把数据分为若干个批，按批来更新参数，这样一批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。</p>
<h4 id="6-6-2-TensorFlow中的梯度下降函数"><a href="#6-6-2-TensorFlow中的梯度下降函数" class="headerlink" title="6.6.2 TensorFlow中的梯度下降函数"></a>6.6.2 TensorFlow中的梯度下降函数</h4><p>下面重点介绍在TensorFlow中进行随机梯度下降优化的函数。</p>
<p>在TensorFlow中是通过一个叫做Optimizer的优化器类进行训练优化的。对于不同算法的优化器，在TensorFlow中会有不同的类，如表6-3所示。</p>
<p>表6-3 梯度下降优化器</p>
<p><img src="Image00097.jpg" alt></p>
<p>在训练过程中，先实例化一个优化函数如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure>

</details>

<p>接着使用一个minimize（）的操作，里面传入损失值节点loss，再启动一个外层的循环，优化器就会按照循环的次数一次次沿着loss最小值的方向优化参数了。</p>
<p>整个过程中的求导和反向传播操作，都是在优化器里自动完成的。目前比较常用的优化器为Adam优化器。关于Adam的算法不在本书的介绍范围之内，有兴趣的读者可以参考相关资料扩充知识。</p>
<h4 id="6-6-3-退化学习率——在训练的速度与精度之间找到平衡"><a href="#6-6-3-退化学习率——在训练的速度与精度之间找到平衡" class="headerlink" title="6.6.3 退化学习率——在训练的速度与精度之间找到平衡"></a>6.6.3 退化学习率——在训练的速度与精度之间找到平衡</h4><p>前面介绍的每个优化器的第一个参数learning_rate就是代表学习率。</p>
<p>设置学习率的大小，是在精度和速度之间找到一个平衡：</p>
<p>·如果学习率的值比较大，则训练速度会提升，但结果的精度不够；</p>
<p>·如果学习率的值比较小，精度虽然提升了，但训练会耗费太多的时间。</p>
<p>下面就来介绍设置学习率的方法——退化学习率。</p>
<p>退化学习率又叫学习率衰减，它的本意是希望在训练过程中对于学习率大和小的优点都能够为我们所用，也就是当训练刚开始时使用大的学习率加快速度，训练到一定程度后使用小的学习率来提高精度，这时可以使用学习率衰减的方法：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def exponential_decay(learning_rate,global_step, decay_steps, decay_rate,</span><br><span class="line">                               staircase=False, name=None):</span><br></pre></td></tr></table></figure>

</details>

<p>学习率的衰减速度是由global_step和decay_steps来决定的。具体的计算公式如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">decayed_learning_rate = learning_rate *decay_rate ^ (global_step / decay_steps)</span><br></pre></td></tr></table></figure>

</details>

<p>staircase值默认为False。当为True时，将没有衰减功能，只是使用上面的公式初始化一个学习率的值而已。</p>
<p>例如下面的代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = tf.train.exponential_decay(starter_learning_rate, global_ </span><br><span class="line">step,100000, 0.96)</span><br></pre></td></tr></table></figure>

</details>

<p>这种方式定义的学习率就是退化学习率，它的意思是当前迭代到global_step步，学习率每一步都按照每10万步缩小到0.96%的速度衰退。</p>
<p>有时还需要对已经训练好的模型进行微调，可以指定不同层使用不同的学习率，这个在后面章节中会详细介绍。</p>
<p><img src="Image00014.jpg" alt> 注意： 通过增大批次处理样本的数量也可以起到退化学习率的效果。但是这种方法要求训练时的最小批次要与实际应用中的最小批次一致。一旦满足该条件时，建议优先选择增大批次数量的方法，因为这样会省去一些开发量和训练中的计算量。</p>
<h4 id="6-6-4-实例26：退化学习率的用法举例"><a href="#6-6-4-实例26：退化学习率的用法举例" class="headerlink" title="6.6.4 实例26：退化学习率的用法举例"></a>6.6.4 实例26：退化学习率的用法举例</h4><p>本例主要是演示学习率衰减的使用方法。</p>
<p>本例中使用迭代循环计数变量global_step来标记循环次数，初始学习率为0.1，令其以每10次衰减0.9的速度来进行退化。</p>
<p>实例描述</p>
<p>定义一个学习率变量，将其衰减系数设置好，并设置好迭代循环的次数，将每次迭代运算的次数与学习率打印出来，观察学习率按照次数退化的现象。</p>
<p>代码6-3 退化学习率</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">global_step = tf.Variable(0, trainable=False)</span><br><span class="line">initial_learning_rate = 0.1             #初始学习率</span><br><span class="line">learning_rate = tf.train.exponential_decay(initial_learning_rate,</span><br><span class="line">                                           global_step=global_step,</span><br><span class="line">                                           decay_steps=10,decay_rate=0.9)</span><br><span class="line">opt = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">add_global = global_step.assign_add(1) #定义一个op，令global_step加1完成记步</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    print(sess.run(learning_rate))</span><br><span class="line">    for i in range(20):</span><br><span class="line">        g, rate = sess.run([add_global, learning_rate])     #循环20步，将每步的学习率打印出来</span><br><span class="line">        print(g,rate)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码运行如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">0.1</span><br><span class="line">1 0.1</span><br><span class="line">2 0.0989519</span><br><span class="line">3 0.0979148</span><br><span class="line">4 0.0968886</span><br><span class="line">5 0.0958732</span><br><span class="line">6 0.0948683</span><br><span class="line">7 0.093874</span><br><span class="line">8 0.0928902</span><br><span class="line">9 0.0919166</span><br><span class="line"> 0.0909533</span><br><span class="line"> 0.09</span><br><span class="line"> 0.0890567</span><br><span class="line"> 0.0881234</span><br><span class="line"> 0.0871998</span><br><span class="line"> 0.0862858</span><br><span class="line"> 0.0853815</span><br><span class="line"> 0.0844866</span><br><span class="line"> 0.0836011</span><br><span class="line"> 0.082725</span><br><span class="line"> 0.0818579</span><br></pre></td></tr></table></figure>

</details>

<p>第1个数是迭代的次数，第2个输出是学习率。可以看到学习率在逐渐变小，在第11次由原来的0.1变为了0.09。</p>
<p><img src="Image00014.jpg" alt> 注意： 这是一种常用的训练策略，在训练神经网络时，通常在训练刚开始时使用较大的learning rate，随着训练的进行，会慢慢减小learning rate。在使用时，一定要把当前迭代次数global_step传进去，否则不会有退化的功能。</p>
<h3 id="6-7-初始化学习参数"><a href="#6-7-初始化学习参数" class="headerlink" title="6.7 初始化学习参数"></a>6.7 初始化学习参数</h3><p>在定义学习参数时可以通过get_variable和Variable两个方式，对于一个网络模型，参数不同的初始化情况，对网络的影响会很大，所以在TensorFlow提供了很多具有不同特性的初始化函数。在使用get_variable时，get_variable的定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def get_variable(name,</span><br><span class="line">                 shape=None,</span><br><span class="line">                 dtype=None,</span><br><span class="line">                 initializer=None,</span><br><span class="line">                 regularizer=None,</span><br><span class="line">                 trainable=True,</span><br><span class="line">                 collections=None,</span><br><span class="line">                 caching_device=None,</span><br><span class="line">                 partitioner=None,</span><br><span class="line">                 validate_shape=True,</span><br><span class="line">                 use_resource=None,</span><br><span class="line">                 custom_getter=None)</span><br></pre></td></tr></table></figure>

</details>

<p>其中，参数initializer就是初始化参数，可以取表6-4中列出的相关函数。</p>
<p>表6-4 初始化函数</p>
<p><img src="Image00098.jpg" alt></p>
<p><img src="Image00099.jpg" alt></p>
<p>另外，在tf.contrib.layers函数中还有个tf.contrib.layers.xavier_initializer初始化函数，用来在所有层中保持梯度大体相同。尤其在深度神经网络里会经常使用（后面卷积内容的章节中还会提到该函数）。</p>
<p>对于Variable定义的变量，可以使用表4-7中的相关函数进行初始化。</p>
<p><img src="Image00014.jpg" alt> 注意： 一般常用的初始化函数为tf.truncated_normal函数，因为该函数有截断功能，可以生成相对比较温和的初始值。</p>
<h3 id="6-8-单个神经元的扩展——Maxout网络"><a href="#6-8-单个神经元的扩展——Maxout网络" class="headerlink" title="6.8 单个神经元的扩展——Maxout网络"></a>6.8 单个神经元的扩展——Maxout网络</h3><p>在早期，单个神经元出现之后，为了得到更好的拟合效果，又出现了一种Maxout网络，下面具体介绍。</p>
<h4 id="6-8-1-Maxout介绍"><a href="#6-8-1-Maxout介绍" class="headerlink" title="6.8.1 Maxout介绍"></a>6.8.1 Maxout介绍</h4><p>Maxout网络可以理解为单个神经元的扩展，主要是扩展单个神经元里面的激活函数，正常的单个神经元如图6-7所示。</p>
<p>Maxout是将激活函数变成一个网络选择器，原理就是将多个神经元并列地放在一起，从它们的输出结果中找到最大的那个，代表对特征响应最敏感，然后取这个神经元的结果参与后面的运算，如图6-8所示。</p>
<p><img src="Image00100.jpg" alt></p>
<p>图6-7 单个神经元</p>
<p><img src="Image00101.jpg" alt></p>
<p>图6-8 Maxout网络</p>
<p>它的公式可以理解成：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">z1=w1*x+b1</span><br><span class="line">z2=w2*x+b2</span><br><span class="line">z3=w3*x+b3</span><br><span class="line">z4=w4*x+b4</span><br><span class="line">z5=w5*x+b5</span><br><span class="line">……</span><br><span class="line">out=max(z1,z2,z3,z4,z5……)</span><br></pre></td></tr></table></figure>

</details>

<p>为什么要这样做呢？在前面我们学习了一个神经元的作用，类似人类的神经细胞，不同的神经元会因为输入的不同而产生不同的输出，即不同的细胞关心的信号不同。依赖于这个原理，现在的做法就是相当于同时使用多个神经元放在一起，哪个有效果就用哪个。所以这样的网络会有更好的拟合效果。</p>
<h4 id="6-8-2-实例27：用Maxout网络实现MNIST分类"><a href="#6-8-2-实例27：用Maxout网络实现MNIST分类" class="headerlink" title="6.8.2 实例27：用Maxout网络实现MNIST分类"></a>6.8.2 实例27：用Maxout网络实现MNIST分类</h4><p>本例主要是演示Maxout网络的构建方法。</p>
<p>本例中以6.5节的练习题答案来修改代码，在本书源代码中的代码“6-2 sparesoftmaxwithminist.py”文件里做如下改动。</p>
<p>实例描述</p>
<p>Maxout网络的构建方法：通过reduce_max函数对多个神经元的输出来计算Max值，将Max值当作输入按照神经元正反传播方向进行计算。</p>
<p>通过上述方法构建Maxout网络，实现MNIST分类。</p>
<p>代码6-4 Maxout网络实现MNIST分类</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">z= tf.matmul(x, W) + b</span><br><span class="line"> </span><br><span class="line">maxout = tf.reduce_max(z,axis= 1,keep_dims=True)</span><br><span class="line"># 设置学习参数</span><br><span class="line">W2 = tf.Variable(tf.truncated_normal([1, 10], stddev=0.1))</span><br><span class="line">b2 = tf.Variable(tf.zeros([1]))</span><br><span class="line"># 构建模型</span><br><span class="line">pred = tf.nn.softmax(tf.matmul(maxout, W2) + b2)</span><br><span class="line">……</span><br><span class="line">learning_rate = 0.04</span><br><span class="line">#使用一般梯度下降方法的优化器</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize </span><br><span class="line">(cost)</span><br><span class="line"> </span><br><span class="line">training_epochs = 200</span><br><span class="line">batch_size = 100</span><br><span class="line">display_step = 1</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>在网络模型部分，添加一层Maxout，然后将Maxout作为maxsoft的交叉熵输入。学习率设为0.04，迭代次数设为200。运行代码，得到如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 5.160553925</span><br><span class="line">Epoch: 0002 cost= 1.797463597</span><br><span class="line">……</span><br><span class="line">Epoch: 0198 cost= 0.290569865</span><br><span class="line">Epoch: 0199 cost= 0.290143878</span><br><span class="line">Epoch: 0200 cost= 0.289847674</span><br><span class="line"> Finished!</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到损失值下降到0.28，随着迭代次数的增加还会继续下降。有兴趣的读者可以自己接着优化。</p>
<p>Maxout的拟合功能很强大，但是也会有节点过多、参数过多、训练过慢的缺点。在第7章中还会学习一种类似于Maxout的全连接网络，会更深刻地讨论拟合的方法及意义。</p>
<h3 id="6-9-练习题"><a href="#6-9-练习题" class="headerlink" title="6.9 练习题"></a>6.9 练习题</h3><p>在了解这么多比较零散的知识点以后，最重要的是熟练掌握它们，读者可以将前面讲过的例子拿出来，通过调节学习率、改变激活函数、调节最小批次的方法，试着去改变模型，看看会得到什么不同的结果。</p>
<h2 id="第7章-多层神经网络——解决非线性问题"><a href="#第7章-多层神经网络——解决非线性问题" class="headerlink" title="第7章 多层神经网络——解决非线性问题"></a>第7章 多层神经网络——解决非线性问题</h2><p>第6章通过实验验证了单层神经网络的拟合功能。但是在实际环境中，发现这种拟合的效果极其有限。对于某些样本，即便是Maxout也无法解决问题。追究根本，源于样本本身的特性，即单层神经网络只能解决对线性可分的问题。</p>
<p>本章将介绍如何使用多层神经网络来解决非线性问题。</p>
<p>本章含有教学视频共6分35秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了快速讲解，包括多层神经网络与单层神经网络的结构区分及功能能区分、线性与非线性的概念、拟合与过拟合的效果（重点掌握多层网络的拟合原理及训练方法）等。</p>
<p><img src="Image00102.jpg" alt></p>
<h3 id="7-1-线性问题与非线性问题"><a href="#7-1-线性问题与非线性问题" class="headerlink" title="7.1 线性问题与非线性问题"></a>7.1 线性问题与非线性问题</h3><p>“线性问题”与“非线性问题”是神经网络中的常用术语。为了能够更准确地解释它们，咱们先从一个例子入手。</p>
<h4 id="7-1-1-实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的"><a href="#7-1-1-实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的" class="headerlink" title="7.1.1 实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的"></a>7.1.1 实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的</h4><p>在介绍线性逻辑回归例子之前，我们先利用第6章所学的知识，做下面的这个分类任务。</p>
<p>实例描述</p>
<p>假设某肿瘤医院想用神经网络对已有的病例数据进行分类，数据的样本特征包括病人的年龄和肿瘤的大小，对应的标签为该病例是良性肿瘤还是恶性肿瘤。</p>
<p>1．生成样本集</p>
<p>对于这个任务，大家可能迫不及待地想用我们所学的模型试试了吧。这里因为没有医院的病例数据，为了方便演示，先用Python生成一些模拟数据来代替样本，它应该是个二维的数组“病人的年纪，肿瘤的大小”。代码7-1中，generate为生成模拟样本的函数，意思是按照指定的均值和方差生成固定数量的样本。</p>
<p>代码7-1 线性逻辑回归</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def generate(sample_size, mean, cov, diff,regression):   </span><br><span class="line">    num_classes = 2 </span><br><span class="line">    samples_per_class = int(sample_size/2)</span><br><span class="line"></span><br><span class="line">    X0 = np.random.multivariate_normal(mean, cov, samples_per_class)</span><br><span class="line">    Y0 = np.zeros(samples_per_class)</span><br><span class="line">    </span><br><span class="line">    for ci, d in enumerate(diff):</span><br><span class="line">        X1 = np.random.multivariate_normal(mean+d, cov, samples_per_</span><br><span class="line">       class)</span><br><span class="line">        Y1 = (ci+1)*np.ones(samples_per_class)</span><br><span class="line">    </span><br><span class="line">        X0 = np.concatenate((X0,X1))</span><br><span class="line">        Y0 = np.concatenate((Y0,Y1))</span><br><span class="line">        </span><br><span class="line">    if regression==False: #one-hot编码，将0转成1 0</span><br><span class="line">        class_ind = [Y==class_number for class_number in range(num_</span><br><span class="line">       classes)]</span><br><span class="line">        Y = np.asarray(np.hstack(class_ind), dtype=np.float32)</span><br><span class="line">    X, Y = shuffle(X0, Y0)</span><br><span class="line">    </span><br><span class="line">    return X,Y</span><br></pre></td></tr></table></figure>

</details>

<p>下面代码是调用generate函数生成1000个数据，并将它们图示化。</p>
<p>·定义随机数的种子值（这样可以保证每次运行代码时生成的随机值都一样），见代码21行。</p>
<p>·定义生成类的个数num_classes=2，见代码22行。</p>
<p>·代码25行中的3.0是表明两类数据的x和y差距3.0。传入的最后一个参数regression =True表明使用非one-hot的编码标签。</p>
<p>代码7-1 线性逻辑回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(10)</span><br><span class="line">num_classes =2</span><br><span class="line">mean = np.random.randn(num_classes)</span><br><span class="line">cov = np.eye(num_classes) </span><br><span class="line">X, Y = generate(1000, mean, cov, [3.0],True)</span><br><span class="line">colors = [&apos;r&apos; if l == 0 else &apos;b&apos; for l in Y[:]]</span><br><span class="line">plt.scatter(X[:,0], X[:,1], c=colors)</span><br><span class="line">plt.xlabel(&quot;Scaled age (in yrs)&quot;)</span><br><span class="line">plt.ylabel(&quot;Tumor size (in cm)&quot;)</span><br><span class="line">plt.show()</span><br><span class="line">lab_dim = 1</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，得到的结果如图7-1所示。</p>
<p><img src="Image00103.jpg" alt></p>
<p>图7-1 模拟数据集</p>
<p>图7-1中左下是红色的样本数据，右上是蓝色的样本数据。</p>
<p>2．构建网络结构</p>
<p>下面开始构建网络模型，见下方代码。</p>
<p>使用前面刚刚学过的一个神经元，先定义输入、输出两个占位符，然后是w和b的权重。</p>
<p>·激活函数使用的是Sigmoid，见代码第38行。</p>
<p>·损失函数loss仍然使用交叉熵，见代码第41行，里面又加了一个平方差函数，用来评估模型的错误率。</p>
<p>·优化器使用AdamOptimizer，见代码第43行。</p>
<p>代码7-1 线性逻辑回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> input_features = tf.placeholder(tf.float32, [None, input_dim])</span><br><span class="line"> input_lables = tf.placeholder(tf.float32, [None, lab_dim])</span><br><span class="line"> # 定义学习参数</span><br><span class="line"> W = tf.Variable(tf.random_normal([input_dim,lab_dim]), name=&quot;weight&quot;)</span><br><span class="line"> b = tf.Variable(tf.zeros([lab_dim]), name=&quot;bias&quot;)</span><br><span class="line"> </span><br><span class="line"> output =tf.nn.sigmoid( tf.matmul(input_features, W) + b)</span><br><span class="line"> cross_entropy = -(input_lables * tf.log(output) + (1 -input_lables) </span><br><span class="line">* tf.log(1 -output))</span><br><span class="line"> ser= tf.square(input_lables -output)</span><br><span class="line"> loss = tf.reduce_mean(cross_entropy)</span><br><span class="line"> err = tf.reduce_mean(ser)</span><br><span class="line"> optimizer = tf.train.AdamOptimizer(0.04)</span><br><span class="line">#尽量用这个，因其收敛快，会动态调节梯度</span><br><span class="line"> train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>

</details>

<p>3．设置参数进行训练</p>
<p>令整个数据集迭代50次，每次的minibatchsize取25条。</p>
<p>代码7-1 线性逻辑回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">maxEpochs = 50</span><br><span class="line">minibatchSize = 25</span><br><span class="line"></span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">       </span><br><span class="line">    # 向模型输入数据</span><br><span class="line">    for epoch in range(maxEpochs):</span><br><span class="line">        sumerr=0</span><br><span class="line">        for i in range(np.int32(len(Y)/minibatchSize)):</span><br><span class="line">            x1 = X[i*minibatchSize:(i+1)*minibatchSize,:]</span><br><span class="line">            y1 = np.reshape(Y[i*minibatchSize:(i+1)*minibatchSize],</span><br><span class="line">           [-1,1])</span><br><span class="line">            tf.reshape(y1,[-1,1])</span><br><span class="line">            _,lossval, outputval,errval = sess.run([train,loss,output,</span><br><span class="line">           err], feed_dict=&#123;input_features: x1, input_lables:y1&#125;)</span><br><span class="line">            sumerr =sumerr+errval</span><br><span class="line"></span><br><span class="line">        print (&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1), &quot;cost=&quot;,&quot;&#123;:.9f&#125;&quot;.format</span><br><span class="line">        (lossval), \</span><br><span class="line">        &quot;err=&quot;,sumerr/minibatchSize)</span><br></pre></td></tr></table></figure>

</details>

<p>每一次的计算都会将err错误值累加起来，数据集迭代完一次会将err的错误率进行一次平均，平均值再输出来。运行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.937670827 err= 0.857066742182</span><br><span class="line">Epoch: 0002 cost= 0.576581895 err= 0.474182988405</span><br><span class="line">Epoch: 0003 cost= 0.326138794 err= 0.273106197715</span><br><span class="line">……</span><br><span class="line">Epoch: 0048 cost= 0.028127037 err= 0.019222549072</span><br><span class="line">Epoch: 0049 cost= 0.027764326 err= 0.0191760268845</span><br><span class="line">Epoch: 0050 cost= 0.027415426 err= 0.0191324938528</span><br></pre></td></tr></table></figure>

</details>

<p>经过50次的迭代，得到了错误率为0.019的模型。</p>
<p>4．数据可视化</p>
<p>为了直观地解释线性可分，下面将模型结果和样本以可视化的方式显示出来，前一部分是先取100个测试点，在图像上显示出来，接着将模型以一条直线的方式显示出来。</p>
<p>代码7-1 线性逻辑回归（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_X, train_Y = generate(100, mean, cov, [3.0],True)</span><br><span class="line">colors = [&apos;r&apos; if l == 0 else &apos;b&apos; for l in train_Y[:]]</span><br><span class="line">plt.scatter(train_X[:,0], train_X[:,1], c=colors)</span><br><span class="line">x = np.linspace(-1,8,200) </span><br><span class="line">y=-x*(sess.run(W)[0]/sess.run(W)[1])-sess.run(b)/sess.run(W)[1]</span><br><span class="line">plt.plot(x,y, label=&apos;Fitted line&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>如上代码，模型生成的z用公式可以表示为z= x1w1+x2*w2+b，如果将x1和x2映射到直角坐标系中的x和y坐标，那么z就可以被分为小于0和大于0两部分。当z=0时，就代表直线本身，令上面的公式中z等于零，就可以将模型转化成如下直线方程：</p>
<p>x2=-x1<em> w1/w2-b/w2，即：y=-x</em> （w1/w2）-（b/w2）</p>
<p>其中，w1、w2、b都是模型中的学习参数，带到公式中用plot显示出来。运行代码，生成结果如图7-2所示。</p>
<p><img src="Image00104.jpg" alt></p>
<p>图7-2 线性逻辑回归</p>
<p>5．线性可分概念</p>
<p>如图7-2所示这种情况，可以用直线分割的方式解决问题，则可以说这个问题是线性可分的。同理，类似这样的数据集就可以被称为线性可分数据集合。凡是使用这种方法来解决的问题就叫做线性问题。</p>
<h4 id="7-1-2-实例29：用线性逻辑回归处理多分类问题"><a href="#7-1-2-实例29：用线性逻辑回归处理多分类问题" class="headerlink" title="7.1.2 实例29：用线性逻辑回归处理多分类问题"></a>7.1.2 实例29：用线性逻辑回归处理多分类问题</h4><p>还是接着前面的例子，这次在数据集中再添加一类样本，可以使用多条直线将数据分成多类。</p>
<p>实例描述</p>
<p>构建网络模型完成将3类样本分开的任务。</p>
<p>在实现过程中先生成3类样本模拟数据，构造神经网络，通过softmax分类的方法计算神经网络的输出值，并将其分开。</p>
<p>1．生成样本集</p>
<p>这里还使用上面代码中的generate函数，这次不同的是生成了2000个点、3类数据，并且使用one_hot编码。</p>
<p>代码7-2 线性多分类</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(10)</span><br><span class="line"></span><br><span class="line">input_dim = 2</span><br><span class="line">num_classes =3 </span><br><span class="line">X, Y = generate(2000,num_classes,  [[3.0],[3.0,0]],False)</span><br><span class="line">aa = [np.argmax(l) for l in Y]</span><br><span class="line">colors =[&apos;r&apos; if l == 0 else &apos;b&apos; if l==1 else &apos;y&apos; for l in aa[:]]</span><br><span class="line">#将具体的点依照不同的颜色显示出来</span><br><span class="line">plt.scatter(X[:,0], X[:,1], c=colors)</span><br><span class="line">plt.xlabel(&quot;Scaled age (in yrs)&quot;)</span><br><span class="line">plt.ylabel(&quot;Tumor size (in cm)&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>进行上面的代码，生成的结果如图7-3所示。</p>
<p><img src="Image00105.jpg" alt></p>
<p>图7-3 三分类模拟数据集</p>
<p>在图7-3中，红色是原始的点，黄色点是在红色点的基础上将x+3.0后的变化，而蓝色的点是在红色点的基础上将x和y各加3.0。</p>
<p>2．构建网络结构</p>
<p>下面开始构建网络模型，这次使用了softmax分类，损失函数loss仍然使用交叉熵，对于错误率评估部分换成了取one_hot结果里面不相同的个数，优化器使用AdamOptimizer。</p>
<p>代码7-2 线性多分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> lab_dim = num_classes</span><br><span class="line"> # 定义占位符</span><br><span class="line"> input_features = tf.placeholder(tf.float32, [None, input_dim])</span><br><span class="line"> input_lables = tf.placeholder(tf.float32, [None, lab_dim])</span><br><span class="line"> # 定义学习参数</span><br><span class="line"> W = tf.Variable(tf.random_normal([input_dim,lab_dim]), name=&quot;weight&quot;)</span><br><span class="line"> b = tf.Variable(tf.zeros([lab_dim]), name=&quot;bias&quot;)</span><br><span class="line"> output = tf.matmul(input_features, W) + b</span><br><span class="line"> </span><br><span class="line"> z = tf.nn.softmax( output )</span><br><span class="line"> </span><br><span class="line"> a1 = tf.argmax(tf.nn.softmax( output ), axis=1) #按行找出最大索引，生成数组</span><br><span class="line"> b1 = tf.argmax(input_lables, axis=1)</span><br><span class="line"> err = tf.count_nonzero(a1-b1) #两个数组相减，不为0的就是错误个数</span><br><span class="line"> </span><br><span class="line"> cross_entropy tf.nn.softmax_cross_entropy_with_logits( labels=</span><br><span class="line">input_lables,logits=output)</span><br><span class="line"> loss = tf.reduce_mean(cross_entropy) #对交叉熵取均值很有必要</span><br><span class="line"> </span><br><span class="line"> optimizer = tf.train.AdamOptimizer(0.04) #尽量用Adam算法的优化器函数，因其收敛快，会动态调节梯度</span><br><span class="line"> train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>

</details>

<p>3．设置参数进行训练</p>
<p>本次同样设置数据集迭代50次，每次的minibatchSize取25条。</p>
<p>代码7-2 线性多分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">maxEpochs = 50</span><br><span class="line">minibatchSize = 25</span><br><span class="line"></span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    for epoch in range(maxEpochs):</span><br><span class="line">        sumerr=0</span><br><span class="line">        for i in range(np.int32(len(Y)/minibatchSize)):</span><br><span class="line">            x1 = X[i*minibatchSize:(i+1)*minibatchSize,:]</span><br><span class="line">            y1 = Y[i*minibatchSize:(i+1)*minibatchSize,:]</span><br><span class="line"></span><br><span class="line">            _,lossval, outputval,errval = sess.run([train,loss,output,</span><br><span class="line">           err], feed_dict=&#123;input_features: x1, input_lables:y1&#125;)</span><br><span class="line">            sumerr =sumerr+(errval/minibatchSize)</span><br><span class="line"></span><br><span class="line">        print (&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1), &quot;cost=&quot;,&quot;&#123;:.9f&#125;&quot;.format</span><br><span class="line">       (lossval),&quot;err=&quot;,sumerr/minibatchSize)</span><br></pre></td></tr></table></figure>

</details>

<p>在迭代训练时对错误率的收集与前面的代码一致，每一次的计算都会将err错误值累加起来，数据集迭代完一次会将err的错误率进行一次平均，然后再输出平均值。运行上面的代码生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.408920079 err= 0.8544</span><br><span class="line">Epoch: 0002 cost= 0.337683767 err= 0.3648</span><br><span class="line">Epoch: 0003 cost= 0.321038276 err= 0.3328</span><br><span class="line">Epoch: 0004 cost= 0.319500208 err= 0.32</span><br><span class="line">……</span><br><span class="line">Epoch: 0048 cost= 0.422929078 err= 0.2784</span><br><span class="line">Epoch: 0049 cost= 0.423131853 err= 0.2784</span><br><span class="line">Epoch: 0050 cost= 0.423317522 err= 0.2784</span><br></pre></td></tr></table></figure>

</details>

<p>4．数据可视化</p>
<p>接下来一起看看对于三分类问题，线性可分是怎么分的。先取200个测试的点，在图像上显示出来，接着将模型中x1、x2的映射关系以一条直线的方式显示出来。因为输出端有3个节点，所以相当于是3条直线。</p>
<p>代码7-2 线性多分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> train_X, train_Y = generate(200,num_classes,  [[3.0],[3.0,0]],</span><br><span class="line">False)</span><br><span class="line"> aa = [np.argmax(l) for l in train_Y]        </span><br><span class="line"> colors =[&apos;r&apos; if l == 0 else &apos;b&apos; if l==1 else &apos;y&apos; for l in aa[:]]</span><br><span class="line"> plt.scatter(train_X[:,0], train_X[:,1], c=colors)</span><br><span class="line"> </span><br><span class="line"> x = np.linspace(-1,8,200) </span><br><span class="line">     </span><br><span class="line"> y=-x*(sess.run(W)[0][0]/sess.run(W)[1][0])-sess.run(b)[0]/sess.</span><br><span class="line">run(W)[1][0]</span><br><span class="line"> plt.plot(x,y, label=&apos;first line&apos;,lw=3)</span><br><span class="line">     </span><br><span class="line"> y=-x*(sess.run(W)[0][1]/sess.run(W)[1][1])-sess.run(b)[1]/sess.</span><br><span class="line">run(W)[1][1]</span><br><span class="line"> plt.plot(x,y, label=&apos;second line&apos;,lw=2)</span><br><span class="line">     </span><br><span class="line"> y=-x*(sess.run(W)[0][2]/sess.run(W)[1][2])-sess.run(b)[2]/sess.</span><br><span class="line">run(W)[1][2]</span><br><span class="line"> plt.plot(x,y, label=&apos;third line&apos;,lw=1)</span><br><span class="line"> </span><br><span class="line"> plt.legend()</span><br><span class="line"> plt.show()</span><br><span class="line"> print(sess.run(W),sess.run(b))</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，输出如下，得到结果如图7-4所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[-1.29152238  1.68322766  1.79681265]</span><br><span class="line"> [-0.55652267  2.47718096 -0.54918939]] [ 6.61509657 -8.44192219 -1.66505146]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00106.jpg" alt></p>
<p>图7-4 三分类线性模型</p>
<p>图7-4中，3个权重分别代表了3条线。还原成模型就是模型里3个输出的分类节点：</p>
<p>·第1个输出节点代表分类0，红色，蓝线（first line）。</p>
<p>·第2个输出节点代表分类1，蓝色，绿线（second line）。</p>
<p>·第3个输出节点代表分类2，黄色，红线（third line）。</p>
<p>这3条直线的斜率和截距是由神经网络的学习参数转化而来的。在神经网络里，一个样本通过这3个公式会得到3个结果，这3个结果可以理解成3个类的特征值。其中哪个值最大，则表示该样本具有哪种类别的特征最强烈，即属于哪一类。可以在横轴随便找一个值，分别带到3条直线的公式里，哪条直线得出的y值最大，则说明该点属于哪一类。这3条线也没有把集合点分开，这是因为它们的分类规则是不一样的。下面回顾一下直线公式：</p>
<p>y=-x* （w1/w2）-（b/w2）</p>
<p>正常来讲：如果一个点在直线上，等式成立；如果点在直线的上方，那么左边的y值就大；如果点在直线的下方，那么右边的算式值就大。</p>
<p>但放到模型里对应的图像上并不是这样的，还取决于w1的正负取值，当w1为负时正好是相反的情况。从上例中的输出结果里可以看到，只有第一条线（蓝线）的w1是负数，所以蓝线是取其下面的点，红线和绿线是取其上方的点。举例：取一点红色的数据，如图7-5所示。</p>
<p><img src="Image00107.jpg" alt></p>
<p>图7-5 三分类线性模型分析</p>
<p>沿着y轴的方向平行画一条线经过该点，可以看到它在第一条线（蓝线）的下方，并且离蓝线的距离是最远的，所以它就属于第一条线对应的红色分类。说明对于这类的数据集，仍然可以使用线性可分的方法将其分开。本例也展示了线性可分在多分类问题上的应用与原理。</p>
<p>5．模型可视化</p>
<p>前面介绍了线性与模型的关系，现在把整个坐标系放到模型里，会得到一个更直观的模型分类可视化。</p>
<p>为了方便演示，还是在图像上生成200个点并显示出来。然后按照坐标系的排列，把x1，x2放到模型里，见如下代码。</p>
<p>代码7-2 线性多分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> train_X, train_Y = generate(200,num_classes,  [[3.0],[3.0,0]],</span><br><span class="line">False)</span><br><span class="line"> aa = [np.argmax(l) for l in train_Y]        </span><br><span class="line"> colors =[&apos;r&apos; if l == 0 else &apos;b&apos; if l==1 else &apos;y&apos; for l in aa[:]]</span><br><span class="line"> plt.scatter(train_X[:,0], train_X[:,1], c=colors)    </span><br><span class="line"> </span><br><span class="line"> nb_of_xs = 200</span><br><span class="line"> xs1 = np.linspace(-1, 8, num=nb_of_xs)</span><br><span class="line"> xs2 = np.linspace(-1, 8, num=nb_of_xs)</span><br><span class="line"> xx, yy = np.meshgrid(xs1, xs2) # 创建网格</span><br><span class="line"> # 初始化和填充 classification plane</span><br><span class="line"> classification_plane = np.zeros((nb_of_xs, nb_of_xs))</span><br><span class="line"> for i in range(nb_of_xs):</span><br><span class="line">     for j in range(nb_of_xs):</span><br><span class="line">         </span><br><span class="line">         classification_plane[i,j] = sess.run(a1, feed_dict=&#123;input_</span><br><span class="line">        features: [[ xx[i,j], yy[i,j] ]]&#125; )</span><br><span class="line"> </span><br><span class="line"> # 创建 color map 用于显示</span><br><span class="line"> cmap = ListedColormap([</span><br><span class="line">         colorConverter.to_rgba(&apos;r&apos;, alpha=0.30),</span><br><span class="line">         colorConverter.to_rgba(&apos;b&apos;, alpha=0.30),</span><br><span class="line">         colorConverter.to_rgba(&apos;y&apos;, alpha=0.30)])</span><br><span class="line"> # 图示各个样本边界</span><br><span class="line"> plt.contourf(xx, yy, classification_plane, cmap=cmap)</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码的运行结果如图7-6所示。</p>
<p>图7-6中将三分类模型用了不同的颜色区域进行区分，这样就是符合人眼规律的一个比较直观的可视化图样了。</p>
<p><img src="Image00108.jpg" alt></p>
<p>图7-6 三分类模型可视化</p>
<h4 id="7-1-3-认识非线性问题"><a href="#7-1-3-认识非线性问题" class="headerlink" title="7.1.3 认识非线性问题"></a>7.1.3 认识非线性问题</h4><p>在明白了线性问题之后，接着介绍非线性问题。</p>
<p>非线性问题，就是用直线分不开的问题。为了解释这个概念，先来看一个数据集异或形态的数据，如图7-7所示。</p>
<p>图7-7中只有4个点，蓝色为一类，红色为一类，蓝色两个点的连线与红色两个点的连线会相交。对于这样的数据，你会发现无法使用一条直线将红色和蓝色两种类型的点分开，这就是非线性数据。</p>
<p>对于这样的数据，有一种笨方法，即对原始数据变形，使其变为线性分布。例如，将数据x1、x2进行一次绝对值运算，这时数据就会变为如图7-8所示的样子。</p>
<p><img src="Image00109.jpg" alt></p>
<p>图7-7 异或形态的数据</p>
<p><img src="Image00110.jpg" alt></p>
<p>图7-8 改变输入数据</p>
<p>类似图7-8的方法有很多种，还可以将其进行一次平方运算。但这一切都是在人们肉眼看到模型分布后，通过分析得来的。而实际应用中会遇到更复杂的非线性数据集（如图7-9所示），或者有时数据维度太大，根本无法可视化。这时就需要用一种新方法——多层神经网络来解决问题了。</p>
<p><img src="Image00111.jpg" alt></p>
<p>图7-9 非线性数据集</p>
<h3 id="7-2-使用隐藏层解决非线性问题"><a href="#7-2-使用隐藏层解决非线性问题" class="headerlink" title="7.2 使用隐藏层解决非线性问题"></a>7.2 使用隐藏层解决非线性问题</h3><p>多层神经网络非常好理解，就是在输入和输出中间多加些神经元，每一层可以加多个，也可以加很多层。下面通过一个例子将前面的异或数据进行分类。</p>
<h4 id="7-2-1-实例30：使用带隐藏层的神经网络拟合异或操作"><a href="#7-2-1-实例30：使用带隐藏层的神经网络拟合异或操作" class="headerlink" title="7.2.1 实例30：使用带隐藏层的神经网络拟合异或操作"></a>7.2.1 实例30：使用带隐藏层的神经网络拟合异或操作</h4><p>实例描述</p>
<p>通过构建符合异或规律的数据集作为模拟样本，构建一个简单的多层神经网络来拟合其样本特征完成分类任务。</p>
<p>1．数据集介绍</p>
<p>所谓的“异或数据”是来源于异或操作，如图7-10所示。图7-10a为0、1操作，图7-10b为数据在直角坐标系上的展示。</p>
<p><img src="Image00112.jpg" alt></p>
<p>图7-10 异或数据介绍</p>
<p>从图7-10a中可以看出，当两个数相同时，输出为0，不相同时输出为1，这就是异或的规则。表示为两类数据就是（0，0）和（1，1）为一类，（0，1）和（1，0）为一类。</p>
<p>2．网络模型介绍</p>
<p>本例中使用了一个隐藏层来解决这个问题，如图7-11所示为要实现的网络结构。</p>
<p><img src="Image00113.jpg" alt></p>
<p>图7-11 隐藏层</p>
<p>3．定义变量</p>
<p>下面开始编写代码。第一步定义变量，在网络参数的定义中，输入是“2”代表两个数，输出是“1”代表最终的结果，再放一个隐藏层，该隐藏层里有两个节点。输入占位符为x，输出为y，学习率为0.0001。</p>
<p>代码7-3 异或操作</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">learning_rate = 1e-4</span><br><span class="line">n_input  = 2                   #输入层节点个数</span><br><span class="line">n_label  = 1</span><br><span class="line">n_hidden = 2                  #隐藏层节点个数</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [None,n_input])</span><br><span class="line">y = tf.placeholder(tf.float32, [None, n_label])</span><br></pre></td></tr></table></figure>

</details>

<p>4．定义学习参数</p>
<p>这里以字典的方式定义权重w和b，里面的h1代表隐藏层，h2代表最终的输出层。</p>
<p>代码7-3 异或操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">weights = &#123;</span><br><span class="line">    &apos;h1&apos;: tf.Variable(tf.truncated_normal([n_input, n_hidden], </span><br><span class="line">   stddev=0.1)),</span><br><span class="line">    &apos;h2&apos;: tf.Variable(tf. truncated_normal ([n_hidden, n_label], </span><br><span class="line">   stddev=0.1))</span><br><span class="line">&#125; </span><br><span class="line">biases = &#123;</span><br><span class="line">    &apos;h1&apos;: tf.Variable(tf.zeros([n_hidden])),</span><br><span class="line">    &apos;h2&apos;: tf.Variable(tf.zeros([n_label]))</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

</details>

<p>5．定义网络模型</p>
<p>该例中模型的正向结构入口为x，经过与第一层的w相乘再加上b，通过Relu函数进行激活转化，最终生成layer_1，再将layer_1代入第二层，使用Tanh激活函数生成最终的输出y_pred。</p>
<p>代码7-3 异或操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights[&apos;h1&apos;]), biases</span><br><span class="line">[&apos;h1&apos;]))</span><br><span class="line"> y_pred = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights[&apos;h2&apos;]),</span><br><span class="line">biases[&apos;h2&apos;]))</span><br><span class="line">   </span><br><span class="line"> loss=tf.reduce_mean((y_pred-y)**2)</span><br><span class="line"> train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)</span><br></pre></td></tr></table></figure>

</details>

<p>模型的反向使用均值平方差（即对预测值与真实值的差取平均值）计算loss，最终使用AdamOptimizer进行优化。</p>
<p>6．构建模拟数据</p>
<p>代码7-3 异或操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#生成数据</span><br><span class="line">X=[[0,0],[0,1],[1,0],[1,1]]</span><br><span class="line">Y=[[0],[1],[1],[0]]</span><br><span class="line">X=np.array(X).astype(&apos;float32&apos;)</span><br><span class="line">Y=np.array(Y).astype(&apos;int16&apos;)</span><br></pre></td></tr></table></figure>

</details>

<p>手动建立X和Y数据集，形成对应的异或关系。</p>
<p>7．运行session，生成结果</p>
<p>首先通过迭代10000次，将模型训练出来，然后将做好的X数据集放进去生成结果，接着再生成第一层的结果。</p>
<p>代码7-3 异或操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#加载session</span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">#训练</span><br><span class="line">for i in range(10000):</span><br><span class="line">    sess.run(train_step,feed_dict=&#123;x:X,y:Y&#125; )</span><br><span class="line">     </span><br><span class="line">#计算预测值</span><br><span class="line">print(sess.run(y_pred,feed_dict=&#123;x:X&#125;))</span><br><span class="line">#输出：已训练100000次</span><br><span class="line">       </span><br><span class="line">#查看隐藏层的输出</span><br><span class="line">print(sess.run(layer_1,feed_dict=&#123;x:X&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的程序，得到如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> [[ 0.10773809]</span><br><span class="line"> [ 0.60417336]</span><br><span class="line"> [ 0.76470393]</span><br><span class="line"> [ 0.26959091]]</span><br><span class="line">[[  0.00000000e+00   2.32602470e-05]</span><br><span class="line"> [  7.25074887e-01   0.00000000e+00]</span><br><span class="line"> [  0.00000000e+00   9.64471161e-01]</span><br><span class="line"> [  2.06250161e-01   1.69421546e-05]]</span><br></pre></td></tr></table></figure>

</details>

<p>第一个是4行1列的数组，用四舍五入法来取值，与我们定义的输出Y完全吻合。第二个为4行2列的数组，为隐藏层的输出。</p>
<h4 id="7-2-2-非线性网络的可视化及其意义"><a href="#7-2-2-非线性网络的可视化及其意义" class="headerlink" title="7.2.2 非线性网络的可视化及其意义"></a>7.2.2 非线性网络的可视化及其意义</h4><p>接上例中的第二个输出是4行2列数组，其中第一列为隐藏层第一个节点的输出，第二列为隐藏层第二个节点的输出，将它们四舍五入取整显示如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[  0   0]</span><br><span class="line">[  1   0]</span><br><span class="line">[  0  1]</span><br><span class="line">[  0   0]]</span><br></pre></td></tr></table></figure>

</details>

<p>可以很明显地看出，最后一层其实是对隐藏层的AND运算，因为最终结果为[0，1，1，0]。也可以理解成第一成将数据转化为线性可分的数据集，然后在输出层使用一个神经元将其分开。</p>
<p>1．隐藏层神经网络相当于线性可分的高维扩展</p>
<p>在几何空间里，两个点可以定位一条直线，两条直线可以定位一个平面，两个平面可以定位一个三维空间，两个三维空间可以定位更高维的空间……</p>
<p>在线性可分问题上也可以这样扩展，线性可分是在一个平面里，通过一条线来分类，那么同理，如果线所在的平面升级到了三维空间，则需要通过一个平面将问题分类。如图7-12所示，把异或数据集的输入x1、x2当成平面的两个点，输出y当作三维空间里的z轴上的坐标，那么所绘制的图形就是这样的（见图7-12）。</p>
<p>很明显，这样的数据集是很好分开的。图7-12中，右面的比例尺指示的是纵坐标。0刻度往下，颜色由浅蓝逐渐变为深蓝；0刻度往上，颜色由浅红逐渐变为深红。作一个平行于底平面、高度为0的平面，即可将数据分开，如图7-12中的虚平面。我们前面使用的隐藏层的两个节点，可以理解成定位中间平面的两条直线。其实，一个隐藏层的作用，就是将线性可分问题转化成平面可分问题。更多的隐藏层，就相当于转化成更高维度的空间可分问题。所以理论上通过升级空间可分的结构，是可以将任何问题分开的。</p>
<p><img src="Image00114.jpg" alt></p>
<p>图7-12 异或集高维展示</p>
<p>2．从逻辑门的角度来理解多层网络</p>
<p>对于多层网络，还可以通过逻辑门的角度来理解，如图7-13所示。将数据集映射到直角坐标系中，通过可视化图形可以看到，在直角坐标系中有两条直线将其分开，对于两条直线的结果，可以再通过神经网络构建一个逻辑运算，即可将它们融合在一起并产生最终想要的结果。</p>
<p><img src="Image00115.jpg" alt></p>
<p>图7-13 隐藏层的意义</p>
<p>图7-13中，对两条直线的结果取AND运算，即可实现异或的效果，而构建AND逻辑的权重很容易实现，图中使用w[-30，20]，b[20]即实现了AND的逻辑。</p>
<p>类似这样的逻辑门还有很多，如图7-14中举例了神经元实现的AND、OR、NOT逻辑，最终通过这些逻辑门的运算，甚至不需要训练就可以搭建出一个异或的模型（如图7-14所示部分）。</p>
<p><img src="Image00116.jpg" alt></p>
<p>图7-14 逻辑门</p>
<p>看到这里，了解计算机原理的读者都知道，CPU的基础运算都是在构建逻辑门基础之上完成的，例如，用逻辑门组成最基本的加减乘除四则运算，再用四则运算组成更复杂的功能操作，最终可以实现操作系统并在其上进行各种操作。</p>
<p>神经网络的结构和功能，使其具有编程和实现各种高级功能的能力，只不过这个编程不需要人脑通过学习算法来拟合现实，而是使用模型学习的方式，直接从现实的表象中优化成需要的结构。</p>
<p>所以说，这种多层的结构只要层数足够多，每层的节点足够多，参数合理，就可以拟合世界上的任何问题，而放在神经网络里考验的则是，模型的自学习功能是否足够高效和精准。</p>
<h4 id="7-2-3-练习题"><a href="#7-2-3-练习题" class="headerlink" title="7.2.3 练习题"></a>7.2.3 练习题</h4><p>（1）试着修改7.2.1节中的例子，调整最后一层的激活函数为Relu或是Sigmoid，看看会有什么结果（Sigmoid可以，但是Relu陷入了局部最优解，如果迭代次数增到20000，全0，即梯度丢失。于是可以使用Leaky relus，发现在10000、20000、30000时都会进入局部最优解，但再也不会出现梯度消失，将迭代次数变为40000时，得到了正确的模型）。</p>
<p>（2）试着将7.2.1节中的例子的数据集修改成one_hot编码来进行拟合，利用所学的知识看看可以用几种方法来实现（可参考本书源代码中的代码“7-4 异或one_hot.py”文件）。</p>
<h3 id="7-3-实例31：利用全连接网络将图片进行分类"><a href="#7-3-实例31：利用全连接网络将图片进行分类" class="headerlink" title="7.3 实例31：利用全连接网络将图片进行分类"></a>7.3 实例31：利用全连接网络将图片进行分类</h3><p>本例使用全连接网络，将第5章中的例子重新实现一遍，将MNIST图像用多层神经网络来分类。</p>
<p>实例描述</p>
<p>构建一个简单的多层神经网络，以拟合MNIST样本特征完成分类任务。</p>
<p>1．定义网络参数</p>
<p>在输入和输出之间使用两个隐藏层，每层各256个节点，学习率使用0.001。</p>
<p>代码7-5 MNIST多层分类</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 定义参数</span><br><span class="line">learning_rate = 0.001</span><br><span class="line">training_epochs = 25</span><br><span class="line">batch_size = 100</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line"># 设置网络模型参数</span><br><span class="line">n_hidden_1 = 256                # 第一个隐藏层节点个数</span><br><span class="line">n_hidden_2 = 256                # 第二个隐藏层节点个数</span><br><span class="line">n_input = 784                    # MNIST 共784 (28×28)维</span><br><span class="line">n_classes = 10                   # MNIST 共10个类别 (0～9)</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义网络结构</p>
<p>multilayer_perceptron函数为封装好的网络模型函数，第一层与第二层均使用Relu激活函数，loss使用softmax交叉熵。具体代码如下。</p>
<p>代码7-5 MNIST多层分类（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"> #定义占位符</span><br><span class="line"> x = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line"> y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"> </span><br><span class="line"> # 创建model</span><br><span class="line"> def multilayer_perceptron(x, weights, biases):</span><br><span class="line">     # 第一层隐藏层</span><br><span class="line">     layer_1 = tf.add(tf.matmul(x, weights[&apos;h1&apos;]), biases[&apos;b1&apos;])</span><br><span class="line">     layer_1 = tf.nn.relu(layer_1)</span><br><span class="line">     # 第二层隐藏层</span><br><span class="line">     layer_2 = tf.add(tf.matmul(layer_1, weights[&apos;h2&apos;]), biases[&apos;b2&apos;])</span><br><span class="line">     layer_2 = tf.nn.relu(layer_2)</span><br><span class="line">     # 输出层</span><br><span class="line">     out_layer = tf.matmul(layer_2, weights[&apos;out&apos;]) + biases[&apos;out&apos;]</span><br><span class="line">     return out_layer</span><br><span class="line">     </span><br><span class="line"> # 学习参数</span><br><span class="line"> weights = &#123;</span><br><span class="line">     &apos;h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">     &apos;h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">     &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_classes]))</span><br><span class="line"> &#125;</span><br><span class="line"> biases = &#123;</span><br><span class="line">     &apos;b1&apos;: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">     &apos;b2&apos;: tf.Variable(tf.random_normal([n_hidden_2])),</span><br><span class="line">     &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> # 输出值</span><br><span class="line"> pred = multilayer_perceptron(x, weights, biases)</span><br><span class="line"> </span><br><span class="line"> # 定义loss和优化器</span><br><span class="line"> cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits</span><br><span class="line">(logits=pred, labels=y))</span><br><span class="line"> optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).</span><br><span class="line">minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>3．运行session输出结果</p>
<p>session运行的代码参见第5章实例，运行结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 166.257328408</span><br><span class="line">Epoch: 0002 cost= 39.961055286</span><br><span class="line">……</span><br><span class="line">Epoch: 0023 cost= 0.335092138</span><br><span class="line">Epoch: 0024 cost= 0.289653350</span><br><span class="line">Epoch: 0025 cost= 0.286943634</span><br><span class="line"> Finished!</span><br><span class="line">Accuracy: 0.957</span><br></pre></td></tr></table></figure>

</details>

<p>全连接网络可以成功地将图片进行分类，并且随着层数的增加和节点的增多，还能够得到更好的拟合效果。</p>
<p><img src="Image00014.jpg" alt> 注意： 由于神经网络的学习算法限制，在实际情况中并不是层数越多、节点越多，效果就越好，因为在训练过程中使用的BP算法，会随着层数的逐渐增大其算出来的调整值会逐渐变小，直到其他层都感觉不到变化，即梯度消失的情况。</p>
<h3 id="7-4-全连接网络训练中的优化技巧"><a href="#7-4-全连接网络训练中的优化技巧" class="headerlink" title="7.4 全连接网络训练中的优化技巧"></a>7.4 全连接网络训练中的优化技巧</h3><p>随着科研人员在使用神经网络训练时不断的尝试，为我们留下了好多有用的技巧，合理地运用这些技巧可以使自己的模型得到更好的拟合效果。本节就来介绍下全连接网络在训练过程中的一些常用技巧。</p>
<h4 id="7-4-1-实例32：利用异或数据集演示过拟合问题"><a href="#7-4-1-实例32：利用异或数据集演示过拟合问题" class="headerlink" title="7.4.1 实例32：利用异或数据集演示过拟合问题"></a>7.4.1 实例32：利用异或数据集演示过拟合问题</h4><p>全连接网络虽然在拟合问题上比较强大，但太强大的拟合效果也带来了其他的麻烦，这就是过拟合问题。什么是过拟合呢？</p>
<p>首先来看一个例子，这次将原有的4个异或数据扩充成上百个具有异或特征的数据集，通过全连接网络将它们进行分类。具体步骤如下：</p>
<p>实例描述</p>
<p>构建异或数据集模拟样本，再构建一个简单的多层神经网络来拟合其样本特征，观察其出现欠拟合的现象，接着通过增大网络复杂性的方式来优化欠拟合问题，使其出现过拟合现象。</p>
<p>1．构建异或数据集</p>
<p>参照代码“7-2线性多分类.py”文件中的生成模拟数据代码，调用generate函数生成4类数据，然后将其中的两类数据合并。</p>
<p>代码7-6 异或集的过拟合</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(10)</span><br><span class="line"></span><br><span class="line">input_dim = 2</span><br><span class="line">num_classes =4 </span><br><span class="line">X, Y = generate(320,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],True)</span><br><span class="line">Y=Y%2</span><br><span class="line"></span><br><span class="line">xr=[]</span><br><span class="line">xb=[]</span><br><span class="line">for(l,k) in zip(Y[:],X[:]):</span><br><span class="line">    if l == 0.0 :</span><br><span class="line">        xr.append([k[0],k[1]])        </span><br><span class="line">    else:</span><br><span class="line">        xb.append([k[0],k[1]])</span><br><span class="line">xr =np.array(xr)</span><br><span class="line">xb =np.array(xb)      </span><br><span class="line">plt.scatter(xr[:,0], xr[:,1], c=&apos;r&apos;,marker=&apos;+&apos;)</span><br><span class="line">plt.scatter(xb[:,0], xb[:,1], c=&apos;b&apos;,marker=&apos;o&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，可以看到数据集的结构如图7-15所示。</p>
<p><img src="Image00117.jpg" alt></p>
<p>图7-15 异或数据集输出</p>
<p>可以看到，图7-15中的数据分为两类，其中左下和右上是一类（红色用+表示），左上和右下是另一类（蓝色用·表示）。</p>
<p>2．修改定义网络模型</p>
<p>这里还沿用代码“7-3异或.py”文件里的代码，不用改动，只需要把原来的异或数据集注释掉即可（代码略）。</p>
<p>3．添加可视化</p>
<p>这里生成120个点并放到模型里，然后将其在直角坐标系中显示出来。</p>
<p>代码7-6 异或集的过拟合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">  xTrain, yTrain = generate(120,num_classes, [[3.0,0],[3.0,3.0],[0,3.0]], </span><br><span class="line">True)</span><br><span class="line">  yTrain=yTrain%2</span><br><span class="line">  xr=[]</span><br><span class="line">  xb=[]</span><br><span class="line">  for(l,k) in zip(yTrain[:],xTrain[:]):</span><br><span class="line">      if l == 0.0 :</span><br><span class="line">          xr.append([k[0],k[1]])        </span><br><span class="line">      else:</span><br><span class="line">          xb.append([k[0],k[1]])</span><br><span class="line">  xr =np.array(xr)</span><br><span class="line">  xb =np.array(xb)      </span><br><span class="line">  plt.scatter(xr[:,0], xr[:,1], c=&apos;r&apos;,marker=&apos;+&apos;)</span><br><span class="line">  plt.scatter(xb[:,0], xb[:,1], c=&apos;b&apos;,marker=&apos;o&apos;)</span><br><span class="line">  yTrain=np.reshape(yTrain,[-1,1])           </span><br><span class="line">  print (&quot;loss:\n&quot;, sess.run(loss, feed_dict=&#123;x: xTrain, y: yTrain&#125;)) </span><br><span class="line">  </span><br><span class="line">  nb_of_xs = 200</span><br><span class="line">  xs1 = np.linspace(-1, 8, num=nb_of_xs)</span><br><span class="line">  xs2 = np.linspace(-1, 8, num=nb_of_xs)</span><br><span class="line">  xx, yy = np.meshgrid(xs1, xs2) # 创建grid</span><br><span class="line">  # 初始和填充 classification plane</span><br><span class="line">  classification_plane = np.zeros((nb_of_xs, nb_of_xs))</span><br><span class="line">  for i in range(nb_of_xs):</span><br><span class="line">      for j in range(nb_of_xs):</span><br><span class="line">          classification_plane[i,j] = sess.run(y_pred, feed_dict=&#123;x: </span><br><span class="line">         [[ xx[i,j], yy[i,j] ]]&#125; )</span><br><span class="line">          classification_plane[i,j] = int(classification_plane[i,j])</span><br><span class="line">  </span><br><span class="line">  # 创建一个color map用来显示每一个格子的分类颜色</span><br><span class="line">  cmap = ListedColormap([</span><br><span class="line">          colorConverter.to_rgba(&apos;r&apos;, alpha=0.30),</span><br><span class="line">          colorConverter.to_rgba(&apos;b&apos;, alpha=0.30)])</span><br><span class="line">  # 图示样本的分类边界</span><br><span class="line">  plt.contourf(xx, yy, classification_plane, cmap=cmap)</span><br><span class="line">  plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，得到如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.50001</span><br><span class="line">Step: 1000 Current loss: 0.359438</span><br><span class="line">……</span><br><span class="line">Step: 10000 Current loss: 0.204833</span><br><span class="line">Step: 11000 Current loss: 0.204797</span><br><span class="line">Step: 12000 Current loss: 0.204775</span><br><span class="line">Step: 13000 Current loss: 0.204766</span><br><span class="line">Step: 14000 Current loss: 0.204765</span><br><span class="line">Step: 15000 Current loss: 0.204765</span><br><span class="line">Step: 16000 Current loss: 0.204765</span><br><span class="line">Step: 17000 Current loss: 0.204765</span><br><span class="line">Step: 18000 Current loss: 0.204765</span><br><span class="line">Step: 19000 Current loss: 0.204765</span><br><span class="line">loss:</span><br><span class="line"> 0.204765</span><br></pre></td></tr></table></figure>

</details>

<p>可视化后生成的数据集结构如图7-16所示。</p>
<p><img src="Image00118.jpg" alt></p>
<p>图7-16 失败模型</p>
<p>可以看到，模型在迭代训练10000次之后停止了梯度，而且loss值约为20%，准确率不高，所可视化的图片也没有将数据完全分开。</p>
<p>4．欠拟合定义</p>
<p>如图7-16所示的这种效果就叫做欠拟合，即没有完全拟合到想要得到的真实数据情况。</p>
<p>5．修正模型提高拟合度</p>
<p>欠拟合的原因并不是模型不行，而是我们的学习方法无法更精准地学习到适合的模型参数。模型越薄弱，对训练的要求就越高。但是可以采用增加节点或增加层的方式，让模型具有更高的拟合性，从而降低模型的训练难度。</p>
<p>将隐藏层的节点提高到200，代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_hidden = 200</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后显示如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.510105</span><br><span class="line">Step: 1000 Current loss: 0.0951028</span><br><span class="line">……</span><br><span class="line">Step: 15000 Current loss: 0.0477655</span><br><span class="line">Step: 16000 Current loss: 0.0463676</span><br><span class="line">Step: 17000 Current loss: 0.0451465</span><br><span class="line">Step: 18000 Current loss: 0.043569</span><br><span class="line">Step: 19000 Current loss: 0.0421998</span><br></pre></td></tr></table></figure>

</details>

<p>可视化后生成的数据集结构如图7-17所示。</p>
<p><img src="Image00119.jpg" alt></p>
<p>图7-17 过拟合</p>
<p>从7-17中可以看到强大的全连接网络，仅仅通过一个隐藏层，使用200个点就可以将数据划分得这么细致。而loss值也在逐渐变小，20000次之后变为0.04。</p>
<p>6．验证过拟合</p>
<p>那么对于上面的模型好不好呢？我们再取少量的数据（12个）放到模型里验证一下，然后用同样的方式在坐标系中可视化（可视化代码部分同上）。</p>
<p>代码7-6 异或集的过拟合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">  xTrain, yTrain = generate(12,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]], </span><br><span class="line">True)</span><br><span class="line">  yTrain=yTrain%2</span><br><span class="line">  xr=[]</span><br><span class="line">  xb=[]</span><br><span class="line">  for(l,k) in zip(yTrain[:],xTrain[:]):</span><br><span class="line">      if l == 0.0 :</span><br><span class="line">          xr.append([k[0],k[1]])        </span><br><span class="line">      else:</span><br><span class="line">          xb.append([k[0],k[1]])</span><br><span class="line">  xr =np.array(xr)</span><br><span class="line">  xb =np.array(xb)      </span><br><span class="line">  plt.scatter(xr[:,0], xr[:,1], c=&apos;r&apos;,marker=&apos;+&apos;)</span><br><span class="line">  plt.scatter(xb[:,0], xb[:,1], c=&apos;b&apos;,marker=&apos;o&apos;)</span><br><span class="line">  yTrain=np.reshape(yTrain,[-1,1])           </span><br><span class="line">  print (&quot;loss:\n&quot;, sess.run(loss, feed_dict=&#123;x: xTrain, y: yTrain&#125;))</span><br><span class="line">  #可视化部分</span><br><span class="line">  ……</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss:</span><br><span class="line"> 0.149396</span><br></pre></td></tr></table></figure>

</details>

<p>可视化后生成的数据集结构如图7-18所示。</p>
<p><img src="Image00120.jpg" alt></p>
<p>图7-18 过拟合验证</p>
<p>由图7-18可以看出，loss飙到了14%，并没有原来训练时那么好（4%），模型还是原来的模型，但是这次却框住了少量的样本。这种现象就是过拟合。它与欠拟合一样都是我们在训练模型中不愿意看到的现象，我们要的是真正的拟合在测试情况下能够表现出训练时的良好效果。</p>
<p>避免过拟合的方法有很多：常用的方法有early stopping、数据集扩增、正则化、dropout等。</p>
<p>·early stopping：在发生过拟合之前提前结束训练。理论上是可以的，但是这个点不好把握。</p>
<p>·数据集扩增（data augmentation）：就是让模型见到更多的情况，可以最大化地满足全样本，但实际应用中对于未来事件的预测却显得鞭长莫及。</p>
<p>·正则化（regularization）：是通过引入范数的概念，增强模型的泛化能力，包括L1、L2（L2 regularization也叫weight decay）。</p>
<p>·dropout：是网络模型中的一种方法，每次训练时舍去一些节点来增强泛化能力。</p>
<p>下面重点介绍一下后两种方法。</p>
<h4 id="7-4-2-正则化"><a href="#7-4-2-正则化" class="headerlink" title="7.4.2 正则化"></a>7.4.2 正则化</h4><p>本节将开始学习正则化技巧。</p>
<p>1．什么是正则化</p>
<p>所谓的正则化，其实就是在神经网络计算损失值的过程中，在损失后面再加一项。这样损失值所代表的输出与标准结果间的误差就会受到干扰，导致学习参数w和b无法按照目标方向来调整，实现模型无法与样本完全拟合的结果，从而达到防止过拟合的效果。</p>
<p>理解了原理之后，现在就来介绍如何添加这个干扰项。干扰项一定要有这样的特性：</p>
<p>·当欠拟合时，希望它对模型误差的影响越小越好，以便让模型快速拟合实际。</p>
<p>·如果是过拟合时，希望它对模型误差的影响越大越好，以便让模型不要产生过拟合的情况。</p>
<p>由此引入了两个范数L1和L2：</p>
<p>·L1：所有学习参数w的绝对值的和。</p>
<p>·L2：所有学习参数w的平方和然后求平方根。</p>
<p>如果放到损失函数的公式里，会将其变形一下，如式（7-1）和式（7-2）所示，其中式（7-1）为L1，式（7-2）为L2。</p>
<p><img src="Image00121.jpg" alt></p>
<p><img src="Image00122.jpg" alt></p>
<p>最终的loss为等式左边的结果，less（0）代表真实的loss值，less（0）后面的那一项就代表正则化了，λ为一个可以调节的参数，用来控制正则化对loss的影响。</p>
<p>对于L2，将其乘以1/2是为了反向传播时对其求导正好可以将数据规整。</p>
<p>2．TensorFlow中的正则化</p>
<p>对于上面的公式，读者了解一下就可以了。因为TensorFlow中已经有封装好的函数可以拿来直接使用。</p>
<p>L2的正则化函数为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.l2_loss(t, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>L1的正则化函数目前在TensorFlow中没有现成的，可以自己组合为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_sum( tf.abs(w))</span><br></pre></td></tr></table></figure>

</details>

<h4 id="7-4-3-实例33：通过正则化改善过拟合情况"><a href="#7-4-3-实例33：通过正则化改善过拟合情况" class="headerlink" title="7.4.3 实例33：通过正则化改善过拟合情况"></a>7.4.3 实例33：通过正则化改善过拟合情况</h4><p>了解完过拟合的解决方法后，现在就来给前面的代码“7-6异或集的过拟合.py”文件添加正则化的处理。代码非常简单，只需要在计算损失值时加上loss的正则化，例子中，使用的λ为0.01，添加的是L2_loss，代码如下。</p>
<p>实例描述</p>
<p>构建异或数据集模拟样本，使用多层神经网络将其分类，并使用正则化技术来改善过拟合情况。</p>
<p>代码7-7 异或集的L2_loss</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> reg = 0.01                #l2_loss参数</span><br><span class="line"> loss=tf.reduce_mean((y_pred-y)**2)+tf.nn.l2_loss(weights[&apos;h1&apos;])</span><br><span class="line">*reg+tf.nn.l2_loss(weights[&apos;h2&apos;])*reg</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>其他的地方都不用动，运行代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.520193</span><br><span class="line">……</span><br><span class="line">Step: 16000 Current loss: 0.0913737</span><br><span class="line">Step: 17000 Current loss: 0.0913519</span><br><span class="line">Step: 18000 Current loss: 0.0913312</span><br><span class="line">Step: 19000 Current loss: 0.0913115</span><br><span class="line"> </span><br><span class="line">loss:</span><br><span class="line"> 0.10637</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出，虽然训练的loss值增加了一些，变成了0.09，但是模型的测试loss却由0.15降到了0.1，比以前进步了不少。可视化后生成的模型如图7-19所示。</p>
<p><img src="Image00123.jpg" alt></p>
<p>图7-19 正则化模型</p>
<p>图7-19中，左边为模型在训练时的结果，右边为测试时的结果。图中的蓝色区域比起前面的例子不再是单独封闭的区间了。</p>
<h4 id="7-4-4-实例34：通过增大数据集改善过拟合"><a href="#7-4-4-实例34：通过增大数据集改善过拟合" class="headerlink" title="7.4.4 实例34：通过增大数据集改善过拟合"></a>7.4.4 实例34：通过增大数据集改善过拟合</h4><p>下面再试试通过增大数据集的方式来改善过拟合情况，这里不再生成一次样本，而是每次循环都生成1000个数据，来看看会发生什么。修改代码如下。</p>
<p>实例描述</p>
<p>构建异或数据集模拟样本，使用多层神经网络将其分类，并使用增大数据集的方法来改善过拟合情况。</p>
<p>在循环训练中，在for循环里的sess.run之前添加生成数据的代码，每次取1000个点。</p>
<p>代码7-7 异或集的L2_loss（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for i in range(20000):#生成异或数据集</span><br><span class="line"></span><br><span class="line">    X, Y = generate(1000,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],</span><br><span class="line">   True)</span><br><span class="line">    Y=Y%2</span><br><span class="line">    Y=np.reshape(Y,[-1,1])</span><br><span class="line">  </span><br><span class="line">    _, loss_val = sess.run([train_step, loss], feed_dict=&#123;x: X, y: Y&#125;)</span><br></pre></td></tr></table></figure>

</details>

<p>其他地方都不用动，运行代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.399712</span><br><span class="line">Step: 1000 Current loss: 0.141141</span><br><span class="line">……</span><br><span class="line">Step: 17000 Current loss: 0.0992013</span><br><span class="line">Step: 18000 Current loss: 0.0991972</span><br><span class="line">Step: 19000 Current loss: 0.0991939</span><br><span class="line">loss:</span><br><span class="line"> 0.09075</span><br></pre></td></tr></table></figure>

</details>

<p>这次得到的模型测试值直接降到了0.9，比训练时还低。所生成的模型可视化如图7-20所示。</p>
<p><img src="Image00124.jpg" alt></p>
<p>图7-20 增大数据集</p>
<p>如图7-20所示增加数据集之后，发现蓝色区域比之前变得更大了，泛化效果也有了明显的提示。</p>
<h4 id="7-4-5-练习题"><a href="#7-4-5-练习题" class="headerlink" title="7.4.5 练习题"></a>7.4.5 练习题</h4><p>试着使用L1_loss来改善过拟合现象，看看效果。</p>
<h4 id="7-4-6-dropout——训练过程中，将部分神经单元暂时丢弃"><a href="#7-4-6-dropout——训练过程中，将部分神经单元暂时丢弃" class="headerlink" title="7.4.6 dropout——训练过程中，将部分神经单元暂时丢弃"></a>7.4.6 dropout——训练过程中，将部分神经单元暂时丢弃</h4><p>还有一种常用的手段叫做dropout，也是用来防止过拟合的。</p>
<p>1．dropout原理</p>
<p>还有一种常用的改善过拟合的方法dropout。dropout的意思是，在训练过程中，每次随机选择一部分节点不要去“学习”。</p>
<p>这样做的原理是什么呢？</p>
<p>因为从样本数据的分析来看，数据本身是不可能很纯净的，即任何一个模型不能100%把数据完全分开，在某一类中一定会有一些异常数据，过拟合的问题恰恰是把这些异常数据当成规律来学习了。对于模型来讲，我们希望它能够有一定的“智商”，把异常数据过滤掉，只关心有用的规律数据。</p>
<p>异常数据的特点是，它与主流样本中的规律都不同，但是量非常少，相当于在一个样本中出现的概率比主流数据出现的概率低很多。我们就是利用这个特性，通过在每次模型中忽略一些节点的数据学习，将小概率的异常数据获得学习的机会降低，这样这些异常数据对模型的影响就会更小了。</p>
<p><img src="Image00014.jpg" alt> 注意： 由于dropout让一部分节点不去“学习”，所以在增加模型的泛化能力的同时，会使学习速度降低，使模型不太容易“学成”，所以在使用的过程中需要合理地调节到底丢弃多少节点，并不是丢弃的节点越多越好。</p>
<p>2．TensorFlow中的dropout</p>
<p>在TensorFlow中dropout的函数原型如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def dropout(x, keep_prob, noise_shape=None, seed=None, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>其中的参数意义如下。</p>
<p>·X：输入的模型节点。</p>
<p>·keep_prob：保持率。如果为1，则代表全部进行学习；如果为0.8，则代表丢弃20%的节点，只让80%的节点参与学习。</p>
<p>·noise_shape：代表指定x中，哪些维度可以使用dropout技术。为None时，表示所有维度都使用dropout技术。也可以将某个维度标志为1，来代表该维度使用dropout技术。例如：x的形状为[n，len，w，ch]，使用noise_shape为[n，1，1，ch]，这表明会对x中的第二维度len和第三维度w进行dropout。</p>
<p>·seed：随机选取节点的过程中随机数的种子值。</p>
<p><img src="Image00014.jpg" alt> 注意： dropout改变了神经网络的网络结构，它仅仅是属于训练时的方法，所以一般在进行测试时要将dropout的keep_prob变为1，代表不需要进行丢弃，否则会影响模型的正常输出。</p>
<h4 id="7-4-7-实例35：为异或数据集模型添加dropout"><a href="#7-4-7-实例35：为异或数据集模型添加dropout" class="headerlink" title="7.4.7 实例35：为异或数据集模型添加dropout"></a>7.4.7 实例35：为异或数据集模型添加dropout</h4><p>本例在代码“7-7 异或集的L2_loss.py”文件的基础上进行修改，为了体现效果，把原来的l2_loss去掉（实际过程中可以两个方法一起使用）。</p>
<p>实例描述</p>
<p>构建异或数据集模拟样本，使用多层神经网络将其分类，并使用dropout技术来改善过拟合情况。</p>
<p>如下代码，在layer_1后面添加一个dropout层，将dropout的keep_prob设为占位符，这样可以在运行时随时指定keep_prob，在session的run中指定keep_prob为0.6，这意味着每次训练将仅允许0.6的节点参与学习运算。由于学习速度慢了，所以要将学习率调大些，变成0.01，加快训练。</p>
<p>另外，在测试时别忘了一定要将keep_prob调成1。</p>
<p>代码7-8 异或集dropout</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> learning_rate = 0.01#1e-4</span><br><span class="line"> ……</span><br><span class="line"> layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights[&apos;h1&apos;]), biases</span><br><span class="line">[&apos;h1&apos;]))</span><br><span class="line"> </span><br><span class="line"> keep_prob = tf.placeholder(&quot;float&quot;)</span><br><span class="line"> layer_1_drop = tf.nn.dropout(layer_1, keep_prob)</span><br><span class="line"> </span><br><span class="line"> #Leaky relus激活函数</span><br><span class="line"> layer2 =tf.add(tf.matmul(layer_1_drop, weights[&apos;h2&apos;]),biases[&apos;h2&apos;])</span><br><span class="line"> y_pred = tf.maximum(layer2,0.01*layer2)</span><br><span class="line"> ……</span><br><span class="line"> for i in range(20000):</span><br><span class="line"> </span><br><span class="line">     X, Y = generate(1000,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],</span><br><span class="line">    True)</span><br><span class="line">     Y=Y%2</span><br><span class="line">     Y=np.reshape(Y,[-1,1])</span><br><span class="line">   </span><br><span class="line">     _, loss_val = sess.run([train_step, loss], feed_dict=&#123;x: X, y: Y,</span><br><span class="line">    keep_prob:0.6&#125;)</span><br><span class="line">     </span><br><span class="line">     if i % 1000 == 0:</span><br><span class="line">         print (&quot;Step:&quot;, i, &quot;Current loss:&quot;, loss_val)</span><br><span class="line"> ……</span><br><span class="line"> yTrain=np.reshape(yTrain,[-1,1])           </span><br><span class="line"> print (&quot;loss:\n&quot;, sess.run(loss, feed_dict=&#123;x: xTrain, y: yTrain,keep_</span><br><span class="line">prob:1.0&#125;))</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.503951</span><br><span class="line">Step: 1000 Current loss: 0.0896698</span><br><span class="line">Step: 2000 Current loss: 0.0923921</span><br><span class="line">Step: 3000 Current loss: 0.0912758</span><br><span class="line">Step: 4000 Current loss: 0.0885499</span><br><span class="line">Step: 5000 Current loss: 0.0899685</span><br><span class="line">Step: 6000 Current loss: 0.0923872</span><br><span class="line">Step: 7000 Current loss: 0.0922362</span><br><span class="line">Step: 8000 Current loss: 0.0920109</span><br><span class="line">Step: 9000 Current loss: 0.0918544</span><br><span class="line">Step: 10000 Current loss: 0.0894592</span><br><span class="line">Step: 11000 Current loss: 0.0899565</span><br><span class="line">Step: 12000 Current loss: 0.0939654</span><br><span class="line">Step: 13000 Current loss: 0.0950037</span><br><span class="line">Step: 14000 Current loss: 0.0922148</span><br><span class="line">Step: 15000 Current loss: 0.0934821</span><br><span class="line">Step: 16000 Current loss: 0.093902</span><br><span class="line">Step: 17000 Current loss: 0.0913219</span><br><span class="line">Step: 18000 Current loss: 0.0939114</span><br><span class="line">Step: 19000 Current loss: 0.0912721</span><br><span class="line">loss:</span><br><span class="line"> 0.0604928</span><br></pre></td></tr></table></figure>

</details>

<p>测试效果很不错！这次的模型测试loss比训练的loss值还要低，而且达到了0.06。这就是dropout的效果。</p>
<h4 id="7-4-8-实例36：基于退化学习率dropout技术来拟合异或数据集"><a href="#7-4-8-实例36：基于退化学习率dropout技术来拟合异或数据集" class="headerlink" title="7.4.8 实例36：基于退化学习率dropout技术来拟合异或数据集"></a>7.4.8 实例36：基于退化学习率dropout技术来拟合异或数据集</h4><p>从上面的结果可以看到，损失值在10000时是0.08，后来又涨到了0.09，尤其在最后几次，出现了抖动的现象，这表明后期的学习率有点大了。读者还记得前面学过的退化学习率吗？下面我们就在上面的例子中添加退化学习率，让开始的学习率很大，后面逐渐变小。</p>
<p>实例描述</p>
<p>构建异或数据集模拟样本，使用多层神经网络将其分类，并使用dropout配合退化学习率的技术来改善过拟合情况。</p>
<p>在使用优化器的代码部分添加decaylearning_rate，设置总步数为20000，每执行1000步，学习率衰减0.9，见如下代码。</p>
<p>代码7-8 异或集dropout（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> decaylearning_rate = tf.train.exponential_decay(learning_rate, </span><br><span class="line">global_step,1000, 0.9)</span><br><span class="line"> #train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)</span><br><span class="line"> train_step = tf.train.AdamOptimizer(decaylearning_rate).minimize</span><br><span class="line">(loss,global_step=global_step)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Step: 0 Current loss: 0.42503</span><br><span class="line">Step: 1000 Current loss: 0.0930188</span><br><span class="line">Step: 2000 Current loss: 0.0894333</span><br><span class="line">Step: 3000 Current loss: 0.0918793</span><br><span class="line">Step: 4000 Current loss: 0.0913094</span><br><span class="line">Step: 5000 Current loss: 0.0913863</span><br><span class="line">Step: 6000 Current loss: 0.0875175</span><br><span class="line">Step: 7000 Current loss: 0.0903373</span><br><span class="line">Step: 8000 Current loss: 0.0899588</span><br><span class="line">Step: 9000 Current loss: 0.0899196</span><br><span class="line">Step: 10000 Current loss: 0.0901761</span><br><span class="line">Step: 11000 Current loss: 0.0887947</span><br><span class="line">Step: 12000 Current loss: 0.0891289</span><br><span class="line">Step: 13000 Current loss: 0.0883277</span><br><span class="line">Step: 14000 Current loss: 0.0908775</span><br><span class="line">Step: 15000 Current loss: 0.0866709</span><br><span class="line">Step: 16000 Current loss: 0.0907037</span><br><span class="line">Step: 17000 Current loss: 0.0897186</span><br><span class="line">Step: 18000 Current loss: 0.0889717</span><br><span class="line">Step: 19000 Current loss: 0.0901095</span><br><span class="line">loss: 0.0568894</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，整个loss的趋势是在减小的，而且loss值变成了0.56，比原来更低了，虽然也有些波动，但那是因为dropout随机时受到了异常数据运算结果的影响。</p>
<p>来看一下最终这次模型的可视化效果，如图7-21所示，红色用+表示，蓝色用·表示。</p>
<p><img src="Image00125.jpg" alt></p>
<p>图7-21 dropout+退化学习率</p>
<h4 id="7-4-9-全连接网络的深浅关系"><a href="#7-4-9-全连接网络的深浅关系" class="headerlink" title="7.4.9 全连接网络的深浅关系"></a>7.4.9 全连接网络的深浅关系</h4><p>全连接神经网络是一个通用的近似框架。只要有足够多的神经元，即使只有一层隐藏层的神经网络，利用常用的Sigmoid，reLU等激活函数，就可以无限逼近任何连续函数。</p>
<p>在实际中，如果想使用浅层神经网络来拟合复杂非线性函数，就需要靠增加的神经元个数来实现。神经元过多意味着需要训练的参数过多，这会增加网络的学习难度，并影响网络的泛化能力。因此，在搭建网络结构时，一般倾向于使用更深的模型，来减少网络中所需要神经元的数量，使网络有更好的泛化能力。</p>
<h3 id="7-5-练习题"><a href="#7-5-练习题" class="headerlink" title="7.5 练习题"></a>7.5 练习题</h3><p>在本书的源代码里有3个关于异或问题的代码文件“7-9 xorerr1.py、7-10 xorerr2.py、7-11 xorerr3.py”，分别存在着不同的错误，试着修正它们，生成正确的模型。</p>
<h2 id="第8章-卷积神经网络——解决参数太多问题"><a href="#第8章-卷积神经网络——解决参数太多问题" class="headerlink" title="第8章 卷积神经网络——解决参数太多问题"></a>第8章 卷积神经网络——解决参数太多问题</h2><p>卷积神经网络是深度学习中最经典的模型之一。当今所有的深度学习经典模型中都能找到卷积神经网络的身影。它巧妙地利用很少的权重却达了全连接网络实现不了的效果。本章将进入卷积神经网络的学习。先看看与全连接网络相比，它能够解决哪些问题。</p>
<p>本章含有教学视频18分04秒。</p>
<p>作者按照本章的内容结构，对主要内容体系进行了概括性的讲解，包括卷积神经网络的作用，卷积操作和反卷积操作的实现及作用，以及关于卷积神经网络在训练中的一些优化技巧等（重点是对卷积及池化中的输入输出对应规则，以及卷积网络的优化技巧）。</p>
<p><img src="Image00126.jpg" alt></p>
<h3 id="8-1-全连接网络的局限性"><a href="#8-1-全连接网络的局限性" class="headerlink" title="8.1 全连接网络的局限性"></a>8.1 全连接网络的局限性</h3><p>在第7章的代码“7-5 mnist多层分类.py”的实例中，仅使用了一个28×28像素的小图片数据集就完成了分类任务。但在实际应用中要处理的图片像素一般都是1024，甚至更大。这么大的图片输入到全连接网络中后会有什么效果呢？我们可以分析一下。</p>
<p>如果只有两个隐藏层，每层各用了256个节点，则MNIST数据集所需要的参数是（28×28×256+256×256+256×10）个w，再加上（256+256+10）个b。</p>
<p>1．图像变大导至色彩数变多，不好解决</p>
<p>如果换为1000像素呢？仅一层就需要1000×1000×256≈2亿个w（可以把b都忽略）。这只是灰度图，如果是RGB的真彩色图呢？再乘上3后则约等于6亿。如果想要得到更好的效果，再加几个隐藏层……可以想象，需要的学习参数量将是非常多的，不仅消耗大量的内存，同时也需要大量的运算，这显然不是我们想要的结果。</p>
<p>2．不便处理高维数据</p>
<p>对于比较复杂的高维数据，如按照全连接的方法，则只能通过增加节点、增加层数的方式来解决。而增加节点会引起参数过多的问题。因为由于隐藏层神经网络使用的是Sigmoid或Tanh激活函数，其反向传播的有效层数也只能在4～6层左右。所以，层数再多只会使反向传播的修正值越来越小，网络无法训练。</p>
<p>而卷积神经网络使用了参数共享的方式，换了一个角度来解决问题，不仅在准确率上大大提升，也把参数降了下来。下面就来学习一下卷积神经网络。</p>
<h3 id="8-2-理解卷积神经网络"><a href="#8-2-理解卷积神经网络" class="headerlink" title="8.2 理解卷积神经网络"></a>8.2 理解卷积神经网络</h3><p>卷积神经网络避免了对参数的过度依赖，相比全连接神经网络，能更好地识别高维数据（即超大图片）。它是什么样的一个东西呢？ 先来理解一下sobel算子吧。如图8-1这就是sobel算子对图片处理后的效果，它可以把图片的轮廓显示出来。</p>
<p><img src="Image00127.jpg" alt></p>
<p>图8-1 sobel算子示例</p>
<p>不要被它的名字吓到，它其实是个很简单的矩阵计算，其方法见图8-2所示的卷积过程。</p>
<p>图8-2a的5×5矩阵可以理解为图8-1a（即原始图片），经过卷积操作后，变为图8-2b对应图8-1b（即轮廓图）。</p>
<p>整个过程如图8-2所示，具体步骤如下。</p>
<p>（1）在外面补了一圈0，这个过程叫做pading，目的是为了变换后生成同样大小的矩阵。</p>
<p>（2）将图8-2a左上角的3×3矩阵中的每个元素分别与中间的3×3矩阵对应位置上的元素相乘，然后再相加，这样得到的值作为图8-2b的第一个元素。</p>
<p>（3）中间的3×3矩阵就是sobel算子。</p>
<p>（4）把图8-2a中左上角的3×3矩阵向右移动一个格，这可以理解为步长为1。</p>
<p>（5）将图8-2a矩阵中的每个元素分别与中间的3×3矩阵对应位置上的元素相乘然后进行加和运算，算出的值填到图8-2b的第二个元素里。</p>
<p>（6）一直重复上述操作，直到将图8-2b中的值都填满，整个这个过程就叫做卷积。</p>
<p>sobel矩阵可以理解为卷积神经网络里的卷积核（也可以叫“滤波器”，filter），它里面的值也可以理解为权重w。在sobel中，这些w是固定的，就相当于一个训练好的模型，只要通过里面的值变换后的图片，就会产生具有轮廓的效果。这个变换后的图片，在卷积神经网络里称为feature map。</p>
<p><img src="Image00128.jpg" alt></p>
<p>图8-2 卷积过程</p>
<p><img src="Image00014.jpg" alt> 注意： 新生成的图片里面的每个像素值并不能保证在0～256之间。对于在区间外的像素点会导致灰度图无法显示，所以还需要做一次归一化，然后每个值都乘以256，再将所有的值映射到这个区间内。</p>
<p>归一化算法：x=（x-Min）/（Max-Min）。</p>
<p>其中，Max与Min为整体数据里的最大值和最小值，x是当前要转换的像素值。归一化之后可以保证每个x都在[0，1]的区间内。</p>
<h3 id="8-3-网络结构"><a href="#8-3-网络结构" class="headerlink" title="8.3 网络结构"></a>8.3 网络结构</h3><p>卷积神经网络的结构与全连接网络相比复杂得多。它的网络结构主要包括卷积层、池化层。细节又可以分为滤波器、步长、卷积操作、池化操作等。</p>
<h4 id="8-3-1-网络结构描述"><a href="#8-3-1-网络结构描述" class="headerlink" title="8.3.1 网络结构描述"></a>8.3.1 网络结构描述</h4><p>前面讲述的是一个基本原理，实际的卷积操作会复杂一些，对于一幅图片一般会使用多个卷积核（滤波器），将它们统一放到卷积层里来操作，这一层中有几个滤波器，就会得出几个feature map，接着还要经历一个池化层（pooling），将生成的feature map缩小（降维），池化层会在下面的文章中介绍。图8-3所示为神经网络中一个标准的卷积操作组合。</p>
<p><img src="Image00129.jpg" alt></p>
<p>图8-3 卷积结构</p>
<p>图8-3中卷积层里面channel的个数代表卷积层的深度。池化层中则只有一个滤波器（fileter），主要参数是尺寸大小（即步长大小）。</p>
<p>下面先来看一个卷积网络的完整结构，如图8-4所示。</p>
<p><img src="Image00130.jpg" alt></p>
<p>图8-4 卷积网络的完整结构</p>
<p>一个卷积神经网络里包括5部分——输入层、若干个卷积操作和池化层结合的部分、全局平均池化层、输出层：</p>
<p>·输入层：将每个像素代表一个特征节点输入进来。</p>
<p>·卷积操作部分：由多个滤波器组合的卷积层。</p>
<p>·池化层：将卷积结果降维。</p>
<p>·全局平均池化层：对生成的feature map取全局平均值。</p>
<p>·输出层：需要分成几类，相应的就会有几个输出节点。每个输出节点都代表当前样本属于的该类型的概率。</p>
<p>输入层、输出层在前面章节已有介绍，下面重点讲讲卷积操作和池化层。</p>
<p><img src="Image00014.jpg" alt> 注意： 全局平均池化层是后出的新技术，在以前的大部分教材里，这个位置通过是使用1～3个全连接层来代替的。全连接层的劣势在于会产生大量的计算，需要大量的参数，但在效果上却和全局平均池化层一样。所以，在这里请读者忘掉全连接层，直接使用效率更高的全局平均池化层。</p>
<h4 id="8-3-2-卷积操作"><a href="#8-3-2-卷积操作" class="headerlink" title="8.3.2 卷积操作"></a>8.3.2 卷积操作</h4><p>前面的8.2节中采用soble因子对图片的操作，可以理解成一次卷积操作。下面来系统地了解卷积操作。卷积分为窄卷积、全卷积和同卷积。</p>
<p>在一一介绍这些卷积类型之前，首先介绍一下步长的概念。</p>
<p>1．步长</p>
<p>步长是卷积操作的核心。通过步长的变换，可以得到想要的不同类型的卷积操作。先以窄卷积为例，看看它的操作及相关术语，如图8-5所示。</p>
<p><img src="Image00131.jpg" alt></p>
<p>图8-5 卷积细节</p>
<p>图8-5中，5×5大小的矩阵代表图片，每个图片右侧的3×3矩阵代表卷积核，最右侧的3×3矩阵为计算完的结果feature map。</p>
<p>卷积操作仍然是将卷积核（filter）对应的图片（image）中的矩阵数据一一相乘，再相加。图8-5中，第一行feature map中的第一个元素，是由image块中前3行3列中的每个元素与filter中的对应元素相乘再相加得到的（4=1×1+1×0+1×1+0×0+1×1+1×0+0×1+0×0+1×1）。</p>
<p>步长（stride）表示卷积核在图片上移动的格数。</p>
<p>·当步长为1的情况下，如图8-5中，第二行右边的feature map块里的第二个元素3，是由卷积核计算完第一个元素4，右移一格后计算得来的，相当于图片中的前3行和第1到第4列围成的3×3矩阵与卷积核各对应元素进行相乘相加操作（3= 1×1+1×0+0×1+1×0+1×1+1×0+0×1+1×0+1×1）。</p>
<p>·当步长为2的情况下，就代表每次移动2个格，最终会得到一个如图8-5中第二行左边的2×2矩阵块的结果。</p>
<p>2．窄卷积</p>
<p>窄卷积（valid卷积），从字面上也可以很容易理解，即生成的feature map比原来的原始图片小，它的步长是可变的。假如滑动步长为S，原始图片的维度为N1×N1，那么卷积核的大小为N2×N2，卷积后的图像大小（N1-N2）/S+1×（N1-N2）/S+1。</p>
<p>3．同卷积</p>
<p>同卷积（same卷积），代表的意思是卷积后的图片尺寸与原始图片的尺寸一样大，同卷积的步长是固定的，滑动步长为1。一般操作时都要使用padding技术（外围补一圈0，以确保生成的尺寸不变）。</p>
<p>4．全卷积</p>
<p>全卷积（full卷积），也叫反卷积，就是把原始图片里的每个像素点都用卷积操作展开。如图8-6所示，白色的块是原始图片，浅色的是卷积核，深色的是正在卷积操作的像素点。反卷积操作的过程中，同样需要对原有图片进行padding操作，生成的结果会比原有的图片尺寸大。</p>
<p><img src="Image00132.jpg" alt></p>
<p>图8-6 反卷积</p>
<p>全卷积的步长也是固定的，滑动步长为1，假如原始图片的维度为N1×N1，那么卷积核的大小为N2×N2，卷积后的图像大小，即N1+N2-1×N1+N2-1</p>
<p>前面的窄卷积和同卷积都是卷积网络里常用的技术，然而全卷积（full卷积）却相反，它更多地用在反卷积网络中，关于反卷积网络的内容，将在后面的章节进行介绍。</p>
<p>5．反向传播</p>
<p>因为反向传播在框架里已经封装好，不需要对其进行编码修改，所以对于反向传播方面的知识，这里只简单介绍下基本原理，读者知道大概意思即可。</p>
<p>反向传播的核心步骤主要有两步：</p>
<p>（1）反向将误差传到前面一层。</p>
<p>（2）根据当前的误差对应的学习参数表达式，计算出其需要更新的差值。</p>
<p>对于第（2）步，与前面的反向求导是一样的，仍然使用链式求导法则，找到使误差最小化的梯度，再配合学习率算出更新的差值。将生成的feature map做一次padding后，与转置后的卷积核做一次卷积操作即可得到输入端的误差，从而实现误差的反向传递。</p>
<p>这里只介绍个概念，具体的计算规则请读者参看后面的反卷积部分，这里不再赘述。</p>
<p>6．多通道的卷积</p>
<p>通道（Channel），是指图片中每个像素由几个数来表示，这几个数一般指的就是色彩。比如一个灰度图的通道就是1，一个彩色图的通道就是3（红、黄、蓝）。前面介绍的都是单通道的卷积计算，那么对于多通道的卷积计算是什么样的呢？</p>
<p>在卷积神经网络里，通道又分输入通道和输出通道。</p>
<p>·输入通道：就是前面刚介绍的图片的通道。如是彩色图片，起始的输入通道就是3。如是中间层的卷积，输入通道就是上一层的输出通道个数，计算方法是，每个输入通道的图片都使用同一个卷积核进行卷积操作，生成与输入通道匹配的feature map（比如彩色图片就是3个），然后再把这几张feature map相同位置上的值加起来，生成一张feature map。</p>
<p>·输出通道：很好理解了，想要输出几个feature map，就放几个卷积核，就是几个输出通道。</p>
<h4 id="8-3-3-池化层"><a href="#8-3-3-池化层" class="headerlink" title="8.3.3 池化层"></a>8.3.3 池化层</h4><p>池化的主要目的是降维，即在保持原有特征的基础上最大限度地将数组的维数变小。</p>
<p>池化的操作外表跟卷积很像，只是算法不同：</p>
<p>·卷积是将对应像素上的点相乘，然后再相加。</p>
<p>·池化中只关心滤波器的尺寸，不考虑内部的值。算法是，滤波器映射区域内的像素点取取平均值或最大值。</p>
<p>池化步骤也有步长，这一点与卷积是一样的。</p>
<p>1．均值池化</p>
<p>这个很好理解，就是在图片上对应出滤波器大小的区域，对里面的所有不为0的像素点取均值。这种方法得到的特征数据会对背景信息更敏感一些。</p>
<p><img src="Image00014.jpg" alt> 注意： 一定是不为0的像素点，这个很重要。如果把带0的像素点加上，则会增加分母，从而使整体数据变低。</p>
<p>2．最大池化</p>
<p>同理，最大池化就是在图片上对应出滤波器大小的区域，将里面的所有像素点取最大值。这种方法得到的特征数据会对纹理特征的信息更敏感一些。</p>
<p>3．反向传播</p>
<p>池化的反向传播要比卷积容易理解。对于最大池化，直接将其误差还原到对应的位置，其他用0填入；对于均值池化，则是将其误差全部填入该像素对应的池化区域。该部分的详细算法也与反池化算法完全相同，读者可以参看反池化部分的介绍。</p>
<h3 id="8-4-卷积神经网络的相关函数"><a href="#8-4-卷积神经网络的相关函数" class="headerlink" title="8.4 卷积神经网络的相关函数"></a>8.4 卷积神经网络的相关函数</h3><p>在TensorFlow中，使用tf.nn.conv2d来实现卷积操作，使用tf.nn.max_pool进行最大池化操作。通过传入不同的参数，来实现各种不同类型的卷积与池化操作。下面介绍这两个函数中各参数的具体意义。</p>
<h4 id="8-4-1-卷积函数tf-nn-conv2d"><a href="#8-4-1-卷积函数tf-nn-conv2d" class="headerlink" title="8.4.1 卷积函数tf.nn.conv2d"></a>8.4.1 卷积函数tf.nn.conv2d</h4><p>TensorFlow里使用tf.nn.conv2d函数来实现卷积，其格式如下。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>除去参数name参数用以指定该操作的name，与方法有关的共有5个参数。</p>
<p>·input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch，in_height，in_width，in_channels]这样的形状（shape），具体含义是“训练时一个batch的图片数量，图片高度，图片宽度，图像通道数”，注意这是一个四维的Tensor，要求类型为float32和float64其中之一。</p>
<p>·filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height，filter_width，in_channels，out_channels]这样的shape，具体含义是“卷积核的高度，滤波器的宽度，图像通道数，滤波器个数”，要求类型与参数input相同。有一个地方需要注意，第三维in_channels，就是参数input的第四维。</p>
<p>·strides：卷积时在图像每一维的步长，这是一个一维的向量，长度为4。</p>
<p>·padding：定义元素边框与元素内容之间的空间。string类型的量，只能是SAME和VALID其中之一，这个值决定了不同的卷积方式，padding的值为’VALID’时，表示边缘不填充，当其为’SAME’时，表示填充到滤波器可以到达图像边缘。</p>
<p>·use_cudnn_on_gpu：bool类型，是否使用cudnn加速，默认为true。</p>
<p>·返回值：tf.nn.conr2d函数结果返回一个Tensor，这个输出就是常说的feature map。</p>
<p><img src="Image00014.jpg" alt> 注意： 在卷积函数中，padding参数是最容易引起歧义的，该参数仅仅决定是否要补0，因此一定要清楚padding设为SAME的真正含义。在设为SAME的情况下，只有在步长为1时生成的feature map才会与输入值相等。</p>
<h4 id="8-4-2-padding规则介绍"><a href="#8-4-2-padding规则介绍" class="headerlink" title="8.4.2 padding规则介绍"></a>8.4.2 padding规则介绍</h4><p>padding属性的意义是定义元素边框与元素内容之间的空间。</p>
<p>在tf.nn.conv2d函数中，当变量padding为VALID和SAME时，函数具体是怎么计算的呢？其实是有公式的。为了方便演示，先来定义几个变量：</p>
<p>·输入的尺寸中高和宽定义成in_height、in_width。</p>
<p>·卷积核的高和宽定义成filter_height、filter_width。</p>
<p>·输出的尺寸中高和宽定义成output_height、output_width。</p>
<p>·步长的高宽方向定义成strides_height、strides_ width。</p>
<p>1．VALID情况</p>
<p>输出宽和高的公式代码分别为：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_width=(in_width–filter_width + 1)/strides_ width（结果向上取整）</span><br><span class="line">output_height=(in_height–filter_height+1)/strides_height（结果向上取整）</span><br></pre></td></tr></table></figure>

</details>

<p>2．SAME情况</p>
<p>输出的宽和高将与卷积核没有关系，具体公式代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_height = in_height / strides_height（结果向上取整）</span><br><span class="line">out_width = in_width / strides_ width（结果向上取整）</span><br></pre></td></tr></table></figure>

</details>

<p>这里有一个很重要的知识点——补零的规则，见如下代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pad_height=max((out_height-1)×strides_height +filter_height-in_height,0)</span><br><span class="line">pad_width = max((out_width-1)×strides_ width +filter_width -in_width, 0)</span><br><span class="line">pad_top = pad_height / 2</span><br><span class="line">pad_bottom = pad _height -pad_top</span><br><span class="line">pad_left = pad _width / 2</span><br><span class="line">pad_right = pad _width -pad_left</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中</p>
<p>·pad_height：代表高度方向要填充0的行数。</p>
<p>·pad_width：代表宽度方向要填充0的列数。</p>
<p>·pad_top、pad_bottom、pad_left、pad_right：分别代表上、下、左、右这4个方向填充0的行、列数。</p>
<p>3．规则举例</p>
<p>下面通过例子来理解一下padding规则。</p>
<p>假设用`一个一维数据来举例，输入是13，filter是6，步长是5，对于padding的取值有如下表示：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&apos;VALID&apos;相当于padding，生成的宽度为（13-6+1）/5 = 2（向上取整）个数字。</span><br><span class="line">   inputs:         1  2  3  4  5  6  7  8  9  10  11  (12 13)</span><br><span class="line">                 |________________|                  dropped</span><br><span class="line">                               |_________________|</span><br></pre></td></tr></table></figure>

</details>

<p>‘SAME’=相当于padding，生成的宽度为13/5=3（向上取整）个数字。</p>
<p>Padding的方式可以如下计算：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Pad_width = (3-1) ×5+6-13 = 3</span><br><span class="line">Pad_left = pad_width/2= 3/2 = 1</span><br><span class="line">Pad_rigth = pad_width-pad_left = 2</span><br></pre></td></tr></table></figure>

</details>

<p>在左边补一个0，右边补2个0。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">              pad|                                          | pad</span><br><span class="line">inputs:      0 | 1  2  3  4  5  6  7  8  9  10  11  12  13 | 0  0  </span><br><span class="line">           |________________|</span><br><span class="line">                         |_________________|</span><br><span class="line">                                        |_____________________|</span><br></pre></td></tr></table></figure>

</details>

<h4 id="8-4-3-实例37：卷积函数的使用"><a href="#8-4-3-实例37：卷积函数的使用" class="headerlink" title="8.4.3 实例37：卷积函数的使用"></a>8.4.3 实例37：卷积函数的使用</h4><p>下面通过一个例子来介绍卷积函数的用法。</p>
<p>实例描述</p>
<p>通过手动生成一个5×5的矩阵来模拟图片，定义一个2×2的卷积核，来测试tf.nn.conv2d函数里的不同参数，验证其输出结果。</p>
<p>在这个例子中，分为如下几个步骤来写代码。</p>
<p>（1）定义输入变量。</p>
<p>（2）定义卷积核变量。</p>
<p>（3）定义卷积操作。</p>
<p>（4）运行卷积操作。</p>
<p>下面就来一一操作。</p>
<p>1．定义输入变量</p>
<p>定义3个输入变量用来模拟输入图片，分别是5×5大小1个通道的矩阵、5×5大小2个通道的矩阵、4×4大小1个通道的矩阵，并将里面的值统统赋为1。</p>
<p>代码8-1 卷积函数使用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> import tensorflow as tf  </span><br><span class="line">   </span><br><span class="line"> # [batch, in_height, in_width, in_channels] [训练时一个批次的图片数量, </span><br><span class="line">图片高度, 图片宽度, 图像通道数]  </span><br><span class="line"> input = tf.Variable(tf.constant(1.0,shape = [1, 5, 5, 1])) </span><br><span class="line"> input2 = tf.Variable(tf.constant(1.0,shape = [1, 5, 5, 2]))</span><br><span class="line"> input3 = tf.Variable(tf.constant(1.0,shape = [1, 4, 4, 1]))</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义卷积核变量</p>
<p>定义5个卷积核，每个卷积核都是2×2的矩阵，只是输入、输出的通道数有差别，分别为1ch输入、1ch输出，1ch输入、2ch输出，1ch输入、3ch输出，2ch输入、2ch输出，2ch输入、1ch输出，并分别在里面填入指定的数值：</p>
<p>代码8-1 卷积函数使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> # [filter_height, filter_width, in_channels, out_channels]</span><br><span class="line">（卷积核的高度，卷积核的宽度，图像通道数，卷积核个数）</span><br><span class="line"> filter1 =  tf.Variable(tf.constant([-1.0,0,0,-1],shape = [2, 2, 1, 1]))</span><br><span class="line"> filter2 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1],shape = </span><br><span class="line">[2, 2, 1, 2])) </span><br><span class="line"> filter3 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1,-1.0,</span><br><span class="line">0,0,-1],shape = [2, 2, 1, 3])) </span><br><span class="line"> filter4 =  tf.Variable(tf.constant([-1.0,0,0,-1,</span><br><span class="line">                                    -1.0,0,0,-1,</span><br><span class="line">                                    -1.0,0,0,-1,</span><br><span class="line">                                    -1.0,0,0,-1],shape = [2, 2, 2, 2])) </span><br><span class="line"> filter5 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1],shape = </span><br><span class="line">[2, 2, 2, 1]))</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义卷积操作</p>
<p>将步骤1的输入与步骤2的卷积核组合起来，建立8个卷积操作，看看生成的内容与前面所讲述的规则是否一致。</p>
<p>代码8-1 卷积函数使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> # padding的值为&apos;VALID&apos;，表示边缘不填充； 当其为&apos;SAME&apos;时，表示填充到卷积核可以到</span><br><span class="line">达图像边缘  </span><br><span class="line"> op1 = tf.nn.conv2d(input, filter1, strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) #1个通道输入，生成1个feature ma</span><br><span class="line"> op2 = tf.nn.conv2d(input, filter2, strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) </span><br><span class="line">#1个通道输入，生成2个feature map</span><br><span class="line"> op3 = tf.nn.conv2d(input, filter3, strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) #1个通道输入，生成3个feature map</span><br><span class="line"> </span><br><span class="line"> op4 = tf.nn.conv2d(input2, filter4, strides=[1, 2, 2, 1], padding=</span><br><span class="line">&apos;SAME&apos;) # 2个通道输入，生成2个feature</span><br><span class="line"> op5 = tf.nn.conv2d(input2, filter5, strides=[1, 2, 2, 1], padding=</span><br><span class="line">&apos;SAME&apos;) # 2个通道输入，生成1个feature map</span><br><span class="line"> </span><br><span class="line"> vop1 = tf.nn.conv2d(input, filter1, strides=[1, 2, 2, 1], padding=</span><br><span class="line">&apos;VALID&apos;) # 5*5 对于pading不同而不同</span><br><span class="line"> op6 = tf.nn.conv2d(input3, filter1, strides=[1, 2, 2, 1], padding=</span><br><span class="line">&apos;SAME&apos;) </span><br><span class="line"> vop6 = tf.nn.conv2d(input3, filter1, strides=[1, 2, 2, 1], padding=</span><br><span class="line">&apos;VALID&apos;)   #4*4与pading无关</span><br></pre></td></tr></table></figure>

</details>

<p>这么多卷积操作看着有点混乱，按照演示的目的将其分类一下，分别介绍。</p>
<p>（1）演示padding补0的情况</p>
<p>如上文代码，op1使用了padding=SAME的一个通道输入、一个通道输出的卷积操作，步长为2×2，按前面的函数介绍，这种情况TensorFlow会对input补0。通过前面的公式计算，会生成3×3大小的矩阵，并且在右侧和下侧各补一圈0，由5×5矩阵变成6×6矩阵，如图8-7所示。</p>
<p><img src="Image00133.jpg" alt></p>
<p>图8-7 padding例子</p>
<p>（2）演示多通道输出时的内存排列</p>
<p>op2示例了1个通道生成2个输出，oP3示例了1个通道生成3个输出，可以看下它们在内存中的排列样子。</p>
<p>（3）演示卷积核对多通道输入的卷积处理</p>
<p>op4示例了2个通道生成2个输出，op5示例了2个通道生成1个输出，比较下对于2个通道的卷积结果，观察是多通道的结果叠加，还是每个通道单独对应一个卷积核进行输出。</p>
<p>（4）验证不同尺寸下的输入受到padding为SAME和VALID的影响</p>
<p>op1和vop1示例了5×5尺寸输入在padding为SAME和VALID时的变化情况，op6 和vop6示例了4×4尺寸输入在padding为SAME和VALID下的变化情况。</p>
<p>4．运行卷积操作</p>
<p>在本步操作之前，读者可以把前面的规则熟记一下，然后试着自己推导一下，比较得到的输出结果。下面把这些结果打印出来，看看与你推导的是否一致。</p>
<p>代码8-1 卷积函数使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()  </span><br><span class="line">with tf.Session() as sess:  </span><br><span class="line">    sess.run(init)  </span><br><span class="line">    </span><br><span class="line">    print(&quot;op1:\n&quot;,sess.run([op1,filter1]))    #1-1  后面补0</span><br><span class="line">    print(&quot;------------------&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;op2:\n&quot;,sess.run([op2,filter2]))   #1-2多卷积核，按列取</span><br><span class="line">    print(&quot;op3:\n&quot;,sess.run([op3,filter3]))   #1-3一个输入，3个输出</span><br><span class="line">    print(&quot;------------------&quot;)   </span><br><span class="line">    </span><br><span class="line">    print(&quot;op4:\n&quot;,sess.run([op4,filter4]))   #2-2通道叠加</span><br><span class="line">    print(&quot;op5:\n&quot;,sess.run([op5,filter5]))   #2-1两个输入，一个输出</span><br><span class="line">    print(&quot;------------------&quot;)</span><br><span class="line">  </span><br><span class="line">    print(&quot;op1:\n&quot;,sess.run([op1,filter1]))    #1-1一个输入，一个输出</span><br><span class="line">    print(&quot;vop1:\n&quot;,sess.run([vop1,filter1]))</span><br><span class="line">    print(&quot;op6:\n&quot;,sess.run([op6,filter1]))</span><br><span class="line">    print(&quot;vop6:\n&quot;,sess.run([vop6,filter1]))</span><br></pre></td></tr></table></figure>

</details>

<p>下面分别是介绍这段代码的执行结果。</p>
<p>（1）执行代码8-1中的31和32行代码，对应的输出如下：（为了看起来方便，将格式进行了整理）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">op1:</span><br><span class="line"> [array([[[[-2.],[-2.], [-1.]],</span><br><span class="line">        [[-2.],[-2.],[-1.]],</span><br><span class="line">        [[-1.],[-1.],[-1.]]]], dtype=float32),</span><br><span class="line"> array([[[[-1.]],[[ 0.]]],</span><br><span class="line">   [[[ 0.]],[[-1.]]]], dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>上面输出中5×5矩阵通过卷积操作生成了3×3矩阵，对padding的补0情况是在后面和下面补0，所以会在矩阵的右边和下边生成-1。</p>
<p>（2）执行代码8-1中的34～36行，对应的输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">op2:</span><br><span class="line"> [array([[[[-2.,-2.],[-2.,-2.],[-2.,0.]],</span><br><span class="line">        [[-2.,-2.],[-2.,-2.],[-2.,0.]],</span><br><span class="line">        [[-1.,-1.],[-1.,-1.],[-1.,0.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.,0.]],[[0.,-1.]]],</span><br><span class="line">[[[-1.,0.]],[[0.,-1.]]]],dtype=float32)]</span><br><span class="line">op3:</span><br><span class="line"> [array([[[[-2.,-2.,-2.],[-2.,-2.,-2.],[-1.,-1.,-1.]],</span><br><span class="line">        [[-2.,-2.,-2.],[-2.,-2.,-2.],[-1.,-1.,-1.]],</span><br><span class="line">        [[-2.,-1.,0.],[-2.,-1.,0.],[-1.,0.,0.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.,0.,0.]],[[-1.,-1.,0.]]],</span><br><span class="line">  [[[ 0.,-1.,-1.]],[[0.,0.,-1.]]]],dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>上面输出中，生成的多通道的输出，是按列排列的（每一个feature map为一列）。为了方便理解，以op2为例，其剖析图如图8-8所示。</p>
<p><img src="Image00134.jpg" alt></p>
<p>图8-8 卷积示例</p>
<p>（3）执行代码8-1中的33～39行，对应的输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">op4:</span><br><span class="line"> [array([[[[-4.,-4.],[-4.,-4.],[-2.,-2.]],</span><br><span class="line">        [[-4.,-4.],[-4.,-4.],[-2.,-2.]],</span><br><span class="line">        [[-2.,-2.],[-2.,-2.],[-1.,-1.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.,0.],[0.,-1.]],[[-1.,0.],[0.,-1.]]],</span><br><span class="line"> [[[-1.,0.],[0.,-1.]],[[-1.,0.],[0.,-1.]]]],dtype=float32)]</span><br><span class="line">op5:</span><br><span class="line"> [array([[[[-4.],[-4.],[-2.]],</span><br><span class="line">        [[-4.],[-4.],[-2.]],</span><br><span class="line">        [[-2.],[-2.],[-1.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.],[0.]],[[0.],[-1.]]],</span><br><span class="line"> [[[-1.],[0.]],[[0.],[-1.]]]],dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>卷积核对多通道输入的卷积处理，是多通道的结果叠加。以op5为例展开。图8-9所示为将每个通道的feature map叠加生成了最终的结果。</p>
<p><img src="Image00135.jpg" alt></p>
<p>图8-9 多通道卷积</p>
<p>（4）执行代码8-1中的42～45行，对应的输出如下，是不同尺寸输入分别为SAME和VALID时的比较。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">op1:</span><br><span class="line"> [array([[[[-2.],[-2.],[-1.]],</span><br><span class="line">        [[-2.],[-2.],[-1.]],</span><br><span class="line"> [[-1.],[-1.],[-1.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.]],[[0.]]],</span><br><span class="line">       [[[0.]],[[-1.]]]],dtype=float32)]</span><br><span class="line">vop1:</span><br><span class="line"> [array([[[[-2.],[-2.]],</span><br><span class="line">        [[-2.],[-2.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.]],[[0.]]],</span><br><span class="line">       [[[0.]],[[-1.]]]],dtype=float32)] </span><br><span class="line">op6:</span><br><span class="line"> [array([[[[-2.],[-2.]],</span><br><span class="line">        [[-2.],[-2.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.]],[[0.]]],</span><br><span class="line">       [[[0.]],[[-1.]]]],dtype=float32)]</span><br><span class="line">vop6:</span><br><span class="line"> [array([[[[-2.],[-2.]],</span><br><span class="line">        [[-2.],[-2.]]]],dtype=float32), </span><br><span class="line">array([[[[-1.]],[[0.]]],</span><br><span class="line">       [[[0.]],[[-1.]]]],dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>通过上面的结果可以看出：</p>
<p>·对于op1和vop1的比较可以看出5×5矩阵在padding为’SAME’时生成的是3×3矩阵，而在’VALID’时生成的是2×2。</p>
<p>·而在op6和vop6的例子中，对于4×4矩阵在padding为’SAME’和’VALID’下都会生成2×2的矩阵，这是因为4×4的输入对于2×2的卷积核步长为2的情况下，正好可以把所有数据处理完，本身在’SAME’的情况下就不需要补0。</p>
<p>通过卷积函数可以实现8.4.2节卷积操作中的窄卷积和同卷积（步长唯一并且补零操作的卷积），但不能实现全卷积。TensorFlow中有单独的反卷积函数，会在后面会讲到。</p>
<p><img src="Image00014.jpg" alt> 注意： 本节特意用了很多篇幅来解释卷积的操作细节，表明这部分内容非常重要，是卷积神经网络的重点。将卷积操作的细节理解透彻，会使你在实际编程过程中少走弯路。因为在自己搭建网络的过程中，必须对输入、输出的具体维度有个清晰的计算，这样才能保证网络结构的正确性，才能使网络运行下去。</p>
<h4 id="8-4-4-实例38：使用卷积提取图片的轮廓"><a href="#8-4-4-实例38：使用卷积提取图片的轮廓" class="headerlink" title="8.4.4 实例38：使用卷积提取图片的轮廓"></a>8.4.4 实例38：使用卷积提取图片的轮廓</h4><p>通过8.4.3节的练习，相信读者已经掌握了卷积操作的细节。下面来做一个实际的例子，通过卷积操作来实现本章开篇所讲的sobel算子。</p>
<p>实例描述</p>
<p>通过卷积操作来实现本章开篇所讲的sobel算子，将彩色的图片生成带有边缘化信息的图片。</p>
<p>本例中先载入一个图片，然后使用一个“3通道输入，1通道输出的3×3卷积核”（即sobel算子），最后使用卷积函数输出生成的结果。</p>
<p>1．载入图片并显示</p>
<p>首先将图片放到代码的同级目录下，通过imread载入，然后将其显示并打印出来。</p>
<p>代码8-2 sobel</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt # plt 用于显示图片</span><br><span class="line">import matplotlib.image as mpimg # mpimg 用于读取图片</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf  </span><br><span class="line"></span><br><span class="line">myimg = mpimg.imread(&apos;img.jpg&apos;) # 读取和代码处于同一目录下的图片</span><br><span class="line">plt.imshow(myimg)                 # 显示图片</span><br><span class="line">plt.axis(&apos;off&apos;)                     # 不显示坐标轴</span><br><span class="line">plt.show()</span><br><span class="line">print(myimg.shape)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，得到输出如下，输出图片如图8-10所示。</p>
<p><img src="Image00136.jpg" alt></p>
<p>图8-10 图片显示</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(3264, 2448, 3)</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，载入的图片维度为3264×2448大小，3个通道。</p>
<p>2．定义占位符、卷积核、卷积op</p>
<p>这里需要手动将sobel算子填入到卷积核里。使用tf.constant函数可以将常量直接初始化到Variable中，因为是3通道，所以sobel卷积核的每个元素都扩成了3个。</p>
<p><img src="Image00014.jpg" alt> 注意： sobel算子处理过的图片不保证每个像素都在0～255之间，所以要做一次归一化操作（即用每个值减去最小值的结果，再除以最大值与最小值的差），让生成的值都在[0，1]之间，然后再乘以255。</p>
<p>代码8-2 sobel（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> full=np.reshape(myimg,[1,3264,2448,3])  </span><br><span class="line"> inputfull = tf.Variable(tf.constant(1.0,shape = [1, 3264, 2448, 3]))</span><br><span class="line"> </span><br><span class="line"> filter = tf.Variable(tf.constant([[-1.0,-1.0,-1.0], [0,0,0], [1.0,1.0,1.0],</span><br><span class="line">                              [-2.0,-2.0,-2.0], [0,0,0],  [2.0,2.0,2.0],</span><br><span class="line">                              [-1.0,-1.0,-1.0],[0,0,0],[1.0,1.0,1.0]],</span><br><span class="line">                                  shape = [3, 3, 3, 1])) </span><br><span class="line"> </span><br><span class="line"> op= tf.nn.conv2d(inputfull, filter, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</span><br><span class="line">  #3个通道输入，生成1个feature ma</span><br><span class="line"> o=tf.cast(  ((op-tf.reduce_min(op))/(tf.reduce_max(op)-tf.reduce_min</span><br><span class="line">(op)) ) *255 ,tf.uint8)</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码中，卷积op的步长为1×1，padding为SAME表明这是个同卷积的操作。</p>
<p>3．运行卷积操作并显示</p>
<p>现在就可以建立session然后运行程序了。具体代码如下。</p>
<p>代码8-2 sobel（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> with tf.Session() as sess:  </span><br><span class="line">     sess.run(tf.global_variables_initializer()  )  </span><br><span class="line"></span><br><span class="line">￼23     t,f=sess.run([o,filter],feed_dict=&#123; inputfull:</span><br><span class="line">    full&#125;)</span><br><span class="line">    </span><br><span class="line">     t=np.reshape(t,[3264,2448]) </span><br><span class="line"> </span><br><span class="line">     plt.imshow(t,cmap=&apos;Greys_r&apos;) #显示图片</span><br><span class="line">     plt.axis(&apos;off&apos;)                  #不显示坐标轴</span><br><span class="line">     plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码执行后输出结果如图8-11所示。</p>
<p><img src="Image00137.jpg" alt></p>
<p>图8-11 边缘化</p>
<p>可以看出，sobel的卷积操作之后，提取到了一张含有轮廓特征的图像。</p>
<h4 id="8-4-5-池化函数tf-nn-max-pool（avg-pool）"><a href="#8-4-5-池化函数tf-nn-max-pool（avg-pool）" class="headerlink" title="8.4.5 池化函数tf.nn.max_pool（avg_pool）"></a>8.4.5 池化函数tf.nn.max_pool（avg_pool）</h4><p>TensorFlow里的池化函数如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.max_pool(input, ksize, strides, padding, name=None)</span><br><span class="line">tf.nn.avg_pool(input, ksize, strides, padding, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>这两个函数中的4个参数和卷积参数很类似，具体说明如下。</p>
<p>·value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch，height，width，channels]这样的shape。</p>
<p>·ksize：池化窗口的大小，取一个四维向量，一般是[1，height，width，1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1。</p>
<p>·strides：和卷积参数含义类似，窗口在每一个维度上滑动的步长，一般也是[1，stride，stride，1]。</p>
<p>·padding：和卷积参数含义一样，也是取VALID或者SAME，VALID是不padding操作，SAME是padding操作。</p>
<p>·返回一个Tensor，类型不变，shape仍然是[batch，height，width，channels]这种形式。</p>
<h4 id="8-4-6-实例39：池化函数的使用"><a href="#8-4-6-实例39：池化函数的使用" class="headerlink" title="8.4.6 实例39：池化函数的使用"></a>8.4.6 实例39：池化函数的使用</h4><p>下面通过一个例子来介绍池化函数的用法。</p>
<p>实例描述</p>
<p>通过手动生成一个4×4的矩阵来模拟图片，定义一个2×2的滤波器，通过几个在卷积神经网络中常用的池化操作来测试池化函数里的参数，并验证输出结果。</p>
<p>1．定义输入变量</p>
<p>定义1个输入变量用来模拟输入图片、4×4大小的2通道矩阵，并将其赋予指定的值。2个通道分别为：4个0到3 3 3 3 组成的矩阵，4个4到7 7 7 7组成的矩阵。</p>
<p>代码8-3 池化函数使用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf  </span><br><span class="line">  </span><br><span class="line">img=tf.constant([  </span><br><span class="line">        [[0.0,4.0],[0.0,4.0],[0.0,4.0],[0.0,4.0]],  </span><br><span class="line">        [[1.0,5.0],[1.0,5.0],[1.0,5.0],[1.0,5.0]],  </span><br><span class="line">        [[2.0,6.0],[2.0,6.0],[2.0,6.0],[2.0,6.0]],  </span><br><span class="line">        [[3.0,7.0],[3.0,7.0], [3.0,7.0],[3.0,7.0]]</span><br><span class="line">    ])</span><br><span class="line">img=tf.reshape(img,[1,4,4,2])</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义池化操作</p>
<p>这里定义了4个池化操作和一个取均值操作。前两个操作是最大池化操作，接下来是两个均值池化操作，最后一个是取均值操作。</p>
<p>代码8-3 池化函数使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> pooling=tf.nn.max_pool(img,[1,2,2,1],[1,2,2,1],padding=&apos;VALID&apos;)  </span><br><span class="line"> pooling1=tf.nn.max_pool(img,[1,2,2,1],[1,1,1,1],padding=&apos;VALID&apos;)</span><br><span class="line"> pooling2=tf.nn.avg_pool(img,[1,4,4,1],[1,1,1,1],padding=&apos;SAME&apos;)  </span><br><span class="line"> pooling3=tf.nn.avg_pool(img,[1,4,4,1],[1,4,4,1],padding=&apos;SAME&apos;) </span><br><span class="line"> nt_hpool2_flat = tf.reshape(tf.transpose(img), [-1, 16]) </span><br><span class="line"> pooling4=tf.reduce_mean(nt_hpool2_flat,1) #1表示对行求均值（1表示轴是列），</span><br><span class="line">0表示对列求均值</span><br></pre></td></tr></table></figure>

</details>

<p>3．运行池化操作</p>
<p>在本步骤操作之前，读者可以把前面的规则熟记一下，然后试着自己推导一下，比较得到的输出结果。下面把这些结果打印出来，看看与你推导的是否一致。</p>
<p>代码8-3 池化函数使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:  </span><br><span class="line">    print(&quot;image:&quot;)  </span><br><span class="line">    image=sess.run(img)  </span><br><span class="line">    print (image)  </span><br><span class="line">    result=sess.run(pooling)  </span><br><span class="line">    print (&quot;reslut:\n&quot;,result)  </span><br><span class="line">    result=sess.run(pooling1)  </span><br><span class="line">    print (&quot;reslut1:\n&quot;,result)     </span><br><span class="line">    result=sess.run(pooling2)  </span><br><span class="line">    print (&quot;reslut2:\n&quot;,result)</span><br><span class="line">    result=sess.run(pooling3)  </span><br><span class="line">    print (&quot;reslut3:\n&quot;,result) </span><br><span class="line">    flat,result=sess.run([nt_hpool2_flat,pooling4])  </span><br><span class="line">    print (&quot;reslut4:\n&quot;,result) </span><br><span class="line">    print(&quot;flat:\n&quot;,flat)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，得到如下输出（为了方便读者观看，这里将格式进行了整理）：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">image:</span><br><span class="line">[[[[ 0.  4.]</span><br><span class="line">   [ 0.  4.]</span><br><span class="line">   [ 0.  4.]</span><br><span class="line">   [ 0.  4.]]</span><br><span class="line"> </span><br><span class="line">  [[ 1.  5.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 2.  6.]</span><br><span class="line">   [ 2.  6.]</span><br><span class="line">   [ 2.  6.]</span><br><span class="line">   [ 2.  6.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]]</span><br></pre></td></tr></table></figure>

</details>

<p>通过上面的输出可以看出，img与我们设置的初始值是一样的，即第一个通道为[[0 0 0 0]，[1 1 1 1]，[2 2 2 2]，[3 3 3 3]]；第二个通道为[[4 4 4 4]，[5 5 5 5]，[6 6 6 6]，[7 7 7 7]]。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reslut:</span><br><span class="line"> [[[[ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]]</span><br></pre></td></tr></table></figure>

</details>

<p>这个操作在卷积神经网络中是最常用的，一般步长都会设成与池化滤波器尺寸一致（池化的卷积尺寸为2×2，所以步长也是2），生成2个通道的2×2矩阵。矩阵的内容是从原始输入中取最大值，由于池化filter中对应通道的维度是1，所以结果仍然保持源通道数。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">reslut1:</span><br><span class="line"> [[[[ 1.  5.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 2.  6.]</span><br><span class="line">   [ 2.  6.]</span><br><span class="line">   [ 2.  6.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]]</span><br><span class="line">reslut2:</span><br><span class="line"> [[[[ 1.   5. ]</span><br><span class="line">   [ 1.   5. ]</span><br><span class="line">   [ 1.   5. ]</span><br><span class="line">   [ 1.   5. ]]</span><br><span class="line"> </span><br><span class="line">  [[ 1.5  5.5]</span><br><span class="line">   [ 1.5  5.5]</span><br><span class="line">   [ 1.5  5.5]</span><br><span class="line">   [ 1.5  5.5]]</span><br><span class="line"> </span><br><span class="line">  [[ 2.   6. ]</span><br><span class="line">   [ 2.   6. ]</span><br><span class="line">   [ 2.   6. ]</span><br><span class="line">   [ 2.   6. ]]</span><br><span class="line"> </span><br><span class="line">  [[ 2.5  6.5]</span><br><span class="line">   [ 2.5  6.5]</span><br><span class="line">   [ 2.5  6.5]</span><br><span class="line">   [ 2.5  6.5]]]]</span><br></pre></td></tr></table></figure>

</details>

<p>result1和result2分别演示了VALID和SAME的两种pading的取值。</p>
<p>·VALID中使用的filter为2×2，步长为1×1，生成了2×2大小的矩阵。</p>
<p>·在SAME中使用的4×4的filter，步长仍然为1×1，生成了4×4的矩阵，padding之后在计算avg_pool时，是将输入矩阵与filter对应尺寸内的元素总和除以这些元素中非零的个数（而不是filter的总个数）。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">reslut3:</span><br><span class="line"> [[[[ 1.5  5.5]]]]</span><br><span class="line">reslut4:</span><br><span class="line"> [ 1.5  5.5]</span><br><span class="line">flat:</span><br><span class="line"> [[ 0.  1.  2.  3.  0.  1.  2.  3.  0.  1.  2.  3.  0.  1.  2.  3.]</span><br><span class="line"> [ 4.  5.  6.  7.  4.  5.  6.  7.  4.  5.  6.  7.  4.  5.  6.  7.]]</span><br></pre></td></tr></table></figure>

</details>

<p>result3是常用的操作手法，也叫全局池化法，就是使用一个与原有输入同样尺寸的filter进行池化，一般放在最后一层，用于表达图像通过卷积网络处理后的最终特征。而result4是一个均值操作，可以看到将数据转置后的均值操作得到的值与全局池化平均值是一样的结果。</p>
<h3 id="8-5-使用卷积神经网络对图片分类"><a href="#8-5-使用卷积神经网络对图片分类" class="headerlink" title="8.5 使用卷积神经网络对图片分类"></a>8.5 使用卷积神经网络对图片分类</h3><p>本节练习使用卷积网络对CIFAR数据集进行分类。在前面接触到了MNIST数据集，它是一堆手写图片，CIFAR也是一堆图片，会比MNIST更为复杂。卷积神经网络最擅长的就是图像数据的处理，所以在CIFAR数据集上做图像识别的练习会更有意思。下面就先从CIFAR开始介绍。</p>
<h4 id="8-5-1-CIFAR介绍"><a href="#8-5-1-CIFAR介绍" class="headerlink" title="8.5.1 CIFAR介绍"></a>8.5.1 CIFAR介绍</h4><p>CIFAR由 Alex Krizhevsky、Vinod Nair和Geoffrey Hinton收集而来，起初的数据集共分为10类，分别为飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车，所以CIFAR数据集常以CIFAR-10命名。CIFAR共包含60 000张32×32的彩色图像（包含50 000张训练图片，10 000张测试图片），其中没有任何类型重叠的情况。</p>
<p>因为是彩色图像，所以这个数据集是三通道的，分别是R，G，B 3个通道。后来CIFAR又出了一个分类更多的版本叫CIFAR-100，从名字也可以看出共有100类，将图片分得更细，当然对神经网络图像识别是更大的挑战了。有了这些数据，我们可以把精力全部投在网络优化上。</p>
<p>CIFAR的官网为<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">http://www.cs.toronto.edu/~kriz/cifar.html</a> ，不同于MNIST数据集，它的数据集是已经打包好的文件（如图8-12所示），分别为Python、MATLIB、二进制bin文件包，以方便不同的程序读取。</p>
<p><img src="Image00138.jpg" alt></p>
<p>图8-12 CIFAR数据集</p>
<h4 id="8-5-2-下载CIFAR数据"><a href="#8-5-2-下载CIFAR数据" class="headerlink" title="8.5.2 下载CIFAR数据"></a>8.5.2 下载CIFAR数据</h4><p>与MNIST类似，TensorFlow中同样有一个下载和导入CIFAR数据集的代码文件，不同的是，自从TensorFlow1.0之后，将里面的Models模块分离了出来。下载和导入CIFAR数据集的代码在models里面，所以要先去TensorFlow的GitHub网站将其下载下来。</p>
<p>如果你使用Git，可以直接用下面的命令下载：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>

</details>

<p>如果没有使用Git，可直接复制上面的网址，在右下角单击clone or download按钮，在下方在单击Download ZIP按钮下载代码的压缩包，如图8-13所示。</p>
<p><img src="Image00139.jpg" alt></p>
<p>图8-13 model代码下载</p>
<p>代码下载后，将其解压，将里面models/tutorials/image/路径下的CIFAR10复制到本地的Python工作区即可。</p>
<p>现在可以在CIFAR10文件夹下新建Python文件，用来下载和导入CIFAR10图片了。与MNIST不同的是，CIFAR数据集代码不是很方便，下载和导入时都需要单独调用，所以本节的例子代码第一个步会有一个独立的代码文件。</p>
<p>将如下代码文件放到cifar10文件夹下（确保import cifar10能找到对应文件），引入CIFAR10，使用函数maybe_download_and_extract即可完成数据的下载和解压。</p>
<p>代码8-4 CIFAR下载</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import cifar10</span><br><span class="line">cifar10.maybe_download_and_extract()</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码会自动将CIFAR10的bin文件ZIP包下载到\tmp\cifar10_data路径下（如果是Windows就是本地磁盘下的这个路径，如D：\tmp\cifar10_data），然后自动解压到\tmp\cifar10_data\cifar-10-batches-bin路径下。</p>
<p>以上这个环节也可以手动下载，然后解压到指定路径里。</p>
<p><img src="Image00014.jpg" alt> 注意： cifar10.py也可以单独运行，但主要功能并不是下载和解压，所以以库的形式引入到代码里，在Anaconda里面不是太友好，运行第二次时会报错，需要重启console才可以。不过好在我们只运行一次，下载并解压后就不需要了。</p>
<p>在两行代码之后，会看到对应路径下生成的相关文件，如图8-14所示。</p>
<p>其中</p>
<p>·batches.meta.txt：标签说明文件。</p>
<p>·data_batch_x.bin：是训练文件，一共有5个，每个10 000条。</p>
<p>·test.batch.bin：10 000条测试文件。</p>
<p><img src="Image00140.jpg" alt></p>
<p>图8-14 生成CIFAR文件</p>
<h4 id="8-5-3-实例40：导入并显示CIFAR数据集"><a href="#8-5-3-实例40：导入并显示CIFAR数据集" class="headerlink" title="8.5.3 实例40：导入并显示CIFAR数据集"></a>8.5.3 实例40：导入并显示CIFAR数据集</h4><p>这里通过import cifar10_input来导入CIFAR数据集，cifar10_input.py里定义了这获取数据的函数，具体调用见代码。</p>
<p>代码8-5 CIFAR</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> import  cifar10_input</span><br><span class="line"> import tensorflow as tf</span><br><span class="line"> import pylab</span><br><span class="line"> </span><br><span class="line"> #取数据</span><br><span class="line"> batch_size = 128</span><br><span class="line"> data_dir = &apos;/tmp/cifar10_data/cifar-10-batches-bin&apos;</span><br><span class="line"> images_test, labels_test = cifar10_input.inputs(eval_data = True, data_</span><br><span class="line">dir = data_dir, batch_size = batch_size)</span><br></pre></td></tr></table></figure>

</details>

<p>cifar10_input.inputs是专门获取数据的函数，返回数据集和对应的标签，但是cifar10_input.inputs函数会将图片裁剪好，由原来的32×32×3，变成了24×24×3。该函数默认是使用测试数据集，如果使用训练数据集，可以将第一个参数传入eval_data=False。</p>
<p>另外，再将batch_size和dir传入，就可以得到dir下面的batch_size个数据了。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里所获得的图片并不是原始图片，是经过了两次变换，首先将32×32尺寸裁剪成了24尺寸，然后又进行了一次图片标准化（减去均值像素，并除以像素方差）。这样做的好处是，使所有的输入都在一个有效的数据分布之内，便于特征的分类处理，会使梯度下降算法的收敛更快。</p>
<p>cifar10_input.py中除了对图像进行了一些预处理，还提供了一个读取大数据的方法示例，即使用queue的方法示例。queue是TesonFlow里常用的方法，尤其是在使用大数据样本做训练时。</p>
<p>关于队列方面的内容会在8.5.8节详细介绍。现在我们将cifar10_input.inputs函数得到的内容显示出来。</p>
<p>代码8-5 CIFAR（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line">tf.train.start_queue_runners()</span><br><span class="line">image_batch, label_batch = sess.run([images_test, labels_test])</span><br><span class="line">print(&quot;__\n&quot;,image_batch[0])</span><br><span class="line">print(&quot;__\n&quot;,label_batch[0])</span><br><span class="line">pylab.imshow(image_batch[0])</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，主要显示内容如下：（部分内容略去）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> [[[1.24836731  0.04940184 -1.49835348]</span><br><span class="line">  [ 1.117571    0.02760247 -1.56375158]</span><br><span class="line">  [ 1.24836731  0.18019807 -1.41115606]</span><br><span class="line">￼  …… </span><br><span class="line">   [-1.58555102 -0.40838495  0.5943861 ]</span><br><span class="line">  [-1.82534409 -0.58277994  0.46358991]</span><br><span class="line">  [-1.56375158 -0.23398998  0.89957732]]]</span><br><span class="line">__</span><br><span class="line"> 3</span><br></pre></td></tr></table></figure>

</details>

<p>代码中，session用的是tf.InteractiveSession函数，原因在后面讲队列时会讲，又额外使用了一个train.start_queue_ runners函数，是运行队列的意思。上面代码的输出是图片像素数据和标签数据。可以看到，读取的数据都是进过标准化处理的（变成了均值为0，方差为1的数据分布），所以输出的图片就是乱的（如图8-15所示）。</p>
<p><img src="Image00141.jpg" alt></p>
<p>图8-15 CIFAR归一化输出</p>
<h4 id="8-5-4-实例41：显示CIFAR数据集的原始图片"><a href="#8-5-4-实例41：显示CIFAR数据集的原始图片" class="headerlink" title="8.5.4 实例41：显示CIFAR数据集的原始图片"></a>8.5.4 实例41：显示CIFAR数据集的原始图片</h4><p>如果希望看到正常的数据怎么办呢？有两种方式：</p>
<p>·修改cifar10_input.py文件，先让它不去标准化。</p>
<p>·手动读取数据并显示。</p>
<p>先来看第一种方式。直接在cifar10_input.py文件里做如下修改：在240行后添加一行代码，并随后将243行代码的内容改为注释。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">float_image = resized_image</span><br><span class="line">  # Subtract off the mean and divide by the variance of the pixels.</span><br><span class="line">  #float_image = tf.image.per_image_standardization(resized_image)</span><br></pre></td></tr></table></figure>

</details>

<p>再次运行代码“8-5 cifar.py”文件，输出如图8-16所示。</p>
<p>可以看出是一只松鼠，但图片仍然是被裁剪过的尺寸24×24×3。</p>
<p>另一种方式是自己手动编写代码，参见下面的具体内容：</p>
<p>代码8-6 cifar手动读取</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np  </span><br><span class="line">from scipy.misc import imsave  </span><br><span class="line">  </span><br><span class="line">filename = &apos;/tmp/cifar10_data/cifar-10-batches-</span><br><span class="line">bin/test_batch.bin&apos;  </span><br><span class="line">  </span><br><span class="line">bytestream = open(filename, &quot;rb&quot;)  </span><br><span class="line">buf = bytestream.read(10000 * (1 + 32 * 32 * 3))  </span><br><span class="line">bytestream.close()  </span><br><span class="line">  </span><br><span class="line">data = np.frombuffer(buf, dtype=np.uint8)  </span><br><span class="line">data = data.reshape(10000, 1 + 32*32*3)  </span><br><span class="line">labels_images = np.hsplit(data, [1])  </span><br><span class="line">labels = labels_images[0].reshape(10000)  </span><br><span class="line">images = labels_images[1].reshape(10000, 32, 32, 3)  </span><br><span class="line">  </span><br><span class="line">img = np.reshape(images[0], (3, 32, 32)) #导出第一幅图</span><br><span class="line">img = img.transpose(1, 2, 0)  </span><br><span class="line">  </span><br><span class="line">import pylab </span><br><span class="line">print(labels[0]) </span><br><span class="line">pylab.imshow(img)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，显示内容如图8-17所示。</p>
<p><img src="Image00142.jpg" alt></p>
<p>图8-16 CIFAR图片输出1</p>
<p><img src="Image00143.jpg" alt></p>
<p>图8-17 CIFAR图片输出2</p>
<p>这次得到的是真实的原始图片，尺寸为32×32×3。</p>
<h4 id="8-5-5-cifar10-input的其他功能"><a href="#8-5-5-cifar10-input的其他功能" class="headerlink" title="8.5.5 cifar10_input的其他功能"></a>8.5.5 cifar10_input的其他功能</h4><p>cifar10_input.py文件里还有个功能更强大的数据——distorted_inputs，可以在代码里找到其实现。它是针对train数据的，对train数据进行了变形处理，起到一个数据增广的作用。在数据集比较小、数据量远远不够的情况下，可以对图片进行翻转、随机剪切等操作以增加数据，制造出更加多的样本，提高对图片的利用率。</p>
<p>这部分功能的核心代码在cifar10_input.py文件的第169～183行。具体代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Randomly crop a [height, width] section of the image.</span><br><span class="line">  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])</span><br><span class="line"> </span><br><span class="line">  # Randomly flip the image horizontally.</span><br><span class="line">  distorted_image = tf.image.random_flip_left_right(distorted_image)</span><br><span class="line"> </span><br><span class="line">  # Because these operations are not commutative, consider randomizing</span><br><span class="line">  # the order their operation.</span><br><span class="line">  distorted_image = tf.image.random_brightness(distorted_image,</span><br><span class="line">                                               max_delta=63)</span><br><span class="line">  distorted_image = tf.image.random_contrast(distorted_image,</span><br><span class="line">                                             lower=0.2, upper=1.8)</span><br><span class="line"> </span><br><span class="line">  # Subtract off the mean and divide by the variance of the pixels.</span><br><span class="line">  float_image = tf.image.per_image_standardization(distorted_image)</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码中分别调用了不同的函数对图片进行不同的变换，具体解释如下。</p>
<p>·tf.random_crop：为图片随机裁剪。</p>
<p>·tf.image.random_flip_left_right：随机左右翻转。</p>
<p>·tf.image.random_brightness：随机亮度变化。</p>
<p>·tf.image.random_contrast：随机对比度变化。</p>
<p>·tf.image.per_image_standardization：减去均值像素，并除以像素方差（图片标准化）。</p>
<p><img src="Image00014.jpg" alt> 注意： 这些函数都是增加数据的好方法，读者可以积累起来，在自己的训练样本中使用。</p>
<h4 id="8-5-6-在TensorFlow中使用queue"><a href="#8-5-6-在TensorFlow中使用queue" class="headerlink" title="8.5.6 在TensorFlow中使用queue"></a>8.5.6 在TensorFlow中使用queue</h4><p>TensorFlow提供了一个队列机制，通过多线程将读取数据与计算数据分开。因为在处理海量数据集的训练时，无法把数据集一次全部载入到内存中，需要一边从硬盘中读取，一边进行训练计算。</p>
<p>对于建立队列读取文件部分的代码，已经在cifar10_input.py里实现了。因为这部分不是本书的重点，所以不做太多介绍，有兴趣的读者可以看下cifar10_input.py里面的源码。</p>
<p>在这里主要讲解内部机制及如何使用，这里分为以下3个知识点。</p>
<p>1．队列线程启动及挂起机制</p>
<p>还记得8.5.4节中的例子代码（“8-5 CIFAR.py”），在session里面有这么一句：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.start_queue_runners()</span><br></pre></td></tr></table></figure>

</details>

<p>可以试着将其注释掉，然后运行一下看下效果——程序不动了，这时处于一个挂起状态，start_queue_runners的作用是启动线程，向队列里面读数据。那么为什么会挂起呢？源于下面的这句代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_batch, label_batch = sess.run([images_test, labels_test])</span><br></pre></td></tr></table></figure>

</details>

<p>这句话的意思是从队列里拿出指定批次的数据。但是队列里没有数据，所以程序进入挂起等待状态。</p>
<p>2．在session内部的退出机制</p>
<p>接下来可以把代码“8-5 CIFAR.py”文件中的session部分改成with语法，如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    tf.train.start_queue_runners()</span><br><span class="line">    image_batch, label_batch = sess.run([images_test, labels_test])</span><br><span class="line">    print(&quot;__\n&quot;,image_batch[0])</span><br><span class="line">    </span><br><span class="line">    print(&quot;__\n&quot;,label_batch[0])</span><br><span class="line">    pylab.imshow(image_batch[0])</span><br><span class="line">    pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>再次运行程序，发现虽然程序能够正常运行，但是结束后会报错，输出如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Session has been closed.</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Run call was cancelled</span><br><span class="line">ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>原因就是带with语法的session是自动关闭的。当运行结束后session自动关闭的同时会把里面所有的操作都关掉，而此时的队列还在等待另一个进程往里写数据，所以就会出现错误。最简单的解决方法就是如代码“8-5 CIFAR.py”文件中的session创建方式，使用sess = tf.InteractiveSession来实现。或者，也可以在原来代码中去掉with语句（将上面代码的第1行改后下面代码的第1行），但后面的操作都要指定属于哪个session（将上一段代码的第1～3行改后下面代码的第1～3行）。改完之后的代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">tf.global_variables_initializer().run(session=sess)</span><br><span class="line">tf.train.start_queue_runners(sess=sess)</span><br><span class="line">image_batch, label_batch = sess.run([images_test, labels_test])</span><br><span class="line">print(&quot;__\n&quot;,image_batch[0])</span><br><span class="line"> </span><br><span class="line">print(&quot;__\n&quot;,label_batch[0])</span><br><span class="line">pylab.imshow(image_batch[0])</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码在单例程序中没什么问题，资源会随着程序关闭而整体销毁。但如果在复杂的代码中，需要某个线程自动关闭，而不是依赖进程的结束而销毁，这种情况下需要使用tf.train.Coordinator函数来创建一个协调器，以信号量的方式来协调线程间的关系，完成线程间的同步。</p>
<h4 id="8-5-7-实例42：协调器的用法演示"><a href="#8-5-7-实例42：协调器的用法演示" class="headerlink" title="8.5.7 实例42：协调器的用法演示"></a>8.5.7 实例42：协调器的用法演示</h4><p>下面来看一下协调器的用法。</p>
<p>在本例子中，先建立一个100大小的队列。主线程使用计数器不停地加1，队列线程再把主线程里的计数器放到队列里。当队列为空时，主线程在sess.run（queue.dequeue（））语句位置挂起，当队列线程写入对列中时，主线程的计数器同步开始工作。整个操作都是在使用with语法的session中进行的，由于使用了Coordinator，当session要关闭之前会进行coord.request_stop函数将所有线程关闭，之后才会关闭session。</p>
<p>代码8-7 queue</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"> </span><br><span class="line">#创建长度为100的队列  </span><br><span class="line">queue = tf.FIFOQueue(100,&quot;float&quot;)</span><br><span class="line"> </span><br><span class="line">c = tf.Variable(0.0)              #计数器  </span><br><span class="line">#加1操作 </span><br><span class="line">op = tf.assign_add(c,tf.constant(1.0))  </span><br><span class="line">#操作:将计数器的结果加入队列  </span><br><span class="line">enqueue_op = queue.enqueue(c)  </span><br><span class="line">  </span><br><span class="line">#创建一个队列管理器QueueRunner，用这两个操作向q中添加元素。目前我们只使用一个线程</span><br><span class="line">qr = tf.train.QueueRunner(queue,enqueue_ops=[op,enqueue_op]) </span><br><span class="line"> </span><br><span class="line">with tf.Session() as sess:  </span><br><span class="line">    sess.run(tf.global_variables_initializer())  </span><br><span class="line">       </span><br><span class="line">    coord = tf.train.Coordinator()  </span><br><span class="line">      </span><br><span class="line">    # 启动入队线程，Coordinator是线程的参数  </span><br><span class="line">    enqueue_threads = qr.create_threads(sess, coord = coord,start=True)</span><br><span class="line">     # 启动入队线程  </span><br><span class="line">      </span><br><span class="line">    # 主线程  </span><br><span class="line">    for i in range(0, 10):  </span><br><span class="line">        print (&quot;-------------------------&quot;)  </span><br><span class="line">        print(sess.run(queue.dequeue()))  </span><br><span class="line">      </span><br><span class="line">     </span><br><span class="line">    coord.request_stop()  #通知其他线程关闭 其他所有线程关闭之后，这一函数才能返回</span><br></pre></td></tr></table></figure>

</details>

<p>运行以上代码，输出如下信息：（可以看到并没有报错）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">3.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br><span class="line">-------------------------</span><br><span class="line">.0</span><br></pre></td></tr></table></figure>

</details>

<p>这里还可以使用coord.join（enqueue_threads）指定等待某个进程结束。</p>
<h4 id="8-5-8-实例43：为session中的队列加上协调器"><a href="#8-5-8-实例43：为session中的队列加上协调器" class="headerlink" title="8.5.8 实例43：为session中的队列加上协调器"></a>8.5.8 实例43：为session中的队列加上协调器</h4><p>这里将上例中的coord放到启动队列里即可。</p>
<p>实例描述</p>
<p>在with tf.Session函数中加入启动队列，并通过加入coord协调器的方式使session close时同步内部线程一起退出。</p>
<p>修改“8-5cifar”代码如下。</p>
<p>代码8-8 cifar队列协调器（部分代码）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    #定义协调器</span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    threads = tf.train.start_queue_runners(sess, coord)</span><br><span class="line">    </span><br><span class="line">    image_batch, label_batch = sess.run([images_test, labels_test])</span><br><span class="line">    print(&quot;__\n&quot;,image_batch[0])</span><br><span class="line">    </span><br><span class="line">    print(&quot;__\n&quot;,label_batch[0])</span><br><span class="line">    pylab.imshow(image_batch[0])</span><br><span class="line">    pylab.show()</span><br><span class="line">    coord.request_stop()</span><br></pre></td></tr></table></figure>

</details>

<h4 id="8-5-9-实例44：建立一个带有全局平均池化层的卷积神经网络"><a href="#8-5-9-实例44：建立一个带有全局平均池化层的卷积神经网络" class="headerlink" title="8.5.9 实例44：建立一个带有全局平均池化层的卷积神经网络"></a>8.5.9 实例44：建立一个带有全局平均池化层的卷积神经网络</h4><p>现在正式开始卷积神经网络的示例。在本示例中，使用了全局平均池化层来代替传统的全连接层，使用了3个卷积层的同卷积操作，滤波器为5×5，每个卷积层后面都会跟个步长为2×2的池化层，滤波器为2×2。2层的卷积加池化后是输出为10个通道的卷积层，然后对这10个feature map进行全局平均池化，得到10个特征，再对这10个特征进行softmax计算，其结果来代表最终分类。</p>
<p>实例描述</p>
<p>通过一个带有全局平局池化层的卷积神经网络对CIFAR数据集分类。</p>
<p>具体步骤如下：</p>
<p>1．导入头文件引入数据集</p>
<p>这步骤与前面的代码相似，还是使用cifar10_input里面的代码，导入这种被切割后的24×24尺寸图片。每次取128个图片进行运算。在“cifar10”文件夹下建立“8-9cifar卷积.py”文件，编写如下代码。</p>
<p>代码8-9 cifar卷积</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> import cifar10_input</span><br><span class="line"> import tensorflow as tf</span><br><span class="line"> import numpy as np</span><br><span class="line"> </span><br><span class="line"> batch_size = 128</span><br><span class="line"> data_dir = &apos;/tmp/cifar10_data/cifar-10-batches-bin&apos;</span><br><span class="line"> print(&quot;begin&quot;)</span><br><span class="line"> images_train, labels_train = cifar10_input.inputs(eval_data = False,</span><br><span class="line">data_dir = data_dir, batch_size = batch_size)</span><br><span class="line"> images_test, labels_test = cifar10_input.inputs(eval_data = True, data_</span><br><span class="line">dir = data_dir, batch_size = batch_size)</span><br><span class="line"> print(&quot;begin data&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义网络结构</p>
<p>对于权重w的定义，统一使用函数truncated_normal来生成标准差为0.1的随机数为其初始化。对于权重b的定义，统一初始化为0.1。</p>
<p>卷积操作的函数中，统一进行同卷积操作，即步长为1，padding=’SAME’。</p>
<p>池化层有两个函数：</p>
<p>·一个是放在卷积后面，取最大值的方法，步长为2，padding=’SAME’，即将原尺寸的长和宽各除以2。</p>
<p>·另一个是用来放在最后一层，取均值的方法，步长为最终生成的特征尺寸6×6（24×24经过两次池化变成了6×6），filter也为6×6。</p>
<p>倒数第二层是没有最大池化的卷积层，因为共有10类，所以卷积输出的是10个通道，并使其全局平均池化为10个节点。</p>
<p>代码8-9 cifar卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">def weight_variable(shape):</span><br><span class="line">  initial = tf.truncated_normal(shape, stddev=0.1)</span><br><span class="line">  return tf.Variable(initial)</span><br><span class="line"></span><br><span class="line">def bias_variable(shape):</span><br><span class="line">  initial = tf.constant(0.1, shape=shape)</span><br><span class="line">  return tf.Variable(initial)</span><br><span class="line">  </span><br><span class="line">def conv2d(x, W):</span><br><span class="line">  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</span><br><span class="line"></span><br><span class="line">def max_pool_2x2(x):</span><br><span class="line">  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],</span><br><span class="line">                        strides=[1, 2, 2, 1], padding=&apos;SAME&apos;)  </span><br><span class="line">                        </span><br><span class="line">def avg_pool_6x6(x):</span><br><span class="line">  return tf.nn.avg_pool(x, ksize=[1, 6, 6, 1],</span><br><span class="line">                        strides=[1, 6, 6, 1], padding=&apos;SAME&apos;)</span><br><span class="line"></span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 24,24,3]) # cifar data的shape 24*24*3</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10])  # 0～9 数字分类=&gt; 10 classes</span><br><span class="line"></span><br><span class="line">W_conv1 = weight_variable([5, 5, 3, 64])</span><br><span class="line">b_conv1 = bias_variable([64])</span><br><span class="line"></span><br><span class="line">x_image = tf.reshape(x, [-1,24,24,3])</span><br><span class="line"></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line">W_conv2 = weight_variable([5, 5, 64, 64])</span><br><span class="line">b_conv2 = bias_variable([64])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line">W_conv3 = weight_variable([5, 5, 64, 10])</span><br><span class="line">b_conv3 = bias_variable([10])</span><br><span class="line">h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)</span><br><span class="line"></span><br><span class="line">nt_hpool3=avg_pool_6x6(h_conv3)#10</span><br><span class="line">nt_hpool3_flat = tf.reshape(nt_hpool3, [-1, 10])</span><br><span class="line">y_conv=tf.nn.softmax(nt_hpool3_flat)</span><br><span class="line"></span><br><span class="line">cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))</span><br><span class="line"></span><br><span class="line">train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br></pre></td></tr></table></figure>

</details>

<p>对于梯度优化算法，还是和多分类问题一样，我们使用AdamOptimizer函数，学习率使用0.0001。</p>
<p>3．运行session进行训练</p>
<p>启动session，迭代15000次数据集，这里记着要启动队列，同时读出来的label还要转成onehot编码。</p>
<p>代码8-9 cifar卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">tf.train.start_queue_runners(sess=sess)</span><br><span class="line">for i in range(15000):#20000</span><br><span class="line">  image_batch, label_batch = sess.run([images_train, labels_train])</span><br><span class="line">  label_b = np.eye(10,dtype=float)[label_batch]  #one hot编码</span><br><span class="line">  </span><br><span class="line">  train_step.run(feed_dict=&#123;x:image_batch, y: label_b&#125;,session=sess)</span><br><span class="line">  </span><br><span class="line">  if i%200 == 0:</span><br><span class="line">    train_accuracy = accuracy.eval(feed_dict=&#123;</span><br><span class="line">        x:image_batch, y: label_b&#125;,session=sess)</span><br><span class="line">    print( &quot;step %d, training accuracy %g&quot;%(i, train_accuracy))</span><br></pre></td></tr></table></figure>

</details>

<p>4．评估结果</p>
<p>从测试数据集里将数据取出，放到模型里运行，查看模型的正确率。</p>
<p>代码8-9 cifar卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image_batch, label_batch = sess.run([images_test, labels_test])</span><br><span class="line">label_b = np.eye(10,dtype=float)[label_batch] #one hot编码</span><br><span class="line">print (&quot;finished！ test accuracy %g&quot;%accuracy.eval(feed_dict=&#123;</span><br><span class="line">     x:image_batch, y: label_b&#125;,session=sess))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#begin</span><br><span class="line">#begin data</span><br><span class="line">#step 0, training accuracy 0.15625</span><br><span class="line">#step 200, training accuracy 0.3125</span><br><span class="line">#step 400, training accuracy 0.359375</span><br><span class="line">#step 600, training accuracy 0.3125</span><br><span class="line">#step 800, training accuracy 0.382812</span><br><span class="line">#step 1000, training accuracy 0.273438</span><br><span class="line">……</span><br><span class="line">#step 14400, training accuracy 0.554688</span><br><span class="line">#step 14600, training accuracy 0.601562</span><br><span class="line">#step 14800, training accuracy 0.5625</span><br><span class="line">#finished！ test accuracy 0.632812</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出，识别效果得到了收敛，正确率在0.6左右，这个正确率不算很高，因为模型相对简单，只是用了两层的卷积操作。接下来还将介绍更多的优化方法来提升准确率。</p>
<p><img src="Image00014.jpg" alt> 注意： 例子中对于卷积和池化的使用也表明了一种习惯，一般在卷积过程中都会设为步长为1的same卷积，即大小不变，需要降维时则是全部通过池化来完成的。</p>
<h4 id="8-5-10-练习题"><a href="#8-5-10-练习题" class="headerlink" title="8.5.10 练习题"></a>8.5.10 练习题</h4><p>（1）使用前面所学的知识，试着将MNIST图片集进行分类（见代码“8-10 MNIST卷积.py”文件）。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def max_pool_with_argmax(net, stride):</span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[1, stride, stride, </span><br><span class="line">   1], strides=[1, stride, stride, 1],padding=&apos;SAME&apos;)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[1, stride, stride, 1],strides=[1, </span><br><span class="line">   stride, stride, 1], padding=&apos;SAME&apos;) </span><br><span class="line">    return net, mask</span><br></pre></td></tr></table></figure>

</details>

<p>（2）将CIFAR卷积分类的例子中最后一层改成全连接网络，试试看会有什么效果（见代码“8-11 Cifar全连接卷积.py”）</p>
<h3 id="8-6-反卷积神经网络"><a href="#8-6-反卷积神经网络" class="headerlink" title="8.6 反卷积神经网络"></a>8.6 反卷积神经网络</h3><p>反卷积是指，通过测量输出和已知输入重构未知输入的过程。在神经网络中，反卷积过程并不具备学习的能力，仅仅是用于可视化一个已经训练好的卷积网络模型，没有学习训练的过程。</p>
<p>如图8-18所示为VGG 16反卷积神经网络的结构，展示了一个卷积网络与反卷积网络结合的过程。VGG 16是一个深度神经网络模型，在后面会专门介绍。它的反卷积就是将中间的数据，按照前面卷积、池化等变化的过程，完全相反地做一遍，从而得到类似原始输入的数据。</p>
<p><img src="Image00144.jpg" alt></p>
<p>图8-18 VGG 16反卷积结构</p>
<h4 id="8-6-1-反卷积神经网络的应用场景"><a href="#8-6-1-反卷积神经网络的应用场景" class="headerlink" title="8.6.1 反卷积神经网络的应用场景"></a>8.6.1 反卷积神经网络的应用场景</h4><p>由于反卷积网络的特性，导致它有许多特别的应用，一般可以用于信道均衡、图像恢复、语音识别、地震学、无损探伤等未知输入估计和过程辨识方面的问题。</p>
<p>在神经网络的研究中，反卷积更多的是充当可视化的作用。对于一个复杂的深度卷积网络，通过每层若干个卷积核的变换，我们无法知道每个卷积核关注的是什么，变换后的特征是什么样子。通过反卷积的还原，可以对这些问题有个清晰的可视化，以各层得到的特征图作为输入，进行反卷积，得到反卷积结果，用以验证显示各层提取到的特征图。</p>
<h4 id="8-6-2-反卷积原理"><a href="#8-6-2-反卷积原理" class="headerlink" title="8.6.2 反卷积原理"></a>8.6.2 反卷积原理</h4><p>反卷积，可以理解为卷积操作的逆操作。这里千万不要当成反卷积操作可以复原卷积操作的输入值，反卷积并没有那个功能，它仅仅是将卷积变换过程中的步骤反向变换一次而已，通过将卷积核转置，与卷积后的结果再做一遍卷积，所以它还有个名字叫是转置卷积。</p>
<p>虽然它不能还原出原来卷积的样子，但是在作用上具有类似的效果，可以将带有小部分缺失的信息最大化地恢复，也可以用来恢复被卷积生成后的原始输入。</p>
<p>反卷积的具体操作比较复杂，具体步骤如下。</p>
<p>（1）首先是将卷积核反转（并不是转置，而是上下左右方向进行递序操作）。</p>
<p>（2）再将卷积结果作为输入，做补0的扩充操作，即往每一个元素后面补0。这一步是根据步长来的，对每一个元素沿着步长的方向补（步长-1）个0。例如，步长为1就不用补0了。</p>
<p>（3）在扩充后的输入基础上再对整体补0。以原始输入的shape作为输出，按照前面介绍的卷积padding规则，计算pading的补0位置及个数，得到的补0位置要上下和左右各自颠倒一下。</p>
<p>（4）将补0后的卷积结果作为真正的输入，反转后的卷积核为filter，进行步长为1的卷积操作。</p>
<p><img src="Image00014.jpg" alt> 注意： 计算padding按规则补0时，统一按照padding=’SAME’、步长为1×1的方式来计算。</p>
<p>如图8-19所示，以一个[1，4，4，1]的矩阵为例，进行filter为2×2，步长为2×2的卷积操作（如图8-19a所示），其对应的反卷积操作步骤如图8-19b所示。</p>
<p><img src="Image00145.jpg" alt></p>
<p>图8-19 卷积与反卷积操作</p>
<p>在反卷积过程中，首先将2×2矩阵通过步长补0的方式变成4×4，再通过padding反方向补0，然后与反转后的filter使用步长为1×1的卷积操作，最终得出了结果。但是这个结果已经与原来的全1矩阵不等了，说明转置卷积只能恢复部分特征，无法百分百地恢复原始数据。</p>
<h4 id="8-6-3-实例45：演示反卷积的操作"><a href="#8-6-3-实例45：演示反卷积的操作" class="headerlink" title="8.6.3 实例45：演示反卷积的操作"></a>8.6.3 实例45：演示反卷积的操作</h4><p>在编写反卷积代码时，心中想着一个正向的卷积过程会很有帮助。在TensorFlow中反卷积是通过函数tf.nn.conv2d_transpose来实现的，其定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def conv2d_transpose(value,</span><br><span class="line">                     filter,</span><br><span class="line">                     output_shape,</span><br><span class="line">                     strides,</span><br><span class="line">                     padding=&quot;SAME&quot;,</span><br><span class="line">                     data_format=&quot;NHWC&quot;,</span><br><span class="line">                     name=None):</span><br></pre></td></tr></table></figure>

</details>

<p>具体参数说明如下。</p>
<p>·value：代表通过卷积操作之后的张量，一般用NHWC类型。</p>
<p>·filter：代表卷积核。</p>
<p>·output_shape：代表输出的张量形状也是个四维张量。</p>
<p>·strides：代表步长。</p>
<p>·padding：代表原数据生成value时使用的补0的方式，是用来检查输入形状和输出形状是否合规的。</p>
<p>·return：反卷积后的结果，按照output_shape指定的形状。</p>
<p><img src="Image00014.jpg" alt> 注意： NHWC类型是神经网络中在处理图像方面常用的类型，4个字母分别代表4个意思，即N-个数、H-高、W-宽、C-通道数。也就是我们常见的四维张量。</p>
<p><img src="Image00014.jpg" alt> 注意： output_shape并不是一个随便填写的形状，它必须是能够生成value参数的原数据的形状，如果输出形状不对，函数会报错。</p>
<p>跟进TensorFlow的源码中可以看到，反卷积操作其实是使用了gen_nn_ops.conv2d_ backprop_input函数来最终实现的，相当于TensorFlow中利用了卷积操作在反向传播的处理函数中做反卷积操作，即卷积操作的反向传播就是反卷积操作。</p>
<p>下面通过例子将前面图示的数据演示出来，并且比较一下SAME和VALID下对应卷积和反卷积的影响。</p>
<p>实例描述</p>
<p>通过对模拟数据进行卷积与反卷积的操作，来比较卷积与反卷积中padding在SAME、VALID下的变化。</p>
<p>代码8-12 反卷积操作</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf </span><br><span class="line">#模拟数据</span><br><span class="line">img = tf.Variable(tf.constant(1.0,shape = [1, 4, 4, 1])) </span><br><span class="line"> </span><br><span class="line">filter =  tf.Variable(tf.constant([1.0,0,-1,-2],shape = [2, 2, 1, 1]))</span><br><span class="line">#分别进行VALID与SAME操作</span><br><span class="line">conv = tf.nn.conv2d(img, filter, strides=[1, 2, 2, 1], padding=&apos;VALID&apos;) </span><br><span class="line">cons = tf.nn.conv2d(img, filter, strides=[1, 2, 2, 1], padding=&apos;SAME&apos;)</span><br><span class="line">print(conv.shape)</span><br><span class="line">print(cons.shape)</span><br><span class="line">#再进行反卷积</span><br><span class="line">contv= tf.nn.conv2d_transpose(conv, filter, [1,4,4,1],strides=[1, 2, 2, </span><br><span class="line">1], padding=&apos;VALID&apos;)</span><br><span class="line">conts = tf.nn.conv2d_transpose(cons, filter, [1,4,4,1],strides=[1, 2, 2, </span><br><span class="line">1], padding=&apos;SAME&apos;)</span><br><span class="line"> </span><br><span class="line">with tf.Session() as sess:  </span><br><span class="line">    sess.run(tf.global_variables_initializer() )  </span><br><span class="line"> </span><br><span class="line">    print(&quot;conv:\n&quot;,sess.run([conv,filter])) </span><br><span class="line">    print(&quot;cons:\n&quot;,sess.run([cons]))    </span><br><span class="line">    print(&quot;contv:\n&quot;,sess.run([contv])) </span><br><span class="line">    print(&quot;conts:\n&quot;,sess.run([conts]))</span><br></pre></td></tr></table></figure>

</details>

<p>先定义一个[1，4，4，1]的矩阵，矩阵里的值全为1，进行filter为2×2、步长为2×2的卷积操作，分别使用padding为SAME和VALID的两种情况生成卷积数据，然后将结果放到 tf.nn.conv2d_transpose里，再次使用padding为SAME和VALID的两种情况生成数据，运行上面代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">(1, 2, 2, 1)</span><br><span class="line">(1, 2, 2, 1)</span><br><span class="line">conv:</span><br><span class="line"> [array([[[[-2.],</span><br><span class="line">         [-2.]],</span><br><span class="line">        [[-2.],</span><br><span class="line">         [-2.]]]], dtype=float32), array([[[[ 1.]],</span><br><span class="line">        [[ 0.]]],</span><br><span class="line">       [[[-1.]],</span><br><span class="line">        [[-2.]]]], dtype=float32)]</span><br><span class="line">cons:</span><br><span class="line"> [array([[[[-2.],</span><br><span class="line">         [-2.]],</span><br><span class="line">        [[-2.],</span><br><span class="line">         [-2.]]]], dtype=float32)]</span><br><span class="line">contv:</span><br><span class="line"> [array([[[[-2.],</span><br><span class="line">         [ 0.],</span><br><span class="line">         [-2.],</span><br><span class="line">         [ 0.]],</span><br><span class="line">        [[ 2.],</span><br><span class="line">         [ 4.],</span><br><span class="line">         [ 2.],</span><br><span class="line">         [ 4.]],</span><br><span class="line">        [[-2.],</span><br><span class="line">         [ 0.],</span><br><span class="line">         [-2.],</span><br><span class="line">         [ 0.]],</span><br><span class="line">        [[ 2.],</span><br><span class="line">         [ 4.],</span><br><span class="line">         [ 2.],</span><br><span class="line">         [ 4.]]]], dtype=float32)]</span><br><span class="line">conts:</span><br><span class="line"> [array([[[[-2.],</span><br><span class="line">         [ 0.],</span><br><span class="line">         [-2.],</span><br><span class="line">         [ 0.]],</span><br><span class="line">        [[ 2.],</span><br><span class="line">         [ 4.],</span><br><span class="line">         [ 2.],</span><br><span class="line">         [ 4.]],</span><br><span class="line">        [[-2.],</span><br><span class="line">         [ 0.],</span><br><span class="line">         [-2.],</span><br><span class="line">         [ 0.]],</span><br><span class="line">        [[ 2.],</span><br><span class="line">         [ 4.],</span><br><span class="line">         [ 2.],</span><br><span class="line">         [ 4.]]]], dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，输出的结果与图8-19是一样的，并且也验证了当panding为SAME并且不需要补0时，卷积和反卷积对于panding是SAME和VALID都是相同的。</p>
<h4 id="8-6-4-反池化原理"><a href="#8-6-4-反池化原理" class="headerlink" title="8.6.4 反池化原理"></a>8.6.4 反池化原理</h4><p>反池化是属于池化的逆操作，是无法通过池化的结果还原出全部的原始数据。因为池化的过程就是只保留主要信息，舍去部分信息。如想从池化后的这些主要信息恢复出全部信息，则存在着信息缺失，这时只能通过补位来实现最大程度的信息完整。</p>
<p>池化有两种最大池化和平均池化，其反池化也需要与其对应。</p>
<p>·平均池化的操作比较简单。首先还原成原来的大小，然后将池化结果中的每个值都填入其对应于原始数据区域中的相应位置即可，如图8-20所示。</p>
<p><img src="Image00146.jpg" alt></p>
<p>图8-20 反平均池化</p>
<p>·最大池化的反池化会复杂一些。要求在池化过程中记录最大激活值的坐标位置，然后在反池化时，只把池化过程中最大激活值所在位置坐标的值激活，其他的值置为0。当然，这个过程只是一种近似。因为在池化的过程中，除了最大值所在的位置，其他的值也是不为0的。如图8-21所示。</p>
<p><img src="Image00147.jpg" alt></p>
<p>图8-21 反最大池化</p>
<h4 id="8-6-5-实例46：演示反池化的操作"><a href="#8-6-5-实例46：演示反池化的操作" class="headerlink" title="8.6.5 实例46：演示反池化的操作"></a>8.6.5 实例46：演示反池化的操作</h4><p>TensorFlow中目前还没有反池化操作的函数。对于最大池化，也不支持输出最大激活值的位置，但是同样有个池化的反向传播函数tf.nn.max_pool_with_argmax。该函数可以输出位置，需要开发者利用这个函数做一些改动，自己封装一个最大池化操作，然后再根据mask写出反池化函数，下面以反最大池化为例。</p>
<p>实例描述</p>
<p>定义一个数组作为模拟图片，将其进行最大池化，接着再进行反池化，比较原始数据与反池化后的数据。</p>
<p>首先重新定义最大池化函数，代码如下。</p>
<p>代码8-13 反池化操作</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def max_pool_with_argmax(net, stride):</span><br><span class="line">    _, mask = tf.nn.max_pool_with_argmax( net,ksize=[1, stride, stride, </span><br><span class="line">   1], strides=[1, stride, stride, 1],padding=&apos;SAME&apos;)</span><br><span class="line">    mask = tf.stop_gradient(mask)</span><br><span class="line">    net = tf.nn.max_pool(net, ksize=[1, stride, stride, 1],strides=[1, </span><br><span class="line">   stride, stride, 1], padding=&apos;SAME&apos;) </span><br><span class="line">    return net, mask</span><br></pre></td></tr></table></figure>

</details>

<p>在上面代码里，先调用tf.nn.max_pool_with_argmax函数获得每个最大值的位置mask，再将反向传播的mask梯度计算停止（后面会有关于梯度停止的介绍），接着再用tf.nn.max_pool函数计算最大池化操作，然后将mask和池化结果一起返回。</p>
<p><img src="Image00014.jpg" alt> 注意： tf.nn.max_pool_with_argmax的方法只支持GPU操作，所以利用这个方法目前还不能在CPU机器上使用。</p>
<p>接下来定义一个数组，并使用最大池化函数对其进行池化操作，比较一下与自带的tf.nn.max_pool函数是否一样，看看输出的mask是什么效果。</p>
<p>代码8-13 反池化操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">img=tf.constant([  </span><br><span class="line">        [[0.0,4.0],[0.0,4.0],[0.0,4.0],[0.0,4.0]],  </span><br><span class="line">        [[1.0,5.0],[1.0,5.0],[1.0,5.0],[1.0,5.0]],  </span><br><span class="line">        [[2.0,6.0],[2.0,6.0],[2.0,6.0],[2.0,6.0]],  </span><br><span class="line">        [[3.0,7.0],[3.0,7.0], [3.0,7.0],[3.0,7.0]]</span><br><span class="line">    ])  </span><br><span class="line">  </span><br><span class="line">img=tf.reshape(img,[1,4,4,2])  </span><br><span class="line">pooling2=tf.nn.max_pool(img,[1,2,2,1],[1,2,2,1],padding=&apos;SAME&apos;)  </span><br><span class="line">encode, mask = max_pool_with_argmax(img, 2)</span><br><span class="line">with tf.Session() as sess:  </span><br><span class="line">    print(&quot;image:&quot;)  </span><br><span class="line">    image=sess.run(img)  </span><br><span class="line">    print (image)     </span><br><span class="line">    result=sess.run(pooling2)  </span><br><span class="line">    print (&quot;pooling2:\n&quot;,result)</span><br><span class="line">    result,mask2=sess.run([encode, mask])  </span><br><span class="line">    print (&quot;encode:\n&quot;,result,mask2)</span><br></pre></td></tr></table></figure>

</details>

<p>代码运行后，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">image:</span><br><span class="line">[[[[ 0.  4.]</span><br><span class="line">   [ 0.  4.]</span><br><span class="line">   [ 0.  4.]</span><br><span class="line">   [ 0.  4.]]</span><br><span class="line"> </span><br><span class="line">  [[ 1.  5.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 2.  6.]</span><br><span class="line">   [ 2.  6.]</span><br><span class="line">   [ 2.  6.]</span><br><span class="line">   [ 2.  6.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]]</span><br><span class="line">pooling2:</span><br><span class="line"> [[[[ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]]</span><br><span class="line">encode:</span><br><span class="line"> [[[[ 1.  5.]</span><br><span class="line">   [ 1.  5.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 3.  7.]]]] [[[[ 8  9]</span><br><span class="line">   [12 13]]</span><br><span class="line"> </span><br><span class="line">  [[24 25]</span><br><span class="line">   [28 29]]]]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，定义的最大池化与原来的版本输出是一样的。mask的值是将整个数组flat（扁平化）后的索引，但却保持与池化结果一致的shape。</p>
<p>了解这些信息后，就可以接着写代码，定义一个反最大池化的操作了。</p>
<p>代码8-13 反池化操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def unpool(net, mask, stride):</span><br><span class="line"></span><br><span class="line">    ksize = [1, stride, stride, 1]</span><br><span class="line">    input_shape = net.get_shape().as_list()</span><br><span class="line">    #  计算new shape</span><br><span class="line">    output_shape = (input_shape[0], input_shape[1] * ksize[1], input_</span><br><span class="line">   shape[2] * ksize[2], input_shape[3])</span><br><span class="line">    # 计算索引</span><br><span class="line">    one_like_mask = tf.ones_like(mask)</span><br><span class="line">    batch_range = tf.reshape(tf.range(output_shape[0], dtype=tf.</span><br><span class="line">   int64), shape=[input_shape[0], 1, 1, 1])</span><br><span class="line">    b = one_like_mask * batch_range</span><br><span class="line">    y = mask // (output_shape[2] * output_shape[3])</span><br><span class="line">    x = mask % (output_shape[2] * output_shape[3]) // output_shape[3]</span><br><span class="line">    feature_range = tf.range(output_shape[3], dtype=tf.int64)</span><br><span class="line">    f = one_like_mask * feature_range</span><br><span class="line">    # 转置索引 </span><br><span class="line">    updates_size = tf.size(net)</span><br><span class="line">    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [4, </span><br><span class="line">   updates_size]))</span><br><span class="line">    values = tf.reshape(net, [updates_size])</span><br><span class="line">    ret = tf.scatter_nd(indices, values, output_shape)</span><br><span class="line">    return ret</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码的大概思路是找到mask对应的索引，将max的值填到指定地方。这里不做过多解释，读者可以将反向传播函数当成一个工具，以后直接使用即可。</p>
<p>下面调用反池化函数，并将结果打印出来。</p>
<p>代码8-13 反池化操作（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img2 = unpool(encode,mask,2)</span><br><span class="line">with tf.Session() as sess:  </span><br><span class="line">    ……</span><br><span class="line">    print (&quot;encode:\n&quot;,result,mask2)</span><br><span class="line">    result=sess.run(img2)  </span><br><span class="line">    print (&quot;reslut:\n&quot;,result)</span><br></pre></td></tr></table></figure>

</details>

<p>代码运行后，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">reslut:</span><br><span class="line"> [[[[ 0.  0.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 0.  0.]]</span><br><span class="line"> </span><br><span class="line">  [[ 1.  5.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 1.  5.]</span><br><span class="line">   [ 0.  0.]]</span><br><span class="line"> </span><br><span class="line">  [[ 0.  0.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 0.  0.]]</span><br><span class="line"> </span><br><span class="line">  [[ 3.  7.]</span><br><span class="line">   [ 0.  0.]</span><br><span class="line">   [ 3.  7.]</span><br><span class="line">   [ 0.  0.]]]]</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，最大值已经填入对应的位置，其他地方的值为0。</p>
<h4 id="8-6-6-实例47：演示gradients基本用法"><a href="#8-6-6-实例47：演示gradients基本用法" class="headerlink" title="8.6.6 实例47：演示gradients基本用法"></a>8.6.6 实例47：演示gradients基本用法</h4><p>这部分内容本来是要放在前面章节讲的，考虑到读者直接了解梯度相关的知识有些生硬，而且一时也用不上，所以就将这部分内容移到了本节中，这样，通过例子中引出的知识点，会使读者学习起来更加通顺。</p>
<p>实例描述</p>
<p>通过定义两个矩阵变量相乘来演示使用gradients求梯度。</p>
<p>在反向传播过程中，神经网络需要对每一个loss对应的学习参数求偏导，算出的这个值也叫梯度，用来乘以学习率然后更新学习参数使用的。它是通过tf.gradients函数来实现的。tf.gradients函数里第一个参数为求导公式的结果，第二个参数为指定公式中的哪个变量来求偏导。下面通过例子介绍tf.gradients函数的用法。</p>
<p>代码8-14 gradients0</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"> </span><br><span class="line">w1 = tf.Variable([[1,2]])</span><br><span class="line">w2 = tf.Variable([[3,4]])</span><br><span class="line"> </span><br><span class="line">y = tf.matmul(w1, [[9],[10]])</span><br><span class="line">grads = tf.gradients(y,[w1])       #求w1的梯度</span><br><span class="line"> </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    gradval = sess.run(grads)</span><br><span class="line">    print(gradval)</span><br></pre></td></tr></table></figure>

</details>

<p>运行后输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[array([[ 9, 10]])]</span><br></pre></td></tr></table></figure>

</details>

<p>上面例子中，由于y是由w1与[[9]，[10]]相乘而来，所以其导数也就是[[9]，[10]]（即斜率）。</p>
<p><img src="Image00014.jpg" alt> 注意： 如果求梯度的式子中没有要求偏导的变量，系统会报错。例如，写成grads = tf.gradients（y，[w1，w2]）。</p>
<h4 id="8-6-7-实例48：使用gradients对多个式子求多变量偏导"><a href="#8-6-7-实例48：使用gradients对多个式子求多变量偏导" class="headerlink" title="8.6.7 实例48：使用gradients对多个式子求多变量偏导"></a>8.6.7 实例48：使用gradients对多个式子求多变量偏导</h4><p>tf.gradients函数还可以同时对多个式子求关于多个变量的偏导，见如下代码</p>
<p>实例描述</p>
<p>有两个OP，4个参数，演示使用gradients同时为两个式子4个参数求梯度。</p>
<p>代码8-15 gradients1</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"> </span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">w1 = tf.get_variable(&apos;w1&apos;, shape=[2])</span><br><span class="line">w2 = tf.get_variable(&apos;w2&apos;, shape=[2])</span><br><span class="line"> </span><br><span class="line">w3 = tf.get_variable(&apos;w3&apos;, shape=[2])</span><br><span class="line">w4 = tf.get_variable(&apos;w4&apos;, shape=[2])</span><br><span class="line"> </span><br><span class="line">y1 = w1 + w2+ w3</span><br><span class="line">y2 = w3 + w4</span><br><span class="line"># grad_ys求梯度的输入值</span><br><span class="line">gradients = tf.gradients([y1,y2],[w1,w2,w3,w4],grad_ys=[tf. convert_to_</span><br><span class="line">tensor([1.,2.]),tf.convert_to_tensor([3.,4.])])</span><br><span class="line">       </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(gradients))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[array([1.,2.], dtype=float32), array([1.,2.], dtype=float32), array([ 4., </span><br><span class="line">6.], dtype=float32),array([ 3., 4.], dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>这里使用了tf.gradients函数的第三个参数，即给定公式结果的值，来求参数偏导，这里相当于y1为[1.，2.]、y2为[3.，4.]。对于y1来讲，求关于w1的偏导时，会认为w2和w3为常数，所以w1和w2的导数为0，即w1的梯度就为[1.，2.]。同理可以得出w2和w3均为[1.，2.]，接着求y2的偏导数，得到w3与w4均为[3.，4.]。然后将两个式子中的w3结果累加起来，所以w3就为[4.，6.]。</p>
<h4 id="8-6-8-实例49：演示梯度停止的实现"><a href="#8-6-8-实例49：演示梯度停止的实现" class="headerlink" title="8.6.8 实例49：演示梯度停止的实现"></a>8.6.8 实例49：演示梯度停止的实现</h4><p>实例描述</p>
<p>演示梯度停止的用法，并观察当变量设置梯度停止后，对其求梯度的结果。</p>
<p>对于反向传播过程中某种特殊情况需要停止梯度的运算时，在TensorFlow中提供了一个tf.stop_gradient函数，被它定义过的节点将没有梯度运算功能。</p>
<p>例如，在前面代码中加入y3结点。通过gradients2来计算其相关变量的梯度。</p>
<p>代码8-16 gradients2</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> a = w1+w2</span><br><span class="line"> a_stoped = tf.stop_gradient(a)              #令a梯度停止</span><br><span class="line"> y3= a_stoped+w3</span><br><span class="line"> </span><br><span class="line"> gradients = tf.gradients([y1,y2],[w1,w2,w3,w4], grad_ys=[tf.convert_</span><br><span class="line">to_tensor([1.,2.]),</span><br><span class="line">                                                          </span><br><span class="line">  tf.convert_to_tensor([3.,4.])])</span><br><span class="line">                                                           </span><br><span class="line"> gradients2 = tf.gradients(y3,[w1,w2,w3], grad_ys=tf.convert_to_tensor</span><br><span class="line">([1.,2.]))          </span><br><span class="line"> print(gradients2) </span><br><span class="line">                                                     </span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     sess.run(tf.global_variables_initializer())</span><br><span class="line">     print(sess.run(gradients))</span><br><span class="line">     print(sess.run(gradients2))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> [None, None, &lt;tf.Tensor &apos;gradients_1/add_4_grad/Reshape_1:0&apos; shape=(2,) </span><br><span class="line">dtype=float32&gt;]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到程序运行出错，并且在出错前显示了gradients2的内容，w1和w2对应的位置都为None，这是由于梯度被停止了。后面的程序试图去求一个None的梯度，所以报错了。</p>
<p>再定义一个gradients3，只求存在的梯度，同时将print（sess.run（gradients2））注释掉，代码如下。</p>
<p>代码8-16 gradients2（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> gradients3 = tf.gradients(y3, [ w3], grad_ys=tf.convert_to_tensor</span><br><span class="line">([1.,2.])) </span><br><span class="line">                                                        </span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     sess.run(tf.global_variables_initializer())</span><br><span class="line">     print(sess.run(gradients))</span><br><span class="line">     #print(sess.run(gradients2))   #程序试图去求一个None的梯度，所以报错</span><br><span class="line">     print(sess.run(gradients3))</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[None, None, &lt;tf.Tensor &apos;gradients_1/add_4_grad/Reshape_1:0&apos; shape=(2,) </span><br><span class="line">dtype=float32&gt;]</span><br><span class="line">[array([ 1.,  2.], dtype=float32), array([ 1.,  2.], dtype=float32), </span><br><span class="line">array([ 4.,  6.], dtype=float32), array([ 3.,  4.], dtype=float32)]</span><br><span class="line">[array([ 1.,  2.], dtype=float32)]</span><br></pre></td></tr></table></figure>

</details>

<p>这时就可以正常运算了。</p>
<h3 id="8-7-实例50：用反卷积技术复原卷积网络各层图像"><a href="#8-7-实例50：用反卷积技术复原卷积网络各层图像" class="headerlink" title="8.7 实例50：用反卷积技术复原卷积网络各层图像"></a>8.7 实例50：用反卷积技术复原卷积网络各层图像</h3><p>在了解了反卷积神经网络之后，下面通过一个例子将前面的卷积神经网络里的卷积层可视化出来，看看每一层到底学到了什么信息。</p>
<p>实例描述</p>
<p>将代码“8-9 cifar卷积.py”文件中的每层卷积结果进行反卷积并输出，通过tensorboard观察其结果。</p>
<p>改写代码代码“8-9 cifar卷积.py”，将每层的卷积内容可视化并在tensroboard中查看，具体步骤如下。</p>
<p>1．替换Maxpool池化函数</p>
<p>这里不再使用自己定义的max_pool_2x2池化函数，改成新加入的带mask返回值的max_pool_with_argmax函数，具体代码如下。</p>
<p>代码8-17 cifar反卷积</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">x_image = tf.reshape(x, [-1,24,24,3])</span><br><span class="line"></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1, mask1 = max_pool_with_argmax(h_conv1, 2)</span><br><span class="line"></span><br><span class="line">W_conv2 = weight_variable([5, 5, 64, 64])</span><br><span class="line">b_conv2 = bias_variable([64])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">#############################################################</span><br><span class="line">h_pool2, mask = max_pool_with_argmax(h_conv2, 2)#(128, 6, 6, 64)</span><br><span class="line">print(h_pool2.shape)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 上面代码的最后一行是将h_pool2的形状打印出来，这也是在组建网络结构时常用的一种调试方法。反卷积和反池化对形状都很敏感（尤其层数太多时），这种方法可以让我们不用花费太多精力来推导到底当前的输入是什么形状。</p>
<p>2．反卷积第二层卷积结果</p>
<p>以第二池化输出的变量h_pool2为开始部分，沿着h_pool2生成的方式反向操作一层一层推导，直到生成原始图t1_x_image。</p>
<p>如图8-22所示，上半部分是h_pool2卷积的过程，下半部分为反卷积过程。为了便于分析，下半部分的名字与代码中的变量一致。</p>
<p><img src="Image00148.jpg" alt></p>
<p>图8-22 反卷积例子</p>
<p>因为在卷积过程中，每个卷积后都要加上权重b，所以在反卷积过程中就要将b减去。由于Relu函数基本上是恒等变化（除了小于0的部分），所以在反向时不需要可逆操作，可以直接略去。</p>
<p>代码8-17 cifar反卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> t_conv2 = unpool(h_pool2, mask, 2)#(128, 12, 12, 64)</span><br><span class="line"> t_pool1 = tf.nn.conv2d_transpose(t_conv2-b_conv2, W_conv2, h_pool1.</span><br><span class="line">shape,[1,1,1,1])#(128, 24, 24, 64)</span><br><span class="line"> print(t_conv2.shape,h_pool1.shape,t_pool1.shape)</span><br><span class="line"> t_conv1 = unpool(t_pool1, mask1, 2)</span><br><span class="line"> t_x_image = tf.nn.conv2d_transpose(t_conv1-b_conv1, W_conv1, x_image.</span><br><span class="line">shape,[1,1,1,1])</span><br></pre></td></tr></table></figure>

</details>

<p>3．反卷积第一层卷积结果</p>
<p>参考第二层的反卷积，第一层会更为简单，代码如下。</p>
<p>代码8-17 cifar反卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#第一层卷积还原</span><br><span class="line">   t1_conv1 = unpool(h_pool1, mask1, 2)</span><br><span class="line">   t1_x_image = tf.nn.conv2d_transpose(t1_conv1-b_conv1, W_conv1, x_</span><br><span class="line">     image.shape,[1,1,1,1])</span><br></pre></td></tr></table></figure>

</details>

<p>4．合并还原结果，并输出给TensorBoard输出</p>
<p>这次是将结果通过TensorBoard进行展示，所以将生成的第一层图片和第二层图片与原始图片合在一起，统一放入tf.summary.image里，这样在TensorBoard的image里就能看到了。</p>
<p>代码8-17 cifar反卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> # 生成最终图像</span><br><span class="line"> stitched_decodings = tf.concat((x_image, t1_x_image,t_x_image), axis=2)</span><br><span class="line"> decoding_summary_op = tf.summary.image(&apos;source/cifar&apos;, stitched_</span><br><span class="line">decodings)</span><br></pre></td></tr></table></figure>

</details>

<p>5．session中写入log</p>
<p>按照前面介绍过的TensorBoard步骤，在session中建立一个summary_writer，然后在代码结尾处通过session.run运行前面的tf.summary.image操作，使用summary_writer将得出的结果写入log。</p>
<p>代码8-17 cifar反卷积（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> cross_entropy = -tf.reduce_sum(y*tf.log(y_conv)) +(tf.nn.l2_loss</span><br><span class="line">(W_conv1)+tf.nn.l2_loss(W_conv2)+tf.nn.l2_loss(W_conv3))</span><br><span class="line"> </span><br><span class="line"> train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</span><br><span class="line"> </span><br><span class="line"> correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"> sess = tf.Session()</span><br><span class="line"> sess.run(tf.global_variables_initializer())</span><br><span class="line"> summary_writer = tf.summary.FileWriter(&apos;./log/&apos;, sess.graph)</span><br><span class="line"> ……</span><br><span class="line"> decoding_summary = sess.run(decoding_summary_op,feed_dict=&#123;x:image_</span><br><span class="line">batch, y: label_b&#125;)</span><br><span class="line"> summary_writer.add_summary(decoding_summary)</span><br></pre></td></tr></table></figure>

</details>

<p>这里在计算cross_entropy时，对所有的w权重用了一次Loss2正则化。</p>
<p>6．Tensorboard中查看结果</p>
<p>运行以上代码后，就可以在TensorBoard中查看结果了。</p>
<p>上面的log是写在本代码同级目录下的log文件夹内，启动TensorBoard的步骤可以参考前面的介绍，这里不再多讲（一定要把路径要找对）。</p>
<p>上面的代码中，image定义的路径是source/cifar，所以在TensorBoard中单击image就会看到source，点开后就能看到如图8-23所示的图片。</p>
<p><img src="Image00149.jpg" alt></p>
<p>图8-23 反卷积结果1</p>
<p>图8-23中的数字是后面标注的。第1幅是原始图片，其很不清晰的原因是在cifar10_input.inputs代码中，将图片做的归一化（变成-1～1之间的数）。第2幅是第一个卷积层还原的图片，第3幅是最后一个卷积层还原的图片。可以看到，最后的卷积输出对图像的主要特征响应更强烈。</p>
<p>为了让图片看得更清晰，我们去掉归一化的操作，使用原始图片在模型中“跑”一下。来到“cifar10_input.py”文件中将第241行代码修改如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">float_image = resized_image</span><br><span class="line"> # Subtract off the mean and divide by the variance of the pixels.</span><br><span class="line"> #float_image = tf.image.per_image_standardization(resized_image)</span><br></pre></td></tr></table></figure>

</details>

<p>再次运行代码，在TensorBoard中如图8-24所示。这时1、2、3分别代表原图、1层卷积后和2层卷积后的图片。</p>
<p>与归一化的效果对比，显然归一化后的图片卷积效果特征会更加明显，这也是为什么做归一化的原因。</p>
<p><img src="Image00150.jpg" alt></p>
<p>图8-24 反卷积结果2</p>
<h3 id="8-8-善用函数封装库"><a href="#8-8-善用函数封装库" class="headerlink" title="8.8 善用函数封装库"></a>8.8 善用函数封装库</h3><p>本节讲一下TensorFlow中的一个封装好的高级库，里面有前面讲过的很多函数的高级封装，使用这个高级库来开发程序将会提高效率。那么这个高级库具体好在哪里？请看下面的例子。</p>
<h4 id="8-8-1-实例51：使用函数封装库重写CIFAR卷积网络"><a href="#8-8-1-实例51：使用函数封装库重写CIFAR卷积网络" class="headerlink" title="8.8.1 实例51：使用函数封装库重写CIFAR卷积网络"></a>8.8.1 实例51：使用函数封装库重写CIFAR卷积网络</h4><p>改写代码代码“8-9 cifar卷积.py”，将网络结构中的全连接、卷积和池化全部用tensorflow.contrib.layers改写。</p>
<p>实例描述</p>
<p>将“代码8-9：cifar卷积.py”中的代码使用tf.contrib.layers重构。</p>
<p>1．改写代码</p>
<p>卷积函数使用tf.contrib.layers.conv2d，池化使用tf.contrib.layers.max_pool2d和tf.contrib.layers.avg_pool2d，这次使用全连接来作为输出层，并演示全连接函数tf.contrib. layers.fully_connected的使用。</p>
<p>代码8-18 cifar简洁代码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(tf.float32,[None, 24,24,3]) #CIFAR数据集的shape 24*24*3</span><br><span class="line">y = tf.placeholder(tf.float32,[None, 10]) # 0-9 数字分类=&gt; 10 类</span><br><span class="line"> </span><br><span class="line">x_image = tf.reshape(x, [-1,24,24,3])</span><br><span class="line"> </span><br><span class="line">h_conv1 =tf.contrib.layers.conv2d(x_image,64,5,1,&apos;SAME&apos;,activation_fn=tf. nn.relu)</span><br><span class="line">h_pool1 = tf.contrib.layers.max_pool2d(h_conv1,[2,2],stride=2, padding=</span><br><span class="line">&apos;SAME&apos;)</span><br><span class="line"> </span><br><span class="line">h_conv2=tf.contrib.layers.conv2d(h_pool1,64,[5,5],1,&apos;SAME&apos;,activation_</span><br><span class="line">fn=tf.nn.relu)</span><br><span class="line">h_pool2 = tf.contrib.layers.max_pool2d(h_conv2,[2,2],stride=2,padding= </span><br><span class="line">&apos;SAME&apos;)</span><br><span class="line"> </span><br><span class="line">nt_hpool2 = tf.contrib.layers.avg_pool2d(h_pool2,[6,6],stride=6,padding= </span><br><span class="line">&apos;SAME&apos;)</span><br><span class="line"> </span><br><span class="line">nt_hpool2_flat = tf.reshape(nt_hpool2, [-1, 64])</span><br><span class="line"> </span><br><span class="line">y_conv = tf.contrib.layers.fully_connected(nt_hpool2_flat,10,activation_</span><br><span class="line">fn=tf.nn.softmax)</span><br><span class="line"> </span><br><span class="line">cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))</span><br><span class="line">train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</span><br><span class="line"> </span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"> </span><br><span class="line">sess = tf.Session()</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>这里只修改“8-9cifar卷积.py”中间的代码，代码的运行不会受到影响。可以看到整个代码段变得简洁了，这就是使用tf.contrib.layers的好处。尤其在深层网络结构中，大量的重复代码会使代码可读性越来越差，所以使用tf.contrib.layers不失为一个好办法。</p>
<p>2．tf.contrib.layers中的具体函数介绍</p>
<p>看似简单的函数，幕后却做了很多事情，在上面的代码中，没有定义权重，没有初始化，没有过多的参数，这些都是tf.contrib.layers帮我们封装好的。</p>
<p>下面以最复杂的卷积为例进行介绍，其他函数与之相似，不再展开介绍。</p>
<p>tf.contrib.layers.conv2d的函数定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def convolution(inputs,</span><br><span class="line">                num_outputs,</span><br><span class="line">                kernel_size,</span><br><span class="line">                stride=1,</span><br><span class="line">                padding=&apos;SAME&apos;,</span><br><span class="line">                data_format=None,</span><br><span class="line">                rate=1,</span><br><span class="line">                activation_fn=nn.relu,</span><br><span class="line">                normalizer_fn=None,</span><br><span class="line">                normalizer_params=None,</span><br><span class="line">                weights_initializer=initializers.xavier_initializer(),</span><br><span class="line">                weights_regularizer=None,</span><br><span class="line">                biases_initializer=init_ops.zeros_initializer(),</span><br><span class="line">                biases_regularizer=None,</span><br><span class="line">                reuse=None,</span><br><span class="line">                variables_collections=None,</span><br><span class="line">                outputs_collections=None,</span><br><span class="line">                trainable=True,</span><br><span class="line">                scope=None):</span><br></pre></td></tr></table></figure>

</details>

<p>常用的参数说明如下。</p>
<p>·inputs：代表输入。</p>
<p>·num_outputs：代表输出几个channel。这里不需要再指定输入的channel了，因为函数会自动根据inputs的shape去判断。</p>
<p>·kernel_size：卷积核大小，不需要带上batch和channel，只需输入尺寸即可。[5，5]就代表5×5大小的卷积核。如果长、宽都一样，也可以直接写一个数5。</p>
<p>·stride：步长，默认是长、宽都相等的步长。卷积时，一般都用1，所以默认值也是1，如果长、宽的步长都不同，也可以用一个数组[1，2]。</p>
<p>·padding：与前面的padding规则一样。</p>
<p>·activation_fn：输出后的激活函数。</p>
<p>·weights_initializer：权重的初始化，默认为initializers.xavier_initializer函数，参见第6章的说明。biases_initializer同理，不再赘述。</p>
<p>·weights_regularizer：正则化项。可以加入正则函数，biases_regularizer同理，不再赘述。</p>
<p>·trainable：是否可训练，如作为训练节点，必须设为True。默认即可。</p>
<p>对于全连接层等其他函数的使用，会在后续代码中找到相应的演示例子，这里就不在一一介绍了。</p>
<h4 id="8-8-2-练习题"><a href="#8-8-2-练习题" class="headerlink" title="8.8.2 练习题"></a>8.8.2 练习题</h4><p>任选一个前面章节的例子，将其该成使用tf.contrib.layers库来实现。</p>
<h3 id="8-9-深度学习的模型训练技巧"><a href="#8-9-深度学习的模型训练技巧" class="headerlink" title="8.9 深度学习的模型训练技巧"></a>8.9 深度学习的模型训练技巧</h3><p>下面看看卷积神经网络的训练有哪些技巧。</p>
<h4 id="8-9-1-实例52：优化卷积核技术的演示"><a href="#8-9-1-实例52：优化卷积核技术的演示" class="headerlink" title="8.9.1 实例52：优化卷积核技术的演示"></a>8.9.1 实例52：优化卷积核技术的演示</h4><p>在实际的卷积训练中，为了加快速度，常常把卷积核裁开。比如一个3×3的过滤器，可以裁成3×1和1×3两个过滤器，分别对原有输入做卷积操作，这样可以大大提升运算的速度。</p>
<p>原理：在浮点运算中乘法消耗的资源比较多，我们目的就是尽量减小乘法运算。</p>
<p>·比如对一个5×2的原始图片进行一次3×3的同卷积，相当于生成的5×2像素中每一个都要经历3×3次乘法，那么一共是90次。</p>
<p>·同样是这个图片，如果先进行一次3×1的同卷积需要30次运算，再进行一次1×3的同卷积还是30次，一共才60次。</p>
<p>这仅仅是一个很小的数据张量，而且随着张量维度的增大，层数的增多，减少的运算会更多。那么运算量减少了，运算效果会等价吗？答案是肯定的。因为有公式来做保证3×1的矩阵乘上1×3的矩阵会正好生成3×3的矩阵。所以这个技巧在卷积网络中很常见。</p>
<p>下面我们把这个技巧用在实例中，改写代码“代码8-9 cifar卷积.py”如下。</p>
<p>实例描述</p>
<p>使用优化卷积核技术将代码“8-9 cifar卷积.py”中的代码重构，并观察效果。</p>
<p>代码8-19 cifar卷积核优化（片段）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">x_image = tf.reshape(x, [-1,24,24,3])</span><br><span class="line"> </span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line">W_conv21 = weight_variable([5, 1, 64, 64])</span><br><span class="line">b_conv21 = bias_variable([64])</span><br><span class="line">h_conv21 = tf.nn.relu(conv2d(h_pool1, W_conv21) + b_conv21)</span><br><span class="line"> </span><br><span class="line">W_conv2 = weight_variable([1, 5, 64, 64])</span><br><span class="line">b_conv2 = bias_variable([64])</span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_conv21, W_conv2) + b_conv2)</span><br><span class="line"> </span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中，将原来的第二层5×5的卷积操作conv2注释掉，换成两个5×1和1×5的卷积操作，代码运行后可以看到准确率没有变化，但是速度快了一些。</p>
<h4 id="8-9-2-实例53：多通道卷积技术的演示"><a href="#8-9-2-实例53：多通道卷积技术的演示" class="headerlink" title="8.9.2 实例53：多通道卷积技术的演示"></a>8.9.2 实例53：多通道卷积技术的演示</h4><p>这里介绍的多通道卷积，可以理解为一种新型的CNN网络模型，在原有的卷积模型基础上的扩展。</p>
<p>·原有的卷积层中是使用单个尺寸的卷积核对输入数据卷积操作（如图8-25中的上半部分），生成若干个feature map。</p>
<p>·而多通道卷积的变化就是，在单个卷积层中加入若干个不同尺寸的过滤器（如图8-25中的下半部分），这样会使生成的feature map特征更加多样性。</p>
<p><img src="Image00151.jpg" alt></p>
<p>图8-25 多通道卷积</p>
<p>同样还是在代码“8-9 cifar卷积.py”中修改，为网络的卷积层增加不同尺寸的卷积核。这里将原有的5×5卷积，扩展到7×7卷积、1×1卷积、3×3卷积，并将它们的输出通过concat函数并在一起。</p>
<p>实例描述</p>
<p>使用多通道技术将代码“8-9 cifar卷积.py”中的代码重构，并观察效果。</p>
<p>代码8-20 cifar多通道卷积</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">x_image = tf.reshape(x, [-1,24,24,3])</span><br><span class="line"> </span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line">#######################################################多卷积核</span><br><span class="line">W_conv2_5x5 = weight_variable([5, 5, 64, 64]) </span><br><span class="line">b_conv2_5x5 = bias_variable([64]) </span><br><span class="line">W_conv2_7x7 = weight_variable([7, 7, 64, 64]) </span><br><span class="line">b_conv2_7x7 = bias_variable([64]) </span><br><span class="line"> </span><br><span class="line">W_conv2_3x3 = weight_variable([3, 3, 64, 64]) </span><br><span class="line">b_conv2_3x3 = bias_variable([64]) </span><br><span class="line"> </span><br><span class="line">W_conv2_1x1 = weight_variable([3, 3, 64, 64]) </span><br><span class="line">b_conv2_1x1 = bias_variable([64]) </span><br><span class="line"> </span><br><span class="line">h_conv2_1x1 = tf.nn.relu(conv2d(h_pool1, W_conv2_1x1) + b_conv2_1x1)</span><br><span class="line">h_conv2_3x3 = tf.nn.relu(conv2d(h_pool1, W_conv2_3x3) + b_conv2_3x3)</span><br><span class="line">h_conv2_5x5 = tf.nn.relu(conv2d(h_pool1, W_conv2_5x5) + b_conv2_5x5)</span><br><span class="line">h_conv2_7x7 = tf.nn.relu(conv2d(h_pool1, W_conv2_7x7) + b_conv2_7x7)</span><br><span class="line">h_conv2 = tf.concat([h_conv2_5x5,h_conv2_7x7,h_conv2_3x3,h_conv2_1x1],3)</span><br><span class="line"> </span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line">#######################################################</span><br><span class="line">W_conv3 = weight_variable([5, 5, 256, 10])</span><br><span class="line">b_conv3 = bias_variable([10])</span><br><span class="line">h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)</span><br><span class="line"> </span><br><span class="line">nt_hpool3=avg_pool_6x6(h_conv3)#10</span><br><span class="line">nt_hpool3_flat = tf.reshape(nt_hpool3, [-1, 10])</span><br><span class="line">y_conv=tf.nn.softmax(nt_hpool3_flat)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中，1×1、3×3、5×5、7×7的卷积操作输入都是h_pool1，每个卷积操作后都生成了64个feature map，再用concat函数将它们合在一起变成一个[batch、12，12，256]大小的数据（4个64channels=256个channels）。</p>
<p>代码运行后输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">step 0, training accuracy 0.0859375</span><br><span class="line">step 200, training accuracy 0.296875</span><br><span class="line">step 400, training accuracy 0.445312</span><br><span class="line">step 600, training accuracy 0.414062</span><br><span class="line">step 800, training accuracy 0.4375</span><br><span class="line">step 1000, training accuracy 0.484375</span><br><span class="line">step 1200, training accuracy 0.5</span><br><span class="line">……</span><br><span class="line">step 14000, training accuracy 0.671875</span><br><span class="line">step 14200, training accuracy 0.671875</span><br><span class="line">step 14400, training accuracy 0.59375</span><br><span class="line">step 14600, training accuracy 0.695312</span><br><span class="line">step 14800, training accuracy 0.609375</span><br><span class="line">finished！ test accuracy 0.664062</span><br></pre></td></tr></table></figure>

</details>

<p>如果上面的concat函数会让你迷惑的话，可以参考第4章中关于concat的说明。</p>
<h4 id="8-9-3-批量归一化"><a href="#8-9-3-批量归一化" class="headerlink" title="8.9.3 批量归一化"></a>8.9.3 批量归一化</h4><p>还有一种应用十分广泛的优化方法——批量归一化（简称BN算法）。一般用在全连接或卷积神经网络中。这个里程碑式技术的问世，使得整个神经网络的识别准确度上升了一个台阶，下面就来介绍下其具体内容。</p>
<p>1．批量归一化介绍</p>
<p>先来看下面的例子：</p>
<p>假如有一个极简的网络模型，每一层只有一个节点，没有偏置。那么如果这个网络有三层的话，可以用如下式子表示其输出值：</p>
<p><img src="Image00152.jpg" alt></p>
<p>假设有两个神经网络，学习出了两套权重（w1：1，w2：1，w3：1）和（w1：0.01，w2：10000，w3：0.01），它们对应的输出z都是相同的。现在让它们训练一次，看看会发生什么。</p>
<p>（1）反向传播：假设反向传播时计算出的损失值Δy为1，那么对于这两套权重的修正值将变为（Δw1：1，Δw2：1，Δw3：1）和（Δw1：100，Δw2：0.0001，Δw3：100）。</p>
<p>（2）更新权重：这时更新过后的两套权重就变成了（w1：2，w2：2，w3：2）和（w1：100.01，w2：10000.0001，w3：100.01）。</p>
<p>（3）第二次正向传播：假设输入样本是1，第一个神经网络的值为：</p>
<p>Z=1×2×2×2 = 8</p>
<p>第二个神经网络的值为：</p>
<p>Z=1×100.01×10000.0001×100.01=100000000</p>
<p>看到这里，读者是不是已经感觉到两个网络的输出值差别巨大？如果再往下进行，这时计算出的loss值会变得更大，使得网络无法计算，这种现象也叫做梯度爆炸。产生梯度爆炸的原因就是因为网络的内部协变量转移（Internal Covariate Shift），即正向传播时的不同层的参数会将反向训练计算时所参照的数据样本分布改变。</p>
<p>这就是引入批量正则化的目的。它的作用是要最大限度地保证每次的正向传播输出在同一分布上，这样反向计算时参照的数据样本分布就会与正向计算时的数据分布一样了。保证了分布统一，对权重的调整才会更有意义。</p>
<p>了解了原理之后，再来看批量正则化的做法就会变得很简单，即将每一层运算出来的数据都归一化成均值为0方差为1的标准高斯分布。这样就会在保留样本分布特征的同时，又消除了层与层间的分布差异。</p>
<p><img src="Image00014.jpg" alt> 提示： 在实际应用中，批量归一化的收敛非常快，并且具有很强的泛化能力，某种情况下可以完全代替前面讲过的正则化、Dropout。</p>
<p>2．批量归一化定义</p>
<p>先来看看TensorFlow中自带的BN函数定义：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.batch_normalization(x,mean,variance,offset,scale,variance_epsilon,</span><br><span class="line">name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>它的参数很简单，各参数说明如下。</p>
<p>·x：代表输入。</p>
<p>·mean：代表样本的均值。</p>
<p>·variance：代表方差。</p>
<p>·offset：代表偏移，即相加一个转化值，后面我们会用激活函数来转换，所以这里不需要再转化，直接使用0。</p>
<p>·scale：代表缩放，即乘以一个转化值，同理，一般都用1。</p>
<p>·variance_epsilon： 是为了避免分母为0的情况，给分母加一个极小值。默认即可。</p>
<p>要想使用这个函数，必须由另一个函数配合——tf.nn.moments，由它来计算均值和方差，然后就可以使用BN了。tf.nn.moments 定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.moments(x, axes, name=None, keep_dims=False)</span><br></pre></td></tr></table></figure>

</details>

<p>axes主要是指定哪个轴来求均值与方差。</p>
<p><img src="Image00014.jpg" alt> 注意： axes在使用过程中经常容易犯错。这里提供一个小技巧，为了求样本的均值和方差，一般都会设为保留最后一个维度，对于x来讲可以直接使用公式axis = list（range（len（x.get_shape（）） -1））即可。例如，[128，3，3，12] axes就为[0，1，2]，输出的均值方差维度为[12]</p>
<p>有了上面的两个函数还不够，为了有更好的效果，我们希望使用平滑指数衰减的方法来优化每次的均值与方差，于是就用到了tf.train.ExponentialMovingAverage函数。它的作用是让上一次的值对本次的值有个衰减后的影响，从而使每次的值连起来后会相对平滑一些。展开后可以用下面的代码来表示：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shadow_variable = decay * shadow_variable + (1 -decay) * variable</span><br></pre></td></tr></table></figure>

</details>

<p>各参数说明如下。</p>
<p>·decay：代表衰减指数，是在ExponentialMovingAverage中指定的，比如0.9。</p>
<p>·variable：代表本批次样本中的值。</p>
<p>·等式右边的shadow_variable：代表上次总样本的值。</p>
<p>·等式左边shadow_variable：代表计算出来的本次总样本的值。</p>
<p>3．批量归一化的简单用法</p>
<p>上面的函数虽然参数不多，但需要几个函数联合起来使用，于是TensorFlow中的layers模块里又实现了一次BN函数，相当于把几个函数合并到了一起，使用起来更加简单。下面来介绍一下，在使用时需要引入头文件：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.contrib.layers.python.layers import batch_norm</span><br></pre></td></tr></table></figure>

</details>

<p>函数的定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def batch_norm(inputs,</span><br><span class="line">               decay=0.999,</span><br><span class="line">               center=True,</span><br><span class="line">               scale=False,</span><br><span class="line">               epsilon=0.001,</span><br><span class="line">               activation_fn=None,</span><br><span class="line">               param_initializers=None,</span><br><span class="line">               param_regularizers=None,</span><br><span class="line">               updates_collections=ops.GraphKeys.UPDATE_OPS,</span><br><span class="line">               is_training=True,</span><br><span class="line">               reuse=None,</span><br><span class="line">               variables_collections=None,</span><br><span class="line">               outputs_collections=None,</span><br><span class="line">               trainable=True,</span><br><span class="line">               batch_weights=None,</span><br><span class="line">               fused=False,</span><br><span class="line">               data_format=DATA_FORMAT_NHWC,</span><br><span class="line">               zero_debias_moving_mean=False,</span><br><span class="line">               scope=None,</span><br><span class="line">               renorm=False,</span><br><span class="line">               renorm_clipping=None,</span><br><span class="line">               renorm_decay=0.99):</span><br></pre></td></tr></table></figure>

</details>

<p>虽然使用简单，但由于其中的参数较多，也增大了学习难度，因此这里列出一些常用的参数及使用习惯。</p>
<p>·inputs：代表输入。</p>
<p>·decay：代表移动平均值的衰败速度，是使用了一种叫做平滑指数衰减的方法更新均值方差，一般会设为0.9；值太小会导致均值和方差更新太快，而值太大又会导致几乎没有衰减，容易出现过拟合，这种情况一般需要把值调小点。</p>
<p>·scale：是否进行变化（通过乘一个gamma值进行缩放），我们常习惯在BN后面接着一个线性的变化，如Relu。所以scale一般都会设为False。因为后面有对数据的转化处理，因此这里就不用再处理了。</p>
<p>·epsilon：是为了避免分母为0的情况，给分母加一个极小值。一般默认即可。</p>
<p>·is_training：当它为True时，代表是训练过程，这时会不断更新样本集的均值与方差。当测试时，要设成False，这样就会使用训练样本集的均值与方差。</p>
<p>·updates_collections：其变量默认是tf.GraphKeys.UPDATE_OPS，在训练时提供了一种内置的均值方差更新机制，即通过图（一个计算任务）中的tf.GraphKeys. UPDATE_OPS变量来更新。但它是在每次当前批次训练完成后才更新均值和方差，这样导致当前数据总是使用前一次的均值和方差，没有得到最新的更新。所以一般都会将其设成None，让均值和方差即时更新。这样做虽然相比默认值在性能上稍慢点，但是对模型的训练还是有很大帮助的。</p>
<p>·reuse：支持共享变量，与下面的scope参数联合使用</p>
<p>·scope：指定变量的作用域variable_scope。</p>
<h4 id="8-9-4-实例54：为CIFAR图片分类模型添加BN"><a href="#8-9-4-实例54：为CIFAR图片分类模型添加BN" class="headerlink" title="8.9.4 实例54：为CIFAR图片分类模型添加BN"></a>8.9.4 实例54：为CIFAR图片分类模型添加BN</h4><p>本例将演示BN函数的使用方法，同样是在原有的代码“8-9 cifar卷积.py”例子中修改，具体步骤如下。</p>
<p>实例描述</p>
<p>使用BN算法将代码“8-9 cifar卷积.py”中的代码重构，并观察其效果。</p>
<p>1．添加BN函数</p>
<p>改写代码“8-9 cifar卷积.py”，在池化函数后面加入BN函数。</p>
<p>代码8-21 cifarBN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def avg_pool_6x6(x):</span><br><span class="line">  return tf.nn.avg_pool(x, ksize=[1, 6, 6, 1],</span><br><span class="line">                        strides=[1, 6, 6, 1], padding=&apos;SAME&apos;)</span><br><span class="line">def batch_norm_layer(value,train = None, name = &apos;batch_norm&apos;): </span><br><span class="line">  if train is not None:       </span><br><span class="line">      return batch_norm(value, decay = 0.9,updates_collections=None, </span><br><span class="line">     is_training = True)</span><br><span class="line">  else:</span><br><span class="line">      return batch_norm(value, decay = 0.9,updates_collections=None, </span><br><span class="line">     is_training = False)</span><br></pre></td></tr></table></figure>

</details>

<p>2．为BN函数添加占位符参数</p>
<p>由于BN里面需要设置是否为训练状态，所以这里定义一个train将训练状态当成一个占位符来传入。</p>
<p>代码8-21 cifarBN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, [None, 24,24,3]) #CIFAR数据集的shape</span><br><span class="line">为24×24×3</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) #  10 类</span><br><span class="line">train = tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p>3．修改网络结构添加BN层</p>
<p>在第一层h_conv1与第二层h_conv2的输出之前卷积之后加入BN层。</p>
<p>代码8-21 cifarBN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> h_conv1 = tf.nn.relu(batch_norm_layer((conv2d(x_image, W_conv1) + </span><br><span class="line">b_conv1),train))</span><br><span class="line"> h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"> </span><br><span class="line"> W_conv2 = weight_variable([5, 5, 64, 64])</span><br><span class="line"> b_conv2 = bias_variable([64])</span><br><span class="line"> </span><br><span class="line"> h_conv2 = tf.nn.relu(batch_norm_layer((conv2d(h_pool1, W_conv2) + </span><br><span class="line">b_conv2),train))</span><br><span class="line"> h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>4．加入退化学习率</p>
<p>将原来的学习率改成退化学习率，使用0.04的初始值，让其每1000次退化0.9。</p>
<p>代码8-21 cifarBN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))</span><br><span class="line"> global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> decaylearning_rate = tf.train.exponential_decay(0.04, global_step,</span><br><span class="line">, 0.9)</span><br><span class="line"> </span><br><span class="line"> train_step = tf.train.AdamOptimizer(decaylearning_rate).minimize</span><br><span class="line">(cross_entropy,global_step=global_step)</span><br><span class="line"> correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>5．在运行session中添加训练标志</p>
<p>在session中找到循环的部分，为占位符train添加数值1，表明当前是训练状态。其他的地方都不用动，因为在第一步的BN函数里设定好train为None时，已经认为是测试状态。</p>
<p>代码8-21 cifarBN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">for i in range(20000):</span><br><span class="line">  image_batch, label_batch = sess.run([images_train, labels_train])</span><br><span class="line">  label_b = np.eye(10,dtype=float)[label_batch] #one hot编码</span><br><span class="line">  </span><br><span class="line">  train_step.run(feed_dict=&#123;x:image_batch, y: label_b,train:1&#125;,</span><br><span class="line"> session=sess)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">begin</span><br><span class="line">begin data</span><br><span class="line">step 0, training accuracy 0.210938</span><br><span class="line">step 200, training accuracy 0.484375</span><br><span class="line">step 400, training accuracy 0.601562</span><br><span class="line">step 600, training accuracy 0.617188</span><br><span class="line">……</span><br><span class="line">step 18400, training accuracy 0.921875</span><br><span class="line">step 18600, training accuracy 0.921875</span><br><span class="line">step 18800, training accuracy 0.921875</span><br><span class="line">step 19000, training accuracy 0.953125</span><br><span class="line">step 19200, training accuracy 0.9375</span><br><span class="line">step 19400, training accuracy 0.914062</span><br><span class="line">step 19600, training accuracy 0.96875</span><br><span class="line">step 19800, training accuracy 0.9375</span><br><span class="line">finished！ test accuracy 0.71875</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，准确率有了明显提升，训练时达到了90%以上，测试时模型的准确率下降了不少。有兴趣的读者可以通过对原样本变形的方式来增大数据集（使用cifar10_input中的distorted_inputs来获取数据），或采用前面讲的一些过拟合的方法继续优化。</p>
<h4 id="8-9-5-练习题"><a href="#8-9-5-练习题" class="headerlink" title="8.9.5 练习题"></a>8.9.5 练习题</h4><p>（1）搭建神经网络，使用多通道卷积，将MNIST数据集进行分类（代码见“8-23多通道mnist.py”。）</p>
<p>（2）再接着练习（1）将多通道卷积加入批量正则化处理（代码见“8-22带BN的多通道mnist.py”，可将准确率提高到99%）。</p>
<h2 id="第9章-循环神经网络——具有记忆功能的网络"><a href="#第9章-循环神经网络——具有记忆功能的网络" class="headerlink" title="第9章 循环神经网络——具有记忆功能的网络"></a>第9章 循环神经网络——具有记忆功能的网络</h2><p>前面讲的内容可以理解为静态数据的处理，也就是样本是单次的，彼此之间没有关系。然而人工智能对计算机的要求不仅仅是单次的运算，还需要让计算机像人一样具有记忆功能。这一节我们就来学习循环神经网络（RNN），它是一个具有记忆功能的网络。这种网络最适合解决连续序列的问题，善于从具有一定顺序意义的样本与样本间学习规律。</p>
<p>本章含有教学视频共10分53秒。</p>
<p>本章的内容比较多，作者按照书中的内容结构做了快速讲解。在视频内容中主要对RNN的作用、原理和结构做了清晰的讲解，同时对本章内容中各个技术点的学习方法及后面的实例通用性做了补充说明。</p>
<p><img src="Image00153.jpg" alt></p>
<h3 id="9-1-了解RNN的工作原理"><a href="#9-1-了解RNN的工作原理" class="headerlink" title="9.1 了解RNN的工作原理"></a>9.1 了解RNN的工作原理</h3><p>在解释RNN原理之前，我们先看看人脑是怎么处理的。</p>
<h4 id="9-1-1-了解人的记忆原理"><a href="#9-1-1-了解人的记忆原理" class="headerlink" title="9.1.1 了解人的记忆原理"></a>9.1.1 了解人的记忆原理</h4><p>如果你身边有2岁或3岁的孩子，可以仔细观察一下，他说话时虽然能表达出具体的意思，但是听起来总会觉得怪怪的。比如笔者的孩子，在刚开始说话时，把“我要”说成了“要我”，一看到喜欢吃的小零食，就会用手指着小零食对你大喊“要我，要我……”。</p>
<p>类似这样的话为什么我们听起来会感觉很别扭呢？这是因为我们的大脑受刺激时对一串后续的字有预测功能。如果从神经网络的角度来理解，大脑中的语音模型在某一场景下一定是对这两个字有先后顺序区分的。比如，第一个字是“我”，后面跟着“要”，人们就会觉得正常，而使用“要我”，来匹配“我要”的意思在生活中很少遇到，于是人们就会觉得很奇怪。</p>
<p>当获得“我来找你玩游”信息后，大脑的语言模型会自动预测后一个字为“戏”，而不是“乐、泳”等其他字，如图9-1所示。</p>
<p><img src="Image00154.jpg" alt></p>
<p>图9-1 人脑处理文字举例</p>
<p>图9-1中的逻辑并不是在说完“我来找你玩游”之后进入大脑来处理的，而是每个字都在脑子里进行着处理，将图9-1中的每个字分别裁开，在语言模型中就形成了一个循环神经网络，图9-1中的逻辑可以用下面的伪码表示：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（input我+ empty—input）→output我</span><br><span class="line">（input来+ output我）→output来</span><br><span class="line">（input找+ output来）→output找</span><br><span class="line">（input你+ output找）→output你</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>即，每个预测的结果都会放到下一个输入里进行运算，与下一次的输入一起来生成下一次的结果。如图9-2所示的网络模型可以很好地表达我们见到的现象。</p>
<p><img src="Image00155.jpg" alt></p>
<p>图9-2 RNN结构</p>
<p>图9-2也可以看成是一个链式的结构，如何理解链式结构呢？举个例子：后来我的孩子上了幼儿园，学习了《三字经》，而且可以背很长的内容，背得很熟练，于是我想考考他，就问了一个中间的句子“名俱扬”下一句是啥，他很快说了出来，马上又问他上一句是啥，他想了半天，从头背了一遍，背到“名俱扬”时才知道上一句是“教五子”。这种现象可以理解为我们大脑并不是简单的存储，而是链式的、有顺序的存储。</p>
<p>这种“链式的、有顺序存储”很节省空间，对于中间状态的序列，我们的大脑没有选择直接记住，而是存储计算方法。当我们需要取值时，直接将具体的数据输入，通过计算得出来相应的结果。这种解决方法在很多具体问题时都会用到。</p>
<p>例如：程序员常常会使用一个递归的函数来求阶乘n！=n×（n-1）×……1。</p>
<p>函数的代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">long ff(int n) &#123;</span><br><span class="line">  long f;</span><br><span class="line">  if(n&lt;0) printf(&quot;n&lt;0,input error&quot;);</span><br><span class="line">  else if(n==0||n==1) f=1;</span><br><span class="line">  else f=ff(n-1)*n;</span><br><span class="line">  return(f);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>

<p>还有，我们在计算加法时的进位过程。</p>
<p>23+17的加法过程是：先个位加个位，再算十位加十位；然后将个位的结果状态（是否有进位）送到十位的运算中去，则十位是“2+1+个位的进位数（1）”等于4。</p>
<h4 id="9-1-2-RNN网络的应用领域"><a href="#9-1-2-RNN网络的应用领域" class="headerlink" title="9.1.2 RNN网络的应用领域"></a>9.1.2 RNN网络的应用领域</h4><p>对于序列化的特征的任务，都适合采用RNN网络来解决。细分起来可以有情感分析（Sentiment Analysis）、关键字提取（Key Term Extraction）、语音识别（Speech Recognition）、机器翻译（Machine Translation）和股票分析等。</p>
<h4 id="9-1-3-正向传播过程"><a href="#9-1-3-正向传播过程" class="headerlink" title="9.1.3 正向传播过程"></a>9.1.3 正向传播过程</h4><p>RNN结构如图9-3左侧图所示，A代表网络，xt代表t时刻输入的x，ht代表网络生成的结果，A中间又画出了一条线指向自己，是表明上一时刻的输出接着输入到了A里面。</p>
<p><img src="Image00156.jpg" alt></p>
<p>图9-3 RNN正向传播</p>
<p>当有一系列的x输入到图9-3左侧结构中后，展开就变成了右侧的样子，其实就是一个含有隐藏层的网络，只不过隐藏层的输出变成了两份，一份传到下一个节点，另一份传给本身节点。其时序图如图9-4所示。</p>
<p><img src="Image00157.jpg" alt></p>
<p>图9-4 RNN正向传播时序</p>
<p>假设有3个时序t1 、t2 、t3 ，如图9-4所示，在RNN中可以分解成以下3个步骤。</p>
<p>（1）开始时t1 通过自己的输入权重和0作为输入，生成了out1 。</p>
<p>（2）out1 通过自己的权重生成了h1 ，然后和t2 经过输入权重转化后一起作为输入，生成了out2 。</p>
<p>（3）out2 通过同样的隐藏层权重生成了h2 ，然后和t3 经过输入权重转化后一起作为输入，生成了out2 。</p>
<h4 id="9-1-4-随时间反向传播"><a href="#9-1-4-随时间反向传播" class="headerlink" title="9.1.4 随时间反向传播"></a>9.1.4 随时间反向传播</h4><p>与单神经元相似，RNN也需要反向传播误差来调整自己的参数。RNN网络使用随时间反向传播（BackPropagation Through Time，BPTT）的链式求导算法来反向传播误差。</p>
<p>先来回顾一下反向传播的BP算法，如图9-5所示。</p>
<p>这是一个含有一个隐藏层的网络结构。隐藏层只有一个节点。具体的过程如下：</p>
<p>（1）有一个批次含有3个数据A、B、C，批次中每个样本有两个数（x1、x2）通过权重（w1、w2）来到隐藏层H并生成批次h，如图9-5中w1、w2两条直线所在方向。</p>
<p>（2）该批次的h通过隐藏层权重p1生成最终的输出结果y。</p>
<p>（3）y与最终的标签p比较，生成输出层误差less（y，p）。</p>
<p>（4）less（y，p）与生成y的导数相乘，得到Del_y。Del_y为输出层所需要的修改值。</p>
<p>（5）将h的转置与del_y相乘得到del_p1。这是源于h与p1相等得到的y，见第（2）步。</p>
<p><img src="Image00158.jpg" alt></p>
<p>图9-5 BP反向传播1</p>
<p>（6）最终将该批次的del_p1求和并更新到p1上。</p>
<p>（7）同理，再将误差反向传递到上一层：计算Del_h。得到Del_h后再计算del_w1、del_w2并更新。</p>
<p>若BP的算法读者已经理解了，下面再来比较一下BPTT算法，如图9-6所示。</p>
<p><img src="Image00159.jpg" alt></p>
<p>图9-6 RNN 反向传播</p>
<p>图9-6中，同样是一个批次的数据A、B、C，按顺序进入循环神经网络。正向传播的实例是B正在进入神经网络的过程，可以看到A的h参与进来并一起经过P1生成了B的y。因为C还没有进入，为了清晰，这里用灰色表示。</p>
<p>当所有块都进入之后，会将p标签与输出进行Del_y的运算，由于C块的y是最后生成的，所以我们先从C块开始对h的输出传递误差Del_h。</p>
<p>图9-6中的反向传播是表示C块已经反向传播完成，开始B块反向传播的状态，可以看到B块Del_h是由B块的del_y和C块的del_h通过计算得来的。这就是与BP算法不同的地方（BP中Del_h直接与自己的Del_y相关，不会与其他的值有联系）。</p>
<p>作为一个批次的数据，正向传播时是沿着ABC的顺序，当反向传播时，就按照正向传播的相反顺序，即每个节点的CBA挨个计算并传递梯度。</p>
<h3 id="9-2-简单RNN"><a href="#9-2-简单RNN" class="headerlink" title="9.2 简单RNN"></a>9.2 简单RNN</h3><p>了解完RNN的原理后，下面一起来实现一个简单的RNN网络。</p>
<h4 id="9-2-1-实例55：简单循环神经网络实现——裸写一个退位减法器"><a href="#9-2-1-实例55：简单循环神经网络实现——裸写一个退位减法器" class="headerlink" title="9.2.1 实例55：简单循环神经网络实现——裸写一个退位减法器"></a>9.2.1 实例55：简单循环神经网络实现——裸写一个退位减法器</h4><p>本例将把前面所讲述的内容用代码实现一遍。如果前面的描述读者还不明白，可以通过这个例子，加深对前面内容的理解。</p>
<p>本例是一个纯手写的代码例子，使用Python手动搭建一个简单的RNN网络，让它来拟合一个退位减法。退位减法也具有RNN的特性，即输入的两个数相减时，一旦发生退位运算，需要将中间状态保存起来，当高位的数传入时将退位标志一并传入参与运算。</p>
<p>下面就来用代码实现RNN拟合减法，具体步骤如下。</p>
<p>实例描述</p>
<p>使用Ptyhon编写简单循环神经网络拟合一个退位减法的操作，观察其反向传播过程。</p>
<p>1．定义基本函数</p>
<p>首先手动写一个Sigmoid函数及其导数（导数用于反向传播）。</p>
<p>代码9-1 subtraction</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import copy, numpy as np</span><br><span class="line">np.random.seed(0)            #固定随机数生成器的种子，可以每次得到一样的值</span><br><span class="line">def sigmoid(x):              #激活函数</span><br><span class="line">    output = 1/(1+np.exp(-x))</span><br><span class="line">    return output</span><br><span class="line"></span><br><span class="line">def sigmoid_output_to_derivative(output): #激活函数的导数</span><br><span class="line">    return output*(1-output)</span><br></pre></td></tr></table></figure>

</details>

<p>2．建立二进制映射</p>
<p>定义的减法最大值限制在256之内，即8位二进制的减法，定义int与二进制之间的映射数组int2binary。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int2binary = &#123;&#125;                #整数到其二进制表示的映射</span><br><span class="line">binary_dim = 8                 #暂时制作256以内的减法</span><br><span class="line">## 计算0～256的二进制表示</span><br><span class="line">largest_number = pow(2,binary_dim)</span><br><span class="line">binary = np.unpackbits(</span><br><span class="line">    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)</span><br><span class="line">for i in range(largest_number):</span><br><span class="line">    int2binary[i] = binary[i]</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义参数</p>
<p>定义学习参数：隐藏层的权重synapse_0、循环节点的权重synapse_h（输入节点16、输出节点16）、输出层的权重synapse_1（输入16节点，输出1节点）。为了减小复杂度，这里只设置w权重，b被忽略。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> # 参数设置</span><br><span class="line"> alpha = 0.9                        #学习速率</span><br><span class="line"> input_dim = 2                      #输入的维度是2，减数和被减数</span><br><span class="line"> hidden_dim = 16 </span><br><span class="line"> output_dim = 1                     #输出维度为1</span><br><span class="line"> </span><br><span class="line"> # 初始化网络</span><br><span class="line"> synapse_0 = (2*np.random.random((input_dim,hidden_dim)) -1)*0.05 </span><br><span class="line">#维度为2*16，2是输入维度，16是隐藏层维度</span><br><span class="line"> synapse_1 = (2*np.random.random((hidden_dim,output_dim)) -1)*0.05</span><br><span class="line"> synapse_h = (2*np.random.random((hidden_dim,hidden_dim)) -1)*0.05</span><br><span class="line"> # =&gt; [-0.05, 0.05)，</span><br><span class="line"> </span><br><span class="line"> # 用于存放反向传播的权重更新值</span><br><span class="line"> synapse_0_update = np.zeros_like(synapse_0)</span><br><span class="line"> synapse_1_update = np.zeros_like(synapse_1)</span><br><span class="line"> synapse_h_update = np.zeros_like(synapse_h)</span><br></pre></td></tr></table></figure>

</details>

<p>synapse_0_update在前面很少见到，是因为它被隐含在优化器里了。这里全部“裸写”（不使用Tensor Flow库函数），需要定义一组变量，用于反向优化参数时存放参数需要调整的调整值，对应于前面的3个权重synapse_0、synapse_1和synapse_h。</p>
<p>4．准备样本数据</p>
<p>大致是这样的过程：</p>
<p>（1）建立循环生成样本数据，先生成两个数a和b。如果a小于b，就交换位置，保证被减数大。</p>
<p>（2）计算出相减的结果c。</p>
<p>（3）将3个数转换成二进制，为模型计算做准备。</p>
<p>将上面过程一一实现，代码如下。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 开始训练</span><br><span class="line">for j in range(10000):</span><br><span class="line">    </span><br><span class="line">    #生成一个数字a</span><br><span class="line">    a_int = np.random.randint(largest_number) </span><br><span class="line">    #生成一个数字b，b的最大值取的是largest_number/2，作为被减数，让它小一点</span><br><span class="line">    b_int = np.random.randint(largest_number/2) </span><br><span class="line">    #如果生成的b大了，那么交换一下</span><br><span class="line">    if a_int&lt;b_int:</span><br><span class="line">        tt = a_int</span><br><span class="line">        b_int = a_int</span><br><span class="line">        a_int=tt</span><br><span class="line">    </span><br><span class="line">    a = int2binary[a_int] # 二进制编码</span><br><span class="line">    b = int2binary[b_int] # 二进制编码</span><br><span class="line">    # 正确的答案</span><br><span class="line">    c_int = a_int -b_int</span><br><span class="line">    c = int2binary[c_int]</span><br></pre></td></tr></table></figure>

</details>

<p>5．模型初始化</p>
<p>初始化输出值为0，初始化总误差为0，定义layer_2_deltas存储反向传播过程中的循环层的误差，layer_1_values为隐藏层的输出值，由于第一个数据传入时，没有前面的隐藏层输出值来作为本次的输入，所以需要为其定义一个初始值，这里定义为0.1。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 存储神经网络的预测值</span><br><span class="line">d = np.zeros_like(c)</span><br><span class="line">overallError = 0                  #每次把总误差清零</span><br><span class="line"></span><br><span class="line">layer_2_deltas = list()         #存储每个时间点输出层的误差</span><br><span class="line">layer_1_values = list()         #存储每个时间点隐藏层的值</span><br><span class="line"></span><br><span class="line">layer_1_values.append(np.ones(hidden_dim)*0.1) # 一开始没有隐藏层，所以初始化一下原始值为0.1</span><br></pre></td></tr></table></figure>

</details>

<p>6．正向传播</p>
<p>循环遍历每个二进制位，从个位开始依次相减，并将中间隐藏层的输出传入下一位的计算（退位减法），把每一个时间点的误差导数都记录下来，同时统计总误差，为输出准备。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">for position in range(binary_dim):         #循环遍历每一个二进制位</span><br><span class="line">        </span><br><span class="line">        # 生成输入和输出</span><br><span class="line">        X = np.array([[a[binary_dim -position -1],b[binary_dim -</span><br><span class="line">       position -1]]]) #从右到左，每次取两个输入数字的一个bit位</span><br><span class="line">        y = np.array([[c[binary_dim -position -1]]]).T #正确答案</span><br><span class="line">        # hidden layer (input ~+ prev_hidden)</span><br><span class="line">        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values</span><br><span class="line">       [-1],synapse_h))#（输入层 + 之前的隐藏层） -&gt; 新的隐藏层，这是体现循环</span><br><span class="line">       神经网络的最核心的地方</span><br><span class="line">        # output layer (new binary representation)</span><br><span class="line">        layer_2 = sigmoid(np.dot(layer_1,synapse_1))   #隐藏层 * 隐藏层到输出层的转化矩阵synapse_1 -&gt; 输出层</span><br><span class="line">        </span><br><span class="line">        layer_2_error = y -layer_2                        #预测误差</span><br><span class="line">      layer_2_deltas.append((layer_2_error)*sigmoid_output_to_</span><br><span class="line"> derivative (layer_2)) #把每一个时间点的误差导数都记录下来</span><br><span class="line">        overallError += np.abs(layer_2_error[0])         #总误差</span><br><span class="line">    </span><br><span class="line">        d[binary_dim -position -1] = np.round(layer_2[0][0]) #记录下每一个预测bit位</span><br><span class="line">        </span><br><span class="line">        # 将隐藏层保存起来。下个时间序列便可以使用</span><br><span class="line">        layer_1_values.append(copy.deepcopy(layer_1))       #记录下隐藏层的值，在下一个时间点用</span><br><span class="line">    </span><br><span class="line">    future_layer_1_delta = np.zeros(hidden_dim)</span><br></pre></td></tr></table></figure>

</details>

<p>最后一行代码是为了反向传播准备的初始化。同正向传播一样，反向传播是从最后一次往前反向计算误差，对于每一个当前的计算都需要有它的下一次结果参与。</p>
<p>反向计算是从最后一次开始的，它没有后一次的输出，所以需要初始化一个值作为其后一次的输入，这里初始化为0。</p>
<p>7．反向训练</p>
<p>初始化之后，开始从高位往回遍历，一次对每一位的所有层计算误差，并根据每层误差对权重求偏导，得到其调整值，最终将每一位算出的各层权重的调整值加在一起乘以学习率，来更新各层的权重，完成一次优化训练。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#反向传播，从最后一个时间点到第一个时间点</span><br><span class="line">    for position in range(binary_dim):</span><br><span class="line">        </span><br><span class="line">        X = np.array([[a[position],b[position]]]) #最后一次的两个输入</span><br><span class="line">        layer_1 = layer_1_values[-position-1]    #当前时间点的隐藏层</span><br><span class="line">        prev_layer_1 = layer_1_values[-position-2] #前一个时间点的隐藏层</span><br><span class="line">        </span><br><span class="line">        layer_2_delta = layer_2_deltas[-position-1] #当前时间点输出层导数</span><br><span class="line">        # 通过后一个时间点（因为是反向传播）的隐藏层误差和当前时间点的输出层误差，</span><br><span class="line">       计算当前时间点的隐藏层误差</span><br><span class="line">        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_</span><br><span class="line">       2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative</span><br><span class="line">      (layer_1)</span><br><span class="line">        </span><br><span class="line">       # 等完成了所有反向传播误差计算，才会更新权重矩阵，先暂时把更新矩阵存起来</span><br><span class="line">        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_</span><br><span class="line">       delta)</span><br><span class="line">        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_</span><br><span class="line">       delta)</span><br><span class="line">        synapse_0_update += X.T.dot(layer_1_delta)</span><br><span class="line">        </span><br><span class="line">        future_layer_1_delta = layer_1_delta</span><br><span class="line">    </span><br><span class="line">    # 完成所有反向传播之后，更新权重矩阵，并把矩阵变量清零</span><br><span class="line">    synapse_0 += synapse_0_update * alpha</span><br><span class="line">    synapse_1 += synapse_1_update * alpha</span><br><span class="line">    synapse_h += synapse_h_update * alpha</span><br><span class="line">    synapse_0_update *= 0</span><br><span class="line">    synapse_1_update *= 0</span><br><span class="line">    synapse_h_update *= 0</span><br></pre></td></tr></table></figure>

</details>

<p>更新完后会将中间变量值清零。</p>
<p>8．输出结果</p>
<p>每运行800次将结果输出，代码如下。</p>
<p>代码9-1 subtraction（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 打印输出过程</span><br><span class="line">    if(j % 800 == 0):</span><br><span class="line">        </span><br><span class="line">        print(&quot;总误差:&quot; + str(overallError))</span><br><span class="line">        print(&quot;Pred:&quot; + str(d))</span><br><span class="line">        print(&quot;True:&quot; + str(c))</span><br><span class="line">        out = 0</span><br><span class="line">        for index,x in enumerate(reversed(d)):</span><br><span class="line">            out += x*pow(2,index)</span><br><span class="line">        print(str(a_int) + &quot; -&quot; + str(b_int) + &quot; = &quot; + str(out))</span><br><span class="line">        print(&quot;------------&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">总误差:[ 3.97242498]</span><br><span class="line">Pred:[0 0 0 0 0 0 0 0]</span><br><span class="line">True:[0 0 0 0 0 0 0 0]</span><br><span class="line">9 -9 = 0</span><br><span class="line">------------</span><br><span class="line">总误差:[ 2.1721182]</span><br><span class="line">Pred:[0 0 0 0 0 0 0 0]</span><br><span class="line">True:[0 0 0 1 0 0 0 1]</span><br><span class="line"> -0 = 0</span><br><span class="line">------------</span><br><span class="line">……</span><br><span class="line">------------</span><br><span class="line">总误差:[ 0.04588656]</span><br><span class="line">Pred:[1 0 0 1 0 1 1 0]</span><br><span class="line">True:[1 0 0 1 0 1 1 0]</span><br><span class="line"> -17 = 150</span><br><span class="line">------------</span><br><span class="line">总误差:[ 0.08098026]</span><br><span class="line">Pred:[1 0 0 1 1 0 0 0]</span><br><span class="line">True:[1 0 0 1 1 0 0 0]</span><br><span class="line"> -52 = 152</span><br><span class="line">------------</span><br><span class="line">总误差:[ 0.03262333]</span><br><span class="line">Pred:[1 1 0 0 0 0 0 0]</span><br><span class="line">True:[1 1 0 0 0 0 0 0]</span><br><span class="line"> -17 = 192</span><br><span class="line">------------</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，刚开始还不准，随着迭代次数增加，到后来已经可以完全拟合退位减法了。</p>
<h4 id="9-2-2-实例56：使用RNN网络拟合回声信号序列"><a href="#9-2-2-实例56：使用RNN网络拟合回声信号序列" class="headerlink" title="9.2.2 实例56：使用RNN网络拟合回声信号序列"></a>9.2.2 实例56：使用RNN网络拟合回声信号序列</h4><p>本例使用TensorFlow中的函数来演示搭建一个简单RNN网络，使用一串随机的模拟数据作为原始信号，让RNN网络来拟合其对应的回声信号。详细介绍如下。</p>
<p>样本数据为一串随机的由0、1组成的数字，将其当成发射出去的一串信号。当碰到阻挡被反弹回来时，会收到原始信号的回音。</p>
<p>如果步长为3，那么输入和输出的序列如图9-7所示。</p>
<p><img src="Image00160.jpg" alt></p>
<p>图9-7 回声序列</p>
<p>如图9-7所示，回声序列的前3项是null，原序列的第一个信号0，对应的是回声序列的第4项，即回声序列的每一个数都会比原序列滞后3个时序。本例的任务就是将序列截取出来，对于每个原序列来预测它的回声序列。</p>
<p>构建的网络结构如图9-8所示。</p>
<p><img src="Image00161.jpg" alt></p>
<p>图9-8 echo例子网络结构</p>
<p>图9-8中，初始的输入有5个，其中4个是中间状态，1个是x的序列值。通过一层具有4个节点的RNN网络，再接一个全连接层输出0、1分类。这样序列中的每个x都会有一个对应的预测分类值，最终将整个序列x生成了预测序列。具体步骤如下。</p>
<p>实例描述</p>
<p>构建一组序列，生成其对应的模拟回声序列。使用TensorFlow创建一个简单循环神经网络拟合这个回声序列。</p>
<p>1．定义参数生成样本数据</p>
<p>在了解前面样本的规则后，开始编写代码制作样本。</p>
<p>导入Python库，定义相关参数，取50000个序列样本数据，每个测试数据截取15个序列，回声序列的步长为3，最小批次为5。定义生成样本函数generateData，在函数里先随机生成50000个0、1数据的数组x，作为原始的序列，令x里的数据向右循环移动3个位置，生成数据y，作为x的回声序列。因为回声步长是3，表明回声y是从x的第3个数据开始才出现，所以将y的前3个数据清零。</p>
<p>代码9-2 echo模拟</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> import numpy as np</span><br><span class="line"> import tensorflow as tf</span><br><span class="line"> import matplotlib.pyplot as plt</span><br><span class="line"> </span><br><span class="line"> num_epochs = 5</span><br><span class="line"> total_series_length = 50000</span><br><span class="line"> truncated_backprop_length = 15</span><br><span class="line"> state_size = 4</span><br><span class="line"> num_classes = 2</span><br><span class="line"> echo_step = 3</span><br><span class="line"> batch_size = 5</span><br><span class="line"> num_batches = total_series_length//batch_size//truncated_backprop_</span><br><span class="line">length</span><br><span class="line"> </span><br><span class="line"> def generateData():</span><br><span class="line">     x = np.array(np.random.choice(2, total_series_length, p=[0.5,</span><br><span class="line">    0.5])) #在0 和1 中选择total_series_length个数</span><br><span class="line">     y = np.roll(x, echo_step)#向右循环移位，将【1111000】变为【0001111】</span><br><span class="line">     y[0:echo_step] = 0</span><br><span class="line"> </span><br><span class="line">     x = x.reshape((batch_size, -1)) # 5,10000</span><br><span class="line">     y = y.reshape((batch_size, -1))</span><br><span class="line"> </span><br><span class="line">     return (x, y)</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义占位符处理输入数据</p>
<p>定义3个占位符，输入的batchX_placeholder原始序列，回声batchY_placeholder作为标签，循环节点的初始值state。如前面介绍的网络结构，x的原始序列是逐个输入网络的，所以需要将输进去的数据打散，按照时间序列变成15个数组，每个数组有batch_size个元素，进行统一批处理。</p>
<p>代码9-2 echo模拟（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> batchX_placeholder = tf.placeholder(tf.float32,[batch_size, truncated_</span><br><span class="line">backprop_length])</span><br><span class="line"> batchY_placeholder = tf.placeholder(tf.int32,[batch_size, truncated_</span><br><span class="line">backprop_length])</span><br><span class="line"> init_state = tf.placeholder(tf.float32, [batch_size, state_size])</span><br><span class="line"> </span><br><span class="line"> # 将batchX_Placeholder沿维度为1的轴方向进行拆分</span><br><span class="line"> inputs_series = tf.unstack(batchX_placeholder, axis=1)</span><br><span class="line">#truncated_backprop_length个序列</span><br><span class="line"> labels_series = tf.unstack(batchY_placeholder, axis=1)</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义网络结构</p>
<p>按照图9-8中的网络结构，定义一层循环网络与一层全连接网络。由于数据是一个数组序列，所以需要通过循环将输入数据按照原有序列逐个输入网络，并输出对应的predictions序列。同样的，对于每个序列值都要对其输出做loss计算，在loss中使用了sparse_softmax_cross_entropy_with_logits函数，因为label的最大值正好是1，而且是一位的，就不需要再转成one_hot编码了（具体细节见本书6.5.3节），最终将所有的loss取均值放入优化器中。</p>
<p>代码9-2 echo模拟（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">current_state = init_state</span><br><span class="line">predictions_series = []</span><br><span class="line">losses =[]</span><br><span class="line">#使用一个循环，按照序列逐个输入</span><br><span class="line">for current_input, labels in zip(inputs_series,labels_series):</span><br><span class="line">    current_input = tf.reshape(current_input, [batch_size, 1])</span><br><span class="line">#加入初始状态</span><br><span class="line">    input_and_state_concatenated = tf.concat([current_input, current_</span><br><span class="line">   state],1) </span><br><span class="line"></span><br><span class="line">    next_state = tf.contrib.layers.fully_connected(input_and_state_</span><br><span class="line">   concatenated,state_size,activation_fn=tf.tanh)</span><br><span class="line">    current_state = next_state</span><br><span class="line">    logits =tf.contrib.layers.fully_connected(next_state,num_</span><br><span class="line">   classes,activation_fn=None)</span><br><span class="line">    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=</span><br><span class="line">   labels,logits=logits)</span><br><span class="line">    losses.append(loss)</span><br><span class="line">    predictions = tf.nn.softmax(logits)</span><br><span class="line">    predictions_series.append(predictions)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">total_loss = tf.reduce_mean(losses)</span><br><span class="line">train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)</span><br></pre></td></tr></table></figure>

</details>

<p>4．建立session训练数据</p>
<p>建立session，总样本循环10次进行迭代。将初始化循环神经网络的状态设为0，在总样本中循环读取15个序列作为批次中的一个样本。</p>
<p>代码9-2 echo模拟（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    plt.ion()</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.show()</span><br><span class="line">    loss_list = []</span><br><span class="line"></span><br><span class="line">    for epoch_idx in range(num_epochs):</span><br><span class="line">        x,y = generateData()</span><br><span class="line">        _current_state = np.zeros((batch_size, state_size))</span><br><span class="line"></span><br><span class="line">        print(&quot;New data, epoch&quot;, epoch_idx)</span><br><span class="line"></span><br><span class="line">        for batch_idx in range(num_batches):#50000/ 5 /15=分成多少段</span><br><span class="line">            start_idx = batch_idx * truncated_backprop_length</span><br><span class="line">            end_idx = start_idx + truncated_backprop_length</span><br><span class="line"></span><br><span class="line">            batchX = x[:,start_idx:end_idx]</span><br><span class="line">            batchY = y[:,start_idx:end_idx]</span><br><span class="line"></span><br><span class="line">            _total_loss, _train_step, _current_state, _predictions_</span><br><span class="line">           series = sess.run(</span><br><span class="line">                [total_loss, train_step, current_state, predictions_</span><br><span class="line">               series],</span><br><span class="line">                feed_dict=&#123;</span><br><span class="line">                    batchX_placeholder:batchX,</span><br><span class="line">                    batchY_placeholder:batchY,</span><br><span class="line">                    init_state:_current_state</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">            loss_list.append(_total_loss)</span><br></pre></td></tr></table></figure>

</details>

<p>5．测试模型及可视化</p>
<p>每循环100次，将打印数据并调用plot函数生成图像。</p>
<p>代码9-2 echo模拟（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">            if batch_idx%100 == 0:</span><br><span class="line">                print(&quot;Step&quot;,batch_idx, &quot;Loss&quot;, _total_loss)</span><br><span class="line">                plot(loss_list, _predictions_series, batchX, batchY)</span><br><span class="line"></span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>plot函数定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">def plot(loss_list, predictions_series, batchX, batchY):</span><br><span class="line">    plt.subplot(2, 3, 1)</span><br><span class="line">    plt.cla()</span><br><span class="line">    plt.plot(loss_list)</span><br><span class="line"></span><br><span class="line">    for batch_series_idx in range(batch_size):</span><br><span class="line">        one_hot_output_series = np.array(predictions_series)[:, batch_</span><br><span class="line">       series_idx, :]</span><br><span class="line">        single_output_series = np.array([(1 if out[0] &lt; 0.5 else 0) for </span><br><span class="line">       out in one_hot_output_series])</span><br><span class="line"></span><br><span class="line">        plt.subplot(2, 3, batch_series_idx + 2)</span><br><span class="line">        plt.cla()</span><br><span class="line">        plt.axis([0, truncated_backprop_length, 0, 2])</span><br><span class="line">        left_offset = range(truncated_backprop_length)</span><br><span class="line">        left_offset2 = range(echo_step,truncated_backprop_length+echo_</span><br><span class="line">       step)</span><br><span class="line">        </span><br><span class="line">        label1 = &quot;past values&quot;</span><br><span class="line">        label2 = &quot;True echo values&quot; </span><br><span class="line">        label3 = &quot;Predictions&quot;      </span><br><span class="line">        plt.plot(left_offset2, batchX[batch_series_idx, :]*0.2+1.5, </span><br><span class="line">       &quot;o--b&quot;, label=label1)</span><br><span class="line">        plt.plot(left_offset, batchY[batch_series_idx, :]*0.2+0.8,</span><br><span class="line">         &quot;x--b&quot;, label=label2)</span><br><span class="line">        plt.plot(left_offset,  single_output_series*0.2+0.1 , &quot;o--y&quot;, </span><br><span class="line">       label=label3)</span><br><span class="line">    </span><br><span class="line">    plt.legend(loc=&apos;best&apos;)</span><br><span class="line">    plt.draw()</span><br><span class="line">    plt.pause(0.0001)</span><br></pre></td></tr></table></figure>

</details>

<p>函数中将输入的x序列、回声y序列和预测的序列同时打印到图像中。按照批次的个数生成图像。为了让3个序列看起来更明显，将其缩放0.2，并且调节每个图像的高度。同时将第一个原始序列的x在显示中滞后echo_step个序列，将3个图像放在同一序列顺序中比较。</p>
<p>运行代码，生成如下结果，如图9-9所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">New data, epoch 0</span><br><span class="line">Step 0 Loss 0.760327</span><br><span class="line">Step 100 Loss 0.462219</span><br><span class="line">Step 200 Loss 0.364076</span><br><span class="line">……</span><br><span class="line">New data, epoch 4</span><br><span class="line">Step 0 Loss 0.324354</span><br><span class="line">Step 100 Loss 0.103451</span><br><span class="line">Step 200 Loss 0.0894693</span><br><span class="line">Step 300 Loss 0.0940791</span><br><span class="line">Step 400 Loss 0.09462</span><br><span class="line">Step 500 Loss 0.10184</span><br><span class="line">Step 600 Loss 0.0910746</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00162.jpg" alt></p>
<p>图9-9 RNN回声实例结果</p>
<p>最下面的点为预测的序列，中间的为回声序列，从图像中可以看到预测序列和回声序列几乎相同，表明RNN网络已经完全可以学到回声的规则。</p>
<h3 id="9-3-循环神经网络（RNN）的改进"><a href="#9-3-循环神经网络（RNN）的改进" class="headerlink" title="9.3 循环神经网络（RNN）的改进"></a>9.3 循环神经网络（RNN）的改进</h3><p>9.2节中演示的代码看似功能很强大，但也仅限于简单的逻辑和样本。对于相对较复杂的问题，这种RNN便会显出其缺陷，原因还是出在激活函数。通常来讲，激活函数在神经网络里最多只能6层左右，因为它的反向误差传递会随着层数的增加，传递的误差值越来越小，而在RNN中，误差传递不仅存在于层与层之间，也在存于每一层的样本序列间，所以RNN无法去学习太长的序列特征。</p>
<p>于是，神经网络学科中又演化了许多RNN网络的变体版本，使得模型能够学习更长的序列特征。接下来一起看看循环神经网络RNN的各种演化版本及内部原理与结构。</p>
<h4 id="9-3-1-LSTM网络介绍"><a href="#9-3-1-LSTM网络介绍" class="headerlink" title="9.3.1 LSTM网络介绍"></a>9.3.1 LSTM网络介绍</h4><p>长短记忆的时间递归神经网络（Long Short Term Memory，LSTM）可以算是RNN网络的代表，其结构同样也非常复杂，下面一起来学习一下。</p>
<p>1．整体介绍</p>
<p>LSTM是一种RNN特殊的类型，可以学习长期依赖信息。LSTM通过刻意的设计来避免长期依赖问题，其结构示意如图9-10所示。</p>
<p><img src="Image00163.jpg" alt></p>
<p>图9-10 LSTM结构示意</p>
<p>图9-10中，每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。方框上方的圆圈代表运算操作（如向量的和），而中间的方框就是学习到的神经网络层。合在一起的线表示向量的连接，分开的线表示内容被复制，然后分发到不同的位置。</p>
<p>将其简化成图9-11，就与之前所说的结构一样了（这里的激活函数使用的是Tanh）。</p>
<p><img src="Image00164.jpg" alt></p>
<p>图9-11 LSTM2</p>
<p>这种结构的核心思想是引入了一个叫做细胞状态的连接，这个细胞状态用来存放想要记忆的东西（对应于简单RNN中的h，只不过这里面不再只存放上一次的状态了，而是通过网络学习存放那些有用的状态）。同时在里面加入3个门。</p>
<p>·忘记门：决定什么时候需要把以前的状态忘记。</p>
<p>·输入门：决定什么时候加入新的状态。</p>
<p>·输出门：决定什么时候需要把状态和输入放在一起输出。</p>
<p>从字面意思可以看出，简单RNN只是把上一次的状态当成本次的输入一起输出。而LSTM在状态的更新和状态是否参与输入都做了灵活的选择，具体选什么，则一起交给神经网络的训练机制来训练。</p>
<p>现在分别介绍一下这三个门的结构和作用。</p>
<p>2．忘记门</p>
<p>如图9-12所示为忘记门。该门决定模型会从细胞状态中丢弃什么信息。</p>
<p>该门会读取ht-1 和xt ，输出一个在0～1之间的数值给每个在细胞状态Ct-1 中的数字。1表示“完全保留”，0表示“完全舍弃”。</p>
<p>例如一个语言模型的例子，假设细胞状态会包含当前主语的性别，于是根据这个状态便可以选择正确的代词。当我们看到新的主语时，应该把新的主语在记忆中更新。该门的功能就是先去记忆中找到以前那个旧的主语（并没有真正忘掉操作，只是找到而已）。</p>
<p><img src="Image00165.jpg" alt></p>
<p>图9-12 lstm忘记门</p>
<p>3．输入门</p>
<p>输入门其实可以分成两部分功能，如图9-13所示。一部分是找到那些需要更新的细胞状态，另一部分是把需要更新的信息更新到细胞状态里。</p>
<p><img src="Image00166.jpg" alt></p>
<p>图9-13 输入门</p>
<p>其中，tanh层就是要创建一个新的细胞状态值向量——Ct ，会被加入到状态中。</p>
<p>忘记门找到了需要忘掉的信息ft 后，再将它与旧状态相乘，丢弃掉确定需要丢弃的信息。再将结果加上it ×Ct 使细胞状态获得新的信息，这样就完成了细胞状态的更新，如图9-14所示。</p>
<p><img src="Image00167.jpg" alt></p>
<p>图9-14 输入门更新</p>
<p>4．输出门</p>
<p>图9-15所示，在输出门中，通过一个Sigmoid层来确定哪部分的信息将输出，接着把细胞状态通过Tanh进行处理（得到一个在-1～1之间的值）并将它和Sigmoid门的输出相乘，得出最终想要输出的那部分，例如在语言模型中，假设已经输入了一个代词，便会计算出需要输出一个与动词相关的信息。</p>
<p><img src="Image00168.jpg" alt></p>
<p>图9-15 输出门</p>
<h4 id="9-3-2-窥视孔连接（Peephole）"><a href="#9-3-2-窥视孔连接（Peephole）" class="headerlink" title="9.3.2 窥视孔连接（Peephole）"></a>9.3.2 窥视孔连接（Peephole）</h4><p>窥视孔连接（Peephole）的出现是为了弥补忘记门一个缺点：当前cell的状态不能影响到Input Gate，Forget Gate在下一时刻的输出，使整个cell对上个序列的处理丢失了部分信息。所以增加了Peephole connections，如图9-16所示虚线部分。计算的顺序为：</p>
<p>（1）上一时刻从cell输出的数据，随着本次时刻的数据一起输入Input Gate和Forget Gate。</p>
<p>（2）将输入门和忘记门的输出数据同时输入cell中。</p>
<p>（3）cell出来的数据输入到当前时刻的Output Gate，也输入到下一时刻的input gate，forget gate。</p>
<p>（4）Forget Gate输出的数据与cell激活后的数据一起作为整个Block的输出。</p>
<p><img src="Image00169.jpg" alt></p>
<p>图9-16 Peephole逻辑</p>
<p>如图9-17所示为Peephole的详细结构。通过这样的结构，将Gate的输入部分增加了一个来源——Forget Gate，Input Gate的输入来源增加了cell前一时刻的输出，Output Gate的输入来源增加了cell当前时刻的输出，使cell对序列记忆增强。</p>
<p><img src="Image00170.jpg" alt></p>
<p>图9-17 Peephole的详细结构</p>
<h4 id="9-3-3-带有映射输出的STMP"><a href="#9-3-3-带有映射输出的STMP" class="headerlink" title="9.3.3 带有映射输出的STMP"></a>9.3.3 带有映射输出的STMP</h4><p>带有映射的LSTM（lstm with recurrent projection layer），在原有lSTM基础之上增加了一个映射层（projection layer），并将这个layer连接到lSTM的输入，该映射层是通过全连接网络来实现的，可以通过改变其输出维度调节总的参数量，起到模型压缩的作用。</p>
<h4 id="9-3-4-基于梯度剪辑的cell"><a href="#9-3-4-基于梯度剪辑的cell" class="headerlink" title="9.3.4 基于梯度剪辑的cell"></a>9.3.4 基于梯度剪辑的cell</h4><p>基于梯度剪辑的cell（Clipping cell）源于这个问题：LSTM的损失函数是每一个时间点的RNN的输出和标签的交叉熵（cross-entropy）之和。这种loss在使用Backpropagation through time（BPTT）梯度下降法的训练过程中，可能会出现剧烈的抖动。</p>
<p>当参数值在较为平坦的区域更新时，由于该区域梯度值比较小，此时的学习率一般会变得较大，如果突然到达了陡峭的区域，梯度值陡增，再与此时较大的学习率相乘，参数就有很大幅度的更新，因此学习过程非常不稳定。</p>
<p>Clipping cell方法的使用可以优化这个问题，具体做法是：为梯度设置阈值，超过该阈值的梯度值都会被cut，这样参数更新的幅度就不会过大，因此容易收敛。</p>
<p>从原理上可以理解为：RNN和LSTM的记忆单元的相关运算是不同的，RNN中每一个时间点的记忆单元中的内容（隐藏层结点）都会更新，而LSTM则是使用忘记门机制将记忆单元中的值与输入值相加（按某种权值）再更新（cell状态），记忆单元中的值会始终对输出产生影响（除非Forget Gate完全关闭），因此梯度值易引起爆炸，所以Clipping功能是很有必要的。</p>
<h4 id="9-3-5-GRU网络介绍"><a href="#9-3-5-GRU网络介绍" class="headerlink" title="9.3.5 GRU网络介绍"></a>9.3.5 GRU网络介绍</h4><p>GRU是与LSTM功能几乎一样的另一个常用的网络结构，它将忘记门和输入门合成了一个单一的更新门，同样还混合了细胞状态和隐藏状态及其他一些改动。最终的模型比标准的LSTM模型要简单，如图9-18所示。</p>
<p><img src="Image00171.jpg" alt></p>
<p>图9-18 GRU模型</p>
<p>当然，基于LSTM的变体不止GRU一个，并且经过一些专业人士的测试，它们在性能和准确度上几乎没什么差别，只是在具体的某些业务上会有略微不同。</p>
<p>由于GRU比LSTM少一个状态输出，效果几乎一样，因此在编码时使用GRU可以让代码更为简单一些。</p>
<h4 id="9-3-6-Bi-RNN网络介绍"><a href="#9-3-6-Bi-RNN网络介绍" class="headerlink" title="9.3.6 Bi-RNN网络介绍"></a>9.3.6 Bi-RNN网络介绍</h4><p>Bi-RNN又叫双向RNN，是采用了两个方向的RNN网络。</p>
<p>RNN网络擅长的是对于连续数据的处理，既然是连续的数据规律，我们不仅可以学习它的正向规律，还可以学习它的反向规律。这样将正向和反向结合的网络，会比单向的循环网络有更高的拟合度。例如，预测一个语句中缺失的词语，则需要根据上下文来进行预测。</p>
<p>双向RNN的处理过程与单向的RNN非常类似，就是在正向传播的基础上再进行一次反向传播，而且这两个都连接着一个输出层。这个结构提供给输出层输入序列中，每一个点完整的过去和未来的上下文信息。图9-19所示为一个沿着时间展开的双向循环神经网络。</p>
<p><img src="Image00172.jpg" alt></p>
<p>图9-19 一个沿着时间展开的双向循环神经网络</p>
<p>双向RNN会比单向RNN多一个隐藏层，6个独特的权值在每一个时步被重复利用，6个权值分别对应输入到向前和向后隐含层（w1，w3），隐含层到隐含层自己（w2，w5），向前和向后隐含层到输出层（w4，w6）。</p>
<p>双向PNN时序在神经网络里的时序步骤如图9-20所示。</p>
<p>在按照时间序列正向运算完之后，网络又从时间的最后一项反向地运算一遍，即把t3时刻的输入与默认值0一起生成反向的out3，把反向out3当成t2时刻的输入与原来的t2时刻输入一起生成反向out2；依此类推，直到第一个时序数据。</p>
<p><img src="Image00014.jpg" alt> 注意： 双向循环网络的输出是2个，正向一个，反向一个。最终会把输出结果通过concat并联在一起，然后交给后面的层来处理。例如，数据输入[batch，nhidden]，输出就会变成[batch，nhidden×2]。</p>
<p>在大多数应用里，基于时间序列与上下文有关的、类似NLP中自动回答类的问题，一般都是使用双向LSTM+LSTM/RNN横向扩展来实现的，效果非常好。</p>
<p><img src="Image00173.jpg" alt></p>
<p>图9-20 双向RNN时序</p>
<h4 id="9-3-7-基于神经网络的时序类分类CTC"><a href="#9-3-7-基于神经网络的时序类分类CTC" class="headerlink" title="9.3.7 基于神经网络的时序类分类CTC"></a>9.3.7 基于神经网络的时序类分类CTC</h4><p>CTC（Connectionist Temporal Classification）是语音辨识中的一个关键技术，通过增加一个额外的Symbol代表NULL来解决叠字问题。</p>
<p>RNN的优势是在处理连续的数据，在基于连续的时间序列分类任务中，常常会使用CTC的方法。</p>
<p>该方法主要体现在处理loss值上，通过对序列对不上的label添加blank（空label）的方式，将预测的输出值与给定的label值在时间序列上对齐，通过交叉熵的算法求出具体损失值。</p>
<p>比如在语音识别的例子中，对于一句语音有它的序列值及对应的文本，可以使用CTC的损失函数求出模型输出与label之间的loss，再通过优化器的迭代训练让损失值变小的方式将模型训练出来。</p>
<p>关于ctc_loss的算法细节，这里不做展开，后文还会有例子演示ctc_loss的真正用法。</p>
<h3 id="9-4-TensorFlow实战RNN"><a href="#9-4-TensorFlow实战RNN" class="headerlink" title="9.4 TensorFlow实战RNN"></a>9.4 TensorFlow实战RNN</h3><p>在了解了RNN原理及类型之后，本节开始讲解在TensorFlow中如何构建RNN网络。</p>
<h4 id="9-4-1-TensorFlow中的cell类"><a href="#9-4-1-TensorFlow中的cell类" class="headerlink" title="9.4.1 TensorFlow中的cell类"></a>9.4.1 TensorFlow中的cell类</h4><p>TensorFlow中定义了5个关于cell的类，具体定义如表9-1所示。</p>
<p>表9-1 cell类</p>
<p><img src="Image00174.jpg" alt></p>
<p><img src="Image00175.jpg" alt></p>
<p><img src="Image00014.jpg" alt> 注意： 在使用MultiRNNCell时，有些习惯写法是cells参数中直接用[cell]×n来代表创建n层的cell，这种写法如果不使用作用域隔离，则会报编译错误，或者使用一个外层循环将cell一个个append进去来解决命名冲突。</p>
<h4 id="9-4-2-通过cell类构建RNN"><a href="#9-4-2-通过cell类构建RNN" class="headerlink" title="9.4.2 通过cell类构建RNN"></a>9.4.2 通过cell类构建RNN</h4><p>定义好cell类之后，还需要将它们连接起来构成RNN网络。TensorFlow中有几种现成的构建网络模式，是封装好的函数，直接调用即可，具体介绍如下。</p>
<p>1．静态RNN构建</p>
<p>TensorFlow中提供了一个构建静态RNN的函数static_rnn，定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def static_rnn(cell, inputs, initial_state=None,dtype=None,sequence_ </span><br><span class="line">length=None, scope=None):</span><br></pre></td></tr></table></figure>

</details>

<p>具体参数说明如下。</p>
<p>·cell：生成好的cell类对象。</p>
<p>·inputs：输入数据，一定是list或者二维张量，list的顺序就是时间序列。元素就是每一个序列的值。</p>
<p>·initial_state：初始化cell状态。见9.4.14的详细介绍。</p>
<p>·dtype：期望输出和初始化state的类型。</p>
<p>·sequence_length：每一个输入的序列长度。</p>
<p>·scope：命名空间。</p>
<p>·返回值有两个，一个是结果，一个是cell状态，我们只关注结果即可，结果也是一个list。输入是多少个时序，list里面就会输出多少个元素。</p>
<p><img src="Image00014.jpg" alt> 注意： TensorFlow中的这种定义很不友好，初学者极易出错。在输入时，一定要将我们习惯使用的张量改成list。另外，在得到输出时也要取结果中的最后一个元素参与后面的运算。</p>
<p>2．动态RNN构建</p>
<p>关于动态RNN函数dynamic_rnn的定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def dynamic_rnn (cell, inputs, sequence_length=None, initial_state=None,</span><br><span class="line">                dtype=None, parallel_iterations=None, swap_memory=False,</span><br><span class="line">                time_major=False, scope=None):</span><br></pre></td></tr></table></figure>

</details>

<p>具体参数说明如下。</p>
<p>·cell：生成好的cell类对象。</p>
<p>·inputs：输入数据，是一个张量，一般是三维张量，[batch_size，max_time，…]。其中batch_size表示一次的批次数量，max_time表示时间序列总数，后面是具体数据。</p>
<p>·initial_state：初始化cell状态。见9.4.14的详细介绍。</p>
<p>·dtype：期望输出和初始化state的类型。</p>
<p>·sequence_length：每一个输入的序列长度。</p>
<p>·time_major：为默认值False时，input的shape为[batch_size，max_time，…]。如果是True，shape为[max_time，batch_size，…]。</p>
<p>·scope：命名空间。</p>
<p>·返回值：一个是结果，一个是cell状态，结果是以[batch_size，max_time，…]形式的张量。</p>
<p><img src="Image00014.jpg" alt> 注意： 动态RNN也存在很多容易出错的地方，尤其在输出部分，它是以批次优先的矩阵。因为我们需要取最后一个时序的输出，所以需要转置成时间优先的形式。</p>
<p>3．双向RNN构建</p>
<p>双向RNN作为一个可以学习正、反向规律的循环神经网络，在TensorFlow中有4个函数可以使用，如表9-2所示。</p>
<p>表9-2 双向RNN函数</p>
<p><img src="Image00176.jpg" alt></p>
<p><img src="Image00177.jpg" alt></p>
<p>表9-2中，第一个函数是建立一个简单的双向RNN网络，两个方向各一个cell。第二个函数是建立多层的双向RNN，每个方向都是一个多层cell。最后一个函数与第二个函数相同，只不过输入和输出是张量的形式。有了前面多层网络结构及卷积的基础之后，再理解LSTM将变得很容易。下面例子中仍然是对MNIST进行分类，这里只列出了核心部分，其他部分与原来一样，不再赘述。</p>
<p><img src="Image00014.jpg" alt> 注意： 在单层、多层、双向RNN函数的介绍中，都有动态和静态之分。静态的意思就是按照样本的时间序列个数（n）展开，在图中创建（n）个序列的cell或cell中；动态的意思是只创建样本中一个序列的RNN，其他的序列数据都会通过循环来进入该RNN来运算。</p>
<p>通过静态生成的RNN网络，生成过程所需的时间会更长，网络所占有的内存会更多，导出的模型会更大。模型中会带有每个序列中间态的信息，利于调试。在使用时必须与训练时的样本序列个数相同。通过动态生成的RNN网络，所占用的内存较少，导出的模型较小。模型中只会有最后的状诚。在使用时还能支持不同的序列个数。</p>
<p>4．使用动态RNN处理变长序列</p>
<p>动态RNN还有个更高级的功能就是可以处理变长序列，方法就是：在准备样本的同时，将样本对应的长度也作为初始化参数，一起创建动态RNN。示例代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"># 创建输入数据</span><br><span class="line">X = np.random.randn(2, 4, 5)</span><br><span class="line"> </span><br><span class="line"># 第二个样本长度为3</span><br><span class="line">X[1,1:] = 0</span><br><span class="line">seq_lengths = [4, 1]</span><br><span class="line">#分别建立一个lstm与GRU的cell，比较输出的状态</span><br><span class="line">cell = tf.contrib.rnn.BasicLSTMCell(num_units=3, state_is_tuple=True)</span><br><span class="line">gru = tf.contrib.rnn.GRUCell(3)</span><br><span class="line"> </span><br><span class="line"># 如果没有 initial_state，必须指定 a dtype</span><br><span class="line">outputs, last_states = tf.nn.dynamic_rnn(cell,X, seq_lengths,dtype=tf. float64)</span><br><span class="line">gruoutputs, grulast_states = tf.nn.dynamic_rnn(gru,X,seq_lengths,dtype= tf.float64)</span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">result,sta ,gruout,grusta=sess.run([outputs,last_states,gruoutputs,grulast_states])</span><br><span class="line"> </span><br><span class="line">print(&quot;全序列：\n&quot;, result[0]) #对于全序列则输出正常长度的值</span><br><span class="line">print(&quot;短序列：\n&quot;, result[1]) #对于短序列，会为多余的序列长度补0</span><br><span class="line">print(&apos;LSTM的状态：&apos;,len(sta),&apos;\n&apos;,sta[1]) #在初始化中设置了state_is_ </span><br><span class="line">   tuple为true，所以lstm的状</span><br><span class="line"> 态，为（状态，输出值）</span><br><span class="line">print(&apos;GRU的短序列：\n&apos;,gruout[1])</span><br><span class="line">print(&apos;GRU的状态：&apos;,len(grusta),&apos;\n&apos;,grusta[1]) #Gru没有状态输出。其状态就是</span><br><span class="line"> 最终结果，因为批次为两个，所</span><br><span class="line"> 以输出为2</span><br></pre></td></tr></table></figure>

</details>

<p>这种变成序列在运算之后，对于短序列会在输出结果后面补0，同时会把补0之前的最后输出放到状态里。例如上面代码执行后，会有如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">全序列：</span><br><span class="line"> [[-0.01654044  0.01401587 -0.09957964]</span><br><span class="line"> [-0.02326733  0.05380562 -0.00796815]</span><br><span class="line"> [-0.01326877  0.26243431 -0.20821182]</span><br><span class="line"> [-0.02425857  0.04418174 -0.2551933 ]]</span><br><span class="line">短序列：</span><br><span class="line"> [[ 0.01152199  0.00987599  0.05193869]</span><br><span class="line"> [ 0.          0.          0.        ]</span><br><span class="line"> [ 0.          0.          0.        ]</span><br><span class="line"> [ 0.          0.          0.        ]]</span><br><span class="line">LSTM的状态： 2 </span><br><span class="line"> [[-0.02425857  0.04418174 -0.2551933 ]</span><br><span class="line"> [ 0.01152199  0.00987599  0.05193869]]</span><br><span class="line">GRU的短序列：</span><br><span class="line"> [[ 0.34744831 -0.0745199   0.04048231]</span><br><span class="line"> [ 0.          0.          0.        ]</span><br><span class="line"> [ 0.          0.          0.        ]</span><br><span class="line"> [ 0.          0.          0.        ]]</span><br><span class="line">GRU的状态： 2 </span><br><span class="line"> [ 0.34744831 -0.0745199   0.04048231]</span><br></pre></td></tr></table></figure>

</details>

<p>在源码中，批次的值为2，里面放了一个全序列样本与一个短序列样本。在输出的结果中，使用result[0]将全序列的结果输出，result[1]将短序列的结果输出。全序列与短序列两部分的输出均为4行3列的数组，其中3是由于有3个RNN单元，而4是源于全序列的长度为4。可以看到由于短序列长度为1，其输出结果中其他的3个序列自动补上了0。</p>
<p>动态RNN会将真实长度的最后输出放到状态里，直接从状态取值即可拿到结果。这里需要区分一下LSTM与GRU的状态取值方法。</p>
<p>·LSTM的状态：一般是一个元组（取决于state_is_tuple初始化时的参数设置），内容为（状态，输出值），取值时需要选择输出值对应的索引。</p>
<p>·GRU的状态：因为GRU本身没有状态输出，所以状态值即为输出值。如上面的代码通过打印grusta[1]的值（最后一行），直接可以得到短序列的最终输出值并在屏幕上打印出来。</p>
<h4 id="9-4-3-实例57：构建单层LSTM网络对MNIST数据集分类"><a href="#9-4-3-实例57：构建单层LSTM网络对MNIST数据集分类" class="headerlink" title="9.4.3 实例57：构建单层LSTM网络对MNIST数据集分类"></a>9.4.3 实例57：构建单层LSTM网络对MNIST数据集分类</h4><p>这里的输入x当成28个时间段，每段内容为28个值，使用unstack将原始的输入28×28调整成具有28个元素的list，每个元素为1×28的数组。这28个时序一次送入RNN中，如图9-21所示。</p>
<p><img src="Image00178.jpg" alt></p>
<p>图9-21 LSTM例子</p>
<p>由于是批次操作，所以每次都取该批次中所有图片的一行作为一个时间序列输入。</p>
<p>理解了这个转换之后，构建网络就变得很容易了，先建立一个包含128个cell的类lstm_cell，然后将变形后的x1放进去生成节点outputs，最后通过全连接生成pred，最后使用softmax进行分类。</p>
<p>实例描述</p>
<p>演示使用单层LSTM网络对MNIST数据集分类。</p>
<p>代码9-3 LSTMMnist</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"># 导入MINST data</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"> </span><br><span class="line">n_input = 28            #MNIST data 输入(img shape: 28*28)</span><br><span class="line">n_steps = 28            #序列个数</span><br><span class="line">n_hidden = 128          #隐藏层个数</span><br><span class="line">n_classes = 10          #MNIST 分类个数 (0～9 digits)</span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"> </span><br><span class="line">x1 = tf.unstack(x, n_steps, 1)</span><br><span class="line">lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)</span><br><span class="line">outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x1, </span><br><span class="line">dtype=tf.float32)</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Extracting /data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Iter 1280, Minibatch Loss= 1.957660, Training Accuracy= 0.35156</span><br><span class="line">Iter 2560, Minibatch Loss= 1.633594, Training Accuracy= 0.46875</span><br><span class="line">……</span><br><span class="line">Iter 98560, Minibatch Loss= 0.156201, Training Accuracy= 0.94531</span><br><span class="line">Iter 99840, Minibatch Loss= 0.170062, Training Accuracy= 0.94531</span><br><span class="line"> Finished!</span><br><span class="line">Testing Accuracy: 0.945</span><br></pre></td></tr></table></figure>

</details>

<p>本例中用到了BasicLSTMCell类，还可以使用LSTMCell类，将类名换一下即可，见本书附带资源中的代码“9-4 LSTMCell.py”文件。</p>
<h4 id="9-4-4-实例58：构建单层GRU网络对MNIST数据集分类"><a href="#9-4-4-实例58：构建单层GRU网络对MNIST数据集分类" class="headerlink" title="9.4.4 实例58：构建单层GRU网络对MNIST数据集分类"></a>9.4.4 实例58：构建单层GRU网络对MNIST数据集分类</h4><p>GRU的实现与LSTM几乎一样，修改该前面的代码“9-3 LSTMMnist.py”文件，将LSTMCell换成GRUCell，同时去掉参数和返回值。</p>
<p>实例描述</p>
<p>演示使用单层GRU网络对MNIST数据集分类。</p>
<p>代码9-5 gru</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">gru = tf.contrib.rnn.GRUCell(n_hidden)</span><br><span class="line">outputs = tf.contrib.rnn.static_rnn(gru, x1, dtype=tf.float32)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>由于GRU只有一个输出，所以创建起来没有state_is_tuple参数。</p>
<h4 id="9-4-5-实例59：创建动态单层RNN网络对MNIST数据集分类"><a href="#9-4-5-实例59：创建动态单层RNN网络对MNIST数据集分类" class="headerlink" title="9.4.5 实例59：创建动态单层RNN网络对MNIST数据集分类"></a>9.4.5 实例59：创建动态单层RNN网络对MNIST数据集分类</h4><p>本例中将静态RNN函数改成动态RNN函数即可，将上面的代码“9-5 gru.py”修改如下。</p>
<p>实例描述</p>
<p>演示使用单层动态RNN网络对MNIST数据集分类。</p>
<p>代码9-6 创建动态RNN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">gru = tf.contrib.rnn.GRUCell(n_hidden)</span><br><span class="line"> </span><br><span class="line"># 创建动态RNN</span><br><span class="line">outputs,_  = tf.nn.dynamic_rnn(gru,x,dtype=tf.float32)</span><br><span class="line">outputs = tf.transpose(outputs, [1, 0, 2])</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中，输入不再是转成list的x1，而是x，输出的outputs也通过transpose做了一次转置。</p>
<p>transpose中的第二参数[1，0，2]的意思是将[batch_size，max_time，……]中的第1维batch_size放在前面，第0维max_time放在后面，而第2维的数据不变。按照这些要求，在数据集变为[max_time，batch_size，……]之后，取最后一个时间序列时得到的就是[batch_size，……]了。</p>
<p><img src="Image00014.jpg" alt> 注意： 对于输出是张量形式的RNN对结果处理先转置，再取最后一条，这是一个常用的技巧。</p>
<p>多层RNN在创建过程中，需要使用到前面介绍的MultiRNNCell类，这个类的实例化需要通过单层的cell对象输入。</p>
<p>与前面的例子类似，先创建单层的cell，然后再创建MultiRNNCell对象，在创建好MultiRNNCell后，可以通过静态或动态的RNN网络建立方式将网络组合起来。</p>
<h4 id="9-4-6-实例60：静态多层LSTM对MNIST数据集分类"><a href="#9-4-6-实例60：静态多层LSTM对MNIST数据集分类" class="headerlink" title="9.4.6 实例60：静态多层LSTM对MNIST数据集分类"></a>9.4.6 实例60：静态多层LSTM对MNIST数据集分类</h4><p>修改该前面的代码“9-3 LSTMMnist.py”例子代码如下：通过一个循环来建立3个LSTM的cell并放在list列表变量stacked_rnn里，然后实例化MultiRNNCell对象得到mcell。用unstack将输入的x转成list，输入到static_rnn函数里，返回值的结果再接一个全连接层进行softmax分类。</p>
<p>实例描述</p>
<p>演示使用静态多层LSTM网络对MNIST数据集分类。</p>
<p>代码9-7 McellMNIST</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"> </span><br><span class="line">stacked_rnn = []</span><br><span class="line">for i in range(3):</span><br><span class="line">    stacked_rnn.append(tf.contrib.rnn.LSTMCell(n_hidden))</span><br><span class="line">mcell = tf.contrib.rnn.MultiRNNCell(stacked_rnn)</span><br><span class="line"> </span><br><span class="line">x1 = tf.unstack(x, n_steps, 1)</span><br><span class="line">outputs, states = tf.contrib.rnn.static_rnn(mcell, x1, dtype=tf.float32)</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br><span class="line"> </span><br><span class="line">learning_rate = 0.001</span><br><span class="line"># 定义loss和优化器</span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits </span><br><span class="line">(logits=pred, labels=y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate). </span><br><span class="line">minimize(cost)</span><br><span class="line"> </span><br><span class="line"># 评估模型节点</span><br><span class="line">correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">training_iters = 100000</span><br><span class="line"> </span><br><span class="line">display_step = 10</span><br><span class="line"> </span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<h4 id="9-4-7-实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类"><a href="#9-4-7-实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类" class="headerlink" title="9.4.7 实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类"></a>9.4.7 实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类</h4><p>MultiRNNCell类的功能就是将多个RNN连接在一起，在前面的例子中将3个一样的LSTM连在了一起，其中这些RNN可以是不同的类型。这个就相当于前面讲过的MLP（多层神经网络）中的神经元节点一样。</p>
<p>下面的例子就要将LSTM连接到GRU网络上输出。代码如下。</p>
<p>实例描述</p>
<p>演示使用静态多层LSTM网络对MNIST数据集分类。</p>
<p>代码9-8 mcellLSTMGRU</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gru = tf.contrib.rnn.GRUCell(n_hidden*2)</span><br><span class="line">lstm_cell = tf.contrib.rnn.LSTMCell(n_hidden)</span><br><span class="line">mcell = tf.contrib.rnn.MultiRNNCell([lstm_cell,gru])</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码只是把循环生成的LSTM换成由LSTM与GRU组成的list即可，为了演示两个cell的无关性，特意将GRU的cell设成了n_hidden×2个，LSTM的cell设成n_hidden个，当然最终输出以最后一个节点为主，就是一个具有28个元素的list，每个元素为[batch_ size，n_hidden×2]。如果想要生成更多层的网络结构，直接在list里添加RNN的cell即可。</p>
<h4 id="9-4-8-实例62：动态多层RNN对MNIST数据集分类"><a href="#9-4-8-实例62：动态多层RNN对MNIST数据集分类" class="headerlink" title="9.4.8 实例62：动态多层RNN对MNIST数据集分类"></a>9.4.8 实例62：动态多层RNN对MNIST数据集分类</h4><p>本例与动态单层一样使用dynamic_rnn函数，改写上面代码如下。</p>
<p>实例描述</p>
<p>演示使用动态多层RNN网络对MNIST数据集分类。</p>
<p>代码9-9 动态多层</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">outputs,states  = tf.nn.dynamic_rnn(mcell,x,dtype=tf.float32)#(?, 28, </span><br><span class="line">)</span><br><span class="line">outputs = tf.transpose(outputs, [1, 0, 2])</span><br><span class="line">#(28, ?, 256) 28个时序，取最后一个时序outputs[-1]=(?,256)</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br></pre></td></tr></table></figure>

</details>

<p>将输入改成x，同时将输出的结果进行tf.transpose（outputs，[1，0，2]）的转置处理，取outputs[-1]放到下一层里参与运算。</p>
<h4 id="9-4-9-练习题"><a href="#9-4-9-练习题" class="headerlink" title="9.4.9 练习题"></a>9.4.9 练习题</h4><p>本书附带资源中有4个代码文件——“9-10 LSTM改错.py”“9-11 lstm改错1.py”“9-12 GRU改错2.py”“9-13 LSTM改错3.py”，分别有不同的错误，请将这些错误找出来使程序正常运行。</p>
<h4 id="9-4-10-实例63：构建单层动态双向RNN对MNIST数据集分类"><a href="#9-4-10-实例63：构建单层动态双向RNN对MNIST数据集分类" class="headerlink" title="9.4.10 实例63：构建单层动态双向RNN对MNIST数据集分类"></a>9.4.10 实例63：构建单层动态双向RNN对MNIST数据集分类</h4><p>先建立两个包含128个正反向cell的类lstm_fw_cell、lstm_bw_cell，然后使用tf.nn.bidirectional_dynamic_rnn函数将x放进去生成节点outputs，由于bidirectional_ dynamic_rnn的输出结果与状态是分离的，所以需要手动将结果合并起来并进行转置，然后通过全连接生成pred，再使用softmax进行分类。代码如下。</p>
<p>实例描述</p>
<p>演示使用单层动态双向RNN网络对MNIST数据集分类。</p>
<p>代码9-14 BiRNNMnist</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.contrib import rnn</span><br><span class="line"># 导入MINST data</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"> </span><br><span class="line"># 定义参数</span><br><span class="line">learning_rate = 0.001</span><br><span class="line">training_iters = 100000</span><br><span class="line">batch_size = 128</span><br><span class="line">display_step = 10</span><br><span class="line"> </span><br><span class="line"># 网络模型参数设置</span><br><span class="line">n_input = 28                  # MNIST data 输入(img shape: 28*28)</span><br><span class="line">n_steps = 28                  # 序列个数</span><br><span class="line">n_hidden = 128                # 隐藏层节点个数</span><br><span class="line">n_classes = 10                # MNIST 分类数 (0～9 digits)</span><br><span class="line"> </span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"> </span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"> </span><br><span class="line">x1 = tf.unstack(x, n_steps, 1)</span><br><span class="line">lstm_fw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)</span><br><span class="line"># 反向cell</span><br><span class="line">lstm_bw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)</span><br><span class="line">outputs, output_states = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, </span><br><span class="line">lstm_bw_cell,x,</span><br><span class="line">                                              dtype=tf.float32)</span><br><span class="line">print(len(outputs),outputs[0].shape,outputs[1].shape)</span><br><span class="line">outputs = tf.concat(outputs, 2)</span><br><span class="line">outputs = tf.transpose(outputs, [1, 0, 2])</span><br><span class="line"> </span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，输出的outputs类型如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 (?, 28, 128) (?, 28, 128)</span><br></pre></td></tr></table></figure>

</details>

<p>可以再次证明，输出的outputs是前向和后向分开的。这种方法最原始也最灵活，但要注意，一定要把两个输出结果进行融合（也可以不用concat）。因为后面实例的方法输出的都是concat之后的结果，不需要再额外考虑融合操作。</p>
<h4 id="9-4-11-实例64：构建单层静态双向RNN对MNIST数据集分类"><a href="#9-4-11-实例64：构建单层静态双向RNN对MNIST数据集分类" class="headerlink" title="9.4.11 实例64：构建单层静态双向RNN对MNIST数据集分类"></a>9.4.11 实例64：构建单层静态双向RNN对MNIST数据集分类</h4><p>静态双向RNN的建立是使用static_bidirectional_rnn函数，先建立两个包含128个正反向cell的类lstm_fw_cell、lstm_bw_cell，然后将变形后的x1放进去生成节点outputs，再通过全连接生成pred，最后使用softmax进行分类。代码如下。</p>
<p>实例描述</p>
<p>演示使用单层静态双向RNN网络对MNIST数据集分类。</p>
<p>代码9-15 单层静态双向rnn</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.contrib import rnn</span><br><span class="line"># 输入MINST data</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"> </span><br><span class="line"># 定义参数</span><br><span class="line">learning_rate = 0.001</span><br><span class="line">training_iters = 100000</span><br><span class="line">batch_size = 128</span><br><span class="line">display_step = 10</span><br><span class="line"> </span><br><span class="line"># 网络模型参数设置</span><br><span class="line">n_input = 28                       #MNIST数据输入 (img shape: 28*28)</span><br><span class="line">n_steps = 28                       #步骤序列</span><br><span class="line">n_hidden = 128                     #隐藏层个数</span><br><span class="line">n_classes = 10                     #MNIST总类别(0～9 digits)</span><br><span class="line"> </span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"> </span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"> </span><br><span class="line">x1 = tf.unstack(x, n_steps, 1)</span><br><span class="line">lstm_fw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)</span><br><span class="line"># 反向cell</span><br><span class="line">lstm_bw_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)</span><br><span class="line">outputs,_,_ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell,x1,</span><br><span class="line">                                              dtype=tf.float32)</span><br><span class="line">print(outputs[0].shape,len(outputs))</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Extracting /data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">(?, 256) 28</span><br><span class="line">Iter 1280, Minibatch Loss= 2.142399, Training Accuracy= 0.30469</span><br><span class="line">Iter 2560, Minibatch Loss= 1.830110, Training Accuracy= 0.37500</span><br><span class="line">Iter 3840, Minibatch Loss= 1.613333, Training Accuracy= 0.46875</span><br><span class="line">……</span><br><span class="line">Iter 96000, Minibatch Loss= 0.114890, Training Accuracy= 0.95312</span><br><span class="line">Iter 97280, Minibatch Loss= 0.159568, Training Accuracy= 0.94531</span><br><span class="line">Iter 98560, Minibatch Loss= 0.168179, Training Accuracy= 0.96094</span><br><span class="line">Iter 99840, Minibatch Loss= 0.089507, Training Accuracy= 0.97656</span><br><span class="line"> Finished!</span><br><span class="line">Testing Accuracy: 0.992188</span><br></pre></td></tr></table></figure>

</details>

<p>在输出过程中，我们将outputs的shape打印了出来，可以看到是个长度为28的list，每个元素为[batch_size，2×n_hidden]。双向RNN将输出两倍的结果。</p>
<h4 id="9-4-12-实例65：构建多层双向RNN对MNIST数据集分类"><a href="#9-4-12-实例65：构建多层双向RNN对MNIST数据集分类" class="headerlink" title="9.4.12 实例65：构建多层双向RNN对MNIST数据集分类"></a>9.4.12 实例65：构建多层双向RNN对MNIST数据集分类</h4><p>修改该前面的“9-15单层静态双向rnn.py”例子：将static_bidirectional_rnn换成stack_bidirectional_rnn，并将前、后向中的lstm_fw_cell和lstm_bw_cell用中括号扩起来。这样就用stack_bidirectional_rnn生成了正反各带有一层RNN的双向RNN网络。如果想再增加层，需要在中括号里接着添加即可。代码如下。</p>
<p>实例描述</p>
<p>演示使用多层双向RNN网络对MNIST数据集分类。</p>
<p>代码9-16 多层双向RNN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs,_,_=rnn.stack_bidirectional_rnn([lstm_fw_cell],[lstm_bw_cell],x1,</span><br><span class="line">                                              dtype=tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p>也可以用循环方式生成多个RNN放到list里，代码如下。</p>
<p>代码9-17 list多层双向RNN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stacked_rnn = []</span><br><span class="line">stacked_bw_rnn = []</span><br><span class="line">for i in range(3):</span><br><span class="line">    stacked_rnn.append(tf.contrib.rnn.LSTMCell(n_hidden))</span><br><span class="line">    stacked_bw_rnn.append(tf.contrib.rnn.LSTMCell(n_hidden))</span><br><span class="line">    </span><br><span class="line">outputs,_,_= rnn.stack_bidirectional_rnn(stacked_rnn,stacked_bw_rnn, x1,</span><br><span class="line">                                              dtype=tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p>还可以构建一个多层cell放到stack_bidirectional_rnn中，代码如下。</p>
<p>代码9-18 Multi双向RNN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stacked_rnn = []</span><br><span class="line">stacked_bw_rnn = []</span><br><span class="line">for i in range(3):</span><br><span class="line">    stacked_rnn.append(tf.contrib.rnn.LSTMCell(n_hidden))</span><br><span class="line">    stacked_bw_rnn.append(tf.contrib.rnn.LSTMCell(n_hidden))</span><br><span class="line"> </span><br><span class="line">mcell = tf.contrib.rnn.MultiRNNCell(stacked_rnn)</span><br><span class="line">mcell_bw = tf.contrib.rnn.MultiRNNCell(stacked_bw_rnn)</span><br><span class="line"> </span><br><span class="line">outputs, _, _ = rnn.stack_bidirectional_rnn([mcell],[mcell_bw], x1,</span><br><span class="line">                                              dtype=tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 使用MultiRNNCell时，虽然是多层，但是从外表上看仍是一个输入，stack_ bidirectional_rnn只关心输入的cell类是不是多个，而不会去识别输入的cell里面是否还包含多个。在这种情况下，就必须将输入用中括号括起来，让其变为list类型。</p>
<h4 id="9-4-13-实例66：构建动态多层双向RNN对MNIST数据集分类"><a href="#9-4-13-实例66：构建动态多层双向RNN对MNIST数据集分类" class="headerlink" title="9.4.13 实例66：构建动态多层双向RNN对MNIST数据集分类"></a>9.4.13 实例66：构建动态多层双向RNN对MNIST数据集分类</h4><p>将前面代码中rnn.stack_bidirectional_rnn注释掉，换成stack_bidirectional_dynamic_ rnn，输入变成x，同样将输出转置，然后送往下一层，代码如下。</p>
<p>实例描述</p>
<p>演示使用动态多层双向RNN网络对MNIST数据集分类。</p>
<p>代码9-19 动态Multi双向rnn</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mcell = tf.contrib.rnn.MultiRNNCell(stacked_rnn)</span><br><span class="line">mcell_bw = tf.contrib.rnn.MultiRNNCell(stacked_bw_rnn)</span><br><span class="line"> </span><br><span class="line">outputs, _, _ = rnn.stack_bidirectional_dynamic_rnn([mcell],[mcell_bw], x,</span><br><span class="line">                                              dtype=tf.float32)</span><br><span class="line">outputs = tf.transpose(outputs, [1, 0, 2])</span><br><span class="line"> </span><br><span class="line">print(outputs[0].shape,outputs.shape)</span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1],n_classes, </span><br><span class="line">activation_fn = None)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，输出的outputs类型如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(?, 256) (28, ?, 256)</span><br></pre></td></tr></table></figure>

</details>

<p>前一个括号中是送往下一层的结果，仍然是256即正、反向的结果concat，后一个括号中是outputs的形状。</p>
<h4 id="9-4-14-初始化RNN"><a href="#9-4-14-初始化RNN" class="headerlink" title="9.4.14 初始化RNN"></a>9.4.14 初始化RNN</h4><p>对应于9.4.2节中介绍的构建RNN的初始化cell状态参数，TensorFlow中也封装了对其初始化的方法，一起来看一下。</p>
<p>1．初始化为0</p>
<p>对于正向或反向，第一个cell传入时没有之前的序列输出值，所以需要对其初始化。一般来讲，不用去刻意指定，系统会默认初始化0，当然也可以手动指定其初始化为0。代码如下。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">initial_state = lstm_cell.zero_state(batch_size, dtype)</span><br><span class="line">#在后续的cell实例化中，将initial_state传入即可</span><br></pre></td></tr></table></figure>

</details>

<p>2．初始化为指定值</p>
<p>在确保创建组成RNN的cell时，设置了输出为元组类型（见表9-1中，创建cell类的初始化参数state_is_tuple=True）的前提下，可以使用LSTMStateTuple函数。但有时想要给lstm_cell的initial state赋予我们想要的值，而不是简单的用0来初始化。</p>
<p>示例：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl import </span><br><span class="line">LSTMStateTuple</span><br><span class="line">……</span><br><span class="line">c_state = ……</span><br><span class="line">h_state = ……</span><br><span class="line"># c_state , h_state 都为Tensor</span><br><span class="line">initial_state = LSTMStateTuple(c_state, h_state)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="9-4-15-优化RNN"><a href="#9-4-15-优化RNN" class="headerlink" title="9.4.15 优化RNN"></a>9.4.15 优化RNN</h4><p>RNN的优化技巧有很多，对于前面讲述的神经网络技巧大部分在RNN上都适用，但也有例外，下面就来介绍下RNN自己特有的两个优化方法的处理。</p>
<p>1．dropout功能</p>
<p>在RNN中，如果想使用dropout功能，不能用以前的CNN下的dropout，CNN中：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def dropout(x, keep_prob, noise_shape=None, seed=None, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>因为RNN有自己的dropout，并且实现方式与RNN不一样：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def rnn_cell.DropoutWrapper(rnn_cell, input_keep_prob=1.0, output_keep_ </span><br><span class="line">prob=1.0):</span><br></pre></td></tr></table></figure>

</details>

<p>使用举例：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lstm_cell=tf.nn.rnn_cell.DropoutWrapper(lstm_cell,output_keep_prob=0.5)</span><br></pre></td></tr></table></figure>

</details>

<p>从t-1时刻的状态传递到t时刻进行计算，这中间不进行memory的dropout，仅在同一个t时刻中，多层cell之间传递信息时进行dropout。所以，RNN的dropout方法会有两个设置参数input_keep_prob（传入cell的保留率）和output_keep_prob（输出cell的保留率）</p>
<p>·如果希望是input传入cell时丢弃掉一部分input信息，就设置input_keep_prob，那么传入到cell的就是部分input。</p>
<p>·如果希望cell的output只有一部分作为下一层cell的input，就定义为output_ keep_prob。</p>
<p>示例代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lstm_cell=tf.nn.rnn_cell.BasicLSTMCell(size,forget_bias=0.0,state_is_</span><br><span class="line">tuple=True)</span><br><span class="line">lstm_cell=tf.nn.rnn_cell.DropoutWrapper(lstm_cell,output_keep_prob=0.5)</span><br></pre></td></tr></table></figure>

</details>

<p>在上面代码中，一个RNN层后面跟一个DropoutWrapper，是一种常见的用法。</p>
<p>2．LN基于层的归一化</p>
<p>这部分内容是对应于批量归一化（BN）的。由于RNN的特殊结构，它的输入不同于前面所讲的全连接、卷积网络。</p>
<p>·在BN中，每一层的输入只考虑当前批次样本（或批次样本的转化值）即可。</p>
<p>·但是在RNN中，每一层的输入除了当前批次样本的转化值，还得考虑样本中上一个序列样本的输出值，所以对于RNN的归一化，BN算法不再适用，最小批次覆盖不了全部的输入数据，而是需要对于输入BN的某一层来做归一化，即layer-Normalization。</p>
<p>由于RNN的网络都被LSTM、GRU这样的结构给封装起来，所以想要实现LN并不像BN那样直接在外层添加一个BN层就可以，需要改写LSTM或GRU的cell，对其内部的输入进行归一化处理。</p>
<p>TensorFlow中目前还不支持这样的cell，所以需要开发者自己来改写原有cell的代码，具体的方法可以在下面例子中找到。</p>
<h4 id="9-4-16-实例67：在GRUCell中实现LN"><a href="#9-4-16-实例67：在GRUCell中实现LN" class="headerlink" title="9.4.16 实例67：在GRUCell中实现LN"></a>9.4.16 实例67：在GRUCell中实现LN</h4><p>在本例中将改写GRUCell代码来实现LN，该例子是在前面的代码“9-3 LSTMMnist.py”文件中改写的。</p>
<p>（1）新加了一个函数LN用于做归一化处理。</p>
<p>（2）定义一个LNGRU来代替原始的GRU。通过右击原有的代码tf.contrib.rnn. GRUCell（n_hidden）中GRUCell部分，选择“go to definition”找到GRU实现的代码，全部复制过来，在其<strong>call</strong>函数里修改为如下代码，即完成了属于我们自己的LNGRU类。具体代码如下。</p>
<p>实例描述</p>
<p>手动构建GRUCell的 LN代码，并演示使用该cell对MNIST数据集分类。</p>
<p>代码9-20 lnGRUonMnist</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"> from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell</span><br><span class="line"> from tensorflow.python.ops.math_ops import sigmoid</span><br><span class="line"> from tensorflow.python.ops.math_ops import tanh</span><br><span class="line"> from tensorflow.python.ops import variable_scope as vs</span><br><span class="line"> from tensorflow.python.ops import array_ops</span><br><span class="line"> from tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl import </span><br><span class="line">_linear </span><br><span class="line"> print(tf.__version__)</span><br><span class="line"> tf.reset_default_graph()</span><br><span class="line"> </span><br><span class="line"> def ln(tensor, scope = None, epsilon = 1e-5):</span><br><span class="line">     &quot;&quot;&quot; Layer normalizes a 2D tensor along its second axis &quot;&quot;&quot;</span><br><span class="line">     assert(len(tensor.get_shape()) == 2)</span><br><span class="line">     m, v = tf.nn.moments(tensor, [1], keep_dims=True)</span><br><span class="line">     if not isinstance(scope, str):</span><br><span class="line">         scope = &apos;&apos;</span><br><span class="line">     with tf.variable_scope(scope + &apos;layer_norm&apos;):</span><br><span class="line">         scale = tf.get_variable(&apos;scale&apos;,</span><br><span class="line">                                 shape=[tensor.get_shape()[1]],</span><br><span class="line">                                 initializer=tf.constant_initializer(1))</span><br><span class="line">         shift = tf.get_variable(&apos;shift&apos;,</span><br><span class="line">                                 shape=[tensor.get_shape()[1]],</span><br><span class="line">                                 initializer=tf.constant_initializer(0))</span><br><span class="line">     LN_initial = (tensor -m) / tf.sqrt(v + epsilon)</span><br><span class="line"> </span><br><span class="line">     return LN_initial * scale + shift</span><br><span class="line"> </span><br><span class="line"> class LNGRUCell(RNNCell):</span><br><span class="line">     &quot;&quot;&quot;Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.</span><br><span class="line">    1078).&quot;&quot;&quot;</span><br><span class="line"> </span><br><span class="line">     def __init__(self, num_units, input_size=None, activation=tanh):</span><br><span class="line">         if input_size is not None:</span><br><span class="line">             print(&quot;%s: The input_size parameter is deprecated.&quot; % self)</span><br><span class="line">         self._num_units = num_units</span><br><span class="line">         self._activation = activation</span><br><span class="line"> </span><br><span class="line">     @property</span><br><span class="line">     def state_size(self):</span><br><span class="line">         return self._num_units</span><br><span class="line"> </span><br><span class="line">     @property</span><br><span class="line">     def output_size(self):</span><br><span class="line">         return self._num_units</span><br><span class="line"> </span><br><span class="line">     def __call__(self, inputs, state):</span><br><span class="line">         &quot;&quot;&quot;Gated recurrent unit (GRU) with nunits cells.&quot;&quot;&quot;</span><br><span class="line">         with vs.variable_scope(&quot;Gates&quot;):  </span><br><span class="line">             value =_linear([inputs, state], 2 * self._num_units, True, 1.0)</span><br><span class="line">             r, u = array_ops.split(value=value, num_or_size_splits=2, </span><br><span class="line">            axis=1)</span><br><span class="line">             r = ln(r, scope = &apos;r/&apos;)</span><br><span class="line">             u = ln(u, scope = &apos;u/&apos;)</span><br><span class="line">             r, u = sigmoid(r), sigmoid(u)</span><br><span class="line">         with vs.variable_scope(&quot;Candidate&quot;):</span><br><span class="line">             Cand = _linear([inputs,  r *state], self._num_units, True)</span><br><span class="line">             c_pre = ln(Cand,  scope = &apos;new_h/&apos;)</span><br><span class="line">             c = self._activation(c_pre)</span><br><span class="line">         new_h = u * state + (1 -u) * c</span><br><span class="line">         return new_h, new_h</span><br></pre></td></tr></table></figure>

</details>

<p>LNGRU定义好之后，直接替换原有的GRU使用代码即可。</p>
<p>代码9-20 lnGRUonMnist（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">#3 gru</span><br><span class="line">gru = LNGRUCell(n_hidden)</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>其他代码均不用变化，运行后可以得出如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.1.0-rc2</span><br><span class="line">……</span><br><span class="line">Iter 93440, Minibatch Loss= 0.022772, Training Accuracy= 1.00000</span><br><span class="line">Iter 94720, Minibatch Loss= 0.060210, Training Accuracy= 0.99219</span><br><span class="line">Iter 96000, Minibatch Loss= 0.116144, Training Accuracy= 0.96875</span><br><span class="line">Iter 97280, Minibatch Loss= 0.057876, Training Accuracy= 0.98438</span><br><span class="line">Iter 98560, Minibatch Loss= 0.030294, Training Accuracy= 0.98438</span><br><span class="line">Iter 99840, Minibatch Loss= 0.158428, Training Accuracy= 0.96094</span><br><span class="line"> Finished!</span><br><span class="line">Testing Accuracy: 0.96875</span><br></pre></td></tr></table></figure>

</details>

<p>生成的结果为0.96，比原来的效果有所提升（原来是0.945）。本例中只是使用了一个GRUcell。在多个cell中，LN的效果会更明显些（多cell的例子可以参考本书附带资源中的代码“9-21 LN多GRu1-1.py”文件），其实质只是在cell中调用了一次LN来处理。</p>
<p>读者可以仿照上面的形式来修改其他的cell。</p>
<p><img src="Image00014.jpg" alt> 注意： 本例中已经将代码版本打印出来，这表明该例子是与代码强关联的。如果读者不是这个版本，很可能会遇到错误。因为不同的版本有可能会修改原始的GRU实现代码，所以请读者记住修改该方法，千万不要直接复制代码。</p>
<p>另外，本书配套资源中还提供了关于1.2.0-rc0的代码修改，可以参考代码“9-22 LN多GRu1-2.py”文件。</p>
<h4 id="9-4-17-CTC网络的loss——ctc-loss"><a href="#9-4-17-CTC网络的loss——ctc-loss" class="headerlink" title="9.4.17 CTC网络的loss——ctc_loss"></a>9.4.17 CTC网络的loss——ctc_loss</h4><p>CTC网络的loss就不能用平方差了，更不能用交叉熵，它有更为复杂的公式方法，在TensorFlow中已经有现成的封装函数ctc_loss。下面来一起学习一下。</p>
<p>1．ctc_loss函数介绍</p>
<p>配合前文的CTC，在TensorFlow中提供了一个ctc_loss函数，其作用就是按照序列来处理输出标签和标准标签之间的损失。因为也是成型的函数封装，对于初学者内部实现不用花太多时间关注，只要会用即。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.ctc_loss(labels,inputs,sequence_length,preprocess_collapse_</span><br><span class="line">repeated=False, ctc_merge_repeated=True, time_major=True)</span><br></pre></td></tr></table></figure>

</details>

<p>具体参数说明如下。</p>
<p>·labels：一个int32类型的稀疏矩阵张量（SparseTensor）。</p>
<p>·inputs：（常用变量logits表示）经过RNN后输出的标签预测值，三维的浮点型张量，当time_major为False时形状为[batch_size，max_time，num_classes]，否则为[max_ time，batch_size，num_classes]。</p>
<p>·sequence_length：序列长度。</p>
<p>·preprocess_collapse_repeated：是否需要预处理，将重复的label合并成一个label，默认是false。</p>
<p>·ctc_merge_repeated：在计算时是否将每个non_blank（非空）重复的label当成单独的label来解释，默认是true。</p>
<p>·time_major：决定inputs的格式。</p>
<p>对于preprocess_collapse_repeated与ctc_merge_repeated，都是对于ctc_loss中重复标签处理的控制，各种情况组合后如表9-3所示。</p>
<p>表9-3 ctc_loss函数参数情况</p>
<p><img src="Image00179.jpg" alt></p>
<p>对于ctc_loss的返回值，仍然属于loss的计算模式，当取批次样本进行训练时，同样也需要对最终的ctc_loss求均值。</p>
<p><img src="Image00014.jpg" alt> 注意： 对于重复标签方面的ctc_loss计算，一般情况下默认即可。</p>
<p>另外这里有个隐含的规则，inputs中的classes是指需要输出多少类，在使用ctc_loss时，要将classes+1，即再多生成一个类，用于存放blank。因为输入的序列与label并不是一一对应的，所以需要通过添加blank类，当对应不上时，最后的softmax就会将其生成到blank。具体做法就是在最后的输出层多构建一个节点即可。</p>
<p>这个规则是ctc_loss内置的，否则当标准标签label中的类索引等于inputs中的size-1时会报错。</p>
<p>2．SparseTensor类型</p>
<p>前面提到了SparseTensor类型，这里主要介绍一下，本来应该将其放在前面章节介绍的，考虑到读者的接受程度，所以就放在这里介绍了。</p>
<p>首先介绍下稀疏矩阵，它是相对于密集矩阵而言的。</p>
<p>密集矩阵就是我们常见的矩阵。当密集矩阵中大部分的数都为0时，就可以使用一种更好的存储方式（只将矩阵中不为0的索引和值记录下来）来存储。这种方式就可以大大节省内存空间，它就是“稀疏矩阵”。</p>
<p>稀疏矩阵在TensorFlow中的结构类型如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparseTensor(indices, values, dense_shape)</span><br></pre></td></tr></table></figure>

</details>

<p>一个密集矩阵只需要3个参数即可，说明如下。</p>
<p>·indices：就是前面所说的不为0的位置信息。它是一个二维的int64 Tensor，shape为（N，ndims），指定了sparse tensor中的索引，例如，indices=[[1，3]，[2，4]]，表示dense tensor中对应索引为[1，3]，[2，4]位置的元素的值不为0。</p>
<p>·values：一个list，存储密集矩阵中不为0位置所对应的值，它要与indices里的顺序对应。例如，indices=[[1，3]，[2，4]]，values=[18，3.6]，表明[1，3]的位置是18，[2，4]的位置是3.6。</p>
<p>·dense_shape：一个1D的int64 tensor，代表原来密集矩阵的形状。</p>
<p>3．生成SparseTensor</p>
<p>了解了SparseTensor类型之后，就可以按照参数来拼接出一个SparseTensor了。在实际应用中，常会用到需要将稠密矩阵dense转成稀疏矩阵SparseTensor。示例代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def sparse from_ dense(dense, dtype=np.int32):</span><br><span class="line">   </span><br><span class="line">    indices = []</span><br><span class="line">    values = []</span><br><span class="line"> </span><br><span class="line">    for n, seq in enumerate(dense):</span><br><span class="line">        indices.extend(zip([n] * len(seq), range(len(seq))))</span><br><span class="line">        values.extend(seq)</span><br><span class="line"> </span><br><span class="line">    indices = np.asarray(indices, dtype=np.int64)</span><br><span class="line">    values = np.asarray(values, dtype=dtype)</span><br><span class="line">    shape = np.asarray([len(dense), indices.max(0)[1] + 1], dtype=np.int64)</span><br><span class="line"> </span><br><span class="line">    return tf.SparseTensor(indices=indices, values=values, shape=shape)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 由于TensorFlow中没有现成的函数，可以自己封装好后保存下来，以后需要时随时拿来用。</p>
<p>4．SparseTensor转dense</p>
<p>在TensorFlow中，可以很方便地实现SparseTensor转dense：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.sparse_tensor_to_dense(sp_input,default_value=0,validate_indices=True,</span><br><span class="line">name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>参数说明如下。</p>
<p>·sp_input：一个SparceTensor。</p>
<p>·default_value：没有指定索引的对应的默认值，默认为0。</p>
<p>·validate_indices：布尔值。如果为True，该函数会检查sp_input的indices的lexicographic order是否有重复。</p>
<p>·name：返回tensor的名字前缀，可选。</p>
<p>5．levenshtein距离</p>
<p>前面讲到了ctc_loss是用来训练时间序列分类模型的。评估模型时，一般常使用计算得到的levenshtein距离值作为模型的评分（正确率或错误率）。</p>
<p>levenshtein距离又叫编辑距离（Edit Distance），是指两个字符串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括：将一个字符替换成另一个字符、插入一个字符、删除一个字符。一般来说，编辑距离越小，两个字符串的相似度越大。</p>
<p>这种方法应用非常广泛，在全序列对比、局部序列对比中都会用到，例如语音识别、拼写纠错、DAN比对等方面。</p>
<p>在TensorFlow中，levenshtein距离的处理被封装成对两个稀疏矩阵进行的操作，具体定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def edit_distance(hypothesis,truth, normalize=True, name=&quot;edit_distance&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>参数说明如下。</p>
<p>·hypothesis：SparseTensor类型，输入预测的序列结果。</p>
<p>·truth：SparseTensor类型，输入真实的序列结果。</p>
<p>·normalize：默认为True，求出来的Levenshtein距离除以真实序列的长度。</p>
<p>·name：operation 的名字，可选。</p>
<p>·返回值：R-1维的DenseTensor，包含着每个Sequence的Levenshtein距离。</p>
<h4 id="9-4-18-CTCdecoder"><a href="#9-4-18-CTCdecoder" class="headerlink" title="9.4.18 CTCdecoder"></a>9.4.18 CTCdecoder</h4><p>CTC结构中还有一个重要的环节就是CTCdecoder，下面就来介绍一下。</p>
<p>1．CTCdecoer介绍</p>
<p>虽然在输入ctc_loss中的logits（inputs）是我们的预测结果，但却是带有空标签（blank）的，而且是一个与时间序列强对应的输出。在实际情况下，我们需要一个转化好的类似于原始标准标签（labels）的输出。这时可以使用CTCdecoder，经过它对预测结果加工后，就可以与标准标签（labels）进行损失值（loss）的运算了。</p>
<p>2．CTCdecoder函数</p>
<p>在TensorFlow中，CTCdecoder有两个函数，如表9-4所示。</p>
<p>表9-4 CTCdecoder函数</p>
<p><img src="Image00180.jpg" alt></p>
<p><img src="Image00014.jpg" alt> 注意： 在实际情况中，解码完事的decoder是list，不能直接用，通常取decoder[0]，然后转成密集矩阵，得到的是一个批次的结果，然后再一条一条地取到每一个样本的结果。</p>
<h3 id="9-5-实例68：利用BiRNN实现语音识别"><a href="#9-5-实例68：利用BiRNN实现语音识别" class="headerlink" title="9.5 实例68：利用BiRNN实现语音识别"></a>9.5 实例68：利用BiRNN实现语音识别</h3><p>在神经网络大势兴起之前，语音识别还是有一定门槛的。传统的语音识别方法，是基于语音学（Phonetics）的方法，它们通常包含拼写、声学和语言模型等单独组件。开发人员需要了解编程以外的很多语言学知识，语言学也会作为一门单独的专业学科存在。训练模型的语料中除了要标注具体的文字，还要标注按照时间对应的音素，需要大量的人工成本。</p>
<p>本节将通过一个例子来演示BiRNN在语音识别中的应用。</p>
<p>实例描述</p>
<p>准备一批带有文字标注的语音样本，构建BiRNN网络，通过该语料样本进行训练，最终实现一个能够识别语音的神经网络模型。</p>
<h4 id="9-5-1-语音识别背景"><a href="#9-5-1-语音识别背景" class="headerlink" title="9.5.1 语音识别背景"></a>9.5.1 语音识别背景</h4><p>使用神经网络技术可以将语音识别变得简单。通过能进行时序分类的连接时间分类（Connectionist Temporal Classification，CTC）目标函数，计算多个标签序列的概率，而序列是语音样本中所有可能的对应文字的集合。随后把预测结果与实际进行比较，计算预测结果的误差，以在训练中不断更新网络权重。这样可以丢弃音素的概念，自然也不需要人工根据时序标注对应的音素了。由于是直接拿音频序列来对应文字，连语言模型都可以省去，这样就脱离了标准的语言模型与声学模型，将使语音识别技术与语言无关（也就是中文、英文、地方语言），只要样本足够多，就可以训练出来。</p>
<p>例子中使用了两个代码文件“9-24 yuyinutils.py”与“9-23 yuyinchall.py”。</p>
<p>·代码文件“9-24 yuyinutils.py”：放置语音识别相关的工具函数。</p>
<p>·代码文件“9-23 yuyinchall.py”：放置语音识别主体流程函数。</p>
<h4 id="9-5-2-获取并整理样本"><a href="#9-5-2-获取并整理样本" class="headerlink" title="9.5.2 获取并整理样本"></a>9.5.2 获取并整理样本</h4><p>1．样本下载</p>
<p>本例中使用了清华大学公开的语料库样本，下载地址如下：</p>
<p>·<a href="http://data.cslt.org/thchs30/zip/wav.tgz" target="_blank" rel="noopener">http://data.cslt.org/thchs30/zip/wav.tgz</a> ；</p>
<p>·<a href="http://data.cslt.org/thchs30/zip/doc.tgz" target="_blank" rel="noopener">http://data.cslt.org/thchs30/zip/doc.tgz</a> 。</p>
<p>第一个是音频WAV文件的压缩包。第二个是WAV文件中对应的文字。thchs30语料库本来有3部分，这里只列出了两部分，还有一部分是语言模型，暂时用不上，所以忽略。</p>
<p>省去了语言模型的语料库看起来简单多了，感兴趣的读者完全可以仿照thchs30语料库，自己录制音频，创建自己的语料库。这样你就可以学出一个识别自己口音的语音识别模型了。</p>
<p><img src="Image00014.jpg" alt> 注意： 自己录制时，一定要将音频录制成单声道的，或者将双声道的音频转成单声道也可以。</p>
<p>文件下载好之后，解压并放到指定目录中即可，后面可以在代码中通过该目录进行读取。</p>
<p>2．样本读取</p>
<p>下面通过代码将数据读入内存。指定训练语音的文件夹与对应的文档，调用get_wavs_lables函数即可。</p>
<p>代码9-23 yuyinchall</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">yuyinutils = __import__(&quot;9-24  yuyinutils&quot;)</span><br><span class="line">get_wavs_lables = yuyinutils.get_wavs_lables</span><br><span class="line"></span><br><span class="line">wav_path=&apos;D:/ data_thchs30/data_thchs30/train&apos;</span><br><span class="line">label_file=&apos;D: /data_thchs30/doc/trans/train.word.txt&apos;</span><br><span class="line">   </span><br><span class="line">wav_files, labels = get_wavs_lables(wav_path,label_file) </span><br><span class="line">print(wav_files[0], labels[0])  </span><br><span class="line">print(&quot;wav:&quot;,len(wav_files),&quot;label&quot;,len(labels))</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>输出信息如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:/ data_thchs30/data_thchs30/train/A11_0.WAV 绿 是 阳春 烟 景 大块 文章 的 底色 四月 的 林 峦 更是 绿 得 鲜活 秀媚 诗意 盎然  </span><br><span class="line">wav: 8911 label 8911</span><br></pre></td></tr></table></figure>

</details>

<p>可见，wav_files里面是一个个音频文件名称，其对应的文字都存放在labels数组里，一共是8911个文件。这里用到的get_wavs_lables函数是自己定义的函数，为了代码规整些，我们把它放到另一个py文件（代码“9-24 yuyinutils.py”）里。get_wavs_lables的定义如下。</p>
<p>代码9-24 yuyinutils</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;读取WAV文件对应的label&apos;&apos;&apos;  </span><br><span class="line">def get_wavs_lables(wav_path=wav_path, label_file=label_file): </span><br><span class="line">#获得训练用的WAV文件路径列表 </span><br><span class="line">    wav_files = []  </span><br><span class="line">    for (dirpath, dirnames, filenames) in os.walk(wav_path):  </span><br><span class="line">        for filename in filenames:  </span><br><span class="line">            if filename.endswith(&apos;.wav&apos;) or filename.endswith(&apos;.WAV&apos;):  </span><br><span class="line">                filename_path = os.sep.join([dirpath, filename])  </span><br><span class="line">                if os.stat(filename_path).st_size &lt; 240000:   # 剔除掉一些小文件  </span><br><span class="line">                    continue  </span><br><span class="line">                wav_files.append(filename_path)     </span><br><span class="line">    </span><br><span class="line">    labels_dict = &#123;&#125;  </span><br><span class="line">    with open(label_file, &apos;rb&apos;) as f:  </span><br><span class="line">        for label in f:  </span><br><span class="line">            label = label.strip(b&apos;\n&apos;)  </span><br><span class="line">            label_id = label.split(b&apos; &apos;, 1)[0]  </span><br><span class="line">            label_text = label.split(b&apos; &apos;, 1)[1]  </span><br><span class="line">            labels_dict[label_id.decode(&apos;ascii&apos;)] = label_text.decode</span><br><span class="line">           (&apos;utf-8&apos;)</span><br><span class="line">            </span><br><span class="line">    labels = []  </span><br><span class="line">    new_wav_files = []  </span><br><span class="line">    for wav_file in wav_files:  </span><br><span class="line">        wav_id = os.path.basename(wav_file).split(&apos;.&apos;)[0] </span><br><span class="line">        </span><br><span class="line">        if wav_id in labels_dict:  </span><br><span class="line">            labels.append(labels_dict[wav_id])  </span><br><span class="line">            new_wav_files.append(wav_file)  </span><br><span class="line">   </span><br><span class="line">    return new_wav_files, labels</span><br></pre></td></tr></table></figure>

</details>

<p>首先是通过WAV文件路径读入文件。然后再将文本文件内容按照WAV文件名进行裁分放到labels里，最终将WAV与labels的对应顺序关联起来。</p>
<p><img src="Image00014.jpg" alt> 注意： 在读取文本时使用的是UTF-8编码，如果在Windows下自建数据集，需要改成GB2312编码。</p>
<p>3．建立批次获取样本函数</p>
<p>在代码“9-23 yuyinchall.py”文件中，读取完WAV文件和labels之后，添加如下代码，对labels的字数进行统计。接着定义一个next_batch函数，该函数的作用就是取一批次的样本数据进行训练。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"> from collections import Counter</span><br><span class="line"> ## 自定义</span><br><span class="line"> from yuyinutils import  sparse_tuple_to_texts_ch,ndarray_to_text_ch</span><br><span class="line"> from yuyinutils import get_audio_and_transcriptch, pad_sequences</span><br><span class="line"> from yuyinutils import sparse_tuple_from</span><br><span class="line"> ……</span><br><span class="line"> # 字表 </span><br><span class="line"> all_words = []  </span><br><span class="line"> for label in labels:  </span><br><span class="line">     all_words += [word for word in label]  </span><br><span class="line"> counter = Counter(all_words)  </span><br><span class="line"> words = sorted(counter)</span><br><span class="line"> words_size= len(words)</span><br><span class="line"> word_num_map = dict(zip(words, range(words_size))) </span><br><span class="line"> </span><br><span class="line"> print(&apos;字表大小:&apos;, words_size) </span><br><span class="line">  </span><br><span class="line"> n_input = 26                 #计算美尔倒谱系数的个数</span><br><span class="line"> n_context = 9                #对于每个时间点，要包含上下文样本的个数</span><br><span class="line">sparse_tuple_to_texts_ch = yuyinutils.sparse_tuple_to_texts_ch</span><br><span class="line">ndarray_to_text_ch        = yuyinutils.ndarray_to_text_ch</span><br><span class="line">get_audio_and_transcritych = yuyinutils.get_audio_and_transcriptch</span><br><span class="line">pad_sequences              = yuyinutils.pad_sequences</span><br><span class="line">sparse_tuple_from         = yuyinutils.sparse_tuple_from</span><br><span class="line"> batch_size =8</span><br><span class="line"> def next_batch(labels, start_idx = 0,batch_size=1,wav_files = wav_</span><br><span class="line">files):</span><br><span class="line">     filesize = len(labels)</span><br><span class="line">     end_idx = min(filesize, start_idx + batch_size)</span><br><span class="line">     idx_list = range(start_idx, end_idx)</span><br><span class="line">     txt_labels = [labels[i] for i in idx_list]</span><br><span class="line">     wav_files = [wav_files[i] for i in idx_list]</span><br><span class="line">     (source, audio_len, target, transcript_len) = get_audio_and_</span><br><span class="line">     transcriptch(None,</span><br><span class="line">                                                       wav_files,</span><br><span class="line">                                                       n_input,</span><br><span class="line">                                                       n_context,word_num_map,</span><br><span class="line">  txt_labels)</span><br><span class="line">     </span><br><span class="line">     start_idx += batch_size</span><br><span class="line">     # 验证 start_idx </span><br><span class="line">     if start_idx &gt;= filesize:</span><br><span class="line">         start_idx = -1</span><br><span class="line"> </span><br><span class="line">     # 使用pad方式对其输入序列</span><br><span class="line">     source, source_lengths = pad_sequences(source) #如果有多个文件将长度统一，支持按最大截断或补0</span><br><span class="line">     sparse_labels = sparse_tuple_from(target)</span><br><span class="line"> </span><br><span class="line">     return start_idx,source, source_lengths, sparse_labels</span><br></pre></td></tr></table></figure>

</details>

<p>将音频数据转成训练数据是在next_batch中的get_audio_and_transcriptch函数里完成的，然后使用pad_sequences函数将该批次的音频数据对齐。对于文本，使用sparse_tuple_from函数将其转成稀疏矩阵，这3个函数都放在代码“9-24 yuyinutils.py”文件里面。</p>
<p>添加测试代码，取出批次数据并打印出来。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> next_idx,source,source_len,sparse_lab = next_batch(labels,0,batch_</span><br><span class="line">size)</span><br><span class="line"> print(len(sparse_lab))</span><br><span class="line"> print(np.shape(source))</span><br><span class="line"> t = sparse_tuple_to_texts_ch(sparse_lab,words)</span><br><span class="line"> print(t[0])</span><br><span class="line"> #source为具体的样本，每条样本的内容为19个时间序列，包括：前9（不够补空）+本身+</span><br><span class="line">后9。每个时间序列有26个美尔倒谱系数。第一条的样本是从第10个时间序列开始的。</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">词汇表大小: 2666</span><br><span class="line">3</span><br><span class="line">(8, 1168, 494)</span><br><span class="line">绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然</span><br></pre></td></tr></table></figure>

</details>

<p>整个样本集里涉及的字数有2666个，sparse_lab为文字转化成向量后并生成的稀疏矩阵，所以长度为3，补0对齐后的音频数据的shape为（8，1168，494），8代表batchsize；1168代表时序的总个数。494是组合好的MFCC特征数：取前9个时序的MFCC，当前MFCC再加上后9个MFCC，每个MFCC由26个数字组成。最后一个输出是通过sparse_tuple_to_texts_ch 函数将稀疏矩阵向量sparse_lab中的第一个内容还原成文字。函数sparse_tuple_to_texts_ch的定义同样在代码“9-24 yuyinutils.py”文件里。</p>
<p>4．安装python_speech_features工具</p>
<p>为了让机器识别音频数据，必须先将数据从时域转换为频域，需要将语音数据转换为需要计算的13位或26位不同倒谱特征的梅尔倒频谱系数（MFCC）。这一过程可以借助工具python_speech_features的代码包来实现，现在一起来安装该代码包。</p>
<p>在计算机联网的状态下，打开“开始”菜单，在“运行”框里输入cmd，调出控制台窗口，输入如下命令：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install python_speech_features</span><br></pre></td></tr></table></figure>

</details>

<p>python_speech_features工具就会自动安装了。</p>
<p>5．提取音频数据MFCC特征</p>
<p>对于WAV音频的样本，通过MFCC转换之后，在函数get_audio_and_transcriptch中将数据存储为时间（列）和频率特征系数（行）的矩阵，其代码如下。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"> import numpy as np</span><br><span class="line"> </span><br><span class="line"> from python_speech_features import mfcc   #需要使用pip install命令来额外安装</span><br><span class="line"> import scipy.io.wavfile as wav</span><br><span class="line"> ……</span><br><span class="line"> def get_audio_and_transcriptch(txt_files, wav_files, n_input, n_</span><br><span class="line">context,word_num_map,txt_labels=None):</span><br><span class="line">     </span><br><span class="line">     audio = []</span><br><span class="line">     audio_len = []</span><br><span class="line">     transcript = []</span><br><span class="line">     transcript_len = []</span><br><span class="line">     if txt_files!=None:</span><br><span class="line">         txt_labels = txt_files</span><br><span class="line"> </span><br><span class="line">     for txt_obj, wav_file in zip(txt_labels, wav_files):</span><br><span class="line">         # 载入音频数据并转化为特征值</span><br><span class="line">         audio_data = audiofile_to_input_vector(wav_file, n_input, n_</span><br><span class="line">        context)</span><br><span class="line">         audio_data = audio_data.astype(&apos;float32&apos;)</span><br><span class="line"> </span><br><span class="line">         audio.append(audio_data)</span><br><span class="line">         audio_len.append(np.int32(len(audio_data)))</span><br><span class="line"> </span><br><span class="line">         # 载入音频对应的文本</span><br><span class="line">         target = []</span><br><span class="line">         if txt_files!=None:#txt_obj是文件</span><br><span class="line">             target = get_ch_lable_v(txt_obj,word_num_map)</span><br><span class="line">         else:</span><br><span class="line">             target = get_ch_lable_v(None,word_num_map,txt_obj) #txt_obj是labels</span><br><span class="line">         transcript.append(target)</span><br><span class="line">         transcript_len.append(len(target))</span><br><span class="line"> </span><br><span class="line">     audio = np.asarray(audio)</span><br><span class="line">     audio_len = np.asarray(audio_len)</span><br><span class="line">     transcript = np.asarray(transcript)</span><br><span class="line">     transcript_len = np.asarray(transcript_len)</span><br><span class="line">     return audio, audio_len, transcript, transcript_len</span><br></pre></td></tr></table></figure>

</details>

<p>这部分代码遍历所有音频文件及文本，将音频调用audiofile_to_input_vector转成MFCC，文本调用get_ch_lable_v函数将文本转成向量。所以接着看audiofile_to_input_vector的实现。</p>
<p>在audiofile_to_input_vector中先将其转化为MFCC特征码，例如第一个文件会被转成（277，26）数组，代表着277个时间序列，每个序列的特征值是26个。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里有个小技巧，因为使用了双向循环神经网络，它的输出包含正、反向的结果，相当于每一个时间序列都扩大了一倍，所以为了保证总时序不变，使用orig_inputs =<br>orig_inputs[：：2]对orig_inputs每隔一行进行一次取样。这样被忽略的那个序列可以用后文中反向RNN生成的输出来代替，维持了总的序列长度。</p>
<p>接着会扩展这26个特征值，将其扩展成：前9个时间序列MFCC+当前MFCC+后9个时间序列。比如第2个序列的前面只有一个序列不够9个，这时就要为其补0，将它凑够9个。同理对于取不到前9、后9时序的序列都做补0操作。这样数据就被扩成了（139，494）。最后再将其进行标准化（减去均值然后再除以方差）处理，这是为了在训练中效果更好。代码如下。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def audiofile_to_input_vector(audio_filename, numcep, numcontext):</span><br><span class="line"></span><br><span class="line">    # 加载wav文件</span><br><span class="line">    fs, audio = wav.read(audio_filename)</span><br><span class="line"></span><br><span class="line">    # 获得mfcc coefficients</span><br><span class="line">    orig_inputs = mfcc(audio, samplerate=fs, numcep=numcep)</span><br><span class="line">    orig_inputs = orig_inputs[::2]             #(139, 26)</span><br><span class="line"></span><br><span class="line">    train_inputs = np.array([], np.float32)</span><br><span class="line">    train_inputs.resize((orig_inputs.shape[0], numcep + 2 * numcep * </span><br><span class="line">   numcontext))</span><br><span class="line">    </span><br><span class="line">    empty_mfcc = np.array([])</span><br><span class="line">    empty_mfcc.resize((numcep))</span><br><span class="line"></span><br><span class="line">    # 准备输入数据。输入数据的格式由三部分安装顺序拼接而成，分为当前样本的前9个</span><br><span class="line">   序列样本，当前样本序列、后9个序列样本</span><br><span class="line">    time_slices = range(train_inputs.shape[0]) #139个切片</span><br><span class="line">    context_past_min = time_slices[0] + numcontext</span><br><span class="line">    context_future_max = time_slices[-1] -numcontext#[9,1,2...,</span><br><span class="line">   137,129]</span><br><span class="line">    for time_slice in time_slices:</span><br><span class="line">        # 前9个补0，mfcc features</span><br><span class="line">        need_empty_past = max(0, (context_past_min -time_slice))</span><br><span class="line">        empty_source_past = list(empty_mfcc for empty_slots in range</span><br><span class="line">       (need_empty_past))</span><br><span class="line">        data_source_past = orig_inputs[max(0, time_slice -numcontext):</span><br><span class="line">       time_slice]</span><br><span class="line">        assert(len(empty_source_past) + len(data_source_past) == </span><br><span class="line">       numcontext)</span><br><span class="line">        </span><br><span class="line">        # 后9个补0，mfcc features</span><br><span class="line">        need_empty_future = max(0, (time_slice -context_future_max))</span><br><span class="line">        empty_source_future = list(empty_mfcc for empty_slots in range</span><br><span class="line">       (need_empty_future))</span><br><span class="line">        data_source_future = orig_inputs[time_slice + 1:time_slice + </span><br><span class="line">       numcontext + 1]</span><br><span class="line">        assert(len(empty_source_future) + len(data_source_future) == </span><br><span class="line">       numcontext)</span><br><span class="line"></span><br><span class="line">        if need_empty_past:</span><br><span class="line">            past = np.concatenate((empty_source_past, data_source_</span><br><span class="line">           past))</span><br><span class="line">        else:</span><br><span class="line">            past = data_source_past</span><br><span class="line"></span><br><span class="line">        if need_empty_future:</span><br><span class="line">            future = np.concatenate((data_source_future, empty_source_</span><br><span class="line">           future))</span><br><span class="line">        else:</span><br><span class="line">            future = data_source_future</span><br><span class="line"></span><br><span class="line">        past = np.reshape(past, numcontext * numcep)</span><br><span class="line">        now = orig_inputs[time_slice]</span><br><span class="line">        future = np.reshape(future, numcontext * numcep)</span><br><span class="line"></span><br><span class="line">        train_inputs[time_slice] = np.concatenate((past, now, future))</span><br><span class="line">        assert(len(train_inputs[time_slice]) == numcep + 2 * numcep * </span><br><span class="line">       numcontext)</span><br><span class="line"></span><br><span class="line">    # 将数据使用正太分布标准化，减去均值然后再除以方差</span><br><span class="line">    train_inputs = (train_inputs -np.mean(train_inputs)) / np.std</span><br><span class="line">   (train_inputs)</span><br><span class="line">    return train_inputs</span><br></pre></td></tr></table></figure>

</details>

<p>orig_inputs代表转化后的MFCC，train_inputs是将时间序列扩充后的数据，里面的for循环是做补0操作。最后两行是数据标准化。</p>
<p>6．批次音频数据对齐</p>
<p>前面是对单个文件里的特征补0，在训练环节中，文件是一批一批的获取并进行训练的，这要求每一批音频的时序数要统一，所以这里需要有一个对齐处理，pad_sequences的定义如下，可以支持补0和截断两个操作。对于补0和截断的方向都可以通过参数来控制，’post’代表后补0（截断），’pre’代表前补0（截断）。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def pad_sequences(sequences, maxlen=None, dtype=np.float32,</span><br><span class="line">                  padding=&apos;post&apos;, truncating=&apos;post&apos;, value=0.):</span><br><span class="line"></span><br><span class="line">    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)</span><br><span class="line"></span><br><span class="line">    nb_samples = len(sequences)</span><br><span class="line">    if maxlen is None:</span><br><span class="line">        maxlen = np.max(lengths)</span><br><span class="line"></span><br><span class="line">    # 从第一个非空的序列中得到样本形状</span><br><span class="line">    sample_shape = tuple()</span><br><span class="line">    for s in sequences:</span><br><span class="line">        if len(s) &gt; 0:</span><br><span class="line">            sample_shape = np.asarray(s).shape[1:]</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).</span><br><span class="line">   astype(dtype)</span><br><span class="line">    for idx, s in enumerate(sequences):</span><br><span class="line">        if len(s) == 0:</span><br><span class="line">            continue   # 如果序列为空，则跳过</span><br><span class="line">        if truncating == &apos;pre&apos;:</span><br><span class="line">            trunc = s[-maxlen:]</span><br><span class="line">        elif truncating == &apos;post&apos;:</span><br><span class="line">            trunc = s[:maxlen]</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(&apos;Truncating type &quot;%s&quot; not understood&apos; % </span><br><span class="line">           truncating)</span><br><span class="line"></span><br><span class="line">        # 检查trunc</span><br><span class="line">        trunc = np.asarray(trunc, dtype=dtype)</span><br><span class="line">        if trunc.shape[1:] != sample_shape:</span><br><span class="line">            raise ValueError(&apos;Shape of sample %s of sequence at position </span><br><span class="line">           %s is different from expected shape %s&apos; %</span><br><span class="line">                             (trunc.shape[1:], idx, sample_shape))</span><br><span class="line"></span><br><span class="line">        if padding == &apos;post&apos;:</span><br><span class="line">            x[idx, :len(trunc)] = trunc</span><br><span class="line">        elif padding == &apos;pre&apos;:</span><br><span class="line">            x[idx, -len(trunc):] = trunc</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(&apos;Padding type &quot;%s&quot; not understood&apos; % </span><br><span class="line">           padding)</span><br><span class="line">    return x, lengths</span><br></pre></td></tr></table></figure>

</details>

<p>7．文字样本的转化</p>
<p>对于文本方面的样本，需要将里面的文字转换成具体的向量。get_ch_lable_v会按照传入的word_num_map将txt_label或是指定文件中的文字转化成向量。后面的get_ch_lable是读取文件操作，本例中用不到。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def get_ch_lable_v(txt_file,word_num_map,txt_label=None):</span><br><span class="line">        </span><br><span class="line">    words_size = len(word_num_map)</span><br><span class="line">    </span><br><span class="line">    to_num = lambda word: word_num_map.get(word, words_size) </span><br><span class="line"></span><br><span class="line">    if txt_file!= None:</span><br><span class="line">        txt_label = get_ch_lable(txt_file)</span><br><span class="line"></span><br><span class="line">    labels_vector = list(map(to_num, txt_label)) </span><br><span class="line">    return labels_vector  </span><br><span class="line">    </span><br><span class="line">def get_ch_lable(txt_file):  </span><br><span class="line">    labels= &quot; &quot;</span><br><span class="line">    with open(txt_file, &apos;rb&apos;) as f:</span><br><span class="line">        for label in f: </span><br><span class="line">            #labels =label.decode(&apos;utf-8&apos;)</span><br><span class="line">            labels = labels +label.decode(&apos;gb2312&apos;)</span><br><span class="line">            </span><br><span class="line">    return  labels</span><br></pre></td></tr></table></figure>

</details>

<p>8．密集矩阵转成稀疏矩阵</p>
<p>TensorFlow中没有密集矩阵转稀疏矩阵函数，所以需要编写一个。该函数比较常用，可以当成工具来储备，具体代码如下。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def sparse_tuple_from(sequences, dtype=np.int32):</span><br><span class="line">   </span><br><span class="line">    indices = []</span><br><span class="line">    values = []</span><br><span class="line"></span><br><span class="line">    for n, seq in enumerate(sequences):</span><br><span class="line">        indices.extend(zip([n] * len(seq), range(len(seq))))</span><br><span class="line">        values.extend(seq)</span><br><span class="line"></span><br><span class="line">    indices = np.asarray(indices, dtype=np.int64)</span><br><span class="line">    values = np.asarray(values, dtype=dtype)</span><br><span class="line">    shape = np.asarray([len(sequences), indices.max(0)[1] + 1], </span><br><span class="line">   dtype=np.int64)</span><br><span class="line"></span><br><span class="line">    return indices, values, shape</span><br></pre></td></tr></table></figure>

</details>

<p>这里主要是算出indices、values、shape这3个值，得到之后可以使用tf.SparseTensor随时生成稀疏矩阵。</p>
<p>9．将字向量转成文字</p>
<p>字向量转成文字主要有两个函数：sparse_tuple_to_texts_ch函数，将稀疏矩阵的字向量转成文字；ndarray_to_text_ch函数，将密集矩阵的字向量转成文字。两个函数都需要传入字表，然后会按照字表对应的索引将字转化回来。</p>
<p>代码9-24 yuyinutils（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">￼200 ……</span><br><span class="line"> # 常量</span><br><span class="line"> SPACE_TOKEN = &apos;&lt;space&gt;&apos;          # space符号</span><br><span class="line"> SPACE_INDEX = 0                    # 0 为space索引</span><br><span class="line"> FIRST_INDEX = ord(&apos;a&apos;) -1  </span><br><span class="line"> </span><br><span class="line"> def sparse_tuple_to_texts_ch(tuple,words):</span><br><span class="line">     indices = tuple[0]</span><br><span class="line">     values = tuple[1]</span><br><span class="line">     results = [&apos;&apos;] * tuple[2][0]</span><br><span class="line">     for i in range(len(indices)):</span><br><span class="line">         index = indices[i][0]</span><br><span class="line">         c = values[i]</span><br><span class="line">         </span><br><span class="line">         c = &apos; &apos; if c == SPACE_INDEX else words[c]</span><br><span class="line">         results[index] = results[index] + c</span><br><span class="line">     # 返回strings的List </span><br><span class="line">     return results</span><br><span class="line">     </span><br><span class="line"> def ndarray_to_text_ch(value,words):</span><br><span class="line">     results = &apos;&apos;</span><br><span class="line">     for i in range(len(value)):</span><br><span class="line">         results += words[value[i]]</span><br><span class="line">     return results.replace(&apos;`&apos;, &apos; &apos;)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="9-5-3-训练模型"><a href="#9-5-3-训练模型" class="headerlink" title="9.5.3 训练模型"></a>9.5.3 训练模型</h4><p>样本准备好后，就开始模型的搭建了。</p>
<p>1．定义占位符</p>
<p>定义3个占位符，具体说明如下。</p>
<p>·input_tensor：为输入的音频数据[none，none，Mfcc_features]，第一个是batch_size用none来表示；第二个是时序数也用none来表示，因为每一批次的时序都是不同的；第三个是MFCC的特征，是取当前特征n_input和前后n_context个特征的组合，即2× n_context+1个序列，每个序列特征数为n_input，于是得出n_input+（2×n_input * n_context）。</p>
<p>·targets：音频数据所对应的文本，是一个稀疏矩阵的占位符。</p>
<p>·seq_length：当前batch数据的序列长度。</p>
<p>·keep_dropout：dropout的参数。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> input_tensor = tf.placeholder(tf.float32, [None, None, n_input + (2</span><br><span class="line">  * n_input * n_context)], name=&apos;input&apos;) #语音MFCC features</span><br><span class="line"> # ctc_loss计算时需要使用sparse_placeholder来生成 SparseTensor</span><br><span class="line">targets = tf.sparse_placeholder(tf.int32, name=&apos;targets&apos;)#文本</span><br><span class="line"># 1d array of size [batch_size]</span><br><span class="line">seq_length = tf.placeholder(tf.int32, [None], name=&apos;seq_length&apos;) #序列长</span><br><span class="line">keep_dropout= tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure>

</details>

<p>2．构建网络模型</p>
<p>网络模型使用了双向RNN的结构，并将其封装在BiRNN_model函数里。调用的代码如下。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> logits = BiRNN_model( input_tensor, tf.to_int64(seq_length), n_input, </span><br><span class="line">n_context,words_size +1, keep_dropout)</span><br></pre></td></tr></table></figure>

</details>

<p>BiRNN_model的定义如下。</p>
<p>使用3个1024节点的全连接层，然后是一个双向RNN，最后接上2个全连接层，并且都带有dropout层。这里使用的激活函数是带截断的Relu，截断值设为20。学习参数的初始化使用标准差为0.046875的random_normal。keep_dropout_rate为0.95。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> b_stddev = 0.046875</span><br><span class="line"> h_stddev = 0.046875</span><br><span class="line"> </span><br><span class="line"> n_hidden = 1024</span><br><span class="line"> n_hidden_1 = 1024</span><br><span class="line"> n_hidden_2 =1024</span><br><span class="line"> n_hidden_5 = 1024</span><br><span class="line"> n_cell_dim = 1024</span><br><span class="line"> n_hidden_3 = 2 * 1024</span><br><span class="line"> </span><br><span class="line"> keep_dropout_rate=0.95</span><br><span class="line"> relu_clip = 20</span><br><span class="line">  </span><br><span class="line">  def BiRNN_model( batch_x, seq_length, n_input, n_context,n_character ,</span><br><span class="line">keep_dropout):</span><br><span class="line">  </span><br><span class="line"> # batch_x_shape: [batch_size, n_steps, n_input + 2*n_input*n_context]</span><br><span class="line">   batch_x_shape = tf.shape(batch_x)</span><br><span class="line">  </span><br><span class="line">   # 将输入转成时间序列优先</span><br><span class="line">   batch_x = tf.transpose(batch_x, [1, 0, 2])</span><br><span class="line">   # 再转成2维传入第一层</span><br><span class="line">   batch_x = tf.reshape(batch_x,</span><br><span class="line">                         [-1, n_input + 2 * n_input * n_context])   # (n_steps*batch_size, n_input + 2*n_input*n_context)</span><br><span class="line"></span><br><span class="line">   # 使用clipped RELU activation and dropout.</span><br><span class="line">   # 第一层</span><br><span class="line">   with tf.name_scope(&apos;fc1&apos;):</span><br><span class="line">       b1 = variable_on_cpu(&apos;b1&apos;, [n_hidden_1], tf.random_normal_</span><br><span class="line">      initializer(stddev=b_stddev))</span><br><span class="line">       h1 = variable_on_cpu(&apos;h1&apos;, [n_input + 2 * n_input * n_context, </span><br><span class="line">      n_hidden_1],</span><br><span class="line">                          tf.random_normal_initializer(stddev=h_stddev))</span><br><span class="line">       layer_1 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(batch_x, h1), </span><br><span class="line">      b1)), relu_clip)</span><br><span class="line">       layer_1 = tf.nn.dropout(layer_1, keep_dropout)</span><br><span class="line"></span><br><span class="line">  # 第二层</span><br><span class="line">  with tf.name_scope(&apos;fc2&apos;):</span><br><span class="line">        b2 = variable_on_cpu(&apos;b2&apos;, [n_hidden_2], tf.random_normal_</span><br><span class="line">       initializer(stddev=b_stddev))</span><br><span class="line">        h2 = variable_on_cpu(&apos;h2&apos;, [n_hidden_1, n_hidden_2], tf.random_</span><br><span class="line">       normal_initializer(stddev=h_stddev))</span><br><span class="line">        layer_2 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_1, h2), </span><br><span class="line">       b2)), relu_clip)</span><br><span class="line">      layer_2 = tf.nn.dropout(layer_2, keep_dropout)</span><br><span class="line">  # 第三层</span><br><span class="line">  with tf.name_scope(&apos;fc3&apos;):</span><br><span class="line">        b3 = variable_on_cpu(&apos;b3&apos;, [n_hidden_3], tf.random_normal_</span><br><span class="line">       initializer(stddev=b_stddev))</span><br><span class="line">        h3 = variable_on_cpu(&apos;h3&apos;, [n_hidden_2, n_hidden_3], tf.random_</span><br><span class="line">       normal_initializer(stddev=h_stddev))</span><br><span class="line">        layer_3 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_2, h3), </span><br><span class="line">       b3)), relu_clip)</span><br><span class="line">      layer_3 = tf.nn.dropout(layer_3, keep_dropout)</span><br><span class="line"></span><br><span class="line">  # 双向RNN</span><br><span class="line">  with tf.name_scope(&apos;lstm&apos;):</span><br><span class="line">      # 前向 cell:</span><br><span class="line">        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_</span><br><span class="line">       bias=1.0, state_is_tuple=True)</span><br><span class="line">  lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(lstm_fw_cell,</span><br><span class="line">                                               input_keep_prob=keep_dropout)</span><br><span class="line">     # 反向 cell:</span><br><span class="line">        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_</span><br><span class="line">       bias=1.0, state_is_tuple=True)</span><br><span class="line">     lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(lstm_bw_cell,</span><br><span class="line">                                               input_keep_prob=keep_dropout)</span><br><span class="line"></span><br><span class="line">      # &apos;layer_3&apos;  &apos; [n_steps, batch_size, 2*n_cell_dim] &apos;</span><br><span class="line">      layer_3 = tf.reshape(layer_3, [-1, batch_x_shape[0], n_hidden_3])</span><br><span class="line"></span><br><span class="line">        outputs, output_states = tf.nn.bidirectional_dynamic_rnn</span><br><span class="line">       (cell_fw=lstm_fw_cell,</span><br><span class="line">                                                     cell_bw=lstm_bw_cell,</span><br><span class="line">                                                     inputs=layer_3,</span><br><span class="line">                                                     dtype=tf.float32,</span><br><span class="line">                                                     time_major=True,</span><br><span class="line">                                               sequence_length=seq_length)</span><br><span class="line"></span><br><span class="line">        # 连接正、反向结果[n_steps, batch_size, 2*n_cell_dim]</span><br><span class="line">      outputs = tf.concat(outputs, 2)</span><br><span class="line">      # 转化形状[n_steps*batch_size, 2*n_cell_dim]        </span><br><span class="line">      outputs = tf.reshape(outputs, [-1, 2 * n_cell_dim])</span><br><span class="line"></span><br><span class="line">    with tf.name_scope(&apos;fc5&apos;):</span><br><span class="line">        b5 = variable_on_cpu(&apos;b5&apos;, [n_hidden_5], tf.random_normal_</span><br><span class="line">       initializer(stddev=b_stddev))</span><br><span class="line">        h5 = variable_on_cpu(&apos;h5&apos;, [(2 * n_cell_dim), n_hidden_5], </span><br><span class="line">       tf.random_normal_initializer(stddev=h_stddev))</span><br><span class="line">        layer_5 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(outputs, h5), </span><br><span class="line">       b5)), relu_clip)</span><br><span class="line">      layer_5 = tf.nn.dropout(layer_5, keep_dropout)</span><br><span class="line"></span><br><span class="line">  with tf.name_scope(&apos;fc6&apos;):</span><br><span class="line">      # 全连接层用于softmax分类</span><br><span class="line">        b6 = variable_on_cpu(&apos;b6&apos;, [n_character], tf.random_normal_</span><br><span class="line">       initializer(stddev=b_stddev))</span><br><span class="line">        h6 = variable_on_cpu(&apos;h6&apos;, [n_hidden_5, n_character], tf.random_</span><br><span class="line">       normal_initializer(stddev=h_stddev))</span><br><span class="line">      layer_6 = tf.add(tf.matmul(layer_5, h6), b6)</span><br><span class="line"></span><br><span class="line">    # 将二维[n_steps*batch_size, n_character]转成三维 time-major [n_</span><br><span class="line">   steps, batch_size, n_character].</span><br><span class="line">  layer_6 = tf.reshape(layer_6, [-1, batch_x_shape[0], n_character])</span><br><span class="line"></span><br><span class="line">  # Output shape: [n_steps, batch_size, n_character]</span><br><span class="line">  return layer_6</span><br><span class="line"></span><br><span class="line">  &quot;&quot;&quot;</span><br><span class="line"> 使用 CPU memory.</span><br><span class="line"> &quot;&quot;&quot;    </span><br><span class="line"> def variable_on_cpu(name, shape, initializer):</span><br><span class="line">  # 使用/cpu:0 device </span><br><span class="line">  with tf.device(&apos;/cpu:0&apos;):</span><br><span class="line"> </span><br><span class="line">        var = tf.get_variable(name=name, shape=shape, initializer=</span><br><span class="line">       initializer)</span><br><span class="line">    return var</span><br></pre></td></tr></table></figure>

</details>

<p>这里的shape变化比较复杂，需要先将输入变为二维的Tensor，才可以传入全连接层。全连接层进入BIRNN时也需要形状转换成三维的Tensor，BIRNN输出的结果是2×n_hidden，所以后面的全连接层输入是2×n_hidden，最终输出时还要再转回三维的Tensor。</p>
<p>与图片分类不同的是，RNN输出的outputs没有取outputs[-1]，而是全部进入了后面的全连接层。语音识别是对输入的每个时序对应的结果进行转换，所以要将RNN的全部结果送入后面的全连接层；而RNN中的图片识别只是把行当成时序，只需要知道最后一行输入后的结果，所以只取了最后一个时序的输出。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里使用了一个小技巧。通过函数variable_on_cpu来声明学习参数变量，将所有的学习参数定义在CPU的内存中，可以让GPU的内存充分地用于运算。</p>
<p>3．定义损失函数即优化器</p>
<p>语音识别是属于非常典型的时间序列分类问题，前面讲过，对于这样的问题要使用ctc_loss的方法来计算损失值。优化器还是使用AdamOptimizer，学习率为0.001。代码如下。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">  ……</span><br><span class="line">  #调用ctc_loss</span><br><span class="line">   avg_loss = tf.reduce_mean(ctc_ops.ctc_loss(targets, logits, seq_</span><br><span class="line">  length))</span><br><span class="line">  </span><br><span class="line"> ###############################</span><br><span class="line"> #优化器</span><br><span class="line"> </span><br><span class="line"> learning_rate = 0.001</span><br><span class="line"> optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).</span><br><span class="line">minimize(avg_loss)</span><br></pre></td></tr></table></figure>

</details>

<p>4．定义解码并评估模型节点</p>
<p>使用ctc_beam_search_decoder 函数以CTC的方式对预测结果logits进行解码，生成了decoded。前面说过，decoded是一个只有一个元素的数组，所以将其decoded[0]传入edit_distance函数，计算与正确标签targets之间的levenshtein距离。下列代码第182行中的targets与decoded[0]都是稀疏矩阵张量（SparseTensor）类型。对得到的distance取reduce_mean，可以得出该模型对于当前batch的平均错误率。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line"> with tf.name_scope(&quot;decode&quot;):    </span><br><span class="line">   decoded, log_prob = ctc_ops.ctc_beam_search_decoder( logits, seq_</span><br><span class="line">  length, merge_repeated=False)</span><br><span class="line">   </span><br><span class="line"> with tf.name_scope(&quot;accuracy&quot;):</span><br><span class="line">   distance = tf.edit_distance( tf.cast(decoded[0], tf.int32), </span><br><span class="line">  targets)</span><br><span class="line">   # 计算label error rate (accuracy)</span><br><span class="line">   ler = tf.reduce_mean(distance, name=&apos;label_error_rate&apos;)</span><br></pre></td></tr></table></figure>

</details>

<p>5．建立session并添加检查点处理</p>
<p>到此模型已经建立好了，剩下的就是训练部分的搭建了。由于样本比较大，运算时间比较长，所以很有必要为模型添加检查点功能。如下代码在session建立之前，定义一个类（名为saver），用于保存检查点的相关操作，并指定检查点文件夹为当前路径下的log\yuyinchalltest\，然后启动session，进行初始，同时在指定路径下查找最后一次检查点。如果有文件就载入到模型，同时更新迭代次数epoch。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line"> epochs = 100</span><br><span class="line"> savedir = &quot;log/yuyinchalltest/&quot;</span><br><span class="line"> saver = tf.train.Saver(max_to_keep=1)             # 生成saver</span><br><span class="line"> # 创建session</span><br><span class="line"> sess = tf.Session() </span><br><span class="line"> # 没有模型，就重新初始化</span><br><span class="line"> sess.run(tf.global_variables_initializer())</span><br><span class="line"> </span><br><span class="line"> kpt = tf.train.latest_checkpoint(savedir)</span><br><span class="line"> print(&quot;kpt:&quot;,kpt)</span><br><span class="line"> startepo= 0</span><br><span class="line"> if kpt!=None:</span><br><span class="line">    saver.restore(sess, kpt) </span><br><span class="line">    ind = kpt.find(&quot;-&quot;)</span><br><span class="line">    startepo = int(kpt[ind+1:])</span><br><span class="line">    print(startepo)</span><br></pre></td></tr></table></figure>

</details>

<p>6．通过循环来迭代训练模型</p>
<p>记录下开始时间，启用循环，进行迭代训练，每次循环通过next_batch函数取一批次样本数据，并设置keep_dropout参数，通过sess.run来运行模型的优化器，同时输出loss的值。总样本迭代100次，每次迭代中，一批次取8条数据。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line"> # 准备运行训练步骤</span><br><span class="line"> section = &apos;\n&#123;0:=^40&#125;\n&apos;</span><br><span class="line"> print(section.format(&apos;Run training epoch&apos;))</span><br><span class="line"> </span><br><span class="line"> train_start = time.time()</span><br><span class="line"> for epoch in range(epochs):                      #样本集迭代次数</span><br><span class="line">    epoch_start = time.time()</span><br><span class="line">    if epoch&lt;startepo:</span><br><span class="line">        continue</span><br><span class="line">   </span><br><span class="line">    print(&quot;epoch start:&quot;,epoch,&quot;total epochs= &quot;,epochs)</span><br><span class="line">#######################运行batch####</span><br><span class="line">    n_batches_per_epoch = int(np.ceil(len(labels) / batch_size))</span><br><span class="line">    print(&quot;total loop &quot;,n_batches_per_epoch,&quot;in one epoch，&quot;,batch_size,&quot;items in one loop&quot;) </span><br><span class="line">    </span><br><span class="line">    train_cost = 0</span><br><span class="line">    train_ler = 0</span><br><span class="line">    next_idx =0</span><br><span class="line">    </span><br><span class="line">    for batch in range(n_batches_per_epoch): #每次取batch_size条数据，共循环n_batches_per_epoch次</span><br><span class="line">        #取数据</span><br><span class="line">        next_idx,source,source_lengths,sparse_labels = \</span><br><span class="line">            next_batch(labels,next_idx ,batch_size)</span><br><span class="line">        feed = &#123;input_tensor: source, targets: sparse_labels,seq_</span><br><span class="line">       length: source_lengths,keep_dropout:keep_dropout_rate&#125;</span><br><span class="line">        </span><br><span class="line">        #计算 avg_loss optimizer </span><br><span class="line">        batch_cost, _ = sess.run([avg_loss, optimizer],  feed_dict=</span><br><span class="line">       feed )</span><br><span class="line">        train_cost += batch_cost</span><br></pre></td></tr></table></figure>

</details>

<p>7．定期评估模型，输出模型解码结果</p>
<p>每取20次batch数据，就将过程信息打印出来，将样本数据送入模型进行语音识别，并输出预测结果。为防止打印信息过多，每次只打印一条信息，并将其文件名、原始的文本和解码文本打印出来。</p>
<p>代码9-23 yuyinchall（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">  ……</span><br><span class="line">          if (batch +1)%20 == 0:</span><br><span class="line">             print(&apos;loop:&apos;,batch, &apos;Train cost: &apos;, train_cost/(batch+1))</span><br><span class="line">             feed2 = &#123;input_tensor: source, targets: sparse_labels,</span><br><span class="line">            seq_length: source_lengths,keep_dropout:1.0&#125;</span><br><span class="line"> </span><br><span class="line">             d,train_ler = sess.run([decoded[0],ler], feed_dict=feed2)</span><br><span class="line">             dense_decoded = tf.sparse_tensor_to_dense( d, default_</span><br><span class="line">  value=-1).eval(session=sess)</span><br><span class="line">             dense_labels = sparse_tuple_to_texts_ch(sparse_labels,</span><br><span class="line">            words)</span><br><span class="line">             </span><br><span class="line">             counter =0</span><br><span class="line">             print(&apos;Label err rate: &apos;, train_ler)</span><br><span class="line">             for orig, decoded_arr in zip(dense_labels, dense_decoded):</span><br><span class="line">                 # 转成strings</span><br><span class="line">                 decoded_str = ndarray_to_text_ch(decoded_arr,words)</span><br><span class="line">                 print(&apos; file &#123;&#125;&apos;.format( counter))</span><br><span class="line">                 print(&apos;Original: &#123;&#125;&apos;.format(orig))</span><br><span class="line">                 print(&apos;Decoded:  &#123;&#125;&apos;.format(decoded_str))</span><br><span class="line">                 counter=counter+1</span><br><span class="line">                 break</span><br><span class="line">             </span><br><span class="line">     epoch_duration = time.time() -epoch_start</span><br><span class="line">     </span><br><span class="line">     log = &apos;Epoch &#123;&#125;/&#123;&#125;, train_cost: &#123;:.3f&#125;, train_ler: &#123;:.3f&#125;, time: </span><br><span class="line">    &#123;:.2f&#125; sec&apos;</span><br><span class="line">     print(log.format(epoch ,epochs, train_cost,train_ler,epoch_</span><br><span class="line">    duration))</span><br><span class="line">     saver.save(sess, savedir+&quot;yuyinch.cpkt&quot;, global_step=epoch)</span><br><span class="line">         </span><br><span class="line"> train_duration = time.time() -train_start</span><br><span class="line"> print(&apos;Training complete, total duration: &#123;:.2f&#125; min&apos;.format(train_</span><br><span class="line">duration / 60))</span><br><span class="line"> </span><br><span class="line"> sess.close()</span><br></pre></td></tr></table></figure>

</details>

<p>通过sess.run计算decoded[0]的值只是个SparseTensor类型，需要用tf.sparse_tensor_ to_dense将其转成dense矩阵（记住Tensor Flow里的类型必须用eval或session.run才能得到真实值），然后再调用sparse_tuple_to_texts_ch将其转成文本dense_labels。</p>
<p>在每次迭代的最后加入检查点保存代码，以便中途中断可以恢复。</p>
<p>运行以上代码，经过一段时间之后（十几小时或几十个小时），会得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">file 0</span><br><span class="line">Original: 另外 加工 修理 和 修配 业务 不 属于 营业税 的 应 税 劳务 不 缴纳 营业税</span><br><span class="line">Decoded:  另外 加工 理 和 修配 务 不 属于 营业税 的 应 税 劳务 不 缴纳 营业税</span><br><span class="line">loop: 79 Train cost:  10.3595850527</span><br><span class="line">Label err rate： 0.0189385</span><br><span class="line"> file 0</span><br><span class="line">Original：这 碗 离 娘 饭 姑娘 再有 离 娘 痛楚 也 要 每样 都 吃 一点 才 算 循 规 遵 俗 的</span><br><span class="line">Decoded： 这 碗 离 娘 饭 姑 有 离 娘 痛楚 也 要 每样 都 吃 一点 才 外算 循 规 遵 俗 的</span><br><span class="line">loop: 99 Train cost：10.3084330273</span><br><span class="line">Label err rate： 0.0270463</span><br><span class="line"> file 0</span><br><span class="line">Epoch 99/100, train_cost: 1176.815, train_ler: 0.047, time: 706.20 sec</span><br><span class="line">WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">Training complete, total duration: 1182.50 min</span><br></pre></td></tr></table></figure>

</details>

<p>由此可见程序基本可以将样本库中的语音全部识别出来，错误率在0.02左右。最后打印的警告是出至TensorFlow中保存模型节点时的，不影响整体功能，可以不用管。</p>
<p>一般来讲，将训练好的模型作为识别后端，通过编写程序录音采集，将WAV文件传入进行解码，即可实现在线实时的语音识别了。</p>
<h4 id="9-5-4-练习题"><a href="#9-5-4-练习题" class="headerlink" title="9.5.4 练习题"></a>9.5.4 练习题</h4><p>（1）试着按照前面例子中的样本形式，自己录制一些语音样本，并做出对应的文本文件，用该代码训练出适应自己声音的语音模型。</p>
<p>（2）实例68中的模型里，fc5层使用的是全连接的方法，还可以使用全局平均池化层的方式代替，读者可以试着改写一下代码，看看效果。</p>
<p>（3）尝试在BIRNN部分加入更深的RNN层，来获得更好的识别率。</p>
<h3 id="9-6-实例69：利用RNN训练语言模型"><a href="#9-6-实例69：利用RNN训练语言模型" class="headerlink" title="9.6 实例69：利用RNN训练语言模型"></a>9.6 实例69：利用RNN训练语言模型</h3><p>下面来做一个实验，用RNN预测语言模型，并让它输出一句话，具体业务描述如下。</p>
<p>先让RNN学习一段文字，之后模型可以根据我们的输入再自动预测后面的文字。同时将模型预测出来的文字当成输入，再放到模型里，模型就会预测出下一个文字，这样循环下去，可以看到RNN能够输出一句话。</p>
<p>那么RNN是怎么样来学习这段文字呢？这里将整段文字都看成一个个的序列。在模型里预设值只关注连续的4个序列，这样在整段文字中，每次随意拿出4个连续的文字放到模型里进行训练，然后把第5个连续的值当成标签，与输出的预测值进行loss的计算，形成一个可训练的模型，通过优化器来迭代训练。</p>
<p>实例描述</p>
<p>通过让RNN网络对一段文字的训练学习来生成模型，最终可以使用机器生成的模型来表达自己的意思。</p>
<p>下面看看具体实现过程。</p>
<h4 id="9-6-1-准备样本"><a href="#9-6-1-准备样本" class="headerlink" title="9.6.1 准备样本"></a>9.6.1 准备样本</h4><p>这个环节很简单，随便复制一段话放到txt里即可。在例子中使用的样本如下：</p>
<p>在尘世的纷扰中，只要心头悬挂着远方的灯光，我们就会坚持不懈地走，理想为我们灌注了精神的蕴藉。所以，生活再平凡、再普通、再琐碎，我们都要坚持一种信念，默守一种精神，为自己积淀站立的信心，前行的气力。</p>
<p>这是笔者随意下载的一段文字，把该段文字放到代码同级目录下，起名为wordstest.txt。</p>
<p>1．定义基本工具函数</p>
<p>具体的基本工具函数与语音识别例子差不多，都是与文本处理相关的，首先引入头文件，然后定义相关函数，其中get_ch_lable函数从文件里获取文本，get_ch_lable_v函数将文本数组转换成向量。具体如下。</p>
<p>代码9-25 rnnwordtest</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.contrib import rnn</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line">from collections import Counter</span><br><span class="line">start_time = time.time()</span><br><span class="line">def elapsed(sec):</span><br><span class="line">    if sec&lt;60:</span><br><span class="line">      return str(sec) + &quot; sec&quot;</span><br><span class="line">    elif sec&lt;(60*60):</span><br><span class="line">        return str(sec/60) + &quot; min&quot;</span><br><span class="line">    else:</span><br><span class="line">        return str(sec/(60*60)) + &quot; hr&quot;</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">training_file = &apos;wordstest.txt&apos;</span><br><span class="line"></span><br><span class="line">#处理多个中文文件</span><br><span class="line">def readalltxt(txt_files):</span><br><span class="line">    labels = []</span><br><span class="line">    for txt_file in txt_files:</span><br><span class="line">        </span><br><span class="line">        target = get_ch_lable(txt_file)</span><br><span class="line">        labels.append(target)  </span><br><span class="line">    return labels</span><br><span class="line">    </span><br><span class="line">#处理汉字</span><br><span class="line">def get_ch_lable(txt_file):  </span><br><span class="line">    labels= “”</span><br><span class="line">    with open(txt_file, &apos;rb&apos;) as f:</span><br><span class="line">        for label in f: </span><br><span class="line">        </span><br><span class="line">          labels = labels +label.decode(&apos;gb2312&apos;)</span><br><span class="line">          </span><br><span class="line">    return  labels</span><br><span class="line">   </span><br><span class="line"> #优先转文件里的字符到向量</span><br><span class="line"> def get_ch_lable_v(txt_file,word_num_map,txt_label=None):</span><br><span class="line">      </span><br><span class="line">    words_size = len(word_num_map)   </span><br><span class="line">    to_num = lambda word: word_num_map.get(word, words_size) </span><br><span class="line">    if txt_file!= None:</span><br><span class="line">        txt_label = get_ch_lable(txt_file)</span><br><span class="line"> </span><br><span class="line">    labels_vector = list(map(to_num, txt_label)) </span><br><span class="line">     return labels_vector</span><br></pre></td></tr></table></figure>

</details>

<p>2．样本预处理</p>
<p>样本预处理工作主要是读取整体样本，并存放到training_data里，获取全部的字表words，并生成样本向量wordlabel和与向量对应关系的word_num_map。具体代码如下。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> training_data =get_ch_lable(training_file)</span><br><span class="line">print(&quot;Loaded training data...&quot;)</span><br><span class="line">    </span><br><span class="line">counter = Counter(training_data)  </span><br><span class="line">words = sorted(counter)</span><br><span class="line">words_size= len(words)</span><br><span class="line">word_num_map = dict(zip(words, range(words_size))) </span><br><span class="line"></span><br><span class="line">print(&apos;字表大小:&apos;, words_size)     </span><br><span class="line">wordlabel = get_ch_lable_v(training_file,word_num_map)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="9-6-2-构建模型"><a href="#9-6-2-构建模型" class="headerlink" title="9.6.2 构建模型"></a>9.6.2 构建模型</h4><p>本例中使用多层RNN模型，后面接入一个softmax分类，对下一个字属于哪个向量进行分类，这里认为一个字就是一类。整个例子步骤如下。</p>
<p>1．设置参数定义占位符</p>
<p>学习率为0.001，迭代10000次，每1000次输出一次中间状态。每次输入4个字，来预测第5个字。</p>
<p>网络模型使用了3层的LSTM RNN，第一层为256个cell，第二层和第三层都是512个cell。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 定义参数</span><br><span class="line">learning_rate = 0.001</span><br><span class="line">training_iters = 10000</span><br><span class="line">display_step = 1000</span><br><span class="line">n_input = 4</span><br><span class="line"></span><br><span class="line">n_hidden1 = 256</span><br><span class="line">n_hidden2 = 512</span><br><span class="line">n_hidden3 = 512</span><br><span class="line">#定义占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_input,1])</span><br><span class="line">wordy = tf.placeholder(&quot;float&quot;, [None, words_size])</span><br></pre></td></tr></table></figure>

</details>

<p>代码中定义了两个占位符x和wordy，其中，x代表输入的4个连续文字，wordy则代表一个字，由于用的是字索引向量的one_hot编码，所以其大小为words_size，代表总共的字数。</p>
<p>2．定义网络结构</p>
<p>将x形状变换并按找时间序列裁分，然后放入3层LSTM网络，最终通过一个全连接生成words_size个节点，为后面的softmax做准备。具体代码如下。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> x1 = tf.reshape(x, [-1, n_input])</span><br><span class="line"> x2 = tf.split(x1,n_input,1)</span><br><span class="line"> # 2-layer LSTM，每层有 n_hidden 个units</span><br><span class="line"> rnn_cell = rnn.MultiRNNCell([rnn.LSTMCell(n_hidden1),rnn.LSTMCell</span><br><span class="line">(n_hidden2),rnn.LSTMCell(n_hidden3)])</span><br><span class="line"> </span><br><span class="line"> # 通过RNN得到输出</span><br><span class="line"> outputs, states = rnn.static_rnn(rnn_cell, x2, dtype=tf.float32)</span><br><span class="line"> </span><br><span class="line"> #  通过全连接输出指定维度</span><br><span class="line"> pred = tf.contrib.layers.fully_connected(outputs[-1],words_size,</span><br><span class="line">activation_fn = None)</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义优化器</p>
<p>优化器同样使用AdamOptimizer，loss使用的是softmax的交叉熵，正确率是统计one_hot中索引对应的位置相同的个数。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> # 定义loss与优化器</span><br><span class="line"> loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits</span><br><span class="line">(logits=pred, labels=wordy))</span><br><span class="line"> optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).</span><br><span class="line">minimize(loss)</span><br><span class="line"> </span><br><span class="line"> # 模型评估</span><br><span class="line"> correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(size_input,1))</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure>

</details>

<p>4．训练模型</p>
<p>在训练过程中同样添加保存检查点功能。在session中每次随机取一个偏移量，然后取后面4个文字向量当作输入，第5个文字向量当作标签用来计算loss。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">savedir = &quot;log/rnnword/&quot;</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1)             # 生成saver</span><br><span class="line"></span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as session:</span><br><span class="line">    session.run(tf.global_variables_initializer())</span><br><span class="line">    step = 0</span><br><span class="line">    offset = random.randint(0,n_input+1)</span><br><span class="line">    end_offset = n_input + 1</span><br><span class="line">    acc_total = 0</span><br><span class="line">    loss_total = 0</span><br><span class="line">    </span><br><span class="line">    kpt = tf.train.latest_checkpoint(savedir)</span><br><span class="line">    print(&quot;kpt:&quot;,kpt)</span><br><span class="line">    startepo= 0</span><br><span class="line">    if kpt!=None:</span><br><span class="line">        saver.restore(session, kpt) </span><br><span class="line">        ind = kpt.find(&quot;-&quot;)</span><br><span class="line">        startepo = int(kpt[ind+1:])</span><br><span class="line">        print(startepo)</span><br><span class="line">        step = startepo</span><br><span class="line"></span><br><span class="line">    while step &lt; training_iters:</span><br><span class="line"></span><br><span class="line">        # 随机取一个位置偏移</span><br><span class="line">        if offset &gt; (len(training_data)-end_offset):</span><br><span class="line">            offset = random.randint(0, n_input+1)</span><br><span class="line">       </span><br><span class="line">        inwords = [ [wordlabel[ i]] for i in range(offset, offset+n_</span><br><span class="line">        input) ] # 按照指定的位置偏移获得后4个文字向量，当作输入</span><br><span class="line"></span><br><span class="line">        inwords = np.reshape(np.array(inwords), [-1, n_input, 1])</span><br><span class="line"></span><br><span class="line">        out_onehot= np.zeros([words_size], dtype=float)</span><br><span class="line">        out_onehot[wordlabel[offset+n_input]] = 1.0</span><br><span class="line">        out_onehot = np.reshape(out_onehot,[1,-1])#所有的字都变成onehot</span><br><span class="line"></span><br><span class="line">        _, acc, lossval, onehot_pred = session.run([optimizer, accuracy, </span><br><span class="line">       loss, pred],feed_dict=&#123;x: inwords, wordy: out_onehot&#125;)</span><br><span class="line">        loss_total += lossval</span><br><span class="line">        acc_total += acc</span><br><span class="line">        if (step+1) % display_step == 0:</span><br><span class="line">            print(&quot;Iter= &quot; + str(step+1) + &quot;, Average Loss= &quot; + \</span><br><span class="line">                  &quot;&#123;:.6f&#125;&quot;.format(loss_total/display_step) + &quot;, Average </span><br><span class="line">                 Accuracy= &quot; + \</span><br><span class="line">                  &quot;&#123;:.2f&#125;%&quot;.format(100*acc_total/display_step))</span><br><span class="line">            acc_total = 0</span><br><span class="line">            loss_total = 0</span><br><span class="line">            in2 = [words [wordlabel[i]] for i in range(offset, offset + </span><br><span class="line">           n_input)]</span><br><span class="line">            out2 = words [wordlabel[offset + n_input]]</span><br><span class="line">            out_pred=words[int(tf.argmax(onehot_pred, 1).eval())]</span><br><span class="line">            print(&quot;%s -[%s] vs [%s]&quot; % (in2,out2,out_pred)) </span><br><span class="line">            saver.save(session, savedir+&quot;rnnwordtest.cpkt&quot;, global_</span><br><span class="line">           step=step)</span><br><span class="line">        step += 1</span><br><span class="line">        offset += (n_input+1) #调整下一次迭代使用的偏移量</span><br><span class="line">        </span><br><span class="line">    print(&quot;Finished!&quot;)</span><br><span class="line">    saver.save(session, savedir+&quot;rnnwordtest.cpkt&quot;, global_step=step)</span><br><span class="line">    print(&quot;Elapsed time: &quot;, elapsed(time.time() -start_time))</span><br></pre></td></tr></table></figure>

</details>

<p>由于检查点文件是建立在log/rnnword/目录下的，所以在运行程序之前需要先在代码文件的当前目录下依次建立log/rnnword/文件夹（有兴趣的读者可以改成自动创建）。</p>
<p>运行代码，训练模型得到如下输出：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in </span><br><span class="line">CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">Iter= 9000, Average Loss=0.585445, Average Accuracy=79.10%</span><br><span class="line">[&apos;注&apos;,&apos;了&apos;,&apos;精&apos;,&apos;神&apos;] -[的]vs[了]</span><br><span class="line">WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in </span><br><span class="line">CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">Iter= 10000, Average Loss= 0.409709, Average Accuracy= 85.60%</span><br><span class="line">[&apos;平&apos;,&apos;凡&apos;,&apos;、&apos;,&apos;再&apos;] -[普]vs[普]</span><br><span class="line">WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in </span><br><span class="line">CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">Finished!</span><br><span class="line">WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in </span><br><span class="line">CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">Elapsed time:  1.3609554409980773 min</span><br></pre></td></tr></table></figure>

</details>

<p>迭代10 000次的正确率达到了85%。达到了模型基本可用的状态。当然这只是个例子，读者可以尝试在模型中添加全连接及更多节点的LSTM或是更深层的LSTM来优化识别率，并且当学习的字数变多时，还会有更强大的拟合功能。</p>
<p>5．运行模型生成句子</p>
<p>启用一个循环，等待输入文字，当收到输入的文本后，通过eval计算onehot_pred节点，并进行文字的转义，得到预测文字。接下来将预测文字再循环输入模型中，预测下一个文字。代码中设定循环32次，输出32个文字。</p>
<p>代码9-25 rnnwordtest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">while True:</span><br><span class="line">        prompt = &quot;请输入%s个字: &quot; % n_input</span><br><span class="line">        sentence = input(prompt)</span><br><span class="line">        inputword = sentence.strip()</span><br><span class="line">        </span><br><span class="line">        if len(inputword) != n_input:</span><br><span class="line">            print(&quot;您输入的字符长度为：&quot;,len(inputword),&quot;请输入4个字&quot;)</span><br><span class="line">            continue</span><br><span class="line">        try:</span><br><span class="line">            inputword = get_ch_lable_v(None,word_num_map,inputword)</span><br><span class="line">           </span><br><span class="line">            for i in range(32):</span><br><span class="line">                keys = np.reshape(np.array(inputword), [-1, n_input, 1])</span><br><span class="line">                onehot_pred = session.run(pred, feed_dict=&#123;x: keys&#125;)</span><br><span class="line">                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())</span><br><span class="line">                sentence = &quot;%s%s&quot; % (sentence,words[onehot_predindex])</span><br><span class="line">                inputword = inputword[1:]</span><br><span class="line">                inputword.append(onehot_pred_index)</span><br><span class="line">            print(sentence)</span><br><span class="line">        except:</span><br><span class="line">            print(&quot;该字我还没学会&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">请输入4个字: 生活平凡</span><br><span class="line">生活平凡，要坚持一种信念，默守一种精神，为自己积淀站立的信心，默守一种精</span><br></pre></td></tr></table></figure>

</details>

<p>在本例中，输入了“生活平凡”4个字，可以看到神经网络自动按照这个开头开始往下输出句子，看起来语句还算通顺。</p>
<h3 id="9-7-语言模型的系统学习"><a href="#9-7-语言模型的系统学习" class="headerlink" title="9.7 语言模型的系统学习"></a>9.7 语言模型的系统学习</h3><p>语言模型包括文法语言模型和统计语言模型。一般我们指的是统计语言模型。</p>
<h4 id="9-7-1-统计语言模型"><a href="#9-7-1-统计语言模型" class="headerlink" title="9.7.1 统计语言模型"></a>9.7.1 统计语言模型</h4><p>统计语言模型是指：把语言（词的序列）看作一个随机事件，并赋予相应的概率来描述其属于某种语言集合的可能性。</p>
<p>统计语言模型的作用是，为一个长度为 m 的字符串确定一个概率分布P（w1； w2； …； wm），表示其存在的可能性。其中，w1～wm 依次表示这段文本中的各个词。用一句话简单地说就是计算一个句子的概率大小。</p>
<p>用这种模型来衡量一个句子的合理性，概率越高，说明越符合人们说出来的自然句子，另一个用处是通过这些方法均可以保留住一定的词序信息，获得一个词的上下文信息。</p>
<h4 id="9-7-2-词向量"><a href="#9-7-2-词向量" class="headerlink" title="9.7.2 词向量"></a>9.7.2 词向量</h4><p>前面9.6节的例子可以看作是一个统计语言模型，所使用的词向量是one_hot编码，由于one_hot编码中所有的字都是独立的，所以该语言模型学到的词与词的上下文信息只能存放在网络节点中。</p>
<p>而现实生活中，我们人类对字词的理解却并非如此，例如“手”和“脚”，会自然让人联想到人体的器官，而“墙”则与人体器官相差甚远。这表明本身的词与词之间是有远近关系的。如果让机器学习这种关系并能加以利用，那么便可以使机器像人一样理解语言的意义。</p>
<p>1．词向量解释</p>
<p>在神经网络中是通过一个描述词分布关系的方法来实现语义的理解，这种方法描述的词与one_hot描述的词都可以叫做词向量，但它还有个另外的名字叫word embedding（词嵌入）。如何理解呢？将one_hot词向量中的每一个元素由整型改为浮点型，变为整个实数范围的表示；然后将原来稀疏的巨大维度压缩嵌入到一个更小维度的空间内，如图9-22所示。</p>
<p><img src="Image00181.jpg" alt></p>
<p>图9-22 词嵌入</p>
<p>图9-22中只举了个例子，将三维的向量映射到二维平面里。实际在语言模型中，常常是将二维的张量[batch，字的index]映射到多维空间[batch，embedding的index]。即，embedding中的元素将不再是一个字，而变成了字所转化的多维向量，所有向量之间是有距离远近关系的。</p>
<p>其实one_hot的映射也是这种方法，把每个字表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为0，只有一个维度的值为1，这个维度就代表了当前的字。one_hot映射与词嵌入的唯一区别就是仅仅将字符号化，不包含任何语义信息而已。</p>
<p>word embedding的映射方法是建立在分布假说（distributional hypothesis）基础上的，即假设词的语义由其上下文决定，上下文相似的词，其语义也相似。</p>
<p>词向量的核心步骤由两部分组成：</p>
<p>（1）选择一种方式描述上下文。</p>
<p>（2）选择一种模型刻画某个词（下文称“目标词”）与其上下文之间的关系。</p>
<p>一般来讲就是使用前面介绍的语言模型来完成这种任务。这类方法的最大优势在于可以表示复杂的上下文。</p>
<p>2．词向量训练</p>
<p>在神经网络训练的词嵌入（word embedding）中，一般会将所有的embedding随机初始化，然后在训练过程中不断更新embedding矩阵的值。对于每一个词与它对应向量的映射值，在TensorFlow中使用了一个叫tf.nn.embedding_lookup的方法来完成。</p>
<p>举例如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(&quot;/cpu:0&quot;):</span><br><span class="line">    embedding = tf.get_variable(&quot;embedding&quot;, [vocab_size, size])</span><br><span class="line">    inputs = tf.nn.embedding_lookup(embedding, input_data)</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码先定义的embedding表示有vocab_size个词，每个词的向量个数为size个。最终得到的inputs就是输入向量input_data映射好的词向量了。比如input_data的形状为[batch_size，ndim]，那么inputs就为[batch_size，ndim，size]。</p>
<p><img src="Image00014.jpg" alt> 注意：· 由于该词向量定义好之后是需要在训练中优化的，所以embedding 类型必须是tf.Variable，并且trainable=True（default）。</p>
<p>·embedding_lookup这个函数目前只支持在CPU上运行。</p>
<p>3．候选采样技术</p>
<p>对于语言模型相关问题，本质上还是属于多分类问题。对于多分类问题，一般的做法是在最后一层生成与类别相等维度的节点，然后根据输入样本对应的标签来计算损失值，最终反向传播优化参数。但是由于词汇量的庞大，导致要分类的基数也会非常巨大，这会使得最后一层要有海量的节点来对应词汇的个数（如上亿的词汇量），并且还要对其逐个计算概率值，判断其是该词汇的可能性。这种做法会使训练过程变得非常缓慢，进而无法完成任务。</p>
<p>为了解决这个问题，可使用一种候选采样的技巧，每次只评估所有类别的一个很小的子集，让网络的最后一层只在这个子集中做每个类别的评估计算。因为是监督学习，所以能够知道对应的正确标签（即正样本），额外挑选的子集（对应标签为0）被称为负样本。这样来训练网络，可在保证效率的同时同样会有很好的效果。</p>
<p>4．词向量的应用</p>
<p>在自然语言处理中，一般都会将该任务中涉及的词训练成词向量。然后让每个词以词向量的形式作为神经网络模型的输入，进行一些指定任务的训练。对于一个完整的训练任务，词向量的训练更多的情况是发生在预训练环节。</p>
<p>词向量也可以理解成为onehot的升级版特征映射。从这个角度来看，只要样本序列彼此间有着某种联系，即使不是词，也可以用这种方法处理。例如，在做恶意域名分析检测任务中，可以把某一个域名字符当作一个词，进行词向量的训练。然后再将每个字符用训练好的一组特定的向量进行映射，作为后面模型真实的输入。这样的输入就会比单纯的onehot编码映射效果好很多。</p>
<h4 id="9-7-3-word2vec"><a href="#9-7-3-word2vec" class="headerlink" title="9.7.3 word2vec"></a>9.7.3 word2vec</h4><p>word2vec是谷歌提出的一种词嵌入的工具或者算法集合，采用了两种模型（CBOW与Skip-Gram模型）与两种方法（负采样与层次softmax方法）的组合，比较常见的组合为Skip-Gram和负采样方法。因为其速度快、效果好而广为人知，在任何场合可直接使用。</p>
<p>CBOW模型（Continous Bag of Words Model，CBOW）和Skip-Gram模型都是可以训练出词向量的方法，在具体代码操作中可以只选择其一，但CBOW要比Skip-Gram更快一些。</p>
<p>1．CBOW&amp;Skip-Gram</p>
<p>前文说过统计语言模型就是给出几个词，在这几个词出现的前提下计算某个词出现的概率（事后概率）。</p>
<p>CBOW也是统计语言模型的一种，顾名思义就是根据某个词前面的n个词或者前后n个连续的词，来计算某个词出现的概率。</p>
<p>Skip-Gram模型与之相反，是根据某个词，然后分别计算它前后出现某几个词的各个概率。</p>
<p>如例，“我爱人工智能”对于CBOW模型来讲，首先会将所有的字转成one_hot，然后取出其中的一个字当作输入，将其前面和后面的字分别当作标签，拆分成如下样子：</p>
<p>“我”“爱”</p>
<p>“爱”“我”</p>
<p>“爱”“人”</p>
<p>“人”“爱”</p>
<p>“人”“工”</p>
<p>每一行代表一个样本，第一列代表输入，第二列代表标签。将输入数据送进神经网络（如“我”），同时将输出的预测值与标签（“爱”）计算loss（如输入“我”对应的标签为“爱”，模型的预测输出值为“好”，则计算“爱”和“好”之间的损失偏差，用来优化网络），进行迭代优化，在整个词库中如果字数特别多，会产生很大的矩阵，影响softmax速度。</p>
<p>word2vec使用基于Huffman编码的Hierarchical softmax筛选掉了一部分不可能的词，然后又用nagetive samping再去掉了一些负样本的词，所以时间复杂度就从O（V）变成了O（logV）。</p>
<p>2．TensorFlow的word2vec</p>
<p>在TensorFlow中提供了几个候选采样函数，用来处理loss计算中候选采样的工作，它们按不同的采样规则被封装成了不同的函数，说明如下。</p>
<p>·tf.nn.uniform_candidate_sampler： 均匀地采样出类别子集。</p>
<p>·tf.nn.log_uniform_candidate_sampler：按照 log-uniform （Zipfian） 分布采样。zipfian叫齐夫分布，指只有少数词经常被使用，大部分词很少被使用。</p>
<p>·tf.nn.learned_unigram_candidate_sampler：按照训练数据中出现的类别分布进行采样。</p>
<p>·tf.nn.fixed_unigram_candidate_sampler：按照用户提供的概率分布进行采样。</p>
<p>在实际使用中一般先通过统计或者其他渠道知道待处理的类别满足哪些分布，接着就可以指定函数（或是在nn.fixed_unigram_candidate_sampler中指定对应的分布）来进行候选采样。如果实在不知道类别分布，还可以用 tf.nn.learned_unigram_candidate_sampler。learned_unigram_candidate_sampler的做法是先初始化一个 [0，range_max] 的数组，数组元素初始为1，在训练过程中碰到一个类别，就将相应数组元素加 1，每次按照数组归一化得到的概率进行采样来实现的。</p>
<p><img src="Image00014.jpg" alt> 注意： 在语言相关的任务中，词按照出现频率从大到小排序之后，服从Zipfian分布。一般会先对类别按照出现频率从大到小排序，然后使用log_uniform_candidate_ sampler函数。</p>
<p>TensorFlow的word2vec实现里，比对目标样本的损失值、计算softmax、负采样等过程统统封装到了nce_loss函数中，其默认使用的是log_uniform_candidate_sampler采样函数，在不指定特殊的采样器时，在该函数实现中会把词频越大的词，其类别编号也定义得越大，即优先采用词频高的词作为负样本，词频越高越有可能成为负样本。nce_loss函数配合优化器可以对最后一层的权重进行调优，更重要的是其还会以同样的方式调节word embedding（词嵌入）中的向量，让它们具有更合理的空间关系。</p>
<p>下面先来看看nce_loss函数的定义：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def nce_loss(weights, biases, inputs, labels, num_sampled, num_classes,</span><br><span class="line">             num_true=1,</span><br><span class="line">             sampled_values=None,</span><br><span class="line">             remove_accidental_hits=False,</span><br><span class="line">             partition_strategy=&quot;mod&quot;,</span><br><span class="line">             name=&quot;nce_loss&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>假设输入数据是K维的，一共有N个类，其参数说明如下。</p>
<p>·weight：shape为（N，K）的权重。</p>
<p>·biases：shape为（N）的偏执。</p>
<p>·inputs：输入数据，shape为（batch_size，K）。</p>
<p>·labels：标签数据，shape为（batch_size，num_true）。</p>
<p>·num_true：实际的正样本个数。</p>
<p>·num_sampled：采样出多少个负样本。</p>
<p>·num_classes：类的个数N。</p>
<p>·sampled_values：采样出的负样本，如果是None，就会用默认的sampler去采样，优先采用词频高的词作为负样本。</p>
<p>·remove_accidental_hits：如果采样时采样到的负样本刚好是正样本，是否要去掉。</p>
<p>·partition_strategy：对weights进行embedding_lookup时并行查表时的策略。TensorFlow的embeding_lookup是在CPU里实现的，这里需要考虑多线程查表时的锁的问题。</p>
<p><img src="Image00014.jpg" alt> 注意： 在TensorFlow中还有一个类似于nce_loss的函数sampled_softmax_loss，其用法与nce_loss函数完全一样。不同的是内部实现，nce_loss函数可以进行多标签分类问题，即标签之前不互斥，原因在于其对每一个输出的类都连接一个logistic二分类。而sampled_softmax_loss只能对单个标签分类，即输出的类别是互斥的，原因是其对每个类的输出放在一起统一做了一个多分类操作。</p>
<h4 id="9-7-4-实例70：用CBOW模型训练自己的word2vec"><a href="#9-7-4-实例70：用CBOW模型训练自己的word2vec" class="headerlink" title="9.7.4 实例70：用CBOW模型训练自己的word2vec"></a>9.7.4 实例70：用CBOW模型训练自己的word2vec</h4><p>本例将使用CBOW模型来训练word2vec，最终将所学到的词向量分布关系可视化出来，同时通过该例子练习使用nce_loss函数与word embedding技术，实现自己的word2vec。</p>
<p>实例描述</p>
<p>准备一段文字作为训练的样本，对其使用CBOW模型计算word2vec，并将各个词的向量关系用图展示出来。</p>
<p>1．引入头文件</p>
<p>本例的最后需要将词向量可视化出来。第7～12行代码是可视化相关的引入，即初始化，通过设置mpl的值让plot能够显示中文信息。Scikit-Learn的t-SNE算法模块的作用是非对称降维，是结合了t分布将高维空间的数据点映射到低维空间的距离，主要用于可视化和理解高维数据。</p>
<p>代码9-26 word2vect</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"> import tensorflow as tf</span><br><span class="line">import random</span><br><span class="line">import collections</span><br><span class="line">from collections import Counter</span><br><span class="line">import jieba</span><br><span class="line"></span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line">import matplotlib as mpl</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;] #用来正常显示中文标签  </span><br><span class="line">mpl.rcParams[&apos;font.family&apos;] = &apos;STSong&apos;</span><br><span class="line">mpl.rcParams[&apos;font.size&apos;] = 20</span><br></pre></td></tr></table></figure>

</details>

<p>这次重点关注的是词，不再对字进行one_hot处理，所以需要借助分词工具将文本进行分词处理。本例中使用的是jieba分词库，需要使用之前先安装该分词库。</p>
<p>在“运行”中，输入cmd，进入命令行模式。保证计算机联网状态下在命令行里输入：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pip install jieba</span><br></pre></td></tr></table></figure>

</details>

<p>安装完毕后可以新建一个py文件，使用如下代码简单测试一下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import jieba</span><br><span class="line">seg_list = jieba.cut(&quot;我爱人工智能&quot;)   # 默认是精确模式 </span><br><span class="line">print(&quot; &quot;.join(seg_list))</span><br></pre></td></tr></table></figure>

</details>

<p>如果能够正常运行并且可以分词，就表明jieba分词库安装成功了。</p>
<p>2．准备样本创建数据集</p>
<p>这个环节使用一篇笔者在另一个领域发表的比较有深度的文章“阴阳人体与电能.txt” 来做样本，将该文件放到代码的同级目录下。</p>
<p>代码中使用get_ch_lable函数将所有文字读入training_data，然后在fenci函数里使用jieba分词库对training_data分词生成training_ci，将training_ci放入build_dataset里并生成指定长度（350）的字典。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"> training_file = &apos;人体阴阳与电能.txt &apos;</span><br><span class="line"> </span><br><span class="line"> #中文字</span><br><span class="line"> def get_ch_lable(txt_file):  </span><br><span class="line">     labels= &quot;&quot;</span><br><span class="line">     with open(txt_file, &apos;rb&apos;) as f:</span><br><span class="line">         for label in f: </span><br><span class="line">             </span><br><span class="line">             labels =labels+label.decode(&apos;gb2312&apos;)</span><br><span class="line">            </span><br><span class="line">     return  labels</span><br><span class="line">    </span><br><span class="line"> #分词</span><br><span class="line"> def fenci(training_data):</span><br><span class="line">     seg_list = jieba.cut(training_data)   # 默认是精确模式  </span><br><span class="line">     training_ci = &quot; &quot;.join(seg_list)</span><br><span class="line">     training_ci = training_ci.split()</span><br><span class="line">     #用空格将字符串分开</span><br><span class="line">     training_ci = np.array(training_ci)</span><br><span class="line">     training_ci = np.reshape(training_ci, [-1, ])</span><br><span class="line">     return training_ci</span><br><span class="line"> </span><br><span class="line"> def build_dataset(words, n_words):</span><br><span class="line"> </span><br><span class="line">   &quot;&quot;&quot;Process raw inputs into a dataset.&quot;&quot;&quot;</span><br><span class="line">   count = [[&apos;UNK&apos;, -1]]</span><br><span class="line">   count.extend(collections.Counter(words).most_common(n_words -1))</span><br><span class="line">   dictionary = dict()</span><br><span class="line">   for word, _ in count:</span><br><span class="line">     dictionary[word] = len(dictionary)</span><br><span class="line">   data = list()</span><br><span class="line">   unk_count = 0</span><br><span class="line">   for word in words:</span><br><span class="line">     if word in dictionary:</span><br><span class="line">       index = dictionary[word]</span><br><span class="line">     else:</span><br><span class="line">       index = 0   # dictionary[&apos;UNK&apos;]</span><br><span class="line">       unk_count += 1</span><br><span class="line">     data.append(index)</span><br><span class="line">   count[0][1] = unk_count</span><br><span class="line">   reversed_dictionary = dict(zip(dictionary.values(), dictionary.</span><br><span class="line">  keys()))</span><br><span class="line">   return data, count, dictionary, reversed_dictionary</span><br><span class="line"> </span><br><span class="line"> training_data =get_ch_lable(training_file)</span><br><span class="line"> print(&quot;总字数&quot;,len(training_data))</span><br><span class="line"> training_ci =fenci(training_data)</span><br><span class="line"> print(&quot;总词数&quot;,len(training_ci))    </span><br><span class="line"> training_label, count, dictionary, words = build_dataset(training_ci, </span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"> words_size = len(dictionary)</span><br><span class="line"> print(&quot;字典词数&quot;,words_size) </span><br><span class="line"> </span><br><span class="line"> print(&apos;Sample data&apos;, training_label[:10], [words[i] for i in training_</span><br><span class="line">label[:10]])</span><br></pre></td></tr></table></figure>

</details>

<p>build_dataset中的实现方式是将统计词频0号位置给unknown（用UNK表示），其余按照频次由高到低排列。unknown的获取按照预设词典大小，比如350，则频次排序靠后于350的都视为unknown。</p>
<p>运行代码，生成结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">总字数 1567</span><br><span class="line">总词数 961</span><br><span class="line">字典词数 350</span><br><span class="line">Sample data [263, 31, 38, 30, 27, 0, 10, 9, 104, 197] [&apos;阴阳&apos;, &apos;人体&apos;, &apos;与&apos;, &apos;电能&apos;, &apos;阴&apos;, &apos;UNK&apos;, &apos;是&apos;, &apos;身体&apos;, &apos;里&apos;, &apos;内在&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>程序显示整个文章的总字数为1567个，总词数为961个，建立好的字典词数为350。接下来是将文字里前10个词即对应的索引显示出来。</p>
<p>3．获取批次数据</p>
<p>定义generate_batch函数，取一定批次的样本数据。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"> data_index = 0</span><br><span class="line"> def generate_batch(data,batch_size, num_skips, skip_window):</span><br><span class="line"> </span><br><span class="line">   global data_index</span><br><span class="line">   assert batch_size % num_skips == 0</span><br><span class="line">   assert num_skips &lt;= 2 * skip_window</span><br><span class="line"> </span><br><span class="line">   batch = np.ndarray(shape=(batch_size), dtype=np.int32)</span><br><span class="line">   labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)</span><br><span class="line">   span = 2 * skip_window + 1   #每一个样本由前skip_window +当前target +后skip_window组成</span><br><span class="line">   buffer = collections.deque(maxlen=span)</span><br><span class="line"> </span><br><span class="line">   if data_index + span &gt; len(data):</span><br><span class="line">     data_index = 0</span><br><span class="line"> </span><br><span class="line">   buffer.extend(data[data_index:data_index + span])</span><br><span class="line">   data_index += span</span><br><span class="line"> </span><br><span class="line">   for i in range(batch_size // num_skips):</span><br><span class="line">     target = skip_window  # target 在buffer中的索引为skip_window</span><br><span class="line">     targets_to_avoid = [skip_window]</span><br><span class="line">     for j in range(num_skips):</span><br><span class="line">       while target in targets_to_avoid:</span><br><span class="line">         target = random.randint(0, span -1)</span><br><span class="line"> </span><br><span class="line">       targets_to_avoid.append(target)</span><br><span class="line">       batch[i * num_skips + j] = buffer[skip_window]</span><br><span class="line">       labels[i * num_skips + j, 0] = buffer[target]</span><br><span class="line"> </span><br><span class="line">     if data_index == len(data):</span><br><span class="line">       buffer = data[:span]</span><br><span class="line">       data_index = span</span><br><span class="line">     else:</span><br><span class="line">       buffer.append(data[data_index])</span><br><span class="line">       data_index += 1</span><br><span class="line"> </span><br><span class="line">   # 注意防止越界</span><br><span class="line">   data_index = (data_index + len(data) -span) % len(data)</span><br><span class="line">   return batch, labels</span><br><span class="line"> </span><br><span class="line"> batch, labels = generate_batch(training_label,batch_size=8, num_</span><br><span class="line">skips=2, skip_window=1)</span><br><span class="line"> </span><br><span class="line"> for i in range(8):# 先循环8次，然后将组合好的样本与标签打印出来</span><br><span class="line">   print(batch[i], words[batch[i]], &apos;-&gt;&apos;, labels[i, 0], words[labels[i, </span><br><span class="line">  0]])</span><br></pre></td></tr></table></figure>

</details>

<p>generate_batch函数中使用CBOW模型来构建样本，是从开始位置的一个一个字作为输入，然后将其前面和后面的字作为标签，再分别组合在一起变成2组数据。运行当前代码，输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">人体 -&gt; 38 与</span><br><span class="line">人体 -&gt; 263 阴阳</span><br><span class="line">与 -&gt; 31 人体</span><br><span class="line">与 -&gt; 30 电能</span><br><span class="line">电能 -&gt; 27 阴</span><br><span class="line">电能 -&gt; 38 与</span><br><span class="line">阴 -&gt; 0 UNK</span><br><span class="line">阴 -&gt; 30 电能</span><br></pre></td></tr></table></figure>

</details>

<p>如果是Skip-Gram方法，根据字取标签的方法正好相反，输出会变成以下这样：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 阴阳 -&gt; 31 人体</span><br><span class="line"> 与 -&gt; 31 人体</span><br><span class="line"> 人体 -&gt; 38 与</span><br><span class="line"> 人体 -&gt; 263 阴阳</span><br><span class="line"> 电能 -&gt; 38 与</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>4．定义取样参数</p>
<p>下面代码中每批次取128个，每个词向量的维度为128，前后取词窗口为1，num_skips表示一个input生成2个标签，nce中负采样的个数为num_sampled。接下来是验证模型的相关参数，valid_size表示在0-words_size/2中的数取随机不能重复的16个字来验证模型。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> batch_size = 128</span><br><span class="line"> embedding_size = 128   # embedding vector的维度</span><br><span class="line"> skip_window = 1         # 左右的词数量</span><br><span class="line"> num_skips = 2            # 一个input生成2个标签</span><br><span class="line"> </span><br><span class="line"> valid_size = 16        </span><br><span class="line"> valid_window = words_size/2   # 取样数据的分布范围</span><br><span class="line"> valid_examples = np.random.choice(valid_window, valid_size, replace=</span><br><span class="line">False)#0-words_size/2中的数取16个。不能重复</span><br><span class="line"> num_sampled = 64        # 负采样个数</span><br></pre></td></tr></table></figure>

</details>

<p>5．定义模型变量</p>
<p>初始化图，为输入、标签、验证数据定义占位符，定义词嵌入变量embeddings为每个字定义128维的向量，并初始化为-1～1之间的均匀分布随机数。tf.nn.embedding_lookup是将输入的train_inputs转成对应的128维向量embed，定义nce_loss要使用的nce_weights和nce_biases。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">train_inputs = tf.placeholder(tf.int32, shape=[batch_size])</span><br><span class="line">train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])</span><br><span class="line">valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line"># CPU上执行</span><br><span class="line">with tf.device(&apos;/cpu:0&apos;):</span><br><span class="line">    # 查找embeddings</span><br><span class="line">    embeddings = tf.Variable(tf.random_uniform([words_size, </span><br><span class="line">   embedding_size], -1.0, 1.0)) #94个字，每个128个向量</span><br><span class="line">    </span><br><span class="line">    embed = tf.nn.embedding_lookup(embeddings, train_inputs)</span><br><span class="line"></span><br><span class="line">    # 计算NCE的loss的值</span><br><span class="line">    nce_weights = tf.Variable( tf.truncated_normal([words_size, </span><br><span class="line">   embedding_size],</span><br><span class="line">                            stddev=1.0 / tf.sqrt(np.float32(embedding_</span><br><span class="line">                           size))))</span><br><span class="line">                            </span><br><span class="line">    nce_biases = tf.Variable(tf.zeros([words_size]))</span><br></pre></td></tr></table></figure>

</details>

<p>在反向传播中，embeddings会与权重一起被nce_loss代表的loss值所优化更新。</p>
<p>6．定义损失函数和优化器</p>
<p>使用nce_loss计算loss来保证softmax时的运算速度不被words_size过大问题所影响，在nce中每次会产生num_sampled（64）个负样本来参与概率运算。优化器使用学习率为1的GradientDescentOptimizer。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> loss = tf.reduce_mean(</span><br><span class="line"> tf.nn.nce_loss(weights=nce_weights, biases=nce_biases,</span><br><span class="line">                  labels=train_labels, inputs=embed,</span><br><span class="line">                  num_sampled=num_sampled, num_classes=words_size))</span><br><span class="line"> </span><br><span class="line"> # 梯度下降优化器</span><br><span class="line"> optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)</span><br><span class="line"> </span><br><span class="line"> # 计算minibatch examples 和所有 embeddings的 cosine 相似度</span><br><span class="line"> norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=</span><br><span class="line">  True))</span><br><span class="line"> normalized_embeddings = embeddings / norm</span><br><span class="line"> valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, </span><br><span class="line">valid_dataset)</span><br><span class="line"> similarity = tf.matmul(valid_embeddings, normalized_embeddings, </span><br><span class="line">transpose_b=True)</span><br></pre></td></tr></table></figure>

</details>

<p>验证数据取值时做了些特殊处理，将embeddings中每个词对应的向量进行平方和再开方得到norm，然后将embeddings与norm相除得到normalized_embeddings。当使用embedding_lookup获得自己对应normalized_embeddings中的向量valid_embeddings时，将该向量与转置后的normalized_embeddings相乘得到每个词的similarity。这个过程实现了一个向量间夹角余弦（Cosine）的计算。</p>
<p>7．夹角余弦介绍</p>
<p>为了能够读懂代码，有必要介绍下夹角余弦的概念。</p>
<p>余弦定理：给定三角形的三条边a、b、c，对应三个角为A、B、C，则角A的余弦见式（9-1）：</p>
<p><img src="Image00182.jpg" alt></p>
<p>如果将b和c看成两个向量，则上述式子等价于（见式9-2）：</p>
<p><img src="Image00183.jpg" alt></p>
<p>分母表示两个向量的长度，分子表示两个向量的内积。引申到二维空间中，向量A（x1，y1）与向量B（x2，y2）的夹角余弦公式见式（9-3）：</p>
<p><img src="Image00184.jpg" alt></p>
<p>再扩展到两个n维样本点，a（x11，x12，…，x1n）和b（x21，x22，…，x2n）的夹角余弦的公式见式（9-4）：</p>
<p><img src="Image00185.jpg" alt></p>
<p>这回可以理解前面的代码了，norm代表每一个词对应向量的长度矩阵，见式（9-5）：</p>
<p><img src="Image00186.jpg" alt></p>
<p>normalized_embeddings表示的意思是向量除以自己的模，即单位向量，它可以确定向量的方向。</p>
<p>很显然，similarity就是valid_dataset 中对应的单位向量valid_embeddings与整个词嵌入字典中单位向量的夹角余弦。</p>
<p>如图9-23所示，算了这么多夹角余弦的目的就是为了衡量两个n维向量间的相似程度。当cosθ为1时，表明夹角为0，即两个向量的方向完全一样。所以当cosθ的值越小，表明两个向量的方向越不一样，相似度越低。</p>
<p><img src="Image00187.jpg" alt></p>
<p>图9-23 词嵌入夹角余弦结构</p>
<p>8．启动session，训练模型</p>
<p>有了理论基础之后，对代码的模型应该好理解了，接下来启动session将模型训练出来。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">num_steps = 100001</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run( tf.global_variables_initializer() )</span><br><span class="line">    print(&apos;Initialized&apos;)</span><br><span class="line">    </span><br><span class="line">    average_loss = 0</span><br><span class="line">    for step in range(num_steps):</span><br><span class="line">        batch_inputs, batch_labels = generate_batch(training_label, </span><br><span class="line">       batch_size, num_skips, skip_window)</span><br><span class="line">        feed_dict = &#123;train_inputs: batch_inputs, train_labels: batch_</span><br><span class="line">       labels&#125;</span><br><span class="line"></span><br><span class="line">        _, loss_val = sess.run([optimizer, loss], feed_dict=feed_dict)</span><br><span class="line">        average_loss += loss_val</span><br><span class="line">        </span><br><span class="line">#通过打印测试可以看到，embed的值在逐渐被调节      </span><br><span class="line">        emv = sess.run(embed,feed_dict = &#123;train_inputs: [37,18]&#125;)</span><br><span class="line">        print(&quot;emv-------------------&quot;,emv[0])</span><br><span class="line"></span><br><span class="line">        if step % 2000 == 0:</span><br><span class="line">          if step &gt; 0:</span><br><span class="line">            average_loss /= 2000</span><br><span class="line">          # 平均loss</span><br><span class="line">          print(&apos;Average loss at step &apos;, step, &apos;: &apos;, average_loss)</span><br><span class="line">          average_loss = 0</span><br></pre></td></tr></table></figure>

</details>

<p>这里设置的迭代次数为10 0001次，每迭代2000次就输出一次loss值。</p>
<p>9．输入验证数据，显示效果</p>
<p>为了能够看到词向量的效果，添加如下代码，将验证数据输入模型中，找出与其相近的词。这里使用了一个argsort函数，是将数组中的值从小到大排列后，返回每个值对应的索引。在使用argsort函数之前，将sim取负，得到的就是从大到小排列的结果了。sim就是当前词与整个词典中每个词的夹角余弦，9.7.4节中讲过夹角余弦值最大则代表相似度越高。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">if step % 10000 == 0:</span><br><span class="line">  sim = similarity.eval(session=sess)</span><br><span class="line">  </span><br><span class="line">  for i in range(valid_size):</span><br><span class="line">    valid_word = words[valid_examples[i]]</span><br><span class="line">    </span><br><span class="line">    top_k = 8   # 取排名最靠前的8个词</span><br><span class="line">    nearest = (-sim[i, :]).argsort()[1:top_k + 1]   #argsort函数返回的是数组值从小到大的索引值</span><br><span class="line">    </span><br><span class="line">    log_str = &apos;Nearest to %s:&apos; % valid_word</span><br><span class="line">     </span><br><span class="line">    for k in range(top_k):</span><br><span class="line">      close_word = words[nearest[k]]</span><br><span class="line">      log_str = &apos;%s,%s&apos; % (log_str, close_word)</span><br><span class="line">    print(log_str)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Average loss at step  92000 :  2.52053320134</span><br><span class="line">Average loss at step  94000 :  2.51920971239</span><br><span class="line">Average loss at step  96000 :  2.51831436144</span><br><span class="line">Average loss at step  98000 :  2.54135515364</span><br><span class="line">Average loss at step  100000 :  2.51433812357</span><br><span class="line">Nearest to 或:,与,和,提升,比,大小,觉得,每次,为阳来</span><br><span class="line">Nearest to ，:,起来,保养,过程,分裂细胞,为什么,新,就是,感到</span><br><span class="line">Nearest to 相当于:,也,会,寿命,刺激,了,低电量,加速,在</span><br><span class="line">Nearest to 桩:,训练,来源,修道,糖,马步,睡觉,放空,第一</span><br><span class="line">Nearest to 衰退:,也,短时间,累,下来,觉得,假如,排量,的</span><br><span class="line">Nearest to 加速:,快速,跑,病变,也,输出,走,相当于,加大</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>由于样本量不大，所以结果并不精确。但是也可以看出，模型基本上按照近义词被归类了一些，如第一个的“或”，与其最近的词有“与”“和”，基本上与人类的理解差不多。</p>
<p>10．词向量可视化</p>
<p>接着继续编写代码，将词向量可视化。在可视化之前，将词典中的词嵌入向量转成单位向量（只有方向），然后将它们通过t-SNE降维映射到二维平面中显示。</p>
<p>代码9-26 word2vect（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">    final_embeddings = normalized_embeddings.eval()</span><br><span class="line"></span><br><span class="line">def plot_with_labels(low_dim_embs, labels, filename=&apos;tsne.png&apos;):</span><br><span class="line">    assert low_dim_embs.shape[0] &gt;= len(labels), &apos;More labels than </span><br><span class="line">   embeddings&apos;</span><br><span class="line">    plt.figure(figsize=(18, 18))  # in inches</span><br><span class="line">    for i, label in enumerate(labels):</span><br><span class="line">        x, y = low_dim_embs[i, :]</span><br><span class="line">        plt.scatter(x, y)</span><br><span class="line">        plt.annotate(label,xy=(x, y),xytext=(5, 2), textcoords=&apos;offset </span><br><span class="line">       points&apos;,</span><br><span class="line">                     ha=&apos;right&apos;,va=&apos;bottom&apos;)</span><br><span class="line">    plt.savefig(filename)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">  </span><br><span class="line">    tsne = TSNE(perplexity=30, n_components=2, init=&apos;pca&apos;, n_iter=5000)</span><br><span class="line">    plot_only = 80#输出100个词</span><br><span class="line">    low_dim_embs = tsne.fit_transform(final_embeddings[:plot_</span><br><span class="line">   only, :])</span><br><span class="line">    labels = [words[i] for i in range(plot_only)]</span><br><span class="line">      </span><br><span class="line">    plot_with_labels(low_dim_embs, labels)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码运行后，输出图片如图9-24所示。</p>
<p>从输出图片中可以看出模型对词意义的理解。距离越近的词，他们的意义越相似，如图中的“但”与“不同”。</p>
<p><img src="Image00188.jpg" alt></p>
<p>图9-24 词向量结果</p>
<h4 id="9-7-5-实例71：使用指定侯选采样本训练word2vec"><a href="#9-7-5-实例71：使用指定侯选采样本训练word2vec" class="headerlink" title="9.7.5 实例71：使用指定侯选采样本训练word2vec"></a>9.7.5 实例71：使用指定侯选采样本训练word2vec</h4><p>上面的例子使用了nce_loss中默认的候选采样方法，本例将其扩展成可以手动指定候选样本来计算loss。例子中，通过手动指定词频数据生成样本，然后再根据生成的样本计算loss。这么做虽然只是将前面的步骤换为手动执行，但该方法具有更强的通用性，使模型不仅适用于满足Zipfian分布的样本，对于其他分布的样本，只需要按照本方法配置指定分布的样本即可。具体步骤如下。</p>
<p>实例描述</p>
<p>准备一段文字作为训练的样本，对其使用CBOW模型计算得到word2vec，并将各个词的向量关系用图表示出来。其中，通过使用手动指定词频样本生成候选词的方法，来代替nce_loss中的默认选词方法。</p>
<p>1．修改字典处理部分，生成词频数据</p>
<p>词频数据是指，对应于字典里的顺序，每个词所出现的频率统计。该数据作为候选样本采样的依据，在代码里是list类型。修改代码“9-26 word2vect.py”文件，在build_dataset函数中添加生成词频数据vocab_freqs。</p>
<p>代码9-27 word2vect自定义候选采样</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> def build_dataset(words, n_words):</span><br><span class="line"> </span><br><span class="line">   &quot;&quot;&quot;建立数据集.&quot;&quot;&quot;</span><br><span class="line">   count = [[&apos;UNK&apos;, -1]]</span><br><span class="line">   count.extend(collections.Counter(words).most_common(n_words -1))</span><br><span class="line">   </span><br><span class="line">   dictionary = dict()</span><br><span class="line">   vocab_freqs = [] #定义词频数据list</span><br><span class="line">   for word, nvocab in count:</span><br><span class="line">     dictionary[word] = len(dictionary)</span><br><span class="line">     vocab_freqs.append(nvocab) # 加入字典里的每个词频</span><br><span class="line">   data = list()</span><br><span class="line">   unk_count = 0</span><br><span class="line">   for word in words:</span><br><span class="line">     if word in dictionary:</span><br><span class="line">       index = dictionary[word]</span><br><span class="line">     else:</span><br><span class="line">       index = 0  # dictionary[&apos;UNK&apos;]</span><br><span class="line">       unk_count += 1</span><br><span class="line">     data.append(index)</span><br><span class="line">   count[0][1] = unk_count</span><br><span class="line">   reversed_dictionary = dict(zip(dictionary.values(), dictionary.</span><br><span class="line">  keys()))</span><br><span class="line">   </span><br><span class="line">   return data, count, dictionary, reversed_dictionary,vocab_freqs</span><br><span class="line"> ……</span><br><span class="line"> #使用vocab_freqs接收词频数据的返回值</span><br><span class="line"> training_label, count, dictionary, words,vocab_freqs = build_dataset</span><br><span class="line">(training_ci, 350)</span><br></pre></td></tr></table></figure>

</details>

<p>2．通过词频数据进行候选样本采样</p>
<p>拿到词频数据后，将其放到自定义采样的函数fixed_unigram_candidate_sampler里生成指定数量的采样数据。这里需要注意的是，原有字典中的第一个词并不是词频最高的词，而是手动添加的一个UNK词（见代码05行），并且当时设置的出现次数为-1。由于词频序数需要从大到小排列，所以需要手动将其改为最大值。通过打印vocab_freqs的数据能够看到，最大的值是89，所以设置一个比89大的数即可，这里设置的是90。</p>
<p>代码9-27 word2vect自定义候选采样（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">     nce_weights = tf.Variable( tf.truncated_normal([words_size, </span><br><span class="line">    embedding_size],</span><br><span class="line">     stddev=1.0 / tf.sqrt(np.float32(embedding_size))))</span><br><span class="line">                            </span><br><span class="line">    nce_biases = tf.Variable(tf.zeros([words_size]))</span><br><span class="line">vocab_freqs[0] = 90 #将手动添加的第一个词UNK的词频改为最大</span><br><span class="line">            </span><br><span class="line">sampled = tf.nn.fixed_unigram_candidate_sampler(</span><br><span class="line">          true_classes=tf.cast(train_labels,tf.int64),</span><br><span class="line">          num_true=1,</span><br><span class="line">          num_sampled=num_sampled,</span><br><span class="line">          unique=True,</span><br><span class="line">          range_max=words_size,</span><br><span class="line">          unigrams=vocab_freqs)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 这里有个小技巧，如何知道fixed_unigram_ candidate_sampler的定义？需要为其填写哪些参数？这里有个方法，用鼠标双击该函数，使其为选中状态，然后右击该函数，在弹出的快捷菜单中选择Go to definition命令（如图9-25所示），即可跳转到该函数的定义。</p>
<p><img src="Image00189.jpg" alt></p>
<p>图9-25 查找函数定义</p>
<p>3．使用自己的采样计算softmax的loss</p>
<p>使用loss生成函数sampled_softmax_loss（当然也可以用nce_loss函数）来计算loss，不同的是，在设置最后一个参数时会传入上一步生成的样本。</p>
<p>代码9-27 word2vect自定义候选采样（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">loss = tf.reduce_mean(</span><br><span class="line">tf.nn.sampled_softmax_loss(weights=nce_weights, biases=nce_biases,</span><br><span class="line">                          labels=train_labels, inputs=embed,</span><br><span class="line">                num_sampled=num_sampled, num_classes=words_size,</span><br><span class="line">               sampled_values=sampled))</span><br></pre></td></tr></table></figure>

</details>

<p>4．运行生成结果</p>
<p>其他代码都不用改动，直接运行即可，得到的效果与实例70一样，这里不再赘述。</p>
<h4 id="9-7-6-练习题"><a href="#9-7-6-练习题" class="headerlink" title="9.7.6 练习题"></a>9.7.6 练习题</h4><p>（1）想一想：9.7.4节的例子，如果将nce_loss改写成sampled_softmax_loss会不会有效？为什么？</p>
<p>答案：有效，因为对于语言模型的每个结果的输出是唯一的，也就是只会有一个词，所以也符合单标签分类。</p>
<p>将如下代码替换nce_loss的调用（参考配套代码“9-28 word2vect -2.py”文件）：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean(</span><br><span class="line">tf.nn.sampled_softmax_loss(weights=nce_weights, biases=nce_biases,</span><br><span class="line">                          labels=train_labels, inputs=embed,</span><br><span class="line">                num_sampled=num_sampled, num_classes=words_size))</span><br></pre></td></tr></table></figure>

</details>

<p>（2）试着将9.7.5节中的例子改成按照训练数据中类别出现分布方法（9.7.3节有介绍）进行采样，看看有什么效果。</p>
<p>答案可参考随书代码“9-29 word2vect学习样本候选采样.py”文件。</p>
<h3 id="9-8-处理Seq2Seq任务"><a href="#9-8-处理Seq2Seq任务" class="headerlink" title="9.8 处理Seq2Seq任务"></a>9.8 处理Seq2Seq任务</h3><p>本节继续介绍RNN的使用场景，处理Seq2Seq任务。Seq2Seq任务，即从一个序列映射到另一个序列的任务。在生活中会有很多符合这样特性的例子：前面的语言模型、语音识别例子，都可以理解成一个Seq2Seq的例子，类似的应用还有机器翻译、词性标注、智能对话等。下面就来学一下Seq2Seq任务的处理方法。</p>
<h4 id="9-8-1-Seq2Seq任务介绍"><a href="#9-8-1-Seq2Seq任务介绍" class="headerlink" title="9.8.1 Seq2Seq任务介绍"></a>9.8.1 Seq2Seq任务介绍</h4><p>Seq2Seq（Sequence 2 Sequence）任务可以理解为，从一个Sequence做某些工作映射到（to）另外一个Sequence的任务，泛指一些Sequence到Sequence的映射问题。</p>
<p>Sequence可以理解为一个字符串序列，在给定一个字符串序列后，希望得到与之对应的另一个字符串序列（如翻译后的、语义上对应的）。Seq2Seq不关心输入和输出的序列是否长度对应。</p>
<p>Seq2Seq如果再细分，可以分成输入、输出序列不一一对应和一一对应两种。前面的语言模型就是一一对应的，类似的还有词性标注，可以用图9-26所示的网络结构来理解。如果给定的每个输入都会有对应的输出，这种情况使用简单的RNN模型就可以解决。而输入输出序列不对应时会比较复杂一些，除了像前面语音识别模型中双向RNN+TensorFlow中的ctc_loss组合的方式之外，还有一种相对比较主流的解决方法——Encoder-Decoder框架。</p>
<p><img src="Image00190.jpg" alt></p>
<p>图9-26 多对多RNN</p>
<h4 id="9-8-2-Encoder-Decoder框架"><a href="#9-8-2-Encoder-Decoder框架" class="headerlink" title="9.8.2 Encoder-Decoder框架"></a>9.8.2 Encoder-Decoder框架</h4><p>1．Encoder-Decoder框架介绍</p>
<p>Encoder-Decoder框架的工作机制是：先使用Encoder将输入编码映射到语义空间（通过Encoder网络生成的特征向量），得到一个固定维数的向量，这个向量就表示输入的语义；然后再使用Decoder将这个语义向量解码，获得所需要的输出。如果输出是文本，则Decoder通常就是语言模型。其内部结构如图9-27所示。</p>
<p><img src="Image00191.jpg" alt></p>
<p>图9-27 Encoder-Decoder结构</p>
<p>图9-27中Encoder-Decoder框架有两个输入：一个是x输入作为Encoder的输入，另一个是y输入作为Decoder输入，x和y依次按照各自的顺序传入网络。</p>
<p>可以看出在Seq2Seq的训练中，标签y既参与计算loss，又参与节点运算，而不是像前面学习的其他网络只用来做loss监督。在Encoder与Decoder之间的C节点就是码器Encoder输出的解码向量，将它作为解码Decoder中cell的初始状态，进行对输出的解码。</p>
<p>这种机制的优点如下：</p>
<p>·非常灵活，并不限制Encoder、Decoder使用何种神经网络，也不限制输入和输出的内容（例如image caption任务，输入是图像，输出是文本）。</p>
<p>·这是一个端到端（end-to-end）的过程，将语义理解和语言生成合在了一起，而不是分开处理。</p>
<p>2．TensorFlow中的Seq2Seq</p>
<p>在TensorFlow中有两套Seq2Seq的接口。一套是TensorFlow 1.0版本之前的旧接口。在tf.contrib.legacy_seq2seq下；另一套为TensorFlow 1.0版本之后推出的新接口，在tf.contrib.seq2seq下。</p>
<p>旧接口的功能相对简单，是静态展开的网络模型。而新接口的功能更加强大，使用的是动态展开的网络模型，并提供了训练和应用两种场景的Helper类封装。从使用角度来看，旧接口同样也是比较简单。而新接口会更加灵活，需要自己组建Encoder和Decoder并通过函数把它们手动连接起来。</p>
<p>为了便于理解，本书主要以旧接口中Seq2Seq框架来举例介绍。关于Seq2Seq的更多例子，及新接口的应用演示，可以参考如下网址中的实例：</p>
<p><a href="https://github.com/ematvey/tensorflow-seq2seq-tutorials" target="_blank" rel="noopener">https://github.com/ematvey/tensorflow-seq2seq-tutorials</a>  </p>
<p>旧接口中基本Seq2Seq函数的定义如下。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.contrib.legacy_seq2seq.basic_rnn_seq2seq(encoder_inputs,</span><br><span class="line">                               decoder_inputs,</span><br><span class="line">                               cell,</span><br><span class="line">                               dtype=dtypes.float32,</span><br><span class="line">                               scope=None)</span><br></pre></td></tr></table></figure>

</details>

<p>参数说明如下。</p>
<p>·encoder_inputs：一个形状为[batch_size x input_size]的list。</p>
<p>·decoder_inputs：同encoder_inputs。</p>
<p>·cell：定义的cell网络。</p>
<p>·dtype：encoder_inputs和decoder_inputs中的类型（默认是tf.float32）。</p>
<p>·返回值：outputs和state。outputs为 [batch_size，output_size]的张量；state为[batch_size，cell.state_size]；cell.state_size可以表示一个或者多个子cell的状态，视输入参数cell而定。</p>
<p>其函数的实现只有如下几行代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with variable_scope.variable_scope(scope or &quot;basic_rnn_seq2seq&quot;):</span><br><span class="line">   enc_cell = copy.deepcopy(cell)</span><br><span class="line">   _, enc_state = core_rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)</span><br><span class="line">   return rnn_decoder(decoder_inputs, enc_state, cell)</span><br></pre></td></tr></table></figure>

</details>

<p>现将传入的cell做一次深拷贝（deepcopy），用来当做Encoder的网络，将生成的结果和原来的cell再加上输入的decoder_inputs一起放到Decoder中，并输出生成结果。</p>
<p><img src="Image00014.jpg" alt> 注意： 在使用过程中，由于需要通过输入x来预测y，没有标签，这种情况就需要手动填充Decoder来代替训练时的标签。</p>
<h4 id="9-8-3-实例72：使用basic-rnn-seq2seq拟合曲线"><a href="#9-8-3-实例72：使用basic-rnn-seq2seq拟合曲线" class="headerlink" title="9.8.3 实例72：使用basic_rnn_seq2seq拟合曲线"></a>9.8.3 实例72：使用basic_rnn_seq2seq拟合曲线</h4><p>TensorFlow虽然对Seq2Seq的框架的封装只用一个函数就完成了。但是，Seq2Seq的这个函数用起来并不友好，跟我们以前使用的TensorFlow中的函数并不是一样，所以有必要通过例子来演示一下。本例中使用2层的GRU循环网络，每层有12个节点。编码器与解码器中使用同样的网络结构。</p>
<p>实例描述</p>
<p>通过sin与con进行叠加变形生成无规律的模拟曲线，使用Seq2Seq模式对其进行学习，拟合特征，从而达到可以预测下一时刻数据的效果。</p>
<p>该例子共分为以下几步。</p>
<p>1．定义模拟样本函数</p>
<p>本例中通过函数制作规则的曲线来验证网络模型；定义两个曲线sin和con，通过随机值将其变形偏移，将两个曲线叠加。具体代码如下。</p>
<p>代码9-30 基本Seq2Seq</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import math</span><br><span class="line">        </span><br><span class="line">import tensorflow as tf </span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt  </span><br><span class="line"></span><br><span class="line">def do_generate_x_y(isTrain, batch_size, seqlen):</span><br><span class="line">    batch_x = []</span><br><span class="line">    batch_y = []</span><br><span class="line">    for _ in range(batch_size):</span><br><span class="line">        offset_rand = random.random() * 2 * math.pi</span><br><span class="line">        freq_rand = (random.random() -0.5) / 1.5 * 15 + 0.5</span><br><span class="line">        amp_rand = random.random() + 0.1</span><br><span class="line"></span><br><span class="line">        sin_data = amp_rand * np.sin(np.linspace(</span><br><span class="line">            seqlen / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,</span><br><span class="line">            seqlen / 15.0 * freq_rand * 3.0 * math.pi + offset_rand, seqlen </span><br><span class="line">           * 2)  )</span><br><span class="line"></span><br><span class="line">        offset_rand = random.random() * 2 * math.pi</span><br><span class="line">        freq_rand = (random.random() -0.5) / 1.5 * 15 + 0.5</span><br><span class="line">        amp_rand = random.random() * 1.2</span><br><span class="line"></span><br><span class="line">        sig_data = amp_rand * np.cos(np.linspace(</span><br><span class="line">            seqlen / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,</span><br><span class="line">            seqlen / 15.0 * freq_rand * 3.0 * math.pi + offset_rand, seqlen </span><br><span class="line">           * 2)) + sin_data</span><br><span class="line"></span><br><span class="line">        batch_x.append(np.array([ sig_data[:seqlen] ]).T)</span><br><span class="line">        batch_y.append(np.array([ sig_data[seqlen:] ]).T)</span><br><span class="line"></span><br><span class="line">    # 当前shape: (batch_size, seq_length, output_dim)</span><br><span class="line">    batch_x = np.array(batch_x).transpose((1, 0, 2))</span><br><span class="line">    batch_y = np.array(batch_y).transpose((1, 0, 2))</span><br><span class="line">    # 转换后shape: (seq_length, batch_size, output_dim)</span><br><span class="line"></span><br><span class="line">    return batch_x, batch_y</span><br><span class="line"></span><br><span class="line">#生成15个连续序列，将con和sin随机偏移变化后的值叠加起来</span><br><span class="line">def generate_data(isTrain, batch_size):</span><br><span class="line">    seq_length =15</span><br><span class="line">    if isTrain :</span><br><span class="line">        return do_generate_x_y(isTrain, batch_size, seq_length=seq_</span><br><span class="line">       length)</span><br><span class="line">    else:</span><br><span class="line">        return do_generate_x_y(isTrain, batch_size, seq_length=seq_</span><br><span class="line">       length*2)</span><br></pre></td></tr></table></figure>

</details>

<p>将该曲线按照30个序列一组的样式组成训练用的样本。30个序列分成了两部分：一部分当成现在的序列batch_x，一部分当成将来的序列batch_y。</p>
<p>2．定义参数及网络结构</p>
<p>前面介绍过basic_rnn_seq2seq的输入是一个list，这与我们平时遇到过的模型不太一样，所以需要构建一个list，以方便传入basic_rnn_seq2seq中。</p>
<p>在代码中，定义3个list（encoder_input、expected_output、decode_input），按照时间序列的数量来循环创建占位符，并使用append方法放入到list中。</p>
<p>网络模型定义为2层的循环网络，每层12个GRUcell。用MultiRNNCell将cell定义好后与前面的list一起传入basic_rnn_seq2seq中。</p>
<p>生成的结果为dec_outputs，dec_outputs中为每个时刻有12个GRUcell的输出，所以还需要通过循环在每个时刻下加一个全连接层，将其转为输出维度output_dim（output_dim=1）的节点。</p>
<p>代码9-30 基本Seq2Seq（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"> sample_now, sample_f = generate_data(isTrain=True, batch_size=3)</span><br><span class="line"> print(&quot;training examples : &quot;)</span><br><span class="line"> print(sample_now.shape)</span><br><span class="line"> print(&quot;(seq_length, batch_size, output_dim)&quot;)</span><br><span class="line"> </span><br><span class="line"> seq_length = sample_now.shape[0]</span><br><span class="line"> batch_size = 10</span><br><span class="line"> </span><br><span class="line"> output_dim = input_dim = sample_now.shape[-1]</span><br><span class="line"> hidden_dim = 12  </span><br><span class="line"> layers_stacked_count = 2</span><br><span class="line"> </span><br><span class="line"> # 学习率</span><br><span class="line"> learning_rate =0.04</span><br><span class="line"> nb_iters = 100</span><br><span class="line"> </span><br><span class="line"> lambda_l2_reg = 0.003                        # L2 正则参数</span><br><span class="line">         </span><br><span class="line"> tf.reset_default_graph()</span><br><span class="line"> </span><br><span class="line"> encoder_input = []</span><br><span class="line"> expected_output = []</span><br><span class="line"> decode_input =[]</span><br><span class="line"> for i in range(seq_length):</span><br><span class="line">     encoder_input.append( tf.placeholder(tf.float32, shape=( None, </span><br><span class="line">    input_dim)) )</span><br><span class="line">     expected_output.append( tf.placeholder(tf.float32, shape=( None, </span><br><span class="line">    output_dim)) )</span><br><span class="line">     decode_input.append( tf.placeholder(tf.float32, shape=( None, </span><br><span class="line">    input_dim)) )</span><br><span class="line">     </span><br><span class="line"> tcells = []</span><br><span class="line"> for i in range(layers_stacked_count):</span><br><span class="line">     tcells.append(tf.contrib.rnn.GRUCell(hidden_dim))</span><br><span class="line"> Mcell = tf.contrib.rnn.MultiRNNCell(tcells)</span><br><span class="line"> </span><br><span class="line"> dec_outputs, dec_memory</span><br><span class="line">tf.contrib.legacy_seq2seq.basic_rnn_seq2seq</span><br><span class="line">(encoder_input,decode_input,Mcell)</span><br><span class="line"> </span><br><span class="line"> reshaped_outputs = []</span><br><span class="line"> for ii in dec_outputs :</span><br><span class="line">     reshaped_outputs.append( tf.contrib.layers.fully_connected(ii,</span><br><span class="line">    output_</span><br><span class="line">dim,activation_fn=None))</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义loss函数及优化器</p>
<p>为了防止过拟合，对basic_rnn_seq2seq循环网络中的参数使用了l2_loss正则，由于最后一个全连接只是起到转化作用，就忽略不做l2_loss正则了（也可以加上，效果没有影响）。L2的调节因子设为0.003，学习率设为0.04。</p>
<p>代码9-30 基本Seq2Seq（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#计算L2的loss值 </span><br><span class="line">output_loss = 0</span><br><span class="line">for _y, _Y in zip(reshaped_outputs, expected_output):</span><br><span class="line">    output_loss += tf.reduce_mean( tf.pow(_y -_Y, 2) )</span><br><span class="line">   </span><br><span class="line"># 求正则化loss值</span><br><span class="line">reg_loss = 0</span><br><span class="line">for tf_var in tf.trainable_variables():</span><br><span class="line">    if not (&quot;fully_connected&quot; in tf_var.name ):</span><br><span class="line">        </span><br><span class="line">        reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))</span><br><span class="line"></span><br><span class="line">loss = output_loss + lambda_l2_reg * reg_loss</span><br><span class="line">train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)</span><br></pre></td></tr></table></figure>

</details>

<p>预测结果与真实结果的平方差再加上l2的loss值，作为输出的loss值。优化器同样使用AdamOptimizer。</p>
<p>4．启用session开始训练</p>
<p>在session中将训练和测试单独封装成了两个函数。在train_batch函数里先取指定批次的数据，通过循环来填充到encoder_input和expected_output列表里。</p>
<p>代码9-30 基本Seq2Seq（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"> sess = tf.InteractiveSession()</span><br><span class="line">         </span><br><span class="line"> def train_batch(batch_size):</span><br><span class="line"> </span><br><span class="line">     X, Y = generate_data(isTrain=True, batch_size=batch_size)</span><br><span class="line">     feed_dict = &#123;encoder_input[t]: X[t] for t in range(len(encoder_</span><br><span class="line">    input))&#125;</span><br><span class="line">     feed_dict.update(&#123;expected_output[t]: Y[t] for t in range(len</span><br><span class="line">    (expected_output))&#125;)</span><br><span class="line"> </span><br><span class="line">     c =np.concatenate(( [np.zeros_like(Y[0])],Y[:-1]),axis = 0)</span><br><span class="line"> </span><br><span class="line">     feed_dict.update(&#123;decode_input[t]: c[t] for t in range(len(c))&#125;)</span><br><span class="line"> </span><br><span class="line">     _, loss_t = sess.run([train_op, loss], feed_dict)</span><br><span class="line">     return loss_t</span><br><span class="line"> </span><br><span class="line"> def test_batch(batch_size):</span><br><span class="line">     X, Y = generate_data(isTrain=True, batch_size=batch_size)</span><br><span class="line">     feed_dict = &#123;encoder_input[t]: X[t] for t in range(len(encoder_</span><br><span class="line">    input))&#125;</span><br><span class="line">     feed_dict.update(&#123;expected_output[t]: Y[t] for t in range(len</span><br><span class="line">    (expected_output))&#125;)</span><br><span class="line">     c =np.concatenate(( [np.zeros_like(Y[0])],Y[:-1]),axis = 0) #来预测最后一个序列</span><br><span class="line">     feed_dict.update(&#123;decode_input[t]: c[t] for t in range(len(c))&#125;)    </span><br><span class="line">     output_lossv,reg_lossv,loss_t = sess.run([output_loss,reg_loss,</span><br><span class="line">    loss], feed_dict)</span><br><span class="line">     print(&quot;-----------------&quot;)    </span><br><span class="line">     print(output_lossv,reg_lossv)</span><br><span class="line">     return loss_t</span><br><span class="line"> </span><br><span class="line"> # 训练</span><br><span class="line"> train_losses = []</span><br><span class="line"> test_losses = []</span><br><span class="line"> </span><br><span class="line"> sess.run(tf.global_variables_initializer())</span><br><span class="line"> for t in range(nb_iters + 1):</span><br><span class="line">     train_loss = train_batch(batch_size)</span><br><span class="line">     train_losses.append(train_loss)</span><br><span class="line">     if t % 50 == 0:</span><br><span class="line">         test_loss = test_batch(batch_size)</span><br><span class="line">         test_losses.append(test_loss)</span><br><span class="line">         print(&quot;Step &#123;&#125;/&#123;&#125;, train loss: &#123;&#125;, \tTEST loss: &#123;&#125;&quot;.format</span><br><span class="line">        (t,nb_iters, train_loss, test_loss))</span><br><span class="line"> print(&quot;Fin. train loss: &#123;&#125;, \tTEST loss: &#123;&#125;&quot;.format(train_loss, </span><br><span class="line">test_loss))</span><br><span class="line">     </span><br><span class="line"> # 输出loss图例</span><br><span class="line"> plt.figure(figsize=(12, 6))</span><br><span class="line"> plt.plot(np.array(range(0, len(test_losses))) /</span><br><span class="line">     float(len(test_losses) -1) * (len(train_losses) -1),</span><br><span class="line">     np.log(test_losses),label=&quot;Test loss&quot;)</span><br><span class="line">     </span><br><span class="line"> plt.plot(np.log(train_losses),label=&quot;Train loss&quot;)</span><br><span class="line"> plt.title(&quot;Training errors over time (on a logarithmic scale)&quot;)</span><br><span class="line"> plt.xlabel(&apos;Iteration&apos;)</span><br><span class="line"> plt.ylabel(&apos;log(Loss)&apos;)</span><br><span class="line"> plt.legend(loc=&apos;best&apos;)</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>对于decode_input的输入要重点说明一下，将其第一个序列的输入变为0，作为起始输入的标记，接上后续的Y数据（未来序列）作为解码器部分的Decoder来输入。由于第一个序列被占用了，保证总长度不变的情况下，Y的最后一个序列没有作为Decoder的输入。但是输出时会有关于未来序列预测的全部序列值，并在计算loss时与真实值Y进行平方差。</p>
<p>最终将loss值通过plot打印出来，生成结果如下，loss结果曲线如图9-28所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">training examples : </span><br><span class="line">(15, 3, 1)</span><br><span class="line">(seq_length, batch_size, output_dim)</span><br><span class="line">-----------------</span><br><span class="line">7.66522 113.373</span><br><span class="line">Step 0/100,train loss: 8.341724395751953,   TEST loss:8.005338668823242</span><br><span class="line">-----------------</span><br><span class="line">1.11881 99.788</span><br><span class="line">Step 50/100,train loss:2.0858113765716553,   TEST loss:1.418175220489502</span><br><span class="line">-----------------</span><br><span class="line">0.618375 83.6507</span><br><span class="line">Step 100/100,train loss:0.9577032327651978,   TEST loss:0.8693273067474365</span><br><span class="line">Fin. train loss:0.9577032327651978,    TEST loss:0.8693273067474365</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00192.jpg" alt></p>
<p>图9-28 loss结果曲线</p>
<p>5．准备可视化数据</p>
<p>一般情况下，将整个输出值进行显示即可。但这里考虑到要配合使用时的演示，因此我们需要模型来预测未来序列，即没有decode_input的输入。前面说了，这种情况可以将decode_input全设为0，但其识别效果不客观。为了模型可用，可以将预测值范围稍加改变，只预测之后一次时间序列的值。例如，知道前面的所有序列，预测当天股票的收盘价格、开盘价格等。这也是非常实际的应用。</p>
<p>于是在可视化部分，取时间序列2倍的样本，前一倍用于输入模型，会产生最后一天的预测值，同时也将后一倍的数据显示出来，用于比对每个序列的预测值。</p>
<p>代码9-30 基本Seq2Seq（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 测试</span><br><span class="line">nb_predictions = 4</span><br><span class="line">print(&quot;visualize &#123;&#125; predictions data:&quot;.format(nb_predictions))</span><br><span class="line"></span><br><span class="line">preout =[]</span><br><span class="line">X, Y = generate_data(isTrain=False, batch_size=nb_predictions)</span><br><span class="line">print(np.shape(X),np.shape(Y))</span><br><span class="line">for tt in  range(seq_length):</span><br><span class="line">    feed_dict = &#123;encoder_input[t]: X[t+tt] for t in range(seq_length)&#125;</span><br><span class="line">    feed_dict.update(&#123;expected_output[t]: Y[t+tt] for t in range</span><br><span class="line">   (len(expected_output))&#125;)</span><br><span class="line">    c =np.concatenate(( [np.zeros_like(Y[0])],Y[tt:seq_length+tt-1]),</span><br><span class="line">   axis = 0)   #从前15个序列的最后一个开始预测  </span><br><span class="line"></span><br><span class="line">    feed_dict.update(&#123;decode_input[t]: c[t] for t in range(len(c))&#125;)</span><br><span class="line">    outputs = np.array(sess.run([reshaped_outputs], feed_dict)[0])</span><br><span class="line">    preout.append(outputs[-1])</span><br><span class="line"></span><br><span class="line">print(np.shape(preout)) #将每个未知预测值收集起来准备显示出来</span><br><span class="line">preout =np.reshape(preout,[seq_length,nb_predictions,output_dim])</span><br></pre></td></tr></table></figure>

</details>

<p>前15次时间序列用于输入，后15次循环来使用模型预测，每次都将输出的最后一个时间序列收集起来，最终得到15个时间序列批次的预测结果preout。</p>
<p>6．画图显示数据</p>
<p>将批次设为4，随机取4个序列片段，每个片段的15个序列预测以图像形式显示出来。</p>
<p>代码9-30 基本Seq2Seq（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">for j in range(nb_predictions):</span><br><span class="line">    plt.figure(figsize=(12, 3))</span><br><span class="line"></span><br><span class="line">    for k in range(output_dim):</span><br><span class="line">        past = X[:, j, k]</span><br><span class="line">        expected = Y[seq_length-1:, j, k] #对应预测值的打印</span><br><span class="line"></span><br><span class="line">        pred = preout[:, j, k]</span><br><span class="line"></span><br><span class="line">        label1 = &quot;past&quot; if k == 0 else &quot;_nolegend_&quot;</span><br><span class="line">        label2 = &quot;future&quot; if k == 0 else &quot;_nolegend_&quot;</span><br><span class="line">        label3 = &quot;Pred&quot; if k == 0 else &quot;_nolegend_&quot;</span><br><span class="line">        plt.plot(range(len(past)), past, &quot;o--b&quot;, label=label1)</span><br><span class="line">        plt.plot(range(len(past), len(expected) + len(past)),</span><br><span class="line">                 expected, &quot;x--b&quot;, label=label2)</span><br><span class="line">        plt.plot(range(len(past), len(pred) + len(past)),</span><br><span class="line">                 pred, &quot;o--y&quot;, label=label3)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=&apos;best&apos;)</span><br><span class="line">    plt.title(&quot;Predictions vs. future&quot;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>为了跟真实的序列值比较，这里将真实的序列值也从15个序列开始打印出来，index=14的值即为预测的第一个值。运行上面的代码，结果如图9-29所示。</p>
<p><img src="Image00193.jpg" alt></p>
<p>图9-29 基于Seg2Seg实例结果</p>
<p><img src="Image00194.jpg" alt></p>
<p>图9-29 基于Seg2Seg实例结果（续）</p>
<p>可以看到，生成的预测数据与真实数据相差并不大。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里使用了feed_dict的update方法来处理复杂的feed_dict的情况，通过Update可以在原有的feed_dict中加入新的feed数据，将一行语句变为多行输入。</p>
<h4 id="9-8-4-实例73：预测当天的股票价格"><a href="#9-8-4-实例73：预测当天的股票价格" class="headerlink" title="9.8.4 实例73：预测当天的股票价格"></a>9.8.4 实例73：预测当天的股票价格</h4><p>既然前面我们用预测股票来打比方，那么这里就演示一个预测股票的例子。直接修改实例72中的数据源即可。</p>
<p>实例描述</p>
<p>使用Seq2Seq模式对某个股票数据的训练学习，拟合特征，从而达到可以预测第二天股票价格的效果。</p>
<p>1．准备数据</p>
<p>需要准备一个股票的数据，本例中的格式是CSV，也可使用本书的配套例子中的数据“600000.csv”（笔者只是随意爬取了A股中的第一个股票，没有其他特殊意义），本书配套代码中提供了一个爬虫代码文件，见代码“9-31 STOCKDATA.py”文件。</p>
<p>2．导入股票数据</p>
<p>直接在“9-30：基本seq2seq.py”文件基础上修改代码，添加载入股票函数loadstock，里面使用了pandas，所以要将该库导入进去。实例中将close收盘价格载入内存用于做样本生成。当然读者也可以自行修改字段，可以将开盘价、最高价格和最低价格等都载入内存作为样本数据，只需将对应的列名放入predictor_names数组中即可。</p>
<p>代码9-32 seq2seqstock</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"> import pandas as pd</span><br><span class="line"> pd.options.mode.chained_assignment = None  # default=&apos;warn&apos;</span><br><span class="line"> def loadstock(window_size):</span><br><span class="line">     names = [&apos;date&apos;,</span><br><span class="line">          &apos;code&apos;,</span><br><span class="line">          &apos;name&apos;,</span><br><span class="line">          &apos;Close&apos;,</span><br><span class="line">          &apos;top_price&apos;,</span><br><span class="line">          &apos;low_price&apos;,</span><br><span class="line">          &apos;opening_price&apos;,</span><br><span class="line">          &apos;bef_price&apos;,</span><br><span class="line">          &apos;floor_price&apos;,</span><br><span class="line">          &apos;floor&apos;,</span><br><span class="line">          &apos;exchange&apos;,</span><br><span class="line">          &apos;Volume&apos;,</span><br><span class="line">          &apos;amount&apos;,</span><br><span class="line">          &apos;总市值&apos;,</span><br><span class="line">          &apos;流通市值&apos;]</span><br><span class="line">     data = pd.read_csv(&apos;600000.csv&apos;, names=names, header=None,encoding</span><br><span class="line">  = &quot;gbk&quot;)</span><br><span class="line">     </span><br><span class="line">     predictor_names = [&quot;Close&quot;]</span><br><span class="line">     training_features = np.asarray(data[predictor_names], dtype = </span><br><span class="line">    &quot;float32&quot;)</span><br><span class="line">     kept_values = training_features[1000:]</span><br><span class="line"> </span><br><span class="line">     X = []</span><br><span class="line">     Y = []</span><br><span class="line">     for i in range(len(kept_values) -window_size * 2):</span><br><span class="line">#  x为前window_size个序列，y为后window_size一个序列</span><br><span class="line">         X.append(kept_values[i:i + window_size])</span><br><span class="line">         Y.append(kept_values[i + window_size:i + window_size * 2])</span><br><span class="line"> </span><br><span class="line">     X = np.reshape(X,[-1,window_size,len(predictor_names)])</span><br><span class="line">     Y = np.reshape(Y,[-1,window_size,len(predictor_names)])</span><br><span class="line">     print(np.shape(X))</span><br><span class="line"> </span><br><span class="line">     return X, Y</span><br></pre></td></tr></table></figure>

</details>

<p>3．生成样本</p>
<p>直接修改代码中生成样本的函数generate_data，和其对应的内部调用的do_generate_ x_y函数，代码如下。</p>
<p>代码9-32 seq2seqstock（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">def generate_data(isTrain, batch_size):        </span><br><span class="line">    # 用前40个样本来预测后40个样本</span><br><span class="line">    </span><br><span class="line">    seq_length = 40   </span><br><span class="line">    seq_length_test = 80</span><br><span class="line"></span><br><span class="line">    global Y_train</span><br><span class="line">    global X_train</span><br><span class="line">    global X_test</span><br><span class="line">    global Y_test</span><br><span class="line">    # 载入内存</span><br><span class="line">    if len(Y_train) == 0:       </span><br><span class="line">        X, Y= loadstock( window_size=seq_length)</span><br><span class="line"></span><br><span class="line">        # Split 80-20:</span><br><span class="line">        X_train = X[:int(len(X) * 0.8)]</span><br><span class="line">        Y_train = Y[:int(len(Y) * 0.8)]</span><br><span class="line"></span><br><span class="line">    if len(Y_test) == 0:</span><br><span class="line">        X, Y  = loadstock( window_size=seq_length_test)</span><br><span class="line"></span><br><span class="line">        # Split 80-20:</span><br><span class="line">        X_test = X[int(len(X) * 0.8):]</span><br><span class="line">        Y_test = Y[int(len(Y) * 0.8):]</span><br><span class="line"></span><br><span class="line">    if isTrain:</span><br><span class="line">        return do_generate_x_y(X_train, Y_train, batch_size)</span><br><span class="line">    else:</span><br><span class="line">        return do_generate_x_y(X_test,  Y_test,  batch_size)</span><br><span class="line"></span><br><span class="line">def do_generate_x_y(X, Y, batch_size):</span><br><span class="line">    assert X.shape == Y.shape, (X.shape, Y.shape)</span><br><span class="line">    idxes = np.random.randint(X.shape[0], size=batch_size)</span><br><span class="line">    X_out = np.array(X[idxes]).transpose((1, 0, 2))</span><br><span class="line">    Y_out = np.array(Y[idxes]).transpose((1, 0, 2))</span><br><span class="line">    return X_out, Y_out</span><br></pre></td></tr></table></figure>

</details>

<p>4．运行程序查看效果</p>
<p>由于股票数据没有固定的规则而言，并且数据量又较大，所以加大batch到100，加大迭代次数到100000，代码片段如下。</p>
<p>代码9-32 seq2seqstock（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">seq_length = sample_now.shape[0]</span><br><span class="line">batch_size = 100</span><br><span class="line"></span><br><span class="line">output_dim = input_dim = sample_now.shape[-1]</span><br><span class="line">hidden_dim = 12  </span><br><span class="line">layers_num = 2</span><br><span class="line"></span><br><span class="line"># 学习率</span><br><span class="line">learning_rate =0.04</span><br><span class="line">nb_iters = 100000</span><br><span class="line">lambda_l2_reg = 0.003 # L2 regularization of weights -avoids overfitting</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>其他地方均不用变，直接运行代码即可，输出如图9-30所示。</p>
<p><img src="Image00195.jpg" alt></p>
<p>图9-30 股票示例结果</p>
<p><img src="Image00196.jpg" alt></p>
<p>图9-30 股票示例结果（续）</p>
<p>可见损失值还是比较高的，中间有两次还出现了飙升，由于没有对数据进行清洗和修正，所以会看到序列中有突然变为0的情况，这是由于或许当天是停牌或者数据缺失等情况照成的。恰好我们可以把它当成噪声数据来泛化网络。图9-30中序列80～120之间的点（即图中灰色的点）代表预测的结果，X代表真实的结果，可以看到，虽然不是很精确，但是总体还是与真实数据很接近的。在真实使用场景中，可以修改显示部分的测试代码，不用随机取样本数据，而是把最后一段时间序列取出来并放到模型里，输出的最后一个预测值即是当天的收盘价预测。</p>
<p><img src="Image00014.jpg" alt> 提示： 股市有风险，用机器炒股也要谨慎。这里演示的只是一个模型，其精确度和拟合度还有待提高，并不能当作炒股指导工具。</p>
<p>通过两个例子的练习，希望读者可以掌握Seq2Seq的基本使用。其实，这种简单的Seq2Seq框架在实际应用中对超长序列数据的学习效果并不是很好。这是因为无论输入端有多大变化，Encoder给出的都是一个固定维数的向量，存在信息损失，所以输入的序列越长，Encoder的输出丢失的原始信息就越多，传入Decoder后，很难在Decoder中有太多的特征表现。</p>
<p>对于这个问题，引出了下面的基于注意力的Seq2Seq。</p>
<h4 id="9-8-5-基于注意力的Seq2Seq"><a href="#9-8-5-基于注意力的Seq2Seq" class="headerlink" title="9.8.5 基于注意力的Seq2Seq"></a>9.8.5 基于注意力的Seq2Seq</h4><p>本节就来介绍一下这个基于注意力的Seq2Seq网络。</p>
<p>1．attention_seq2seq介绍</p>
<p>注意力机制，即在生成每个词时，对不同的输入词给予不同的关注权重。如图9-31所示，右侧序列是输入序列，上方序列是输出序列。在注意力机制下，对于一个输出网络会自动学习与其对应的输入关系的权重。如How下面一列。</p>
<p><img src="Image00197.jpg" alt></p>
<p>图9-31 注意力表现</p>
<p>在训练过程中，模型会通过注意力机制把某个输出对应的所有输入列出来，学习其关系并更新到权重上。如图9-31所示，“you”下面那一列（80、5、0、15、0），就是模型在生成you这个词时的概率分布，对应列的表格中值最大的地方对应的是输入的“你”（对应图中第1行第4列，值为80），说明模型在生成you这个词时最为关注的输入词是“你”。这样在预测时，该机制就会根据输入及其权重反向推出更有可能的预测值了。</p>
<p>注意力机制是在原有Seq2Seq中的Encoder与Decoder框架中修改而来，具体结构如图9-32所示。</p>
<p>修改后的模型特点是序列中每个时刻Encoder生成的c，都将要参与Decoder中解码的各个时刻，而不是只参与初始时刻。当然对于生成的结果节点c，参与到Decoder的每个序列运算都会经过权重w，那么这个w就可以以loss的方式通过优化器来调节了，最终会逐渐逼近与它紧密的那个词，这就是注意力的原理。添加入了Attention注意力分配机制后，使得Decoder在生成新的Target Sequence时，能得到之前Encoder编码阶段每个字符的隐藏层的信息向量Hidden State，使得新生成序列的准确度提高。</p>
<p><img src="Image00198.jpg" alt></p>
<p>图9-32 Seq2Seq attention</p>
<p>2．TensorFlow中的attention_seq2seq</p>
<p>在TensorFlow中也有关于带有注意力机制的Seq2Seq定义，封装后的Seq2Seq与前面basic_rnn_seq2seq差不多，具体函数如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tf.contrib.legacy_seq2seq.embedding_attention_seq2seq (encoder_inputs,</span><br><span class="line">                                decoder_inputs,</span><br><span class="line">                                cell,</span><br><span class="line">                                num_encoder_symbols,</span><br><span class="line">                                num_decoder_symbols,</span><br><span class="line">                                embedding_size,</span><br><span class="line">                                num_heads=1,</span><br><span class="line">                                output_projection=None,</span><br><span class="line">                                feed_previous=False,</span><br><span class="line">                                dtype=None,</span><br><span class="line">                                scope=None,</span><br><span class="line">                                initial_state_attention=False):</span><br></pre></td></tr></table></figure>

</details>

<p>参数说明如下。</p>
<p>·encoder_inputs：一个形状为[batch_size]的list。</p>
<p>·decoder_inputs：同encoder_inputs。</p>
<p>·cell：定义的cell网络。</p>
<p>·num_encoder_symbols：输入数据对应的词总个数。</p>
<p>·num_decoder_symbols：输出数据对应的词的总个数。</p>
<p>·embedding_size：每个输入对应的词向量编码大小。</p>
<p>·num_heads：从注意力状态里读取的个数。</p>
<p>·output_projection：对输出结果是否进行全连接的维度转化，如果需要转化，则传入全连接对应的w和b。</p>
<p>·feed_previous：为True时，表明只有第一个Decoder输入以Go开始，其他都使用前面的状态。如果为False时，每个Decoder的输入都会以Go开始。Go为自己定义模型时定义的一个起始符，一般用0或1来指定。</p>
<p>3．Seq2Seq中桶（bucket）的实现机制</p>
<p>在Seq2Seq模型中，由于输入、输出都是可变长的，这就给计算带来了很大的效率影响。在TensorFlow中使用了一个“桶”（bucket）的观念来权衡这个问题，思想就是初始化几个bucket，对数据预处理，按照每个序列的长短，将其放到不同的bucket中，小于bucket size部分统一补0来完成对齐的工作，之后就可以进行不同bucket的批处理计算了。</p>
<p>由于该问题与Seq2Seq模型关联比较紧密，在TensorFlow中就将其封装成整体的框架模式，开发者只需要将输入、输出、网络模型传入函数中，其他的都交给函数自己来处理，大大简化了开发过程，其定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model_with_buckets(encoder_inputs,</span><br><span class="line">                       decoder_inputs,</span><br><span class="line">                       targets,</span><br><span class="line">                       weights,</span><br><span class="line">                       buckets,</span><br><span class="line">                       seq2seq,</span><br><span class="line">                       softmax_loss_function=None,</span><br><span class="line">                       per_example_loss=False,</span><br><span class="line">                       name=None):</span><br></pre></td></tr></table></figure>

</details>

<p>参数说明如下。</p>
<p>·encoder_inputs：一个形状为[batch_size]的list。</p>
<p>·decoder_inputs：同encoder_inputs，作为解码器部分的输入。</p>
<p>·targets：最终输出结果的label。</p>
<p>·weights：传入的权重值，必须与decoder_inputs的size相同。</p>
<p>·buckets：传入的桶，描述为[（xx，xx），（xx，xx）…]每一对有两个数，第一个数为输入的size，第二个数为输出的size。</p>
<p>·seq2seq：带有Seq2Seq结构的网络，以函数名的方式传入。在Seq2Seq里可以载入定义的cell网络。</p>
<p>·softmax_loss_function：是否使用自己指定的loss函数。</p>
<p>·per_example_loss：是否对每个样本求loss。</p>
<p>这里面有疑问的部分就是weights，为什么会多了个weights？它是做什么的呢？跟进代码里可以看到，它会调用sequence_loss_by_example函数，在sequence_loss_by_example函数中weights是用来做loss计算的。具体见tensorflow\contrib\legacy_seq2seq\python\ops seq2seq.py文件中第1048行函数sequence_loss_by_example的实现，代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">with ops.name_scope(name, &quot;sequence_loss_by_example&quot;,</span><br><span class="line">                      logits + targets + weights):</span><br><span class="line">    log_perp_list = []</span><br><span class="line">    for logit, target, weight in zip(logits, targets, weights):</span><br><span class="line">      if softmax_loss_function is None:</span><br><span class="line">        # TODO(irving,ebrevdo):为了符合调用sequence_loss_by_example时的需要，需要对张量进行reshape</span><br><span class="line">        target = array_ops.reshape(target, [-1])</span><br><span class="line">        crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">            labels=target, logits=logit)</span><br><span class="line">      else:</span><br><span class="line">        crossent = softmax_loss_function(labels=target, logits=logit)</span><br><span class="line">      log_perp_list.append(crossent * weight)</span><br><span class="line">    log_perps = math_ops.add_n(log_perp_list)</span><br><span class="line">    if average_across_timesteps:</span><br><span class="line">      total_size = math_ops.add_n(weights)</span><br><span class="line">      total_size += 1e-12   # 避免除数为0</span><br><span class="line">      log_perps /= total_size</span><br><span class="line">  return log_perps</span><br></pre></td></tr></table></figure>

</details>

<p>可见在求每个样本loss时对softmax_loss的结果乘了weight，同时又将乘完weight后的总和结果除以weights的总和（log_perps<br>/= total_size）。这种做法就是叫做基于权重的交叉熵计算（weighted cross_entropy loss）（具体细节不再展开，读者简单了解即可）。</p>
<h4 id="9-8-6-实例74：基于Seq2Seq注意力模型实现中英文机器翻译"><a href="#9-8-6-实例74：基于Seq2Seq注意力模型实现中英文机器翻译" class="headerlink" title="9.8.6 实例74：基于Seq2Seq注意力模型实现中英文机器翻译"></a>9.8.6 实例74：基于Seq2Seq注意力模型实现中英文机器翻译</h4><p>本例中将使用前面介绍的函数，将它们组合在一起实现一个具有机器翻译功能的例。该例中共涉及4个代码文件，各文件说明如下。</p>
<p>·文件“9-33 datautil.py”：样本预处理文件。</p>
<p>·文件“9-34 seq2seq_model.py”：模型文件，该文件是在GitHub上TensorFlow的例子基础上修改而来。</p>
<p>·文件“9-35 train.py”：模型的训练文件。</p>
<p>·文件“9-36 test.py”：模型的测试使用文件。</p>
<p>本例同样也是先从样本入手，然后搭建模型、训练、测试，具体步骤如下。</p>
<p>实例描述</p>
<p>准备一部分中英对照的翻译语料，使用Seq2Seq模式对其进行学习，拟合特征，从而实现机器翻译。</p>
<p>1．样本准备</p>
<p>对于样本的准备，本书配套资源中提供了一个“中英文平行语料库.rar”文件，如果读者需要更多、更全的样本，需要自己准备。解压后有两个文件，一个是英文文件，一个是对应的中文文件。</p>
<p>如果想与本书同步路径，可以将英文文件放到代码同级文件夹fanyichina\yuliao\from下；中文文件放在代码同级文件夹fanyichina\yuliao\to下。</p>
<p>2．生成中、英文字典</p>
<p>编写代码，分别载入两个文件，并生成正反向字典。</p>
<p><img src="Image00014.jpg" alt> 注意： 样本的编码是UTF-8，如果读者使用自己定义的样本，不是UTF-8编码，则在读取文件时会报错，需要改成正确的编码。如果是Windows编辑的样本，编码为GB2312。</p>
<p>代码9-33 datautil</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"> data_dir = &quot;fanyichina/&quot;</span><br><span class="line"> raw_data_dir = &quot;fanyichina/yuliao/from&quot;</span><br><span class="line"> raw_data_dir_to = &quot;fanyichina/yuliao/to&quot;</span><br><span class="line"> vocabulary_fileen =&quot;dicten.txt&quot;</span><br><span class="line"> vocabulary_filech = &quot;dictch.txt&quot;</span><br><span class="line"> </span><br><span class="line"> plot_histograms = plot_scatter =True</span><br><span class="line"> vocab_size =40000</span><br><span class="line"> </span><br><span class="line"> max_num_lines =1</span><br><span class="line"> max_target_size = 200</span><br><span class="line"> max_source_size = 200</span><br><span class="line"> </span><br><span class="line"> def main():</span><br><span class="line">     vocabulary_filenameen = os.path.join(data_dir, vocabulary_fileen)</span><br><span class="line">     vocabulary_filenamech = os.path.join(data_dir, vocabulary_filech)</span><br><span class="line"> ##############################</span><br><span class="line"> #  创建英文字典</span><br><span class="line">     training_dataen, counten, dictionaryen, reverse_dictionaryen,</span><br><span class="line">    textsszen =create_vocabulary(vocabulary_filenameen</span><br><span class="line">                                                        ,raw_data_dir,vocab_</span><br><span class="line">size,Isch=False,normalize_digits = True)</span><br><span class="line">     print(&quot;training_data&quot;,len(training_dataen))</span><br><span class="line">     print(&quot;dictionary&quot;,len(dictionaryen)) </span><br><span class="line"> #########################</span><br><span class="line">     #创建中文字典    </span><br><span class="line">     training_datach, countch, dictionarych, reverse_dictionarych,</span><br><span class="line">    textsszch =create_vocabulary(vocabulary_filenamech</span><br><span class="line">                                                     ,raw_data_dir_to,vocab_</span><br><span class="line">    size,Isch=True,normalize_digits = True)</span><br><span class="line">     print(&quot;training_datach&quot;,len(training_datach))</span><br><span class="line">     print(&quot;dictionarych&quot;,len(dictionarych))</span><br></pre></td></tr></table></figure>

</details>

<p>执行完上面的代码后，会在当前目录下的fanyichina文件夹里找到dicten.txt与dictch.txt两个字典文件。</p>
<p>其中所调用的部分代码定义如下，严格来讲本例中生成的应该是词点，因为在中文处理中用了jieba分词库将文字分开了，是以词为单位存储对应索引的。</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"> import jieba</span><br><span class="line"> jieba.load_userdict(&quot;myjiebadict.txt&quot;)</span><br><span class="line"> </span><br><span class="line"> def fenci(training_data):</span><br><span class="line">     seg_list = jieba.cut(training_data)         # 默认是精确模式</span><br><span class="line">     training_ci = &quot; &quot;.join(seg_list)</span><br><span class="line">     training_ci = training_ci.split()</span><br><span class="line">     return training_ci</span><br><span class="line"> </span><br><span class="line"> import collections</span><br><span class="line"> #系统字符，创建字典时需要加入</span><br><span class="line"> _PAD = &quot;_PAD&quot;</span><br><span class="line"> _GO = &quot;_GO&quot;</span><br><span class="line"> _EOS = &quot;_EOS&quot;</span><br><span class="line"> _UNK = &quot;_UNK&quot;</span><br><span class="line"> </span><br><span class="line"> PAD_ID = 0</span><br><span class="line"> GO_ID = 1</span><br><span class="line"> EOS_ID = 2</span><br><span class="line"> UNK_ID = 3</span><br><span class="line"> </span><br><span class="line"> #文字字符替换，不属于系统字符</span><br><span class="line"> _NUM = &quot;_NUM&quot;</span><br><span class="line"> #Isch=true 中文，</span><br><span class="line"></span><br><span class="line">false 英文</span><br><span class="line">  #创建词典，max_vocabulary_size=500代表字典中有500个词  </span><br><span class="line"> def create_vocabulary(vocabulary_file, raw_data_dir, max_vocabulary_</span><br><span class="line">size,Isch=True, normalize_digits=True):</span><br><span class="line">     texts,textssz = get_ch_path_text(raw_data_dir,Isch,normalize_</span><br><span class="line">    digits)</span><br><span class="line">     print( texts[0],len(texts)) </span><br><span class="line">     print(&quot;行数&quot;,len(textssz),textssz)</span><br><span class="line"> # 处理多行文本texts </span><br><span class="line">     all_words = []  </span><br><span class="line">     for label in texts:  </span><br><span class="line">         print(&quot;词数&quot;,len(label))   </span><br><span class="line">         all_words += [word for word in label]     </span><br><span class="line">     print(&quot;词数&quot;,len(all_words))</span><br><span class="line">     </span><br><span class="line">     training_label, count, dictionary, reverse_dictionary = build_</span><br><span class="line">    dataset(all_words,max_vocabulary_size)</span><br><span class="line">     print(&quot;reverse_dictionary&quot;,reverse_dictionary,len(reverse_</span><br><span class="line">      dictionary))</span><br><span class="line">     if not gfile.Exists(vocabulary_file):</span><br><span class="line">         print(&quot;Creating vocabulary %s from data %s&quot; % (vocabulary_file, </span><br><span class="line">        data_dir))</span><br><span class="line">         if len(reverse_dictionary) &gt; max_vocabulary_size:</span><br><span class="line">             reverse_dictionary = reverse_dictionary[:max_vocabulary_</span><br><span class="line">            size]</span><br><span class="line">         with gfile.GFile(vocabulary_file, mode=&quot;w&quot;) as vocab_file:</span><br><span class="line">             for w in reverse_dictionary:</span><br><span class="line">                 print(reverse_dictionary[w])</span><br><span class="line">                 vocab_file.write(reverse_dictionary[w] + &quot;\n&quot;)</span><br><span class="line">     else:</span><br><span class="line">         print(&quot;already have vocabulary!  do nothing !!!!!!!!!!!!!!!!!</span><br><span class="line">        !!!!!!!!!!!!&quot;)</span><br><span class="line">     return training_label, count, dictionary, reverse_dictionary,</span><br><span class="line">    textssz</span><br><span class="line"> </span><br><span class="line"> def build_dataset(words, n_words):</span><br><span class="line">   &quot;&quot;&quot;Process raw inputs into a dataset.&quot;&quot;&quot;</span><br><span class="line">   count = [[_PAD, -1],[_GO, -1],[_EOS, -1],[_UNK, -1]]</span><br><span class="line">   count.extend(collections.Counter(words).most_common(n_words -1))</span><br><span class="line">   dictionary = dict()</span><br><span class="line">   for word, _ in count:</span><br><span class="line">     dictionary[word] = len(dictionary)</span><br><span class="line">   data = list()</span><br><span class="line">   unk_count = 0</span><br><span class="line">   for word in words:</span><br><span class="line">     if word in dictionary:</span><br><span class="line">       index = dictionary[word]</span><br><span class="line">     else:</span><br><span class="line">       index = 0  # dictionary[&apos;UNK&apos;]</span><br><span class="line">       unk_count += 1</span><br><span class="line">     data.append(index)</span><br><span class="line">   count[0][1] = unk_count</span><br><span class="line">   reversed_dictionary = dict(zip(dictionary.values(), dictionary.</span><br><span class="line">  keys()))</span><br><span class="line">   return data, count, dictionary, reversed_dictionary</span><br></pre></td></tr></table></figure>

</details>

<p>在字典中添加额外的字符标记PAD、_GO、_EOS、_UNK是为了在训练模型时起到辅助标记的作用。</p>
<p>·PAD用于在桶机制中为了对齐填充占位。</p>
<p>·_GO是解码输入时的开头标志位。</p>
<p>·_EOS是用来标记输出结果的结尾。</p>
<p>·_UNK用来代替处理样本时出现字典中没有的字符。</p>
<p>另外还有_NUM，用来代替文件中的数字（_NUM是根据处理的内容可选项，如果内容与数字高度相关，就不能用NUM来代替）。</p>
<p>在jieba的分词库中，附加一个字典文件myjiebadict.txt，以免自定义的字符标记被分开。myjiebadict.txt里的内容如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_NUM nz</span><br><span class="line">_PAD nz</span><br><span class="line">_GO nz</span><br><span class="line">_EOS nz</span><br><span class="line">_UNK nz</span><br></pre></td></tr></table></figure>

</details>

<p>每一行有两项，用空格分开，第一项为指定的字符，第二项nz代表不能被分开的意思。</p>
<p>3．将数据转成索引格式</p>
<p>原始的中英文是无法让机器认知的，所以要根据字典中对应词的索引对原始文件进行相应的转化，方便读取。在本地建立两个文件夹fanyichina\fromids和fanyichina\toids，用于存放生成的ids文件。在main函数中编写以下代码，先通过initialize_vocabulary将前面生成的字典读入内存中，然后使用textdir_to_idsdir函数将文本转成ids文件。</p>
<p>textdir_to_idsdir函数中最后的两个参数说明如下。</p>
<p>·normalize_digits：代表是否将数字替换掉。</p>
<p>·Isch：表示是否是按中文方式处理。</p>
<p>中文方式会在处理过程中对读入的文本进行一次jieba分词。</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">   ……</span><br><span class="line">      vocaben, rev_vocaben =initialize_vocabulary(vocabulary_</span><br><span class="line">         filenameen)</span><br><span class="line">      vocabch, rev_vocabch =initialize_vocabulary(vocabulary_</span><br><span class="line">         filenamech)</span><br><span class="line">  </span><br><span class="line">      print(len(rev_vocaben))</span><br><span class="line">      textdir_to_idsdir(raw_data_dir,data_dir+&quot;fromids/&quot;,vocaben,</span><br><span class="line">         normalize_digits=True,Isch=False)</span><br><span class="line">      textdir_to_idsdir(raw_data_dir_to,data_dir+&quot;toids/&quot;,vocabch,</span><br><span class="line">         normalize_digits=True,Isch=True)</span><br></pre></td></tr></table></figure>

</details>

<p>所使用的函数定义如下：</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> def initialize_vocabulary(vocabulary_path):</span><br><span class="line">   if gfile.Exists(vocabulary_path):</span><br><span class="line">     rev_vocab = []</span><br><span class="line">     with gfile.GFile(vocabulary_path, mode=&quot;r&quot;) as f:</span><br><span class="line">       rev_vocab.extend(f.readlines())</span><br><span class="line">     rev_vocab = [line.strip() for line in rev_vocab]</span><br><span class="line">     vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])</span><br><span class="line">     return vocab, rev_vocab</span><br><span class="line">   else:</span><br><span class="line">     raise ValueError(&quot;Vocabulary file %s not found.&quot;, vocabulary_path)</span><br><span class="line"> #将文件批量转成ids文件</span><br><span class="line"> def textdir_to_idsdir(textdir,idsdir,vocab, normalize_digits=True,</span><br><span class="line">Isch=True):</span><br><span class="line">     text_files,filenames = getRawFileList(textdir)</span><br><span class="line">     </span><br><span class="line">     if len(text_files)== 0:</span><br><span class="line">         raise ValueError(&quot;err:no files in &quot;,raw_data_dir)</span><br><span class="line">         </span><br><span class="line">     print(len(text_files),&quot;files,one is&quot;,text_files[0])</span><br><span class="line">     </span><br><span class="line">     for text_file,name in zip(text_files,filenames):</span><br><span class="line">         print(text_file,idsdir+name)</span><br><span class="line">         textfile_to_idsfile(text_file,idsdir+name,vocab, normalize_</span><br><span class="line">          digits,Isch)</span><br></pre></td></tr></table></figure>

</details>

<p>其他用到的底层函数代码如下：</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">#获取文件列表</span><br><span class="line">def getRawFileList( path):</span><br><span class="line">    files = []</span><br><span class="line">    names = []</span><br><span class="line">    for f in os.listdir(path):</span><br><span class="line">        if not f.endswith(&quot;~&quot;) or not f == &quot;&quot;:</span><br><span class="line">            files.append(os.path.join(path, f))</span><br><span class="line">            names.append(f)</span><br><span class="line">    return files,names</span><br><span class="line">#读取分词后的中文词</span><br><span class="line">def get_ch_lable(txt_file,Isch=True,normalize_digits=False):  </span><br><span class="line">    labels= list()#&quot;&quot;</span><br><span class="line">    labelssz = []</span><br><span class="line">    with open(txt_file, &apos;rb&apos;) as f:</span><br><span class="line">        for label in f: </span><br><span class="line">            linstr1 =label.decode(&apos;utf-8&apos;)</span><br><span class="line">            if normalize_digits :</span><br><span class="line">                linstr1=re.sub(&apos;\d+&apos;,_NUM,linstr1)</span><br><span class="line">            notoken = basic_tokenizer(linstr1 )</span><br><span class="line">            if Isch:</span><br><span class="line">                notoken = fenci(notoken)</span><br><span class="line">            else:</span><br><span class="line">                notoken = notoken.split()</span><br><span class="line"></span><br><span class="line">            labels.extend(notoken)</span><br><span class="line">            labelssz.append(len(labels))</span><br><span class="line">    return  labels,labelssz</span><br><span class="line">   </span><br><span class="line">#获取文件中的文本</span><br><span class="line">def get_ch_path_text(raw_data_dir,Isch=True,normalize_digits=False):</span><br><span class="line">    text_files,_ = getRawFileList(raw_data_dir)</span><br><span class="line">    labels = []</span><br><span class="line">    </span><br><span class="line">    training_dataszs = list([0])</span><br><span class="line">    </span><br><span class="line">    if len(text_files)== 0:</span><br><span class="line">        print(&quot;err:no files in &quot;,raw_data_dir)</span><br><span class="line">        return labels</span><br><span class="line">    print(len(text_files),&quot;files,one is&quot;,text_files[0])</span><br><span class="line">    shuffle(text_files)</span><br><span class="line">    </span><br><span class="line">    for text_file in text_files:</span><br><span class="line">        training_data,training_datasz =get_ch_lable(text_file,Isch,</span><br><span class="line">           normalize_digits)</span><br><span class="line">        </span><br><span class="line">        training_ci = np.array(training_data)</span><br><span class="line">        training_ci = np.reshape(training_ci, [-1, ])</span><br><span class="line">        labels.append(training_ci)</span><br><span class="line">        </span><br><span class="line">        training_datasz =np.array( training_datasz)+training_dataszs[-1]</span><br><span class="line">        training_dataszs.extend(list(training_datasz))</span><br><span class="line">        print(&quot;here&quot;,training_dataszs)</span><br><span class="line">    return labels,training_dataszs</span><br><span class="line">       </span><br><span class="line">def basic_tokenizer(sentence):    </span><br><span class="line">    _WORD_SPLIT = &quot;([.,!?\&quot;&apos;:;)(])&quot;</span><br><span class="line">    _CHWORD_SPLIT = &apos;、|。|，|‘|’&apos;</span><br><span class="line">    str1 = &quot;&quot;</span><br><span class="line">    for i in re.split(_CHWORD_SPLIT,  sentence):</span><br><span class="line">        str1 = str1 +i</span><br><span class="line">    str2 = &quot;&quot;</span><br><span class="line">    for i in re.split(_WORD_SPLIT ,  str1):</span><br><span class="line">        str2 = str2 +i</span><br><span class="line">    return str2</span><br><span class="line">#将句子转成索引ids</span><br><span class="line">def sentence_to_ids(sentence, vocabulary,</span><br><span class="line">                           normalize_digits=True,Isch=True):</span><br><span class="line"></span><br><span class="line">    if normalize_digits :</span><br><span class="line">        sentence=re.sub(&apos;\d+&apos;,_NUM,sentence)</span><br><span class="line">    notoken = basic_tokenizer(sentence )</span><br><span class="line">    if Isch:</span><br><span class="line">        notoken = fenci(notoken)</span><br><span class="line">    else:</span><br><span class="line">        notoken = notoken.split()</span><br><span class="line">  </span><br><span class="line">    idsdata = [vocabulary.get( w, UNK_ID) for w in notoken]</span><br><span class="line">  </span><br><span class="line">    return idsdata</span><br><span class="line"></span><br><span class="line">#将文件中的内容转成ids，不是Windows下的文件要使用utf8编码格式</span><br><span class="line">def textfile_to_idsfile(data_file_name, target_file_name, vocab,</span><br><span class="line">                       normalize_digits=True,Isch=True):</span><br><span class="line">  </span><br><span class="line">  if not gfile.Exists(target_file_name):</span><br><span class="line">    print(&quot;Tokenizing data in %s&quot; % data_file_name)</span><br><span class="line">    with gfile.GFile(data_file_name, mode=&quot;rb&quot;) as data_file:</span><br><span class="line">      with gfile.GFile(target_file_name, mode=&quot;w&quot;) as ids_file:</span><br><span class="line">        counter = 0</span><br><span class="line">        for line in data_file:</span><br><span class="line">          counter += 1</span><br><span class="line">          if counter % 100000 == 0:</span><br><span class="line">            print(&quot;  tokenizing line %d&quot; % counter)</span><br><span class="line">          token_ids = sentence_to_ids(line.decode(&apos;utf8&apos;), vocab,</span><br><span class="line">         normalize_digits,Isch)</span><br><span class="line">          ids_file.write(&quot; &quot;.join([str(tok) for tok in token_ids]) + </span><br><span class="line">         &quot;\n&quot;)</span><br><span class="line">def ids2texts( indices,rev_vocab):</span><br><span class="line">    texts = []</span><br><span class="line">    for index in indices:</span><br><span class="line">        </span><br><span class="line">        texts.append(rev_vocab[index])</span><br><span class="line">    return texts</span><br></pre></td></tr></table></figure>

</details>

<p>运行上述代码后，可以在本地路径fanyichina\fromids、fanyichina\toids文件夹下面找到同名的txt文件，打开后能够看到里面全是索引值。</p>
<p>4．对样本文件进行分析图示</p>
<p>为了使bucket的设置机制较合理，我们把样本的数据用图示方式显示出来，直观地看一下每个样本的各个行长度分布情况，在main函数中接着添加以下代码：</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">……</span><br><span class="line">#分析样本分布</span><br><span class="line">    filesfrom,_=getRawFileList(data_dir+&quot;fromids/&quot;)</span><br><span class="line">    filesto,_=getRawFileList(data_dir+&quot;toids/&quot;)</span><br><span class="line">    source_train_file_path = filesfrom[0]</span><br><span class="line">    target_train_file_path= filesto[0]    </span><br><span class="line">    analysisfile(source_train_file_path,target_train_file_path)</span><br><span class="line">    </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

</details>

<p>最后两行为启动main函数。analysisfile为文件的分析函数，实现如下：</p>
<p>代码9-33 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"> def analysisfile(source_file,target_file):</span><br><span class="line"> #分析文本    </span><br><span class="line">     source_lengths = []</span><br><span class="line">     target_lengths = []</span><br><span class="line"> </span><br><span class="line">     with gfile.GFile(source_file, mode=&quot;r&quot;) as s_file:</span><br><span class="line">         with gfile.GFile(target_file, mode=&quot;r&quot;) as t_file:</span><br><span class="line">             source= s_file.readline()</span><br><span class="line">             target = t_file.readline()</span><br><span class="line">             counter = 0</span><br><span class="line">             </span><br><span class="line">             while source and target:</span><br><span class="line">                 counter += 1</span><br><span class="line">                 if counter % 100000 == 0:</span><br><span class="line">                     print(&quot;  reading data line %d&quot; % counter)</span><br><span class="line">                     sys.stdout.flush()</span><br><span class="line">                 num_source_ids = len(source.split())</span><br><span class="line">                 source_lengths.append(num_source_ids)</span><br><span class="line">                 num_target_ids = len(target.split()) + 1#plus 1 for EOS </span><br><span class="line">                token</span><br><span class="line">                 target_lengths.append(num_target_ids)</span><br><span class="line">                 source, target = s_file.readline(), t_file.readline()</span><br><span class="line">     print(target_lengths,source_lengths)</span><br><span class="line">     if plot_histograms:</span><br><span class="line">         plot_histo_lengths(&quot;target lengths&quot;, target_lengths)</span><br><span class="line">         plot_histo_lengths(&quot;source_lengths&quot;, source_lengths)</span><br><span class="line">     if plot_scatter:</span><br><span class="line">         plot_scatter_lengths(&quot;target vs source length&quot;, &quot;source </span><br><span class="line">        length&quot;,&quot;target length&quot;, source_lengths, target_lengths)</span><br><span class="line"> def plot_scatter_lengths(title, x_title, y_title, x_lengths, y_</span><br><span class="line">lengths):</span><br><span class="line"> plt.scatter(x_lengths, y_lengths)</span><br><span class="line"> plt.title(title)</span><br><span class="line"> plt.xlabel(x_title)</span><br><span class="line"> plt.ylabel(y_title)</span><br><span class="line"> plt.ylim(0, max(y_lengths))</span><br><span class="line"> plt.xlim(0,max(x_lengths))</span><br><span class="line"> plt.show()</span><br><span class="line"> </span><br><span class="line"> def plot_histo_lengths(title, lengths):</span><br><span class="line"> mu = np.std(lengths)</span><br><span class="line"> sigma = np.mean(lengths)</span><br><span class="line"> x = np.array(lengths)</span><br><span class="line"> n, bins, patches = plt.hist(x,  50, facecolor=&apos;green&apos;, alpha=0.5)</span><br><span class="line"> y = mlab.normpdf(bins, mu, sigma)</span><br><span class="line"> plt.plot(bins, y, &apos;r--&apos;)</span><br><span class="line"> plt.title(title)</span><br><span class="line"> plt.xlabel(&quot;Length&quot;)</span><br><span class="line"> plt.ylabel(&quot;Number of Sequences&quot;)</span><br><span class="line"> plt.xlim(0,max(lengths))</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，得到如图9-33所示结果。</p>
<p><img src="Image00199.jpg" alt></p>
<p>图9-33 样本分析</p>
<p>从图9-33可知，样本的长度都在60之间，可以将bucket分为4个区间，即_buckets =[（20，20），（40，40），（50，50），（60，60）]。由于输入和输出的长度差别不大，所以令它们的bucket相等。这部分还有更好的方法：可以使用聚类方式处理，然后自动化生成bucket，这样会更加方便，有兴趣的读者可以自己尝试一下。</p>
<p><img src="Image00014.jpg" alt> 说明： 网络模型初始化的部分，放到了后面讲解（见代码“9-34 seg2seg_model.py”文件），是想让读者先对整个流程有个大致了解。</p>
<p>5．载入字典准备训练</p>
<p>预处理结束后，就可以开始编写训练代码了，在代码“9-35 train.py”文件里将刚才生成的字典载入，在getfanyiInfo中通过datautil.initialize_vocabulary将字典读入本地。同时引入库，设置初始参数，网络结构为两层，每层100个GRUcell组成的网络，在Seq2Seq模型中解码器与编码器同为相同的这种结构。</p>
<p>代码9-35 train</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import math</span><br><span class="line">import sys</span><br><span class="line">import time</span><br><span class="line">import numpy as np</span><br><span class="line">from six.moves import xrange</span><br><span class="line">import tensorflow as tf</span><br><span class="line">datautil = __import__(&quot;9-33  datautil&quot;)</span><br><span class="line">seq2seq_model = __import__(&quot;9-34  seq2seq_model&quot;)</span><br><span class="line">import datautil</span><br><span class="line">import seq2seq_model</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">steps_per_checkpoint=200 </span><br><span class="line"></span><br><span class="line">max_train_data_size= 0 #(0代表输入数据的长度没有限制)</span><br><span class="line"></span><br><span class="line">dropout = 0.9 </span><br><span class="line">grad_clip = 5.0</span><br><span class="line">batch_size = 60</span><br><span class="line"></span><br><span class="line">num_layers =2</span><br><span class="line">learning_rate =0.5</span><br><span class="line">lr_decay_factor =0.99</span><br><span class="line"></span><br><span class="line">#设置翻译模型相关参数</span><br><span class="line">hidden_size = 100</span><br><span class="line">checkpoint_dir= &quot;fanyichina/checkpoints/&quot;</span><br><span class="line">_buckets =[(20, 20), (40, 40), (50, 50), (60, 60)]</span><br><span class="line">def getfanyiInfo():</span><br><span class="line">    vocaben, rev_vocaben=datautil.initialize_vocabulary(os.path.join</span><br><span class="line">   (datautil.data_dir, datautil.vocabulary_fileen))</span><br><span class="line">    vocab_sizeen= len(vocaben)</span><br><span class="line">    print(&quot;vocab_size&quot;,vocab_sizeen)</span><br><span class="line">    </span><br><span class="line">    vocabch, rev_vocabch=datautil.initialize_vocabulary(os.path.join</span><br><span class="line">   (datautil.data_dir, datautil.vocabulary_filech))</span><br><span class="line">    vocab_sizech= len(vocabch)</span><br><span class="line">    print(&quot;vocab_sizech&quot;,vocab_sizech) </span><br><span class="line">    </span><br><span class="line">    filesfrom,_=datautil.getRawFileList(datautil.data_dir+&quot;fromids/&quot;)</span><br><span class="line">    filesto,_=datautil.getRawFileList(datautil.data_dir+&quot;toids/&quot;)</span><br><span class="line">    source_train_file_path = filesfrom[0]</span><br><span class="line">    target_train_file_path= filesto[0]</span><br><span class="line">    return vocab_sizeen,vocab_sizech,rev_vocaben,rev_vocabch,source_</span><br><span class="line">   train_file_path,target_train_file_path</span><br><span class="line">    </span><br><span class="line">def main():</span><br><span class="line">    vocab_sizeen,vocab_sizech,rev_vocaben,rev_vocabch,source_train_</span><br><span class="line">   file_path,target_train_file_path = getfanyiInfo()</span><br></pre></td></tr></table></figure>

</details>

<p>通过getfanyiInfo函数得到中英词的数量、反向的中英字典、输入样本文件的路径以及目标样本的路径。</p>
<p>6．启动session，创建模型并读取样本数据</p>
<p>代码9-35 train（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">if not os.path.exists(checkpoint_dir):</span><br><span class="line">    os.mkdir(checkpoint_dir)</span><br><span class="line">print (&quot;checkpoint_dir is &#123;0&#125;&quot;.format(checkpoint_dir))</span><br><span class="line">     </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    model = createModel(sess,False,vocab_sizeen,vocab_sizech)</span><br><span class="line">    print (&quot;Using bucket sizes:&quot;)</span><br><span class="line">    print (_buckets)</span><br><span class="line">     </span><br><span class="line">    source_test_file_path = source_train_file_path</span><br><span class="line">    target_test_file_path = target_train_file_path</span><br><span class="line">    </span><br><span class="line">    print (source_train_file_path)</span><br><span class="line">    print (target_train_file_path)</span><br><span class="line">    </span><br><span class="line">    train_set = readData(source_train_file_path, target_train_</span><br><span class="line">   file_path,max_train_data_size)</span><br><span class="line">    test_set = readData(source_test_file_path, target_test_file_</span><br><span class="line">   path,max_train_data_size)</span><br><span class="line">    </span><br><span class="line">    train_bucket_sizes = [len(train_set[b]) for b in xrange(len</span><br><span class="line">   (_buckets))]</span><br><span class="line">    print( &quot;bucket sizes = &#123;0&#125;&quot;.format(train_bucket_sizes))</span><br><span class="line">    train_total_size = float(sum(train_bucket_sizes))</span><br><span class="line"></span><br><span class="line">    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_</span><br><span class="line">   total_size for i in xrange(len(train_bucket_sizes))]</span><br><span class="line">    step_time, loss = 0.0, 0.0</span><br><span class="line">    current_step = 0</span><br><span class="line">    previous_losses = []</span><br></pre></td></tr></table></figure>

</details>

<p>由于样本不足，这里直接在测试与训练中使用相同的样本，仅仅是为了演示。通过createModel创建模型，并查找检查点文件是否存在，如果存在，则将检测点载入。在createModel 中通过调用Seq2SeqModel类生成模型，并指定模型中的具体初始参数。</p>
<p>代码9-35 train（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"> def createModel(session, forward_only,from_vocab_size,to_vocab_</span><br><span class="line">size):</span><br><span class="line">     model = seq2seq_model.Seq2SeqModel(</span><br><span class="line">       from_vocab_size,#from</span><br><span class="line">       to_vocab_size,#to</span><br><span class="line">       _buckets,</span><br><span class="line">       hidden_size,</span><br><span class="line">       num_layers,</span><br><span class="line">       dropout,</span><br><span class="line">       grad_clip,</span><br><span class="line">       batch_size,</span><br><span class="line">       learning_rate,</span><br><span class="line">       lr_decay_factor,</span><br><span class="line">       forward_only=forward_only,</span><br><span class="line">       dtype=tf.float32)</span><br><span class="line">       </span><br><span class="line">     print(&quot;model is ok&quot;)</span><br><span class="line">     </span><br><span class="line">     ckpt = tf.train.latest_checkpoint(checkpoint_dir)</span><br><span class="line">     if ckpt!=None:</span><br><span class="line">         model.saver.restore(session, ckpt)</span><br><span class="line">         print (&quot;Reading model parameters from &#123;0&#125;&quot;.format(ckpt))</span><br><span class="line">     else:</span><br><span class="line">         print (&quot;Created model with fresh parameters.&quot;)</span><br><span class="line">         session.run(tf.global_variables_initializer())  </span><br><span class="line"> </span><br><span class="line">     return model</span><br></pre></td></tr></table></figure>

</details>

<p>通过latest_checkpoint发现检查点文件。如果有检查点文件，就将其恢复到session中。</p>
<p>读取文件的函数定义如下：为了适用带有bucket机制的网络模型，按照bucket的大小序列读取数据，先按照bucket的个数定义好数据集data_set，然后在读取每一对输入、输出时，都会比较其适合哪个bucket，并将其放入对应的bucket中，最后返回data_set。</p>
<p>代码9-35 train（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> def readData(source_path, target_path, max_size=None):</span><br><span class="line"> &apos;&apos;&apos;</span><br><span class="line"> 这个方法来自于tensorflow 中的translation 例子</span><br><span class="line"> &apos;&apos;&apos;</span><br><span class="line"> data_set = [[] for _ in _buckets]</span><br><span class="line"> with tf.gfile.GFile(source_path, mode=&quot;r&quot;) as source_file:</span><br><span class="line"> with tf.gfile.GFile(target_path, mode=&quot;r&quot;) as target_file:</span><br><span class="line"> source, target = source_file.readline(), target_file.</span><br><span class="line">readline()</span><br><span class="line"> counter = 0</span><br><span class="line"> while source and target and (not max_size or counter &lt; </span><br><span class="line">max_size):</span><br><span class="line"> counter += 1</span><br><span class="line"> if counter % 100000 == 0:</span><br><span class="line"> print(&quot;  reading data line %d&quot; % counter)</span><br><span class="line"> sys.stdout.flush()</span><br><span class="line"> source_ids = [int(x) for x in source.split()]</span><br><span class="line"> target_ids = [int(x) for x in target.split()]</span><br><span class="line"> target_ids.append(vocab_utils.EOS_ID)</span><br><span class="line"> for bucket_id, (source_size, target_size) in enumerate</span><br><span class="line">(_buckets):</span><br><span class="line"> if len(source_ids) &lt; source_size and len(target_</span><br><span class="line">ids) &lt; target_size:</span><br><span class="line"> data_set[bucket_id].append([source_ids, </span><br><span class="line">target_ids])</span><br><span class="line"> break</span><br><span class="line"> source, target = source_file.readline(), target_file.</span><br><span class="line">readline()</span><br><span class="line"> return data_set</span><br></pre></td></tr></table></figure>

</details>

<p>对于输出的每一句话都会加上EOS_ID，这么做的目的是为了让网络学习到结束的标记，可以控制输出的长短。</p>
<p>7．通过循环进行训练</p>
<p>在main函数中接着添加代码：通过循环来调用model.step进行迭代训练，每执行steps_per_checkpoint次，就保存检查点；测试结果，并将结果输出。</p>
<p>代码9-35 train（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">……       </span><br><span class="line">    while True:</span><br><span class="line">            # 根据数据样本的分布情况来选择bucket</span><br><span class="line">            </span><br><span class="line">            random_number_01 = np.random.random_sample()</span><br><span class="line">            bucket_id = min([i for i in xrange(len(train_buckets_scale)) </span><br><span class="line">           if train_buckets_scale[i] &gt; random_number_01])</span><br><span class="line"></span><br><span class="line">            # 开始训练</span><br><span class="line">            start_time = time.time()</span><br><span class="line">            encoder_inputs, decoder_inputs, target_weights = model.</span><br><span class="line">           get_batch(train_set, bucket_id)</span><br><span class="line">            _, step_loss, _ = model.step(sess, encoder_inputs, decoder_</span><br><span class="line">           inputs,target_weights, bucket_id, False)</span><br><span class="line">            step_time += (time.time() -start_time) / steps_per_</span><br><span class="line">           checkpoint</span><br><span class="line">            loss += step_loss / steps_per_checkpoint</span><br><span class="line">            current_step += 1</span><br><span class="line">            </span><br><span class="line">            # 保存检查点，测试数据</span><br><span class="line">            if current_step % steps_per_checkpoint == 0:</span><br><span class="line">                # Print statistics for the previous epoch.</span><br><span class="line">                perplexity = math.exp(loss) if loss &lt; 300 else float</span><br><span class="line">               (&apos;inf&apos;)</span><br><span class="line">                print (&quot;global step %d learning rate %.4f step-time %.2f </span><br><span class="line">               perplexity &quot;</span><br><span class="line">                    &quot;%.2f&quot; % (model.global_step.eval(), model.learning_</span><br><span class="line">                   rate.eval(),step_time, perplexity))</span><br><span class="line">                # 退化学习率</span><br><span class="line">                if len(previous_losses) &gt; 2 and loss &gt; max(previous_</span><br><span class="line">               losses[-3:]):</span><br><span class="line">                    sess.run(model.learning_rate_decay_op)</span><br><span class="line">                previous_losses.append(loss)</span><br><span class="line">                # 保存checkpoint</span><br><span class="line">                checkpoint_path = os.path.join(checkpoint_dir, </span><br><span class="line">               &quot;seq2seqtest.ckpt&quot;)</span><br><span class="line">                print(checkpoint_path)</span><br><span class="line">                model.saver.save(sess, checkpoint_path, global_step=</span><br><span class="line">               model.global_step)</span><br><span class="line">                step_time, loss = 0.0, 0.0  # 初始化为0</span><br><span class="line">                # 输出test_set中 empty bucket的bucket_id</span><br><span class="line">                    if len(test_set[bucket_id]) == 0:</span><br><span class="line">                        print(&quot;  eval: empty bucket %d&quot; % (bucket_id))</span><br><span class="line">                        continue</span><br><span class="line">                    encoder_inputs, decoder_inputs, target_weights = </span><br><span class="line">                   model.get_batch(test_set, bucket_id)</span><br><span class="line"></span><br><span class="line">                    _, eval_loss,output_logits = model.step(sess, </span><br><span class="line">      encoder_inputs, decoder_inputs,target_weights, bucket_id, True)</span><br><span class="line">                    eval_ppx = math.exp(eval_loss) if eval_loss &lt; 300 else </span><br><span class="line">                   float(&apos;inf&apos;)</span><br><span class="line">                    print(&quot;  eval: bucket %d perplexity %.2f&quot; % (bucket_</span><br><span class="line">                   id, eval_ppx))</span><br><span class="line">                    </span><br><span class="line">                    </span><br><span class="line">                    inputstr = datautil.ids2texts(reversed([en[0] for en </span><br><span class="line">                   in encoder_inputs]) ,rev_vocaben)</span><br><span class="line">                    print(&quot;输入&quot;,inputstr)</span><br><span class="line">                    print(&quot;输出&quot;,datautil.ids2texts([en[0] for en in </span><br><span class="line">                   decoder_inputs] ,rev_vocabch))</span><br><span class="line">  </span><br><span class="line">                    outputs = [np.argmax(logit, axis=1)[0] for logit in </span><br><span class="line">                   output_logits]                    </span><br><span class="line">                   </span><br><span class="line">                    if datautil.EOS_ID in outputs:</span><br><span class="line">                        outputs = outputs[:outputs.index(datautil.</span><br><span class="line">                       EOS_ID)]</span><br><span class="line">                        print(&quot;结果&quot;,datautil.ids2texts(outputs,rev_</span><br><span class="line">                       vocabch))</span><br><span class="line">                        </span><br><span class="line">                sys.stdout.flush()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

</details>

<p>这里使用的是一个死循环，默认会一直训练下去。因为有检查点文件，所以可以不用关注迭代次数，通过输出测试的打印结果与loss值，可以看出模型的好坏。训练到一定程度后直接退出即可。</p>
<p>8．网络模型Seq2SeqModel的初始化</p>
<p>这里为了先让读者对整体流程有个了解，所以将网络模型放在了最后单独介绍。这部分的代码在“9-34 seq2seq_model.py”文件中，该代码为GitHub中的一个例子代码，我们在其上面做了修改，增加了dropout功能，在初始化函数中增加了dropout_keep_prob参数。</p>
<p>在原有代码中，由于指定了输出的target_vocab_size，表明要求在模型结束后输出的应该是target_vocab_size其中的一类（one_hot），所以先定义了output_projection参数，里面由w和b构成，作为最后输出的权重。</p>
<p>代码9-34 seq2seq_model</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;带有注意力机制的Sequence-to-sequence 模型.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from __future__ import absolute_import</span><br><span class="line">from __future__ import division</span><br><span class="line">from __future__ import print_function</span><br><span class="line"></span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from six.moves import xrange  # pylint: disable=redefined-builtin</span><br><span class="line">import tensorflow as tf</span><br><span class="line">datautil = __import__(&quot;9-33  datautil&quot;)</span><br><span class="line">import datautil as data_utils</span><br><span class="line"></span><br><span class="line">class Seq2SeqModel(object):</span><br><span class="line">  &quot;&quot;&quot;带有注意力机制并且具有multiple buckets的Sequence-to-sequence 模型.</span><br><span class="line">  这个类实现了一个多层循环网络组成的编码器和一个具有注意力机制的解码器.完全是按</span><br><span class="line"> 照论文：</span><br><span class="line">  http://arxiv.org/abs/1412.7449 -中所描述的机制实现。更多细节信息可以参看</span><br><span class="line"> 论文内容</span><br><span class="line">  这个class 除了使用LSTM cells还可以使用GRU cells, 还使用了sampled </span><br><span class="line"> softmax 来</span><br><span class="line">  处理大词汇量的输出. 在论文http://arxiv.org/abs/1412.2007中的第三节描述了</span><br><span class="line">  sampled softmax。在论文http://arxiv.org/abs/1409.0473里面还有一个关于</span><br><span class="line"> 这个模型的一个单层的使用双向RNN编码器的版本</span><br><span class="line">    </span><br><span class="line">  &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">  def __init__(self,</span><br><span class="line">               source_vocab_size,</span><br><span class="line">               target_vocab_size,</span><br><span class="line">               buckets,</span><br><span class="line">               size,</span><br><span class="line">               num_layers,</span><br><span class="line">               dropout_keep_prob,</span><br><span class="line">               max_gradient_norm,</span><br><span class="line">               batch_size,</span><br><span class="line">               learning_rate,</span><br><span class="line">               learning_rate_decay_factor,</span><br><span class="line">               use_lstm=False,</span><br><span class="line">               num_samples=512,</span><br><span class="line">               forward_only=False,</span><br><span class="line">               dtype=tf.float32):</span><br><span class="line">    &quot;&quot;&quot;创建模型</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">      source_vocab_size:原词汇的大小.</span><br><span class="line">      target_vocab_size:目标词汇的大小.</span><br><span class="line">      buckets: 一个 (I, O)的list, I 代表输入的最大长度，O代表输出的最大长度，例如</span><br><span class="line">[(2, 4), (8, 16)].</span><br><span class="line">      size: 模型中每层的units个数.</span><br><span class="line">      num_layers: 模型的层数.</span><br><span class="line">      max_gradient_norm: 截断梯度的阀值.</span><br><span class="line">      batch_size: 训练中的批次数据大小;</span><br><span class="line">      learning_rate: 开始学习率.</span><br><span class="line">      learning_rate_decay_factor: 退化学习率的衰减参数.</span><br><span class="line">      use_lstm: 如果true, 使用 LSTM cells 替代GRU cells.</span><br><span class="line">      num_samples: sampled softmax的样本个数.</span><br><span class="line">      forward_only: 如果设置了, 模型只有正向传播.</span><br><span class="line">      dtype: internal variables的类型.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    self.source_vocab_size = source_vocab_size</span><br><span class="line">    self.target_vocab_size = target_vocab_size</span><br><span class="line">    self.buckets = buckets</span><br><span class="line">    self.batch_size = batch_size</span><br><span class="line">    self.dropout_keep_prob_output = dropout_keep_prob</span><br><span class="line">    self.dropout_keep_prob_input = dropout_keep_prob</span><br><span class="line">    self.learning_rate = tf.Variable(</span><br><span class="line">        float(learning_rate), trainable=False, dtype=dtype)</span><br><span class="line">    self.learning_rate_decay_op = self.learning_rate.assign(</span><br><span class="line">        self.learning_rate * learning_rate_decay_factor)</span><br><span class="line">    self.global_step = tf.Variable(0, trainable=False)</span><br><span class="line"></span><br><span class="line">    # 如果使用 sampled softmax, 需要一个输出的映射.</span><br><span class="line">    output_projection = None</span><br><span class="line">    softmax_loss_function = None</span><br><span class="line">    # 当采样数小于vocabulary size 时Sampled softmax 才有意义</span><br><span class="line">    if num_samples &gt; 0 and num_samples &lt; self.target_vocab_size:</span><br><span class="line">      w_t = tf.get_variable(&quot;proj_w&quot;, [self.target_vocab_size, size], </span><br><span class="line">     dtype=dtype)</span><br><span class="line">      w = tf.transpose(w_t)</span><br><span class="line">      b = tf.get_variable(&quot;proj_b&quot;, [self.target_vocab_size], dtype=</span><br><span class="line">     dtype)</span><br><span class="line">      output_projection = (w, b)</span><br></pre></td></tr></table></figure>

</details>

<p>lobal_step变量的作用是同步检查点文件对应的迭代步数。</p>
<p>9．自定义损失函数</p>
<p>sampled_loss为自定义损失函数，计算在分类target_vocab_size里模型输出的logits与标签labels（seq2seq框架中的输出）之间的交叉熵，并将该函数指针赋值给softmax_loss_function。softmax_loss_function会在后面使用model_with_buckets时，作为参数传入。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def sampled_loss(labels, logits):</span><br><span class="line">  labels = tf.reshape(labels, [-1, 1])</span><br><span class="line">  #需要使用 32bit的浮点数类型来计算sampled_softmax_loss，才能避免数值</span><br><span class="line"> 的不稳定性</span><br><span class="line">  local_w_t = tf.cast(w_t, tf.float32)</span><br><span class="line">  local_b = tf.cast(b, tf.float32)</span><br><span class="line">  local_inputs = tf.cast(logits, tf.float32)</span><br><span class="line">  return tf.cast(</span><br><span class="line">      tf.nn.sampled_softmax_loss(</span><br><span class="line">          weights=local_w_t,</span><br><span class="line">          biases=local_b,</span><br><span class="line">          labels=labels,</span><br><span class="line">          inputs=local_inputs,</span><br><span class="line">          num_sampled=num_samples,</span><br><span class="line">          num_classes=self.target_vocab_size),</span><br><span class="line">      dtype)</span><br><span class="line">softmax_loss_function = sampled_loss</span><br></pre></td></tr></table></figure>

</details>

<p>10．定义Seq2Seq框架结构</p>
<p>seq2seq_f函数的作用是定义Seq2Seq框架结构，该函数也是为了使用model_with_buckets时，作为参数传入。前面介绍model_with_buckets函数时说该函数更像一个封装好的框架，原因就在于此。</p>
<p>读者也要适应这种方式：将损失函数、网络结构、buckets统统定义完，然后将它们作为参数放入model_with_buckets函数中，之后一切交给TensorFlow来实现即可。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 使用词嵌入量（embedding）作为输入</span><br><span class="line">def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):</span><br><span class="line">  </span><br><span class="line">  with tf.variable_scope(&quot;GRU&quot;) as scope:</span><br><span class="line">      cell = tf.contrib.rnn.DropoutWrapper(</span><br><span class="line">          tf.contrib.rnn.GRUCell(size),</span><br><span class="line">            input_keep_prob=self.dropout_keep_prob_input,</span><br><span class="line">            output_keep_prob=self.dropout_keep_prob_output)</span><br><span class="line">      if num_layers &gt; 1:</span><br><span class="line">          cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers)</span><br><span class="line">  </span><br><span class="line">  print(&quot;new a cell&quot;)</span><br><span class="line">  return tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(</span><br><span class="line">      encoder_inputs,</span><br><span class="line">      decoder_inputs,</span><br><span class="line">      cell,</span><br><span class="line">      num_encoder_symbols=source_vocab_size,</span><br><span class="line">      num_decoder_symbols=target_vocab_size,</span><br><span class="line">      embedding_size=size,</span><br><span class="line">      output_projection=output_projection,</span><br><span class="line">      feed_previous=do_decode,</span><br><span class="line">      dtype=dtype)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中，额外加了一个打印信息print（”new a cell”），是为了测试seq2seq_model函数是什么时被调用的，在实验中可以得出结论。在构建网络模型时，会由model_with_buckets函数来调用，而model_with_buckets函数调用的次数取决于bucket的个数，即在model_with_buckets函数中，会为每个bucket使用seq2seq_f函数构建出一套网络Seq2Seq的网络模型，但是不用担心，它们的权重是共享的。具体可以参见model_with_buckets函数的实现，就是使用了共享变量的机制。</p>
<p>11．定义Seq2seq模型的输入占位符</p>
<p>下面定义Seq2Seq模型的输入占位符，这些占位符都是为了传入model_with_buckets函数中做准备的。</p>
<p>首先是Seq2Seq模型自己的两个list占位符：一个是输入encoder_inputs，一个是输出decoder_inputs。另外，model_with_buckets还需要一个额外的输入，在前面已经提过，因为其在做loss时使用的是带权重的交叉熵，所以还要输入大小等同于decoder_inputs的权重target_weights。</p>
<p>另外还有一个输入就是做交叉熵时的标签targets，因为它与decoder_inputs一样，所以可以直接由decoder_inputs变换而来，把decoder_inputs的第一个“_GO”去掉，在放到targets中。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 注入数据</span><br><span class="line">self.encoder_inputs = []</span><br><span class="line">self.decoder_inputs = []</span><br><span class="line">self.target_weights = []</span><br><span class="line">for i in xrange(buckets[-1][0]):   # 最后的bucket 是最大的</span><br><span class="line">  self.encoder_inputs.append(tf.placeholder(tf.int32,</span><br><span class="line">   shape=[None],</span><br><span class="line">                                          name=&quot;encoder&#123;0&#125;&quot;.format(i)))</span><br><span class="line">for i in xrange(buckets[-1][1] + 1):</span><br><span class="line">  self.decoder_inputs.append(tf.placeholder(tf.int32, shape=</span><br><span class="line"> [None],</span><br><span class="line">                                          name=&quot;decoder&#123;0&#125;&quot;.format(i)))</span><br><span class="line">  self.target_weights.append(tf.placeholder(dtype, shape=[None],</span><br><span class="line">                                            name=&quot;weight&#123;0&#125;&quot;.format(i)))</span><br><span class="line">     </span><br><span class="line">#将解码器移动一位得到targets</span><br><span class="line">targets = [self.decoder_inputs[i + 1]</span><br><span class="line">           for i in xrange(len(self.decoder_inputs) -1)]</span><br></pre></td></tr></table></figure>

</details>

<p>占位符的list大小是取buckets中的最大数。targets的长度与buckets 的长度一致，decoder_inputs与target_weights的长度会比buckets的长度大1，因为前面有“_GO”占位。</p>
<p>12．定义正向的输出与loss</p>
<p>当一切参数准备好后，就可以使用model_with_buckets将整个网络贯穿起来了。</p>
<p>在测试时会只进行正向传播，这时seq2seq_f里面的最后一个参数为True，该参数最终会在seq2seq_f里的embedding_attention_seq2seq中的feed_previous中生效。前面介绍过，如果为True时，表明只有第一个decoder输入是“_GO”开头，这样可以保证测试时，模型可以一直记着前面的cell状态。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">     # 训练的输出和loss定义</span><br><span class="line">     if forward_only:</span><br><span class="line">       self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_</span><br><span class="line">      with_buckets(</span><br><span class="line">           self.encoder_inputs, self.decoder_inputs, targets,</span><br><span class="line">           self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, </span><br><span class="line">          True),</span><br><span class="line">           softmax_loss_function=softmax_loss_function)</span><br><span class="line">       # 如果使用了输出映射，</span><br><span class="line"></span><br><span class="line">需要为解码器映射输出处理</span><br><span class="line">       if output_projection is not None:</span><br><span class="line">         for b in xrange(len(buckets)):</span><br><span class="line">           self.outputs[b] = [</span><br><span class="line">               tf.matmul(output, output_projection[0]) + output_</span><br><span class="line">              projection[1]</span><br><span class="line">               for output in self.outputs[b]</span><br><span class="line">           ]</span><br><span class="line">     else:</span><br><span class="line">       self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_</span><br><span class="line">              with_buckets(</span><br><span class="line">           self.encoder_inputs, self.decoder_inputs, targets,</span><br><span class="line">           self.target_weights, buckets,</span><br><span class="line">           lambda x, y: seq2seq_f(x, y, False),</span><br><span class="line">           softmax_loss_function=softmax_loss_function)</span><br></pre></td></tr></table></figure>

</details>

<p>在测试过程中，还需要将model_with_buckets的输出结果转化成outputs维度的one_hot。因为model_with_buckets是多个桶的输出，所以需要对每个桶都进行转换。</p>
<p>13．反向传播计算梯度并通过优化器更新</p>
<p>在前面已经通过model_with_buckets得到了loss。</p>
<p>下面的代码先通过tf.trainable_variables函数获得可训练的参数params，然后用tf.gradients计算loss对应参数params的梯度，并通过tf.clip_by_global_norm将过大的梯度按照max_gradient_norm来截断，将截断后的梯度通过优化器opt来迭代更新。同样，还要针对每个桶（bucket）进行这样的操作。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 梯度下降更新操作</span><br><span class="line">params = tf.trainable_variables()</span><br><span class="line">if not forward_only:</span><br><span class="line">  self.gradient_norms = []</span><br><span class="line">  self.updates = []</span><br><span class="line">  opt = tf.train.GradientDescentOptimizer(self.learning_rate)</span><br><span class="line">  for b in xrange(len(buckets)):</span><br><span class="line">    gradients = tf.gradients(self.losses[b], params)</span><br><span class="line">    clipped_gradients, norm = tf.clip_by_global_norm(gradients,</span><br><span class="line">                                                     max_gradient_norm)</span><br><span class="line">    self.gradient_norms.append(norm)</span><br><span class="line">    self.updates.append(opt.apply_gradients(</span><br><span class="line">        zip(clipped_gradients, params), global_step=self.global_</span><br><span class="line">       step))</span><br><span class="line">     </span><br><span class="line">self.saver = tf.train.Saver(tf.global_variables())</span><br></pre></td></tr></table></figure>

</details>

<p>最后更新saver，在代码“9-35 train.py”中会调用这部分代码来保存训练中的学习参数及相关变量。</p>
<p>14．按批次获取样本数据</p>
<p>在模型中，按批次获取的样本数据并不能直接使用，还需要在get_batch函数中进行相应转化，首先根据指定bucket_id所对应的大小确定输入和输出的size，根据size进行pad的填充，并且针对输出数据进行第一位为“_Go”的重整作为解码的input。这里用了个小技巧将输入的数据进行了倒序排列。而对于输入weight则将其全部初始化为0，对应的size为每一批次中decoder每个序列一个权重weight，即与decoder相等。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"> def get_batch(self, data, bucket_id):</span><br><span class="line">     &quot;&quot;&quot;在迭代训练过程中，从指定 bucket中获得一个随机批次数据</span><br><span class="line"> </span><br><span class="line">     Args:</span><br><span class="line">       data: 一个大小为len(self.buckets)的tuple，包含了创建一个batch中的输</span><br><span class="line">      入输出的</span><br><span class="line">         lists.</span><br><span class="line">       bucket_id: 整型, 指定从哪个bucket中取数据.</span><br><span class="line"> </span><br><span class="line">     Returns:</span><br><span class="line">       方便以后调用的 triple (encoder_inputs, decoder_inputs, target_</span><br><span class="line">      weights) </span><br><span class="line">       .</span><br><span class="line">     &quot;&quot;&quot;</span><br><span class="line">     encoder_size, decoder_size = self.buckets[bucket_id]</span><br><span class="line">     encoder_inputs, decoder_inputs = [], []</span><br><span class="line"> </span><br><span class="line">     # 获得一个随机批次的数据作为编码器与解码器的输入</span><br><span class="line">     # 如果需要时会有pad操作, 同时反转encoder的输入顺序，并且为decoder添加GO</span><br><span class="line">     for _ in xrange(self.batch_size):</span><br><span class="line">       encoder_input, decoder_input = random.choice(data[bucket_id])</span><br><span class="line"> </span><br><span class="line">       # pad和反转Encoder 的输入数据</span><br><span class="line">       encoder_pad = [data_utils.PAD_ID] * (encoder_size -len(encoder_</span><br><span class="line">      input))</span><br><span class="line">       encoder_inputs.append(list(reversed(encoder_input + encoder_</span><br><span class="line">      pad)))</span><br><span class="line"> </span><br><span class="line">       # 为Decoder输入数据添加一个额外的“GO”，</span><br><span class="line"></span><br><span class="line">并且进行pad</span><br><span class="line">       decoder_pad_size = decoder_size -len(decoder_input) -1</span><br><span class="line">       decoder_inputs.append([data_utils.GO_ID] + decoder_input +</span><br><span class="line">                             [data_utils.PAD_ID] * decoder_pad_size)</span><br><span class="line"> </span><br><span class="line">     # 从上面选择好的数据中创建 batch-major vectors</span><br><span class="line">     batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []</span><br><span class="line"> </span><br><span class="line">     for length_idx in xrange(encoder_size):</span><br><span class="line">       batch_encoder_inputs.append(</span><br><span class="line">           np.array([encoder_inputs[batch_idx][length_idx]</span><br><span class="line">                     for batch_idx in xrange(self.batch_size)], dtype=</span><br><span class="line">                    np.int32))</span><br><span class="line"> </span><br><span class="line">     for length_idx in xrange(decoder_size):</span><br><span class="line">       batch_decoder_inputs.append(</span><br><span class="line">           np.array([decoder_inputs[batch_idx][length_idx]</span><br><span class="line">                     for batch_idx in xrange(self.batch_size)], dtype=</span><br><span class="line">                    np.int32))</span><br><span class="line"> </span><br><span class="line">       # 定义target_weights 变量，默认是1，如果对应的targets是padding，</span><br><span class="line">      则target_weigts就为0</span><br><span class="line">       batch_weight = np.ones(self.batch_size, dtype=np.float32)</span><br><span class="line">       for batch_idx in xrange(self.batch_size):</span><br><span class="line">         # 如果对应的输出target 是一个 PAD符号，就将weight设为0</span><br><span class="line">         # 将decoder_input向前移动1位得到对应的target</span><br><span class="line">         if length_idx &lt; decoder_size -1:</span><br><span class="line">           target = decoder_inputs[batch_idx][length_idx + 1]</span><br><span class="line">         if length_idx == decoder_size -1 or target == data_utils.PAD_ID:</span><br><span class="line">           batch_weight[batch_idx] = 0.0</span><br><span class="line">       batch_weights.append(batch_weight)</span><br><span class="line">     return batch_encoder_inputs, batch_decoder_inputs, batch_weights</span><br></pre></td></tr></table></figure>

</details>

<p>15．Seq2Seq框架的迭代更新处理</p>
<p>这部分代码主要是构建输入feed数据，即输出的OP。在输入时，根据传入的bucket_id构建相应大小的输入输出list，通过循环传入list中对应的操作符里。由于decoder_inputs的长度比bucket中的长度大1，所以需要再多放一位到decoder_inputs的list中，在前面构建targets时，需要将所有的decoder_inputs向后移一位，targets作为标签要与bucket中的长度相等。确切地说target_weights是与targets相等的，所以不需要再输入值。</p>
<p>代码9-34 seq2seq_model（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"> def step(self, session, encoder_inputs, decoder_inputs, target_</span><br><span class="line">weights,</span><br><span class="line">          bucket_id, forward_only):</span><br><span class="line">   &quot;&quot;&quot;注入给定输入数据步骤</span><br><span class="line">     </span><br><span class="line">   Args:</span><br><span class="line">     session: tensorflow 所使用的session</span><br><span class="line">     encoder_inputs:用来注入encoder输入数据的numpy int vectors类型的list</span><br><span class="line">     decoder_inputs:用来注入decoder输入数据的numpy int vectors类型的list</span><br><span class="line">     target_weights:用来注入target weights的numpy float vectors类型的list</span><br><span class="line">     bucket_id: which bucket of the model to use</span><br><span class="line">     forward_only: 只进行正向传播</span><br><span class="line">     </span><br><span class="line">   Returns:</span><br><span class="line">     一个由gradient norm (不做反向时为none),average perplexity, and the </span><br><span class="line">    outputs组成的triple</span><br><span class="line">     </span><br><span class="line">   Raises:</span><br><span class="line">     ValueError:如果 encoder_inputs, decoder_inputs, 或者是target_</span><br><span class="line">    weights 的长度与指定bucket_id 的bucket size不符合</span><br><span class="line">   &quot;&quot;&quot;</span><br><span class="line">   # 检查长度</span><br><span class="line">   encoder_size, decoder_size = self.buckets[bucket_id]</span><br><span class="line">   if len(encoder_inputs) != encoder_size:</span><br><span class="line">     raise ValueError(&quot;Encoder length must be equal to the one in </span><br><span class="line">    bucket,&quot;</span><br><span class="line">                      &quot; %d != %d.&quot; % (len(encoder_inputs), encoder_size))</span><br><span class="line">   if len(decoder_inputs) != decoder_size:</span><br><span class="line">     raise ValueError(&quot;Decoder length must be equal to the one in </span><br><span class="line">    bucket,&quot;</span><br><span class="line">                      &quot; %d != %d.&quot; % (len(decoder_inputs), decoder_size))</span><br><span class="line">   if len(target_weights) != decoder_size:</span><br><span class="line">     raise ValueError(&quot;Weights length must be equal to the one in </span><br><span class="line">    bucket,&quot;</span><br><span class="line">                      &quot; %d != %d.&quot; % (len(target_weights), decoder_size))</span><br><span class="line">     </span><br><span class="line">   # 定义Input feed</span><br><span class="line">   input_feed = &#123;&#125;</span><br><span class="line">   for l in xrange(encoder_size):</span><br><span class="line">     input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]</span><br><span class="line">   for l in xrange(decoder_size):</span><br><span class="line">     input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]</span><br><span class="line">     input_feed[self.target_weights[l].name] = target_weights[l]</span><br><span class="line">     </span><br><span class="line">   last_target = self.decoder_inputs[decoder_size].name</span><br><span class="line">   input_feed[last_target] = np.zeros([self.batch_size], dtype=np.</span><br><span class="line">  int32)</span><br><span class="line">     </span><br><span class="line">   # 定义Output feed</span><br><span class="line">   if not forward_only:</span><br><span class="line">     output_feed = [self.updates[bucket_id], </span><br><span class="line">                    self.gradient_norms[bucket_id],  </span><br><span class="line">                    self.losses[bucket_id]]  </span><br><span class="line">   else:</span><br><span class="line">     output_feed = [self.losses[bucket_id]]  </span><br><span class="line">     for l in xrange(decoder_size):  </span><br><span class="line">       output_feed.append(self.outputs[bucket_id][l])</span><br><span class="line">     </span><br><span class="line">   outputs = session.run(output_feed, input_feed)</span><br><span class="line">   if not forward_only:</span><br><span class="line">     return outputs[1], outputs[2], None  </span><br><span class="line">   else:</span><br><span class="line">     return None, outputs[0], outputs[1:]</span><br></pre></td></tr></table></figure>

</details>

<p>对于输出，也要区分是测试还是训练。如果是测试，需要将loss与logit输出，结果在outputs中，outputs[0]为loss，outputs[1：]为输出的decoder_size大小序列。如果是训练，输出需要更新的梯度与loss。这里多输出一个None是为了统一输出，保证第二位输出的都是loss。</p>
<p>整个代码进展到这里就可以进行训练操作了，运行train.py文件，将模型运行起来进行迭代训练。输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Loading model from cache C:\Users\LIJINH~1\AppData\Local\Temp\jieba.cache</span><br><span class="line">Loading model cost 0.672 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">vocab_size 11963</span><br><span class="line">vocab_sizech 15165</span><br><span class="line">checkpoint_dir is fanyichina/checkpoints/</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">model is ok</span><br><span class="line">Using bucket sizes:</span><br><span class="line">[(20, 20), (40, 40), (50, 50), (60, 60)]</span><br><span class="line">fanyichina/fromids/english1w.txt</span><br><span class="line">fanyichina/toids/chinese1w.txt</span><br><span class="line">bucket sizes = [1649, 4933, 1904, 1383]</span><br><span class="line">fanyichina/checkpoints/seq2seqtest.ckpt</span><br><span class="line">WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.</span><br><span class="line">Type is unsupported, or the types of the items don&apos;t match field type in </span><br><span class="line">CollectionDef.</span><br><span class="line">&apos;dict&apos; object has no attribute &apos;name&apos;</span><br><span class="line">  eval: bucket 0 perplexity 1.71</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到输出了词典的大小vocab_size 11963、vocab_sizech 15165，与定义的buckets，4个bucket分别需要调用4次seq2seq_f，于是打印了4次new a cell。接着会显示每一批次中每个bucket的输入（因为是反转的，这里已经给反过来了），并且能够看到对输入的pad进行了填充。对于每个输出由’_GO’字符开始，结束时都会有’_EOS’字符。对于模型预测的输出结果，也是将’_EOS’字符前面的内容打印出来，没有’_EOS’字符的预测结果将视为没有翻译成功，因此没有打印出来。</p>
<p>16．测试模型</p>
<p>测试模型代码在代码“9-36 test.py”文件中，与前面实例中的代码基本相似，需要考虑的是，在创建模型时要使用测试模式（最后一个参数为True），并且dropout设为1.0。在main函数里，先等待用户输入，然后对用户输入的字符进行处理并传入模型，最终输出结果并显示出来。完整代码如下。</p>
<p>代码9-36 test</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">from six.moves import xrange</span><br><span class="line"></span><br><span class="line">_buckets = []</span><br><span class="line">convo_hist_limit = 1</span><br><span class="line">max_source_length = 0</span><br><span class="line">max_target_length = 0</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line">datautil = __import__(&quot;9-33  datautil&quot;)</span><br><span class="line">seq2seq_model = __import__(&quot;9-34  seq2seq_model&quot;)</span><br><span class="line">import datautil</span><br><span class="line">import seq2seq_model</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">max_train_data_size= 0 #0表示训练数据的输入长度没有限制</span><br><span class="line"></span><br><span class="line">data_dir = &quot;datacn/&quot;</span><br><span class="line"></span><br><span class="line">dropout = 1.0 </span><br><span class="line">grad_clip = 5.0</span><br><span class="line">batch_size = 60</span><br><span class="line">hidden_size = 14</span><br><span class="line">num_layers =2</span><br><span class="line">learning_rate =0.5</span><br><span class="line">lr_decay_factor =0.99</span><br><span class="line"></span><br><span class="line">checkpoint_dir= &quot;data/checkpoints/&quot;</span><br><span class="line"></span><br><span class="line">###############翻译</span><br><span class="line">hidden_size = 100</span><br><span class="line">checkpoint_dir= &quot;fanyichina/checkpoints/&quot;</span><br><span class="line">data_dir = &quot;fanyichina/&quot;</span><br><span class="line">_buckets =[(20, 20), (40, 40), (50, 50), (60, 60)]</span><br><span class="line"></span><br><span class="line">def getfanyiInfo():</span><br><span class="line">    vocaben, rev_vocaben=datautil.initialize_vocabulary(os.path.join</span><br><span class="line">   (datautil.data_dir, datautil.vocabulary_fileen))</span><br><span class="line">    vocab_sizeen= len(vocaben)</span><br><span class="line">    print(&quot;vocab_size&quot;,vocab_sizeen)</span><br><span class="line">    </span><br><span class="line">    vocabch, rev_vocabch=datautil.initialize_vocabulary(os.path.join</span><br><span class="line">   (datautil.data_dir, datautil.vocabulary_filech))</span><br><span class="line">    vocab_sizech= len(vocabch)</span><br><span class="line">    print(&quot;vocab_sizech&quot;,vocab_sizech) </span><br><span class="line"></span><br><span class="line">    return vocab_sizeen,vocab_sizech,vocaben,rev_vocabch   </span><br><span class="line">    </span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    vocab_sizeen,vocab_sizech,vocaben,rev_vocabch= getfanyiInfo()</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(checkpoint_dir):</span><br><span class="line">        os.mkdir(checkpoint_dir)</span><br><span class="line">    print (&quot;checkpoint_dir is &#123;0&#125;&quot;.format(checkpoint_dir))</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        model = createModel(sess,True,vocab_sizeen,vocab_sizech)    </span><br><span class="line">    </span><br><span class="line">        print (_buckets)</span><br><span class="line">        model.batch_size = 1</span><br><span class="line"></span><br><span class="line">        conversation_history =[]</span><br><span class="line">        while True:  </span><br><span class="line">            prompt = &quot;请输入: &quot;</span><br><span class="line">            sentence = input(prompt)</span><br><span class="line">            conversation_history.append(sentence.strip())</span><br><span class="line">            conversation_history = conversation_history[-convo_hist_</span><br><span class="line">           limit:]</span><br><span class="line">            </span><br><span class="line">            token_ids = list(reversed( datautil.sentence_to_ids(&quot; &quot;.</span><br><span class="line">           join(conversation_history) ,vocaben,normalize_digits=True,</span><br><span class="line">           Isch=False) )  )</span><br><span class="line">            print(token_ids)</span><br><span class="line">            bucket_id = min([b for b in xrange(len(_buckets))if _buckets</span><br><span class="line">           [b][0] &gt; len(token_ids)])</span><br><span class="line">            </span><br><span class="line">            encoder_inputs, decoder_inputs, target_weights = model.</span><br><span class="line">           get_batch(&#123;bucket_id: [(token_ids, [])]&#125;, bucket_id)</span><br><span class="line"></span><br><span class="line">            _, _, output_logits = model.step(sess, encoder_inputs, </span><br><span class="line">           decoder_inputs,target_weights, bucket_id, True)</span><br><span class="line"></span><br><span class="line">            #使用 beam search策略</span><br><span class="line">            outputs = [int(np.argmax(logit, axis=1)) for logit in </span><br><span class="line">           output_logits]</span><br><span class="line">            print(&quot;outputs&quot;,outputs,datautil.EOS_ID)</span><br><span class="line">            if datautil.EOS_ID in outputs:</span><br><span class="line">                outputs = outputs[:outputs.index(datautil.EOS_ID)]</span><br><span class="line">                </span><br><span class="line">                convo_output =  &quot; &quot;.join(datautil.ids2texts(outputs,</span><br><span class="line">               rev_vocabch))</span><br><span class="line">                conversation_history.append(convo_output)</span><br><span class="line">                print (convo_output)</span><br><span class="line">            else：</span><br><span class="line">                print(&quot;can not translation！&quot;)</span><br><span class="line"></span><br><span class="line">def createModel(session, forward_only,from_vocab_size,to_vocab_size):</span><br><span class="line">    &quot;&quot;&quot;Create translation model and initialize or load parameters in </span><br><span class="line">   session.&quot;&quot;&quot;</span><br><span class="line">    model = seq2seq_model.Seq2SeqModel(</span><br><span class="line">      from_vocab_size,#from</span><br><span class="line">      to_vocab_size,#to</span><br><span class="line">      _buckets,</span><br><span class="line">      hidden_size,</span><br><span class="line">      num_layers,</span><br><span class="line">      dropout,</span><br><span class="line">      grad_clip,</span><br><span class="line">      batch_size,</span><br><span class="line">      learning_rate,</span><br><span class="line">      lr_decay_factor,</span><br><span class="line">      forward_only=forward_only,</span><br><span class="line">      dtype=tf.float32)</span><br><span class="line">      </span><br><span class="line">    print(&quot;model is ok&quot;)</span><br><span class="line">    </span><br><span class="line">    ckpt = tf.train.latest_checkpoint(checkpoint_dir)</span><br><span class="line">    if ckpt!=None:</span><br><span class="line">        model.saver.restore(session, ckpt)</span><br><span class="line">        print (&quot;Reading model parameters from &#123;0&#125;&quot;.format(ckpt))</span><br><span class="line">    else:</span><br><span class="line">        print (&quot;Created model with fresh parameters.&quot;)</span><br><span class="line">        session.run(tf.global_variables_initializer())  </span><br><span class="line"></span><br><span class="line">    return model</span><br><span class="line"></span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Loading model from cache C:\Users\LIJINH~1\AppData\Local\Temp\jieba.cache</span><br><span class="line">Loading model cost 0.719 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">vocab_size 11963</span><br><span class="line">vocab_sizech 15165</span><br><span class="line">checkpoint_dir is fanyichina/checkpoints/</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">new a cell</span><br><span class="line">model is ok</span><br><span class="line">INFO:tensorflow:Restoring parameters from fanyichina/checkpoints/</span><br><span class="line">seq2seqtest.ckpt-99600</span><br><span class="line">Reading model parameters from fanyichina/checkpoints/seq2seqtest.</span><br><span class="line">ckpt-99600</span><br><span class="line">[(20, 20), (40, 40), (50, 50), (60, 60)]</span><br><span class="line"> </span><br><span class="line">请输入: will reap good results and the large</span><br><span class="line">[149, 4, 6, 341, 169, 4980, 22]</span><br><span class="line">not use</span><br><span class="line">outputs[838,838,26,105,643,8,1595,1089,5,968,8,968,6,2,5,1365,6,2,6,2]2</span><br><span class="line">最终 最终 也 会 对此 和 坚强 有力 的 指导 和 指导 .</span><br></pre></td></tr></table></figure>

</details>

<p>当前的例子是“跑了”约半天时间的模型效果，通过载入检查点打印信息可以看到当前迭代了99 600次，从原有的样本中简单复制几句话输入系统中，则系统可以大致翻译出一些汉语。可以看到它并没有按照词顺序逐个翻译，而是用学到原有样本的意思来表达，尽管语句还不通畅。这里只是做个演示，如果需要训练更好的模型，可以增加样本数量，并增加训练时间。</p>
<h3 id="9-9-实例75：制作一个简单的聊天机器人"><a href="#9-9-实例75：制作一个简单的聊天机器人" class="headerlink" title="9.9 实例75：制作一个简单的聊天机器人"></a>9.9 实例75：制作一个简单的聊天机器人</h3><p>实例74中的Seq2Seq模型的代码可以作为很好的框架来扩展使用，简单地改变一下数据样本，即可扩展到许多更有意思的应用中。例如，让机器人对对联、讲故事、生成文章摘要、汉语翻译成英语、聊天机器人等都可以实现。这些扩展应用基本上不需要改动太多的代码就可以完成，本节以聊天机器人来举例演示。</p>
<p>实例描述</p>
<p>准备一部分聊天对话的语料，使用Seq2Seq模式对其进行学习，拟合特征，从而实现聊天机器人的功能。</p>
<p>基于9.8.6节例子中的代码文件，本例中需要变化的代码主要在处理样本方面，包括“9-33 datautil.py”“9-35 train.py”“9-36 test.py”。“9-34 seq2seq_model.py”文件为模型文件，可以不做变化，如需要修改网络结构，可以在其seq2seq_f函数中改变cell的组成即可。这样新生成的文件就是“9-37 datautil.py”“9-38 seq2seq_model.py”“9-39 train.py”“9-40 test.py”，具体步骤如下。</p>
<h4 id="9-9-1-构建项目框架"><a href="#9-9-1-构建项目框架" class="headerlink" title="9.9.1 构建项目框架"></a>9.9.1 构建项目框架</h4><p>新建一个文件夹（本例为“实例75 dialog”），将“实例74”原有代码全部复制进去，然后建立一个子文件夹datacn用于放样本，同时在datacn文件夹里建立checkpoints、dialog、fromids和toids这4个文件夹。</p>
<h4 id="9-9-2-准备聊天样本"><a href="#9-9-2-准备聊天样本" class="headerlink" title="9.9.2 准备聊天样本"></a>9.9.2 准备聊天样本</h4><p>因本例只是演示作用，因此并没有用正规样本，只是随意写了几句对话放到了两个文件里，然后将文件放到dialog下。</p>
<h4 id="9-9-3-预处理样本"><a href="#9-9-3-预处理样本" class="headerlink" title="9.9.3 预处理样本"></a>9.9.3 预处理样本</h4><p>修改代码“9-33 datautil.py”文件，将main函数修改如下，更新data_dir、raw_data_dir_to路径，将英文字典相关的代码全部注释掉见代码第15～21行。</p>
<p>代码9-37 datautil</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">data_dir = &quot;datacn/&quot;</span><br><span class="line">raw_data_dir_to = &quot;datacn/dialog/&quot;</span><br><span class="line">vocabulary_filech = &quot;dictch.txt&quot;</span><br><span class="line"></span><br><span class="line">plot_histograms = plot_scatter =True</span><br><span class="line">vocab_size =40000</span><br><span class="line"></span><br><span class="line">max_num_lines =1</span><br><span class="line">max_target_size = 200</span><br><span class="line">max_source_size = 200</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    vocabulary_filenamech = os.path.join(data_dir, vocabulary_filech)</span><br><span class="line">##############################</span><br><span class="line">    #创建英文字典</span><br><span class="line">#    training_dataen, counten, dictionaryen, reverse_dictionaryen,</span><br><span class="line">    textsszen =create_vocabulary(vocabulary_filenameen</span><br><span class="line">#                                  ,raw_data_dir,vocab_size,Isch=False,</span><br><span class="line">                                  normalize_digits = True)</span><br><span class="line">#    print(&quot;training_data&quot;,len(training_dataen))</span><br><span class="line">#    print(&quot;dictionary&quot;,len(dictionaryen)) </span><br><span class="line">#########################</span><br><span class="line">    #创建中文字典    </span><br><span class="line">    training_datach, countch, dictionarych, reverse_dictionarych,</span><br><span class="line">   textsszch =create_vocabulary(vocabulary_filenamech</span><br><span class="line">                                   ,raw_data_dir_to,vocab_size,Isch=True,</span><br><span class="line">                                  normalize_digits = True)</span><br><span class="line">    source_file,target_file =splitFileOneline(training_datach,</span><br><span class="line">     textsszch)</span><br><span class="line">    print(&quot;training_datach&quot;,len(training_datach))</span><br><span class="line">    print(&quot;dictionarych&quot;,len(dictionarych)) </span><br><span class="line">    analysisfile(source_file,target_file)</span><br></pre></td></tr></table></figure>

</details>

<p>创建中文字典之后，通过splitFileOneline函数将原有样本分为from和to，即把对话中的两个角色分到两个文档里。splitFileOneline的定义如下：</p>
<p>代码9-37 datautil（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> #将读好的对话文本按行分开，一行问，一行答。存为两个文件。training_data为总数据，</span><br><span class="line">textssz为每行的索引</span><br><span class="line"> def splitFileOneline(training_data ,textssz):</span><br><span class="line">     source_file = os.path.join(data_dir+&apos;fromids/&apos;, &quot;data_source_</span><br><span class="line">    test.txt&quot;)</span><br><span class="line">     target_file = os.path.join(data_dir+&apos;toids/&apos;, &quot;data_target_</span><br><span class="line">    test.txt&quot;)</span><br><span class="line">     create_seq2seqfile(training_data,source_file ,target_file,</span><br><span class="line">      textssz)</span><br><span class="line">     return source_file,target_file</span><br></pre></td></tr></table></figure>

</details>

<p>运行之后可以看到，在datacn下生成了中文字典，并且在datacn\fromids与datacn\toids下生成了两个ids文件。</p>
<h4 id="9-9-4-训练样本"><a href="#9-9-4-训练样本" class="headerlink" title="9.9.4 训练样本"></a>9.9.4 训练样本</h4><p>训练样本步骤只修改代码“9-35 train.py”中的样本部分即可，代码如下，将原来在main函数之前的翻译相关的信息代码全部去掉，换成dialog的相关信息，更新checkpoint_dir与buckets，定义getdialogInfo。为了返回值不变，返回的英文词典和英文词典中的英文词数量替换成返回中文词典和中文词典中的中文词数量。</p>
<p>代码9-39 train</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">checkpoint_dir= &quot;datacn/checkpoints/&quot;</span><br><span class="line"> </span><br><span class="line">_buckets =[(5, 5), (10, 10), (20, 20)]</span><br><span class="line">def getdialogInfo():</span><br><span class="line">    vocabch, rev_vocabch=datautil.initialize_vocabulary(os.path.join(datautil.data_</span><br><span class="line">dir, datautil.vocabulary_filech))</span><br><span class="line">    vocab_sizech= len(vocabch)</span><br><span class="line">    print(&quot;vocab_sizech&quot;,vocab_sizech) </span><br><span class="line">    filesfrom,_=datautil.getRawFileList(datautil.data_dir+&quot;fromids/&quot;)</span><br><span class="line">    filesto,_=datautil.getRawFileList(datautil.data_dir+&quot;toids/&quot;)</span><br><span class="line">    source_train_file_path = filesfrom[0]</span><br><span class="line">    target_train_file_path= filesto[0]</span><br><span class="line">return vocab_sizech,vocab_sizech,rev_vocabch,rev_vocabch,source_train_file_</span><br><span class="line">path,target_train_file_path</span><br><span class="line">def main():</span><br><span class="line">vocab_sizeen,vocab_sizech,rev_vocaben,rev_vocabch,source_train_file_</span><br><span class="line">path,target_train_file_path = getdialogInfo()</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>在main函数的第一句中，修改调用的函数为getdialogInfo以获得dialog的信息，修改完样本后，就可以运行该文件进行模型训练了。由于样本量非常小（仅仅是演示而已），因此模型训练的时间也很短，几分钟即可。</p>
<h4 id="9-9-5-测试模型"><a href="#9-9-5-测试模型" class="headerlink" title="9.9.5 测试模型"></a>9.9.5 测试模型</h4><p>与上一步类似，修改代码“9-36 test.py”中的样本部分即可，代码如下，将原来在main函数之前的翻译相关的信息代码全部去掉，换成dialog的相关信息，更新checkpoint_dir与buckets，定义getdialogInfo。为了返回值不变，将原来返回的英文词典中的英文词数量变为返回中文词典中的中文词数量用中文词典代替英文词典，并且在转换成ids的地方需要将isch改为True。</p>
<p>代码9-40 test</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hidden_size = 100</span><br><span class="line">checkpoint_dir= &quot;datacn/checkpoints/&quot;</span><br><span class="line">_buckets =[(5, 5), (10, 10), (20, 20)]</span><br><span class="line">def getdialogInfo():</span><br><span class="line">    vocabch,rev_vocabch=datautil.initialize_vocabulary(os.path.join</span><br><span class="line">     (datautil.data_dir, datautil.vocabulary_filech))</span><br><span class="line">    vocab_sizech= len(vocabch)</span><br><span class="line">    print(&quot;vocab_sizech&quot;,vocab_sizech) </span><br><span class="line">    filesfrom,_=datautil.getRawFileList(datautil.data_dir+&quot;fromids/&quot;)</span><br><span class="line">    filesto,_=datautil.getRawFileList(datautil.data_dir+&quot;toids/&quot;)   </span><br><span class="line">    source_train_file_path = filesfrom[0]</span><br><span class="line">    target_train_file_path= filesto[0]</span><br><span class="line">    return vocab_sizech,vocab_sizech,vocabch,rev_vocabch</span><br><span class="line"> </span><br><span class="line">def main():</span><br><span class="line">    vocab_sizeen,vocab_sizech,vocaben,rev_vocabch= getdialogInfo()</span><br><span class="line">……</span><br><span class="line">        while True:  </span><br><span class="line">           prompt = &quot;请输入: &quot;</span><br><span class="line">           sentence = input(prompt)</span><br><span class="line">           conversation_history.append(sentence.strip())</span><br><span class="line">           conversation_history = conversation_history[-convo_hist_limit:]</span><br><span class="line">            </span><br><span class="line">            token_ids=list(reversed(datautil.sentence_to_ids(&quot;&quot;.join</span><br><span class="line">            (conversation_history) ,vocaben,normalize_digits=True,</span><br><span class="line">            Isch=True) )  )</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>同样在main函数的第一行中修改代码，调用getdialogInfo获得信息。</p>
<p>整个代码完成后运行程序，并输入类似样本中简单的对话，可以看到如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">请输入: 你好</span><br><span class="line">[20]</span><br><span class="line">outputs [30, 2, 2, 2, 2] 2</span><br><span class="line">您好</span><br><span class="line"> </span><br><span class="line">请输入: 你吃了吗</span><br><span class="line">[12, 7, 4, 6]</span><br><span class="line">outputs [5, 4, 7, 2, 2] 2</span><br><span class="line">我 吃 了</span><br><span class="line"> </span><br><span class="line">请输入: 吃的啥</span><br><span class="line">[3, 10, 4]</span><br><span class="line">outputs [5, 4, 10, 2, 2] 2</span><br><span class="line">我 吃 的</span><br><span class="line"> </span><br><span class="line">请输入: 你吃啥</span><br><span class="line">[3, 4, 6]</span><br><span class="line">outputs [5, 4, 17, 2, 2] 2</span><br><span class="line">我 吃 三文鱼</span><br><span class="line"> </span><br><span class="line">请输入: 还有吗</span><br><span class="line">[12, 11]</span><br><span class="line">outputs [5, 29, 13, 16, 2] 2</span><br><span class="line">我 没吃够 呢 不能</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，在样本里最后一句的回答完全不一样，但是神经网络仿佛学到了里面的语义。在简单的问话：“还有吗？”可以读懂说话人的意思是想要，于是输出：“我 没吃够 呢 不能”。从聊天机器人的例子可以看出，通过学习某个专业方面的对话样本（如某个业务的客服对话），会在该业务下产生很好的语义，并有很好的专业交流。</p>
<p>该例只是演示，主要目的是为了让读者学会如何应用框架代码，有兴趣的读者可以找些样本，自己动手试试，将前面举例的几种场景应用到模型中。当然，前面列出的场景只是一部分，只要符合序列对序列的模式都可以用Seq2Seq的框架来学习。希望读者可以举一反三，在此基础上做出更多出色的应用。</p>
<h3 id="9-10-时间序列的高级接口TFTS"><a href="#9-10-时间序列的高级接口TFTS" class="headerlink" title="9.10 时间序列的高级接口TFTS"></a>9.10 时间序列的高级接口TFTS</h3><p>TFTS（TensorFlow Time Series）是一个专门处理时间序列数据的高级接口，从TensorFlow的1.3版本开始，陆续改进迭代，直到1.5版本得到了最终的完善。</p>
<p>TFTS属于估算器框架下的一个具体应用。估算器是TensorFlow 1.3版本的新功能，是对机器学习全流程的代码封装。使得开发者不需要再编写流程代码，按照估算器的框架专心实现某一部分具有独立功能（如模型结构、样本输入处理）的代码即可。</p>
<p>TFTS的具体接口在tf.contrib.timeseries下。它支持非线性自动回归模型（估算器：ARRegressor）、基于线性状态空间建模的组件集合模型（包括趋势、预测、向量自回归、移动平均值等，估算器：StructuralEnsembleRegressor）、自定义LSTM模型。</p>
<p>开发者可以按照估算器的框架对时间序列数据进行训练、预测。该接口不仅具有处理单变量和多变量的时间序列数据的功能，还具有按照标注忽略具体序列数据的功能。</p>
<p>为了让开发者方便使用，该接口特意给出了4个例子。统一放在如下地址中：</p>
<p><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/timeseries/examples" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/timeseries/examples</a>  </p>
<p>上述网址打开后，可以找到如下4个代码文件，分别对应4个例子，具体介绍如下。</p>
<p>·known_anomaly.py：单变量时间序列训练及模型评估，并带有按照标注值忽略的功能；</p>
<p>·multivariate.py ：多变量时间序列训练及模型评估；</p>
<p>·predict.py：对时间序列进行训练及预测的例子；</p>
<p>·lstm.py ：自定义lstm模型例子。</p>
<p>这4个例子中的知识点几乎介绍了TFTS的全部应用。但对模型的导出、载入并未有代码演示。TFTS模型部分使用了saved_model接口。读者可以在如下网站查看关于TFTS的导出、载入说明。</p>
<p><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md</a></p>
<p><img src="Image00014.jpg" alt> 注意： TFTS的预测功能并不是一个独立的计算，它是依赖估算器的evaluate方法的返回值进行的。这就要求在使用predict之前必须进行一次evaluate的调用。但是在TFTS的代码中，对evaluate的封装是默认在开发环境下运行的，每次调用都会生成支持TensorBoard的Summary日志文件。在生产情况下，这个功能会消耗不必要的性能。可以通过注释掉源码库中的对应代码将其关闭。具体做法如下：</p>
<p>（1）打开文件Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py；</p>
<p>（2）在_evaluate_model函数中，找到如下代码：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_write_dict_to_summary( </span><br><span class="line">    output_dir=eval_dir,</span><br><span class="line">    dictionary=eval_results,</span><br><span class="line">current_global_step=eval_results[ops.GraphKeys.GLOBAL_STEP])</span><br></pre></td></tr></table></figure>

</details>

<p>（3）将其全部注释掉即可。</p>
<h2 id="第10章-自编码网络——能够自学习样本特征的网络"><a href="#第10章-自编码网络——能够自学习样本特征的网络" class="headerlink" title="第10章 自编码网络——能够自学习样本特征的网络"></a>第10章 自编码网络——能够自学习样本特征的网络</h2><p>深度学习领域主要有两种训练模式：一种是监督学习，即不仅有样本，还有对应的标签；另一种是非监督学习，即只有样本没有标签。此外还有半监督学习，但也属于非监督领域，这里不展开讲解了。</p>
<p>对于监督学习的训练任务，为已有样本准备对应的标签是项很繁重的工作，所以相对来讲，非监督学习就显得简单得多。如果能让网络直接使用样本进行训练，不需要再准备标签，则是更高效的事情。</p>
<p>本章来学习一个非监督模型的网络——自编码网络。</p>
<p>本章含有教学视频共11分15秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了概括性讲解，对自编码网络的结构、用途及类型部分依次做了简要介绍（掌握自编码网络的分步训练方法，以及条件变分自编码网络是本章内容的重点）。</p>
<p><img src="Image00200.jpg" alt></p>
<h3 id="10-1-自编码网络介绍及应用"><a href="#10-1-自编码网络介绍及应用" class="headerlink" title="10.1 自编码网络介绍及应用"></a>10.1 自编码网络介绍及应用</h3><p>人们平时看一幅图时，并不是像计算机那个逐个像素去读，一般是扫一眼物体，大致能得到需要的信息，如形状、颜色和特征等。那么怎样让机器也有这项能力呢？这里就为大家介绍一下自编码网络。</p>
<p>自编码网络是非监督学习领域中的一种，可以自动从无标注的数据中学习特征，是一种以重构输入信号为目标的神经网络，它可以给出比原始数据更好的特征描述，具有较强的特征学习能力，在深度学习中常用自编码网络生成的特征来取代原始数据，以得到更好的结果。</p>
<h3 id="10-2-最简单的自编码网络"><a href="#10-2-最简单的自编码网络" class="headerlink" title="10.2 最简单的自编码网络"></a>10.2 最简单的自编码网络</h3><p>自编码（Auto-Encoder，AE）网络是输入等于输出的网络，最基本的模型可以视为三层的神经网络，即输入层、隐藏层、输出层。其中，输入层的样本也会充当输出层的标签角色。换句话说，这个神经网络就是一种尽可能复现输入信号的神经网络。具体的网络结构如图10-1所示。</p>
<p><img src="Image00201.jpg" alt></p>
<p>图10-1 让输出的信号等于输入</p>
<p>其中，从输入到中间状态的过程叫做编码，从中间状态再回到输出的过程叫做解码。这样构成的自动编码器可以捕捉代表输入数据的最重要的因素，类似PCA算法（主成份分析），找到可以代表原信息的主要成分。</p>
<p>自编码器要求输出尽可能等于输入，并且其隐藏层必须满足一定的稀疏性，是通过将隐藏层中的后一层个数比前一层神经元个数少的方式来实现稀疏效果的。相当于隐藏层对输入进行了压缩，并在输出层中解压缩。整个过程中肯定会丢失信息，但训练能够使丢失的信息尽量减少，最大化地保留其主要特征。</p>
<p>如果激活函数不使用Sigmoid函数，而使用线性函数，那么便是PCA模型了。</p>
<h3 id="10-3-自编码网络的代码实现"><a href="#10-3-自编码网络的代码实现" class="headerlink" title="10.3 自编码网络的代码实现"></a>10.3 自编码网络的代码实现</h3><p>本节通过实例演示自编码网络的实现。</p>
<h4 id="10-3-1-实例76：提取图片的特征，并利用特征还原图片"><a href="#10-3-1-实例76：提取图片的特征，并利用特征还原图片" class="headerlink" title="10.3.1 实例76：提取图片的特征，并利用特征还原图片"></a>10.3.1 实例76：提取图片的特征，并利用特征还原图片</h4><p>实例描述</p>
<p>通过构建一个两层降维的自编码网络，将MNIST数据集的数据特征提取出来，并通过这些特征再重建一个MNIST数据集。</p>
<p>本例分为如下几个步骤。</p>
<p>1．引入头文件，并加载MNIST数据</p>
<p>假设MNIST数据放在代码文件同级目录的data下，将其以one-hot的形式载入。</p>
<p>代码10-1 自编码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 导入MINST 数据集</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义网络模型</p>
<p>下面输入MNIST数据集的图片，将其像素点组成的数据（28×28=784）从784维降维到256，然后再降到128，最后再以同样的方式经过128再经过256，最终还原到原来的图片，其过程如图10-2所示。</p>
<p><img src="Image00202.jpg" alt></p>
<p>图10-2 自编码实例代码的维度变化过程</p>
<p>定义网络模型的具体代码如下。</p>
<p>代码10-1 自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = 0.01</span><br><span class="line">n_hidden_1 = 256                             # 第一层256个节点</span><br><span class="line">n_hidden_2 = 128                             # 第二层128个节点</span><br><span class="line">n_input = 784                                  # MNIST 数据集中图片的维度</span><br><span class="line"></span><br><span class="line"># 占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_input])     #输入</span><br><span class="line">y = x                                                    #输出</span><br><span class="line"></span><br><span class="line">#学习参数</span><br><span class="line">weights = &#123;</span><br><span class="line">    &apos;encoder_h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_</span><br><span class="line">   1])),</span><br><span class="line">    &apos;encoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_</span><br><span class="line">   2])),</span><br><span class="line">    &apos;decoder_h1&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_</span><br><span class="line">   1])),</span><br><span class="line">    &apos;decoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_</span><br><span class="line">   input])),</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    &apos;encoder_b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;encoder_b2&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    &apos;decoder_b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;decoder_b2&apos;: tf.Variable(tf.zeros([n_input])),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 编码</span><br><span class="line">def encoder(x):</span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;encoder_</span><br><span class="line">   h1&apos;]),biases[&apos;encoder_b1&apos;]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights</span><br><span class="line">   [&apos;encoder_h2&apos;]), biases[&apos;encoder_b2&apos;]))</span><br><span class="line">    return layer_2</span><br><span class="line"></span><br><span class="line"># 解码</span><br><span class="line">def decoder(x):</span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;decoder_</span><br><span class="line">   h1&apos;]),biases[&apos;decoder_b1&apos;]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights</span><br><span class="line">   [&apos;decoder_h2&apos;]),biases[&apos;decoder_b2&apos;]))</span><br><span class="line">    return layer_2</span><br><span class="line"></span><br><span class="line">#输出的节点</span><br><span class="line">encoder_out = encoder(x)</span><br><span class="line">pred = decoder(encoder_out)</span><br><span class="line"></span><br><span class="line"># cost为y与pred的平方差</span><br><span class="line">cost = tf.reduce_mean(tf.pow(y -pred, 2))</span><br><span class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码里先定义了学习率为0.01，这个值可以动态调节，会直接影响到收敛速度和学习的准确性，由于输出标签也是输入标签，所以后面直接定义y=x。</p>
<p>3．开始训练</p>
<p>接下来设置训练参数，一次取256条数据，将所有的训练数据集进行20次的迭代训练。</p>
<p>代码10-1 自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 训练参数</span><br><span class="line">training_epochs = 20             #一共迭代20次</span><br><span class="line">batch_size = 256               #每次取256个样本</span><br><span class="line">display_step = 5               #迭代5次输出一次信息</span><br><span class="line"></span><br><span class="line"># 启动会话</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">    # 开始训练</span><br><span class="line">    for epoch in range(training_epochs): #迭代</span><br><span class="line">      </span><br><span class="line">      for i in range(total_batch):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(batch_size)#取数据</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs&#125;)   # 训练模型</span><br><span class="line">        if epoch % display_step == 0: # 现实日志信息</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),&quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.</span><br><span class="line">           format(c))</span><br><span class="line">    print(&quot;完成!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>4．测试模型</p>
<p>接下来通过MNIST数据集中的test集来测试一下模型的准确度。</p>
<p>代码10-1 自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line"> # 计算错误率</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"> print (&quot;Accuracy:&quot;, 1-accuracy.eval(&#123;x: mnist.test.images, y: </span><br><span class="line">mnist.test.images&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>执行代码，信息输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.216481194</span><br><span class="line">Epoch: 0006 cost= 0.144190893</span><br><span class="line">Epoch: 0011 cost= 0.128914982</span><br><span class="line">Epoch: 0016 cost= 0.120772459</span><br><span class="line">完成!</span><br><span class="line">Accuracy: 0.885104</span><br></pre></td></tr></table></figure>

</details>

<p>上面的输出信息中，前面打印的是每一次迭代的错误率，最终输出的Accuracy指的是整个模型的正确率。</p>
<p>5．双比输入和输出</p>
<p>随意取出10张图片，比对一下输入与输出，可以看到自编码网络还原的图片与真实图片几乎一样。</p>
<p>代码10-1 自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 可视化结果</span><br><span class="line">    show_num = 10</span><br><span class="line">    reconstruction = sess.run(</span><br><span class="line">        pred, feed_dict=&#123;x: mnist.test.images[:show_num]&#125;)</span><br><span class="line">    f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(reconstruction[i], (28, 28)))</span><br><span class="line">    plt.draw()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，会生成如图10-3所示图片。图片分为上下两行，第一行显示的内容为输入图片，第二行显示的内容为输出图片。</p>
<p><img src="Image00203.jpg" alt></p>
<p>图10-3 自编码实例的输出结果</p>
<h4 id="10-3-2-线性解码器"><a href="#10-3-2-线性解码器" class="headerlink" title="10.3.2 线性解码器"></a>10.3.2 线性解码器</h4><p>在实例76中使用的激活函数为S型激活函数，输出范围是[0，1]，当我们对最终提取的特征节点采用该激励函数时，就相当于对输入限制或缩放，使其位于[0，1]范围中。有一些数据集，比如MNIST，能方便地将输出缩放到[0，1]中，但是很难满足对输入值的要求。例如，PCA白化处理的输入并不满足[0，1]范围要求，也不清楚是否有最好的办法可以将数据缩放到特定范围中。</p>
<p>如果利用一个恒等式来作为激励函数，就可以很好地解决这个问题，即将f（z）=z作为激励函数（即，没有激励函数）。</p>
<p><img src="Image00014.jpg" alt> 注意： 这个方法只是对最后的输出层而言，对于神经网络中隐含层的神经元依然还要使用S型（或者tanh）激励函数。</p>
<p>由多个带有S型激活函数的隐含层及一个线性输出层构成的自编码器，称为线性解码器。下面来看一个线性解码器的例子。</p>
<h4 id="10-3-3-实例77：提取图片的二维特征，并利用二维特征还原图片"><a href="#10-3-3-实例77：提取图片的二维特征，并利用二维特征还原图片" class="headerlink" title="10.3.3 实例77：提取图片的二维特征，并利用二维特征还原图片"></a>10.3.3 实例77：提取图片的二维特征，并利用二维特征还原图片</h4><p>本节用一个更为极致的例子来展示自编码网络的“威力”。将MNIST图片压缩成二维数据，这样也可以在直角坐标系上将其显示出来，让读者更形象地了解自编码网络在特征提取方面的功能。</p>
<p>实例描述</p>
<p>在自编码网络中使用线性解码器对MNIST数据特征进行再压缩，并将其映射到直角坐标系上。</p>
<p>这里使用4层逐渐压缩将784维度分别压缩成256、64、16、2这4个特征向量。编码部分的具体结构如图10-4所示。</p>
<p><img src="Image00204.jpg" alt></p>
<p>图10-4 线性解码器实例编码部分网络结构</p>
<p>然后以直角坐标系的形式将数据点显示出来，这样可以更直观地看到自编码器对于同一类图片的聚类效果。</p>
<p><img src="Image00014.jpg" alt> 说明： 如果读者想得到更好的特征提取效果，可以将压缩的层数变得更多，每层压缩一点点（如：512、256、128、64、32、16、2），由于Sigmoid函数的“天生”缺陷，无法使用更深的层，所以这里只能做成4层压缩。但不用担心，这个问题可以在学完本章内容之后得到一个满意的解决办法（使用栈式自编码器）。</p>
<p>在这个例子中分为如下几步来编写代码。</p>
<p>1．引入头文件，定义学习参数变量</p>
<p>由于要建立4层网络，所以要为每一层分配节点个数，学习参数。</p>
<p>代码10-2 自编码进阶</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># 导入MNIST数据集</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line"># 定义学习率</span><br><span class="line">learning_rate = 0.01    </span><br><span class="line"># 隐藏层设置</span><br><span class="line">n_hidden_1 = 256</span><br><span class="line">n_hidden_2 = 64</span><br><span class="line">n_hidden_3 = 16</span><br><span class="line">n_hidden_4 = 2</span><br><span class="line">n_input = 784  # MNIST data 输入(img shape: 28*28)</span><br><span class="line"></span><br><span class="line">#定义输入占位符</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None,n_input])</span><br><span class="line">y=x</span><br><span class="line">weights = &#123;</span><br><span class="line">    &apos;encoder_h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1],)),</span><br><span class="line">    &apos;encoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],)),</span><br><span class="line">    &apos;encoder_h3&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3],)),</span><br><span class="line">    &apos;encoder_h4&apos;: tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4],)),</span><br><span class="line"></span><br><span class="line">    &apos;decoder_h1&apos;: tf.Variable(tf.random_normal([n_hidden_4, n_hidden_3],)),</span><br><span class="line">    &apos;decoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_3, n_hidden_2],)),</span><br><span class="line">    &apos;decoder_h3&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1],)),</span><br><span class="line">    &apos;decoder_h4&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_input],)),</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">biases = &#123;</span><br><span class="line">    &apos;encoder_b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;encoder_b2&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    &apos;encoder_b3&apos;: tf.Variable(tf.zeros([n_hidden_3])),</span><br><span class="line">    &apos;encoder_b4&apos;: tf.Variable(tf.zeros([n_hidden_4])),</span><br><span class="line"></span><br><span class="line">    &apos;decoder_b1&apos;: tf.Variable(tf.zeros([n_hidden_3])),</span><br><span class="line">    &apos;decoder_b2&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    &apos;decoder_b3&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;decoder_b4&apos;: tf.Variable(tf.zeros([n_input])),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义网络模型</p>
<p>下面的代码是定义编码和解码的网络结构，这里使用了线性解码器。在编码的最后一层，没有进行Sigmoid变换，这是因为生成的二维数据其数据特征已经变得极为主要，所以我们希望让它透传到解码器中，少一些变换可以最大化地保存原有的主要特征。当然，这一切也是通过分析之后实际测试得来的结果。</p>
<p>代码10-2 自编码进阶（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">  def encoder(x):</span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;encoder_h1&apos;]),</span><br><span class="line">                                   biases[&apos;encoder_b1&apos;]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights</span><br><span class="line">   [&apos;encoder_h2&apos;]),</span><br><span class="line">                                   biases[&apos;encoder_b2&apos;]))</span><br><span class="line">    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights</span><br><span class="line">   [&apos;encoder_h3&apos;]),</span><br><span class="line">                                   biases[&apos;encoder_b3&apos;]))</span><br><span class="line">    layer_4 = tf.add(tf.matmul(layer_3, weights[&apos;encoder_h4&apos;]),</span><br><span class="line">                                    biases[&apos;encoder_b4&apos;])</span><br><span class="line">    return layer_4</span><br><span class="line"></span><br><span class="line">def decoder(x):</span><br><span class="line">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;decoder_h1&apos;]),</span><br><span class="line">                                   biases[&apos;decoder_b1&apos;]))</span><br><span class="line">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights</span><br><span class="line">   [&apos;decoder_h2&apos;]),</span><br><span class="line">                                   biases[&apos;decoder_b2&apos;]))</span><br><span class="line">    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights</span><br><span class="line">   [&apos;decoder_h3&apos;]),</span><br><span class="line">                                biases[&apos;decoder_b3&apos;]))</span><br><span class="line">    layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights</span><br><span class="line">   [&apos;decoder_h4&apos;]),</span><br><span class="line">                                biases[&apos;decoder_b4&apos;]))</span><br><span class="line">    return layer_4</span><br><span class="line"># 构建模型</span><br><span class="line">encoder_op = encoder(x) </span><br><span class="line">y_pred = decoder(encoder_op) # 784 维度</span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.pow(y -y_pred, 2))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>3．开始训练</p>
<p>这一步中还是一次取256条数据，将全部数据集迭代20次。</p>
<p>代码10-2 自编码进阶（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#训练</span><br><span class="line">training_epochs = 20 # 迭代训练20一次</span><br><span class="line">batch_size = 256</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">    # 启动循环开始训练</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  </span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),</span><br><span class="line">                  &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.format(c))</span><br><span class="line">    print(&quot;完成!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>输出结果如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.106694221</span><br><span class="line">Epoch: 0002 cost= 0.096146211</span><br><span class="line">Epoch: 0003 cost= 0.089687020</span><br><span class="line">Epoch: 0004 cost= 0.085342437</span><br><span class="line">Epoch: 0005 cost= 0.076942392</span><br><span class="line">Epoch: 0006 cost= 0.077152036</span><br><span class="line">Epoch: 0007 cost= 0.074504733</span><br><span class="line">Epoch: 0008 cost= 0.071438089</span><br><span class="line">Epoch: 0009 cost= 0.070937753</span><br><span class="line">Epoch: 0010 cost= 0.067885153</span><br><span class="line">Epoch: 0011 cost= 0.068935215</span><br><span class="line">Epoch: 0012 cost= 0.067724347</span><br><span class="line">Epoch: 0013 cost= 0.065405361</span><br><span class="line">Epoch: 0014 cost= 0.069433592</span><br><span class="line">Epoch: 0015 cost= 0.068582796</span><br><span class="line">Epoch: 0016 cost= 0.067146875</span><br><span class="line">Epoch: 0017 cost= 0.065363437</span><br><span class="line">Epoch: 0018 cost= 0.066899218</span><br><span class="line">Epoch: 0019 cost= 0.065677144</span><br><span class="line">Epoch: 0020 cost= 0.064701408</span><br><span class="line">完成!</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出，通过自编码网络将784维的数据压缩成了二维，用二维数据来代替784维，这就是自编码网络的神奇之处！</p>
<p>4．对比输入和输出</p>
<p>同样我们再添加一些代码将效果显示出来。随意取出10张图片，并将图片输入模型中，得到输出图片。同时比对一下输入与输出的图片。</p>
<p>代码10-2 自编码进阶（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 可视化结果</span><br><span class="line">show_num = 10</span><br><span class="line">encode_decode = sess.run(</span><br><span class="line">    y_pred, feed_dict=&#123;x: mnist.test.images[:show_num]&#125;)</span><br><span class="line"># 将自编码输出结果和原始样本显示出来</span><br><span class="line">f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">for i in range(show_num):</span><br><span class="line">    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如图10-5所示图片。</p>
<p><img src="Image00205.jpg" alt></p>
<p>图10-5 自编码进阶实例结果1</p>
<p>5．显示数据的二维特征</p>
<p>接着就是比较好玩的事情了。我们要把数据压缩后的二维特征显示出来。</p>
<p>代码10-2 自编码进阶（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> aa = [np.argmax(l)for l in mnist.test.labels]#将onehot转成一般编码</span><br><span class="line"> encoder_result = sess.run(encoder_op, feed_dict=&#123;x: mnist.test.</span><br><span class="line">images&#125;)</span><br><span class="line"> plt.scatter(encoder_result[:, 0], encoder_result[:, 1], c=aa)</span><br><span class="line"> plt.colorbar()</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如图10-6所示图片。</p>
<p><img src="Image00206.jpg" alt></p>
<p>图10-6 自编码进阶实例结果2</p>
<p>这样看这是不是直观多了！看了这个图你会有什么感觉，聚类？K均值？softmax？没错，一般来讲用自编码网络将数据降维之后的数据更有利于进行分类处理。</p>
<p><img src="Image00014.jpg" alt> 注意： 上面代码中的aa是将mnist.test.labels里面的one_hot转换成一般的数字，然后进行图像显示。这个代码建议读者把它收集起来，因为在深度学习过程中one_hot的互转会经常用到。另外，one_hot转码有多种方法，细心的读者可以在前面章节中找到更简洁的转换代码。</p>
<p>当然也可以不用这句代码，那么在最前面引入MNIST时就必须把onehot关掉，将</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>改成：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=False)</span><br></pre></td></tr></table></figure>

</details>

<p>同时将倒数第三句改成使用mnist的测试标签：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(encoder_result[:,0],encoder_result[:,1],c=mnist.test.labels)</span><br></pre></td></tr></table></figure>

</details>

<h4 id="10-3-4-实例78：实现卷积网络的自编码"><a href="#10-3-4-实例78：实现卷积网络的自编码" class="headerlink" title="10.3.4 实例78：实现卷积网络的自编码"></a>10.3.4 实例78：实现卷积网络的自编码</h4><p>自编码结构不仅只用在全连接网络上，还可用在卷积网络上。下面举例实现一个卷积网络的自编码。代码变化不大，是在原有的基础上将全连接改成卷积，具体改动步骤如下。</p>
<p>实例描述</p>
<p>在自编码网络中使用卷积网络完成MNIST的自编码功能。</p>
<p>1．修改网络权重定义</p>
<p>保持b不变，将原来的w改成卷积核的定义如下。</p>
<p>代码10-3 卷积网络自编码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">#学习参数</span><br><span class="line">weights = &#123;</span><br><span class="line">    &apos;encoder_conv1&apos;: tf.Variable(tf.truncated_normal([5, 5, 1, n_conv_</span><br><span class="line">   1],stddev=0.1)),</span><br><span class="line">    &apos;encoder_conv2&apos;: tf.Variable(tf.random_normal([3, 3, n_conv_1, n_</span><br><span class="line">   conv_2],stddev=0.1)),</span><br><span class="line">    &apos;decoder_conv1&apos;: tf.Variable(tf.random_normal([5, 5, 1, n_conv_</span><br><span class="line">   1],stddev=0.1)),</span><br><span class="line">    &apos;decoder_conv2&apos;: tf.Variable(tf.random_normal([3, 3, n_conv_1, n_</span><br><span class="line">   conv_2],stddev=0.1))</span><br><span class="line">&#125;</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>2．改变编码和解码结构</p>
<p>原来的编码器和解码器分别由全连接改成卷积和反卷积操作，通过外层的池化与反池化将整个网络贯穿起来。在网络入口处还要将输入的维度改成[-1，28，28，1]。</p>
<p>代码10-3 卷积网络自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">x_image = tf.reshape(x, [-1,28,28,1])</span><br><span class="line"># 编码</span><br><span class="line">def encoder(x):</span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x, weights[&apos;encoder_conv1&apos;]) + biases</span><br><span class="line">   [&apos;encoder_conv1&apos;])</span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_conv1, weights[&apos;encoder_conv2&apos;]) + </span><br><span class="line">   biases[&apos;encoder_conv2&apos;])  </span><br><span class="line">    return h_conv2,h_conv1</span><br><span class="line"></span><br><span class="line"># 解码</span><br><span class="line">def decoder(x,conv1):</span><br><span class="line">    t_conv1 = tf.nn.conv2d_transpose(x-biases[&apos;decoder_conv2&apos;],</span><br><span class="line">     weights[&apos;decoder_conv2&apos;], conv1.shape,[1,1,1,1])</span><br><span class="line">    t_x_image = tf.nn.conv2d_transpose(t_conv1-biases[&apos;decoder_</span><br><span class="line">   conv1&apos;], weights[&apos;decoder_conv1&apos;], x_image.shape,[1,1,1,1])</span><br><span class="line">    return t_x_image</span><br><span class="line"></span><br><span class="line">#输出的节点</span><br><span class="line">encoder_out,conv1 = encoder(x_image)</span><br><span class="line">h_pool2, mask = max_pool_with_argmax(encoder_out, 2)</span><br><span class="line"></span><br><span class="line">h_upool = unpool(h_pool2, mask, 2)</span><br><span class="line">pred = decoder(h_upool,conv1)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中用到的卷积函数和反池化函数，可以在8.4节和8.6节中查看具体实现过程。</p>
<p>3．测试及可视化部分改动</p>
<p>因为反池化的函数要求输入图片的一个维度不能为Nine，所以，需要把评估部分也改一下。</p>
<p>代码10-3 卷积网络自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 测试</span><br><span class="line">batch_xs, batch_ys = mnist.train.next_batch(batchsize)</span><br><span class="line">print (&quot;Error:&quot;, cost.eval(&#123;x: batch_xs&#125;))</span><br><span class="line">     </span><br><span class="line"># 可视化结果</span><br><span class="line">show_num = 10</span><br><span class="line">reconstruction = sess.run(</span><br><span class="line">    </span><br><span class="line">    pred, feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">     </span><br><span class="line">f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">for i in range(show_num):</span><br><span class="line">    </span><br><span class="line">    a[0][i].imshow(np.reshape(batch_xs[i], (28, 28)))</span><br><span class="line">    a[1][i].imshow(np.reshape(reconstruction[i], (28, 28)))</span><br><span class="line">plt.draw()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上面的代码，可以看到如下信息，生成的图片如图10-7所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 0.026543943</span><br><span class="line">Epoch: 0006 cost= 0.538754463</span><br><span class="line">Epoch: 0011 cost= 0.006631755</span><br><span class="line">Epoch: 0016 cost= 0.003391982</span><br><span class="line">完成!</span><br><span class="line">error: 0.0214768</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00207.jpg" alt></p>
<p>图10-7 卷积自编码网络实例</p>
<h4 id="10-3-5-练习题"><a href="#10-3-5-练习题" class="headerlink" title="10.3.5 练习题"></a>10.3.5 练习题</h4><p>仿照10.3.1节的例子，试着建立一个更深层的自编码，分为3层将图片压缩成512、256、128维度，然后再将其还原（可以参考本书配套代码的代码“10-4 自编码练习题.py”文件）。</p>
<h3 id="10-4-去噪自编码"><a href="#10-4-去噪自编码" class="headerlink" title="10.4 去噪自编码"></a>10.4 去噪自编码</h3><p>要想取得好的特征只靠重构输入数据是不够的，在实际应用中，还需要让这些特征具有抗干扰的能力，即当输入数据发生一定程度的扰动时，生成的特征仍然保持不变。这时需要添加噪声来为模型增加更大的困难。在这种情况下训练出来的模型才会有更好的鲁棒性，于是就有了本节所介绍的去噪自动编码器。</p>
<p>去噪自动编码器（Denoising Autoencoder，DA），是在自动编码的基础上，训练数据加入噪声，输出的标签仍是原始的样本（没有加过噪声的），这样自动编码器必须学习去除噪声而获得真正的没有被噪声污染过的输入特征。因此，这就迫使编码器去学习输入信号的更加鲁棒的特征表达，即具有更加强悍的泛化能力。</p>
<p>在实际训练中，人为加入的噪声有两种途径：</p>
<p>（1）在选择训练数据集时，额外选择一些样本集以外的数据。</p>
<p>（2）改变已有的样本数据集中的数据（使样本个体不完整，或通过噪声与样本进行的加减乘除之类的运算，使样本数据发生变化）。</p>
<h3 id="10-5-去噪自编码网络的代码实现"><a href="#10-5-去噪自编码网络的代码实现" class="headerlink" title="10.5 去噪自编码网络的代码实现"></a>10.5 去噪自编码网络的代码实现</h3><p>下面进入实例环节，通过例子来构建一个去噪自编码网络。</p>
<h4 id="10-5-1-实例79：使用去噪自编码网络提取MNIST特征"><a href="#10-5-1-实例79：使用去噪自编码网络提取MNIST特征" class="headerlink" title="10.5.1 实例79：使用去噪自编码网络提取MNIST特征"></a>10.5.1 实例79：使用去噪自编码网络提取MNIST特征</h4><p>本节做一个更简单的自编码模型，让784维只通过一层压缩成256维。与前面例子唯一不同的是，将原始的数据进行一些变换，每个像素点都乘以一个高斯噪声，然后在输出的位置仍然使用原始的输入样本，这样迫使网络在提取特征的同时将噪声去掉。为了防止其过拟合，还需要在其中加入Dropout层。</p>
<p>在这个例子中分为如下几个步骤来编写代码。</p>
<p>实例描述</p>
<p>对MNIST集原始输入图片加入噪声，在自编码网络中进行训练，以得到抗干扰更强的特征提取模型。</p>
<p>1．引入头文件，创建网络模型及定义学习参数变量</p>
<p>代码10-5 去噪声自编码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"> import numpy as np</span><br><span class="line"> import tensorflow as tf</span><br><span class="line"> import matplotlib.pyplot as plt</span><br><span class="line"> from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"> </span><br><span class="line"> mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"> </span><br><span class="line"> train_X   = mnist.train.images</span><br><span class="line"> train_Y = mnist.train.labels</span><br><span class="line"> test_X    = mnist.test.images</span><br><span class="line"> test_Y  = mnist.test.labels</span><br><span class="line"> </span><br><span class="line"> n_input    = 784 </span><br><span class="line"> n_hidden_1 = 256 </span><br><span class="line">  </span><br><span class="line"> # 占位符</span><br><span class="line"> x = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line"> y = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line"> dropout_keep_prob = tf.placeholder(&quot;float&quot;)</span><br><span class="line"> </span><br><span class="line"> #学习参数</span><br><span class="line"> weights = &#123;</span><br><span class="line">     &apos;h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">     &apos;h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_1])),</span><br><span class="line">     &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_input]))</span><br><span class="line"> &#125;</span><br><span class="line"> biases = &#123;</span><br><span class="line">     &apos;b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">     &apos;b2&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">     &apos;out&apos;: tf.Variable(tf.zeros([n_input]))</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> # 网络模型</span><br><span class="line"> def denoise_auto_encoder(_X, _weights, _biases, _keep_prob):</span><br><span class="line">     layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights[&apos;h1&apos;]), </span><br><span class="line">    _biases[&apos;b1&apos;])) </span><br><span class="line">     layer_1out = tf.nn.dropout(layer_1, _keep_prob) </span><br><span class="line">     layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1out, _weights</span><br><span class="line">    [&apos;h2&apos;]), _biases[&apos;b2&apos;])) </span><br><span class="line">     layer_2out = tf.nn.dropout(layer_2, _keep_prob) </span><br><span class="line">     return tf.nn.sigmoid(tf.matmul(layer_2out, _weights[&apos;out&apos;]) + </span><br><span class="line">    _biases[&apos;out&apos;])</span><br><span class="line"> </span><br><span class="line"> reconstruction = denoise_auto_encoder(x, weights, biases, dropout_</span><br><span class="line">keep_prob)</span><br><span class="line"> </span><br><span class="line"> # COST计算</span><br><span class="line"> cost = tf.reduce_mean(tf.pow(reconstruction-y, 2))</span><br><span class="line"> # 优化器</span><br><span class="line"> optm = tf.train.AdamOptimizer(0.01).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，在定义学习参数时，加了dropout的学习参数，因为后面要为网络添加dropout层。</p>
<p>2．设置训练参数，开始训练</p>
<p>这一步还和前面例子一样，重点看下一步的变化。</p>
<p>代码10-5 去噪声自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#训练参数</span><br><span class="line">epochs     = 20</span><br><span class="line">batch_size = 256</span><br><span class="line">disp_step  = 2</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print (&quot;开始训练&quot;)</span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = 0.</span><br><span class="line">        for i in range(num_batch):</span><br></pre></td></tr></table></figure>

</details>

<p>3．生成噪声数据</p>
<p>在这里做了添加噪声的操作，每次取出一批次的数据，将输入数据的每一个像素都加上0.3倍的高斯噪声。</p>
<p>代码10-5 去噪声自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            batch_xs_noisy = batch_xs + 0.3*np.random.randn(batch_size, 784)</span><br><span class="line">            feeds = &#123;x: batch_xs_noisy, y: batch_xs, dropout_keep_prob: 1.&#125;</span><br><span class="line">            sess.run(optm, feed_dict=feeds)</span><br><span class="line">            total_cost += sess.run(cost, feed_dict=feeds)</span><br><span class="line">            </span><br><span class="line">        # 显示训练日志</span><br><span class="line">        if epoch % disp_step == 0:</span><br><span class="line">            print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    print (&quot;完成&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">开始训练</span><br><span class="line">Epoch 00/20 average cost: 0.097613</span><br><span class="line">Epoch 02/20 average cost: 0.073714</span><br><span class="line">Epoch 04/20 average cost: 0.068687</span><br><span class="line">Epoch 06/20 average cost: 0.065391</span><br><span class="line">Epoch 08/20 average cost: 0.063086</span><br><span class="line">Epoch 10/20 average cost: 0.062062</span><br><span class="line">Epoch 12/20 average cost: 0.061144</span><br><span class="line">Epoch 14/20 average cost: 0.060415</span><br><span class="line">Epoch 16/20 average cost: 0.060192</span><br><span class="line">Epoch 18/20 average cost: 0.059686</span><br><span class="line">完成</span><br></pre></td></tr></table></figure>

</details>

<p>4．数据可视化</p>
<p>接下来是数据可视化部分，接着添加以下代码。</p>
<p>代码10-5 去噪声自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> show_num = 10</span><br><span class="line"> test_noisy = mnist.test.images[:show_num] + 0.3*np.random.randn</span><br><span class="line">(show_num, 784)</span><br><span class="line"> encode_decode = sess.run(</span><br><span class="line">     reconstruction, feed_dict=&#123;x: test_noisy, dropout_keep_prob: 1.&#125;)</span><br><span class="line"> f, a = plt.subplots(3, 10, figsize=(10, 3))</span><br><span class="line"> for i in range(show_num):</span><br><span class="line">     a[0][i].imshow(np.reshape(test_noisy[i], (28, 28)))</span><br><span class="line">     a[1][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">     a[2][i].matshow(np.reshape(encode_decode[i], (28, 28)), cmap=</span><br><span class="line">    plt.get_cmap(&apos;gray&apos;))</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如图10-8所示图片。</p>
<p><img src="Image00208.jpg" alt></p>
<p>图10-8 去噪自编码结果1</p>
<p>第一行图片是加入噪声后的输入，第二行图片是原始的样本（在这里作为标签），最后一行是输出。这里为了让结果看起来明显一些，将输出以灰色的图来显示。可以看出，输出的图片还能看出原来的样子，而且基本上将前面的噪声大部分都过滤掉了。</p>
<p>5．测试鲁棒性</p>
<p>为了测试模型的鲁棒性，我们换一种噪声方式，然后再生成一个样本测试效果（接着上面的sess）。</p>
<p>代码10-5 去噪声自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> randidx   = np.random.randint(test_X.shape[0], size=1)</span><br><span class="line"> orgvec    = test_X[randidx, :]</span><br><span class="line"> testvec   = test_X[randidx, :]</span><br><span class="line"> label     = np.argmax(test_Y[randidx, :], 1)</span><br><span class="line"> </span><br><span class="line"> print (&quot;label is %d&quot; % (label)) </span><br><span class="line"> # 噪音类型</span><br><span class="line"> print (&quot;Salt and Pepper Noise&quot;)</span><br><span class="line"> noisyvec = testvec</span><br><span class="line"> rate     = 0.15</span><br><span class="line"> noiseidx = np.random.randint(test_X.shape[1]</span><br><span class="line">                              , size=int(test_X.shape[1]*rate))</span><br><span class="line"> noisyvec[0, noiseidx] = 1-noisyvec[0, noiseidx]    </span><br><span class="line"> outvec   = sess.run(reconstruction, feed_dict=&#123;x: noisyvec,</span><br><span class="line">  dropout_keep_prob: 1&#125;)</span><br><span class="line"> outimg   = np.reshape(outvec, (28, 28))</span><br><span class="line"> </span><br><span class="line"> # 可视化</span><br><span class="line"> plt.matshow(np.reshape(orgvec, (28, 28)), cmap=plt.get_cmap(&apos;gray&apos;))</span><br><span class="line"> plt.title(&quot;Original Image&quot;)</span><br><span class="line"> plt.colorbar()</span><br><span class="line"> </span><br><span class="line"> plt.matshow(np.reshape(noisyvec, (28, 28)), cmap=plt.get_cmap</span><br><span class="line">(&apos;gray&apos;))</span><br><span class="line"> plt.title(&quot;Input Image&quot;)</span><br><span class="line"> plt.colorbar()</span><br><span class="line"> </span><br><span class="line"> plt.matshow(outimg, cmap=plt.get_cmap(&apos;gray&apos;))</span><br><span class="line"> plt.title(&quot;Reconstructed Image&quot;)</span><br><span class="line"> plt.colorbar()</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，会生成如下信息，生成的图片如图10-9所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label is 9</span><br><span class="line">Salt and Pepper Noise</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00209.jpg" alt></p>
<p>图10-9 去噪自编码结果2</p>
<p>可以看出，使用Salt and Pepper噪声对原始图片进行干扰后，仍然可以得到很好的效果。</p>
<h4 id="10-5-2-练习题"><a href="#10-5-2-练习题" class="headerlink" title="10.5.2 练习题"></a>10.5.2 练习题</h4><p>试着将dropout的值改成0.5，看一下模型训练出来的样子，然后再将Salt and Pepper噪声变换后的图片放到模型里，观察输出的图片。想想这是为什么？为什么要在去噪声自编码网络里加入dropout。</p>
<h3 id="10-6-栈式自编码"><a href="#10-6-栈式自编码" class="headerlink" title="10.6 栈式自编码"></a>10.6 栈式自编码</h3><p>接下来一起看看什么是栈式自编码。</p>
<h4 id="10-6-1-栈式自编码介绍"><a href="#10-6-1-栈式自编码介绍" class="headerlink" title="10.6.1 栈式自编码介绍"></a>10.6.1 栈式自编码介绍</h4><p>栈式自编码神经网络（Stacked Autoencoder，SA），是对自编码网络的一种使用方法，是一个由多层训练好的自编码器组成的神经网络。由于网络中的每一层都是单独训练而来，相当于都初始化了一个合理的数值。所以，这样的网络会更容易训练，并且有更快的收敛性及更高的准确度。</p>
<p>栈式自编码常常被用于预训练（初始化）深度神经网络之前的权重预训练步骤。例如，在一个分类问题上，可以按照从前向后的顺序执行每一层通过自编码器来训练，最终将网络中最深层的输出作为softmax分类器的输入特征，通过softmax层将其分开。</p>
<p>为了使这个过程容易理解，下面以训练一个包含两个隐含层的栈式自编码网络为例，一步一步为大家介绍具体操作。</p>
<p>（1）训练一个自编码器，得到原始输入的一阶特征表示h（1） （如图10-10中的features1所示）。</p>
<p><img src="Image00210.jpg" alt></p>
<p>图10-10 栈式自编码一层结构</p>
<p>（2）将上一步输出的特征h（1） 作为输入，对其进行再一次的自编码，并同时获取特征h（2） （如图10-11中的featuresII所示）。</p>
<p><img src="Image00211.jpg" alt></p>
<p>图10-11 栈式自编码二层结构</p>
<p>（3）把上一步的特征h（2） 连上softmax分类器，得到了一个图片数字标签分类的模型，具体网络结构如图10-12所示。</p>
<p><img src="Image00212.jpg" alt></p>
<p>图10-12 栈式自编码三层结构</p>
<p>（4）把这3层结合起来，就构成了一个包含两个隐藏层加一个softmax的栈式自编码网络，它可以对数字图片分类。具体网络结构如图10-13所示。</p>
<p><img src="Image00213.jpg" alt></p>
<p>图10-13 栈式自编码级联结构</p>
<h4 id="10-6-2-栈式自编码在深度学习中的意义"><a href="#10-6-2-栈式自编码在深度学习中的意义" class="headerlink" title="10.6.2 栈式自编码在深度学习中的意义"></a>10.6.2 栈式自编码在深度学习中的意义</h4><p>看到这里或许有读者会有疑问，为什么要这么麻烦，直接使用多层神经网络来训练不是也可以吗？在这里是为大家介绍一种训练方法，而这个训练更像是手动训练，之所以我们愿意这么麻烦，主要是因为其有以下几个优点：</p>
<p>·每一层都可以单独训练，保证降维特征的可控性。</p>
<p>·对于高维度的分类问题，一下拿出一套完整可用的模型相对来讲并不是容易的事，因为节点太多，参数太多，一味地增加深度只会使结果越来越不可控，成为测底的黑盒，而使用栈式自编码逐层降维，可以将复杂问题简单化，更容易完成任务。</p>
<p>·任意深层，理论上是越深层的神经网络对现实的拟合度越高，但是传统的多层神经网络，由于使用的是误差反向传播方式，导致层越深，传播的误差越小。栈式自编码巧妙地绕过这个问题，直接使用降维后的特征值进行二次训练，可以任意层数的加深。</p>
<p>栈式自编码神经网络具有强大的表达能力和深度神经网络的所有优点，它通常能够获取到输入的“层次型分组”或者“部分-整体分解”结构，自编码器倾向于学习得到与样本相对应的低维向量，该向量可以更好地表示高维样本的数据特征。</p>
<p>如果网络输入的是图像，第一层会学习去识别边，二层会学习组合边、构成轮廓角等，更高层会学习组合更形象的特征。例如，人脸图像，学习如何识别眼睛、鼻子、嘴等。</p>
<h3 id="10-7-深度学习中自编码的常用方法"><a href="#10-7-深度学习中自编码的常用方法" class="headerlink" title="10.7 深度学习中自编码的常用方法"></a>10.7 深度学习中自编码的常用方法</h3><p>下面介绍深度学习中关于自编码的常用方法。</p>
<h4 id="10-7-1-代替和级联"><a href="#10-7-1-代替和级联" class="headerlink" title="10.7.1 代替和级联"></a>10.7.1 代替和级联</h4><p>栈式自编码会将网络中的中间层作为下一个网络的输入进行训练。我们可以得到网络中每一个中间层的原始值，为了能有更好的效果，还可以使用级联的方式进一步优化网络参数。</p>
<p>在已有的模型上接着优化参数的步骤习惯上称为“微调”。该方法不仅在自编码网络，在整个深度学习里都是常见的技术。</p>
<p>在什么时候应用微调呢？通常仅在有大量已标注训练数据的情况下使用。在这样的情况下，微调能显著提升分类器性能。但如果有大量未标注数据集（用于非监督特征学习/预训练），却只有相对较少的已标注训练集，则微调的作用非常有限。</p>
<h4 id="10-7-2-自编码的应用场景"><a href="#10-7-2-自编码的应用场景" class="headerlink" title="10.7.2 自编码的应用场景"></a>10.7.2 自编码的应用场景</h4><p>本章使用MNIST举例，主要是为了得到一个很好的可视化效果。但在实际应用中，全连接的自编码网络并不适合处理图片类问题，原因在第8章的开头部分已经讲过了，这里不再赘述。</p>
<p>自编码更像是一种技巧，任何一种网络及方法不可能不变化就可以满足所有的问题，现实环境中，需要使用具体的模型配合各种技巧来解决问题。明白其原理，知道它的优、劣势才是核心。在任何一个多维数据的分类中也可以用自编码，或在大型图片文类任务中，卷积池化后的特征数据进行自编码降维也是一个好方法。</p>
<h3 id="10-8-去噪自编码与栈式自编码的综合实现"><a href="#10-8-去噪自编码与栈式自编码的综合实现" class="headerlink" title="10.8 去噪自编码与栈式自编码的综合实现"></a>10.8 去噪自编码与栈式自编码的综合实现</h3><p>本节将前面的知识综合一下，实现一个把去噪自编码加入栈式自编码网络中的例子。</p>
<h4 id="10-8-1-实例80：实现去噪自编码"><a href="#10-8-1-实例80：实现去噪自编码" class="headerlink" title="10.8.1 实例80：实现去噪自编码"></a>10.8.1 实例80：实现去噪自编码</h4><p>这次我们把前面所学的知识全部用上一起做一个综合的实例。首先建立一个去噪自编码，然后再对第一层的输出做一次简单的自编码压缩，然后再将第二层的输出做一个softmax的分类，最后，把这3个网络里的中间层拿出来，组成一个新的网络进行微调。下面就来一一操作。</p>
<p>1．引入头文件，创建网络模型及定义学习参数变量</p>
<p>实例描述</p>
<p>对MNIST集中的原始输入图片加入噪声，在自编码网络中进行训练，得到抗干扰更强的特征提取模型。</p>
<p>引入头文件，创建MINST数据集。</p>
<p>代码10-6 自编码综合</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line">train_X   = mnist.train.images</span><br><span class="line">train_Y = mnist.train.labels</span><br><span class="line">test_X    = mnist.test.images</span><br><span class="line">test_Y  = mnist.test.labels</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义占位符</p>
<p>最终训练的网络为一个输入、一个输出和两个隐藏层，结构如图10-14所示。</p>
<p><img src="Image00214.jpg" alt></p>
<p>图10-14 自编码综合实例结构</p>
<p>在这个例子中要建立4个网络：每一层都用一个网络来训练，于是我们需要训练3个网络，最后再把训练好的各个层组合到一起，形成第4个网络。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># NETOWRK PARAMETERS</span><br><span class="line">n_input    = 784 </span><br><span class="line">n_hidden_1 = 256             #第一层自编码</span><br><span class="line">n_hidden_2 = 128             #第二层自编码</span><br><span class="line">n_classes = 10</span><br><span class="line"></span><br><span class="line"># 占位符</span><br><span class="line"># 第一层输入</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line">dropout_keep_prob = tf.placeholder(&quot;float&quot;)</span><br><span class="line">#第二层输入</span><br><span class="line">l2x = tf.placeholder(&quot;float&quot;, [None, n_hidden_1])</span><br><span class="line">l2y = tf.placeholder(&quot;float&quot;, [None, n_hidden_1]) </span><br><span class="line">#第三层输入</span><br><span class="line">l3x = tf.placeholder(&quot;float&quot;, [None, n_hidden_2])</span><br><span class="line">l3y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义学习参数</p>
<p>除了输入层，后面的其他三层（256、128、10）每一层都需要单独使用一个自编码网络来训练，所以要为这3个网络创建3套学习参数。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># WEIGHTS</span><br><span class="line">weights = &#123;</span><br><span class="line">    #网络1  784-256-784</span><br><span class="line">    &apos;h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">    &apos;l1_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_1])),</span><br><span class="line">    &apos;l1_out&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_input])),</span><br><span class="line">    #网络2  256-128-256</span><br><span class="line">    &apos;l2_h1&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    &apos;l2_h2&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_2])),</span><br><span class="line">    &apos;l2_out&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),</span><br><span class="line">    #网络3  128-10</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    &apos;b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;l1_b2&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;l1_out&apos;: tf.Variable(tf.zeros([n_input])),</span><br><span class="line">    </span><br><span class="line">    &apos;l2_b1&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    &apos;l2_b2&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line">    &apos;l2_out&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    </span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.zeros([n_classes]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>

<p>4．第1层网络结构</p>
<p>为第1层建立一个自编码网络，并定义其网络结构。这里注意，由于要往第1层里加入噪声，所以第1层需要有dropout层。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> #第1层的编码输出</span><br><span class="line"> l1_out = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;h1&apos;]), biases</span><br><span class="line">[&apos;b1&apos;])) </span><br><span class="line">     </span><br><span class="line"> #l1 解码器MODEL</span><br><span class="line"> def noise_l1_autodecoder(layer_1, _weights, _biases, _keep_prob):</span><br><span class="line">     layer_1out = tf.nn.dropout(layer_1, _keep_prob) </span><br><span class="line">     layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1out, _weights</span><br><span class="line">    [&apos;l1_h2&apos;]), _biases[&apos;l1_b2&apos;])) </span><br><span class="line">     layer_2out = tf.nn.dropout(layer_2, _keep_prob) </span><br><span class="line">     return tf.nn.sigmoid(tf.matmul(layer_2out, _weights[&apos;l1_out&apos;]) + </span><br><span class="line">    _biases[&apos;l1_out&apos;])</span><br><span class="line"> </span><br><span class="line"> # 第一层的解码输出</span><br><span class="line"> l1_reconstruction = noise_l1_autodecoder(l1_out, weights, biases, </span><br><span class="line">dropout_keep_prob)</span><br><span class="line"> </span><br><span class="line"> # 计算COST</span><br><span class="line"> l1_cost = tf.reduce_mean(tf.pow(l1_reconstruction-y, 2))</span><br><span class="line"> # OPTIMIZER</span><br><span class="line"> l1_optm = tf.train.AdamOptimizer(0.01).minimize(l1_cost)</span><br></pre></td></tr></table></figure>

</details>

<p>5．第2层网络结构</p>
<p>为第2层建立一个自编码网络，并定义其网络结构。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> #l2 解码器MODEL</span><br><span class="line"> def l2_autodecoder(layer1_2, _weights, _biases):</span><br><span class="line">     layer1_2out = tf.nn.sigmoid(tf.add(tf.matmul(layer1_2, _weights</span><br><span class="line">    [&apos;l2_h2&apos;]), _biases[&apos;l2_b2&apos;])) </span><br><span class="line">     return tf.nn.sigmoid(tf.matmul(layer1_2out, _weights[&apos;l2_out&apos;]) + </span><br><span class="line">    _biases[&apos;l2_out&apos;])</span><br><span class="line"> </span><br><span class="line"> #第二层的编码输出</span><br><span class="line"> l2_out = tf.nn.sigmoid(tf.add(tf.matmul(l2x, weights[&apos;l2_h1&apos;]), </span><br><span class="line">biases[&apos;l2_b1&apos;])) </span><br><span class="line"> # 第二层的解码输出</span><br><span class="line"> l2_reconstruction = l2_autodecoder(l2_out, weights, biases)</span><br><span class="line"> </span><br><span class="line"> # COST计算</span><br><span class="line"> l2_cost = tf.reduce_mean(tf.pow(l2_reconstruction-l2y, 2))</span><br><span class="line"> # 优化器</span><br><span class="line"> optm2 = tf.train.AdamOptimizer(0.01).minimize(l2_cost)</span><br></pre></td></tr></table></figure>

</details>

<p>6．第3层网络结构</p>
<p>为第3层建立一个自编码网络，并定义其网络结构。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> l3_out = tf.matmul(l3x, weights[&apos;out&apos;]) + biases[&apos;out&apos;]</span><br><span class="line"> l3_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits</span><br><span class="line">(logits=l3_out, labels=l3y))</span><br><span class="line"> l3_optm = tf.train.AdamOptimizer(0.01).minimize(l3_cost)</span><br></pre></td></tr></table></figure>

</details>

<p>7．定义级联网络结构</p>
<p>将3层网络级联在一起，建立第4个网络，并定义其网络结构。这里复用了l1_out的节点，因为它是第1层的输出，其输入数据也是原始样本，与级联网络结构里的第一层一样，其他几层则需要重新定义。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> #3层 级联</span><br><span class="line"> #1联2</span><br><span class="line"> l1_l2out = tf.nn.sigmoid(tf.add(tf.matmul(l1_out, weights[&apos;l2_h1&apos;]), </span><br><span class="line">biases[&apos;l2_b1&apos;])) </span><br><span class="line"> # 2联3</span><br><span class="line"> pred = tf.matmul(l1_l2out, weights[&apos;out&apos;]) + biases[&apos;out&apos;]</span><br><span class="line"> # 定义loss和优化器</span><br><span class="line"> cost3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits</span><br><span class="line">(logits=pred, labels=l3y))</span><br><span class="line"> optm3 = tf.train.AdamOptimizer(0.001).minimize(cost3)</span><br></pre></td></tr></table></figure>

</details>

<p>8．第1层网络训练</p>
<p>网络结构定义好之后，下面开始第1层网络的训练。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">epochs = 50</span><br><span class="line">batch_size = 100</span><br><span class="line">disp_step  = 10</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    print (&quot;开始训练&quot;)</span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = 0.</span><br><span class="line">        for i in range(num_batch):</span><br><span class="line">           batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">           batch_xs_noisy = batch_xs + 0.3*np.random.randn(batch_size, 784)</span><br><span class="line">           feeds = &#123;x: batch_xs_noisy, y: batch_xs, dropout_keep_prob: 0.5&#125;</span><br><span class="line">           sess.run(l1_optm, feed_dict=feeds)</span><br><span class="line">           total_cost += sess.run(l1_cost, feed_dict=feeds)</span><br><span class="line">        # DISPLAY</span><br><span class="line">        if epoch % disp_step == 0:</span><br><span class="line">            print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    print (&quot;完成&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">开始训练</span><br><span class="line">Epoch 00/50 average cost: 0.113718</span><br><span class="line">Epoch 10/50 average cost: 0.035614</span><br><span class="line">Epoch 20/50 average cost: 0.033097</span><br><span class="line">Epoch 30/50 average cost: 0.032123</span><br><span class="line">Epoch 40/50 average cost: 0.031541</span><br><span class="line">完成</span><br></pre></td></tr></table></figure>

</details>

<p>从测试数据集中拿出10个样本放到模型里，将生成的结果可视化。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">show_num = 10</span><br><span class="line">    test_noisy = mnist.test.images[:show_num] + 0.3*np.random.randn</span><br><span class="line">   (show_num, 784)</span><br><span class="line">    encode_decode = sess.run(</span><br><span class="line">        l1_reconstruction, feed_dict=&#123;x: test_noisy, dropout_keep_</span><br><span class="line">       prob: 1.&#125;)</span><br><span class="line">    f, a = plt.subplots(3, 10, figsize=(10, 3))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(test_noisy[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">        a[2][i].matshow(np.reshape(encode_decode[i], (28, 28)), </span><br><span class="line">       cmap=plt.get_cmap(&apos;gray&apos;))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如图10-15所示信息。</p>
<p><img src="Image00215.jpg" alt></p>
<p>图10-15 自编码综合实例第1层结果</p>
<p>为什么这次的还原数据几乎将噪声全部过滤了呢？还记得去噪自编码那一章的练习题吗？这就是dropout的效果。仔细看，这次dropout的值设成了0.5，意味着有一半的节点是丢弃的，所以才会得到更好的拟合效果。</p>
<p>9．第2层网络训练</p>
<p>下面开始训练第2层网络。需要注意的地方是，这个网络模型的输入已经不再是我们的MNIST图片了，而是上一层的输出，所以在准备输入数据时，要让输入的数据在上一层的模型中运算一次才可以作为本次的输入。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print (&quot;开始训练&quot;)</span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = 0.</span><br><span class="line">        for i in range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">            l1_h = sess.run(l1_out, feed_dict=&#123;x: batch_xs, y: batch_xs, </span><br><span class="line">           dropout_keep_prob: 1.&#125;)</span><br><span class="line">            _,l2cost = sess.run([optm2,l2_cost], feed_dict=&#123;l2x: l1_h, </span><br><span class="line">           l2y: l1_h &#125;)</span><br><span class="line">            total_cost += l2cost</span><br><span class="line">       </span><br><span class="line">       # log输出</span><br><span class="line">        if epoch % disp_step == 0:</span><br><span class="line">            print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    print (&quot;完成  layer_2 训练&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">开始训练</span><br><span class="line">Epoch 00/50 average cost: 0.126013</span><br><span class="line">Epoch 10/50 average cost: 0.019285</span><br><span class="line">Epoch 20/50 average cost: 0.014477</span><br><span class="line">Epoch 30/50 average cost: 0.012606</span><br><span class="line">Epoch 40/50 average cost: 0.012108</span><br><span class="line">完成  layer_2 训练</span><br></pre></td></tr></table></figure>

</details>

<p>同理，可视化部分也是这样，所有准备输入的点都要在模型1中生成一次，见以下代码。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> show_num = 10</span><br><span class="line"> testvec = mnist.test.images[:show_num]</span><br><span class="line"> out1vec = sess.run(l1_out, feed_dict=&#123;x: testvec,y: testvec, </span><br><span class="line">dropout_keep_prob: 1.&#125;)</span><br><span class="line"> out2vec = sess.run(l2_reconstruction, feed_dict=&#123;l2x: out1vec&#125;)</span><br><span class="line">     </span><br><span class="line"> f, a = plt.subplots(3, 10, figsize=(10, 3))</span><br><span class="line"> for i in range(show_num):</span><br><span class="line">     a[0][i].imshow(np.reshape(testvec[i], (28, 28)))</span><br><span class="line">     a[1][i].imshow(np.reshape(out1vec[i], (16, 16)))</span><br><span class="line">     a[2][i].matshow(np.reshape(out2vec[i], (16, 16)), cmap=plt.</span><br><span class="line">    get_cmap(&apos;gray&apos;))</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如图10-16所示信息。</p>
<p><img src="Image00216.jpg" alt></p>
<p>图10-16 自编码综合实例第2层结果</p>
<p>10．第3层网络训练</p>
<p>现在开始训练第3层的网络，同理，这次的输入数据要经过前面两层网络的运算才可以生成。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    print (&quot;开始训练&quot;)</span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = 0.</span><br><span class="line">        for i in range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size) </span><br><span class="line">            l1_h = sess.run(l1_out, feed_dict=&#123;x: batch_xs, y: batch_xs, </span><br><span class="line">           dropout_keep_prob: 1.&#125;)</span><br><span class="line">            l2_h = sess.run(l2_out, feed_dict=&#123;l2x: l1_h, l2y: l1_h &#125;)</span><br><span class="line">            _,l3cost = sess.run([l3_optm,l3_cost], feed_dict=&#123;l3x: l2_</span><br><span class="line">           h, l3y: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">            total_cost += l3cost</span><br><span class="line">        # 输出cost</span><br><span class="line">        if epoch % disp_step == 0:</span><br><span class="line">            print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    print (&quot;完成  layer_3 训练&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">开始训练</span><br><span class="line">Epoch 00/50 average cost: 1.379495</span><br><span class="line">Epoch 10/50 average cost: 0.277589</span><br><span class="line">Epoch 20/50 average cost: 0.271069</span><br><span class="line">Epoch 30/50 average cost: 0.269604</span><br><span class="line">Epoch 40/50 average cost: 0.269904</span><br><span class="line">完成  layer_3 训练</span><br></pre></td></tr></table></figure>

</details>

<p>11．栈式自编码网络验证</p>
<p>这次我们暂时略过对第3层网络模型的单独验证，直接去验证整个分类模型，将MNIST数据输入进去，看看栈式自编码器的分类效果如何。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 测试 model</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(l3y, 1))</span><br><span class="line">    # 计算准确率</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line">    print (&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, l3y: </span><br><span class="line">   mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 0.9213</span><br></pre></td></tr></table></figure>

</details>

<p>可以看出，直接将每层的训练参数堆起来，网络会有很好的表现。为了进一步优化，来看看下面的步骤。</p>
<p>12．级联微调</p>
<p>下面进入微调阶段，将网络模型联起来进行分类训练，这部分的测试代码与前面一样，所以这里只把训练部分的代码贴出来。</p>
<p>代码10-6 自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">   </span><br><span class="line">    print (&quot;开始训练&quot;)</span><br><span class="line">    for epoch in range(epochs):</span><br><span class="line">        num_batch  = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        total_cost = 0.</span><br><span class="line">        for i in range(num_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            </span><br><span class="line">            feeds = &#123;x: batch_xs, l3y: batch_ys&#125;</span><br><span class="line">            sess.run(optm3, feed_dict=feeds)</span><br><span class="line">            total_cost += sess.run(cost3, feed_dict=feeds)</span><br><span class="line">        # 输出cost</span><br><span class="line">        if epoch % disp_step == 0:</span><br><span class="line">            print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                   % (epoch, epochs, total_cost/num_batch))</span><br><span class="line">    print (&quot;完成  级联 训练&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">开始训练</span><br><span class="line">Epoch 00/50 average cost: 1.003439</span><br><span class="line">Epoch 10/50 average cost: 0.035012</span><br><span class="line">Epoch 20/50 average cost: 0.001034</span><br><span class="line">Epoch 30/50 average cost: 0.000112</span><br><span class="line">Epoch 40/50 average cost: 0.000039</span><br><span class="line">完成  级联训练</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到，由于网络模型中各层的初始值已经训练好了，所以开始就是很低的错误率，错误率接着每次的迭代都有很大幅度的下降。到此这个例子就算是完成了，该例已经非常接近真实工作中的场景了，读者学习时在跟着做例子的同时更要理解所使用的方法，它可以将任何复杂的任务化简。</p>
<p><img src="Image00014.jpg" alt> 提示： 搭建网络模型时，层数过多，参数也会随之增加，所以逻辑一定要清楚，一个好的命名规范可以让你在这个问题上轻松许多。</p>
<h4 id="10-8-2-实例81：添加模型存储支持分布训练"><a href="#10-8-2-实例81：添加模型存储支持分布训练" class="headerlink" title="10.8.2 实例81：添加模型存储支持分布训练"></a>10.8.2 实例81：添加模型存储支持分布训练</h4><p>栈式自编码的另一个优点就是可以将神经网络模块化，便于分工，非常适合团队合作。在实际中，为了得到更好的模型，需要将上述的每个环节分别单独训练，由不同的小组或人员来分步工作。</p>
<p>小组或人员之间的对接则需要通过模型文件来完成，这就要求每个环节的参数都必须保存下来，在自己的步骤开始之前先把上个步骤的环境加载进去。</p>
<p>实例描述</p>
<p>对自编码模型进行分布式模型存储与载入，使每一层都可以单个环节逐一训练。</p>
<p>可以修改上述代码，在训练开始前定义模型保存参数。</p>
<p>代码10-7 分布自编码综合</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">savedir = &quot;d:/python/log/&quot;</span><br><span class="line">saver   = tf.train.Saver(max_to_keep=1)  #保存一个模型</span><br><span class="line">load_epoch = 49</span><br><span class="line">print (savedir)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>在每个训练迭代之后都将模型保存起来。</p>
<p>代码10-7 分布自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> if epoch % disp_step == 0:</span><br><span class="line">             print (&quot;Epoch %02d/%02d average cost: %.6f&quot; </span><br><span class="line">                    % (epoch, epochs, total_cost/num_batch))</span><br><span class="line"> saver.save(sess, savedir + &apos;stacked_auto_encoder.ckpt&apos;, global_</span><br><span class="line">step=epoch)</span><br><span class="line">     print (&quot;完成  级联 训练&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>在每次训练的开始将模型读入（第一个网络不需要读入）。</p>
<p>代码10-7 分布自编码综合（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver.restore(sess, savedir +&quot;stacked_auto_encoder.ckpt-&quot; + </span><br><span class="line">   str(load_epoch))</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 这里给出的代码是按照迭代保存的。这是一种好习惯，尤其在训练海量数据时，由于某种意外导致训练终止，使所有的训练结果丢失，还得需要花大量的时间重新训练。这种方法可以恢复到上一次迭代的结果。</p>
<p>加完这些代码之后，就可以将上面的代码放在一个文件里，通过注释的方式，按照步骤一步步往下进行了（每次只打开一个模型训练的代码）。</p>
<h4 id="10-8-3-小心分布训练中的“坑”"><a href="#10-8-3-小心分布训练中的“坑”" class="headerlink" title="10.8.3 小心分布训练中的“坑”"></a>10.8.3 小心分布训练中的“坑”</h4><p>如果读者是使用Anaconda在Windows下运行，那么这里有个“坑”需要填一下。当加上保存模型的功能之后，在一步一步训练过程中，如果运行两次读取模型则会报错。更奇怪的事情是，在保存模型过程中，如果你第一次运行一半停止了，第二次运行成功并且也生成了模型，但是当你从模型里载入时，会是错误的参数。</p>
<p>原因是，在Anaconda中的py程序默认都是在同一个图中运行的，即除非关掉Anaconda，否则运行两次时，这两次的代码是在一个图中，那么会有什么影响呢？</p>
<p>在定义变量时，在同一个图中，同一句代码tf.Variable所生成的变量是不同的名字，例如在代码中添加打印信息，输出变量的名字：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 权重</span><br><span class="line">weights = &#123;</span><br><span class="line">    #网络1  784-256-784</span><br><span class="line">    &apos;h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),</span><br><span class="line">……</span><br><span class="line">print (weights[&apos;h1&apos;].name)</span><br></pre></td></tr></table></figure>

</details>

<p>执行上面的代码，生成如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Variable:0</span><br><span class="line">Variable:14</span><br></pre></td></tr></table></figure>

</details>

<p>这时会发现，运行两次weights[h1]有了两个不同的名字，在内存里会有两套变量。所以当运行两次后保存模型时，其实是保存了两套，但是读取时只是读取了第一套。同理。当运行两次读取时，第一次的模型可以与变量对应上，第二次会新生成另外一套变量，并且模型里找对应关系，但因为找不到所以就报错了。</p>
<p>解决方法：只需要在变量定义之前加上下面一行代码。让所有的图环境重置，即可解决问题。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br></pre></td></tr></table></figure>

</details>

<h4 id="10-8-4-练习题"><a href="#10-8-4-练习题" class="headerlink" title="10.8.4 练习题"></a>10.8.4 练习题</h4><p>使用栈式自编码对MNIST数据集逐层训练压缩特征，直到压缩成二维数据（如512、256、128、64、32、16、2），再将其图示出来。</p>
<h3 id="10-9-变分自编码"><a href="#10-9-变分自编码" class="headerlink" title="10.9 变分自编码"></a>10.9 变分自编码</h3><p>前面所描述的自编码可以降维重构样本，在这个基础上我们来学习一个更强大的自编码网络。</p>
<h4 id="10-9-1-什么是变分自编码"><a href="#10-9-1-什么是变分自编码" class="headerlink" title="10.9.1 什么是变分自编码"></a>10.9.1 什么是变分自编码</h4><p>变分自编码学习的不再是样本的个体，而是学习样本的规律。这样训练出来的自编码不单具有重构样本的功能，还具有仿照样本的功能。</p>
<p>听起来这么强大的功能，到底是怎么做到的呢？下面我们来讲讲它的原理。</p>
<p>变分自编码，其实就是在编码过程中改变了样本的分布（“变分”可以理解为改变分布）。前面所说的“学习样本的规律”，具体指的就是样本的分布，假设我们知道样本的分布函数，就可以从这个函数中随便取一个样本，然后进行网络解码层前向传导，这样就可以生成一个新的样本。</p>
<p>为了得到这个样本的分布函数，模型训练的目的将不再是样本本身，而是通过加一个约束项，将网络生成一个服从于高斯分布的数据集，这样按照高斯分布里的均值和方差规则就可以任意取相关的数据，然后通过解码层还原成样本。</p>
<h4 id="10-9-2-实例82：使用变分自编码模拟生成MNIST数据"><a href="#10-9-2-实例82：使用变分自编码模拟生成MNIST数据" class="headerlink" title="10.9.2 实例82：使用变分自编码模拟生成MNIST数据"></a>10.9.2 实例82：使用变分自编码模拟生成MNIST数据</h4><p>对于变分自编码，好多文献都给出了一堆晦涩难懂的公式，其实里面真正的公式只有一个——KL离散度的计算。而它也属于成熟的式子，就跟交叉熵一样，直接拿来用就可以。</p>
<p>公式本来是语言的高度概括，而如果一篇文章全是公式没有语言就会令人难以理解，本节会通过代码加上语言描述，让这部分知识学习起来不会感觉晦涩难懂。</p>
<p>本例共分如下几个步骤，下面就来一一操作。</p>
<p>实例描述</p>
<p>使用变分自编码模型进行模拟MNIST数据的生成。</p>
<p>1．引入库，定义占位符</p>
<p>本例建立的网络与之前略有不同，编码器为两个全连接层，第一个全连接层由784个维度的输入变化256个维度的输出；第二个全连接层并列连接了两个输出网络（mean与lg_var），每个网络都输出了两个维度的输出。然后将两个输出通过一个公式的计算，输入到以一个2节点为开始的解码部分，接着后面为两个全连接层的解码器，第一层由两个维度的输入到256个维度的输出，第二层由256个维度的输入到784个维度的输出，如图10-17所示。</p>
<p><img src="Image00217.jpg" alt></p>
<p>图10-17 变分自编码器层次</p>
<p>具体的计算公式，后面会有详细介绍。</p>
<p>在下面的代码中与前面代码不同，引入了一个scipy库，在后面可视化时会用到。头文件引入之后，定义操作符x和z。x用于原始的图片输入，z用于中间节点解码器的输入。</p>
<p>代码10-8 变分自编码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.stats import norm</span><br><span class="line"></span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;) #, one_hot=True)</span><br><span class="line"></span><br><span class="line">n_input = 784</span><br><span class="line">n_hidden_1 = 256</span><br><span class="line">n_hidden_2 = 2</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [None, n_input])</span><br><span class="line"></span><br><span class="line">zinput = tf.placeholder(tf.float32, [None, n_hidden_2])</span><br></pre></td></tr></table></figure>

</details>

<p>zinput是个占位符，在后面要通过它输入分布数据，用来生成模拟样本数据。</p>
<p>2．定义学习参数</p>
<p>由于这次的网络结构不同，所以定义的参数也有变化，mean_w1与mean_b1是生成mean的权重，log_sigma_w1与log_sigma_b1是生成log_sigma的权重。</p>
<p>代码10-8 变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">weights = &#123;</span><br><span class="line"></span><br><span class="line">    &apos;w1&apos;: tf.Variable(tf.truncated_normal([n_input, n_hidden_1],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line">    &apos;b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line"></span><br><span class="line">    &apos;mean_w1&apos;: tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line">    &apos;log_sigma_w1&apos;: tf.Variable(tf.truncated_normal([n_hidden_1, n_</span><br><span class="line">   hidden_2],</span><br><span class="line">                                   stddev=0.001)),    </span><br><span class="line">    </span><br><span class="line">    &apos;w2&apos;: tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_1],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line"></span><br><span class="line">    &apos;b2&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;w3&apos;: tf.Variable(tf.truncated_normal([n_hidden_1, n_input],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line"></span><br><span class="line">    &apos;b3&apos;: tf.Variable(tf.zeros([n_input])),</span><br><span class="line"></span><br><span class="line">    &apos;mean_b1&apos;: tf.Variable(tf.zeros([n_hidden_2])),</span><br><span class="line"></span><br><span class="line">    &apos;log_sigma_b1&apos;: tf.Variable(tf.zeros([n_hidden_2]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 这里初始化w的权重与以往不同，使用了很小的值（方差为0.001的truncated_ normal）。这里设置得非常小心，由于在算KL离散度时计算的是与标准高斯分布的距离，如果网络初始生成的模型均值方差都很大，那么与标准高斯分布的距离就会非常大，这样会导致模型训练不出来，生成NAN的情况。</p>
<p>3．定义网络结构</p>
<p>按照图10-17的描述，网络节点可以按照以下代码来定义，在变分解码器中为训练的中间节点赋予了特殊的意义，让它们代表均值和方差，并将它们所代表的数据集向着标准高斯分布数据集靠近（也就是原始数据是样本，高斯分布数据是标签），然后可以使用KL离散度公式，来计算它所代表的集合与标准的高斯分布集合（均值是0，方差为1的正态分布）间的距离，将这个距离当成误差，让它最小化从而优化网络参数。</p>
<p>这里的方差节点不是真正意义的方差，是取了log之后的，所以会有tf.exp（z_log_sigma_sq）的变换，是取得方差的值，再通过tf.sqrt将其开平方得到标准差。用符合标准正太分布的一个数乘以标准差加上均值，就使这个数成为符合（z_mean，sigma）数据分布集合里的一个点（z_mean是指网络生成均值，sigma是指网络生成的z_log_sigma_sq变换后的值）。</p>
<p><img src="Image00014.jpg" alt> 注意： 输出的值当成任意一个意义，并通过训练得到对应的关系。具体做法为：将具有代表该意义的值代入相应的公式（该公式要求必须能够支持反向传播），计算公式输出值与目标值的误差，并将误差放到优化器里，然后通过多次迭代的方式进行训练即可。</p>
<p>到此，完成了编码阶段。将原始数据编码输出3个值：</p>
<p>·一个是表示该数据分布的均值。</p>
<p>·一个是表示该数据分布的方差。</p>
<p>·还有一个是得到了该数据分布中的一个实际的点z。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里的变换对应的知识点是：假如一个符合高斯分布的数据集均值、标准差为（m，sigma），其里面的某个点，可以通过一个符合标准高斯分布（0，1）中的点x，通过m+x×sigma的方式转化而成。</p>
<p>但这是在一个假设背景下完成的，假设数据分布属于高斯分布。我们现在无法保证转换后的数据分布符合高斯分布，则可以通过测量输出值代表的数据集与标准高斯分布数据集之间的差距，利用神经网络来将其训练成符合高斯分布的数据集。</p>
<p>代码10-8 变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> h1=tf.nn.relu(tf.add(tf.matmul(x, weights[&apos;w1&apos;]), weights[&apos;b1&apos;]))</span><br><span class="line"> z_mean = tf.add(tf.matmul(h1, weights[&apos;mean_w1&apos;]), weights[&apos;mean_b1&apos;])</span><br><span class="line"> z_log_sigma_sq = tf.add(tf.matmul(h1, weights[&apos;log_sigma_w1&apos;]), </span><br><span class="line">weights[&apos;log_sigma_b1&apos;])</span><br><span class="line"> </span><br><span class="line">  # 高斯分布样本</span><br><span class="line"> eps = tf.random_normal(tf.stack([tf.shape(h1)[0], n_hidden_2]), 0, 1, </span><br><span class="line">dtype = tf.float32)</span><br><span class="line"> z =tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps))</span><br><span class="line"> h2=tf.nn.relu( tf.matmul(z, weights[&apos;w2&apos;])+ weights[&apos;b2&apos;])</span><br><span class="line"> reconstruction = tf.matmul(h2, weights[&apos;w3&apos;])+ weights[&apos;b3&apos;]</span><br><span class="line"> </span><br><span class="line"> h2out=tf.nn.relu( tf.matmul(zinput, weights[&apos;w2&apos;])+ weights[&apos;b2&apos;])</span><br><span class="line"> reconstructionout = tf.matmul(h2out, weights[&apos;w3&apos;])+ weights[&apos;b3&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>得到了符合原数据集上的一个具体点z之后，就可以通过神经网络这个点z还原成原始数据reconstruction了。解码部分和前面一样，参照编码的网络逐层还原回去即可。</p>
<p>h2out和reconstructionout两个节点不属于训练中的结构，是为了生成指定数据时用的。</p>
<p>4．构建模型的反向传播</p>
<p>这一步和前面一样，需要定义损失函数的节点和优化算法的OP，代码如下。</p>
<p>代码10-8 变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> # 计算重建loss</span><br><span class="line"> reconstr_loss = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(reconstruction,</span><br><span class="line"> x), 2.0))</span><br><span class="line"> latent_loss = -0.5 * tf.reduce_sum(1 + z_log_sigma_sq</span><br><span class="line">                                    -tf.square(z_mean)</span><br><span class="line">                                    -tf.exp(z_log_sigma_sq), 1)</span><br><span class="line"> cost = tf.reduce_mean(reconstr_loss + latent_loss)</span><br><span class="line"> </span><br><span class="line"> optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize</span><br><span class="line">(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码描述了网络的两个优化方向：</p>
<p>·一个是比较生成的数据分布与标准高斯分布的距离，这里使用KL离散度的公式（见latent_loss）。</p>
<p>·另一个是计算生成数据与原始数据间的损失，这里用的是平方差，也可以用交叉熵。</p>
<p>最后将两种损失值放在一起，通过Adam的随机梯度下降算法实现在训练中的优化参数。</p>
<p>5．设置参数，进行训练</p>
<p>这一步与前面类似，设置训练参数，迭代50次，在session中每次循环取指定批次数据进行训练。</p>
<p>代码10-8 变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">training_epochs = 50</span><br><span class="line">batch_size = 128</span><br><span class="line">display_step = 3</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line"></span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)#取数据</span><br><span class="line">            </span><br><span class="line">            # 输入数据，运行优化器</span><br><span class="line">            _,c = sess.run([optimizer,cost], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">            </span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch + 1), &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.</span><br><span class="line">           format(c))</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br><span class="line">    </span><br><span class="line">    # 测试</span><br><span class="line">    print (&quot;Result:&quot;, cost.eval(&#123;x: mnist.test.images&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>可视化部分这里不再详述，读者可以参考本书的配套代码，最终程序运行的结果输出如下，输出图片如图10-18所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 2766.966308594</span><br><span class="line">Epoch: 0004 cost= 2503.895507812</span><br><span class="line">Epoch: 0007 cost= 2177.547363281</span><br><span class="line">Epoch: 0010 cost= 2221.667724609</span><br><span class="line">Epoch: 0013 cost= 2110.643798828</span><br><span class="line">Epoch: 0016 cost= 2103.255859375</span><br><span class="line">Epoch: 0019 cost= 2258.502685547</span><br><span class="line">Epoch: 0022 cost= 2231.131347656</span><br><span class="line">Epoch: 0025 cost= 2092.596191406</span><br><span class="line">Epoch: 0028 cost= 2018.563964844</span><br><span class="line">Epoch: 0031 cost= 1993.950439453</span><br><span class="line">Epoch: 0034 cost= 2091.635253906</span><br><span class="line">Epoch: 0037 cost= 1992.461059570</span><br><span class="line">Epoch: 0040 cost= 2018.574462891</span><br><span class="line">Epoch: 0043 cost= 1992.727661133</span><br><span class="line">Epoch: 0046 cost= 2056.166503906</span><br><span class="line">Epoch: 0049 cost= 1939.133544922</span><br><span class="line">完成!</span><br><span class="line">Result: 156414.0</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00218.jpg" alt></p>
<p>图10-18 变分自编码结果</p>
<p>图10-18中，第一行代表原始的样本图片，第二行代表变分自编码重建后生成的图片。可以看到生成的数字中不再一味单纯地学习形状，而是通过数据分布的方式学习规则，对原有图片具有更清晰的修正功能。</p>
<p>仿照前面的可视化代码，将均值和方差代表的二维数据在直角坐标系中展现如下，如图10-19所示。</p>
<p><img src="Image00219.jpg" alt></p>
<p>图10-19 变分自编码二维可视化</p>
<p>从图10-19中可以看出，MNIST数据集中同一类样本的特征分布还是比较集中的，说明变分自解码也具有降维功能，也可以用它进行分类任务的数据降维预处理。</p>
<p>6．高斯分布取样，生成模拟数据</p>
<p>为了进一步证实模型学到了数据分布的情况，这次在高斯分布抽样中取一些点，将其映射到模型中的z，然后通过解码部分还原成真实图片看看效果，代码如下。</p>
<p><img src="Image00014.jpg" alt> 注意： 代码中norm.ppf函数的作用是从按照百分比由大到小排列后的标准高斯分布中取值。np.linspace（0.05，0.95，n）的意思是，将整个高斯分布数据集从大到小排列，取出前0.05%到0.95%区间，并且分成n份，每份对应的点的具体数值。</p>
<p>norm代表标准高斯分布，ppf代表累积分布函数的反函数。累积分布的意思是，在一个结合里所有小于a的值出现的概率的和。例如，x=ppf（0.05）就代表在集合里有个x，集合中每个小于x的数在集合里出现的概率的总和等于0.05。</p>
<p>代码10-8 变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">n = 15  # 15×15 的figure </span><br><span class="line">digit_size = 28</span><br><span class="line">figure = np.zeros((digit_size * n, digit_size * n))</span><br><span class="line">grid_x = norm.ppf(np.linspace(0.05, 0.95, n))</span><br><span class="line">grid_y = norm.ppf(np.linspace(0.05, 0.95, n))</span><br><span class="line"></span><br><span class="line">for i, yi in enumerate(grid_x):</span><br><span class="line">    for j, xi in enumerate(grid_y):</span><br><span class="line">        z_sample = np.array([[xi, yi]])</span><br><span class="line">        x_decoded = sess.run(reconstructionout,feed_dict=&#123;zinput:z_</span><br><span class="line">       sample&#125;)</span><br><span class="line">        </span><br><span class="line">        digit = x_decoded[0].reshape(digit_size, digit_size)</span><br><span class="line">        figure[i * digit_size: (i + 1) * digit_size,</span><br><span class="line">               j * digit_size: (j + 1) * digit_size] = digit</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(10, 10))</span><br><span class="line">plt.imshow(figure, cmap=&apos;Greys_r&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行以上代码，生成图片如图10-20所示。</p>
<p><img src="Image00220.jpg" alt></p>
<p>图10-20 变分自编码生成模拟数据</p>
<p>可以看到，在神经网络的世界里，从左下角到右上角显示了网络是按照图片的形状变化而排列的，并不像人类一样，把数字按照1到9的顺序排列，因为机器学的只是图片，而人类对数字的理解更多的是其代表的意思。</p>
<h4 id="10-9-3-练习题"><a href="#10-9-3-练习题" class="headerlink" title="10.9.3 练习题"></a>10.9.3 练习题</h4><p>读者可以自己试试在初始化时将所有的w设为0和设为truncated_normal，不指定stddev的效果，想想为什么？</p>
<h3 id="10-10-条件变分自编码"><a href="#10-10-条件变分自编码" class="headerlink" title="10.10 条件变分自编码"></a>10.10 条件变分自编码</h3><p>前面的变分自编码是为了本节条件变分自编码器做铺垫的，在实际中条件变分自编码的应用更广泛一些，下面来介绍条件变分自编码器。</p>
<h4 id="10-10-1-什么是条件变分自编码"><a href="#10-10-1-什么是条件变分自编码" class="headerlink" title="10.10.1 什么是条件变分自编码"></a>10.10.1 什么是条件变分自编码</h4><p>变分自编码存在一个问题——虽然可以生成一个样本，但只能输出与输入图片相同类别的样本。虽然也可以随机从符合模型生成的高斯分布中取数据来还原成样本，但是这样的话我们并不知道生成的样本属于哪个类别。条件变分解码则可以解决这个问题，让网络按指定的类别生成样本。</p>
<p>在变分自编码的基础上，再去理解条件变分自编码会很容易。主要的改动是，在训练、测试时加入一个one-hot向量，用于表示标签向量。其实，就是给变分自编码网络加入了一个条件，让网络学习图片分布时加入了标签因素，这样可以按照标签的数值生成指定的图片。</p>
<h4 id="10-10-2-实例83：使用标签指导变分自编码网络生成MNIST数据"><a href="#10-10-2-实例83：使用标签指导变分自编码网络生成MNIST数据" class="headerlink" title="10.10.2 实例83：使用标签指导变分自编码网络生成MNIST数据"></a>10.10.2 实例83：使用标签指导变分自编码网络生成MNIST数据</h4><p>了解完原理，再来介绍下具体做法。在编码阶段需要在输入端添加标签对应的特征，在解码阶段同样也需要将标签加入输入，这样，再解码的结果向原始的输入样本不断逼近，最终得到的模型将会把输入的标签特征当成MNIST数据的一部分，从而实现通过标签生成MNIST数据。</p>
<p>在输入端添加标签时，一般是通过一个全连接层的变换将得到的结果使用contact函数连接到原始输入的地方，在解码阶段也将标签作为样本输入，与高斯分布的随机值一并运算，生成模拟样本。条件变为自编码结构如图10-21所示。</p>
<p><img src="Image00221.jpg" alt></p>
<p>图10-21 条件变分自编码结构</p>
<p>具体代码步骤如下。</p>
<p>实例描述</p>
<p>使用条件变分自编码模型，通过指定标签输入生成对应类别的MNIST模拟数据。</p>
<p>1．添加标签占位符</p>
<p>在“10-8变分自编码.py”代码基础上修改，添加占位符y。</p>
<p>代码10-9 条件变分自编码</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">y = tf.placeholder(tf.float32, [None, n_labels])</span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>2．添加输入全连接权重</p>
<p>添加全连接层的权重’wlab1’与’blab1’，作为输入标签的特征转换。这里输入的标签也转换成256个输出，因为最终要连接到原始的图片全连接输出，所以到第二层全连接时，输入就变成了256×2，因此也需要将mean_w1和log_sigma_w1的输入修改成n_hidden_1×2。</p>
<p>代码10-9 条件变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">weights = &#123;</span><br><span class="line"></span><br><span class="line">    &apos;w1&apos;: tf.Variable(tf.truncated_normal([n_input, n_hidden_1],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line">    &apos;b1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line"></span><br><span class="line">    &apos;wlab1&apos;: tf.Variable(tf.truncated_normal([n_labels, n_hidden_1],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line">    &apos;blab1&apos;: tf.Variable(tf.zeros([n_hidden_1])),</span><br><span class="line">    &apos;mean_w1&apos;: tf.Variable(tf.truncated_normal([n_hidden_1*2, n_</span><br><span class="line">   hidden_2],</span><br><span class="line">                                   stddev=0.001)),</span><br><span class="line">    &apos;log_sigma_w1&apos;: tf.Variable(tf.truncated_normal([n_hidden_1*2, n_</span><br><span class="line">   hidden_2],</span><br><span class="line">                                   stddev=0.001)),   </span><br><span class="line">    &apos;w2&apos;: tf.Variable(tf.truncated_normal([n_hidden_2+n_labels, n_</span><br><span class="line">   hidden_1],</span><br><span class="line">                                   stddev=0.001)), </span><br><span class="line">……</span><br></pre></td></tr></table></figure>

</details>

<p>同样，对于生成的z也要与label连接后输入加码器，所以w2的输入维度需要被改成n_hidden_2+n_labels。</p>
<p>3．修改模型，将标签输出接入编码</p>
<p>定义新节点hlab1为输入标签的输出，接着使用concat函数将它与原来的h1合并到一起，变成hall1。此时，hall1的shape为[batch_size，n_hidden_1×2]。接着，将合成好的hall1代替原来的h1输入z_mean与z_log_sigma_sq中。</p>
<p>代码10-9 条件变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> h1=tf.nn.relu(tf.add(tf.matmul(x, weights[&apos;w1&apos;]), weights[&apos;b1&apos;]))</span><br><span class="line"> </span><br><span class="line"> hlab1=tf.nn.relu(tf.add(tf.matmul(y, weights[&apos;wlab1&apos;]), weights</span><br><span class="line">[&apos;blab1&apos;]))</span><br><span class="line"> </span><br><span class="line"> hall1= tf.concat([h1,hlab1],1)#256*2</span><br><span class="line"> </span><br><span class="line"> z_mean = tf.add(tf.matmul(hall1, weights[&apos;mean_w1&apos;]), weights</span><br><span class="line">[&apos;mean_b1&apos;])</span><br><span class="line"> z_log_sigma_sq = tf.add(tf.matmul(hall1, weights[&apos;log_sigma_w1&apos;]), </span><br><span class="line">weights[&apos;log_sigma_b1&apos;])</span><br></pre></td></tr></table></figure>

</details>

<p>4．修改模型将标签接入解码</p>
<p>这一步里中间的z不用变化，在z之后同样连接上y的特征，一起输入到解码器中。这里需要同时修改reconstruction和reconstructionout节点，一个用来训练，一个用来生成。</p>
<p>代码10-9 条件变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">zall=tf.concat([z,y],1)</span><br><span class="line">h2=tf.nn.relu( tf.matmul(zall, weights[&apos;w2&apos;])+ weights[&apos;b2&apos;])</span><br><span class="line">reconstruction = tf.matmul(h2, weights[&apos;w3&apos;])+ weights[&apos;b3&apos;]</span><br><span class="line"></span><br><span class="line">zinputall = tf.concat([zinput,y],1)</span><br><span class="line">h2out=tf.nn.relu( tf.matmul(zinputall, weights[&apos;w2&apos;])+ weights[&apos;b2&apos;])</span><br><span class="line">reconstructionout = tf.matmul(h2out, weights[&apos;w3&apos;])+ weights[&apos;b3&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>5．修改session中的feed部分</p>
<p>优化器不用变化，直接修改session的feed部分即可，在feed中加入标签占位符及对应的数据。</p>
<p>代码10-9 条件变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line"></span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)#取数据</span><br><span class="line">            </span><br><span class="line">            # 输入数据，运行优化器</span><br><span class="line">            _,c = sess.run([optimizer,cost], feed_dict=&#123;x: batch_xs,</span><br><span class="line">           y:batch_ys&#125;)</span><br><span class="line">            </span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch + 1), &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.</span><br><span class="line">           format(c))</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br><span class="line">    </span><br><span class="line">    # 测试</span><br><span class="line">    print (&quot;Result:&quot;, cost.eval(&#123;x: mnist.test.images,y:mnist.</span><br><span class="line">   test.labels&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>6．运行模型生成模拟数据</p>
<p>这一步是最有意思的部分了。随意生成一个高斯分布随机数，并通过指定的one_hot输入标签，就可以命令模型生成指定的MNIST图片数据了。</p>
<p>代码10-9 条件变分自编码（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">    # 根据label模拟生产图片可视化结果</span><br><span class="line">    show_num = 10</span><br><span class="line">    z_sample = np.random.randn(10,2)</span><br><span class="line">    </span><br><span class="line">    pred = sess.run(</span><br><span class="line">        reconstructionout, feed_dict=&#123;zinput:z_sample,y: mnist.test.</span><br><span class="line">       labels[:show_num]&#125;)</span><br><span class="line"></span><br><span class="line">    f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(pred[i], (28, 28)))</span><br><span class="line">    plt.draw()</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码取了10个测试样本数据，将样本数据的label随高斯分布值z_sample一起生成了模拟的MNIST数据。运行代码，生成如图10-22和图10-23所示的数据。</p>
<p><img src="Image00222.jpg" alt></p>
<p>图10-22 根据原数据生成模拟数据</p>
<p><img src="Image00223.jpg" alt></p>
<p>图10-23 根据标签生成模拟数据</p>
<p>图10-22为根据原始图片生成的自编码数据，第一行为原始数据，第二行为自编码数据。</p>
<p>图10-23为根据label生成的模拟数据，第一行为label对应的原始数据，第二行为解码器生成的模拟数据。</p>
<p>比较两幅图片可以看出，使用原图生成的自编码数据还会带有一些原来的样子，而以标签生成的解码数据，已经彻底地学会了数据的分布，并生成截然不同却带有相同意义的数据。</p>
<h1 id="第3篇-深度学习进阶"><a href="#第3篇-深度学习进阶" class="headerlink" title="第3篇 深度学习进阶"></a>第3篇 深度学习进阶</h1><p>本篇是对基础网络模型的灵活运用与自由组合，是对前面知识的综合及拔高。本篇内容包括：</p>
<p>第11章 深度神经网络</p>
<p>第12章 对抗神经网络（GAN）</p>
<h2 id="第11章-深度神经网络"><a href="#第11章-深度神经网络" class="headerlink" title="第11章 深度神经网络"></a>第11章 深度神经网络</h2><p>本章开始学习深度神经网络的知识。作为深度学习的代表，深度神经网络可以算是深度学习中最主要的知识。前面讲了许多网络形态，都会在各自的领域中有一定的效果，但是要体现出真正的人工智能能力，就必须将这些网络形态组合起来，利用各种网络的优势，使整体效果达到最优，实现可以匹配人工智能的要求。</p>
<p>本章含有教学视频共10分25秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了讲解，包括深度神经网络、实物检测相关模型、slim、Object Detection API及预训练模型等相关知识（重点为掌握深度神经网络模型的使用及训练方法）。</p>
<p><img src="Image00224.jpg" alt></p>
<h3 id="11-1-深度神经网络介绍"><a href="#11-1-深度神经网络介绍" class="headerlink" title="11.1 深度神经网络介绍"></a>11.1 深度神经网络介绍</h3><p>本节主要介绍深度神经网络。先从深度神经网络的起源说起，接着介绍在深度神经网络中都有哪些知名的经典模型及各自的特点。</p>
<h4 id="11-1-1-深度神经网络起源"><a href="#11-1-1-深度神经网络起源" class="headerlink" title="11.1.1 深度神经网络起源"></a>11.1.1 深度神经网络起源</h4><p>深度学习的兴起源于深度神经网络的崛起。2012年，由 Alex Krizhevsky开发的一个深度学习模型AlexNet，赢得了视觉领域竞赛ILSVRC 2012的冠军，并且效果大幅度超过传统的方法。在百万量级的ImageNet数据集合上，识别率从传统的70%多提升到80%多，将深度学习正式推上了舞台。之后ILSVRC每年都不断被深度学习刷榜，并且模型变得越来越深，错误率也越来越低，目前已经降到了3.5%左右，而在同样的ImageNet数据集合上，人眼的辨识错误率大概在5.1%，也就是说目前的深度学习模型的识别能力已经超过了人眼。</p>
<p>自从2012年之后，在ILSVRC竞赛中获得冠军的模型如下。</p>
<p>·2012年：AlexNet；</p>
<p>·2013年：VGG；</p>
<p>·2014年：GoogLeNet；</p>
<p>·2015年：ResNet；</p>
<p>·2016年：Inception-ResNet-v2。</p>
<p>随着深度神经网络学科的进步，使用神经网络征服ImageNet的门槛已经越来越低，于是在2017年，ILSVRC竞赛举办完最后一届，宣布了停办。与此同时，在2017年的ICCV竞赛中，在物体检测、物体分割等细分领域的冠军中出现了多家中国企业的名字，这表明中国的人工智能技术正在逐步地引领全球。</p>
<h4 id="11-1-2-经典模型的特点介绍"><a href="#11-1-2-经典模型的特点介绍" class="headerlink" title="11.1.2 经典模型的特点介绍"></a>11.1.2 经典模型的特点介绍</h4><p>下面具体介绍各界冠军模型的特点。</p>
<p>1．VGG模型</p>
<p>VGG又分为VGG16和VGG19，分别在AlexNet的基础上将层数增加到16和19层，它除了在识别方面很优秀之外，对图像的目标检测也有很好的识别效果，是目标检测领域的较早期模型。</p>
<p>2．GoogLeNet模型</p>
<p>GoogLeNet除了层数加深到22层以外，主要的创新在于它的Inception，这是一种网中网（Network In Network）的结构，即原来的节点也是一个网络。用了Inception之后整个网络结构的宽度和深度都可扩大，能够带来2到3倍的性能提升。</p>
<p>3．ResNet模型</p>
<p>ResNet直接将深度拉到了152层，其主要的创新在于残差网络，其实这个网络的提出本质上是要解决层次比较深时无法训练的问题。这种借鉴了Highway Network思想的网络，相当于旁边专门开个通道使得输入可以直达输出，而优化的目标由原来的拟合输出H（x）变成输出和输入的差H（x）-x，其中H（x）是某一层原始的期望映射输出，x是输入。</p>
<p>4．Inception-ResNet-v2模型</p>
<p>Inception-ResNet-v2：是目前比较新的经典模型，将深度和宽带融合到一起，在当下ILSVRC图像分类基准测试中实现了最好的成绩，是将Inception v3与ResNet结合而成的。</p>
<p>接下来主要对当前比较前沿的GoogLeNet、ResNet、Inception-ResNet-v2几种网络结构进行详细介绍。</p>
<h3 id="11-2-GoogLeNet模型介绍"><a href="#11-2-GoogLeNet模型介绍" class="headerlink" title="11.2 GoogLeNet模型介绍"></a>11.2 GoogLeNet模型介绍</h3><p>前面已经介绍过GoogLeNet，其中最核心的亮点就是它的Inception，GoogLeNet网络最大的特点就是去除了最后的全连接层，用全局平均池化层（即使用与图片尺寸相同的过滤器来做平均池化）来取代它。</p>
<p>这么做的原因是：在以往的AlexNet和VGGNet网络中，全连接层几乎占据90%的参数量，占用了过多的运算量内存使用率，而且还会引起过拟合。</p>
<p>GoogLeNet的做法是去除全连接层，使得模型训练更快并且减轻了过拟合。</p>
<p>之后GoogLeNet的Inception还在继续发展，目前已经有v2、v3和v4版本，主要针对解决深层网络的以下3个问题产生的。</p>
<p>·参数太多，容易过拟合，训练数据集有限。</p>
<p>·网络越大计算复杂度越大，难以应用。</p>
<p>·网络越深，梯度越往后传越容易消失（梯度弥散），难以优化模型。</p>
<p>Inception的核心思想是通过增加网络深度和宽度的同时减少参数的方法来解决问题。Inception v1有22层深，比AlexNet的8层或者VGGNet的19层更深。但其计算量只有15亿次浮点运算，同时只有500万的参数量，仅为AlexNet参数量（6000万）的1/12，却有着更高的准确率。</p>
<p>下面沿着Inception的进化来一步步了解Inception网络。Inception是在一些突破性的研究成果之上推出的，所以有必要从Inception的前身理论开始介绍。下面先介绍MLP卷积层。</p>
<h4 id="11-2-1-MLP卷积层"><a href="#11-2-1-MLP卷积层" class="headerlink" title="11.2.1 MLP卷积层"></a>11.2.1 MLP卷积层</h4><p>MLP卷积层（Mlpconv）源于2014年ICLR的一篇论文《Network In Network》。它改进了传统的CNN网络，在效果等同的情况下，参数只是原有的Alexnet网络参数的1/10。</p>
<p>卷积层要提升表达能力，主要依靠增加输出通道数，每一个输出通道对应一个滤波器，同一个滤波器共享参数只能提取一类特征，因此一个输出通道只能做一种特征处理。所以在传统的CNN中会使用尽量多的滤波器，把原样本中尽可能多的潜在的特征提取出来，然后再通过池化和大量的线性变化在其中筛选出需要的特征。这样的代价就是参数太多，运算太慢，而且很容易引起过拟合。</p>
<p>MLP卷积层的思想是将CNN高维度特征转成低维度特征，将神经网络的思想融合在具体的卷积操作当中。直白的理解就是在网络中再放一个网络，即，使每个卷积的通道中包含一个微型的多层网络，用一个网络来代替原来具体的卷积运算过程（卷积核的每个值与样本对应的像素点相乘，再将相乘后的所有结果加在一起生成新的像素点的过程）。其结构如图11-1所示。</p>
<p><img src="Image00225.jpg" alt></p>
<p>图11-1 MLP结构</p>
<p>图11-1中a为传统的卷积结构，图11-1b为MLP结构。相比较而言，利用多层MLP的微型网络，对每个局部感受野的神经元进行更加复杂的运算，而以前的卷积层，局部感受野的运算仅仅只是一个单层的神经网络。在MLP网络中比较常见的是使用一个三层的全连接网络结构，这等效于普通卷积层后再连接1∶1的卷积和ReLU激活函数。</p>
<h4 id="11-2-2-全局均值池化"><a href="#11-2-2-全局均值池化" class="headerlink" title="11.2.2 全局均值池化"></a>11.2.2 全局均值池化</h4><p>在11.2节开始时已经提到过全局均值池化的方法，就是在平均池化层中使用同等大小的过滤器将其特征保存下来。这种结构用来代替深层网络结构最后的全连接输出层。这个方法也是《Network In Network》论文中所论述的。</p>
<p>全局均值池化的具体用法是在卷积处理之后，对每个特征图的整张图片进行全局均值池化，生成一个值，即每张特征图相当于一个输出特征，这个特征就表示了我们输出类的特征。例如，在做1000个分类任务时，最后一层的特征图个数就要选择1000，就可以直接得出分类了。</p>
<p>在《Network In Network》论文中作者利用其进行1000物体分类问题，最后设计了一个4层的NIN+全局均值池化网络，如图11-2所示。</p>
<p><img src="Image00226.jpg" alt></p>
<p>图11-2 NIN+全局均值池化</p>
<h4 id="11-2-3-Inception-原始模型"><a href="#11-2-3-Inception-原始模型" class="headerlink" title="11.2.3 Inception 原始模型"></a>11.2.3 Inception 原始模型</h4><p>Inception的原始模型是相对于MLP卷积层更为稀疏，它采用了MLP卷积层的思想，将中间的全连接层换成了多通道卷积层。Inception与MLP卷积在网络中的作用一样，把封装好的Inception作为一个卷积单元，堆积起来形成了原始的GoogLeNet网络。</p>
<p>Inception的结构是将1×1、3×3、5×5的卷积核对应的卷积操作和3×3的滤波器对应的池化操作堆叠在一起，一方面增加了网络的宽度，另一方面增加了网络对尺度的适应性，如图11-3所示。</p>
<p><img src="Image00227.jpg" alt></p>
<p>图11-3 nception模型</p>
<p>Inception模型中包含了3种不同尺寸的卷积和一个最大池化，增加了网络对不同尺度的适应性，这和Multi-Scale的思想类似。早期计算机视觉的研究中，受灵长类神经视觉系统的启发，Serre使用不同尺寸的Gabor滤波器处理不同尺寸的图片，Inception v1借鉴了这种思想。Inception v1的论文中指出，Inception模型可以让网络的深度和宽度高效率地扩充，提升了准确率且不致于过拟合。</p>
<p>形象的解释就是Inception模型本身如同大网络中的一个小网络，其结构可以反复堆叠在一起形成更大网络。</p>
<h4 id="11-2-4-Inception-v1模型"><a href="#11-2-4-Inception-v1模型" class="headerlink" title="11.2.4 Inception v1模型"></a>11.2.4 Inception v1模型</h4><p>Inception v1模型在原有的Inception模型基础上做了一些改进，原因是由于Inception的原始模型是将所有的卷积核都在上一层的所有输出上来做，那么5×5的卷积核所需的计算量就比较大，造成了特征图厚度很大。</p>
<p>为了避免这一现象，Inception v1模型在3×3前、5×5前、最大池化层后分别加上了1×1的卷积核，起到了降低特征图厚度的作用（其中1×1卷积主要用来降维），网络结构如图11-4所示。</p>
<p><img src="Image00228.jpg" alt></p>
<p>图11-4 Inception v1模型</p>
<p>Inception v1模型中有以下4个分支。</p>
<p>·第1个分支对输入进行1×1的卷积，这其实也是NIN中提出的一个重要结构。1×1的卷积可以跨通道组织信息，提高网络的表达能力，同时可以对输出通道升维和降维。</p>
<p>·第2个分支先使用了1×1卷积，然后连接3×3卷积，相当于进行了两次特征变换。</p>
<p>·第3个分支与第2个分支类似，先是1×1的卷积，然后连接5×5卷积。</p>
<p>·第4个分支则是3×3最大池化后直接使用1×1卷积。</p>
<p>可以发现4个分支都用到了1×1卷积，有的分支只使用1×1卷积，有的分支在使用了其他尺寸的卷积的同时会再使用1×1卷积，这是因为1×1卷积的性价比很高，增加一层特征变换和非线性转化所需的计算量更小。</p>
<p>Inception v1模型的4个分支在最后再通过一个聚合操作合并（使用tf.concat函数在输出通道数的维度上聚合）。</p>
<h4 id="11-2-5-Inception-v2模型"><a href="#11-2-5-Inception-v2模型" class="headerlink" title="11.2.5 Inception v2模型"></a>11.2.5 Inception v2模型</h4><p>Inception v2模型在Inception v1模型基础上应用当时的主流技术，在卷积之后加入了BN层，使每一层的输出都归一化处理，减少了内变协变量的移动问题； 同时还使用了梯了度截断技术，增加了训练的稳定性。</p>
<p>另外，Inception学习了VGG，用2个3×3的conv替代inception模块中的5×5，这既降低了参数数量，也提升了计算速度。其结构如图11-5所示。</p>
<p><img src="Image00229.jpg" alt></p>
<p>图11-5 Inception v2模型</p>
<h4 id="11-2-6-Inception-v3模型"><a href="#11-2-6-Inception-v3模型" class="headerlink" title="11.2.6 Inception v3模型"></a>11.2.6 Inception v3模型</h4><p>Inception v3模型没有再加入其他的技术，只是将原有的结构进行了调整，其最重要的一个改进是分解，将图11-5中的卷积核变得更小。</p>
<p>具体的计算方法是：将7×7分解成两个一维的卷积（1×7，7×1），3×3的卷积操作也一样（1×3，3×1）。这种做法是基于线性代数的原理，即一个[n，n]的矩阵，可以分解成矩阵[n，1]×矩阵[1，n]，得出的结构如图11-6所示。</p>
<p><img src="Image00230.jpg" alt></p>
<p>图11-6 Inception v3模型</p>
<p>这么做会有什么效果呢？我们举一个例子。</p>
<p>假设有256个特征输入，256个特征输出，如果Inception 层只能执行3×3的卷积，即总共要完成256×256×3×3的卷积（将近589 000次乘积累加运算）。</p>
<p>如果需要减少卷积运算的特征数量，将其变为64（即256/4）个。则需要先进行256→64 1×1的卷积，然后在所有Inception的分支上进行64次卷积，接着再使用一个来自64→256的特征的1×1卷积，运算的公式如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">×64 × 1×1 = 16 000s</span><br><span class="line">×64 × 3×3 = 36 000s</span><br><span class="line">×256 × 1×1 = 16 000s</span><br></pre></td></tr></table></figure>

</details>

<p>相比于之前的60万，现在共有7万的计算量，几乎原有的1/10。</p>
<p>在实际测试中，这种结构在前几层处理较大特征数据时的效果并不太好，但在处理中间状态生成的大小在12～20之间的特征数据时效果会非常明显，也可以大大提升运算速度。另外，Inception v3还做了其他的变化，将网络的输入尺寸由224×224变为了299×299，并增加了卷积核为35×35/17×17/8×8的卷积模块。</p>
<h4 id="11-2-7-Inception-v4模型"><a href="#11-2-7-Inception-v4模型" class="headerlink" title="11.2.7 Inception v4模型"></a>11.2.7 Inception v4模型</h4><p>Inception v4是在Inception模块基础上，结合残差连接（Residual Connection）技术的特点进行了结构的优化调整。Inception-ResNet v2网络与Inception v4网络，二者性能差别不大，结构上的区别在于Inception v4中仅仅是在Inception v3基础上做了更复杂的结构变化（从Inception v3的4个卷积模型变为6个卷积模块等），但没有使用残差连接。</p>
<p>这里提到了一个残差连接（Residual Connection），它属于ResNet网络模型里的核心技术，通过对下面ResNet的学习，读者将会了解残差连接的含义。</p>
<h3 id="11-3-残差网络（ResNet）"><a href="#11-3-残差网络（ResNet）" class="headerlink" title="11.3 残差网络（ResNet）"></a>11.3 残差网络（ResNet）</h3><p>残差网络（ResNet），在ILSVRC 2015中取得了冠军，该框架能够大大简化模型网络的训练时间，使得在可接受时间内，模型能够更深。</p>
<p>在深度学习领域中，网络越深意味着拟合越强，出现过拟合问题是正常的，训练误差越来越大却是不正常的。但是，网络逐渐加深会对网络的反向传播能力提出挑战，在反向传播中每一层的梯度都是在上一层的基础上计算的，层数多会导致梯度在多层传播时越来越小，直到梯度消失，于是表现的结果就是随着层数变多，训练的误差会越来越大。</p>
<p>残差网络通过一个叫残差连接的技术解决了这个问题。所谓的残差连接就是在标准的前馈卷积网络上加一个跳跃，从而绕过一些层的连接方式。</p>
<h4 id="11-3-1-残差网络结构"><a href="#11-3-1-残差网络结构" class="headerlink" title="11.3.1 残差网络结构"></a>11.3.1 残差网络结构</h4><p>残差网络的结构，如图11-7所示。</p>
<p><img src="Image00231.jpg" alt></p>
<p>图11-7 残差网络结构</p>
<p>假设，经过两个神经层之后输出的H（x）如下所示：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f(x)=relu(xw+b)</span><br><span class="line">H(x)=relu(f(x)w+b)</span><br></pre></td></tr></table></figure>

</details>

<p>H（x）和x之间存在一个函数的关系，如果这两层神经网络构成的是H（x）=2x的关系，则残差网络的定义如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">H(x)=relu(f(x)w+b)+x</span><br></pre></td></tr></table></figure>

</details>

<h4 id="11-3-2-残差网络原理"><a href="#11-3-2-残差网络原理" class="headerlink" title="11.3.2 残差网络原理"></a>11.3.2 残差网络原理</h4><p>如图11-7所示，ResNet中，输入层与Addition之间存在着两个连接，左侧的连接是输入层通过若干神经层之后连接到Addition，右侧的连接是输入层直接传给Addition，在反向传播的过程中误差传到Input时会得到两个误差的相加和，一个是左侧一堆网络的误差，一个是右侧直接的原始误差。左侧的误差会随着层数变深而梯度越来越小，右侧则是由Addition直接连到Input，所以还会保留着Addition的梯度。这样Input得到的相加和后的梯度就没有那么小了，可以保证接着将误差往下传。</p>
<p>这种方式看似解决了梯度越传越小的问题，但是残差连接在正向同样也发挥了作用。由于正向的作用，导致网络结构已经不再是深层了，而是一个并行的模型，即残差连接的作用是将网络串行改成了并行。这也可以理解为什么Inception v4结合了残差网络的原理后，却没有使用残差连接，反而做出了与Inception-ResNet v2等同的效果。</p>
<p>介绍Resnet主要是为下面的Inception-ResNet v2做铺垫，下面就来看看ILSVRC 2016年的冠军Inception-ResNet v2网络。</p>
<h3 id="11-4-Inception-ResNet-v2结构"><a href="#11-4-Inception-ResNet-v2结构" class="headerlink" title="11.4 Inception-ResNet-v2结构"></a>11.4 Inception-ResNet-v2结构</h3><p>Inception-ResNet v2网络主要是在Inception v3的基础上，加入了ResNet的残差连接而来的。其原理与Inception v4一样，都是进行了细微的结构调整，并且二者的结构复杂度也不相上下。</p>
<p>通过有关论文实验表明：在网络复杂度相近的情况下，Inception-ResNet-v2略优于Inception v4。并且实验出，残差连接在Inception结构中具有提高网络准确率且不会提升计算量的作用，通过将3个带有残差连接的Inception模型和一个Inception v4的组合，就可以在ImageNet上得到3.08%的错误率。</p>
<p>关于二者的具体结构在11.5.2节会介绍相关代码位置，有兴趣的读者可以自行研究，这里不再展开介绍。</p>
<h3 id="11-5-TensorFlow中的图片分类模型库——slim"><a href="#11-5-TensorFlow中的图片分类模型库——slim" class="headerlink" title="11.5 TensorFlow中的图片分类模型库——slim"></a>11.5 TensorFlow中的图片分类模型库——slim</h3><p>TensorFlow 1.0之后推出了一个叫slim的库，TF-slim是TensorFlow的一个新的轻量级高级API接口。它类似前面所介绍的TensorFlow.contrib.layers模块，将很多常见的TensorFlow函数进行了二次封装，使代码变得更加简洁，特别适用于构建复杂结构的深度神经网络，它可以用来定义、训练和评估复杂的模型。</p>
<p>同时，在TensorFlow的models模块里又提供了大量用slim写好的网络模型结构代码，以及用该代码训练出的模型检查点文件，可以作为我们的预训练模型来使用。这些模型主要是与图片分类相关，包括ResNet、VGG、Inception-ResNet-v2等。下面就来详细了解下slim。</p>
<h4 id="11-5-1-获取models中的-slim模块代码"><a href="#11-5-1-获取models中的-slim模块代码" class="headerlink" title="11.5.1 获取models中的 slim模块代码"></a>11.5.1 获取models中的 slim模块代码</h4><p>为了能够使用models中的代码，需要先验证下我们的TensorFlow版本是否集成了slim模块，接着再从GitHub上将models代码下载下来，具体操作如下。</p>
<p>1．验证slim库</p>
<p>在使用slim前，要测试本地的tf.contrib.slim模块是否有效。在命令行中输入如下命令：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -c &quot;import tensorflow.contrib.slim as slim;</span><br><span class="line">eval = slim.evaluation.evaluate_once&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>如果没有生成任何错误，则表明TF-Slim是可以工作的。</p>
<p>2．下载models模块</p>
<p>接下来需要安装TF-slim image models library。来到以下网址<a href="https://github.com/tensorflow/%20models/" target="_blank" rel="noopener">https://github.com/tensorflow/ models/</a> ，可以通过Git 将代码复制下来，也可以手动下载下来（具体操作见8.5.2的详细介绍）。然后解压到本地workspace路径下（就是你自己建立的用来放个人TF代码的路径），通过下面的代码来验证它是否工作。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $workspace/models/research/slim</span><br><span class="line">python -c &quot;from nets import cifarnet; mynet = cifarnet.cifarnet&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>将上面的$workspace替换成你的工作路径（如笔者的是d：\python）。运行时如果没有发生任何错误，则表明一切正常。</p>
<h4 id="11-5-2-models中的slim目录结构"><a href="#11-5-2-models中的slim目录结构" class="headerlink" title="11.5.2 models中的slim目录结构"></a>11.5.2 models中的slim目录结构</h4><p>在models下的slim中一共有5个文件夹。</p>
<p>·Datasets：处理数据集相关的代码。</p>
<p>·Deployment：部署。通过创建clone方式实现跨机器的分布训练，可以在多CPU和多GPU上实现运算的同步或异步。</p>
<p>·Nets：该文件夹里放着各种网络模型。</p>
<p>·Preprocessing：适用于各个网络的图片处理函数。</p>
<p>·Scripts：运行网络模型的一些案例脚本，这些脚本只能在支持shell的系统下使用。</p>
<p>在这里重点介绍Datasets、nets和Preprocessing这3个文件夹。</p>
<p>1．Dataset——数据集处理模块</p>
<p>Dataset里放着常用的图片训练数据集相关的代码。主要支持的数据集主要有cifar10、flowers、mnist、imagenet。</p>
<p>代码文件的名字与数据集相对应，可以使用这些代码下载或获取数据集中的数据。以imagenet为例，可以使用如下函数从网上获取imagenet标签。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imagenet.create_readable_names_for_imagenet_labels()</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码返回的是imagenet中1000个类的分类标签名字（与样本序列对应）。</p>
<p>2．nets模块</p>
<p>nets文件夹下包含前面介绍的各种网络模型，如图11-8所示。</p>
<p><img src="Image00232.jpg" alt></p>
<p>图11-8 nets文件结构</p>
<p>每个网络模型文件都是以自己的名字命名的，而且里面的代码结构框架也大致相同，以inception_resnet_v2为例，如表11-1中列出了比较常用的函数接口。</p>
<p>表11-1 slim中nets的代码框架接口</p>
<p><img src="Image00233.jpg" alt></p>
<p><img src="Image00014.jpg" alt> 注意： 表11-1中的框架全部是使用slim库代码来实现的，由于与tensorflow.contrib.layers模块的使用方式很相似，这里不再展开介绍，但是建议读者配合前面讲的各个模型的结构再看看其具体在代码中的真实实现，对自己构建高效的模型会有很大帮助。</p>
<p>3．Preprocessing模块</p>
<p>该模块代码里包含几个图片预处理文件，命名也是按照模型的名字来命名的。slim会把某一类模型常用的预处理函数放到一个文件里，并命名为该类模型相关的名字，而且每个代码文件函数结构也大致相似。例如，调用inception_preprocessing函数中的代码如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inception_preprocessing.preprocess_image</span><br></pre></td></tr></table></figure>

</details>

<p>该函数是将传入的图片转化成模型尺寸并归一化处理。</p>
<h4 id="11-5-3-slim中的数据集处理"><a href="#11-5-3-slim中的数据集处理" class="headerlink" title="11.5.3 slim中的数据集处理"></a>11.5.3 slim中的数据集处理</h4><p>slim模块包自带了函数，可以用来下载数据集，也可以对数据集进行转换操作。它可以下载标准的数据集并转换为TensorFlow自带的TFRecord格式，还可以使用TF-slim的data reading和queueing utilities来读取TFRecord格式的数据集。slim所支持的数据集如表11-2所示。</p>
<p>表11-2 slim中集成的数据集</p>
<p><img src="Image00234.jpg" alt></p>
<p>1. 将数据转为TFRecord格式</p>
<p>TFRecord是TensorFlow推荐的数据集格式，与TensorFlow框架结合紧密。在TensorFlow中提供了一系列接口可以访问TFRecord格式。该结构存在的意义主要是为了满足在处理海量样本集时，需要边执行训练边从硬盘上读取数据的需求。将原始文件转化成TFRecord的格式，然后在运行中通过多线程的方式来读取，这样可以减小主线程训练的负担，使整个训练过程变得更高效。</p>
<p>只需要在命令行里输入下列命令，即可将下载数据集并将其转成TFRecord格式：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\python\research\models\slim&gt;python download_and_convert_data.py--dataset_ name=flowers—dataset_dir=/tmp/data/flowers</span><br></pre></td></tr></table></figure>

</details>

<p>这里需要指定两个关键点：一个是数据集（例子中的flowers），另一个是下载路径（笔者的Python文件是在D盘，所以会下载到D：\tmp\data\flowers下）。执行完后会看到下载的数据文件和生成的TFRecord文件，如图11-9所示。</p>
<p>这里包含5个训练数据文件、5个验证数据文件及一个标签文件。标签文件定义了整数标签和分类名称。</p>
<p>如果想将其他数据集转成TFRecord格式，可以参考上面的代码实现，这里不再展开介绍。</p>
<p>同样，也可以按照这个方法下载MNIST和cifar10数据集。如果需要下载imageNet数据集，则需要在image-net.org中注册一个账号，然后再运行下载脚本，大概有500GB，因此需要留出足够大的硬盘空间，并且下载时间会很长。</p>
<p>2．处理slim数据集时的常见错误</p>
<p>由于有时网络有时会不稳定，因此使用上面讲的方法下载数据时往往会遇到如下错误，主要是由于没有下载完成的原因。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">urllib.error.ContentTooShortError: &lt;urlopen error retrieval incomplete: </span><br><span class="line">got only</span><br><span class="line"> 64456280 out of 228813984 bytes&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>这表明由于网络原因数据包没有下载完整，有两种方法可以解决。</p>
<p>·如果你的网速较快的话，可以多运行几次，总有一次可以成功。</p>
<p>·可以将<a href="http://download.tensorflow.org/example_images/%20flower_photos.tgz" target="_blank" rel="noopener">http://download.tensorflow.org/example_images/ flower_photos.tgz</a> 网址放到下载工具（如迅雷等）里自行下载。</p>
<p>解压后的路径如图11-10所示。</p>
<p><img src="Image00235.jpg" alt></p>
<p>图11-9 flowers文件夹的TFRecord数据集</p>
<p><img src="Image00236.jpg" alt></p>
<p>图11-10 flowers数据集</p>
<p>然后来到download_and_convert_flowers.py第191行，注释掉下列代码即可。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#dataset_utils.download_and_uncompress_tarball(_DATA_URL,dataset_dir)</span><br></pre></td></tr></table></figure>

</details>

<p>本书配套的代码中会有实例文件（见“11.5.3代码参考”文件夹）。</p>
<p>下载完成后，运行如下命令将刚下载的数据集转成TFRecord格式（以图11-10中的路径“/tmp/data/flowers”为例）：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\python\research\models\slim&gt;python download_and_convert_data.py --dataset_ name=flowers --dataset_dir=/tmp/data/flowers</span><br></pre></td></tr></table></figure>

</details>

<h4 id="11-5-4-实例84：利用slim读取TFRecord中的数据"><a href="#11-5-4-实例84：利用slim读取TFRecord中的数据" class="headerlink" title="11.5.4 实例84：利用slim读取TFRecord中的数据"></a>11.5.4 实例84：利用slim读取TFRecord中的数据</h4><p>TFRecord文件创建好后，就可以读取文件中的数据了，本例将演示如何读取TFRecord中的数据，步骤如下。</p>
<p>实例描述</p>
<p>利用slim代码库里的函数读取TFRecord格式的数据并显示出来。</p>
<p>1．定义slim数据集，创建provider</p>
<p>在图11-9中可以看到，有两个数据集train与validation。在读取时，需要指定一个数据集然后创建provider对象，接着就可以从provider里读取数据了，代码如下：</p>
<p>代码11-1 tfrecodertest</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from datasets import flowers</span><br><span class="line">import pylab </span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line">DATA_DIR=&quot;D:/own/python/flower_photosos&quot; #指定flower数据集的路径</span><br><span class="line"></span><br><span class="line">#选择数据集validation</span><br><span class="line">dataset = flowers.get_split(&apos;validation&apos;, DATA_DIR)</span><br><span class="line"></span><br><span class="line">#创建一个provider</span><br><span class="line">provider = slim.dataset_data_provider.DatasetDataProvider(dataset)</span><br><span class="line">#通过provider的get获得一条样本数据</span><br><span class="line">[image, label] = provider.get([&apos;image&apos;, &apos;label&apos;])</span><br><span class="line">print(image.shape)</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码中，先引入头文件，然后创建provider，通过get来获得image与label两个张量。这时并没有真的读到数据，只是一个构建图的过程。具体取数据则要通过session中启动队列线程后才可以。</p>
<p>provider是使用DatasetDataProvider类的实例化实现的，在DatasetDataProvider类中还可以有更多的设置：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class DatasetDataProvider(data_provider.DataProvider):</span><br><span class="line"> </span><br><span class="line">  def __init__(self,</span><br><span class="line">               dataset,</span><br><span class="line">               num_readers=1,</span><br><span class="line">               reader_kwargs=None,</span><br><span class="line">               shuffle=True,</span><br><span class="line">               num_epochs=None,</span><br><span class="line">               common_queue_capacity=256,</span><br><span class="line">               common_queue_min=128,</span><br><span class="line">               record_key=&apos;record_key&apos;,</span><br><span class="line">               seed=None,</span><br><span class="line">               scope=None):</span><br></pre></td></tr></table></figure>

</details>

<p>必选参数是传入指定的数据集dataset，其他还包括指定几个并行读取器来读取数据num_readers、是否打乱顺序shuffle、指定数据源读取的循环次数num_epochs（None表示无限循环）、队列大小common_queue_capacity等。没有特殊要求的情况下，直接默认即可。</p>
<p><img src="Image00014.jpg" alt> 注意： 本例演示的是只读取一条样本，在训练中需要按批次读取指定数量的样本，这时会需要配合tf.train.batch一起使用，tf.train.batch有个条件就是必须指定样本的固定大小，所以在传入时需要将变长的图片按固定大小调整。在slim的训练模型代码里有使用的例子，读者可以自己参考。另外，在第12章对抗神经网络里，超分辨率部分也有实例供读者学习、参考。</p>
<p>2．启用session读取数据</p>
<p>在session中初始化变量之后，需要通过tf.train.start_queue_runners来启动队列线程。这时会有一个线程专门负责从磁盘里读图片数据，接着通过run来运行图节点image与label得到真实的数据。</p>
<p>代码11-1 tfrecodertest（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">￼17  sess = tf.InteractiveSession()</span><br><span class="line">  tf.global_variables_initializer().run()</span><br><span class="line">  #启动队列</span><br><span class="line">  tf.train.start_queue_runners()</span><br><span class="line">  #获取数据</span><br><span class="line">  image_batch, label_batch = sess.run([image, label])</span><br><span class="line">  #显示</span><br><span class="line">  print(label_batch)</span><br><span class="line">  pylab.imshow(image_batch)</span><br><span class="line">  pylab.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上述代码，输出的图片如图11-11所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(?, ?, 3)</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00237.jpg" alt></p>
<p>图11-11 TFRecord例子</p>
<p>多运行几次发现，每次的结果都不一样，再次证实了默认是随机读取的。</p>
<p><img src="Image00014.jpg" alt> 注意： 在处理大数据样本时，将数据转成TFRecord后使用线程来读取，是一个较常规的方式。千万不能像MNIST数据集读取那样一次都读入内存，内存会被样本耗尽，系统就无法处理其他的数据了。另外，除了使用 TFRecord方式以外，还可以从filenames中读取，通过异步读取文件，然后按批次的随机抽取指定样本数量，再输入到模型中来做模型参数的更新。</p>
<h4 id="11-5-5-在slim中训练模型"><a href="#11-5-5-在slim中训练模型" class="headerlink" title="11.5.5 在slim中训练模型"></a>11.5.5 在slim中训练模型</h4><p>slim提供了很多便捷的方式，前面提到的全部模型在slim中都可以找到对应的代码实现。不仅如此，slim还共享了模型的训练代码，使用者不再需要关注模型代码，只需通过命令行方式即可完成训练、微调、测试等任务，大大方便了模型的产出。</p>
<p>对于linux用户，在slim的Scripts文件夹下还提供了模型下载、训练、预训练、微调、测试等一条龙的完整shell脚本。如果你用的是Windows，也可以在命令行下一条一条地复制命令并执行命令。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">D:\python\research\models\slim&gt;python train_image_classifier.py --train_dir=</span><br><span class="line">log/in3flower --dataset_name=flowers --dataset_split_name=train –datas</span><br><span class="line">et_dir=/tmp/data/flowers/flower_photosos --model_name=inception_v3</span><br></pre></td></tr></table></figure>

</details>

<p>关于shell脚本代码，不再逐条解释，下面举例演示使用命令行来训练模型的相关操作。</p>
<p>1．从头训练</p>
<p>训练模型的代码被放在slim下的train_image_classifier.py文件里，这里用flower数据集来训练Inception_v3网络结构的深度神经网络模型。在命令行中执行如下命令：</p>
<p>参数说明如下。</p>
<p>·train_dir：是要生成模型的路径。</p>
<p>·dataset_name：数据集名字。</p>
<p>·dataset_split_name：数据集中的哪一部分是validation还是train。</p>
<p>·dataset_dir：数据集路径。</p>
<p>·model_name：模型名字。</p>
<p>这里只列出了主要的参数，其他的参数可以仿照shell脚本中的例子，如果读者想知道全部的参数，可参看train_image_classifier.py文件。也可以修改train_image_classifier.py文件，添加自己喜欢的参数。</p>
<p><img src="Image00014.jpg" alt> 注意： dataset_name、dataset_split_name、model_name的名字不是随意命名的，必须与代码中的名字对应。如果使用自己的数据集，则需要在slim中的dataset文件夹下仿照其他的数据集加一个.py文件，然后也可以用train_image_classifier.py来运行。当然读者也可以不使用train_image_classifier.py，直接自己编写代码载入数据集。</p>
<p>2．预训练模型</p>
<p>预训练就是在别人训练好的模型基础上进行二次训练，以得到自己需要的模型。可以帮你省去大量的时间。一些高质量的模型都是通过了大量的数据样本训练而来的。GitHub上提供了很多训练好的模型，可用于预训练，可以在<a href="https://github.com/TensorFlow/models/%20tree/master/research/slim#Pretrained" target="_blank" rel="noopener">https://github.com/TensorFlow/models/ tree/master/research/slim#Pretrained</a> 中下载。</p>
<p>该链接是TensorFlow里slim模块在GitHub中的页面，页面中的表的部分内容如图11-12所示。</p>
<p><img src="Image00238.jpg" alt></p>
<p>图11-12 模型下载截图</p>
<p>图11-12中的表格内，Checkpoint列是模型下载的链接。这些模型都是在ILSVRC-2012-CLS（ImageNet）数据集上训练而来的，这个数据集共500GB，共分为1000个类的图片。想要了解更多关于ImageNet的信息，可以看网站<a href="http://www.image-net.org/%20challenges/LSVRC/2012/" target="_blank" rel="noopener">http://www.image-net.org/ challenges/LSVRC/2012/</a> 。</p>
<p>下载完预训练模型后，只需要在11.5.5节“从头训练”的命令中添加一个参数——checkpoint_path即可。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--checkpoint_path =模型的路径</span><br></pre></td></tr></table></figure>

</details>

<p>--checkpoint_path里的模型用于预训练模型的参数初始化。在训练过程中不会改变，新产生的模型会被保存在—train_dir指定的路径下面。</p>
<p><img src="Image00014.jpg" alt> 注意： 预训练时使用的样本必须与原来的输入尺寸和输出的分类个数一致。这些可下载的模型都是要分成1000类的，如果你不想分这么多类，可以使用下面微调的方法。</p>
<p>3．微调fine-tuning</p>
<p>上述的预训练模型都是在imagenet上训练的，最终输出的是1000个分类，如果我们想使用预训练模型训练自己的数据集时，就要微调了。</p>
<p>在微调过程中，需要将原有模型中的最后一层去掉，换成自己的数据集对应的分类层。例如我们要训练flowers数据集，就需要将1000个输出换成10个输出。</p>
<p>具体做法如下。</p>
<p>（1）通过参数—checkpoint_exclude_scopes指定载入预训练模型时哪一层的权重不被载入。</p>
<p>（2）再通过—trainable_scopes参数指定对哪一层的参数进行训练。当—trainable_scopes出现时，没有被指定训练的参数将在训练中被冻结。</p>
<p>举例：使用inception_v3的模型进行微调，使其可以训练flowers数据集。将下载好的模型inception_v3.ckpt解压后放在当前目录文件夹inception_v3下，通过cmd进入命令行来到models\slim文件夹下，运行如下命令：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\own\python\research\models\slim&gt;python train_image_classifier.py --train_ dir=log/in3--dataset_name=flowers--dataset_split_name=train --dataset_dir= D:\own\python\flower_photosos--model_name=inception_v3--checkpoint_path=</span><br><span class="line">inception_v3/inception_v3.ckpt --checkpoint_exclude_scopes=InceptionV3/ Logits,InceptionV3/AuxLogits --trainable_scopes=InceptionV3/Logits,InceptionV3/ AuxLogits</span><br></pre></td></tr></table></figure>

</details>

<p>在例子中，—checkpoint_path里的模型会被载入，将权重初始化成模型里的值，同时—checkpoint_exclude_scopes限制了最后一层没有被初始化成模型里的参数。—trainable_scopes指定了只训练最后新加的一层，这样在训练过程中被冻结的其他参数具有原来训练好的合适值，而新加的一层则通过迭代在不断地优化自己的参数。</p>
<p>在微调的过程中，还可以通过在上面命令中加入：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--max_number_of_steps=500</span><br></pre></td></tr></table></figure>

</details>

<p>来指定训练步数。如果没有指定训练步数，默认会一直训练下去。更多的参数，可参看train_image_classifier.py的源码。另外，slim的Scripts中还有使用模型来识别图片的例子，读者可以一起配合着学习。</p>
<p><img src="Image00014.jpg" alt> 注意： 有时会报初始化失败的错误：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\ stream _executor\cuda\cuda_dnn.cc:359] could not create cudnn handle: CUDNN_STATUS_</span><br><span class="line">NOT_INITIALIZED</span><br><span class="line">-05-02 17:48:48.334466: E c:\tf_jenkins\home\workspace\release-win\ device\ gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:366] error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows</span><br><span class="line">-05-02 17:48:48.343454: E c:\tf_jenkins\home\workspace\release-win\ device\gpu\ os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:326] could not destroy cudnn handle: CUDNN_STATUS_</span><br><span class="line">BAD_PARAM</span><br></pre></td></tr></table></figure>

</details>

<p>这种问题表明显卡没有启动，重启计算机即可</p>
<p>4．评估模型</p>
<p>eval_image_classifier.py文件是已经封装好用来评估模型的。下面还是以上面的flower集合微调Inception_v3的模型为例，评估模型的命令如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python eval_image_classifier.py--checkpoint_path=log/in3/model.ckpt</span><br><span class="line">-3416059--eval_dir=log/in3/model.ckpt-3416059--dataset_name=flowers</span><br><span class="line">--dataset_split_name=validation--dataset_dir=D:\own\python\flower_</span><br><span class="line">photosos--model_name=inception_v3</span><br></pre></td></tr></table></figure>

</details>

<p>其中，指定路径的文件为log/in3/model.ckpt-3416059，即在微调中训练出来的模型文件。</p>
<p>5．打包模型</p>
<p>训练好的模型可以被打包到各个平台上使用，无论是iOS、Android还是Linux系列。具体是通过一个bazel开源工具来实现的。这部分内容不在本书的范围之内，有兴趣的读者可以自行研究。</p>
<p>更多的内容可以参考链接<a href="https://github.com/tensorflow/models/tree/master/research/%20slim#Export" target="_blank" rel="noopener">https://github.com/tensorflow/models/tree/master/research/ slim#Export</a> 。</p>
<h3 id="11-6-使用slim中的深度网络模型进行图像的识别与检测"><a href="#11-6-使用slim中的深度网络模型进行图像的识别与检测" class="headerlink" title="11.6 使用slim中的深度网络模型进行图像的识别与检测"></a>11.6 使用slim中的深度网络模型进行图像的识别与检测</h3><p>前面模型训练的知识点可以覆盖模型方面的大部分情况。如果读者刚好有图片分类的任务，或是想进行图片的识别，用slim中已有的网络结构来训练出自己的模型，比自己重新写一个模型的可行性更高一些。智者必须要学会借力而行。</p>
<p>有了模型之后就是使用模型了。下面通过几个实例来演示如何使用模型。</p>
<h4 id="11-6-1-实例85：调用Inception-ResNet-v2模型进行图像识别"><a href="#11-6-1-实例85：调用Inception-ResNet-v2模型进行图像识别" class="headerlink" title="11.6.1 实例85：调用Inception_ResNet_v2模型进行图像识别"></a>11.6.1 实例85：调用Inception_ResNet_v2模型进行图像识别</h4><p>本例是使用在ImageNet上训练好的Inception_ResNet_v2模型来识别图片内容，练习通过编写代码来调用slim中的inception_resnet_v2函数。具体步骤如下。</p>
<p>实例描述</p>
<p>使用基于ImageNet上训练的Inception_ResNet_v2模型对任意图片进行识别。</p>
<p>1．准备工作</p>
<p>需要准备好Inception_ResNet_v2的模型文件（上文有下载方法介绍），以及两张用于识别的图片。</p>
<p>2．引入头文件，指定模型</p>
<p>在slim文件夹下创建代码文件。代码中通过导入nets中的Inception模块，即可包含slim中的所有网络结构代码，导入Datasets中的imagenet是为了使用imagenet的label标签，方便识别后的显示。为了让代码简洁一些，令slim = tf.contrib.slim。</p>
<p>代码11-2 inception_resnet_v2使用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> import tensorflow as tf</span><br><span class="line"> </span><br><span class="line"> from PIL import Image</span><br><span class="line"> from matplotlib import pyplot as plt</span><br><span class="line"> from nets import inception</span><br><span class="line"> import numpy as np</span><br><span class="line"> from datasets import imagenet</span><br><span class="line"> </span><br><span class="line"> tf.reset_default_graph()</span><br><span class="line"> image_size = inception.inception_resnet_v2.default_image_size</span><br><span class="line"> names = imagenet.create_readable_names_for_imagenet_labels()</span><br><span class="line"> </span><br><span class="line"> slim = tf.contrib.slim</span><br><span class="line"> </span><br><span class="line"> checkpoint_file = &apos;inception_resnet_v2/inception_resnet_v2_2016_</span><br><span class="line">_30.ckpt&apos;</span><br><span class="line"> sample_images = [&apos;img.jpg&apos;, &apos;ps.jpg&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>将inception_resnet_v2中的默认尺寸取到，给出模型文件和图片的路径即文件名。</p>
<p>3．载入模型</p>
<p>获取模型参数的命名空间arg_scope，定义相同命名空间下的输出节点。Logits是刚从网络结构里运算出来的输出。end_points为一个全集，里面包含logits和将logits经过softmax之后的预测结果及其他信息。具体可以参考nets下Inception_ResNet_v2里的inception_resnet_v2函数。</p>
<p>代码11-2 inception_resnet_v2使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> input_imgs = tf.placeholder(&quot;float&quot;, [None, image_size,image_size,3])</span><br><span class="line"> </span><br><span class="line"> #载入 model</span><br><span class="line"> sess = tf.Session()</span><br><span class="line"> arg_scope = inception.inception_resnet_v2_arg_scope()</span><br><span class="line"> </span><br><span class="line"> with slim.arg_scope(arg_scope):</span><br><span class="line">   logits, end_points = inception.inception_resnet_v2(input_imgs, </span><br><span class="line">is_training=False)</span><br><span class="line"> </span><br><span class="line"> saver = tf.train.Saver()</span><br><span class="line"> saver.restore(sess, checkpoint_file)</span><br></pre></td></tr></table></figure>

</details>

<p>在session里通过saver载入模型，这部分内容前面讲过，这里不再赘述。</p>
<p>4．输入图片进行识别</p>
<p>通过循环读入sample_images中指定的图片，然后使用resize函数将其重新调整尺寸到指定大小，再使用reshape函数重新将形状调整成[-1，image_size，image_size，3]矩阵，并将其除以255再乘上2，然后减去1，归一化成[-1，1]之间的值，输入模型生成结果。</p>
<p>代码11-2 inception_resnet_v2使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">for image in sample_images:</span><br><span class="line">    reimg = Image.open(image).resize((image_size,image_size))</span><br><span class="line">    reimg = np.array(reimg)</span><br><span class="line">    reimg = reimg.reshape(-1,image_size,image_size,3)</span><br><span class="line">    </span><br><span class="line">    plt.figure()  </span><br><span class="line">    p1 = plt.subplot(121)</span><br><span class="line">    p2 = plt.subplot(122)</span><br><span class="line">    </span><br><span class="line">    p1.imshow(reimg[0])# 显示图片</span><br><span class="line">    p1.axis(&apos;off&apos;) </span><br><span class="line">    p1.set_title(&quot;organization image&quot;)</span><br><span class="line"></span><br><span class="line">    reimg_norm = 2 *(reimg / 255.0)-1.0 </span><br><span class="line">    </span><br><span class="line">    p2.imshow(reimg_norm[0])                  # 显示图片</span><br><span class="line">    p2.axis(&apos;off&apos;) </span><br><span class="line">    p2.set_title(&quot;input image&quot;)  </span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line">    predict_values, logit_values = sess.run([end_points[&apos;Predictions&apos;],</span><br><span class="line">     logits], feed_dict=&#123;input_imgs: reimg_norm&#125;)</span><br><span class="line">     </span><br><span class="line">    print (np.max(predict_values), np.max(logit_values))</span><br><span class="line">    print (np.argmax(predict_values), np.argmax(logit_values),names</span><br><span class="line">     [np.argmax(logit_values)])</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 在数值变换中，本来应该使用slim自带的inception_preprocessing.preprocess_image函数将图片直接处理好，但是该代码似乎有点bug，模型不能识别出处理完的图片。于是改为手动来转化。GitHub中的代码还在不断更新中，或许当读者看这本书的时候已经没有bug了，那么就可以用inception_preprocessing.preprocess_image函数来替代。</p>
<p>运行代码，得到输出如下，输出图片如图11-13和图11-14所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Restoring parameters from inception_resnet_v2/inception_</span><br><span class="line">resnet_v2_2016_08_30.ckpt</span><br><span class="line">0.61667 9.0568</span><br><span class="line"> 621 laptop, laptop computer</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00239.jpg" alt></p>
<p>图11-13 inception_resnet_v2例子结果1</p>
<p><img src="Image00240.jpg" alt></p>
<p>图11-14 inception_resnet_v2例子结果2</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.242343 8.80805</span><br><span class="line"> 223 kuvasz</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到模型成功地识别了平板电脑。对于第二幅图，本来是只羊，却识别成了库瓦兹犬，这可能是由于训练样本中关于狗的样本比较多的原因，整个ImageNet数据集对狗的分类比较细致。不过看一下库瓦兹犬的图片（如图11-5所示），它跟羊真的有点相像。</p>
<p><img src="Image00241.jpg" alt></p>
<p>图11-15 库瓦兹犬</p>
<p>从图11-5中看，库瓦兹犬就像是一只“披着羊皮”的狗，可见Inception_ResNet_v2惊人的识别力。</p>
<p>slim中的所有的模型的使用方法几乎一样，这里使用的Inception_ResNet_v2模型只是一个例子。若读者想使用其他模型，可以仿照该例子直接将模型名字替换Inception_ ResNet_v2即可。</p>
<h4 id="11-6-2-实例86：调用VGG模型进行图像检测"><a href="#11-6-2-实例86：调用VGG模型进行图像检测" class="headerlink" title="11.6.2 实例86：调用VGG模型进行图像检测"></a>11.6.2 实例86：调用VGG模型进行图像检测</h4><p>VGG作为深度学习模型，本来是为了识别图像而产生的，但其在图像检测方面的效果很好，于是就成为图像检测方面的标杆模型。下面通过一个实例来使用VGG19模型对图片进行检测，看看VGG模型能从图片中识别哪些东西。具体步骤如下。</p>
<p>实例描述</p>
<p>使用基于ImageNet上训练的VGG19模型对任意图片进行检测。</p>
<p>1．准备工作</p>
<p>准备好解压后的vgg_19.ckpt模型文件，放到当前vgg_19_2016_08_28目录下，这里还使用实例85中的两张图片进行检测。</p>
<p>2．引入头文件，指定模型</p>
<p>类似实例85，在slim文件夹下创建代码文件。导入nets中的VGG模块，同时导入像素均值处理函数mean_image_subtraction，导入Datasets中imagenet的label标签，令slim = tf.contrib.slim。</p>
<p>代码11-3 vgg19图片检测使用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">from datasets import imagenet</span><br><span class="line">from nets import vgg</span><br><span class="line"># 加载像素均值及相关函数</span><br><span class="line">from preprocessing.vgg_preprocessing import (_mean_image_subtraction,</span><br><span class="line">_R_MEAN, _G_MEAN, _B_MEAN)</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">import matplotlib as mpl</span><br><span class="line">mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]    #用来正常显示中文标签</span><br><span class="line">mpl.rcParams[&apos;font.family&apos;] = &apos;STSong&apos;</span><br><span class="line">mpl.rcParams[&apos;font.size&apos;] = 12</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"># 网络模型的输入图像有默认的尺寸</span><br><span class="line"># 先调整输入图片的尺寸</span><br><span class="line"></span><br><span class="line">names = imagenet.create_readable_names_for_imagenet_labels()</span><br><span class="line">checkpoints_dir = &apos;vgg_19_2016_08_28&apos;</span><br><span class="line">sample_images = [&apos;hy.jpg&apos;, &apos;ps.jpg&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义节点，载入模型</p>
<p>定义输入占位符，在这里不需要使用VGG的默认尺寸，所以使用[None，None，3]的shape对输入节点进行均值处理，并使用reshape函数更新，将形状调整成1，None，None，3]。</p>
<p>获取模型参数的命名空间arg_scope，定义相同命名空间下的输出节点。Logits是刚从网络结构里运算出来的输出。手动将logits的最大索引放入pred里，即代表分类。</p>
<p>代码11-3 vgg19图片检测使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">input_imgs = tf.placeholder(&quot;float&quot;, [None,None,3])</span><br><span class="line"># 每个像素减去像素的均值</span><br><span class="line">processed_image = _mean_image_subtraction(input_imgs,</span><br><span class="line">                                          [_R_MEAN, _G_MEAN, _B_MEAN])</span><br><span class="line"></span><br><span class="line">input_image = tf.expand_dims(processed_image, 0)</span><br><span class="line">with slim.arg_scope(vgg.vgg_arg_scope()): #spatial_squeeze选项用于压缩结果的空间维度，将不必要的空间维度删除</span><br><span class="line"></span><br><span class="line">    logits, _ = vgg.vgg_19(input_image,</span><br><span class="line">                           num_classes=1000,</span><br><span class="line">                           is_training=False,</span><br><span class="line">                           spatial_squeeze=False)</span><br><span class="line"></span><br><span class="line">pred = tf.argmax(logits, dimension=3)</span><br><span class="line"></span><br><span class="line">init_fn = slim.assign_from_checkpoint_fn(</span><br><span class="line">    os.path.join(checkpoints_dir, &apos;vgg_19.ckpt&apos;),</span><br><span class="line">    slim.get_model_variables(&apos;vgg_19&apos;))</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    init_fn(sess)</span><br></pre></td></tr></table></figure>

</details>

<p>指定模型文件vgg_19.ckpt，并在session中载入。</p>
<p>4．输入图片进行检测</p>
<p>通过循环读入sample_images中指定的图片，传入模型，生成结果obj。VGG的输出与其他模型不一样，它会返回识别出来的所有类别，并且顺序是与像素位置关系相对应的。使用np.unique函数会返回两个值，第一个值为对应的类别，第二个值为该类在obj中的起始位置。</p>
<p>代码11-3 vgg19图片检测使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">for image in sample_images:</span><br><span class="line">        reimg = Image.open(image)</span><br><span class="line">        plt.suptitle(&quot;原始图片&quot;, fontsize=14, fontweight=&apos;bold&apos;)</span><br><span class="line">        plt.imshow(reimg)               # 显示图片</span><br><span class="line">        plt.axis(&apos;off&apos;)                 # 不显示坐标轴</span><br><span class="line">        plt.show()        </span><br><span class="line">        </span><br><span class="line">        reimg = np.asarray(reimg, dtype=&apos;float&apos;)</span><br><span class="line">        </span><br><span class="line">        obj,inpt= sess.run([pred,input_image],feed_dict=&#123;input_imgs: </span><br><span class="line">       reimg&#125;)</span><br><span class="line">        </span><br><span class="line">        obj = np.squeeze(obj)</span><br><span class="line">        </span><br><span class="line">        unique_classes, relabeled_image = np.unique(obj,</span><br><span class="line">                                                    return_inverse=True)</span><br><span class="line">        </span><br><span class="line">        obj_size = obj.shape</span><br><span class="line">        relabeled_image = relabeled_image.reshape(obj_size)</span><br><span class="line">        labels_names = []</span><br><span class="line"></span><br><span class="line">        for index, current_class_number in enumerate(unique_classes):</span><br><span class="line">            labels_names.append(str(index) + &apos; &apos; + names[current_class_</span><br><span class="line">           number+1])</span><br></pre></td></tr></table></figure>

</details>

<p>5．输出结果</p>
<p>接着添加如下代码，将结果显示出来。</p>
<p>代码11-3 vgg19图片检测使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> showobjlab(img=relabeled_image, labels_str=labels_names, </span><br><span class="line">title=&quot;画面识别&quot;)</span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>这里用到了一个显示函数showobjlab，需要先定义一下。它将img位置obj中的类以不同的颜色在图像中显示出来。具体实现如下。</p>
<p>代码11-3 vgg19图片检测使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def showobjlab(img, labels_str=[], title=&quot;&quot;):</span><br><span class="line">    minval = np.min(img)</span><br><span class="line">    maxval = np.max(img)</span><br><span class="line">    #获取离散化的色彩表</span><br><span class="line">    plt.figure(figsize=(3,3)) </span><br><span class="line">    cmap = plt.get_cmap(&apos;Paired&apos;, np.max(img)-np.min(img)+1)</span><br><span class="line">    mat = plt.matshow(img, cmap=cmap,vmin = minval-0.5,vmax = maxval +0.5)</span><br><span class="line">    </span><br><span class="line">    #定义colorbar</span><br><span class="line">    cax = plt.colorbar(mat,ticks=np.arange(minval,maxval+1),shrink=2)</span><br><span class="line"></span><br><span class="line">    # 添加类别名称</span><br><span class="line">    if labels_str:</span><br><span class="line">        cax.ax.set_yticklabels(labels_str)</span><br><span class="line"></span><br><span class="line">    if title:</span><br><span class="line">        plt.suptitle(title, fontsize=14, fontweight=&apos;bold&apos;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，得到如下结果，输出图片如图11-16～图11-19所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Restoring parameters from vgg_19_2016_08_28\vgg_19.ckpt</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00242.jpg" alt></p>
<p>图11-16 Vgg例子1的原始图片</p>
<p><img src="Image00243.jpg" alt></p>
<p>图11-17 Vgg例子1的识别结果</p>
<p><img src="Image00244.jpg" alt></p>
<p>图11-18 Vgg例子2的原始图片</p>
<p><img src="Image00245.jpg" alt></p>
<p>图11-19 Vgg例子2的识别结果</p>
<p>代码中将检测到的物体类别分别用不同的颜色来显示，并在图片上的对应位置做了标记。可以看到，对于元素较多的第一幅图片，VGG会识别出来更多的类型。</p>
<h3 id="11-7-实物检测模型库——Object-Detection-API"><a href="#11-7-实物检测模型库——Object-Detection-API" class="headerlink" title="11.7 实物检测模型库——Object Detection API"></a>11.7 实物检测模型库——Object Detection API</h3><p>Object Detection API是谷歌开放的一个内部使用的物体识别系统。2016年10月，该系统在COCO识别挑战中名列第一。它支持当前最佳的实物检测模型，能够在单个图像中定位和识别多个对象。该系统不仅用于谷歌于自身的产品和服务，还被推广至整个研究社区。</p>
<p>1．代码位置与内置的模型</p>
<p>Object Detection模块的位置与slim的位置相近，同在github.com中TensorFlow的models\research目录下。类似slim，Object Detection也囊括了各种关于物体检测的各种先进模型：</p>
<p>·带有MobileNets的SSD（Single Shot Multibox Detector）。</p>
<p>·带有Inception V2的SSD。</p>
<p>·带有Resnet 101的R-FCN（Region-Based Fully Convolutional Networks）。</p>
<p>·带有Resnet 101的Faster RCNN。</p>
<p>·带有Inception-Resnet v2的Faster RCNN。</p>
<p>上述每一个模型的冻结权重（在COCO数据集上训练）可被直接加载使用。</p>
<p>SSD模型使用了轻量化的 MobileNet，这意味着它们可以轻而易举地在移动设备中实时使用。谷歌使用了Fast RCNN模型需要更多计算资源，但结果更为准确。</p>
<p>2．COCO数据集介绍</p>
<p>在实物检测领域，训练模型的最权威数据集就是COCO数据集。</p>
<p>COCO数据集是微软发布的一个可以用来进行图像识别训练的数据集，官方网址为<a href="http://mscoco.org/" target="_blank" rel="noopener">http://mscoco.org/</a> 。其图像主要从复杂的日常场景中截取，图像中的目标通过精确的segmentation进行位置的标定。</p>
<p>COCO数据集包括91类目标，分两部分发布，前部分于2014年发布，后部分于2015年发布。</p>
<p>·2014年版本：训练集有82783个样本，验证集有40504个样本，测试集有40775个样本，有270KB的人物标注和886KB的物体标注。</p>
<p>·2015年版本：训练集有165482个样本，验证集有81208个样本，测试集有81434个样本。</p>
<h4 id="11-7-1-准备工作"><a href="#11-7-1-准备工作" class="headerlink" title="11.7.1 准备工作"></a>11.7.1 准备工作</h4><p>1．获取protobuf</p>
<p>Object Detection API使用protobufs来配置模型和训练参数，这些文件以“.proto”的扩展名放在models\research\object_detection\protos下。在使用框架之前，必须使用protobuf库将其编译成py文件才可以正常运行。protobuf库使用的是2.6版本，下载地址为<a href="https://github.com/%20google/protobuf/releases/tag/v2.6.1" target="_blank" rel="noopener">https://github.com/ google/protobuf/releases/tag/v2.6.1</a> 。</p>
<p>进入网址后会看到如图11-20所示，单击相应链接即可下载。</p>
<p><img src="Image00246.jpg" alt></p>
<p>图11-20 protobuf下载包</p>
<p>protoc-2.6.1-win32.zip文件是个绿色程序，可以直接在命令行里运行。下载并解压后将其放到models\research路径下（假设你已经完成了在11.5.1中下载models的步骤）。</p>
<p>2．编译proto配置文件</p>
<p>来到命令行里，进入models\research目录（如笔者的目录是D：\own\python\models research）下，执行如下命令：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\own\python\models\ research&gt;protoc.exe object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

</details>

<p>如果不显示任何信息，则表明运行成功了。为了检验成功效果，可以来到D：\own python\models\research\object_detection\protos下，如图11-21所示，可以看到生成了很多py文件。</p>
<p><img src="Image00247.jpg" alt></p>
<p>图11-21 编译protos</p>
<p>3．检测API是否正常</p>
<p>如果前面两步都完成了，下面可以测试一下Object Detection API是否可以正常使用了，还需要两步操作：</p>
<p>（1）将models\research\slim中的nets文件夹复制出来放到models\research下。</p>
<p>（2）将models\research\object_detection\builders下的model_builder_test.py复制到models\research下。</p>
<p>变成如图11-22所示的文件夹结构。</p>
<p><img src="Image00248.jpg" alt></p>
<p>图11-22 Object Detection配置的文件结构</p>
<p>用spyder将model_builder_test.py/research文件打开，运行之后会看到如下信息：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">runfile(&apos;D:/own/python/models/research/model_builder_test.py&apos;, wdir=&apos;D:/</span><br><span class="line">own/python/models/research&apos;)</span><br><span class="line">Reloaded modules: object_detection.protos.box_predictor_pb2, object_</span><br><span class="line">detection.core, object_detection.anchor_generators.multiple_grid_anchor_generator, object_detection.core.target_assigner, object_detection.protos.image_resizer_pb2, object_detection.protos.losses_pb2, object_detection.utils.static_shape, object_detection.builders.anchor_generator_builder, object_detection.anchor_generators.grid_anchor_generator, object_detection.builders,object_detection.core.standard_fields,object_detection.core.losses,object_detection.builders.hyperparams_builder, </span><br><span class="line">object_detection.core.box_list_ops, object_detection.protos.box_coder_pb2,object_detection.utils,object_</span><br><span class="line">detection.builders.box_predictor_builder,object_detection.utils.shape_</span><br><span class="line">utils,object_detection.core.box_list,object_detection.anchor_generators,</span><br><span class="line">object_detection.box_coders,object_detection.box_coders.mean_stddev_box_</span><br><span class="line">coder, object_detection.protos, object_detection.protos.hyperparams_pb2, </span><br><span class="line">object_detection.core.box_coder,object_detection.protos.ssd_anchor_</span><br><span class="line">generator_pb2, object_detection.meta_architectures, object_detection.</span><br><span class="line">core.model,object_detection.protos.square_box_coder_pb2,object_detection.</span><br><span class="line">core.post_processing,object_detection.box_coders.faster_rcnn_box_coder,</span><br><span class="line">object_detection.protos.grid_anchor_generator_pb2,object_detection.protos.</span><br><span class="line">matcher_pb2, object_detection.models, object_detection.protos.anchor_</span><br><span class="line">generator_pb2,object_detection.matchers.bipartite_matcher,object_detection.</span><br><span class="line">core.preprocessor,object_detection.meta_architectures.ssd_meta_arch,</span><br><span class="line">object_detection.protos.post_processing_pb2,object_detection.protos.</span><br><span class="line">argmax_matcher_pb2,object_detection.core.anchor_generator,object_detection.</span><br><span class="line">utils.ops,object_detection.matchers,object_detection.matchers.argmax_</span><br><span class="line">matcher,object_detection.protos.faster_rcnn_box_coder_pb2,object_detection.</span><br><span class="line">builders.region_similarity_calculator_builder,object_detection.</span><br><span class="line">builders.image_resizer_builder,object_detection.core.matcher,object_</span><br><span class="line">detection.meta_architectures.faster_rcnn_meta_arch,object_detection.</span><br><span class="line">core.minibatch_sampler,object_detection.core.balanced_positive_negative_</span><br><span class="line">sampler,object_detection.protos.bipartite_matcher_pb2,object_detection.</span><br><span class="line">core.keypoint_ops,object_detection.protos.region_similarity_calculator_</span><br><span class="line">pb2,object_detection.builders.matcher_builder,object_detection.builders.</span><br><span class="line">losses_builder,object_detection.meta_architectures.rfcn_meta_arch,object_</span><br><span class="line">detection.core.box_predictor,object_detection.builders.box_coder_builder,</span><br><span class="line">object_detection.box_coders.square_box_coder,object_detection.protos.</span><br><span class="line">mean_stddev_box_coder_pb2,object_detection.utils.variables_helper,object_</span><br><span class="line">detection,object_detection.core.region_similarity_calculator,object_</span><br><span class="line">detection.builders.post_processing_builder</span><br><span class="line">……</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">Ran 7 tests in 0.047s</span><br><span class="line"> </span><br><span class="line">OK</span><br><span class="line">To exit: use &apos;exit&apos;,&apos;quit&apos;,or Ctrl-D.</span><br><span class="line">An exception has occurred,use %tb to see the full traceback.</span><br><span class="line"> </span><br><span class="line">SystemExit: &lt;sitecustomize.IPyTesProgram object at 0x000002B770CBA048&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>表明Object Detection API一切正常，可以使用了。</p>
<p>4．将Object Detection API加入Python库默认搜索路径</p>
<p>为了不用每次都将文件复制到Object Detection文件夹外，可以将Object Detection加到Python引入库的默认搜索路径中，将Object Detection文件夹整个复制到anaconda3安装文件目录下的lib\site-packages下，如图11-23所示。</p>
<p><img src="Image00249.jpg" alt></p>
<p>图11-23 Object Detection安装</p>
<p>这样无论文件在哪里，只要搜索import Object Detection xxx ，系统都会找到Object Detection了。</p>
<h4 id="11-7-2-实例87：调用Object-Detection-API进行实物检测"><a href="#11-7-2-实例87：调用Object-Detection-API进行实物检测" class="headerlink" title="11.7.2 实例87：调用Object Detection API进行实物检测"></a>11.7.2 实例87：调用Object Detection API进行实物检测</h4><p>下面用一个例子来测试下Object Detection API中的检测效果。该例子改编于Object Detection API的自带程序，使用的图片也是Object Detection API中的图片。具体步骤如下。</p>
<p>实例描述</p>
<p>使用Object Detection API基于COCO上训练的ssd_mobilenet_v1模型，对任意图片进行分类识别。</p>
<p>1．下载模型</p>
<p>上面介绍的已有模型，在以下网址都可以下载<a href="https://github.com/tensorflow/models/%20blob/master/research/object_detection/g3doc/detection_model_zoo.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/ blob/master/research/object_detection/g3doc/detection_model_zoo.md</a> 。</p>
<p>下载模型如图11-24所示。</p>
<p><img src="Image00250.jpg" alt></p>
<p>图11-24 下载Detection模型</p>
<p>每一个压缩文件里都包含如下3种文件：</p>
<p>·放置权重的检查点文件。</p>
<p>·描述网络变量的txt文件。</p>
<p>·可用于变量载入内存的图frozen文件。该文件与检查点结合可以实现“开箱即用”的使用理念，即不需要如前面例子中再引入一次网络模型源码文件。</p>
<p>2．载入模型及数据集样本标签</p>
<p>在Object Detection文件夹下新建一个py文件，编写如下代码。</p>
<p>代码中首先加载引入库。然后指定检测点文件及相关路径，将*.pb文件读入serialized_ graph中，重新定义一个图od_graph_def，使用其ParseFromString方法将serialized_graph的内容恢复到图中，接着再使用tf.import_graph_def将od_graph_def的内容导入到当前的默认图中。</p>
<p>代码11-4 Object Detection使用</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> import numpy as np</span><br><span class="line"> import os</span><br><span class="line"> </span><br><span class="line"> import tensorflow as tf</span><br><span class="line"> from matplotlib import pyplot as plt</span><br><span class="line"> from PIL import Image</span><br><span class="line"> from object_detection.utils import label_map_util</span><br><span class="line"> </span><br><span class="line"> from object_detection.utils import visualization_utils as vis_util</span><br><span class="line"> </span><br><span class="line"> # 指定要使用模型的名字</span><br><span class="line"> MODEL_NAME = &apos;ssd_mobilenet_v1_coco_11_06_2017&apos;</span><br><span class="line"> </span><br><span class="line"> # 指定模型的路径</span><br><span class="line"> PATH_TO_CKPT = MODEL_NAME + &apos;/frozen_inference_graph.pb&apos;</span><br><span class="line"> </span><br><span class="line"> # 数据集对应的label</span><br><span class="line"> PATH_TO_LABELS = os.path.join(&apos;data&apos;, &apos;mscoco_label_map.pbtxt&apos;)</span><br><span class="line"> </span><br><span class="line"> NUM_CLASSES = 90</span><br><span class="line"> </span><br><span class="line"> tf.reset_default_graph()</span><br><span class="line">         </span><br><span class="line"> od_graph_def = tf.GraphDef()</span><br><span class="line"> with tf.gfile.GFile(PATH_TO_CKPT, &apos;rb&apos;) as fid:</span><br><span class="line">     serialized_graph = fid.read()</span><br><span class="line">     od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">     tf.import_graph_def(od_graph_def, name=&apos;&apos;)       </span><br><span class="line"> #载入coco数据集标签文件        </span><br><span class="line"> label_map = label_map_util.load_labelmap(PATH_TO_LABELS)</span><br><span class="line"> categories = label_map_util.convert_label_map_to_categories(label_</span><br><span class="line">map, max_num_classes=NUM_CLASSES, use_display_name=True)</span><br><span class="line"> category_index = label_map_util.create_category_index(categories)</span><br></pre></td></tr></table></figure>

</details>

<p>在Object Detection模块中有一个data文件夹，里面为放置好的coco数据集对应的标签txt文件和其他的数据集标签文件（pascal与pet数据集）。使用Object Detection 自带的label_map_util类可以将其以index的方式读入内存中。</p>
<p>3．定义session加载待测试的图片文件</p>
<p>本例也使用Object Detection自带的测试图片来演示。该图片存放在Object Detection test_images中，一共有两张。当然读者也可以自己再添加图片进行测试，但要修改对应的名字和代码。</p>
<p>代码11-4 Object Detection使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> def load_image_into_numpy_array(image):</span><br><span class="line">   (im_width, im_height) = image.size</span><br><span class="line">   return np.array(image.getdata()).reshape(</span><br><span class="line">       (im_height, im_width, 3)).astype(np.uint8)        </span><br><span class="line">         </span><br><span class="line"> PATH_TO_TEST_IMAGES_DIR = &apos;test_images&apos;</span><br><span class="line"> TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, &apos;image&#123;&#125;.</span><br><span class="line">jpg&apos;.format(i)) for i in range(1, 3) ] #将要测试的图片路径放到数组里</span><br><span class="line"> </span><br><span class="line"> # 设置输出图片的大小</span><br><span class="line"> IMAGE_SIZE = (12, 8)        </span><br><span class="line">         </span><br><span class="line"> detection_graph = tf.get_default_graph()        </span><br><span class="line"> with tf.Session(graph=detection_graph) as sess:</span><br><span class="line">     for image_path in TEST_IMAGE_PATHS:</span><br><span class="line">       image = Image.open(image_path)</span><br><span class="line">     </span><br><span class="line">       image_np = load_image_into_numpy_array(image)</span><br></pre></td></tr></table></figure>

</details>

<p>本例中新建立了一个图，为了不易混淆，可通过get_default_graph获得当前的默认图，接下来在默认的图上建立session并进行测试。</p>
<p>4．定义节点，运行结果并可视化</p>
<p>下面可以体验一下Object Detection中的“开箱即用”概念。因为在前面已经将变量导入图中了，所以这里不需要再定义一套变量，直接通过get_tensor_by_name拿到变量并使用即可。这种方式将模型与应用很好的解耦，做应用的人不再需要了解模型的结构，只需关心输入输出和模型文件，做模型的人也不用担心模型代码被误改导致功能失效。</p>
<p>代码11-4 Object Detection使用（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 扩充维度 shape，变成: [1, None, None, 3]</span><br><span class="line">      image_np_expanded = np.expand_dims(image_np, axis=0)</span><br><span class="line">      image_tensor = detection_graph.get_tensor_by_name(&apos;image_</span><br><span class="line">     tensor:0&apos;)</span><br><span class="line">      # boxes用来显示识别结果</span><br><span class="line">      boxes = detection_graph.get_tensor_by_name(&apos;detection_boxes:0&apos;)</span><br><span class="line">      # Each score代表识别出的物体与标签匹配的相似程度，在类型标签后面</span><br><span class="line">      </span><br><span class="line">      scores = detection_graph.get_tensor_by_name(&apos;detection_</span><br><span class="line">     scores:0&apos;)</span><br><span class="line">      classes = detection_graph.get_tensor_by_name(&apos;detection_</span><br><span class="line">     classes:0&apos;)</span><br><span class="line">      num_detections = detection_graph.get_tensor_by_name(&apos;num_</span><br><span class="line">     detections:0&apos;)</span><br><span class="line">      # 开始检测</span><br><span class="line">      (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">          [boxes, scores, classes, num_detections],</span><br><span class="line">          feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">      # 可视化结果</span><br><span class="line">      vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">          image_np,</span><br><span class="line">          np.squeeze(boxes),</span><br><span class="line">          np.squeeze(classes).astype(np.int32),</span><br><span class="line">          np.squeeze(scores),</span><br><span class="line">          category_index,</span><br><span class="line">          use_normalized_coordinates=True,</span><br><span class="line">          line_thickness=8)</span><br><span class="line">      plt.figure(figsize=IMAGE_SIZE)</span><br><span class="line">      plt.imshow(image_np)</span><br></pre></td></tr></table></figure>

</details>

<p>模型的检测结果有3个输出，一个是位置boxes、一个是类型，另一个是分数。得到这3个输出后调用Object Detection中的visualize_boxes_and_labels_on_image_array函数，将图片显示出来。运行代码，输出如图11-25所示。</p>
<p><img src="Image00251.jpg" alt></p>
<p>图11-25 实物检测例子运行结果</p>
<p><img src="Image00014.jpg" alt> 注意： 如何得到里面的变量名？一般会在提供模型时会给出对应例子；如果没有，则可以在代码中找到相应的模型定义；也可以通过在代码中添加print（detection_ graph.get_operations（））将图中所有的变量打印出来，第一行就可以找到占位符，最后一行也可以找到输出结果。</p>
<h3 id="11-8-实物检测领域的相关模型"><a href="#11-8-实物检测领域的相关模型" class="headerlink" title="11.8 实物检测领域的相关模型"></a>11.8 实物检测领域的相关模型</h3><p>前面的预置模型都属于实物检测领域的优秀模型，也是比较成熟的模型。本节来介绍一下该领域的其他相关模型知识。</p>
<h4 id="11-8-1-RCNN基于卷积神经网络特征的区域方法"><a href="#11-8-1-RCNN基于卷积神经网络特征的区域方法" class="headerlink" title="11.8.1 RCNN基于卷积神经网络特征的区域方法"></a>11.8.1 RCNN基于卷积神经网络特征的区域方法</h4><p>实物检测领域的基础模型需要从RCNN（regions with CNN）说起。RCNN模型可以理解为，增加特征的穷举范围，然后在其中发现有价值的特征。大概步骤如下。</p>
<p>（1）对于一幅输入的图片，通过选择性搜索，找出2000个候选窗口。</p>
<p>（2）利用CNN对它们提取特征向量，即将这2000个子图片统一缩放到227×227，然后进行卷积操作。</p>
<p>（3）利用SVM算法对特征向量进行分类识别。</p>
<p>RCNN中对每一类都进行SVM训练，根据输出的特征类为每一个区打分，最终决定保留或拒绝该区域特征。</p>
<h4 id="11-8-2-SPP-Net：基于空间金字塔池化的优化RCNN方法"><a href="#11-8-2-SPP-Net：基于空间金字塔池化的优化RCNN方法" class="headerlink" title="11.8.2 SPP-Net：基于空间金字塔池化的优化RCNN方法"></a>11.8.2 SPP-Net：基于空间金字塔池化的优化RCNN方法</h4><p>RCNN这种海量的穷举方法显然会带来巨大的计算量，有一种优化办法是使用空间金字塔池化方法。</p>
<p>空间金字塔池化（Spatial Pyramid Pooling，SPP）最大的特点是，不再关心输入图片的尺寸，而是根据最后的输出类别个数，通过算法来生成多个不同范围的池化层，由它们对输入进行并行池化处理，使最终的输出特征个数与生成类别个数相等，接着再进行类别的比较和判定。</p>
<p>由这样的技术产生的网络叫做SPP-Net。该网络只需要计算完整图像的特征图（feature maps）一次，然后通过池化子窗口的特征，来保持固定长度的输出，比RCNN先划分窗口再对每个窗口进行卷积的效率要快30～170倍，并且有更好的准确率。</p>
<h4 id="11-8-3-Fast-R-CNN快速的RCNN模型"><a href="#11-8-3-Fast-R-CNN快速的RCNN模型" class="headerlink" title="11.8.3 Fast-R-CNN快速的RCNN模型"></a>11.8.3 Fast-R-CNN快速的RCNN模型</h4><p>Fast-R-CNN在SPP-Net基础上进行了改进，并将它嫁接到VGG16上所形成的网络，将SPP改成RoI Layer pooling层，并且不再使用SVM分类器，而是通过Softmax Classifer和Bounding-Box Regressors联合训练的方式来更新所有参数，实现了整个网络端到端的训练。</p>
<p>RoI Pooling Layer可以理解为SPP-Layer的简化形式。SPP-Layer中会包含不同尺度的池化层；而RoI Layer只包含一种尺度，它是先将图片进行相同尺度的裁分，每个子块就成为RoI，然后对所有的RoI进行单独的Max-Pool，得到每个Block的最大值。</p>
<p>Fast-R-CNN保留了VGG16中的第5个池化层之前的网络，后面接上自己的RoI Pooling Layer，然后通过全连接层进行softmax分类，最终形成了整个网络。其结构可以简单描述为：“13个卷积层+4个Pooling层+RoI层+2个FC层+两个平级层”（即SoftmaxLoss层和SmoothL1Loss层）。</p>
<p>后来人们习惯在其前面加上一个RPN网络，用来对图片进行一次候选框的筛选，所以整个网络结构会变成“RPN+Fast-R-CNN”的形式。</p>
<p>所谓的RPN（Region Proposal Network）是指，先使用n×n的滑块窗口在原图像上扫描，生成M个特征值，将这M个特征值接到两个卷积网络reglayer与classlayer中输出。Reglayer里面包含图像坐标的x、y与长宽，classlayer里面有判断这部分是前景还是背景的标志值。在训练时，一个Mini-batch是由一幅图像中任意选取的256个候选框组成的，其中正、负样本的比例为1∶1。如果正样本不足128，则多用一些负样本，以满足有256个Proposal可以用于训练。对于正、负样本的标注是，reglayer范围内对应的classlayer的重合度大于0.7（即为正样本），如果都不大于0.7，则其中的最大值为正样本。最终通过softmax loss和regression loss按照一定权重比例计算loss。</p>
<h4 id="11-8-4-YOLO：能够一次性预测多个位置和类别的模型"><a href="#11-8-4-YOLO：能够一次性预测多个位置和类别的模型" class="headerlink" title="11.8.4 YOLO：能够一次性预测多个位置和类别的模型"></a>11.8.4 YOLO：能够一次性预测多个位置和类别的模型</h4><p>使用滑窗（即前景背景）时，RPN常常把背景区域误检为特定目标。所以YOLO（You Only Look Once）使用了全新的训练方式筛选候选框的筛选——采用整图的方式来训练模型，并且可以一次性预测多个Box的位置和类别。</p>
<p>YOLO的方式是，先将图片分为S×S个网格，每个网格相当于一个任务，负责检测内部是否有物体的中心点落入该区域，一旦有的话，则启动该任务来检测n个bounding boxes对象。</p>
<p>bounding boxes由中心点坐标（x，y）、宽高（w，h）和置信度评分这5部分组成。置信度评分可以理解为当前网格内物体属于该类别的概率与真实和预测区域的重叠度的乘积。</p>
<p>例如，如果一共有4类物体，那么每个网格里面就会有该物体对应的这4个类的概率（p0，p1，p2，p3），同时通过bounding boxes的位置信息（x、y、w、h）可以知道其预测区域，并算出与对于类别真实区域的重叠度（Iou1、Iou2、Iou3、Iou4），二者相乘就可以得到置信度。这样，如果有9个网格（7×7），每个网格负责找到2个bounding boxes，每个bounding boxes内部由5个元素组成，而且每个网格还需要有对应10个类别的概率，如式子49×（2×5+10）=1470个特征值。YOLO网络通过预测该特征值的训练，来实现实物的识别检测。</p>
<p>对于这1470个特征值的loss计算，并没有用常用的平方差等方法，原因是大多数网格实际不包含物体（即很多网格的分类概率为0），这会出现位置误差正常、分类误差稀疏的情况。</p>
<p><img src="Image00014.jpg" alt> 提示： 106维度的数据内部存在着某部分维度分布不均的情况，如直接用平方差会使整体的loss很不稳定，所以这部分也采用了更复杂的算法，这里不再展开。</p>
<p>YOLO网络结构分为两种：一个是正常的网络结构，用到了Inception的结构；另一个是其简化版，会有更好的速度，但是准确度会降低。</p>
<h4 id="11-8-5-SSD：比YOLO更快更准的模型"><a href="#11-8-5-SSD：比YOLO更快更准的模型" class="headerlink" title="11.8.5 SSD：比YOLO更快更准的模型"></a>11.8.5 SSD：比YOLO更快更准的模型</h4><p>前面讲的YOLO也有缺陷：</p>
<p>·每个网格预测的物体个数是指定的，容易造成遗漏（如指定检测2个，但是实际有3个）。</p>
<p>·对物体的尺度相对比较敏感，对尺度变化较大的物体泛化能力较差。</p>
<p>而SSD（Single Shot MultiBox Detector）的方法在YOLO的基础上融合了RPN的思想，在不同卷积层所输出的不同尺度的卷积结果（Feature Map）上面划格子，在多种尺度的格子上提取目标中心点，从而大大改善了这两个问题。</p>
<p>类似于Fast-R-CNN，SSD网络使用的是基于VGG 16改进的模型结构。</p>
<h4 id="11-8-6-YOLO2：YOLO的升级版模型"><a href="#11-8-6-YOLO2：YOLO的升级版模型" class="headerlink" title="11.8.6 YOLO2：YOLO的升级版模型"></a>11.8.6 YOLO2：YOLO的升级版模型</h4><p>YOLO2，在YOLO的基础上也改掉了很多缺陷，去掉了网格与类别的预测绑定在一起，也使用了anchor box模式。另外，在一些结构细节上做了一些优化：更多地使用了卷积来代替全连接网络，并增加了BN算法，同时提升了网络的入口分辨率，去掉最后池化层，保证有更好的分辨率等。同样，YOLO 2沿用了基于GoogLeNet的自定制网络，也使用了Inception（见11.2.3节至11.2.7节）中的很多最新技术，算是目前最好的实物检测模型了。</p>
<h3 id="11-9-机器自己设计的模型（NASNet）"><a href="#11-9-机器自己设计的模型（NASNet）" class="headerlink" title="11.9 机器自己设计的模型（NASNet）"></a>11.9 机器自己设计的模型（NASNet）</h3><p>NASNet是谷歌公司AutoML项目产出的模型。AutoML项目是一种实现机器学习模型设计自动化的项目，致力于让计算机设计出性能可与人类专家设计的神经网络相媲美的神经网络。而NASNet就是该项目的产出成果。NASNet架构在CIFAR-10、ImageNet分类和COCO实物检测上都优于现有的开源模型。</p>
<p>NASNet架构由两种类型的层组成：正常层和还原层。下面引用在谷歌的博客（Google Research Blog）上公开NASNet的结构，如图11-26所示。</p>
<p>根据初始化NASNet结构的不同规模，TensorFlow中提供了两种版本的NASNet，即large NASNet model与mobile NASNet model。large NASNet model可实现最高的准确率，适用于在后端服务器上应用；mobile NASNet model是一个小规模模型。在保留了原有74%的准确率基础上，将计算开销控制在非常低的水平，适用于在移动平台上应用。</p>
<p><img src="Image00252.jpg" alt></p>
<p>图11-26 NASNet结构：正常层（左）、还原层（右）</p>
<p>更多信息可以参考如下链接：</p>
<p><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/README.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/README.md</a> 。</p>
<p>该链接中提供了NASNet两种版本的预编模型，并且NASNet结构的实现代码在以下链接里也可以找到：</p>
<p><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py</a> 。</p>
<p>该模型代码中提供了两个初始化规模的函数_large_imagenet_config和_mobile_ imagenet_config，分别对应于large NASNet model与mobile NASNet model两种模型。读者可以将本章介绍的模型使用例子套用到NASNet模型的使用上。在实际工作中，遇到图片分类问题时，建议优先考虑NASNet模型。</p>
<h2 id="第12章-对抗神经网络（GAN）"><a href="#第12章-对抗神经网络（GAN）" class="headerlink" title="第12章 对抗神经网络（GAN）"></a>第12章 对抗神经网络（GAN）</h2><p>对抗神经网络其实是两个网络的的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自己让判别的网络判断不出来，判别的网络也要优化自己让自己判断得更准确。二者关系形成对抗，因此叫对抗神经网络。</p>
<p>实验证明，利用这种网络间的对抗关系所形成的网络，在无监督及半监督领域取得了很好的效果，可以算是用网络来监督网络的一个自学习过程。</p>
<p>下面我们就来系统地学习对抗神经网络的相关知识。</p>
<p>本章含有教学视频共22分11秒。</p>
<p>作者按照本章的内容结构，对主要内容进行了讲解，包括基本神经网络的概念和结构，以及在此之上的其他几种GAN网络模型的结构部分等（重点是最后一个实例，以及对SRGAN的掌握）。</p>
<p><img src="Image00253.jpg" alt></p>
<h3 id="12-1-GAN的理论知识"><a href="#12-1-GAN的理论知识" class="headerlink" title="12.1 GAN的理论知识"></a>12.1 GAN的理论知识</h3><p>GAN由generator（生成式模型）和discriminator（判别式模型）两部分构成。</p>
<p>·generator：主要是从训练数据中产生相同分布的samples，对于输入x，类别标签y，在生成式模型中估计其联合概率分布（两个及以上随机变量组成的随机向量的概率分布）。</p>
<p>·discriminator：判断输入是真实数据还是generator生成的数据，即估计样本属于某类的条件概率分布。它采用传统的监督学习的方法。</p>
<p>二者结合后，经过大量次数的迭代训练会使generator尽可能模拟出以假乱真的样本，而discriminator会有更精确的鉴别真伪数据的能力，最终整个GAN会达到所谓的纳什均衡，即discriminator对于generator的数据鉴别结果为正确率和错误率各占50%。</p>
<p>GAN的网络结构如图12-1所示。</p>
<p>·生成式模型又叫生成器。它先用一个随机编码向量来输出一个模拟样本（如图12-1左侧所示）。</p>
<p>·判别式模型又叫判别器。它的输入是一个样本（可以是真实样本也可以是模拟样本），输出一个判断该样本是真样本还是模拟样本（假样本）的结果，如图12-1右侧所示。</p>
<p><img src="Image00254.jpg" alt></p>
<p>图12-1 GAN网络</p>
<p>判别器的目标是区分真假样本，生成器的目标是让判别器区分不出真假样本，两者目标相反，存在对抗。</p>
<p>我们前面学习的监督学习神经网络就属于discriminator。下面介绍generator。</p>
<h4 id="12-1-1-生成式模型的应用"><a href="#12-1-1-生成式模型的应用" class="headerlink" title="12.1.1 生成式模型的应用"></a>12.1.1 生成式模型的应用</h4><p>generator的特性主要包括以下几方面：</p>
<p>·在应用数学和工程方面，能够有效地表征高维数据分布。</p>
<p>·在强化学习方面，作为一种技术手段，有效表征强化学习模型中的state状态。</p>
<p>·在半监督学习方面，能够在数据缺失下训练模型，并给出相应的输出。</p>
<p>generator还适用于一个输入伴随多个输出的场景下，如在视频中通过场景预测下一帧的场景，而discriminator通过最小化模型输出和期望输出的某个预测值，无法训练单输入多输出的模型。前面学习的自编码部分就属于一个generator。</p>
<h4 id="12-1-2-GAN的训练方法"><a href="#12-1-2-GAN的训练方法" class="headerlink" title="12.1.2 GAN的训练方法"></a>12.1.2 GAN的训练方法</h4><p>根据GAN的结构不同，会有不同的对应训练方法。无论什么方法，其原理是一样的，即在迭代训练的优化过程中进行两个网络的优化。有的会在一个优化步骤中对两个网络优化，有的会对两个网络采取不同的优化步骤。</p>
<h3 id="12-2-DCGAN——基于深度卷积的GAN"><a href="#12-2-DCGAN——基于深度卷积的GAN" class="headerlink" title="12.2 DCGAN——基于深度卷积的GAN"></a>12.2 DCGAN——基于深度卷积的GAN</h3><p>DCGAN即使用卷积网络的对抗网络，其原理和GAN一样，只是把CNN卷积技术用于GAN模式的网络里，G（生成器）网在生成数据时，使用反卷积的重构技术来重构原始图片。D（判别器）网用卷积技术来识别图片特征，进而作出判别。</p>
<p>同时，DCGAN中的卷积神经网络也做了一些结构的改变，以提高样本的质量和收敛速度：</p>
<p>·G网中取消所有池化层，使用转置卷积（transposed convolutional layer）并且步长大于等于2进行上采样。</p>
<p>·D网中也用加入stride的卷积代替pooling。</p>
<p>·在D网和G网中均使用批量化归一（batch normalization），而在最后一层时通常不会使用batch normalizaiton，这是为了保证模型能够学习到数据的正确均值和方差。</p>
<p>·去掉了FC层，使网络变为全卷积网络。</p>
<p>·G网中使用ReLU作为激活函数，最后一层使用Tanh作为激活函数。</p>
<p>·D网中使用LeakyReLU作为激活函数。</p>
<p>DCGAN中换成了两个卷积神经网络（CNN）的G和D，可以更好地学到对输入图像层次化的表示，尤其在生成器部分会有更好的模拟效果。DCGAN在训练中会使用Adam优化算法。</p>
<h3 id="12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN"><a href="#12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN" class="headerlink" title="12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN"></a>12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN</h3><p>InfoGAN是一种把信息论与GAN相融合的神经网络，能够使网络具有信息解读功能。下面来一起看看它的介绍。</p>
<h4 id="12-3-1-InfoGAN：带有隐含信息的GAN"><a href="#12-3-1-InfoGAN：带有隐含信息的GAN" class="headerlink" title="12.3.1 InfoGAN：带有隐含信息的GAN"></a>12.3.1 InfoGAN：带有隐含信息的GAN</h4><p>GAN的生成器在构建样本时使用了任意的噪声向量z，并从低维的噪声数据z中还原出来高维的样本数据。这说明数据z中含有具有与样本相同的特征。</p>
<p>由于随意使用的噪声都能还原出高维样本数据，表明噪声中的特征数据部分是与无用的数据部分高度地纠缠在一起的，即我们能够知道噪声中含有有用特征，但无法知道哪些是有用特征。</p>
<p>InfoGAN是GAN模型的一种改进，是一种能够学习样本中的关键维度信息的GAN，即对生成样本的噪音进行了细化。先来看它的结构，相比对抗自编码，InfoGAN的思路正好相反，InfoGAN是先固定标准高斯分布作为网络输入，再慢慢调整网络输出去匹配复杂样本分布。</p>
<p><img src="Image00255.jpg" alt></p>
<p>图12-2 InfoGAN模型</p>
<p>如图12-2所示，InfoGAN生成器是从标准高斯分布中随机采样来作为输入，生成模拟样本，解码器是将生成器输出的模拟样本还原回生成器输入的随机数中的一部分，判别器是将样本作为输入来区分真假样本。</p>
<p>InfoGAN的理论思想是将输入的随机标准高斯分布当成噪音数据，并将噪音分为两类，第一类是不可压缩的噪音Z，第二类是可解释性的信息C。假设在一个样本中，决定其本身的只有少量重要的维度，那么大多数的维度是可以忽略的。而这里的解码器可以更形象地叫成重构器，即通过重构一部分输入的特征来确定与样本互信息的那些维度。最终被找到的维度可以代替原始样本的特征（类似PCA算法中的主成份），实现降维、解耦的效果。</p>
<h4 id="12-3-2-AC-GAN：带有辅助分类信息的GAN"><a href="#12-3-2-AC-GAN：带有辅助分类信息的GAN" class="headerlink" title="12.3.2 AC-GAN：带有辅助分类信息的GAN"></a>12.3.2 AC-GAN：带有辅助分类信息的GAN</h4><p>AC-GAN（Auxiliary Classifier GAN），即在判别器discriminator中再输出相应的分类概率，然后增加输出的分类与真实分类的损失计算，使生成的模拟数据与其所属的class一一对应。</p>
<p>一般来讲，AC-GAN可以属于InfoGAN的一部分，class信息可以作为InfoGAN中的潜在信息，只不过这部分信息可以使用半监督方式来学习。</p>
<h4 id="12-3-3-实例88：构建InfoGAN生成MNIST模拟数据"><a href="#12-3-3-实例88：构建InfoGAN生成MNIST模拟数据" class="headerlink" title="12.3.3 实例88：构建InfoGAN生成MNIST模拟数据"></a>12.3.3 实例88：构建InfoGAN生成MNIST模拟数据</h4><p>本例演示在MNISTT数据集上使用InfoGAN网络模型生成模拟数据，并且加入标签信息的loss函数同时实现AC-GAN网络。其中的D和G都是用卷积网络来实现的，相当于DCGAN基础上的InfoGAN例子。</p>
<p>实例描述</p>
<p>通过使用InfoGAN网络学习MNIST数据特征，生成以假乱真的MNIST模拟样本，并发现内部潜在的特征信息。</p>
<p>具体实现可以分为如下几个步骤。</p>
<p>1．引入头文件并加载MNIST数据</p>
<p>假设MNIST数据放在本地磁盘根目录的data下。本例中将使用前面介绍的slim模块构建网络结构，所以需要引入slim。当然也可以不用slim，引入slim的目的是为了编写代码比较方便，不用考虑输入维度即相关权重的定义，最主要的是slim还对反卷积有封装，后面会用到。</p>
<p>代码12-1 Mnistinfogan</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import tensorflow.contrib.slim as slim</span><br><span class="line"></span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;)#, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>2．网络结构介绍</p>
<p>建立两个噪声数据（一般噪声和隐含信息）与label结合放到生成器中，生成模拟样本，然后将模拟样本和真实样本分别输入到判别器中，生成判别结果、重构造的隐含信息，以及样本标签。</p>
<p>在优化时，让判别器对真实的样本判别结果为1、对模拟数据的判别结果为0来做损失值计算（loss）；对生成器让判别结果为1来做损失值计算（loss）。</p>
<p>3．定义生成器与判别器</p>
<p>由于是先从模拟噪声数据来恢复样本，所以在生成器中要使用反卷积函数。这里通过“两个全连接＋两个反卷积”模拟样本的生成，并且每一层都有BN（批量归一化）处理。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">def generator(x):#生成器函数</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.startswith</span><br><span class="line">   (&apos;generator&apos;)]) &gt; 0</span><br><span class="line">   </span><br><span class="line">    with tf.variable_scope(&apos;generator&apos;, reuse = reuse):</span><br><span class="line">        x = slim.fully_connected(x, 1024)</span><br><span class="line">      </span><br><span class="line">        x = slim.batch_norm(x, activation_fn=tf.nn.relu)</span><br><span class="line">        x = slim.fully_connected(x, 7*7*128)</span><br><span class="line">        x = slim.batch_norm(x, activation_fn=tf.nn.relu)</span><br><span class="line">        x = tf.reshape(x, [-1, 7, 7, 128])</span><br><span class="line">     </span><br><span class="line">        x = slim.conv2d_transpose(x, 64, kernel_size=[4,4], stride=2, </span><br><span class="line">       activation_fn = None)</span><br><span class="line">        </span><br><span class="line">        x = slim.batch_norm(x, activation_fn = tf.nn.relu)</span><br><span class="line">        z = slim.conv2d_transpose(x, 1, kernel_size=[4, 4], stride=2, </span><br><span class="line">       activation_fn=tf.nn.sigmoid)</span><br><span class="line">        </span><br><span class="line">    return z</span><br><span class="line"></span><br><span class="line">def leaky_relu(x):</span><br><span class="line">     return tf.where(tf.greater(x, 0), x, 0.01 * x)</span><br><span class="line">#判别器函数</span><br><span class="line">def discriminator(x, num_classes=10, num_cont=2):</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.startswith</span><br><span class="line">     (&apos;discriminator&apos;)]) &gt; 0</span><br><span class="line">  </span><br><span class="line">    with tf.variable_scope(&apos;discriminator&apos;, reuse=reuse):</span><br><span class="line">        x = tf.reshape(x, shape=[-1, 28, 28, 1])</span><br><span class="line">        x = slim.conv2d(x, num_outputs = 64, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        x = slim.conv2d(x, num_outputs=128, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        </span><br><span class="line">        x = slim.flatten(x)</span><br><span class="line">        shared_tensor = slim.fully_connected(x, num_outputs=1024, </span><br><span class="line">       activation_fn = leaky_relu)</span><br><span class="line">        recog_shared = slim.fully_connected(shared_tensor, num_</span><br><span class="line">       outputs=128, activation_fn = leaky_relu)</span><br><span class="line">        disc = slim.fully_connected(shared_tensor, num_outputs=1, </span><br><span class="line">       activation_fn=None) </span><br><span class="line">        disc = tf.squeeze(disc, -1)</span><br><span class="line">        </span><br><span class="line">        recog_cat = slim.fully_connected(recog_shared, num_outputs=</span><br><span class="line">       num_classes, activation_fn=None) #判别类型</span><br><span class="line">        recog_cont = slim.fully_connected(recog_shared, num_outputs=</span><br><span class="line">       num_cont, activation_fn=tf.nn.sigmoid) #判别info</span><br><span class="line">    return disc, recog_cat, recog_cont</span><br></pre></td></tr></table></figure>

</details>

<p>如果判别器输入的是真正的样本，同样也要经过两次卷积，再接两次全连接，生成的数据可以分别连接不同的输出层产生不同的结果，其中1维的输出层产生判别结果1或是0，10维的输出层产生分类结果，2维输出层产生隐含维度信息。</p>
<p><img src="Image00014.jpg" alt> 注意： 在生成器与判别器中都会使用各自的命名空间，这是在多网络模型里定义变量的一个好习惯。在指定训练参数、获取及显示训练参数时，都可以通过指定的命名空间来拿到对应的变量，不至于混乱。</p>
<p>4．定义网络模型</p>
<p>令一般噪声的维度为38，应节点为z_rand；隐含信息维度为2，应节点为z_con，二者都是符合标准高斯分布的随机数。将它们与one_hot转换后的标签连接在一起放到生成器中。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> batch_size = 10</span><br><span class="line"> classes_dim = 10   # 10 个类别</span><br><span class="line"> con_dim = 2   # 隐含信息变量的维度</span><br><span class="line"> rand_dim = 38  </span><br><span class="line"> n_input  = 784</span><br><span class="line"> </span><br><span class="line"> x = tf.placeholder(tf.float32, [None, n_input])</span><br><span class="line"> y = tf.placeholder(tf.int32, [None])</span><br><span class="line"> </span><br><span class="line"> z_con = tf.random_normal((batch_size, con_dim)) #2列</span><br><span class="line"> z_rand = tf.random_normal((batch_size, rand_dim)) #38列</span><br><span class="line"> z = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), </span><br><span class="line">z_con, z_rand]) # z的函数为50</span><br><span class="line"> gen = generator(z)</span><br><span class="line"> genout= tf.squeeze(gen, -1)</span><br><span class="line"> </span><br><span class="line"> # 判别器的标准结果</span><br><span class="line"> y_real = tf.ones(batch_size) #真</span><br><span class="line"> y_fake = tf.zeros(batch_size) #假</span><br><span class="line"> </span><br><span class="line"> # discriminator</span><br><span class="line"> disc_real, class_real, _ = discriminator(x) #真样本的输出</span><br><span class="line"> disc_fake, class_fake, con_fake = discriminator(gen) #模拟样本的输出</span><br><span class="line"> pred_class = tf.argmax(class_fake, dimension=1)</span><br></pre></td></tr></table></figure>

</details>

<p>对应判别器的结果，定义了一个值全为0的数组y_fake和一个值全为1的y_real，并且将x与生成的模拟数据gen放到判别器中，得到对应的输出。</p>
<p>5．定义损失函数与优化器</p>
<p>判别器中，判别结果的loss有两个：真实输入的结果与模拟输入的结果。将二者结合在一起生成loss_d。生成器的loss为自己输出的模拟数据，让它在判别器中为真，定义为loss_g。</p>
<p>然后还要定义网络中共有的loss值：真实的标签与输入真实样本判别出的标签、真实的标签与输入模拟样本判别出的标签、隐含信息的重构误差。然后创建两个优化器，将它们放到对应的优化器中。</p>
<p>这里用了一个技巧：将判别器的学习率设小，将生成器的学习率设大一些。这么做是为了让生成器有更快的进化速度来模拟真实数据，优化同样是用AdamOptimizer方法。具体代码如下。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # 判别器loss</span><br><span class="line"> loss_d_r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_real, labels=y_real))</span><br><span class="line"> loss_d_f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_fake, labels=y_fake))</span><br><span class="line"> loss_d = (loss_d_r + loss_d_f) / 2  #判别器的loss</span><br><span class="line"> # 生成器loss</span><br><span class="line"> loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_fake, labels=y_real)) #生成器的loss</span><br><span class="line"> # 计算 factor loss</span><br><span class="line"> loss_cf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_</span><br><span class="line">logits(logits=class_fake, labels=y)) #分类正确，但生成的样本错了</span><br><span class="line"> loss_cr = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_</span><br><span class="line">logits(logits=class_real, labels=y)) #生成的样本与分类都正确，但是与输入的分类对不上</span><br><span class="line"> loss_c =(loss_cf + loss_cr) / 2</span><br><span class="line"> # 隐含信息变量的loss</span><br><span class="line"> loss_con =tf.reduce_mean(tf.square(con_fake-z_con))</span><br><span class="line"> </span><br><span class="line"> # 获得可训练的学习参数列表</span><br><span class="line"> t_vars = tf.trainable_variables()</span><br><span class="line"> d_vars = [var for var in t_vars if &apos;discriminator&apos; in var.name]</span><br><span class="line"> g_vars = [var for var in t_vars if &apos;generator&apos; in var.name]</span><br><span class="line"> </span><br><span class="line"> disc_global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> gen_global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> </span><br><span class="line"> train_disc = tf.train.AdamOptimizer(0.0001).minimize(loss_d + loss_c </span><br><span class="line">+ loss_con, var_list = d_vars, global_step = disc_global_step)</span><br><span class="line"> train_gen = tf.train.AdamOptimizer(0.001).minimize(loss_g + loss_c + </span><br><span class="line">loss_con, var_list = g_vars, global_step = gen_global_step)</span><br></pre></td></tr></table></figure>

</details>

<p>所谓的AC-GAN就是将loss_cr加入到loss_c中。如果没有loss_cr，令loss_c= loss_cf，对于网络生成模拟数据是不影响的，但是却会损失真实分类与模拟数据间的对应关系。</p>
<p>6．开始训练与测试</p>
<p>建立session，在循环里使用run来运行前面构建的两个优化器。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">training_epochs = 3</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line"></span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line"></span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size) #取数据</span><br><span class="line">            feeds = &#123;x: batch_xs, y: batch_ys&#125;</span><br><span class="line"></span><br><span class="line">            # 输入数据，运行优化器</span><br><span class="line">            l_disc, _, l_d_step = sess.run([loss_d, train_disc, disc_</span><br><span class="line">           global_step],feeds)</span><br><span class="line">            l_gen, _, l_g_step = sess.run([loss_g, train_gen, gen_</span><br><span class="line">           global_step],feeds)</span><br><span class="line"></span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch + 1), &quot;cost=&quot;, &quot;&#123;:.9f&#125; </span><br><span class="line">           &quot;.format(l_disc),l_gen)</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br><span class="line">    # 测试</span><br><span class="line">    print (&quot;Result:&quot;, loss_d.eval(&#123;x: mnist.test.images[:batch_size],</span><br><span class="line">   y:mnist.test.labels[:batch_size]&#125;)</span><br><span class="line">                        , loss_g.eval(&#123;x: mnist.test.images[:batch_</span><br><span class="line">                       size],y:mnist.test.labels[:batch_size]&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>测试部分分别使用loss_d和loss_g的eval来完成。运行代码后输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Extracting /data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Epoch: 0001 cost= 0.536611855  0.795714</span><br><span class="line">Epoch: 0002 cost= 0.610126615  0.928032</span><br><span class="line">Epoch: 0003 cost= 0.699066639  1.10242</span><br><span class="line">完成!</span><br><span class="line">Result: 0.56922 1.00881</span><br></pre></td></tr></table></figure>

</details>

<p>整个数据集运行3次后，通过模型的测试结果可以看到，判别的误差在0.57左右，基本可以认为对真假数据无法分辨。</p>
<p>7．可视化</p>
<p>可视化部分会生成两个图片：原样本与对应的模拟数据图片、利用隐含信息生成的模拟样本图片。</p>
<p>·原样本与对应的模拟数据图片会将对应的分类、预测分类、隐含信息一起打印出来。</p>
<p>·利用隐含信息生成的模拟样本图片会在整个[0，1]空间里均匀抽样，与样本的标签混合在一起，生成模拟数据。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 根据图片模拟生成图片</span><br><span class="line">    show_num = 10</span><br><span class="line">    gensimple,d_class,inputx,inputy,con_out = sess.run(</span><br><span class="line">        [genout,pred_class,x,y,con_fake], feed_dict=&#123;x: mnist.test.</span><br><span class="line">       images[:batch_size],y: mnist.test.labels[:batch_size]&#125;)</span><br><span class="line"></span><br><span class="line">    f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(inputx[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(gensimple[i], (28, 28)))</span><br><span class="line">        print(&quot;d_class&quot;,d_class[i],&quot;inputy&quot;,inputy[i],&quot;con_out&quot;,</span><br><span class="line">         con_out[i])</span><br><span class="line">        </span><br><span class="line">    plt.draw()</span><br><span class="line">    plt.show()  </span><br><span class="line">    #将隐含信息分布对应的图片打印出来</span><br><span class="line">    my_con=tf.placeholder(tf.float32, [batch_size,2])</span><br><span class="line">    myz = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), </span><br><span class="line">   my_con, z_rand])</span><br><span class="line">    mygen = generator(myz)</span><br><span class="line">    mygenout= tf.squeeze(mygen, -1) </span><br><span class="line">    </span><br><span class="line">    my_con1 = np.ones([10,2])</span><br><span class="line">    a = np.linspace(0.0001, 0.99999, 10)</span><br><span class="line">    y_input= np.ones([10])</span><br><span class="line">    figure = np.zeros((28 * 10, 28 * 10))</span><br><span class="line">    my_rand = tf.random_normal((10, rand_dim))</span><br><span class="line">    for i in range(10):</span><br><span class="line">        for j in range(10):</span><br><span class="line">            my_con1[j][0]=a[i]</span><br><span class="line">            my_con1[j][1]=a[j]</span><br><span class="line">            y_input[j] = j</span><br><span class="line">        mygenoutv =  sess.run(mygenout,feed_dict=&#123;y:y_input,my_</span><br><span class="line">       con:my_con1&#125;)</span><br><span class="line">        for jj in range(10):</span><br><span class="line">            digit = mygenoutv[jj].reshape(28, 28)</span><br><span class="line">            figure[i * 28: (i + 1) * 28,</span><br><span class="line">                   jj * 28: (jj + 1) * 28] = digit</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(10, 10))</span><br><span class="line">    plt.imshow(figure, cmap=&apos;Greys_r&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，生成如下结果，输出图片如图12-3所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">d_class 7 inputy 7 con_out [  1.92287825e-05   1.04916848e-01]</span><br><span class="line">d_class 2 inputy 2 con_out [ 0.86672944  0.00166412]</span><br><span class="line">d_class 1 inputy 1 con_out [ 0.00043415  0.06153901]</span><br><span class="line">d_class 0 inputy 0 con_out [ 0.00313404  0.00186323]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.01356777  0.9993856 ]</span><br><span class="line">d_class 1 inputy 1 con_out [  2.54907101e-01   1.13632974e-04]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.95273513  0.74673545]</span><br><span class="line">d_class 9 inputy 9 con_out [  4.87649202e-01   7.44661302e-05]</span><br><span class="line">d_class 5 inputy 5 con_out [ 0.00222825  0.99024838]</span><br><span class="line">d_class 9 inputy 9 con_out [  6.79908317e-06   3.18196639e-02]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00256.jpg" alt></p>
<p>图12-3 InfoGAN实例结果1</p>
<p>在上面的结果中，可以很容易观察到，除了可控的类别信息一致外，隐含信息中某些维度具有非常显著的语义信息。例如，第二个元素“2”的第一个维度数值很大，表现出来就是倾斜很大，同样第5个元素“4”会看上去粗一些，这与其第二个维度的数值很大也是有关的。所以显然网络模型已经学到了MNIST 数据集的重要信息（主成分）。将隐含信息对应的0、1间的数值抽样配合类别标签的图像生成结果如图12-4所示。</p>
<p><img src="Image00257.jpg" alt></p>
<p>图12-4 InfoGAN实例结果2</p>
<h4 id="12-3-4-练习题"><a href="#12-3-4-练习题" class="headerlink" title="12.3.4 练习题"></a>12.3.4 练习题</h4><p>在前面的例子中找到如下代码，并修改：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss_cf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits</span><br><span class="line">(logits=class_fake, labels=y)) #分类正确，但生成的样本错了</span><br><span class="line">loss_cr = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits</span><br><span class="line">(logits=class_real, labels=y)) #生成的样本与分类正确，但是与输入的分类对不上</span><br><span class="line">loss_c =(loss_cf + loss_cr) / 2</span><br></pre></td></tr></table></figure>

</details>

<p>令loss_c分别等于loss_cr和loss_cf。运行代码观察结果，体验loss_cr和loss_cf两个loss值的作用。</p>
<h3 id="12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN-1"><a href="#12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN-1" class="headerlink" title="12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN"></a>12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN</h3><p>InfoGAN是一种把信息论与GAN相融合的神经网络，能够使网络具有信息解读功能。下面来一起看看它的介绍。</p>
<h4 id="12-3-1-InfoGAN：带有隐含信息的GAN-1"><a href="#12-3-1-InfoGAN：带有隐含信息的GAN-1" class="headerlink" title="12.3.1 InfoGAN：带有隐含信息的GAN"></a>12.3.1 InfoGAN：带有隐含信息的GAN</h4><p>GAN的生成器在构建样本时使用了任意的噪声向量z，并从低维的噪声数据z中还原出来高维的样本数据。这说明数据z中含有具有与样本相同的特征。</p>
<p>由于随意使用的噪声都能还原出高维样本数据，表明噪声中的特征数据部分是与无用的数据部分高度地纠缠在一起的，即我们能够知道噪声中含有有用特征，但无法知道哪些是有用特征。</p>
<p>InfoGAN是GAN模型的一种改进，是一种能够学习样本中的关键维度信息的GAN，即对生成样本的噪音进行了细化。先来看它的结构，相比对抗自编码，InfoGAN的思路正好相反，InfoGAN是先固定标准高斯分布作为网络输入，再慢慢调整网络输出去匹配复杂样本分布。</p>
<p><img src="Image00255.jpg" alt></p>
<p>图12-2 InfoGAN模型</p>
<p>如图12-2所示，InfoGAN生成器是从标准高斯分布中随机采样来作为输入，生成模拟样本，解码器是将生成器输出的模拟样本还原回生成器输入的随机数中的一部分，判别器是将样本作为输入来区分真假样本。</p>
<p>InfoGAN的理论思想是将输入的随机标准高斯分布当成噪音数据，并将噪音分为两类，第一类是不可压缩的噪音Z，第二类是可解释性的信息C。假设在一个样本中，决定其本身的只有少量重要的维度，那么大多数的维度是可以忽略的。而这里的解码器可以更形象地叫成重构器，即通过重构一部分输入的特征来确定与样本互信息的那些维度。最终被找到的维度可以代替原始样本的特征（类似PCA算法中的主成份），实现降维、解耦的效果。</p>
<h4 id="12-3-2-AC-GAN：带有辅助分类信息的GAN-1"><a href="#12-3-2-AC-GAN：带有辅助分类信息的GAN-1" class="headerlink" title="12.3.2 AC-GAN：带有辅助分类信息的GAN"></a>12.3.2 AC-GAN：带有辅助分类信息的GAN</h4><p>AC-GAN（Auxiliary Classifier GAN），即在判别器discriminator中再输出相应的分类概率，然后增加输出的分类与真实分类的损失计算，使生成的模拟数据与其所属的class一一对应。</p>
<p>一般来讲，AC-GAN可以属于InfoGAN的一部分，class信息可以作为InfoGAN中的潜在信息，只不过这部分信息可以使用半监督方式来学习。</p>
<h4 id="12-3-3-实例88：构建InfoGAN生成MNIST模拟数据-1"><a href="#12-3-3-实例88：构建InfoGAN生成MNIST模拟数据-1" class="headerlink" title="12.3.3 实例88：构建InfoGAN生成MNIST模拟数据"></a>12.3.3 实例88：构建InfoGAN生成MNIST模拟数据</h4><p>本例演示在MNISTT数据集上使用InfoGAN网络模型生成模拟数据，并且加入标签信息的loss函数同时实现AC-GAN网络。其中的D和G都是用卷积网络来实现的，相当于DCGAN基础上的InfoGAN例子。</p>
<p>实例描述</p>
<p>通过使用InfoGAN网络学习MNIST数据特征，生成以假乱真的MNIST模拟样本，并发现内部潜在的特征信息。</p>
<p>具体实现可以分为如下几个步骤。</p>
<p>1．引入头文件并加载MNIST数据</p>
<p>假设MNIST数据放在本地磁盘根目录的data下。本例中将使用前面介绍的slim模块构建网络结构，所以需要引入slim。当然也可以不用slim，引入slim的目的是为了编写代码比较方便，不用考虑输入维度即相关权重的定义，最主要的是slim还对反卷积有封装，后面会用到。</p>
<p>代码12-1 Mnistinfogan</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">import tensorflow.contrib.slim as slim</span><br><span class="line"></span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;)#, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>2．网络结构介绍</p>
<p>建立两个噪声数据（一般噪声和隐含信息）与label结合放到生成器中，生成模拟样本，然后将模拟样本和真实样本分别输入到判别器中，生成判别结果、重构造的隐含信息，以及样本标签。</p>
<p>在优化时，让判别器对真实的样本判别结果为1、对模拟数据的判别结果为0来做损失值计算（loss）；对生成器让判别结果为1来做损失值计算（loss）。</p>
<p>3．定义生成器与判别器</p>
<p>由于是先从模拟噪声数据来恢复样本，所以在生成器中要使用反卷积函数。这里通过“两个全连接＋两个反卷积”模拟样本的生成，并且每一层都有BN（批量归一化）处理。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">def generator(x):#生成器函数</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.startswith</span><br><span class="line">   (&apos;generator&apos;)]) &gt; 0</span><br><span class="line">   </span><br><span class="line">    with tf.variable_scope(&apos;generator&apos;, reuse = reuse):</span><br><span class="line">        x = slim.fully_connected(x, 1024)</span><br><span class="line">      </span><br><span class="line">        x = slim.batch_norm(x, activation_fn=tf.nn.relu)</span><br><span class="line">        x = slim.fully_connected(x, 7*7*128)</span><br><span class="line">        x = slim.batch_norm(x, activation_fn=tf.nn.relu)</span><br><span class="line">        x = tf.reshape(x, [-1, 7, 7, 128])</span><br><span class="line">     </span><br><span class="line">        x = slim.conv2d_transpose(x, 64, kernel_size=[4,4], stride=2, </span><br><span class="line">       activation_fn = None)</span><br><span class="line">        </span><br><span class="line">        x = slim.batch_norm(x, activation_fn = tf.nn.relu)</span><br><span class="line">        z = slim.conv2d_transpose(x, 1, kernel_size=[4, 4], stride=2, </span><br><span class="line">       activation_fn=tf.nn.sigmoid)</span><br><span class="line">        </span><br><span class="line">    return z</span><br><span class="line"></span><br><span class="line">def leaky_relu(x):</span><br><span class="line">     return tf.where(tf.greater(x, 0), x, 0.01 * x)</span><br><span class="line">#判别器函数</span><br><span class="line">def discriminator(x, num_classes=10, num_cont=2):</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.startswith</span><br><span class="line">     (&apos;discriminator&apos;)]) &gt; 0</span><br><span class="line">  </span><br><span class="line">    with tf.variable_scope(&apos;discriminator&apos;, reuse=reuse):</span><br><span class="line">        x = tf.reshape(x, shape=[-1, 28, 28, 1])</span><br><span class="line">        x = slim.conv2d(x, num_outputs = 64, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        x = slim.conv2d(x, num_outputs=128, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        </span><br><span class="line">        x = slim.flatten(x)</span><br><span class="line">        shared_tensor = slim.fully_connected(x, num_outputs=1024, </span><br><span class="line">       activation_fn = leaky_relu)</span><br><span class="line">        recog_shared = slim.fully_connected(shared_tensor, num_</span><br><span class="line">       outputs=128, activation_fn = leaky_relu)</span><br><span class="line">        disc = slim.fully_connected(shared_tensor, num_outputs=1, </span><br><span class="line">       activation_fn=None) </span><br><span class="line">        disc = tf.squeeze(disc, -1)</span><br><span class="line">        </span><br><span class="line">        recog_cat = slim.fully_connected(recog_shared, num_outputs=</span><br><span class="line">       num_classes, activation_fn=None) #判别类型</span><br><span class="line">        recog_cont = slim.fully_connected(recog_shared, num_outputs=</span><br><span class="line">       num_cont, activation_fn=tf.nn.sigmoid) #判别info</span><br><span class="line">    return disc, recog_cat, recog_cont</span><br></pre></td></tr></table></figure>

</details>

<p>如果判别器输入的是真正的样本，同样也要经过两次卷积，再接两次全连接，生成的数据可以分别连接不同的输出层产生不同的结果，其中1维的输出层产生判别结果1或是0，10维的输出层产生分类结果，2维输出层产生隐含维度信息。</p>
<p><img src="Image00014.jpg" alt> 注意： 在生成器与判别器中都会使用各自的命名空间，这是在多网络模型里定义变量的一个好习惯。在指定训练参数、获取及显示训练参数时，都可以通过指定的命名空间来拿到对应的变量，不至于混乱。</p>
<p>4．定义网络模型</p>
<p>令一般噪声的维度为38，应节点为z_rand；隐含信息维度为2，应节点为z_con，二者都是符合标准高斯分布的随机数。将它们与one_hot转换后的标签连接在一起放到生成器中。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> batch_size = 10</span><br><span class="line"> classes_dim = 10   # 10 个类别</span><br><span class="line"> con_dim = 2   # 隐含信息变量的维度</span><br><span class="line"> rand_dim = 38  </span><br><span class="line"> n_input  = 784</span><br><span class="line"> </span><br><span class="line"> x = tf.placeholder(tf.float32, [None, n_input])</span><br><span class="line"> y = tf.placeholder(tf.int32, [None])</span><br><span class="line"> </span><br><span class="line"> z_con = tf.random_normal((batch_size, con_dim)) #2列</span><br><span class="line"> z_rand = tf.random_normal((batch_size, rand_dim)) #38列</span><br><span class="line"> z = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), </span><br><span class="line">z_con, z_rand]) # z的函数为50</span><br><span class="line"> gen = generator(z)</span><br><span class="line"> genout= tf.squeeze(gen, -1)</span><br><span class="line"> </span><br><span class="line"> # 判别器的标准结果</span><br><span class="line"> y_real = tf.ones(batch_size) #真</span><br><span class="line"> y_fake = tf.zeros(batch_size) #假</span><br><span class="line"> </span><br><span class="line"> # discriminator</span><br><span class="line"> disc_real, class_real, _ = discriminator(x) #真样本的输出</span><br><span class="line"> disc_fake, class_fake, con_fake = discriminator(gen) #模拟样本的输出</span><br><span class="line"> pred_class = tf.argmax(class_fake, dimension=1)</span><br></pre></td></tr></table></figure>

</details>

<p>对应判别器的结果，定义了一个值全为0的数组y_fake和一个值全为1的y_real，并且将x与生成的模拟数据gen放到判别器中，得到对应的输出。</p>
<p>5．定义损失函数与优化器</p>
<p>判别器中，判别结果的loss有两个：真实输入的结果与模拟输入的结果。将二者结合在一起生成loss_d。生成器的loss为自己输出的模拟数据，让它在判别器中为真，定义为loss_g。</p>
<p>然后还要定义网络中共有的loss值：真实的标签与输入真实样本判别出的标签、真实的标签与输入模拟样本判别出的标签、隐含信息的重构误差。然后创建两个优化器，将它们放到对应的优化器中。</p>
<p>这里用了一个技巧：将判别器的学习率设小，将生成器的学习率设大一些。这么做是为了让生成器有更快的进化速度来模拟真实数据，优化同样是用AdamOptimizer方法。具体代码如下。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # 判别器loss</span><br><span class="line"> loss_d_r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_real, labels=y_real))</span><br><span class="line"> loss_d_f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_fake, labels=y_fake))</span><br><span class="line"> loss_d = (loss_d_r + loss_d_f) / 2  #判别器的loss</span><br><span class="line"> # 生成器loss</span><br><span class="line"> loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_fake, labels=y_real)) #生成器的loss</span><br><span class="line"> # 计算 factor loss</span><br><span class="line"> loss_cf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_</span><br><span class="line">logits(logits=class_fake, labels=y)) #分类正确，但生成的样本错了</span><br><span class="line"> loss_cr = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_</span><br><span class="line">logits(logits=class_real, labels=y)) #生成的样本与分类都正确，但是与输入的分类对不上</span><br><span class="line"> loss_c =(loss_cf + loss_cr) / 2</span><br><span class="line"> # 隐含信息变量的loss</span><br><span class="line"> loss_con =tf.reduce_mean(tf.square(con_fake-z_con))</span><br><span class="line"> </span><br><span class="line"> # 获得可训练的学习参数列表</span><br><span class="line"> t_vars = tf.trainable_variables()</span><br><span class="line"> d_vars = [var for var in t_vars if &apos;discriminator&apos; in var.name]</span><br><span class="line"> g_vars = [var for var in t_vars if &apos;generator&apos; in var.name]</span><br><span class="line"> </span><br><span class="line"> disc_global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> gen_global_step = tf.Variable(0, trainable=False)</span><br><span class="line"> </span><br><span class="line"> train_disc = tf.train.AdamOptimizer(0.0001).minimize(loss_d + loss_c </span><br><span class="line">+ loss_con, var_list = d_vars, global_step = disc_global_step)</span><br><span class="line"> train_gen = tf.train.AdamOptimizer(0.001).minimize(loss_g + loss_c + </span><br><span class="line">loss_con, var_list = g_vars, global_step = gen_global_step)</span><br></pre></td></tr></table></figure>

</details>

<p>所谓的AC-GAN就是将loss_cr加入到loss_c中。如果没有loss_cr，令loss_c= loss_cf，对于网络生成模拟数据是不影响的，但是却会损失真实分类与模拟数据间的对应关系。</p>
<p>6．开始训练与测试</p>
<p>建立session，在循环里使用run来运行前面构建的两个优化器。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">training_epochs = 3</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line"></span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line"></span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size) #取数据</span><br><span class="line">            feeds = &#123;x: batch_xs, y: batch_ys&#125;</span><br><span class="line"></span><br><span class="line">            # 输入数据，运行优化器</span><br><span class="line">            l_disc, _, l_d_step = sess.run([loss_d, train_disc, disc_</span><br><span class="line">           global_step],feeds)</span><br><span class="line">            l_gen, _, l_g_step = sess.run([loss_g, train_gen, gen_</span><br><span class="line">           global_step],feeds)</span><br><span class="line"></span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch + 1), &quot;cost=&quot;, &quot;&#123;:.9f&#125; </span><br><span class="line">           &quot;.format(l_disc),l_gen)</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br><span class="line">    # 测试</span><br><span class="line">    print (&quot;Result:&quot;, loss_d.eval(&#123;x: mnist.test.images[:batch_size],</span><br><span class="line">   y:mnist.test.labels[:batch_size]&#125;)</span><br><span class="line">                        , loss_g.eval(&#123;x: mnist.test.images[:batch_</span><br><span class="line">                       size],y:mnist.test.labels[:batch_size]&#125;))</span><br></pre></td></tr></table></figure>

</details>

<p>测试部分分别使用loss_d和loss_g的eval来完成。运行代码后输出如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Extracting /data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Epoch: 0001 cost= 0.536611855  0.795714</span><br><span class="line">Epoch: 0002 cost= 0.610126615  0.928032</span><br><span class="line">Epoch: 0003 cost= 0.699066639  1.10242</span><br><span class="line">完成!</span><br><span class="line">Result: 0.56922 1.00881</span><br></pre></td></tr></table></figure>

</details>

<p>整个数据集运行3次后，通过模型的测试结果可以看到，判别的误差在0.57左右，基本可以认为对真假数据无法分辨。</p>
<p>7．可视化</p>
<p>可视化部分会生成两个图片：原样本与对应的模拟数据图片、利用隐含信息生成的模拟样本图片。</p>
<p>·原样本与对应的模拟数据图片会将对应的分类、预测分类、隐含信息一起打印出来。</p>
<p>·利用隐含信息生成的模拟样本图片会在整个[0，1]空间里均匀抽样，与样本的标签混合在一起，生成模拟数据。</p>
<p>代码12-1 Mnistinfogan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 根据图片模拟生成图片</span><br><span class="line">    show_num = 10</span><br><span class="line">    gensimple,d_class,inputx,inputy,con_out = sess.run(</span><br><span class="line">        [genout,pred_class,x,y,con_fake], feed_dict=&#123;x: mnist.test.</span><br><span class="line">       images[:batch_size],y: mnist.test.labels[:batch_size]&#125;)</span><br><span class="line"></span><br><span class="line">    f, a = plt.subplots(2, 10, figsize=(10, 2))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(inputx[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(gensimple[i], (28, 28)))</span><br><span class="line">        print(&quot;d_class&quot;,d_class[i],&quot;inputy&quot;,inputy[i],&quot;con_out&quot;,</span><br><span class="line">         con_out[i])</span><br><span class="line">        </span><br><span class="line">    plt.draw()</span><br><span class="line">    plt.show()  </span><br><span class="line">    #将隐含信息分布对应的图片打印出来</span><br><span class="line">    my_con=tf.placeholder(tf.float32, [batch_size,2])</span><br><span class="line">    myz = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), </span><br><span class="line">   my_con, z_rand])</span><br><span class="line">    mygen = generator(myz)</span><br><span class="line">    mygenout= tf.squeeze(mygen, -1) </span><br><span class="line">    </span><br><span class="line">    my_con1 = np.ones([10,2])</span><br><span class="line">    a = np.linspace(0.0001, 0.99999, 10)</span><br><span class="line">    y_input= np.ones([10])</span><br><span class="line">    figure = np.zeros((28 * 10, 28 * 10))</span><br><span class="line">    my_rand = tf.random_normal((10, rand_dim))</span><br><span class="line">    for i in range(10):</span><br><span class="line">        for j in range(10):</span><br><span class="line">            my_con1[j][0]=a[i]</span><br><span class="line">            my_con1[j][1]=a[j]</span><br><span class="line">            y_input[j] = j</span><br><span class="line">        mygenoutv =  sess.run(mygenout,feed_dict=&#123;y:y_input,my_</span><br><span class="line">       con:my_con1&#125;)</span><br><span class="line">        for jj in range(10):</span><br><span class="line">            digit = mygenoutv[jj].reshape(28, 28)</span><br><span class="line">            figure[i * 28: (i + 1) * 28,</span><br><span class="line">                   jj * 28: (jj + 1) * 28] = digit</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(10, 10))</span><br><span class="line">    plt.imshow(figure, cmap=&apos;Greys_r&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，生成如下结果，输出图片如图12-3所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">d_class 7 inputy 7 con_out [  1.92287825e-05   1.04916848e-01]</span><br><span class="line">d_class 2 inputy 2 con_out [ 0.86672944  0.00166412]</span><br><span class="line">d_class 1 inputy 1 con_out [ 0.00043415  0.06153901]</span><br><span class="line">d_class 0 inputy 0 con_out [ 0.00313404  0.00186323]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.01356777  0.9993856 ]</span><br><span class="line">d_class 1 inputy 1 con_out [  2.54907101e-01   1.13632974e-04]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.95273513  0.74673545]</span><br><span class="line">d_class 9 inputy 9 con_out [  4.87649202e-01   7.44661302e-05]</span><br><span class="line">d_class 5 inputy 5 con_out [ 0.00222825  0.99024838]</span><br><span class="line">d_class 9 inputy 9 con_out [  6.79908317e-06   3.18196639e-02]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00256.jpg" alt></p>
<p>图12-3 InfoGAN实例结果1</p>
<p>在上面的结果中，可以很容易观察到，除了可控的类别信息一致外，隐含信息中某些维度具有非常显著的语义信息。例如，第二个元素“2”的第一个维度数值很大，表现出来就是倾斜很大，同样第5个元素“4”会看上去粗一些，这与其第二个维度的数值很大也是有关的。所以显然网络模型已经学到了MNIST 数据集的重要信息（主成分）。将隐含信息对应的0、1间的数值抽样配合类别标签的图像生成结果如图12-4所示。</p>
<p><img src="Image00257.jpg" alt></p>
<p>图12-4 InfoGAN实例结果2</p>
<h4 id="12-3-4-练习题-1"><a href="#12-3-4-练习题-1" class="headerlink" title="12.3.4 练习题"></a>12.3.4 练习题</h4><p>在前面的例子中找到如下代码，并修改：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">loss_cf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits</span><br><span class="line">(logits=class_fake, labels=y)) #分类正确，但生成的样本错了</span><br><span class="line">loss_cr = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits</span><br><span class="line">(logits=class_real, labels=y)) #生成的样本与分类正确，但是与输入的分类对不上</span><br><span class="line">loss_c =(loss_cf + loss_cr) / 2</span><br></pre></td></tr></table></figure>

</details>

<p>令loss_c分别等于loss_cr和loss_cf。运行代码观察结果，体验loss_cr和loss_cf两个loss值的作用。</p>
<h3 id="12-5-WGAN-GP：更容易训练的GAN"><a href="#12-5-WGAN-GP：更容易训练的GAN" class="headerlink" title="12.5 WGAN-GP：更容易训练的GAN"></a>12.5 WGAN-GP：更容易训练的GAN</h3><p>WGAN-GP又称为具有梯度惩罚（Gradient Penalty）的WGAN（Wasserstein GAN），是WGAN的升级版，一般可以全面代替WGAN。但是为了让读者了解WGAN-GP，还是先来介绍WGAN。</p>
<h4 id="12-5-1-WGAN：基于推土机距离原理的GAN"><a href="#12-5-1-WGAN：基于推土机距离原理的GAN" class="headerlink" title="12.5.1 WGAN：基于推土机距离原理的GAN"></a>12.5.1 WGAN：基于推土机距离原理的GAN</h4><p>1．原始GAN的问题即原因</p>
<p>实际训练中，GAN存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。这与GAN的机制有关。</p>
<p>GAN最终达到对抗的纳什均衡只是一个理想状态，而现实情况中得到的结果都是中间状态（伪平衡）。大部分的情况是，随着训练的次数越多判别器D的效果越好，会导致一直可以将生成器G的输出与真实样本区分开。</p>
<p>这是因为生成器G是从低维空间向高维空间（复杂的样本空间）映射，其生成的样本分布空间Pg难以充满整个真实样本的分布空间Pr。即两个分布完全没有重叠的部分，或者它们重叠的部分可以忽略，这样就使得判别器D总会将它们分开。</p>
<p>为什么可以忽略呢？放在二维空间中会更好理解一些。在二维平面中随机取两条曲线，两条曲线上的点可以代表二者的分布，要想判别器无法分辨它们，需要两个分布融合在一起，即它们之间需要存在重叠线段，然而这样的概率为0；另一方面，即使它们很可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0代表它只是一个点，代表不了分布情况，所以可以忽略。</p>
<p>这样会带来什么后果呢？假设先将D训练得足够好，然后固定D，再来训练G，通过实验会发现G的loss无论怎么更新也无法收敛到最小值，而是无限接近log2。这个log2可以理解为Pg与Pr两个样本分布的距离。loss值恒定即表明G的梯度为0，无法再通过训练来优化自己。</p>
<p>所以在原始GAN的训练中，判别器训练得太好，会使生成器梯度消失，生成器loss降不下去；判别器训练得不好，会使生成器梯度不准，四处乱跑。只有判别器训练到中间状态最佳，但是这个尺度很难把握，甚至在同一轮训练的前后不同阶段，这个状态出现的时段都不一样，是个完全不可控的情况。</p>
<p>2．WGan介绍</p>
<p>WGan（Wasserstein Gan），Wasserstein是指Wasserstein距离，又叫Earth-Mover（EM）推土机距离。</p>
<p>WGan的思想是将生成的模拟样本分布Pg与原始样本分布Pr组合起来，当成所有可能的联合分布的集合。然后可以从中采样得到真实样本与模拟样本，并能够计算二者的距离，还可以算出距离的期望值。这样就可以通过训练，让网络在所有可能的联合分布中对这个期望值取下界的方向优化，也就是将两个分布的集合拉到一起。这样原来的判别式就不再是判别真伪的功能了，而是计算两个分布集合距离的功能。所以将其称为评论器更加合适，同样，最后一层的sigmoid也需要去掉了。</p>
<p>为了实现计算Wasserstein距离的功能，我们将这部分交给神经网络去拟合。为了简化公式，现在就让神经网络拟合如下函数，见式（12-1）：</p>
<p><img src="Image00261.jpg" alt></p>
<p>f（x）可以理解成神经网络的计算，让判别器来实现将f（x1 ）与f（x2 ）的距离变换成x1 -x2 的绝对值×k（K≥0）。K代表函数f（x）的Lipschitz常数，这样两个分布集合的距离就可以表示成D（real）-D（G（x））的绝对值×k了，这个k可以理解成梯度，即在神经网络f（x）中x的梯度绝对值会小于K。</p>
<p>将k忽略整理后可以得到二者分布的式子，见式（12-2）：</p>
<p><img src="Image00262.jpg" alt></p>
<p>现在要做的就是将L当成目标来计算loss，G将希望生成的结果Pg越来越接近Pr，所以需要通过训练让距离L最小化。因为生成器G与第一项无关，所以G的loss可以简化为式（12-3）。</p>
<p><img src="Image00263.jpg" alt></p>
<p>而D的任务是区分它们，所以希望二者距离变大，所以loss需要取反，得到式（12-4）。</p>
<p><img src="Image00264.jpg" alt></p>
<p>同样，通过D的loss值也可以看出G的生成质量，即loss越小代表距离越近，则生成的质量越高。</p>
<p>而对于前面的梯度限制，WGAN直接使用了截断（clipping）的方式。这个方式在实际应用中有问题，所以后来又产生了其升级版WGAN-GP。</p>
<h4 id="12-5-2-WGAN-GP：带梯度惩罚项的WGAN"><a href="#12-5-2-WGAN-GP：带梯度惩罚项的WGAN" class="headerlink" title="12.5.2 WGAN-GP：带梯度惩罚项的WGAN"></a>12.5.2 WGAN-GP：带梯度惩罚项的WGAN</h4><p>1．WGAN问题即原因</p>
<p>前面介绍了原始WGAN的Lipschitz限制的施加方式不对，使用Weight clipping方式太过生硬。每当更新完一次判别器的参数之后，就检查判别器的所有参数的绝对值有没有超过一个阈值，比如0.01，如果有的话就把这些参数截断（clip）回[-0.01，0.01]的范围内。</p>
<p>Lipschitz限制本意是当输入的样本稍微变化后，判别器给出的分数不能发生太剧烈的变化。通过在训练过程中保证判别器的所有参数有界，就保证了判别器不能对两个略微不同的样本给出天差地别的分数值，从而间接实现了Lipschitz限制。</p>
<p>然而，这种渴望与判别器本身的目的相矛盾。在判别器中，是希望loss尽可能地大，才能拉大真假样本的区别，这种情况会导致在判别器中通过loss算出的梯度会沿着loss越来越大的方向变化，然而经过Weight clipping后每一个网络参数又被独立地限制了取值范围（如[-0.01，0.01]），这种结果只能是所有的参数走向极端，要么取最大值（如0.01）要么取最小值（如-0.01），判别器没能充分利用自身的模型能力，经过它回传给生成器的梯度也会跟着变差。</p>
<p>如果判别器是一个多层网络，Weight clipping还会导致梯度消失或者梯度爆炸。原因是，如果我们把Clipping threshold设得稍微小了一点，每经过一层网络，梯度就变小一点，多层之后就会指数衰减；反之，如果设得稍微大了一点，每经过一层网络，梯度就会变大一点，多层之后就会指数爆炸。然而在实际应用中很难做到设置适宜，让生成器获得恰到好处的回传梯度。</p>
<p>2．WGAN-GP介绍</p>
<p>WGAN-GP中的GP是梯度惩罚（Gradient penalty）的意思。它是替换Weight clipping的一种方法。通过直接设置一个额外的梯度惩罚项，来实现判别器的梯度不超过K。</p>
<p>例如式（12-5）和式（12-6）中：</p>
<p><img src="Image00265.jpg" alt></p>
<p><img src="Image00266.jpg" alt></p>
<p>MSE为平方差公式，X_inter为整个联合分布空间的x取样，即梯度惩罚项grad_pen为求整个联合分布空间的x对应D的梯度与k的平方差。</p>
<p>判别器尽可能拉大真假样本的分数差距，希望梯度越大越好，变化幅度越大越好，所以判别器在充分训练之后，其梯度Norm其实就会在k附近。因此可以把上面的loss改成要求梯度Norm离k越近越好，k可以是任何数，我们就简单地把k定为1，再跟WGAN原来的判别器loss加权合并，就得到新的判别器loss，见式（12-7）：</p>
<p><img src="Image00267.jpg" alt></p>
<p>即式（12-8）：  </p>
<p><img src="Image00268.jpg" alt></p>
<p>λ为梯度惩罚参数，可以用来调节梯度惩罚的力度。</p>
<p>grad_pen是需要从Pg与Pr的联合空间里采样。对于整个样本空间而言，需要抓住生成样本集中区域、真实样本集中区域及夹在它们中间的区域，即先随机取一个0～1的随机数，令一对真假样本分别按随机数的比例加和来生成X_inter的采样，见式（12-9）和式（12-10）：</p>
<p><img src="Image00269.jpg" alt></p>
<p><img src="Image00270.jpg" alt></p>
<p>这样把X_inter代入到式（12-5）中，就得到最终版本的判别器loss。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eps = tf.random_uniform([shape], minval=0., maxval=1.)</span><br><span class="line">X_inter = eps*real + (1. -eps)* G（x）</span><br><span class="line">L= D（real）-D（G（x））+λMSE（tf.gradients(D(X_inter), [X_inter])-1）</span><br></pre></td></tr></table></figure>

</details>

<p>在WGAN-GP相关论文的实验中，Gradient penalty能够显著提高训练速度，解决了原始WGAN生成器梯度二值化问题（如图12-8a）与梯度消失爆炸问题（如图12-8b）。</p>
<p><img src="Image00014.jpg" alt> 注意： 由于我们是对每个样本独立地施加梯度惩罚，所以判别器的模型架构中不能使用Batch Normalization，因为它会引入同一个batch中不同样本的相互依赖关系。如果需要，可以选择其他的normalization方法，如Layer Normalization、Weight Normalization和Instance Normalization，这些方法就不会引入样本之间的依赖。WGAN-GP的作者推荐的是Layer Normalization。</p>
<p><img src="Image00271.jpg" alt></p>
<p>图12-8 WGAN-GP优势（该图片来源于WGAN-GP相关论文）</p>
<h4 id="12-5-3-实例90：构建WGAN-GP生成MNIST数据集"><a href="#12-5-3-实例90：构建WGAN-GP生成MNIST数据集" class="headerlink" title="12.5.3 实例90：构建WGAN-GP生成MNIST数据集"></a>12.5.3 实例90：构建WGAN-GP生成MNIST数据集</h4><p>在掌握了理论之后，下面通过一个例子对WGAN-GP有个更深刻的了解。</p>
<p>本例演示在MNIST数据集上使用WGAN-GP网络模型生成模拟数据。这次的D和G用最简单的全连接网络来实现。</p>
<p>实例描述</p>
<p>通过使用WGAN-GP网络学习MNIST数据特征，并生成以假乱真的MNIST模拟样本。</p>
<p>具体实现可以分为如下几个步骤。</p>
<p>1．引入头文件并加载MNIST数据</p>
<p>假设MNIST数据放在本地磁盘跟目录的data下，同样使用slim库建立网络模型。代码如下：</p>
<p>代码12-3 wgan-gp</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">from scipy import misc,ndimage</span><br><span class="line">import tensorflow.contrib.slim as slim</span><br><span class="line">#from tensorflow.python.ops import init_ops</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br></pre></td></tr></table></figure>

</details>

<p>2．定义生成器与判别器</p>
<p>由于复杂部分都放在loss方面了，所以生成器G和判别器D就会简单一些，各自有3个全连接层。生成器最终输出与MNIST图片相同维度的数据作为模拟样本。判别器的输出不需要再有激活函数，输出维度为1的数值用来表示其结果。</p>
<p>代码12-3 wgan-gp（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def G(x):#生成器</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.</span><br><span class="line">   startswith(&apos;generator&apos;)]) &gt; 0</span><br><span class="line">    with tf.variable_scope(&apos;generator&apos;, reuse = reuse):</span><br><span class="line">        x = slim.fully_connected(x, 32,activation_fn = tf.nn.relu)</span><br><span class="line">        x = slim.fully_connected(x, 128,activation_fn = tf.nn.relu)</span><br><span class="line">        x = slim.fully_connected(x, mnist_dim,activation_fn = </span><br><span class="line">       tf.nn.sigmoid)</span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line">def D(X):#判别器</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.</span><br><span class="line">   startswith(&apos;discriminator&apos;)]) &gt; 0</span><br><span class="line">    with tf.variable_scope(&apos;discriminator&apos;, reuse=reuse): </span><br><span class="line">        X = slim.fully_connected(X, 128,activation_fn = tf.nn.relu)</span><br><span class="line">        X = slim.fully_connected(X, 32,activation_fn = tf.nn.relu)</span><br><span class="line">        X = slim.fully_connected(X, 1,activation_fn = None)</span><br><span class="line">    return X</span><br></pre></td></tr></table></figure>

</details>

<p>3．定义网络模型与loss</p>
<p>生成的模拟数据为random_Y，与前面所描述的一致；生成器的Loss为-D（random_Y）；而判别器的loss为D（random_Y）-D（real_X）再加上一个联合分布样本梯度的惩罚项grad_pen；惩罚项的采样X_inter由一部分Pg分布和一部分Pr分布组成。同时对D（X_inter）求梯度得到grad_pen。具体代码如下：</p>
<p>代码12-3 wgan-gp（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> real_X = tf.placeholder(tf.float32, shape=[batch_size, mnist_dim])</span><br><span class="line"> random_X = tf.placeholder(tf.float32, shape=[batch_size, random_dim])</span><br><span class="line"> random_Y = G(random_X)</span><br><span class="line"> </span><br><span class="line"> eps = tf.random_uniform([batch_size, 1], minval=0., maxval=1.)</span><br><span class="line"> X_inter = eps*real_X + (1. -eps)*random_Y #按照eps比例生成真假样本采样X_inter</span><br><span class="line"> grad = tf.gradients(D(X_inter), [X_inter])[0]</span><br><span class="line"> grad_norm = tf.sqrt(tf.reduce_sum((grad)**2, axis=1))</span><br><span class="line"> grad_pen = 10 * tf.reduce_mean(tf.nn.relu(grad_norm -1.))#梯度惩罚项</span><br><span class="line"> </span><br><span class="line"> D_loss = tf.reduce_mean(D(random_Y)) -tf.reduce_mean(D(real_X)) + </span><br><span class="line">grad_pen</span><br><span class="line"> G_loss = -tf.reduce_mean(D(random_Y))</span><br></pre></td></tr></table></figure>

</details>

<p>4．定义优化器并开始训练</p>
<p>通过前面定义的命名空间，找到生成器和判别器的训练参数，通过AdamOptimizer进行优化训练。</p>
<p>代码12-3 wgan-gp（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"> # 获得各个网络中各自的训练参数</span><br><span class="line"> t_vars = tf.trainable_variables()</span><br><span class="line"> d_vars = [var for var in t_vars if &apos;discriminator&apos; in var.name]</span><br><span class="line"> g_vars = [var for var in t_vars if &apos;generator&apos; in var.name]</span><br><span class="line"> print(len(t_vars),len(d_vars))</span><br><span class="line"> #定义D和G的优化器</span><br><span class="line"> D_solver = tf.train.AdamOptimizer(1e-4, 0.5).minimize(D_loss, var_</span><br><span class="line">list=d_vars)</span><br><span class="line"> G_solver = tf.train.AdamOptimizer(1e-4, 0.5).minimize(G_loss, var_</span><br><span class="line">list=g_vars)</span><br><span class="line"> </span><br><span class="line"> training_epochs =100</span><br><span class="line"> </span><br><span class="line"> with tf.Session() as sess:</span><br><span class="line">     sess.run(tf.global_variables_initializer())    </span><br><span class="line">     if not os.path.exists(&apos;out/&apos;):</span><br><span class="line">         os.makedirs(&apos;out/&apos;)</span><br><span class="line">         </span><br><span class="line">     for epoch in range(training_epochs):</span><br><span class="line">         total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line"> </span><br><span class="line">         # 遍历全部数据集</span><br><span class="line">         for e in range(total_batch):</span><br><span class="line">             for i in range(5):</span><br><span class="line">                 real_batch_X,_ = mnist.train.next_batch(batch_size)</span><br><span class="line">                 random_batch_X = np.random.uniform(-1, 1, (batch_size, </span><br><span class="line">                random_dim))</span><br><span class="line">                 _,D_loss_ = sess.run([D_solver,D_loss], feed_dict=</span><br><span class="line">                &#123;real_X:real_batch_X, random_X:random_batch_X&#125;)</span><br><span class="line">             random_batch_X = np.random.uniform(-1, 1, (batch_size, </span><br><span class="line">            random_dim))</span><br><span class="line">             _,G_loss_ = sess.run([G_solver,G_loss], feed_dict=&#123;random_</span><br><span class="line">            X:random_batch_X&#125;)</span><br></pre></td></tr></table></figure>

</details>

<p>在session中优先让判别器学习次数多一些，让判别器每训练5次，生成器优化一次。WGAN_GP不会因为判别器准确度太高而引起生成器梯度消失的问题，好的判别器只会让生成器有更好的模拟效果。</p>
<p>5．可视化结果</p>
<p>这次我们把生成的结果用图片的方式保存起来，并生成到硬盘上。每10次的全样本迭代会生成一次图片，图片的位置为本地代码文件所在目录下的out文件夹内。代码如下：</p>
<p>代码12-3 wgan-gp（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">if epoch % 10 == 0:</span><br><span class="line">            print (&apos;epoch %s, D_loss: %s, G_loss: %s&apos;%(epoch, D_loss_, </span><br><span class="line">           G_loss_))</span><br><span class="line">            n_rows = 6</span><br><span class="line">            check_imgs = sess.run(random_Y, feed_dict=&#123;random_X:random_</span><br><span class="line">            batch_X&#125;).reshape((batch_size, width, height))[:n_rows*n_</span><br><span class="line">            rows]</span><br><span class="line">            imgs = np.ones((width*n_rows+5*n_rows+5, height*n_rows+5*n_</span><br><span class="line">           rows+5))</span><br><span class="line">            for i in range(n_rows*n_rows):</span><br><span class="line">               num1 = (i%n_rows)</span><br><span class="line">               num2 = np.int32(i/n_rows)</span><br><span class="line">               imgs[5+5*num1+width*num1:5+5*num1+width+width*num1,5+5*</span><br><span class="line">               num2+height*num2:5+5*num2+height+height*num2] = check_</span><br><span class="line">               imgs[i]</span><br><span class="line">    </span><br><span class="line">            misc.imsave(&apos;out/%s.png&apos;%(epoch/10), imgs)</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码后，生成如下结果：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">epoch 0, D_loss: -4.15614, G_loss: 0.35294</span><br><span class="line">epoch 10, D_loss: -2.5528, G_loss: 1.48789</span><br><span class="line">epoch 20, D_loss: -2.21916, G_loss: 1.0337</span><br><span class="line">epoch 30, D_loss: -1.87463, G_loss: 0.875138</span><br><span class="line">epoch 40, D_loss: -1.65764, G_loss: 0.752094</span><br><span class="line">epoch 50, D_loss: -1.40312, G_loss: 0.967182</span><br><span class="line">epoch 60, D_loss: -1.16828, G_loss: 0.772282</span><br><span class="line">epoch 70, D_loss: -1.20912, G_loss: 1.03305</span><br><span class="line">epoch 80, D_loss: -1.02528, G_loss: 1.05023</span><br><span class="line">epoch 90, D_loss: -0.922399, G_loss: 1.31767</span><br><span class="line">完成!</span><br></pre></td></tr></table></figure>

</details>

<p>可以看到D_loss的值在逐渐变小，表明生成的模拟样本质量越来越高。来到本地的out文件夹下，找到10张图片，如图12-9所示（这里举例出3张）。</p>
<p><img src="Image00272.jpg" alt></p>
<p>图12-9 WGAN-GP结果</p>
<p>图12-9a为第一次迭代时的输出，图12-9c为第10次的输出。可以看到，在WGAN-PG的判别器严格要求下，生成器的模拟数据越来越逼真。</p>
<h4 id="12-5-4-练习题"><a href="#12-5-4-练习题" class="headerlink" title="12.5.4 练习题"></a>12.5.4 练习题</h4><p>把前面的例子代码loss部分分别改成如下两种情况。</p>
<p>（1）第一种情况：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D_loss = tf.reduce_mean(D(random_Y))-tf.reduce_mean(D(real_X)) + grad_pen</span><br><span class="line">G_loss = tf.reduce_mean(D(random_Y))</span><br></pre></td></tr></table></figure>

</details>

<p>（2）第二种情况：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D_loss = tf.reduce_mean(D(real_X)) -tf.reduce_mean(D(random_Y)) + grad_pen</span><br><span class="line">G_loss = tf.reduce_mean(D(random_Y))</span><br></pre></td></tr></table></figure>

</details>

<p>猜想一下会产生什么样的效果？为什么会这样？通过运行实际代码验证你的假设。</p>
<h3 id="12-6-LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN"><a href="#12-6-LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN" class="headerlink" title="12.6 LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN"></a>12.6 LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN</h3><p>前文已经介绍过GAN是以对抗的方式逼近概率分布。但是直接使用该方法，会随着判别器越来越好而生成器无法与其对抗，进而形成梯度消失的问题。所以不论是WGAN，还是本节中的LSGAN，都是试图使用不同的距离度量，从而构建一个不仅稳定，同时还收敛迅速的生成对抗网络。</p>
<p>下面就来一起学习一下LSGAN。</p>
<h4 id="12-6-1-LSGAN介绍"><a href="#12-6-1-LSGAN介绍" class="headerlink" title="12.6.1 LSGAN介绍"></a>12.6.1 LSGAN介绍</h4><p>WGAN使用的是Wasserstein理论来构建度量距离。而LSGAN使用了另一个方法，即使用了更加平滑和非饱和梯度的损失函数——最小乘二来代替原来的Sigmoid交叉熵。这是由于L2正则独有的特性，在数据偏离目标时会有一个与其偏离距离成比例的惩罚，再将其拉回来，从而使数据的偏离不会越来越远。</p>
<p>相对于WGAN而言，LSGAN的loss简单很多。直接将传统的GAN中的softmax变为平方差即可。</p>
<p>判别器的loss：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D_loss=tf.reduce_sum(tf.square(D(real_X)-1) + tf.square(D(random_Y)))/2</span><br></pre></td></tr></table></figure>

</details>

<p>生成器的loss：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">G_loss = tf.reduce_sum(tf.square(D(random_Y)-1))/2</span><br></pre></td></tr></table></figure>

</details>

<p>为什么要除以2？和以前的原理一样，在对平方求导时会得到一个系数2，与事先的1/2运算正好等于1，使公式更加完整。</p>
<h4 id="12-6-2-实例91：构建LSGAN生成MNIST模拟数据"><a href="#12-6-2-实例91：构建LSGAN生成MNIST模拟数据" class="headerlink" title="12.6.2 实例91：构建LSGAN生成MNIST模拟数据"></a>12.6.2 实例91：构建LSGAN生成MNIST模拟数据</h4><p>本例中直接修改“12-1 Mnistinfogan.py”代码中的loss函数，将其改成LSGAN网络。</p>
<p>实例描述</p>
<p>通过使用LSGAN网络学习MNIST数据特征，并生成以假乱真的MNIST模拟样本。</p>
<p>下面给出具体步骤。</p>
<p>1．修改判别器</p>
<p>将判别器的最后一层输出disc改成使用Sigmoid的激活函数。代码如下：</p>
<p>代码12-4 mnistLSgan</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def discriminator(x, num_classes=10, num_cont=2):</span><br><span class="line">   </span><br><span class="line">……</span><br><span class="line">        disc = slim.fully_connected(shared_tensor, num_outputs=1, </span><br><span class="line">       activation_fn=tf.nn.sigmoid)</span><br><span class="line">        disc = tf.squeeze(disc, -1)</span><br><span class="line">        recog_cat = slim.fully_connected(recog_shared, num_</span><br><span class="line">       outputs=num_classes, activation_fn=None)</span><br><span class="line">        recog_cont = slim.fully_connected(recog_shared, num_</span><br><span class="line">       outputs=num_cont, activation_fn=tf.nn.sigmoid)</span><br><span class="line">    return disc, recog_cat, recog_cont</span><br></pre></td></tr></table></figure>

</details>

<p>2．修改loss值</p>
<p>将原有的loss_d与loss_g改成平方差形式，原有的y_real与y_fake不再需要了，可以删掉，其他代码不用变动。</p>
<p>代码12-4 MnistLSgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> # 判别器discriminator</span><br><span class="line"> disc_real, class_real, _ = discriminator(x)</span><br><span class="line"> disc_fake, class_fake, con_fake = discriminator(gen)</span><br><span class="line"> pred_class = tf.argmax(class_fake, dimension=1)</span><br><span class="line"> </span><br><span class="line"> # 判别器loss</span><br><span class="line"> #loss_d_r = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_real, labels=y_real))</span><br><span class="line"> #loss_d_f = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits</span><br><span class="line">(logits=disc_fake, labels=y_fake))</span><br><span class="line"> #最小乘二loss</span><br><span class="line"> loss_d = tf.reduce_sum(tf.square(disc_real-1) + tf.square(disc_</span><br><span class="line">fake))/2</span><br><span class="line"> loss_g = tf.reduce_sum(tf.square(disc_fake-1))/2</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>3．运行代码生成结果</p>
<p>运行代码，生成结果如下，输出图片如图12-10所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 0001 cost= 2.074717045  0.93645</span><br><span class="line">Epoch: 0002 cost= 2.024495363  1.88027</span><br><span class="line">Epoch: 0003 cost= 2.158437967  2.78284</span><br><span class="line">完成!</span><br><span class="line">Result: 1.71483 3.07138</span><br><span class="line">d_class 7 inputy 7 con_out [ 0.16134234  0.03605343]</span><br><span class="line">d_class 2 inputy 2 con_out [ 0.30764639  0.98185432]</span><br><span class="line">d_class 1 inputy 1 con_out [ 0.11353409  0.02166406]</span><br><span class="line">d_class 0 inputy 0 con_out [  2.32195278e-04   2.08523397e-06]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.355297    0.94447494]</span><br><span class="line">d_class 1 inputy 1 con_out [  1.33050963e-01   1.69226732e-05]</span><br><span class="line">d_class 4 inputy 4 con_out [ 0.17757109  0.78396767]</span><br><span class="line">d_class 9 inputy 9 con_out [  6.99081238e-06   2.24134132e-01]</span><br><span class="line">d_class 5 inputy 5 con_out [ 0.87434149  0.98944479]</span><br><span class="line">d_class 9 inputy 9 con_out [ 0.00770722  0.00958756]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00273.jpg" alt></p>
<p>图12-10 LSGAN例子结果</p>
<p>可见LSGAN也可以产生与WGAN一样的效果。</p>
<p><img src="Image00014.jpg" alt> 注意： WGAN与LSGAN谁更好呢？答案是很难一概而论，只能具体问题具体分析。在实际实现中还会有更多细节决定最终的结果，不同的技术使用都会对结果造成相应的影响。</p>
<h3 id="12-7-GAN-cls：具有匹配感知的判别器"><a href="#12-7-GAN-cls：具有匹配感知的判别器" class="headerlink" title="12.7 GAN-cls：具有匹配感知的判别器"></a>12.7 GAN-cls：具有匹配感知的判别器</h3><p>本节介绍一种GAN网络增强技术——具有匹配感知的判别器。前面讲过，在InfoGAN中，使用了ACGAN的方式进行指导模拟数据与生成数据的对应关系。在GAN-cls中该效果会以更简单的方式来实现，即增强判别器的功能，令其不仅能判断图片真伪，还能判断匹配真伪。</p>
<h4 id="12-7-1-GAN-cls的具体实现"><a href="#12-7-1-GAN-cls的具体实现" class="headerlink" title="12.7.1 GAN-cls的具体实现"></a>12.7.1 GAN-cls的具体实现</h4><p>GAN-cls的具体做法是，在原有的GAN网络上，将判别器的输入变为图片与对应标签的连接数据。这样判别器的输入特征中就会有生成图像的特征与对应标签的特征。然后用这样的判别器分别对真实标签与真实图片、假标签与真实图片、真实标签与假图片进行判断，预期的结果依次为真、假、假，在训练的过程中沿着这个方向收敛即可。而对于生成器，则不需要做任何改动。这样简单的一步就完成了生成根据标签匹配的模拟数据功能。</p>
<h4 id="12-7-2-实例92：使用GAN-cls技术实现生成标签匹配的模拟数据"><a href="#12-7-2-实例92：使用GAN-cls技术实现生成标签匹配的模拟数据" class="headerlink" title="12.7.2 实例92：使用GAN-cls技术实现生成标签匹配的模拟数据"></a>12.7.2 实例92：使用GAN-cls技术实现生成标签匹配的模拟数据</h4><p>本例中直接修改“12-4 mnistLSgan.py”代码中的判别器函数。演示GAN-cls技术的使用。</p>
<p>实例描述</p>
<p>在代码“12-4 mnistLSgan.py”的基础上，使用GAN-cls技术对判别器进行改造，并通过输入错误的样本标签让判别器学习样本与标签的匹配，从而优化生成器，使生成器最终生成与标签一致的样本，实现与ACGAN等同的效果。</p>
<p>下面给出具体步骤。</p>
<p>1．修改判别器</p>
<p>在代码“12-4 mnistLSgan.py”的基础上，将判别器的输入改成x与y，新增加的y代表输入的样本标签；在内部处理中，先通过全连接网络将y变为与图片一样维度的映射，并调整为图片相同的形状，使用concat将二者连接到一起统一处理。后续的处理过程是一样的，两个卷积后再接两个全连接，最后一层输出disc。代码如下：</p>
<p>代码12-5 GAN-cls</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def discriminator(x,y):</span><br><span class="line">    reuse = len([t for t in tf.global_variables() if t.name.startswith</span><br><span class="line">   (&apos;discriminator&apos;)]) &gt; 0</span><br><span class="line">    with tf.variable_scope(&apos;discriminator&apos;, reuse=reuse):</span><br><span class="line">        y = slim.fully_connected(y, num_outputs=n_input, activation_</span><br><span class="line">       fn = leaky_relu)</span><br><span class="line">        y = tf.reshape(y, shape=[-1, 28, 28, 1]) #将y统一成图片格式</span><br><span class="line">        x = tf.reshape(x, shape=[-1, 28, 28, 1])</span><br><span class="line">        #将二者连接到一起，统一处理</span><br><span class="line">        x= tf.concat(axis=3, values=[x,y])</span><br><span class="line">        x = slim.conv2d(x, num_outputs = 64, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        x = slim.conv2d(x, num_outputs=128, kernel_size=[4,4], </span><br><span class="line">       stride=2, activation_fn=leaky_relu)</span><br><span class="line">        x = slim.flatten(x)</span><br><span class="line">        shared_tensor = slim.fully_connected(x, num_outputs=1024, </span><br><span class="line">       activation_fn = leaky_relu)</span><br><span class="line">        disc = slim.fully_connected(shared_tensor, num_outputs=1, </span><br><span class="line">       activation_fn=tf.nn.sigmoid)</span><br><span class="line">        disc = tf.squeeze(disc, -1)</span><br><span class="line"></span><br><span class="line">    return disc</span><br></pre></td></tr></table></figure>

</details>

<p>2．添加错误标签输入符，构建网络结构</p>
<p>添加错误标签misy，同时在判别器中分别将真实样本与真实标签、生成的图像gen与真实标签、真实样本与错误标签组成的输入传入判别器中。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里是将3种输入的x与y分别按照batch_size维度连接变为判别器的一个输入的。生成结果后再使用split函数将其裁成3个结果disc_real、disc_fake和disc_mis，分别代表真实样本与真实标签、生成的图像gen与真实标签、真实样本与错误标签所对应的判别值。这么写会使代码看上去简洁一些，当然也可以一个一个地输入x、y，然后调用三次判别器，效果是一样的。</p>
<p>由于本例中不需要InfoGAN模型，将“12-4 mnistLSgan.py”代码中的隐含信息z_con部分全部去掉。代码如下：</p>
<p>代码12-5 GAN-cls（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> x = tf.placeholder(tf.float32, [None, n_input])      #输入样本</span><br><span class="line"> y = tf.placeholder(tf.int32, [None])                   #正确标签</span><br><span class="line"> misy = tf.placeholder(tf.int32, [None])                #错误标签</span><br><span class="line"> </span><br><span class="line"> z_rand = tf.random_normal((batch_size, rand_dim)) #38列</span><br><span class="line"> z = tf.concat(axis=1, values=[tf.one_hot(y, depth = classes_dim), </span><br><span class="line">z_rand])#50列</span><br><span class="line"> gen = generator(z)</span><br><span class="line"> genout= tf.squeeze(gen, -1)</span><br><span class="line"> </span><br><span class="line"> # 判别器discriminator</span><br><span class="line"> xin=tf.concat([x, tf.reshape(gen, shape=[-1,784]),x],0)</span><br><span class="line"> yin=tf.concat([tf.one_hot(y, depth = classes_dim),tf.one_hot(y, depth = classes_dim),tf.one_hot(misy, depth = classes_dim)],0)</span><br><span class="line"> disc_all = discriminator(xin,yin)</span><br><span class="line"> disc_real,disc_fake,disc_mis =tf.split(disc_all,3)</span><br><span class="line"> </span><br><span class="line"> #构建loss</span><br><span class="line"> loss_d = tf.reduce_sum(tf.square(disc_real-1) + ( tf.square(disc_fake)</span><br><span class="line">+tf.square(disc_mis))/2 )/2</span><br><span class="line"> loss_g = tf.reduce_sum(tf.square(disc_fake-1))/2</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>在计算判别器的loss时，同样使用LSGAN方式，并且将错误部分的loss变为disc_fake与disc_mis的和，然后再除以2。因为对于生成器生成的样本与错误的输入标签，判别器都应该将其判断为错误。</p>
<p>3．使用MonitoredTrainingSession创建sesson，开始训练</p>
<p>定义global_step，使用MonitoredTrainingSession创建sesson，来管理检查点文件，在session中构建错误标签数据，训练模型。</p>
<p>代码12-5 GAN-cls（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> </span><br><span class="line"> global_step = tf.train.get_or_create_global_step() #使用MonitoredTrainingSession，必须有</span><br><span class="line"> </span><br><span class="line"> train_disc = tf.train.AdamOptimizer(0.0001).minimize(loss_d , var_</span><br><span class="line">list = d_vars, global_step = global_step)</span><br><span class="line"> train_gen = tf.train.AdamOptimizer(0.001).minimize(loss_g , var_</span><br><span class="line">list = g_vars, global_step = gen_global_step)</span><br><span class="line"> </span><br><span class="line"> training_epochs = 3         #整体数据集迭代3次</span><br><span class="line"> display_step = 1             #每迭代一次显示一次输出信息</span><br><span class="line"> </span><br><span class="line"> with tf.train.MonitoredTrainingSession(checkpoint_dir=&apos;log/</span><br><span class="line">checkpointsnew&apos;,save_checkpoint_secs  =60) as sess:</span><br><span class="line"> </span><br><span class="line">     total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">     print(&quot;global_step.eval(session=sess)&quot;,global_step.eval</span><br><span class="line">   (session=sess),int(global_step.eval(session=sess)/total_batch))</span><br><span class="line">     for epoch in range( int(global_step.eval(session=sess)/total_</span><br><span class="line">    batch),training_epochs):</span><br><span class="line">         avg_cost = 0.</span><br><span class="line"> </span><br><span class="line">         # 遍历全部数据集</span><br><span class="line">         for i in range(total_batch):</span><br><span class="line">             batch_xs, batch_ys = mnist.train.next_batch(batch_size) #取数据</span><br><span class="line">             _, mis_batch_ys = mnist.train.next_batch(batch_size) #取错误标签数据</span><br><span class="line">             feeds = &#123;x: batch_xs, y: batch_ys,misy:mis_batch_ys&#125;</span><br><span class="line"> </span><br><span class="line">             # 输入数据，运行优化器</span><br><span class="line">             l_disc, _, l_d_step = sess.run([loss_d, train_disc, global_</span><br><span class="line">            step],feeds)</span><br><span class="line">             l_gen, _, l_g_step = sess.run([loss_g, train_gen, gen_global_</span><br><span class="line">            step],feeds)</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，生成如下结果，输出图片如图12-11所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">完成!</span><br><span class="line">result: 1.17139 0.829812</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00274.jpg" alt></p>
<p>图12-11 GAN-cls结果</p>
<p>如图12-11所示，使用GAN-cls技术同样也实现了生成与标签对应的样本，而且整体代码的运算要比ACGAN简洁很多。</p>
<h3 id="12-8-SRGAN——适用于超分辨率重建的GAN"><a href="#12-8-SRGAN——适用于超分辨率重建的GAN" class="headerlink" title="12.8 SRGAN——适用于超分辨率重建的GAN"></a>12.8 SRGAN——适用于超分辨率重建的GAN</h3><p>SRGAN属于GAN理论在超分辨率重建（SR）方面的应用。在学习SRGAN之前有必要先了解一下SR领域的相关技术。</p>
<h4 id="12-8-1-超分辨率技术"><a href="#12-8-1-超分辨率技术" class="headerlink" title="12.8.1 超分辨率技术"></a>12.8.1 超分辨率技术</h4><p>1．SR（超分辨率重建）技术介绍</p>
<p>SR（Super-Resolution，超分辨率）技术，是指从观测到的低分辨率图像重建出相应的高分辨率图像，在监控设备、卫星图像和医学影像等领域都有重要的应用价值，该技术也可应用于马赛克图片的恢复应用场景中。</p>
<p>SR可分为两类：从多张低分辨率图像重建出高分辨率图像，和从单张低分辨率图像重建出高分辨率图像。基于深度学习的SR，主要是基于单张低分辨率的重建方法，即Single Image Super-Resolution（SISR）。</p>
<p>SISR是一个逆问题。对于一个低分辨率图像，可能存在许多不同的高分辨率图像与之对应，为了让逆向图片的结果更接近真实图片，则需要让模型在一定约束下，指定某个领域中来进行可逆训练，而这个约束，就是指现有的低分辨率像素的色度信息与位置信息。为了能让模型更好地学习并利用这个信息，基于深度学习的SR通过神经网络直接通过优化低分辨率图像到高分辨率图像的损失函数loss来进行端到端训练，以实现超分辨率重建功能。</p>
<p>2．深度学习中的SR方法</p>
<p>在GAN出现之前，先是以SRCNN、DRCN为主的SR方法。该方法的大体思想是将低分辨率像素先扩展到高分辨率的像素大小，然后通过卷积方式训练网络，优化其与真实高分辨率图片的loss，最终形成模型。并且在这一方法上也总结了不少经验参数，如在SRCNN中，使用3层步长为1的同卷积，分别为（9×9的64输出、1×1的32输出、5×5的3输出）效果会更好。</p>
<p>后来出现了另一种比较高效的方法ESPCN（实时的基于卷积神经网络的图像超分辨率方法）。ESPCN的核心概念是亚像素卷积层（sub-pixel convolutional layer），即先在原有的低像素图片上做卷积操作，最终输出一个含有多feature map的结果，保证总像素点与高分辨率的像素点总和是一致的，然后将多张低分辨率图片合并成一张高分辨率图片。例如，假设需要将低分辨率图片的像素扩大2倍（从128×128扩大到256×256），就直接将其进行卷积操作，最终输出放大倍数的平方（2×2）个feature map，即[batch_size，W，H，4]（如果是RGB彩色图片就会是[batch_size，W，H，12]）。以灰度图为例，将4个图片中的第一个像素取出成为重构图中的4个像素，依此类推，在重构图中的每个2×2区域都是由这4幅图对应位置的像素组成，最终形成形状为[batch_size，2×W，2×H，1]大小的高分辨率图像。这个变换被称为sub-pixel convolution，如图12-12所示。</p>
<p><img src="Image00275.jpg" alt></p>
<p>图12-12 ESPCN图例</p>
<p>sub-pixel convolution的方法只在最后一层进行图像低分辩率到高分辨率的大小变换，保证了前面的卷积运算均在低分辨率图像上进行，得到了更高的运算效率。</p>
<p>另外，基于视频图像的SR方法还有VESPCN，这里不再展开介绍，有兴趣的读者可以自行学习。</p>
<p>3．TensorFlow中的图片变换函数</p>
<p>在TensorFlow中变化分辨率的函数主要是tf.image.resize_images，其具体原型如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def resize_images(images,</span><br><span class="line">                  size,</span><br><span class="line">                  method=ResizeMethod.BILINEAR,</span><br><span class="line">                  align_corners=False):</span><br></pre></td></tr></table></figure>

</details>

<p>前两个参数分别是输入的图片及要变化的尺寸，图片的形状为[batch，height，width，channels]或[height，width，channels]均可。第3个参数method的取值如下。</p>
<p>·ResizeMethod.BILINEAR：表示使用双线性插值算法变化图片。</p>
<p>·ResizeMethod.NEAREST_NEIGHBOR：表示使用邻近值插值算法变化图片。</p>
<p>·ResizeMethod.BICUBIC：表示使用双立方插值算法变化图片。</p>
<p>·ResizeMethod.AREA：表示使用面积插值算法变化图片。</p>
<p>具体算法这里不展开介绍，后面会通过实例演示其各个算法的效果。</p>
<p>还可以直接使用内部函数来做类似的处理，例如：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.image.resize_bicubic(images,size,align_corners=None,name=None)</span><br><span class="line">tf.image.resize_nearest_neighbor(images,size,align_corners=None,name=</span><br><span class="line">None)</span><br><span class="line">tf.image.resize_bilinear(images, size, align_corners=None, name=None)</span><br></pre></td></tr></table></figure>

</details>

<p>与前面不同的是，images的格式只支持一种[batch，height，width，channels]。</p>
<p>4．TensorFlow的图像变化函数汇总</p>
<p>TensorFlow的图像变化函数如表12-1所示。</p>
<p>表12-1 图像变化函数汇总</p>
<p><img src="Image00276.jpg" alt></p>
<h4 id="12-8-2-实例93：ESPCN实现MNIST数据集的超分辨率重建"><a href="#12-8-2-实例93：ESPCN实现MNIST数据集的超分辨率重建" class="headerlink" title="12.8.2 实例93：ESPCN实现MNIST数据集的超分辨率重建"></a>12.8.2 实例93：ESPCN实现MNIST数据集的超分辨率重建</h4><p>本实例主要通过对MNIST数据集实现超分辨率的重建，来示范TensorFlow中相关图片变化的函数用法和效果，以及ESPCN的网络结构。该实例共分为以下几步骤。</p>
<p>实例描述</p>
<p>通过使用ESPCN网络，在MNIST数据集上将低分辨率图片复原成高分辨率图片，并与其他复原函数的生成结果进行比较。</p>
<p>1．引入头文件，构建低分辨率样本</p>
<p>在头文件部分导入slim库，使用resize_bicubic来构建缩小4倍的低分辨率样本，将28×28的像素变为14×14（长、宽个缩小2倍）。</p>
<p>代码12-6 mnistEspcn</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow.contrib.slim as slim</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/data/&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line">batch_size = 30    # 获取样本的批次大小</span><br><span class="line">n_input = 784      # MNIST data 输入(img shape: 28*28)</span><br><span class="line">n_classes = 10     # MNIST 列别 (0-9 ，一共10类)</span><br><span class="line"></span><br><span class="line"># 待输入的样本图片</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_input])</span><br><span class="line">img = tf.reshape(x,[-1,28,28,1])</span><br><span class="line"># 缩小image</span><br><span class="line">x_small = tf.image.resize_bicubic(img, (14, 14)) # 缩小一半</span><br></pre></td></tr></table></figure>

</details>

<p>2．通过TensorFlow函数实现超分辨率</p>
<p>分别使用bicubic、nearest_neighbor和bilinear方法将分辨率还原，为了后续比较效果。</p>
<p>代码12-6 mnistEspcn（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_bicubic = tf.image.resize_bicubic(x_small, (28, 28))#双立方插值算法变化</span><br><span class="line">x_nearest = tf.image.resize_nearest_neighbor(x_small, (28, 28))</span><br><span class="line">x_bilin = tf.image.resize_bilinear(x_small, (28, 28))</span><br></pre></td></tr></table></figure>

</details>

<p>3．建立ESPCN网络结构</p>
<p>建立一个简单的三层卷积网络：第1层使用5×5的卷积核，输出64通道的图片，slim卷积函数中使用的是默认激活函数Relu；第2层使用3×3的卷积核，输出的是32通道；最后一层使用3×3卷积核，生成4通道图片。这个4通道需要和恢复超分辨率缩放范围对应，4代表长、宽各放大2倍。接着使用tf.depth_to_space函数，将多张图片合并成一张图片。</p>
<p>tf.depth_to_space函数的意思是将深度数据按照块的模式展开重新排列，第一个输入是原始数据，第二个输入是块的尺寸，输入2则代表尺寸为2×2的块。而深度就是生成图片的通道数，即将每个通道对应的像素值填充到指定大小的块中。</p>
<p>代码12-6 mnistEspcn（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#ESPCN网络结构</span><br><span class="line">net = slim.conv2d(x_small, 64, 5)</span><br><span class="line">net =slim.conv2d(net, 32, 3)</span><br><span class="line">net = slim.conv2d(net, 4, 3)</span><br><span class="line">net = tf.depth_to_space(net,2)</span><br><span class="line">print(&quot;net.shape&quot;,net.shape)</span><br></pre></td></tr></table></figure>

</details>

<p>4．构建loss及优化器</p>
<p>将图片重新调整形状（reshape）为（batch_size，784）的形状，通过平方差来计算loss，设定学习率为0.01，通过AdamOptimizer进行优化。</p>
<p>代码12-6 mnistEspcn（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = tf.reshape(net,[-1,784])</span><br><span class="line"></span><br><span class="line">cost = tf.reduce_mean(tf.pow(x -y_pred, 2))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(0.01 ).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>5．建立session，运行</p>
<p>令数据即循环100次。启动session进行迭代训练。</p>
<p>代码12-6 mnistEspcn（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">training_epochs =100</span><br><span class="line">display_step =20</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">    # 启动循环开始训练</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        # 遍历全部数据集</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  </span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">        # 显示训练中的详细信息</span><br><span class="line">        if epoch % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),</span><br><span class="line">                  &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.format(c))</span><br><span class="line"></span><br><span class="line">    print(&quot;完成!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>6．图示结果</p>
<p>为了比较效果，将原始图片、低分辨率图片、各种算法的变化图片及模型恢复的图片一起显示出来。代码如下：</p>
<p>代码12-6 mnistEspcn（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">show_num = 10</span><br><span class="line">    encode_s,encode_b,encode_n ,encode_bi,y_predv= sess.run(</span><br><span class="line">        [x_small,x_bicubic,x_nearest,x_bilin,y_pred], feed_dict=&#123;x: </span><br><span class="line">       mnist.test.images[:show_num]&#125;)</span><br><span class="line">    </span><br><span class="line">    f, a = plt.subplots(6, 10, figsize=(10, 6))</span><br><span class="line">    for i in range(show_num):</span><br><span class="line">        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))</span><br><span class="line">        a[1][i].imshow(np.reshape(encode_s[i], (14, 14)))</span><br><span class="line">        a[2][i].imshow(np.reshape(encode_b[i], (28, 28)))</span><br><span class="line">        a[3][i].imshow(np.reshape(encode_n[i], (28, 28)))</span><br><span class="line">        a[4][i].imshow(np.reshape(encode_bi[i], (28, 28)))</span><br><span class="line">        a[5][i].imshow(np.reshape(y_predv[i], (28, 28)))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，显示图片如图12-13所示。</p>
<p><img src="Image00277.jpg" alt></p>
<p>图12-13 ESPCN实例MNIST结果</p>
<p>最后一行是模型恢复的数据，可以看到，清晰度完全超过前面几行。Bicubic和bilinear效果还可以，nearest_neighbor是最差的。</p>
<h4 id="12-8-3-实例94：ESPCN实现flowers数据集的超分辨率重建"><a href="#12-8-3-实例94：ESPCN实现flowers数据集的超分辨率重建" class="headerlink" title="12.8.3 实例94：ESPCN实现flowers数据集的超分辨率重建"></a>12.8.3 实例94：ESPCN实现flowers数据集的超分辨率重建</h4><p>前面的MNIST数据集轻巧方便，非常适合对模型的演示与理解。下面学习对彩色图片进行超分辨率的重建。彩色图片与MNIST样本不同的地方主要是，图片变为了3通道，并且像素点更多，而MNIST像素点更稀疏。所以应用在训练模型上，会有一些细节进行调节。通过对本例的学习，读者可以掌握对全彩色图片的一些处理技巧，这也是本例的主要意义。</p>
<p>本例主要实现对flowers数据集的图片处理。flowers数据集在第11章中的slim部分介绍过。本例同样还是使用slim模块进行数据的操作。另外flowers是尺寸不一的数据样本，所以在本例中也可以借鉴统一尺寸处理的方法。同样，本例还会示范TensorFlow中相关图片变化的函数用法和效果，以及ESPCN的网络结构。该实例共分为以下几步。</p>
<p>实例描述</p>
<p>通过使用ESPCN网络，在flower数据集上将低分辨率图片复原成高分辨率图片并与其他复原函数的生成结果进行比较。</p>
<p>1．引入头文件，创建样本数据源</p>
<p>同样使用slim，这次使用的数据源是flowers，所以将该代码文件建立到models下面的slim下，然后就可以其引入flowers数据集了（这一步不熟悉的读者可以参考第11章的slim数据集部分）。</p>
<p>指定TFRecord文件夹，创建数据集。代码如下：</p>
<p>代码12-7 tfrecoderSRESPCN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"> import tensorflow as tf</span><br><span class="line"> from datasets import flowers</span><br><span class="line"> import numpy as np</span><br><span class="line"> import matplotlib.pyplot as plt</span><br><span class="line"> </span><br><span class="line"> slim = tf.contrib.slim</span><br><span class="line"> </span><br><span class="line"> height = width = 200</span><br><span class="line"> batch_size = 4</span><br><span class="line"> DATA_DIR=&quot;D:/own/python/flower_photosos&quot;</span><br><span class="line"> </span><br><span class="line"> #选择数据集validation</span><br><span class="line"> dataset = flowers.get_split(&apos;validation&apos;, DATA_DIR)</span><br><span class="line"> #创建一个provider</span><br><span class="line"> provider = slim.dataset_data_provider.DatasetDataProvider(dataset,</span><br><span class="line">num_readers = 2)</span><br><span class="line"> #通过provider的get拿到内容</span><br><span class="line"> [image, label] = provider.get([&apos;image&apos;, &apos;label&apos;])</span><br><span class="line"> print(image.shape)</span><br></pre></td></tr></table></figure>

</details>

<p>2．获取批次样本并通过TensorFlow函数实现超分辨率</p>
<p>通过resize_image_with_crop_or_pad函数统一样本大小，大的剪掉，不够的加0填充。使用tf.train.batch函数获得指定批次数据images和labels。</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> # 剪辑图片为统一大小 </span><br><span class="line"> distorted_image = tf.image.resize_image_with_crop_or_pad(image, </span><br><span class="line">height, width) #剪辑尺寸，不够填充 </span><br><span class="line"> ################################################</span><br><span class="line"> images, labels = tf.train.batch([distorted_image, label], batch_size= </span><br><span class="line">batch_size)</span><br><span class="line"> print(images.shape)</span><br><span class="line"> </span><br><span class="line"> x_smalls = tf.image.resize_images(images, (np.int32(height/2), np.</span><br><span class="line">int32(width/2)))#  尺寸变为原来的1/4</span><br><span class="line"> x_smalls2 = x_smalls/255.0</span><br><span class="line"> #还原</span><br><span class="line"> x_nearests = tf.image.resize_images(x_smalls, (height, width),tf.</span><br><span class="line">image.ResizeMethod.NEAREST_NEIGHBOR)</span><br><span class="line"> x_bilins = tf.image.resize_images(x_smalls, (height, width),tf.</span><br><span class="line">image.ResizeMethod.BILINEAR)</span><br><span class="line"> x_bicubics = tf.image.resize_images(x_smalls, (height, width),tf.</span><br><span class="line">image.ResizeMethod.BICUBIC)</span><br></pre></td></tr></table></figure>

</details>

<p>先通过resize_images创建一个低分辩率图片x_smalls，然后将x_smalls通过不同算法的变化，生成对应的高分辨率图片。</p>
<p>3．建立ESPCN网络结构</p>
<p>网络结构与上例一样，不同的是输入的图片做了归一化处理，统一除以255，使其变为0～1之间的数。最后一个卷积成输出的为12通道，代表2×2的缩放比例，一共3个通道，所以再乘以3。另外，各层均使用了Tanh函数，最后一层没有使用激活函数。</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">net = slim.conv2d(x_smalls2, 64, 5,activation_fn = tf.nn.tanh)</span><br><span class="line">net =slim.conv2d(net, 32, 3,activation_fn = tf.nn.tanh)</span><br><span class="line">net = slim.conv2d(net, 12, 3,activation_fn = None)#2*2*3</span><br><span class="line">y_predt = tf.depth_to_space(net,2)</span><br><span class="line"></span><br><span class="line">y_pred = y_predt*255.0</span><br><span class="line">y_pred = tf.maximum(y_pred,0)</span><br><span class="line">y_pred = tf.minimum(y_pred,255)</span><br><span class="line"></span><br><span class="line">dbatch=tf.concat([tf.cast(images,tf.float32),y_pred],0)</span><br></pre></td></tr></table></figure>

</details>

<p>y_pred是由y_predt转化而来的，通过tf.maximum 与tf.minimum函数将内部的值都变为 0～255之间的数字。y_predt会参与损失值的计算。</p>
<p>dbatch是将生成的y_pred与images按照批次的维度合并起来，该张量是为了后面进行图片质量评估使用的。</p>
<p><img src="Image00014.jpg" alt> 注意： 上面例子中y_pred进行了最大值和最小值的规整处理，这是个很常用的技巧。如果不处理，那么生成的图片会在显示时看到有亮点，使图片显得不清晰。读者可以试着将这段代码去掉，看看效果。</p>
<p>4．构建loss及优化器</p>
<p>对于全彩色训练的学习率设定还是需要非常小心的，在这里设置为0.000001，让其缓慢地变化。由于输入的样本归一化了，所以计算loss时的images也需要归一化。代码如下：</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost = tf.reduce_mean(tf.pow( tf.cast(images,tf.float32)/255.0  -y_predt, 2))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(0.000001 ).minimize(cost)</span><br></pre></td></tr></table></figure>

</details>

<p>5．建立session，运行</p>
<p>启动session，运行15 0000次。代码如下：</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">training_epochs =150000</span><br><span class="line">display_step =200</span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">#启动队列</span><br><span class="line">tf.train.start_queue_runners(sess=sess)</span><br><span class="line"></span><br><span class="line"># 启动循环开始训练</span><br><span class="line">for epoch in range(training_epochs):</span><br><span class="line">    </span><br><span class="line">    _, c = sess.run([optimizer, cost])</span><br><span class="line">    # 显示训练中的详细信息</span><br><span class="line">    if epoch % display_step == 0:</span><br><span class="line">        d_batch=dbatch.eval()</span><br><span class="line">        mse,psnr=batch_mse_psnr(d_batch)</span><br><span class="line">        ypsnr=batch_y_psnr(d_batch)</span><br><span class="line">        ssim=batch_ssim(d_batch)</span><br><span class="line">        print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),</span><br><span class="line">              &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.format(c),&quot;psnr&quot;,psnr,&quot;ypsnr&quot;,ypsnr,&quot;ssim&quot;,ssim)</span><br><span class="line"></span><br><span class="line">print(&quot;完成!&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>在显示评估结果时，使用batch_mse_psnr、batch_y_psnr和batch_ssim这3个函数分别对节点dbatch的值进行运算，得到图片的质量评估值。</p>
<p>6．构建图片质量评估函数</p>
<p>SR图片质量有其自己的一套评估质量算法：常用的两个指标是PSNR（Peak Signal-to-Noise Ratio）和SSIM（Structure Similarity Index）。这两个值越高，代表重建结果的像素值和标准越接近。对于PSNR的计算有两个方法：</p>
<p>·基于R、G、B，分别计算三通道中的MSE值再求平均值，然后再将结果代入求PSNR。</p>
<p>·基于YUV，求图像YUV空间中的Y分量，计算Y分量的PSNR值。</p>
<p>对于YUV的介绍如下：</p>
<p>YUV（亦称YCrCb）是另一种颜色编码方法，常被欧洲电视系统所采用。Y代表亮度信号，U（R-Y）与V（B-Y）分别代表两个色差信号。在没有U和V时，就会表现为只有亮度的黑白色，彩色电视采用YUV空间正是为了用亮度信号Y解决彩色电视机与黑白电视机的兼容问题，使黑白电视机也能接收彩色电视信号。</p>
<p>YUV和RGB互相转换的公式如下（RGB取值范围均为0～255）：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y = 0.299R + 0.587G + 0.114B</span><br><span class="line">U = -0.147R-0.289G + 0.436B</span><br><span class="line">V = 0.615R-0.515G-0.100B</span><br><span class="line">R = Y + 1.14V</span><br><span class="line">G = Y-0.39U -0.58V</span><br><span class="line">B = Y + 2.03U</span><br></pre></td></tr></table></figure>

</details>

<p>将这3个指标用代码实现如下。</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def batch_mse_psnr(dbatch):</span><br><span class="line">    im1,im2=np.split(dbatch,2)</span><br><span class="line">    mse=((im1-im2)**2).mean(axis=(1,2))</span><br><span class="line">    psnr=np.mean(20*np.log10(255.0/np.sqrt(mse)))</span><br><span class="line">    return np.mean(mse),psnr</span><br><span class="line">def batch_y_psnr(dbatch):</span><br><span class="line">    r,g,b=np.split(dbatch,3,axis=3)</span><br><span class="line">    y=np.squeeze(0.3*r+0.59*g+0.11*b)</span><br><span class="line">    im1,im2=np.split(y,2)</span><br><span class="line">    mse=((im1-im2)**2).mean(axis=(1,2))</span><br><span class="line">    psnr=np.mean(20*np.log10(255.0/np.sqrt(mse)))</span><br><span class="line">    return psnr</span><br><span class="line">def batch_ssim(dbatch):</span><br><span class="line">    im1,im2=np.split(dbatch,2)</span><br><span class="line">    imgsize=im1.shape[1]*im1.shape[2]</span><br><span class="line">    avg1=im1.mean((1,2),keepdims=1)</span><br><span class="line">    avg2=im2.mean((1,2),keepdims=1)</span><br><span class="line">    std1=im1.std((1,2),ddof=1)</span><br><span class="line">    std2=im2.std((1,2),ddof=1)</span><br><span class="line">    cov=((im1-avg1)*(im2-avg2)).mean((1,2))*imgsize/(imgsize-1)</span><br><span class="line">    avg1=np.squeeze(avg1)</span><br><span class="line">    avg2=np.squeeze(avg2)</span><br><span class="line">    k1=0.01</span><br><span class="line">    k2=0.03</span><br><span class="line">    c1=(k1*255)**2</span><br><span class="line">    c2=(k2*255)**2</span><br><span class="line">    c3=c2/2</span><br><span class="line">    return np.mean((2*avg1*avg2+c1)*2*(cov+c3)/(avg1**2+avg2**2+c1)/</span><br><span class="line">   (std1**2+std2**2+c2))</span><br></pre></td></tr></table></figure>

</details>

<p>7．图示结果</p>
<p>与前面例子类似，将原始图片与函数变化的图片及模型输出的图片一并显示。这里先定义一个函数用来统一显示。</p>
<p><img src="Image00014.jpg" alt> 注意： 必须要将其转化为UINT8的形式，否则图片会显示不出来。</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def showresult(subplot,title,orgimg,thisimg,dopsnr = True):</span><br><span class="line">    p =plt.subplot(subplot)</span><br><span class="line">    p.axis(&apos;off&apos;) </span><br><span class="line">    p.imshow(np.asarray(thisimg[0], dtype=&apos;uint8&apos;))</span><br><span class="line">    if dopsnr :</span><br><span class="line">        conimg =  np.concatenate((orgimg,thisimg))</span><br><span class="line">        mse,psnr=batch_mse_psnr(conimg)</span><br><span class="line">        ypsnr=batch_y_psnr(conimg)</span><br><span class="line">        ssim=batch_ssim(conimg)</span><br><span class="line">        p.set_title(title+str(int(psnr))+&quot; y:&quot;+str(int(ypsnr))+&quot; </span><br><span class="line">       s:&quot;+str(ssim))</span><br><span class="line">    else:</span><br><span class="line">        p.set_title(title)</span><br></pre></td></tr></table></figure>

</details>

<p>接着取一批次的图片放入模型，调用Showresult函数将生成的结果及评分值全部显示出来。</p>
<p>代码12-7 tfrecoderSRESPCN（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> imagesv, label_batch,x_smallv,x_nearestv,x_bilinv,x_bicubicv,y_predv </span><br><span class="line">= sess.run([images, labels,x_smalls,x_nearests,x_bilins,x_bicubics,</span><br><span class="line">y_pred])</span><br><span class="line"> print(&quot;原&quot;,np.shape(imagesv),&quot;缩放后的&quot;,np.shape(x_smallv),label_batch)</span><br><span class="line"> </span><br><span class="line"> #显示</span><br><span class="line"> plt.figure(figsize=(20,10))  </span><br><span class="line"> </span><br><span class="line"> showresult(161,&quot;org&quot;,imagesv,imagesv,False)</span><br><span class="line"> showresult(162,&quot;small/4&quot;,imagesv,x_smallv,False)</span><br><span class="line"> showresult(163,&quot;near&quot;,imagesv,x_nearestv)</span><br><span class="line"> showresult(164,&quot;biline&quot;,imagesv,x_bilinv)</span><br><span class="line"> showresult(165,&quot;bicubicv&quot;,imagesv,x_bicubicv)</span><br><span class="line"> showresult(166,&quot;pred&quot;,imagesv,y_predv)</span><br><span class="line">     </span><br><span class="line"> plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，输出如下，输出图片如图12-14所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Epoch: 144801 cost= 0.003637410 psnr 23.8877 ypsnr 24.0189 ssim 0.96434</span><br><span class="line">Epoch: 145001 cost= 0.008538806 psnr 25.0453 ypsnr 25.3529 ssim 0.91564</span><br><span class="line">Epoch: 145201 cost= 0.005899625 psnr 28.1946 ypsnr 29.1575 ssim 0.975755</span><br><span class="line">Epoch: 145401 cost= 0.002309756 psnr 25.6251 ypsnr 25.5808 ssim 0.95208</span><br><span class="line">Epoch: 145601 cost= 0.004211991 psnr 25.2114 ypsnr 25.2179 ssim 0.947036</span><br><span class="line">Epoch: 145801 cost= 0.002519545 psnr 27.9464 ypsnr 28.9226 ssim 0.973354</span><br><span class="line">Epoch: 146001 cost= 0.005268521 psnr 20.8838 ypsnr 20.7228 ssim 0.9175</span><br><span class="line">Epoch: 146201 cost= 0.002536027 psnr 23.988 ypsnr 24.3302 ssim 0.934929</span><br><span class="line">Epoch: 146401 cost= 0.003322446 psnr 28.2296 ypsnr 29.4929 ssim 0.908311</span><br><span class="line">Epoch: 146601 cost= 0.007955125 psnr 25.5261 ypsnr 26.271 ssim 0.948738</span><br><span class="line">Epoch: 146801 cost= 0.002779651 psnr 29.1436 ypsnr 30.8613 ssim 0.983795</span><br><span class="line">Epoch: 147001 cost= 0.005602385 psnr 24.6309 ypsnr 25.1222 ssim 0.920429</span><br><span class="line">Epoch: 147201 cost= 0.004883423 psnr 25.3241 ypsnr 25.7193 ssim 0.964581</span><br><span class="line">Epoch: 147401 cost= 0.005192784 psnr 26.5626 ypsnr 26.9226 ssim 0.952263</span><br><span class="line">Epoch: 147601 cost= 0.006907145 psnr 27.7884 ypsnr 28.4125 ssim 0.96983</span><br><span class="line">Epoch: 147801 cost= 0.008132000 psnr 26.7713 ypsnr 27.9356 ssim 0.976656</span><br><span class="line">Epoch: 148001 cost= 0.008132160 psnr 24.6795 ypsnr 26.011 ssim 0.96252</span><br><span class="line">Epoch: 148201 cost= 0.003620633 psnr 24.5258 ypsnr 24.9886 ssim 0.943705</span><br><span class="line">Epoch: 148401 cost= 0.008644918 psnr 21.6561 ypsnr 21.704 ssim 0.90348</span><br><span class="line">Epoch: 148601 cost= 0.003554154 psnr 25.849 ypsnr 25.9136 ssim 0.97194</span><br><span class="line">Epoch: 148801 cost= 0.003299494 psnr 23.6707 ypsnr 24.2183 ssim 0.959333</span><br><span class="line">Epoch: 149001 cost= 0.003197462 psnr 23.7814 ypsnr 24.1327 ssim 0.913214</span><br><span class="line">Epoch: 149201 cost= 0.001375712 psnr 26.5407 ypsnr 26.7266 ssim 0.957788</span><br><span class="line">Epoch: 149401 cost= 0.003641539 psnr 25.5488 ypsnr 26.2268 ssim 0.925159</span><br><span class="line">Epoch: 149601 cost= 0.003025041 psnr 25.2158 ypsnr 25.65 ssim 0.969086</span><br><span class="line">Epoch: 149801 cost= 0.001514586 psnr 27.9188 ypsnr 28.6265 ssim 0.976076</span><br><span class="line">完成!</span><br><span class="line">原 (4, 200, 200, 3) 缩放后的 (4, 100, 100, 3) [3 0 0 1]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00278.jpg" alt></p>
<p>图12-14 ESPCN实例flowers结果</p>
<p>结果可见，使用ESPCN可以实现很好的SR效果。</p>
<p>本例仅将图片分辨率放大了2倍，而且与BILINEAR的比较优势不大，但没关系，下面就来演示一个更明显的例子，通过进一步优化网络将图片分辨率放大4倍。</p>
<h4 id="12-8-4-实例95：使用残差网络的ESPCN"><a href="#12-8-4-实例95：使用残差网络的ESPCN" class="headerlink" title="12.8.4 实例95：使用残差网络的ESPCN"></a>12.8.4 实例95：使用残差网络的ESPCN</h4><p>在实例94中ESPCN与BILINEAR的结果比较优势没有那么明显，这是因为普通算法在仅仅放大两倍的图片处理上是很优秀的，另一个原因也是由于例子中的网络结构过于简单（仅三层）。下面通过对实例94的网络结构优化，实现在分辨率放大4倍任务上的图片重建。</p>
<p>实例描述</p>
<p>将flower数据集中的图片转成低分辨率，再通过使用带残差网络的ESPCN网络复原成高分辨率图片，并与其他复原函数的生成结果进行比较。</p>
<p>具体实现步骤如下。</p>
<p>1．修改输入图片分辨率</p>
<p>在代码“12-7 tfrecoderSRESPCN.py”的基础上进行修改，将原来的输入尺寸由长宽各缩小一半变为长宽各缩小为原来的1/4。</p>
<p>代码12-8 resESPCN</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> images, labels = tf.train.batch([distorted_image, label], batch_</span><br><span class="line">size=batch_size)</span><br><span class="line"> print(images.shape)</span><br><span class="line"> </span><br><span class="line"> x_smalls = tf.image.resize_images(images, (np.int32(height/4), np.</span><br><span class="line">int32(width/4)))#  尺寸变为原来的1/16</span><br><span class="line"> x_smalls2 = x_smalls/255.0</span><br><span class="line"> ……</span><br></pre></td></tr></table></figure>

</details>

<p>2．添加残差网络</p>
<p>添加两个函数，一个是leaky_relu为leaky relu激活函数，另一个是用于生成网络残差块的函数residual_block，实现一个中间有两层卷积的残差块。接着在整个网络构造中，通过一个卷积层与一个残差层完成图像特征的转换。残差层是由16个残差块与一个卷积层组成的网络。特征转换之后再通过5层神经网络完成最终的特征修复处理过程，如图12-15所示。</p>
<p><img src="Image00279.jpg" alt></p>
<p>图12-15 ResESPCN例子结构</p>
<p>图12-15中，最下面的5层为修复特征数据，第1层是一个卷积层，第2层会按照2×2大小的像素块将第一层的结果展开，第3层与第1层一样，第4层与第2层一样，第5层也是个卷积层。连续2次变换进行放大4倍的处理，最终通过输出3通道的卷积生成最终修复图片。</p>
<p>代码12-8 resESPCN （续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"> def leaky_relu(x,alpha=0.1,name=&apos;lrelu&apos;):</span><br><span class="line">      with tf.name_scope(name):</span><br><span class="line">          x=tf.maximum(x,alpha*x)</span><br><span class="line">          return x</span><br><span class="line"> def residual_block(nn,i,name=&apos;resblock&apos;):</span><br><span class="line">     with tf.variable_scope(name+str(i)):</span><br><span class="line">         conv1=slim.conv2d(nn, 64, 3,activation_fn = leaky_relu,</span><br><span class="line">        normalizer_fn=slim.batch_norm)</span><br><span class="line">         conv2=slim.conv2d(conv1, 64, 3,activation_fn = leaky_relu,</span><br><span class="line">        normalizer_fn=slim.batch_norm)</span><br><span class="line">         return tf.add(nn,conv2)</span><br><span class="line"> </span><br><span class="line"> net = slim.conv2d(x_smalls2, 64, 5,activation_fn = leaky_relu)</span><br><span class="line"> block=[]</span><br><span class="line"> for i in range(16):</span><br><span class="line">     block.append(residual_block(block[-1] if i else net,i))</span><br><span class="line"> conv2=slim.conv2d(block[-1], 64, 3,activation_fn = leaky_relu,</span><br><span class="line">normalizer_fn=slim.batch_norm)</span><br><span class="line"> sum1=tf.add(conv2,net)</span><br><span class="line"> </span><br><span class="line"> conv3=slim.conv2d(sum1, 256, 3,activation_fn = None)</span><br><span class="line"> ps1=tf.depth_to_space(conv3,2) </span><br><span class="line"> relu2=leaky_relu(ps1)</span><br><span class="line"> conv4=slim.conv2d(relu2, 256, 3,activation_fn = None)</span><br><span class="line"> ps2=tf.depth_to_space(conv4,2) #再放大两倍 </span><br><span class="line"> relu3=leaky_relu(ps2)</span><br><span class="line"> y_predt=slim.conv2d(relu3, 3, 3,activation_fn = None) #输出</span><br></pre></td></tr></table></figure>

</details>

<p>3．修改学习率，进行网络训练</p>
<p>将学习率改为0.001，同样使用AdamOptimizer优化方法，循环迭代100 000次开始训练。</p>
<p>代码12-8 resESPCN （续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> learn_rate =0.001</span><br><span class="line"> </span><br><span class="line"> cost = tf.reduce_mean(tf.pow( tf.cast(images,tf.float32)/255.0  -</span><br><span class="line">y_predt, 2))</span><br><span class="line"> optimizer = tf.train.AdamOptimizer(learn_rate ).minimize(cost)</span><br><span class="line"> training_epochs =10000</span><br></pre></td></tr></table></figure>

</details>

<p>4．添加检测点</p>
<p>网络结构的修改会使单次训练的时间变长，因此有必要添加检查点文件保存功能。先对变量flags赋值定义检查点保存的路径，在session中读取到检查点文件后解析出运行的迭代次数。在range中设置起始次数，让其继续训练。</p>
<p>代码12-8 resESPCN （续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> ……</span><br><span class="line"> flags=&apos;b&apos;+str(batch_size)+&apos;_h&apos;+str(height/4)+&apos;_r&apos;+str(learn_</span><br><span class="line">rate)+&apos;_res&apos; </span><br><span class="line"> if not os.path.exists(&apos;save&apos;):</span><br><span class="line">     os.mkdir(&apos;save&apos;)</span><br><span class="line"> save_path=&apos;save/tf_&apos;+flags</span><br><span class="line"> if not os.path.exists(save_path):</span><br><span class="line">     os.mkdir(save_path)</span><br><span class="line"> saver = tf.train.Saver(max_to_keep=1) # 生成saver</span><br><span class="line"> </span><br><span class="line"> sess = tf.InteractiveSession()</span><br><span class="line"> sess.run(tf.global_variables_initializer())</span><br><span class="line"> </span><br><span class="line"> kpt = tf.train.latest_checkpoint(save_path)</span><br><span class="line"> print(kpt)</span><br><span class="line"> startepo= 0</span><br><span class="line"> if kpt!=None:</span><br><span class="line">     saver.restore(sess, kpt) </span><br><span class="line">     ind = kpt.find(&quot;-&quot;)</span><br><span class="line">     startepo = int(kpt[ind+1:])</span><br><span class="line">     print(&quot;startepo=&quot;,startepo)</span><br><span class="line"> </span><br><span class="line"> #启动队列</span><br><span class="line"> tf.train.start_queue_runners(sess=sess)</span><br><span class="line"> </span><br><span class="line"> # 启动循环开始训练</span><br><span class="line"> for epoch in range(startepo,training_epochs):</span><br><span class="line"> ……</span><br><span class="line">         print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),</span><br><span class="line">               &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.format(c),&quot;psnr&quot;,psnr,&quot;ypsnr&quot;,ypsnr,&quot;ssim&quot;,ssim)</span><br><span class="line"> </span><br><span class="line">         saver.save(sess, save_path+&quot;/tfrecord.cpkt&quot;, global_</span><br><span class="line">        step=epoch)</span><br><span class="line"> print(&quot;完成!&quot;)</span><br><span class="line"> saver.save(sess, save_path+&quot;/tfrecord.cpkt&quot;, global_step=epoch)</span><br></pre></td></tr></table></figure>

</details>

<p>在迭代指定次数后保存检查点，并且在全部训练结束后保存检查点文件。</p>
<p>运行整个代码生成结果如下，输出图片如图12-16所示。</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">Epoch: 4801 cost= 0.003252075 psnr 24.5383 ypsnr 25.332 ssim 0.956795592532</span><br><span class="line">Epoch: 5201 cost= 0.002841802 psnr 26.1108 ypsnr 26.599 ssim 0.959523112064</span><br><span class="line">Epoch: 5601 cost= 0.004468028 psnr 25.7363 ypsnr 26.3008 ssim 0.96185231328</span><br><span class="line">Epoch: 6001 cost= 0.004859785 psnr 26.1274 ypsnr 26.7174 ssim 0.962346682679</span><br><span class="line">Epoch: 6401 cost= 0.004147850 psnr 25.9059 ypsnr 26.7208 ssim 0.969348364467</span><br><span class="line">Epoch: 6801 cost= 0.003628785 psnr 25.7018 ypsnr 26.4992 ssim 0.966612183827</span><br><span class="line">Epoch: 7201 cost= 0.002464779 psnr 23.9676 ypsnr 24.4634 ssim 0.953078157091</span><br><span class="line">Epoch: 7601 cost= 0.003710205 psnr 24.7987 ypsnr 25.4836 ssim 0.953239908046</span><br><span class="line">Epoch: 8001 cost= 0.002421107 psnr 27.0966 ypsnr 28.1542 ssim 0.958096604393</span><br><span class="line">Epoch: 8401 cost= 0.003401657 psnr 25.6712 ypsnr 26.4028 ssim 0.958035056742</span><br><span class="line">Epoch: 8801 cost= 0.003299317 psnr 26.5742 ypsnr 27.1549 ssim 0.95990466244</span><br><span class="line">Epoch: 9201 cost= 0.002930838 psnr 26.4124 ypsnr 26.9374 ssim 0.958304362037</span><br><span class="line">Epoch: 9601 cost= 0.003253016 psnr 25.8007 ypsnr 26.2591 ssim 0.975577563284</span><br><span class="line">完成!</span><br><span class="line">原 (16,256,256,3)缩放后的(16,64,64,3)[0 2 4 1 0 4 1 3 0 0 1 1 3 1 0 2]</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00280.jpg" alt></p>
<p>图12-16 resESPCN例子结果</p>
<p>图12-16中最后一幅图为模型生成的图片。放大4倍后可以看到，直接使用resize_ images生成的图片已经得不到很好的效果，但是通过模型生成的图片却有着同样高质量的清晰度。</p>
<p><img src="Image00014.jpg" alt> 注意： 在构建相对较大型复杂网络结构（类似该例子的结构）进行训练时，检查点的设置是必须的，常常是运行一段，调节下参数，观察效果，然后再运行，再调节参数，再观察效果。这里有个技巧：如本例中将结构中的参数组成flags用于对检查点目录动态命名，这么做可以在调节参数时不用再额外考虑修改路径的问题，同时又能为不同参数对应的模型留下清晰的备份，便于比较。</p>
<p>5．练习题</p>
<p>想一想，图12-16中从左向右的方向上，倒数第二幅图片为什么会如此显示？有什么办法能让其正常显示？</p>
<p>答案在12.8.3节中第3个小节的“注意”事项里，读者可以参考对应的代码完成该功能。</p>
<h4 id="12-8-5-SRGAN的原理"><a href="#12-8-5-SRGAN的原理" class="headerlink" title="12.8.5 SRGAN的原理"></a>12.8.5 SRGAN的原理</h4><p>在图像放大4倍以上时，前面所介绍的方法得到的结果显得过于平滑，而缺少一些细节上的真实感。这是因为，传统方法使用的代价函数是基于像素点的最小均方差（MSE），该代价函数使重建结果有较高的信噪比，但是缺少了高频信息，所以会出现过度平滑的纹理。</p>
<p>SRGAN的思想是，使重建的高分辨率图像与真实的高分辨率图像，无论是低层次的像素值还是高层次的抽象特征及整体概念及风格上，都应当接近。</p>
<p>其中，对整体概念和风格的评估可以使用一个判别器，判断一幅高分辨率图像是由算法生成的还是真实的图像。如果一个判别器无法区分出来，那么由算法生成的图像就达到了对超分辨率修复成功的效果。</p>
<p>输入图片自身内容方面的损失值与来自对抗神经网络的损失值一起组成了最终的损失值（loss）。而对于自己的内容方面，基于像素点的平方差是一部分，另一部分是基于特征空间的平方差。基于特征空间特征的提取使用了VGG网络。</p>
<h4 id="12-8-6-实例96：使用SRGAN实现flowers数据集的超分辨率修复"><a href="#12-8-6-实例96：使用SRGAN实现flowers数据集的超分辨率修复" class="headerlink" title="12.8.6 实例96：使用SRGAN实现flowers数据集的超分辨率修复"></a>12.8.6 实例96：使用SRGAN实现flowers数据集的超分辨率修复</h4><p>本例中用SRGAN在有基于残差网络的ESPCN上面进行SR处理，观察它能带给我们怎样的效果。由于在计算生成器loss中的一部分需要使用VGG网络来提取特征，因此本例会用到第11章中的VGG19预训练模型。为了方便训练，这里直接使用了前面训练好的残差网络ESPCN网络模型作为生成器，用其生成的图片作为判别器的输入，通过GAN的机制进行二次优化。</p>
<p>实例描述</p>
<p>将flower数据集中的图片转为低分辨率，通过使用SRGAN网络将其还原成高分辨率，并与其他复原函数的生成结果进行比较。</p>
<p>具体实现步骤如下。</p>
<p>1．引入头文件，图片预处理</p>
<p>在代码“12-8 resESPCN.py”基础上进行修改，引入slim中VGG网络头文件。样本部分与前面一样，只是增加了一个对输入的图片做归一化处理。</p>
<p>代码12-9 rsgan</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> import tensorflow as tf</span><br><span class="line"> import time</span><br><span class="line"> import os </span><br><span class="line"> import numpy as np</span><br><span class="line"> import matplotlib.pyplot as plt</span><br><span class="line"> from nets import vgg</span><br><span class="line"> ……</span><br><span class="line"> </span><br><span class="line"> images, labels = tf.train.batch([distorted_image, label], batch_</span><br><span class="line">size=batch_size)</span><br><span class="line"> print(images.shape)</span><br><span class="line"> </span><br><span class="line"> images = tf.cast(images,tf.float32)</span><br><span class="line"> x_smalls=tf.image.resize_bicubic(images,[np.int32(height/4), np.</span><br><span class="line">int32(width/4)]) #  变为原来的1/16</span><br><span class="line"> x_smalls2 = x_smalls/127.5-1 #将输入样本进行归一化处理</span><br></pre></td></tr></table></figure>

</details>

<p>由于图片中每个像素都在0～255之间，所以除以255/2之后就会变为0～2之间的值，再减去1，就得到了x_smalls2。</p>
<p>2．构建生成器</p>
<p>为了可以重用代码“12-8 resESPCN.py”中的模型，生成器的代码要与代码“12-8 resESPCN.py”保持一致，这里直接复制到gen函数中。</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def gen(x_smalls2 ):</span><br><span class="line">    net = slim.conv2d(x_smalls2, 64, 5,activation_fn = leaky_relu)</span><br><span class="line">    block=[]</span><br><span class="line">    for i in range(16):</span><br><span class="line">        block.append(residual_block(block[-1] if i else net,i))</span><br><span class="line">    conv2=slim.conv2d(block[-1], 64, 3,activation_fn = leaky_relu,</span><br><span class="line">   normalizer_fn=slim.batch_norm)</span><br><span class="line">    sum1=tf.add(conv2,net)</span><br><span class="line">    </span><br><span class="line">    conv3=slim.conv2d(sum1, 256, 3,activation_fn = None)</span><br><span class="line">    ps1=tf.depth_to_space(conv3,2) </span><br><span class="line">    relu2=leaky_relu(ps1)</span><br><span class="line">    conv4=slim.conv2d(relu2, 256, 3,activation_fn = None)</span><br><span class="line">    ps2=tf.depth_to_space(conv4,2) #再放大两倍</span><br><span class="line">    relu3=leaky_relu(ps2)</span><br><span class="line">    y_predt=slim.conv2d(relu3, 3, 3,activation_fn = None) #输出</span><br><span class="line">    return y_predt</span><br></pre></td></tr></table></figure>

</details>

<p>3．VGG的预输入处理</p>
<p>为了得到生成器基于内容的loss，要将生成的图片与真实图片分别输入VGG网络以获得它们的特征，然后在特征空间上计算loss。所以先将低分辨率图片作为输入放进生成器gen函数中，得到生成图片resnetimg，并将图片还原成0～255区间的正常像素值。同时准备好生成器的训练参数gen_var_list为后面优化器使用做准备。</p>
<p><img src="Image00014.jpg" alt> 注意： 本例使用了一个新方法来提取已有模型的参数：①在生成器定义好后，获取一次图（运算任务）中的所有变量；②将已有模型载入判别器后，再获取一次图（运算任务）中的所有变量。由于两次执行的时间不一样，第一次得到的仅仅是生成器gen的变量，而第二次得到的是gen和判别器的变量总和，所以从变量总和中去掉第一次的变量剩下的就是判别器的变量。这么做的目的是为了再次使用前面例子里已经训练好的模型。</p>
<p>使用VGG模型时，必须在输入之前对图片做RGB均值的预处理。先定义处理RGB均值的函数，然后做具体变换。</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def rgbmeanfun(rgb):</span><br><span class="line">    _R_MEAN = 123.68</span><br><span class="line">    _G_MEAN = 116.78</span><br><span class="line">    _B_MEAN = 103.94</span><br><span class="line">    print(&quot;build model started&quot;)</span><br><span class="line">    # 将 RGB 转化成BGR</span><br><span class="line">    red, green, blue = tf.split(axis=3, num_or_size_splits=3, </span><br><span class="line">   value=rgb)</span><br><span class="line">    rgbmean = tf.concat(axis=3, values=[red -_R_MEAN,green -_G_MEAN, </span><br><span class="line">   blue -_B_MEAN,])</span><br><span class="line">    return rgbmean</span><br><span class="line">    </span><br><span class="line">resnetimg=gen(x_smalls2)</span><br><span class="line">result=(resnetimg+1)*127.5</span><br><span class="line">gen_var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)</span><br><span class="line"></span><br><span class="line">y_pred = tf.maximum(result,0)</span><br><span class="line">y_pred = tf.minimum(y_pred,255)</span><br><span class="line"></span><br><span class="line">dbatch=tf.concat([images,result],0)</span><br><span class="line">rgbmean = rgbmeanfun(dbatch)</span><br></pre></td></tr></table></figure>

</details>

<p>RGB的处理与第11章中一样。具体的细节可以回看第11章的内容。</p>
<p><img src="Image00014.jpg" alt> 注意： 这里将生成的图片与真实的图片通过维度为0的concat组合在一起处理。这是一个编写代码的小技巧。因为真实图片与生成的图片其处理过程是一样的（都要经过预处理，然后放到判别器中），所以就一起打包，这相当于两个batch的数据进行处理然后塞进判别式中，得到结果后再按照打包的先后顺序将它们分开即可。这种做法只用一套代码就可以完成真实图片和生成图片的处理。</p>
<p>4．计算VGG特征空间的loss</p>
<p>VGG中的前5个卷积层用于特征提取，所以在使用时，只取其第5个卷积层的输出节点，其他的节点可以全部忽略。那么问题来了，如何能拿到模型中的指定节点呢？可以通过slim中nets文件夹下对应的VGG源码找到对应节点的名称。这里使用了一个更简单的方法：直接在models\slim\nets文件夹下打开“vgg_test.py”文件，在第50行中可以找到testEndPoints函数，其内容如下：</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">……</span><br><span class="line">def testEndPoints(self):</span><br><span class="line">    batch_size = 5</span><br><span class="line">    height, width = 224, 224</span><br><span class="line">    num_classes = 1000</span><br><span class="line">    with self.test_session():</span><br><span class="line">      inputs = tf.random_uniform((batch_size,height, width, 3))</span><br><span class="line">      _, end_points = vgg.vgg_19(inputs, num_classes)</span><br><span class="line">      expected_names = [</span><br><span class="line">          &apos;vgg_19/conv1/conv1_1&apos;,</span><br><span class="line">          &apos;vgg_19/conv1/conv1_2&apos;,</span><br><span class="line">          &apos;vgg_19/pool1&apos;,</span><br><span class="line">          &apos;vgg_19/conv2/conv2_1&apos;,</span><br><span class="line">          &apos;vgg_19/conv2/conv2_2&apos;,</span><br><span class="line">          &apos;vgg_19/pool2&apos;,</span><br><span class="line">          &apos;vgg_19/conv3/conv3_1&apos;,</span><br><span class="line">          &apos;vgg_19/conv3/conv3_2&apos;,</span><br><span class="line">          &apos;vgg_19/conv3/conv3_3&apos;,</span><br><span class="line">          &apos;vgg_19/conv3/conv3_4&apos;,</span><br><span class="line">          &apos;vgg_19/pool3&apos;,</span><br><span class="line">          &apos;vgg_19/conv4/conv4_1&apos;,</span><br><span class="line">          &apos;vgg_19/conv4/conv4_2&apos;,</span><br><span class="line">          &apos;vgg_19/conv4/conv4_3&apos;,</span><br><span class="line">          &apos;vgg_19/conv4/conv4_4&apos;,</span><br><span class="line">          &apos;vgg_19/pool4&apos;,</span><br><span class="line">          &apos;vgg_19/conv5/conv5_1&apos;,</span><br><span class="line">          &apos;vgg_19/conv5/conv5_2&apos;,</span><br><span class="line">          &apos;vgg_19/conv5/conv5_3&apos;,</span><br><span class="line">          &apos;vgg_19/conv5/conv5_4&apos;,</span><br><span class="line">          &apos;vgg_19/pool5&apos;,</span><br><span class="line">          &apos;vgg_19/fc6&apos;,</span><br><span class="line">          &apos;vgg_19/fc7&apos;,</span><br><span class="line">          &apos;vgg_19/fc8&apos;</span><br><span class="line">      ]</span><br><span class="line">      self.assertSetEqual(set(end_points.keys()), set(expected_names))</span><br></pre></td></tr></table></figure>

</details>

<p>这是一个单元测试函数，里面列举了VGG19网络结构中所有的节点名称。如上代码’vgg_19/conv5/conv5_4’ 就是本例中想要的节点，直接将该字符串复制放到本例代码中，如下所示。</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> #vgg 特征值</span><br><span class="line"> _, end_points = vgg.vgg_19(rgbmean, num_classes=1000,is_training=</span><br><span class="line">False,spatial_squeeze=False)</span><br><span class="line"> conv54=end_points[&apos;vgg_19/conv5/conv5_4&apos;]</span><br><span class="line"> print(&quot;vgg.conv5_4&quot;,conv54.shape)</span><br><span class="line"> fmap=tf.split(conv54,2)</span><br><span class="line"> </span><br><span class="line"> content_loss=tf.losses.mean_squared_error(fmap[0],fmap[1])</span><br></pre></td></tr></table></figure>

</details>

<p>由于前面通过concat将两个图片放一起来处理，得到结果后，还要使用split将其分开，接着通过平方差算出基于特征空间的loss。</p>
<p>5．判别器的构建</p>
<p>判别器主要是通过一系列卷积层组合起来所构成的，最终使用两个全连接层实现映射到一维的输出结果。具体函数实现如下：</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def Discriminator(dbatch, name =&quot;Discriminator&quot;):</span><br><span class="line">    with tf.variable_scope(name):</span><br><span class="line">        net = slim.conv2d(dbatch, 64, 1,activation_fn = leaky_relu)</span><br><span class="line"></span><br><span class="line">        ochannels=[64,128,128,256,256,512,512]</span><br><span class="line">        stride=[2,1]</span><br><span class="line"></span><br><span class="line">        for i in range(7):</span><br><span class="line">            net = slim.conv2d(net, ochannels[i], 3,stride = stride</span><br><span class="line">           [i%2],activation_fn = leaky_relu,normalizer_fn=slim.</span><br><span class="line">           batch_norm,scope=&apos;block&apos;+str(i))</span><br><span class="line"></span><br><span class="line">        dense1 = slim.fully_connected(net, 1024, activation_</span><br><span class="line">       fn=leaky_relu)</span><br><span class="line">        dense2 = slim.fully_connected(dense1, 1, activation_</span><br><span class="line">       fn=tf.nn.sigmoid)</span><br><span class="line">        </span><br><span class="line">        return dense2</span><br></pre></td></tr></table></figure>

</details>

<p>6．计算loss，定义优化器</p>
<p>将判别器的结果裁开，分别得到真实图片与生成图片判别的结果，以LSGAN的方式计算生成器与判别器的loss，在生成器loss中加入基于特征空间的loss。按照前面第3步中所讲的训练参数的获取方式获得判别器训练参数disc_var_list，使用AdamOptimizer优化loss值。代码如下：</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"> disc=Discriminator(dbatch)</span><br><span class="line"> D_x,D_G_z=tf.split(tf.squeeze(disc),2)   </span><br><span class="line"> </span><br><span class="line">   </span><br><span class="line"> adv_loss=tf.reduce_mean(tf.square(D_G_z-1.0))</span><br><span class="line"> </span><br><span class="line"> gen_loss=(adv_loss+content_loss)</span><br><span class="line"> disc_loss=(tf.reduce_mean(tf.square(D_x-1.0)+tf.square(D_G_z)))</span><br><span class="line"> </span><br><span class="line"> disc_var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)</span><br><span class="line"> print(&quot;len-----&quot;,len(disc_var_list),len(gen_var_list))</span><br><span class="line"> for x in gen_var_list:</span><br><span class="line">     disc_var_list.remove(x)</span><br><span class="line"> </span><br><span class="line"> learn_rate =0.001</span><br><span class="line"> global_step=tf.Variable(0,trainable=0,name=&apos;global_step&apos;)</span><br><span class="line"> gen_train_step=tf.train.AdamOptimizer(learn_rate).minimize</span><br><span class="line">(gen_loss,global_step,gen_var_list)</span><br><span class="line"> disc_train_step=tf.train.AdamOptimizer(learn_rate).minimize</span><br><span class="line">(disc_loss,global_step,disc_var_list)</span><br></pre></td></tr></table></figure>

</details>

<p>7．指定准备载入的预训练模型路径</p>
<p>这次需要对3个检查点路径进行配置，第一个是本程序的SRGAN检查点文件，第二个是srResNet检查点文件，最后一个是VGG模型文件。</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> #残差网络检查点文件相关定义</span><br><span class="line"> flags=&apos;b&apos;+str(batch_size)+&apos;_r&apos;+str(np.int32(height/4))+&apos;_r&apos;+str</span><br><span class="line">(learn_rate)+&apos;rsgan&apos;</span><br><span class="line"> save_path=&apos;save/srgan_&apos;+flags</span><br><span class="line"> if not os.path.exists(save_path):</span><br><span class="line">     os.mkdir(save_path)</span><br><span class="line"> saver = tf.train.Saver(max_to_keep=1) # 生成saver</span><br><span class="line"> </span><br><span class="line"> srResNet_path=&apos;./save/tf_b16_h64.0_r0.001_res/&apos;</span><br><span class="line"> srResNetloader = tf.train.Saver(var_list=gen_var_list) # 生成saver</span><br><span class="line"> </span><br><span class="line"> #VGG检查点</span><br><span class="line"> checkpoints_dir = &apos;vgg_19_2016_08_28&apos;</span><br><span class="line"> init_fn = slim.assign_from_checkpoint_fn(</span><br><span class="line">     os.path.join(checkpoints_dir, &apos;vgg_19.ckpt&apos;),</span><br><span class="line">     slim.get_model_variables(&apos;vgg_19&apos;))</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00014.jpg" alt> 注意： 这里对于srResNet的变量恢复，要在建立Saver时传入var_list参数来指定好所要恢复的变量列表，否则默认是恢复所有变量，但是模型里却找不到其他变量，会报错误。</p>
<p>8．启动session从检查点恢复变量</p>
<p>对于VGG模型的恢复，可以参考第11章中的内容。其他的检查点恢复的写法与前面一样。代码如下：</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">log_steps=100</span><br><span class="line">training_epochs=16000</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line"> </span><br><span class="line">    sess.run(tf.global_variables_initializer())  </span><br><span class="line">    </span><br><span class="line">    init_fn(sess)    </span><br><span class="line">    </span><br><span class="line">    kpt = tf.train.latest_checkpoint(srResNet_path)</span><br><span class="line">    print(&quot;srResNet_path&quot;,kpt,srResNet_path)</span><br><span class="line">    startepo= 0</span><br><span class="line">    if kpt!=None:</span><br><span class="line">        srResNetloader.restore(sess, kpt) </span><br><span class="line">        ind = kpt.find(&quot;-&quot;)</span><br><span class="line">        startepo = int(kpt[ind+1:])</span><br><span class="line">        print(&quot;srResNetloader global_step=&quot;,global_step.eval(),startepo)     </span><br><span class="line">    </span><br><span class="line">    kpt = tf.train.latest_checkpoint(save_path)</span><br><span class="line">    print(&quot;srgan&quot;,kpt)</span><br><span class="line">    startepo= 0</span><br><span class="line">    if kpt!=None:</span><br><span class="line">        saver.restore(sess, kpt) </span><br><span class="line">        ind = kpt.find(&quot;-&quot;)</span><br><span class="line">        startepo = int(kpt[ind+1:])</span><br><span class="line">        print(&quot;global_step=&quot;,global_step.eval(),startepo)</span><br></pre></td></tr></table></figure>

</details>

<p>9．启动带协调器的队列线程，开始训练</p>
<p>本例中涉及的参数比较多，模型比较大，会导致每次迭代时间都很长，所以加入检测点是非常有必要的。这里涉及检查点保存的粒度，如间隔太短，因为频繁地写文件会减慢训练速度，如果设置的间隔太长，中途如发生意外暂停会导致浪费了一部分训练时间，可以通过try的方式在异常捕获时再保存一次检查点，这样可以把中途的训练结果保存下来。</p>
<p>代码12-9 rsgan（续）</p>
<details>
  <summary>代码详情</summary>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">coord = tf.train.Coordinator()</span><br><span class="line">    threads = tf.train.start_queue_runners(sess, coord)</span><br><span class="line">    </span><br><span class="line">    try:</span><br><span class="line">        def train(endpoint,gen_step,disc_step):</span><br><span class="line">            while global_step.eval()&lt;=endpoint:</span><br><span class="line">                </span><br><span class="line">                if((global_step.eval()/2)%log_steps==0): # 一次走两步</span><br><span class="line">                   </span><br><span class="line">                    d_batch=dbatch.eval()</span><br><span class="line">                    mse,psnr=batch_mse_psnr(d_batch)</span><br><span class="line">                    ssim=batch_ssim(d_batch)</span><br><span class="line">                    s=time.strftime(&apos;%Y-%m-%d %H:%M:%S:&apos;,time.localtime</span><br><span class="line">                   (time.time()))+&apos;step=&apos;+str(global_step.eval())+&apos; </span><br><span class="line">                    mse=&apos;+str(mse)+&apos; psnr=&apos;+str(psnr)+&apos; ssim=&apos;+str</span><br><span class="line">                    (ssim)+&apos; gen_loss=&apos;+str(gen_loss.eval())+&apos; disc_</span><br><span class="line">                    loss=&apos;+str(disc_loss.eval())</span><br><span class="line">                    print(s)</span><br><span class="line">                    f=open(&apos;info.train_&apos;+flags,&apos;a&apos;)</span><br><span class="line">                    f.write(s+&apos;\n&apos;)</span><br><span class="line">                    f.close()</span><br><span class="line">                    saver.save(sess, save_path+&quot;/srgan.cpkt&quot;, global_</span><br><span class="line">                   step=global_step.eval())</span><br><span class="line">                    </span><br><span class="line">                sess.run(disc_step)</span><br><span class="line">                sess.run(gen_step)</span><br><span class="line">        train(training_epochs,gen_train_step,disc_train_step)</span><br><span class="line">        print(&apos;训练完成&apos;)</span><br><span class="line">……          #显示部分同resEspcn例子，代码省略</span><br><span class="line">    except tf.errors.OutOfRangeError:</span><br><span class="line">        print(&apos;Done training --epoch limit reached&apos;)</span><br><span class="line">    except KeyboardInterrupt:</span><br><span class="line">        print(&quot;Ending Training...&quot;)</span><br><span class="line">        saver.save(sess, save_path+&quot;/srgan.cpkt&quot;, global_</span><br><span class="line">       step=global_step.eval())</span><br><span class="line">    finally:</span><br><span class="line">        coord.request_stop()</span><br><span class="line"></span><br><span class="line">    coord.join(threads)</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码，生成结果如图12-17所示。</p>
<p><img src="Image00281.jpg" alt></p>
<p>图12-17 SRGAN例子结果</p>
<p>图12-17中最后一张是模型生成的结果，每张图片上都有其评分值，可以看到SRGAN得到的PSNR和SSIM评价值不是最高的。但是我们肉眼看上去确实清晰了不少，并且通过有关机构对其进行MOS（Mean Opinion Score）的评价也表明，SRGAN生成的高分辨率图像看起来更真实。</p>
<p><img src="Image00014.jpg" alt> 注意： MOS（mean opinion score）采用主观评定和技术评定相结合的方式。所谓主观评定就是有人为的参与，用人来评定。</p>
<p>该例中只演示了运行迭代1万多次的效果。如果将ResEspcn的模型与srGAN的模型分别加一个数量级，还会得到效果更优质的图片，有兴趣的读者可以自行尝试。</p>
<h3 id="12-9-GAN网络的高级接口TFGAN"><a href="#12-9-GAN网络的高级接口TFGAN" class="headerlink" title="12.9 GAN网络的高级接口TFGAN"></a>12.9 GAN网络的高级接口TFGAN</h3><p>TFGAN是一个训练和评估生成式对抗网络（GAN）的轻量级库。它的初衷是为了让基于GAN的实验更加容易。</p>
<p>TFGAN也是基于估算器开发的一种应用接口，使用GANEstimator类来进行模型训练的。在TFGAN中，会使用很多已经集成的技巧（tricks）来稳定和提升GAN网络的训练效果。同时也集成了对GAN训练步骤的监视和可视化操作，以及训练后的模型评估操作，为开发者节省了大量的编码和调参时间。</p>
<p>TFGAN接口为开发者规范了开发GAN网络模型的标准步骤，每一个步骤都提供了全面的组建封装，使得开发者在开发GAN网络时，就像拼积木一样，按步骤选择不同的组建拼接起来即可。</p>
<p>TFGAN接口中规范的GAN网络开发步骤如下：</p>
<p>（1）指定网络的输入。</p>
<p>（2）使用GANModel函数来设置生成器和判别器模型。</p>
<p>（3）使用GANLoss函数来指定loss值。</p>
<p>（4）使用GANTrainOps函数来创建训练操作。</p>
<p>（5）运行训练操作。</p>
<p>当然开发者也可以将TFGAN中已经实现了的损失值和惩罚处理（包括推土机距离损失、梯度惩罚、互信息惩罚等），集成到原生的GAN网络或是其他框架中。</p>
<p>更多关于TFGAN的信息见如下链接：</p>
<p><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan</a> 。</p>
<p>该链接中包含的不仅仅是TFGAN的介绍，更多的是关于TFGAN实现各种GAN网络的例子代码。</p>
<p>在本书中，给出的均属于原生的GAN网络实例。目的是让读者掌握更底层的原理，以便于能够驾驭更有挑战性的任务。在实际应用中，使用TFGAN高级接口，可以起到事半功倍的效果，因此强烈推荐读者使用TFGAN高级接口。</p>
<h3 id="12-10-总结"><a href="#12-10-总结" class="headerlink" title="12.10 总结"></a>12.10 总结</h3><p>GAN网络可以说是2017年深度学习领域最热门的技术，从图12-18中可以看出2017年起GAN的种类已经由40多种发展到了250多种，而且速度越来越快。</p>
<p><img src="Image00282.jpg" alt></p>
<p>图12-18 GAN种类的发展</p>
<p>让网络来监督网络，使得深度学习在人工智能方向大踏步前进，由于篇幅所限，本书关于GAN网络的介绍只是冰山一角，GAN还可以实现通过文字描述生成图片；将图片生成文字，进行图像风格的转移；为人脸生成带眼镜的照片，或将戴眼镜的照片还原成没带眼镜的照片；编写小说、诗歌等。另外，GAN在通信加密、文本分类等领域也广泛应用。在TensorFlow的官方GitHub中甚至还有使用GAN生成技术来扩充样本的工程。希望读者在结束本书的学习后不要停止脚步，人工智能的领域永无止尽，让我们一起努力用科学改变世界。</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      <div>    
       
       
      <ul class="post-copyright">
        <li class="post-copyright-author">
            <strong>本文作者：</strong>hac_lang
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/" title="book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪">2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          许可协议，请勿用于商业，转载注明出处！
        </li>
      </ul>
      
      </div>
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/计算机/" rel="tag"># 计算机</a>
          
            <a href="/tags/人工智能/" rel="tag"># 人工智能</a>
          
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          
            <a href="/tags/自评/" rel="tag"># 自评</a>
          
            <a href="/tags/books/" rel="tag"># books</a>
          
            <a href="/tags/更毕/" rel="tag"># 更毕</a>
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/AI/" rel="tag"># AI</a>
          
            <a href="/tags/豆瓣8/" rel="tag"># 豆瓣8</a>
          
            <a href="/tags/Programming/" rel="tag"># Programming</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/24/book-《TensorFlow机器学习实战指南》/" rel="next" title="book_《TensorFlow机器学习实战指南》">
                <i class="fa fa-chevron-left"></i> book_《TensorFlow机器学习实战指南》
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/" rel="prev" title="book_《TensorFlow+Keras深度学习人工智能实践应用》">
                book_《TensorFlow+Keras深度学习人工智能实践应用》 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="hac_lang">
  
  <p class="site-author-name" itemprop="name">hac_lang</p>
  <div class="site-description motion-element" itemprop="description">小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">82</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>







  <div class="links-of-author motion-element">
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/HACLANG" title="GitHub &rarr; https://github.com/HACLANG" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://stackoverflow.com/yourname" title="StackOverflow &rarr; https://stackoverflow.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://gitter.im" title="Gitter &rarr; https://gitter.im" rel="noopener" target="_blank"><i class="fa fa-fw fa-github-alt"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.jianshu.com/u/442ddccf3f32" title="简书 &rarr; https://www.jianshu.com/u/442ddccf3f32" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="Quora &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://plus.google.com/yourname" title="Google &rarr; https://plus.google.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:haclang.org@gmail.com" title="E-Mail &rarr; mailto:haclang.org@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="skype:haclang?call|chat" title="Skype &rarr; skype:haclang?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://twitter.com/haclang2" title="Twitter &rarr; https://twitter.com/haclang2" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="FaceBook &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a>
      </span>
    
  </div>








          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#配套学习资源"><span class="nav-text">配套学习资源</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#本书特色"><span class="nav-text">本书特色</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#本书内容"><span class="nav-text">本书内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#本书读者对象"><span class="nav-text">本书读者对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关于作者"><span class="nav-text">关于作者</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#第1篇-深度学习与TensorFlow基础"><span class="nav-text">第1篇 深度学习与TensorFlow基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第1章-快速了解人工智能与TensorFlow"><span class="nav-text">第1章 快速了解人工智能与TensorFlow</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-什么是深度学习"><span class="nav-text">1.1 什么是深度学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-TensorFlow是做什么的"><span class="nav-text">1.2 TensorFlow是做什么的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-TensorFlow的特点"><span class="nav-text">1.3 TensorFlow的特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-其他深度学习框架特点及介绍"><span class="nav-text">1.4 其他深度学习框架特点及介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-如何通过本书学好深度学习"><span class="nav-text">1.5 如何通过本书学好深度学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-1-深度学习怎么学"><span class="nav-text">1.5.1 深度学习怎么学</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-2-如何学习本书"><span class="nav-text">1.5.2 如何学习本书</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第2章-搭建开发环境"><span class="nav-text">第2章 搭建开发环境</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-下载及安装Anaconda开发工具"><span class="nav-text">2.1 下载及安装Anaconda开发工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-在Windows平台下载及安装TensorFlow"><span class="nav-text">2.2 在Windows平台下载及安装TensorFlow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-GPU版本的安装方法"><span class="nav-text">2.3 GPU版本的安装方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-安装CUDA软件包"><span class="nav-text">2.3.1 安装CUDA软件包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-2-安装cuDNN库"><span class="nav-text">2.3.2 安装cuDNN库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-3-测试显卡"><span class="nav-text">2.3.3 测试显卡</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-熟悉Anaconda-3开发工具"><span class="nav-text">2.4 熟悉Anaconda 3开发工具</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-1-快速了解Spyder"><span class="nav-text">2.4.1 快速了解Spyder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-2-快速了解Jupyter-Notebook"><span class="nav-text">2.4.2 快速了解Jupyter Notebook</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第3章-TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例"><span class="nav-text">第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-实例1：从一组看似混乱的数据中找出y≈2x的规律"><span class="nav-text">3.1 实例1：从一组看似混乱的数据中找出y≈2x的规律</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-准备数据"><span class="nav-text">3.1.1 准备数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-搭建模型"><span class="nav-text">3.1.2 搭建模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-迭代训练模型"><span class="nav-text">3.1.3 迭代训练模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-4-使用模型"><span class="nav-text">3.1.4 使用模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-模型是如何训练出来的"><span class="nav-text">3.2 模型是如何训练出来的</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-模型里的内容及意义"><span class="nav-text">3.2.1 模型里的内容及意义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-模型内部的数据流向"><span class="nav-text">3.2.2 模型内部的数据流向</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-了解TensorFlow开发的基本步骤"><span class="nav-text">3.3 了解TensorFlow开发的基本步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-1-定义输入节点的方法"><span class="nav-text">3.3.1 定义输入节点的方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-2-实例2：通过字典类型定义输入节点"><span class="nav-text">3.3.2 实例2：通过字典类型定义输入节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-3-实例3：直接定义输入节点"><span class="nav-text">3.3.3 实例3：直接定义输入节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-4-定义“学习参数”的变量"><span class="nav-text">3.3.4 定义“学习参数”的变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-5-实例4：通过字典类型定义“学习参数”"><span class="nav-text">3.3.5 实例4：通过字典类型定义“学习参数”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-6-定义“运算”"><span class="nav-text">3.3.6 定义“运算”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-7-优化函数，优化目标"><span class="nav-text">3.3.7 优化函数，优化目标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-8-初始化所有变量"><span class="nav-text">3.3.8 初始化所有变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-9-迭代更新参数到最优解"><span class="nav-text">3.3.9 迭代更新参数到最优解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-10-测试模型"><span class="nav-text">3.3.10 测试模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-11-使用模型"><span class="nav-text">3.3.11 使用模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第4章-TensorFlow编程基础"><span class="nav-text">第4章 TensorFlow编程基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-编程模型"><span class="nav-text">4.1 编程模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-1-了解模型的运行机制"><span class="nav-text">4.1.1 了解模型的运行机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-2-实例5：编写hello-world程序演示session的使用"><span class="nav-text">4.1.2 实例5：编写hello world程序演示session的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-3-实例6：演示with-session的使用"><span class="nav-text">4.1.3 实例6：演示with session的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-4-实例7：演示注入机制"><span class="nav-text">4.1.4 实例7：演示注入机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-5-建立session-的其他方法"><span class="nav-text">4.1.5 建立session 的其他方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-6-实例8：使用注入机制获取节点"><span class="nav-text">4.1.6 实例8：使用注入机制获取节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-7-指定GPU运算"><span class="nav-text">4.1.7 指定GPU运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-8-设置GPU使用资源"><span class="nav-text">4.1.8 设置GPU使用资源</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-9-保存和载入模型的方法介绍"><span class="nav-text">4.1.9 保存和载入模型的方法介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-10-实例9：保存-载入线性回归模型"><span class="nav-text">4.1.10 实例9：保存/载入线性回归模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-11-实例10：分析模型内容，演示模型的其他保存方法"><span class="nav-text">4.1.11 实例10：分析模型内容，演示模型的其他保存方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-12-检查点（Checkpoint）"><span class="nav-text">4.1.12 检查点（Checkpoint）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-13-实例11：为模型添加保存检查点"><span class="nav-text">4.1.13 实例11：为模型添加保存检查点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-14-实例12：更简便地保存检查点"><span class="nav-text">4.1.14 实例12：更简便地保存检查点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-15-模型操作常用函数总结"><span class="nav-text">4.1.15 模型操作常用函数总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-16-TensorBoard可视化介绍"><span class="nav-text">4.1.16 TensorBoard可视化介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-17-实例13：线性回归的TensorBoard可视化"><span class="nav-text">4.1.17 实例13：线性回归的TensorBoard可视化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-TensorFlow基础类型定义及操作函数介绍"><span class="nav-text">4.2 TensorFlow基础类型定义及操作函数介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-1-张量及操作"><span class="nav-text">4.2.1 张量及操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-算术运算函数"><span class="nav-text">4.2.2 算术运算函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-矩阵相关的运算"><span class="nav-text">4.2.3 矩阵相关的运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-4-复数操作函数"><span class="nav-text">4.2.4 复数操作函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-5-规约计算"><span class="nav-text">4.2.5 规约计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-6-分割"><span class="nav-text">4.2.6 分割</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-7-序列比较与索引提取"><span class="nav-text">4.2.7 序列比较与索引提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-8-错误类"><span class="nav-text">4.2.8 错误类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-共享变量"><span class="nav-text">4.3 共享变量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-1-共享变量用途"><span class="nav-text">4.3.1 共享变量用途</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-2-使用get-variable获取变量"><span class="nav-text">4.3.2 使用get-variable获取变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-3-实例14：演示get-variable和Variable的区别"><span class="nav-text">4.3.3 实例14：演示get_variable和Variable的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-4-实例15：在特定的作用域下获取变量"><span class="nav-text">4.3.4 实例15：在特定的作用域下获取变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-5-实例16：共享变量功能的实现"><span class="nav-text">4.3.5 实例16：共享变量功能的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-6-实例17：初始化共享变量的作用域"><span class="nav-text">4.3.6 实例17：初始化共享变量的作用域</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-7-实例18：演示作用域与操作符的受限范围"><span class="nav-text">4.3.7 实例18：演示作用域与操作符的受限范围</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-实例19：图的基本操作"><span class="nav-text">4.4 实例19：图的基本操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-1-建立图"><span class="nav-text">4.4.1 建立图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-2-获取张量"><span class="nav-text">4.4.2 获取张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-3-获取节点操作"><span class="nav-text">4.4.3 获取节点操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-4-获取元素列表"><span class="nav-text">4.4.4 获取元素列表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-5-获取对象"><span class="nav-text">4.4.5 获取对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-6-练习题"><span class="nav-text">4.4.6 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-配置分布式TensorFlow"><span class="nav-text">4.5 配置分布式TensorFlow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-1-分布式TensorFlow的角色及原理"><span class="nav-text">4.5.1 分布式TensorFlow的角色及原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-2-分布部署TensorFlow的具体方法"><span class="nav-text">4.5.2 分布部署TensorFlow的具体方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-3-实例20：使用TensorFlow实现分布式部署训练"><span class="nav-text">4.5.3 实例20：使用TensorFlow实现分布式部署训练</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-动态图（Eager）"><span class="nav-text">4.6 动态图（Eager）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-7-数据集（tf-data）"><span class="nav-text">4.7 数据集（tf.data）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第5章-识别图中模糊的手写数字（实例21）"><span class="nav-text">第5章 识别图中模糊的手写数字（实例21）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-导入图片数据集"><span class="nav-text">5.1 导入图片数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-1-MNIST数据集介绍"><span class="nav-text">5.1.1 MNIST数据集介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-2-下载并安装MNIST数据集"><span class="nav-text">5.1.2 下载并安装MNIST数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-分析图片的特点，定义变量"><span class="nav-text">5.2 分析图片的特点，定义变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-构建模型"><span class="nav-text">5.3 构建模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3-1-定义学习参数"><span class="nav-text">5.3.1 定义学习参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3-2-定义输出节点"><span class="nav-text">5.3.2 定义输出节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3-3-定义反向传播的结构"><span class="nav-text">5.3.3 定义反向传播的结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-训练模型并输出中间状态参数"><span class="nav-text">5.4 训练模型并输出中间状态参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-测试模型"><span class="nav-text">5.5 测试模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-保存模型"><span class="nav-text">5.6 保存模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-读取模型"><span class="nav-text">5.7 读取模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第2篇-深度学习基础——神经网络"><span class="nav-text">第2篇 深度学习基础——神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第6章-单个神经元"><span class="nav-text">第6章 单个神经元</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-神经元的拟合原理"><span class="nav-text">6.1 神经元的拟合原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-1-正向传播"><span class="nav-text">6.1.1 正向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-2-反向传播"><span class="nav-text">6.1.2 反向传播</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-激活函数——加入非线性因素，解决线性模型缺陷"><span class="nav-text">6.2 激活函数——加入非线性因素，解决线性模型缺陷</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-1-Sigmoid函数"><span class="nav-text">6.2.1 Sigmoid函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-2-Tanh函数"><span class="nav-text">6.2.2 Tanh函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-3-ReLU函数"><span class="nav-text">6.2.3 ReLU函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-4-Swish函数"><span class="nav-text">6.2.4 Swish函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-5-激活函数总结"><span class="nav-text">6.2.5 激活函数总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-softmax算法——处理分类问题"><span class="nav-text">6.3 softmax算法——处理分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-1-什么是softmax"><span class="nav-text">6.3.1 什么是softmax</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-2-softmax原理"><span class="nav-text">6.3.2 softmax原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-3-常用的分类函数"><span class="nav-text">6.3.3 常用的分类函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-损失函数——用真实值与预测值的距离来指导模型的收敛方向"><span class="nav-text">6.4 损失函数——用真实值与预测值的距离来指导模型的收敛方向</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-1-损失函数介绍"><span class="nav-text">6.4.1 损失函数介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-2-TensorFlow中常见的loss函数"><span class="nav-text">6.4.2 TensorFlow中常见的loss函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-softmax算法与损失函数的综合应用"><span class="nav-text">6.5 softmax算法与损失函数的综合应用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-1-实例22：交叉熵实验"><span class="nav-text">6.5.1 实例22：交叉熵实验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-2-实例23：one-hot实验"><span class="nav-text">6.5.2 实例23：one_hot实验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-3-实例24：sparse交叉熵的使用"><span class="nav-text">6.5.3 实例24：sparse交叉熵的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-4-实例25：计算loss值"><span class="nav-text">6.5.4 实例25：计算loss值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-5-5-练习题"><span class="nav-text">6.5.5 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-6-梯度下降——让模型逼近最小偏差"><span class="nav-text">6.6 梯度下降——让模型逼近最小偏差</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-6-1-梯度下降的作用及分类"><span class="nav-text">6.6.1 梯度下降的作用及分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-6-2-TensorFlow中的梯度下降函数"><span class="nav-text">6.6.2 TensorFlow中的梯度下降函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-6-3-退化学习率——在训练的速度与精度之间找到平衡"><span class="nav-text">6.6.3 退化学习率——在训练的速度与精度之间找到平衡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-6-4-实例26：退化学习率的用法举例"><span class="nav-text">6.6.4 实例26：退化学习率的用法举例</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-7-初始化学习参数"><span class="nav-text">6.7 初始化学习参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-8-单个神经元的扩展——Maxout网络"><span class="nav-text">6.8 单个神经元的扩展——Maxout网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-8-1-Maxout介绍"><span class="nav-text">6.8.1 Maxout介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-8-2-实例27：用Maxout网络实现MNIST分类"><span class="nav-text">6.8.2 实例27：用Maxout网络实现MNIST分类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-9-练习题"><span class="nav-text">6.9 练习题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第7章-多层神经网络——解决非线性问题"><span class="nav-text">第7章 多层神经网络——解决非线性问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-线性问题与非线性问题"><span class="nav-text">7.1 线性问题与非线性问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-1-实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的"><span class="nav-text">7.1.1 实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-2-实例29：用线性逻辑回归处理多分类问题"><span class="nav-text">7.1.2 实例29：用线性逻辑回归处理多分类问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-3-认识非线性问题"><span class="nav-text">7.1.3 认识非线性问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-使用隐藏层解决非线性问题"><span class="nav-text">7.2 使用隐藏层解决非线性问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-1-实例30：使用带隐藏层的神经网络拟合异或操作"><span class="nav-text">7.2.1 实例30：使用带隐藏层的神经网络拟合异或操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-2-非线性网络的可视化及其意义"><span class="nav-text">7.2.2 非线性网络的可视化及其意义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-3-练习题"><span class="nav-text">7.2.3 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-实例31：利用全连接网络将图片进行分类"><span class="nav-text">7.3 实例31：利用全连接网络将图片进行分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-全连接网络训练中的优化技巧"><span class="nav-text">7.4 全连接网络训练中的优化技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-1-实例32：利用异或数据集演示过拟合问题"><span class="nav-text">7.4.1 实例32：利用异或数据集演示过拟合问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-2-正则化"><span class="nav-text">7.4.2 正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-3-实例33：通过正则化改善过拟合情况"><span class="nav-text">7.4.3 实例33：通过正则化改善过拟合情况</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-4-实例34：通过增大数据集改善过拟合"><span class="nav-text">7.4.4 实例34：通过增大数据集改善过拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-5-练习题"><span class="nav-text">7.4.5 练习题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-6-dropout——训练过程中，将部分神经单元暂时丢弃"><span class="nav-text">7.4.6 dropout——训练过程中，将部分神经单元暂时丢弃</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-7-实例35：为异或数据集模型添加dropout"><span class="nav-text">7.4.7 实例35：为异或数据集模型添加dropout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-8-实例36：基于退化学习率dropout技术来拟合异或数据集"><span class="nav-text">7.4.8 实例36：基于退化学习率dropout技术来拟合异或数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-9-全连接网络的深浅关系"><span class="nav-text">7.4.9 全连接网络的深浅关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-5-练习题"><span class="nav-text">7.5 练习题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第8章-卷积神经网络——解决参数太多问题"><span class="nav-text">第8章 卷积神经网络——解决参数太多问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-全连接网络的局限性"><span class="nav-text">8.1 全连接网络的局限性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-理解卷积神经网络"><span class="nav-text">8.2 理解卷积神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-网络结构"><span class="nav-text">8.3 网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-3-1-网络结构描述"><span class="nav-text">8.3.1 网络结构描述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-3-2-卷积操作"><span class="nav-text">8.3.2 卷积操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-3-3-池化层"><span class="nav-text">8.3.3 池化层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-卷积神经网络的相关函数"><span class="nav-text">8.4 卷积神经网络的相关函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-1-卷积函数tf-nn-conv2d"><span class="nav-text">8.4.1 卷积函数tf.nn.conv2d</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-2-padding规则介绍"><span class="nav-text">8.4.2 padding规则介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-3-实例37：卷积函数的使用"><span class="nav-text">8.4.3 实例37：卷积函数的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-4-实例38：使用卷积提取图片的轮廓"><span class="nav-text">8.4.4 实例38：使用卷积提取图片的轮廓</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-5-池化函数tf-nn-max-pool（avg-pool）"><span class="nav-text">8.4.5 池化函数tf.nn.max_pool（avg_pool）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-6-实例39：池化函数的使用"><span class="nav-text">8.4.6 实例39：池化函数的使用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-使用卷积神经网络对图片分类"><span class="nav-text">8.5 使用卷积神经网络对图片分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-1-CIFAR介绍"><span class="nav-text">8.5.1 CIFAR介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-2-下载CIFAR数据"><span class="nav-text">8.5.2 下载CIFAR数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-3-实例40：导入并显示CIFAR数据集"><span class="nav-text">8.5.3 实例40：导入并显示CIFAR数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-4-实例41：显示CIFAR数据集的原始图片"><span class="nav-text">8.5.4 实例41：显示CIFAR数据集的原始图片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-5-cifar10-input的其他功能"><span class="nav-text">8.5.5 cifar10_input的其他功能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-6-在TensorFlow中使用queue"><span class="nav-text">8.5.6 在TensorFlow中使用queue</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-7-实例42：协调器的用法演示"><span class="nav-text">8.5.7 实例42：协调器的用法演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-8-实例43：为session中的队列加上协调器"><span class="nav-text">8.5.8 实例43：为session中的队列加上协调器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-9-实例44：建立一个带有全局平均池化层的卷积神经网络"><span class="nav-text">8.5.9 实例44：建立一个带有全局平均池化层的卷积神经网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-10-练习题"><span class="nav-text">8.5.10 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-6-反卷积神经网络"><span class="nav-text">8.6 反卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-1-反卷积神经网络的应用场景"><span class="nav-text">8.6.1 反卷积神经网络的应用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-2-反卷积原理"><span class="nav-text">8.6.2 反卷积原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-3-实例45：演示反卷积的操作"><span class="nav-text">8.6.3 实例45：演示反卷积的操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-4-反池化原理"><span class="nav-text">8.6.4 反池化原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-5-实例46：演示反池化的操作"><span class="nav-text">8.6.5 实例46：演示反池化的操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-6-实例47：演示gradients基本用法"><span class="nav-text">8.6.6 实例47：演示gradients基本用法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-7-实例48：使用gradients对多个式子求多变量偏导"><span class="nav-text">8.6.7 实例48：使用gradients对多个式子求多变量偏导</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-6-8-实例49：演示梯度停止的实现"><span class="nav-text">8.6.8 实例49：演示梯度停止的实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-7-实例50：用反卷积技术复原卷积网络各层图像"><span class="nav-text">8.7 实例50：用反卷积技术复原卷积网络各层图像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-8-善用函数封装库"><span class="nav-text">8.8 善用函数封装库</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-8-1-实例51：使用函数封装库重写CIFAR卷积网络"><span class="nav-text">8.8.1 实例51：使用函数封装库重写CIFAR卷积网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-8-2-练习题"><span class="nav-text">8.8.2 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-9-深度学习的模型训练技巧"><span class="nav-text">8.9 深度学习的模型训练技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-9-1-实例52：优化卷积核技术的演示"><span class="nav-text">8.9.1 实例52：优化卷积核技术的演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-9-2-实例53：多通道卷积技术的演示"><span class="nav-text">8.9.2 实例53：多通道卷积技术的演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-9-3-批量归一化"><span class="nav-text">8.9.3 批量归一化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-9-4-实例54：为CIFAR图片分类模型添加BN"><span class="nav-text">8.9.4 实例54：为CIFAR图片分类模型添加BN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-9-5-练习题"><span class="nav-text">8.9.5 练习题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第9章-循环神经网络——具有记忆功能的网络"><span class="nav-text">第9章 循环神经网络——具有记忆功能的网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-了解RNN的工作原理"><span class="nav-text">9.1 了解RNN的工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-1-1-了解人的记忆原理"><span class="nav-text">9.1.1 了解人的记忆原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-1-2-RNN网络的应用领域"><span class="nav-text">9.1.2 RNN网络的应用领域</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-1-3-正向传播过程"><span class="nav-text">9.1.3 正向传播过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-1-4-随时间反向传播"><span class="nav-text">9.1.4 随时间反向传播</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-简单RNN"><span class="nav-text">9.2 简单RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-2-1-实例55：简单循环神经网络实现——裸写一个退位减法器"><span class="nav-text">9.2.1 实例55：简单循环神经网络实现——裸写一个退位减法器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-2-2-实例56：使用RNN网络拟合回声信号序列"><span class="nav-text">9.2.2 实例56：使用RNN网络拟合回声信号序列</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-循环神经网络（RNN）的改进"><span class="nav-text">9.3 循环神经网络（RNN）的改进</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-1-LSTM网络介绍"><span class="nav-text">9.3.1 LSTM网络介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-2-窥视孔连接（Peephole）"><span class="nav-text">9.3.2 窥视孔连接（Peephole）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-3-带有映射输出的STMP"><span class="nav-text">9.3.3 带有映射输出的STMP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-4-基于梯度剪辑的cell"><span class="nav-text">9.3.4 基于梯度剪辑的cell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-5-GRU网络介绍"><span class="nav-text">9.3.5 GRU网络介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-6-Bi-RNN网络介绍"><span class="nav-text">9.3.6 Bi-RNN网络介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-3-7-基于神经网络的时序类分类CTC"><span class="nav-text">9.3.7 基于神经网络的时序类分类CTC</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-4-TensorFlow实战RNN"><span class="nav-text">9.4 TensorFlow实战RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-1-TensorFlow中的cell类"><span class="nav-text">9.4.1 TensorFlow中的cell类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-2-通过cell类构建RNN"><span class="nav-text">9.4.2 通过cell类构建RNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-3-实例57：构建单层LSTM网络对MNIST数据集分类"><span class="nav-text">9.4.3 实例57：构建单层LSTM网络对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-4-实例58：构建单层GRU网络对MNIST数据集分类"><span class="nav-text">9.4.4 实例58：构建单层GRU网络对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-5-实例59：创建动态单层RNN网络对MNIST数据集分类"><span class="nav-text">9.4.5 实例59：创建动态单层RNN网络对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-6-实例60：静态多层LSTM对MNIST数据集分类"><span class="nav-text">9.4.6 实例60：静态多层LSTM对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-7-实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类"><span class="nav-text">9.4.7 实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-8-实例62：动态多层RNN对MNIST数据集分类"><span class="nav-text">9.4.8 实例62：动态多层RNN对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-9-练习题"><span class="nav-text">9.4.9 练习题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-10-实例63：构建单层动态双向RNN对MNIST数据集分类"><span class="nav-text">9.4.10 实例63：构建单层动态双向RNN对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-11-实例64：构建单层静态双向RNN对MNIST数据集分类"><span class="nav-text">9.4.11 实例64：构建单层静态双向RNN对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-12-实例65：构建多层双向RNN对MNIST数据集分类"><span class="nav-text">9.4.12 实例65：构建多层双向RNN对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-13-实例66：构建动态多层双向RNN对MNIST数据集分类"><span class="nav-text">9.4.13 实例66：构建动态多层双向RNN对MNIST数据集分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-14-初始化RNN"><span class="nav-text">9.4.14 初始化RNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-15-优化RNN"><span class="nav-text">9.4.15 优化RNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-16-实例67：在GRUCell中实现LN"><span class="nav-text">9.4.16 实例67：在GRUCell中实现LN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-17-CTC网络的loss——ctc-loss"><span class="nav-text">9.4.17 CTC网络的loss——ctc_loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-4-18-CTCdecoder"><span class="nav-text">9.4.18 CTCdecoder</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-5-实例68：利用BiRNN实现语音识别"><span class="nav-text">9.5 实例68：利用BiRNN实现语音识别</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-5-1-语音识别背景"><span class="nav-text">9.5.1 语音识别背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-5-2-获取并整理样本"><span class="nav-text">9.5.2 获取并整理样本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-5-3-训练模型"><span class="nav-text">9.5.3 训练模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-5-4-练习题"><span class="nav-text">9.5.4 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-6-实例69：利用RNN训练语言模型"><span class="nav-text">9.6 实例69：利用RNN训练语言模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-1-准备样本"><span class="nav-text">9.6.1 准备样本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-6-2-构建模型"><span class="nav-text">9.6.2 构建模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-7-语言模型的系统学习"><span class="nav-text">9.7 语言模型的系统学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-1-统计语言模型"><span class="nav-text">9.7.1 统计语言模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-2-词向量"><span class="nav-text">9.7.2 词向量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-3-word2vec"><span class="nav-text">9.7.3 word2vec</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-4-实例70：用CBOW模型训练自己的word2vec"><span class="nav-text">9.7.4 实例70：用CBOW模型训练自己的word2vec</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-5-实例71：使用指定侯选采样本训练word2vec"><span class="nav-text">9.7.5 实例71：使用指定侯选采样本训练word2vec</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-7-6-练习题"><span class="nav-text">9.7.6 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-8-处理Seq2Seq任务"><span class="nav-text">9.8 处理Seq2Seq任务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-1-Seq2Seq任务介绍"><span class="nav-text">9.8.1 Seq2Seq任务介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-2-Encoder-Decoder框架"><span class="nav-text">9.8.2 Encoder-Decoder框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-3-实例72：使用basic-rnn-seq2seq拟合曲线"><span class="nav-text">9.8.3 实例72：使用basic_rnn_seq2seq拟合曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-4-实例73：预测当天的股票价格"><span class="nav-text">9.8.4 实例73：预测当天的股票价格</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-5-基于注意力的Seq2Seq"><span class="nav-text">9.8.5 基于注意力的Seq2Seq</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-8-6-实例74：基于Seq2Seq注意力模型实现中英文机器翻译"><span class="nav-text">9.8.6 实例74：基于Seq2Seq注意力模型实现中英文机器翻译</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-9-实例75：制作一个简单的聊天机器人"><span class="nav-text">9.9 实例75：制作一个简单的聊天机器人</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#9-9-1-构建项目框架"><span class="nav-text">9.9.1 构建项目框架</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-9-2-准备聊天样本"><span class="nav-text">9.9.2 准备聊天样本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-9-3-预处理样本"><span class="nav-text">9.9.3 预处理样本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-9-4-训练样本"><span class="nav-text">9.9.4 训练样本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-9-5-测试模型"><span class="nav-text">9.9.5 测试模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-10-时间序列的高级接口TFTS"><span class="nav-text">9.10 时间序列的高级接口TFTS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第10章-自编码网络——能够自学习样本特征的网络"><span class="nav-text">第10章 自编码网络——能够自学习样本特征的网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-自编码网络介绍及应用"><span class="nav-text">10.1 自编码网络介绍及应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-最简单的自编码网络"><span class="nav-text">10.2 最简单的自编码网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-自编码网络的代码实现"><span class="nav-text">10.3 自编码网络的代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-3-1-实例76：提取图片的特征，并利用特征还原图片"><span class="nav-text">10.3.1 实例76：提取图片的特征，并利用特征还原图片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-3-2-线性解码器"><span class="nav-text">10.3.2 线性解码器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-3-3-实例77：提取图片的二维特征，并利用二维特征还原图片"><span class="nav-text">10.3.3 实例77：提取图片的二维特征，并利用二维特征还原图片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-3-4-实例78：实现卷积网络的自编码"><span class="nav-text">10.3.4 实例78：实现卷积网络的自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-3-5-练习题"><span class="nav-text">10.3.5 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-去噪自编码"><span class="nav-text">10.4 去噪自编码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-5-去噪自编码网络的代码实现"><span class="nav-text">10.5 去噪自编码网络的代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-5-1-实例79：使用去噪自编码网络提取MNIST特征"><span class="nav-text">10.5.1 实例79：使用去噪自编码网络提取MNIST特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-5-2-练习题"><span class="nav-text">10.5.2 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-6-栈式自编码"><span class="nav-text">10.6 栈式自编码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-6-1-栈式自编码介绍"><span class="nav-text">10.6.1 栈式自编码介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-6-2-栈式自编码在深度学习中的意义"><span class="nav-text">10.6.2 栈式自编码在深度学习中的意义</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-7-深度学习中自编码的常用方法"><span class="nav-text">10.7 深度学习中自编码的常用方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-7-1-代替和级联"><span class="nav-text">10.7.1 代替和级联</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-7-2-自编码的应用场景"><span class="nav-text">10.7.2 自编码的应用场景</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-8-去噪自编码与栈式自编码的综合实现"><span class="nav-text">10.8 去噪自编码与栈式自编码的综合实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-8-1-实例80：实现去噪自编码"><span class="nav-text">10.8.1 实例80：实现去噪自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-8-2-实例81：添加模型存储支持分布训练"><span class="nav-text">10.8.2 实例81：添加模型存储支持分布训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-8-3-小心分布训练中的“坑”"><span class="nav-text">10.8.3 小心分布训练中的“坑”</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-8-4-练习题"><span class="nav-text">10.8.4 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-9-变分自编码"><span class="nav-text">10.9 变分自编码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-9-1-什么是变分自编码"><span class="nav-text">10.9.1 什么是变分自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-9-2-实例82：使用变分自编码模拟生成MNIST数据"><span class="nav-text">10.9.2 实例82：使用变分自编码模拟生成MNIST数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-9-3-练习题"><span class="nav-text">10.9.3 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-10-条件变分自编码"><span class="nav-text">10.10 条件变分自编码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-10-1-什么是条件变分自编码"><span class="nav-text">10.10.1 什么是条件变分自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-10-2-实例83：使用标签指导变分自编码网络生成MNIST数据"><span class="nav-text">10.10.2 实例83：使用标签指导变分自编码网络生成MNIST数据</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第3篇-深度学习进阶"><span class="nav-text">第3篇 深度学习进阶</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第11章-深度神经网络"><span class="nav-text">第11章 深度神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#11-1-深度神经网络介绍"><span class="nav-text">11.1 深度神经网络介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-1-1-深度神经网络起源"><span class="nav-text">11.1.1 深度神经网络起源</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-1-2-经典模型的特点介绍"><span class="nav-text">11.1.2 经典模型的特点介绍</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-2-GoogLeNet模型介绍"><span class="nav-text">11.2 GoogLeNet模型介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-1-MLP卷积层"><span class="nav-text">11.2.1 MLP卷积层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-2-全局均值池化"><span class="nav-text">11.2.2 全局均值池化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-3-Inception-原始模型"><span class="nav-text">11.2.3 Inception 原始模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-4-Inception-v1模型"><span class="nav-text">11.2.4 Inception v1模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-5-Inception-v2模型"><span class="nav-text">11.2.5 Inception v2模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-6-Inception-v3模型"><span class="nav-text">11.2.6 Inception v3模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-7-Inception-v4模型"><span class="nav-text">11.2.7 Inception v4模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-3-残差网络（ResNet）"><span class="nav-text">11.3 残差网络（ResNet）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-3-1-残差网络结构"><span class="nav-text">11.3.1 残差网络结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-3-2-残差网络原理"><span class="nav-text">11.3.2 残差网络原理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-4-Inception-ResNet-v2结构"><span class="nav-text">11.4 Inception-ResNet-v2结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-5-TensorFlow中的图片分类模型库——slim"><span class="nav-text">11.5 TensorFlow中的图片分类模型库——slim</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-1-获取models中的-slim模块代码"><span class="nav-text">11.5.1 获取models中的 slim模块代码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-2-models中的slim目录结构"><span class="nav-text">11.5.2 models中的slim目录结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-3-slim中的数据集处理"><span class="nav-text">11.5.3 slim中的数据集处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-4-实例84：利用slim读取TFRecord中的数据"><span class="nav-text">11.5.4 实例84：利用slim读取TFRecord中的数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-5-在slim中训练模型"><span class="nav-text">11.5.5 在slim中训练模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-6-使用slim中的深度网络模型进行图像的识别与检测"><span class="nav-text">11.6 使用slim中的深度网络模型进行图像的识别与检测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-6-1-实例85：调用Inception-ResNet-v2模型进行图像识别"><span class="nav-text">11.6.1 实例85：调用Inception_ResNet_v2模型进行图像识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-6-2-实例86：调用VGG模型进行图像检测"><span class="nav-text">11.6.2 实例86：调用VGG模型进行图像检测</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-7-实物检测模型库——Object-Detection-API"><span class="nav-text">11.7 实物检测模型库——Object Detection API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-7-1-准备工作"><span class="nav-text">11.7.1 准备工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-7-2-实例87：调用Object-Detection-API进行实物检测"><span class="nav-text">11.7.2 实例87：调用Object Detection API进行实物检测</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-8-实物检测领域的相关模型"><span class="nav-text">11.8 实物检测领域的相关模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-1-RCNN基于卷积神经网络特征的区域方法"><span class="nav-text">11.8.1 RCNN基于卷积神经网络特征的区域方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-2-SPP-Net：基于空间金字塔池化的优化RCNN方法"><span class="nav-text">11.8.2 SPP-Net：基于空间金字塔池化的优化RCNN方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-3-Fast-R-CNN快速的RCNN模型"><span class="nav-text">11.8.3 Fast-R-CNN快速的RCNN模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-4-YOLO：能够一次性预测多个位置和类别的模型"><span class="nav-text">11.8.4 YOLO：能够一次性预测多个位置和类别的模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-5-SSD：比YOLO更快更准的模型"><span class="nav-text">11.8.5 SSD：比YOLO更快更准的模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-6-YOLO2：YOLO的升级版模型"><span class="nav-text">11.8.6 YOLO2：YOLO的升级版模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-9-机器自己设计的模型（NASNet）"><span class="nav-text">11.9 机器自己设计的模型（NASNet）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第12章-对抗神经网络（GAN）"><span class="nav-text">第12章 对抗神经网络（GAN）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#12-1-GAN的理论知识"><span class="nav-text">12.1 GAN的理论知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-1-1-生成式模型的应用"><span class="nav-text">12.1.1 生成式模型的应用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-1-2-GAN的训练方法"><span class="nav-text">12.1.2 GAN的训练方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-2-DCGAN——基于深度卷积的GAN"><span class="nav-text">12.2 DCGAN——基于深度卷积的GAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN"><span class="nav-text">12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-1-InfoGAN：带有隐含信息的GAN"><span class="nav-text">12.3.1 InfoGAN：带有隐含信息的GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-2-AC-GAN：带有辅助分类信息的GAN"><span class="nav-text">12.3.2 AC-GAN：带有辅助分类信息的GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-3-实例88：构建InfoGAN生成MNIST模拟数据"><span class="nav-text">12.3.3 实例88：构建InfoGAN生成MNIST模拟数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-4-练习题"><span class="nav-text">12.3.4 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-3-InfoGAN和ACGAN：指定类别生成模拟样本的GAN-1"><span class="nav-text">12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-1-InfoGAN：带有隐含信息的GAN-1"><span class="nav-text">12.3.1 InfoGAN：带有隐含信息的GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-2-AC-GAN：带有辅助分类信息的GAN-1"><span class="nav-text">12.3.2 AC-GAN：带有辅助分类信息的GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-3-实例88：构建InfoGAN生成MNIST模拟数据-1"><span class="nav-text">12.3.3 实例88：构建InfoGAN生成MNIST模拟数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-3-4-练习题-1"><span class="nav-text">12.3.4 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-5-WGAN-GP：更容易训练的GAN"><span class="nav-text">12.5 WGAN-GP：更容易训练的GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-5-1-WGAN：基于推土机距离原理的GAN"><span class="nav-text">12.5.1 WGAN：基于推土机距离原理的GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-5-2-WGAN-GP：带梯度惩罚项的WGAN"><span class="nav-text">12.5.2 WGAN-GP：带梯度惩罚项的WGAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-5-3-实例90：构建WGAN-GP生成MNIST数据集"><span class="nav-text">12.5.3 实例90：构建WGAN-GP生成MNIST数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-5-4-练习题"><span class="nav-text">12.5.4 练习题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-6-LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN"><span class="nav-text">12.6 LSGAN（最小乘二GAN）：具有WGAN同样效果的GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-6-1-LSGAN介绍"><span class="nav-text">12.6.1 LSGAN介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-6-2-实例91：构建LSGAN生成MNIST模拟数据"><span class="nav-text">12.6.2 实例91：构建LSGAN生成MNIST模拟数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-7-GAN-cls：具有匹配感知的判别器"><span class="nav-text">12.7 GAN-cls：具有匹配感知的判别器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-7-1-GAN-cls的具体实现"><span class="nav-text">12.7.1 GAN-cls的具体实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-7-2-实例92：使用GAN-cls技术实现生成标签匹配的模拟数据"><span class="nav-text">12.7.2 实例92：使用GAN-cls技术实现生成标签匹配的模拟数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-8-SRGAN——适用于超分辨率重建的GAN"><span class="nav-text">12.8 SRGAN——适用于超分辨率重建的GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-1-超分辨率技术"><span class="nav-text">12.8.1 超分辨率技术</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-2-实例93：ESPCN实现MNIST数据集的超分辨率重建"><span class="nav-text">12.8.2 实例93：ESPCN实现MNIST数据集的超分辨率重建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-3-实例94：ESPCN实现flowers数据集的超分辨率重建"><span class="nav-text">12.8.3 实例94：ESPCN实现flowers数据集的超分辨率重建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-4-实例95：使用残差网络的ESPCN"><span class="nav-text">12.8.4 实例95：使用残差网络的ESPCN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-5-SRGAN的原理"><span class="nav-text">12.8.5 SRGAN的原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-8-6-实例96：使用SRGAN实现flowers数据集的超分辨率修复"><span class="nav-text">12.8.6 实例96：使用SRGAN实现flowers数据集的超分辨率修复</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-9-GAN网络的高级接口TFGAN"><span class="nav-text">12.9 GAN网络的高级接口TFGAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-10-总结"><span class="nav-text">12.10 总结</span></a></li></ol></li></ol></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hac_lang</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  





  
    
    
      
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="true"></script>









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  
  

  
  

  


  

  

  

  

  


  


  




  




  




  



<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>


  

  

  


  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false,"scale":0.5},"react":{"opacity":0.7},"log":false,"tagMode":false});</script></body>
</html>
