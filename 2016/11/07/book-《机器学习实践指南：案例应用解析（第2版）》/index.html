<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="作者: 麦好出版社: 机械工业出版社副标题: 案例应用解析出版年: 2016-7-15丛书: 大数据技术丛书ISBN: 9787111540212 推荐序在2013年的中国大数据创新峰会上，我偶然结识了作者，期间聊到了人工智能革命和机器学习的话题，被作者的渊博知识所折服，慢慢地结下了深厚的友谊。时间一晃而过，机器学习现在已经得到了井喷式发展，按照麻省理工学院罗德尼·布鲁克斯的预测：到2100年以前">
<meta name="keywords" content="机器学习,自评,books,算法,更毕,NLP,豆瓣-,IBOM,FK,BUPE,Citrix,统计分析,SVM,机器视觉,文本分类,NLTK,虚拟化">
<meta property="og:type" content="article">
<meta property="og:title" content="book_《机器学习实践指南：案例应用解析（第2版）》">
<meta property="og:url" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/index.html">
<meta property="og:site_name" content="Hac_lang">
<meta property="og:description" content="作者: 麦好出版社: 机械工业出版社副标题: 案例应用解析出版年: 2016-7-15丛书: 大数据技术丛书ISBN: 9787111540212 推荐序在2013年的中国大数据创新峰会上，我偶然结识了作者，期间聊到了人工智能革命和机器学习的话题，被作者的渊博知识所折服，慢慢地结下了深厚的友谊。时间一晃而过，机器学习现在已经得到了井喷式发展，按照麻省理工学院罗德尼·布鲁克斯的预测：到2100年以前">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00000.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00001.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00002.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00003.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00004.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00005.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00006.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00007.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00008.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00009.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00010.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00011.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00012.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00013.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00015.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00016.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00017.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00018.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00019.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00020.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00021.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00022.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00023.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00024.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00025.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00026.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00027.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00028.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00029.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00030.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00031.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00032.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00033.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00034.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00035.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00036.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00037.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00038.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00142.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00143.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00144.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00145.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00146.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00147.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00148.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00149.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00150.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00151.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00152.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00153.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00154.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00155.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00156.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00157.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00158.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00159.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00160.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00161.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00162.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00163.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00164.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00165.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00166.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00167.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00168.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00169.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00170.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00171.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00172.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00173.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00174.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00175.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00176.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00177.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00178.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00179.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00180.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00181.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00182.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00183.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00184.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00185.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00186.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00187.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00188.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00189.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00190.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00191.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00192.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00193.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00194.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00195.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00196.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00197.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00198.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00199.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00200.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00201.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00202.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00203.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00204.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00205.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00206.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00207.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00208.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00209.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00210.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00211.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00212.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00213.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00214.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00215.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00216.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00217.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00218.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00219.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00220.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00221.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00222.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00223.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00224.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00225.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00226.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00227.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00228.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00229.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00230.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00231.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00232.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00233.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00234.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00235.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00236.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00237.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00238.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00239.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00240.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00241.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00242.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00243.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00244.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00245.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00246.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00247.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00248.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00249.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00250.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00536.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00537.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00050.jpg">
<meta property="og:updated_time" content="2020-08-14T17:59:10.355Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="book_《机器学习实践指南：案例应用解析（第2版）》">
<meta name="twitter:description" content="作者: 麦好出版社: 机械工业出版社副标题: 案例应用解析出版年: 2016-7-15丛书: 大数据技术丛书ISBN: 9787111540212 推荐序在2013年的中国大数据创新峰会上，我偶然结识了作者，期间聊到了人工智能革命和机器学习的话题，被作者的渊博知识所折服，慢慢地结下了深厚的友谊。时间一晃而过，机器学习现在已经得到了井喷式发展，按照麻省理工学院罗德尼·布鲁克斯的预测：到2100年以前">
<meta name="twitter:image" content="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/Image00000.jpg">





  
  
  <link rel="canonical" href="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>book_《机器学习实践指南：案例应用解析（第2版）》 | Hac_lang</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hac_lang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">小白hac_lang的笔记，涉及内容包含但不限于：人工智能   基因工程    信息安全   软件工程   嵌入式   天文物理</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-news">

    
    
      
    

    

    <a href="/news/" rel="section"><i class="menu-item-icon fa fa-fw fa-rss"></i> <br>news</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    
  
  

  

  <a href="https://github.com/HACLANG" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://haclang.github.io/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="hac_lang">
      <meta itemprop="description" content="小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hac_lang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">book_《机器学习实践指南：案例应用解析（第2版）》

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-07 16:06:55" itemprop="dateCreated datePublished" datetime="2016-11-07T16:06:55+08:00">2016-11-07</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者: 麦好<br>出版社: 机械工业出版社<br>副标题: 案例应用解析<br>出版年: 2016-7-15<br>丛书: 大数据技术丛书<br>ISBN: 9787111540212</p>
<h1 id="推荐序"><a href="#推荐序" class="headerlink" title="推荐序"></a>推荐序</h1><p>在2013年的中国大数据创新峰会上，我偶然结识了作者，期间聊到了人工智能革命和机器学习的话题，被作者的渊博知识所折服，慢慢地结下了深厚的友谊。时间一晃而过，机器学习现在已经得到了井喷式发展，按照麻省理工学院罗德尼·布鲁克斯的预测：到2100年以前，我们的日常生活中将充满智能机器人，而且人类无法将自己同它们区分开来，我们也将是机器人，同机器人互相联系。</p>
<p>追忆2011年，当时我在吉林大学读研三，幸运地拿到了百度研发工程师的offer，进入百度商务搜索架构部，一直做着与凤巢广告相关的工作。现代广告业的奠基人大卫·奥格威曾经说过，除非你的广告建立在伟大的创意之上，否则它就像夜航的船，不为人所注意。广告的创意是广告的灵魂，我也一直沿着广告内容技术的方向，优化创意，提升用户的体验，提升广告主的转化。在这个方向上，我采用了机器学习的相关技术，取得了毕昇（获得2014年度百度最高奖）、图片凤巢、知识凤巢、地域识别等项目的成功，深刻地体会到了机器学习的强大，正是有了机器学习的闪闪发光，才推动了很多令人惊艳的产品的诞生。对于互联网、IT从业人员，机器学习已经成为必备利器，掌握了它，就等于站在了巨人的肩膀上工作，可帮助自己提高个人的核心竞争力。</p>
<p>我和作者认识近3年，同时也是《机器学习实践指南》第1版的读者，并在工作之余与作者一起管理《机器学习实践指南》的读者QQ群（群号：192029861），在群里认识了更多专注机器学习的朋友和学者。《机器学习实践指南》第1版主要针对初、中级读者，作者出书的目标就是：以机器学习算法的实践应用为主，将更多的“门外汉”带入机器学习殿堂，让更多拥有机器学习理论却无法下手的朋友掌握机器学习实践思维，轻松步入机器学习实战领域。实践思维对IT行业非常重要，一旦形成了适当的思维方式，很多工作中遇到的技术难题将迎刃而解，学习新知识的速度也更快，因为只有实践与理论相结合才能更精准地理解知识。也希望对机器学习有兴趣的读者能从中受益。</p>
<p>《机器学习实践指南》第2版出版在即，我高兴地接受了作者的邀请——为本书写推荐序。第2版比第1版增加了更多的案例和算法解析，全书详细介绍了机器学习发展及应用前景、科学计算平台、Python计算平台应用、R语言计算平台应用、生产环境基础、统计分析基础、描述性分析案例、假设检验与回归模型案例、神经网络、统计算法、欧氏距离与余弦相似度、SVM、回归算法、PCA降维、关联规则、聚类与分类算法、数据拟合案例、图像算法案例、机器视觉案例、文本分类案例等机器学习实践与应用。</p>
<p>第2版致力推动机器学习理论在国内的普及和应用，为公司创建更多的商业价值；同时，力争让更多的学生、IT工程师等进入人工智能相关领域，适应智能时代工作的需要。</p>
<p>最后，希望大家喜欢这本书，进而从中受益。</p>
<p>徐培治</p>
<p>百度在线网络技术（北京）有限公司</p>
<p>2016年3月于北京</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h4 id="为什么要写这本书"><a href="#为什么要写这本书" class="headerlink" title="为什么要写这本书"></a>为什么要写这本书</h4><p>随着全球第三次工业革命的迅猛发展，机器学习技术异军突起，人类对机器学习技术的研究也开辟出了许多全新的应用领域，这使智能机器的计算能力和可定制性上升到了一个新的层次。到了2015年，人类在机器学习领域取得了一系列重大的突破，这项技术已悄无声息地潜入我们的日常生活，而在未来，机器学习也将拥抱变化，持续发力。如今，它已经在各行各业的技术革新中扮演着日益重要的角色，从各方面影响和改变着我们的生活。</p>
<p>近年来，机器学习技术在国外得到了海量应用和深入发展。2015年11月，谷歌开源了全新的TensorFlow机器学习系统，该系统更快、更智能，也更具有弹性。2015年1月，机器学习平台GraphLab改名为Dato，并获得了1850万美元的新融资（投资方为Vulcan Capital、Opus Capital、New Enterprise Associates、Madrona Venture Group），此前他们曾获得680万美元的融资。2015年8月，Facebook推出了“M”，Facebook认为人类不仅会回答人工智能所不能回答的问题，而且从长远来看，人类也会帮助改善人工智能技术，“M”除了能做到回答问题、查阅信息等基本功能外，还可以帮助用户完成如购买商品、餐厅定位、安排旅行计划等操作。在2015年12月召开的“2015年神经信息处理系统”（NIPS）会议上，微软研究人员和工程师公开了20多篇机器学习最新研究成果的论文。此外，微软还宣布，机器学习正在成为Windows 10的一部分：Skype翻译可以将口语几乎实时地翻译成其他语言，就像《星际迷航》中的通用翻译器那样，可以做到面对面的交流。Cortana个人数字助理在与用户的互动中不断学习与改进，从而帮助用户管理日历、跟踪快递，甚至能与用户聊天和讲笑话，实现真正的个性化互动体验。Clutter是微软Office 2016的成员，通过学习它可以识别出哪些电子邮件对用户来说最重要，并自动将不重要的邮件重定向到一个单独的文件夹中，从而保持用户收件箱的整洁。2015年9月，美军军队医疗中心指挥官少将Steve Jones在美军陆军的一次会议上发言表示，未来可以让智能机器人代替人类上战场运送伤员，美国军方甚至高调宣布：未来战场上机器人救起的可能不是人，而是机器人，因为智能机器人军团将代替人类出征。</p>
<p>在国内，机器学习掀起了技术革新的热潮，智能技术得到了广泛的普及和应用。隶属于中国科学院的新松机器人自动化公司生产了智能复合型机器人，这个安装了眼睛和感知器件的智能机器人，可以在车间里自由地行走并十分精确地完成任务，当其他工位人手不足时，接到指令的他还会主动上前帮忙，马上进入角色并开始工作。百度创造和完善了大规模机器学习的技术，搭建了一个能容纳万亿特征数据的、分钟级别模型更新的、高效训练的点击率预估系统；为进一步深入地发展机器学习技术，百度开始研究如何从“机器学习”到“复制人类大脑”；此外，百度甚至在2016年提出，百度的产品和服务都靠机器学习等技术来驱动。</p>
<p>随着机器学习技术在国内外的大量应用，机器学习工程师成为炙手可热的职位。现在中国已经悄然兴起了机器学习的学习热潮，掌握了机器学习技术的工程师将成为各大IT巨头疯抢的“香馍馍”，良好的发展势头和较高的职业薪水，吸引着越来越多的软件工程师和数据分析师涌入机器学习的领域。国内知名的公司百度、阿里巴巴、腾讯（俗称BAT）为迎接大数据时代带来的挑战，早已全面引进机器学习方面的人才，并有组织地对机器学习技术展开大规模的、更深入的研究。其他各大公司（包括非IT行业的公司）也提出了引进机器学习研发工程师的渴求。</p>
<p>但是，机器学习的入门门槛较高，尤其是对研究者的数学理解能力有较高的要求，相对于数据结构、算法导论中讲述的计算机算法及系统架构知识来说，机器学习是一个全新的领域，理解机器学习算法往往要从理解它所涉及的数学公式和数学知识开始，打好数学基础是非常有必要的，一旦掌握了数学分析、线性代数、概率与统计、统计学、离散数学、抽象代数、数学建模等数学理论后，理解机器学习算法就会容易很多，不再畏惧那些让人生厌的、麻烦的数学符号和数学公式，说不定还会喜欢上这些数学公式，并亲自推导一番。希望本书能帮助朋友们进入机器学习的精彩世界。</p>
<h4 id="读者对象"><a href="#读者对象" class="headerlink" title="读者对象"></a>读者对象</h4><p>·开发人员。在理解机器学习算法的基础上，调用机器学习的中间库进行开发，将机器学习应用于各种场景，如数据分析、图像识别、文本分类、搜索引擎、中文智能输入法等。</p>
<p>·架构师。在理解机器学习算法的基础上，适应现代云计算平台的发展，将机器学习算法应用在大规模的并行计算上。同时，机器学习算法是大数据分析的基础，如神经网络、SVM、相似度分析、统计分析等技术。</p>
<p>·机器学习的初、中级读者。人类对机器学习的研究只是一个开始，还远远没有结束。近年来，机器学习一直保持着强劲的发展势头，并拥有美好的发展前景，这点不同于某些软件开发领域中的程序语言或架构知识。掌握机器学习技术有一定的难度，但也意味着，掌握机器学习的技术就能获得更高的薪水和更具前景的职业。</p>
<h4 id="如何阅读本书"><a href="#如何阅读本书" class="headerlink" title="如何阅读本书"></a>如何阅读本书</h4><p>全书分为准备篇、基础篇、统计分析实战篇和机器学习实战篇。机器学习算法建立在复杂的计算理论基础之上，并涉及多门数学学科。抽象的理论加上成堆的数学公式，给部分读者带来了极大的挑战，将渴求学习的人们挡在了门外。针对这种情况，本书力求理论联系实际，在介绍理论基础的同时，注重机器学习算法的实际运用，让读者更好地明白其中的原理。</p>
<p>准备篇中首先将介绍机器学习的发展及应用前景，使读者产生浓厚的兴趣，同时也将介绍目前常用的科学计算平台和本书将用到的工程计算平台，使读者消除对机器学习的畏难情绪，这些平台的使用也降低了机器学习软件实现的难度。</p>
<p>基础篇将介绍数学知识基础和计算平台应用实例，介绍计算平台的开发基本知识，并应用这些平台实现计算应用。</p>
<p>最后，本书将针对统计分析实战和机器学习实战两个部分帮助读者建立机器学习实战指南，应用计算平台对统计分析及机器学习算法进行实现和应用，同时还会附上效果图，让读者对机器学习的基本应用和理论基础有一个形象的理解。</p>
<h4 id="勘误和支持"><a href="#勘误和支持" class="headerlink" title="勘误和支持"></a>勘误和支持</h4><p>由于作者的水平有限，编写的时间也很仓促，书中难免会出现一些错误或不准确的地方，不妥之处恳请读者批评指正。如果遇到任何问题，或有更多的宝贵意见，欢迎发送邮件至我的邮箱myhaspl@myhaspl.com，很期待能够听到您的真挚反馈。此外，本书的代码及相关资源（包括思考题中涉及的数据等）的下载地址为：<a href="https://yunpan.cn/cYjhBYGLKkKTb" target="_blank" rel="noopener">https://yunpan.cn/cYjhBYGLKkKTb</a><br>（提取码：65ad）。</p>
<h2 id="第1章-机器学习发展及应用前景"><a href="#第1章-机器学习发展及应用前景" class="headerlink" title="第1章 机器学习发展及应用前景"></a>第1章 机器学习发展及应用前景</h2><p>纵观国内软件工程师的发展路线，前期多以程序员（“码农”）、测试工程师、数据库管理员、多媒体技术员、网页与信息技术员等职业为主；中期主要是软件设计师、软件评测师、技术支持师等职业；后期是职业发展的黄金阶段，这一阶段对于拥有丰富技术经验的工程师来说十分重要，但这一阶段容易遭遇到技术发展瓶颈，因此，很多人将目光投向了项目管理和系统架构，比如：系统架构师、项目管理师等。</p>
<p>近年来，国内对机器学习的研究日益深入，应用领域不断扩大，催生了新的IT职位——机器学习工程师，百度、搜狗、阿里巴巴、淘宝、奇虎等国内IT巨头纷纷提出了对机器学习工程师的需求，掌握机器学习的人才成为了各大IT厂商争抢的“香饽饽”。机器学习迅速走红成为热门技术，这给软件工程师带来了绝佳的发展机遇，研究与应用机器学习算法成为了突破技术瓶颈的方式，机器学习工程师、项目管理师和系统架构师并称为后期发展的三大黄金职位。</p>
<h3 id="1-1-机器学习概述"><a href="#1-1-机器学习概述" class="headerlink" title="1.1 机器学习概述"></a>1.1 机器学习概述</h3><p>机器学习作为一门多领域的交叉学科，在近20年里异军突出。机器学习涉及概率论、统计学、微积分、代数学、算法复杂度理论等多门学科。通过可以让计算机自动“学习”的算法来实现人工智能，是人类在人工智能领域展开的积极探索。</p>
<p>2009年，被誉为人工大脑之父的雨果·德·加里斯教授走进清华大学讲堂，在两小时的演讲时间内，给大家描述了一个人工智能的世界：20年后，人工智能机器可以和人类做朋友，50年后，人工智能将成为人类最大的威胁，世界最终会因人工智能超过人类而爆发一场战争，这场智能战争也许会夺去数十亿人的生命。这样的描述并不是幻想，随着人类在人工智能领域取得的进步，这很有可能成为事实。而这一切主要归功于对机器学习的研究和探索。</p>
<h4 id="1-1-1-什么是机器学习"><a href="#1-1-1-什么是机器学习" class="headerlink" title="1.1.1 什么是机器学习"></a>1.1.1 什么是机器学习</h4><p>学习是人类具有的一种重要智能行为。人类一直梦想机器能像人类一样学习，也一直在为这个终极目标努力。那么，什么是机器学习呢？长期以来众说纷纭，Langley（1996）定义机器学习为：“机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”（Machine learning is a science of the artificial.The field’s main objects of study are artifacts，specifically algorithms that improve their performance with experience.）。Mitchell（1997）在《Machine Learning》中写道：“机器学习是计算机算法的研究，并通过经验提高其自动进行改善”（Machine Learning is the study of computer algorithms that improve automatically through experience.）。Alpaydin（2004）提出自己对机器学习的定义：“机器学习是用数据或以往的经验，来优化计算机程序的性能标准”（Machine learning is programming computers to optimize a performance criterion using example data or past experience）。</p>
<p>笔者综合维基百科和百度百科的定义，尝试着将机器学习定义如下：“机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能，它是人工智能的核心，是使计算机具有智能的根本途径。机器学习的研究方法通常是根据生理学、认知科学等对人类学习机理的了解，建立人类学习过程的计算模型或认识模型，发展各种学习理论和学习方法，研究通用的学习算法并进行理论上的分析，建立面向任务的具有特定应用的学习系统。”</p>
<h4 id="1-1-2-机器学习的发展"><a href="#1-1-2-机器学习的发展" class="headerlink" title="1.1.2 机器学习的发展"></a>1.1.2 机器学习的发展</h4><p>早在古代，人类就萌生了制造出智能机器的想法。中国人在4500年前发明的指南车，以及三国时期诸葛亮发明的尽人皆知的木牛流马；日本人在几百年前制造过靠机械装置驱动的玩偶；1770年英国公使给中国皇帝进贡了一个能写“八方向化，九土来王”8个汉字的机器玩偶（这个机器人至今还保存在故宫博物院），等等。这些例子，都只是人类早期对机器学习的一种认识和尝试。</p>
<p>真正的机器学习研究起步较晚，它的发展过程大体上可分为以下4个时期：</p>
<p>第一阶段是在20世纪50年代中叶到20世纪60年代中叶，属于热烈时期。</p>
<p>第二阶段是在20世纪60年代中叶至20世纪70年代中叶，被称为机器学习冷静期。</p>
<p>第三阶段是从20世纪70年代中叶至20世纪80年代中叶，称为机器学习复兴期。</p>
<p>最新的阶段起始于1986年。当时，机器学习综合应用了心理学、生物学和神经生理学以及数学、自动化和计算机科学，并形成了机器学习理论基础，同时还结合各种学习方法取长补短，形成集成学习系统。此外，机器学习与人工智能各种基础问题的统一性观点正在形成，各种学习方法的应用范围不断扩大，同时出现了商业化的机器学习产品，还积极开展了与机器学习有关的学术活动。</p>
<p>近年来，随着全球第三次工业革命的迅猛发展，机器学习在国内外得到了广泛的应用和发展，如今，它已经在各行各业的技术革新中扮演着日益重要的角色，从各方面影响和改变着我们的生活。</p>
<p>2015年8月，Facebook推出了“M”，Facebook认为人类不仅会回答人工智能所不能回答的问题，而且从长远来看，人类也会帮助改善人工智能技术，“M”除了能做到回答问题、查阅信息等基本功能，还可以帮助用户完成如购买商品、餐厅定位、安排旅行计划等操作。</p>
<p>2015年11月，谷歌开源了全新的TensorFlow机器学习系统，该系统更快、更智能、更具有弹性。2015年1月，机器学习平台GraphLab改名为Dato，并获得了1850万美元的新融资（投资方为Vulcan Capital、Opus Capital、New Enterprise Associates、Madrona Venture Group），此前他们曾获得680万美元的融资。</p>
<p>在2015年12月召开的“2015年神经信息处理系统”（NIPS）会议上，微软研究人员和工程师公开了20多篇机器学习最新研究成果的论文。此外，微软还宣布，机器学习正在成为Windows 10的一部分：Skype翻译可以将口语几乎实时地翻译成其他语言，就像《星际迷航》中的通用翻译器那样，可以做到面对面的交流。Cortana个人数字助理在与用户的互动中不断学习与改进，从而帮助用户管理日历、跟踪快递甚至与用户聊天和讲笑话，实现真正的个性化互动体验。Clutter是微软Office 2016的成员，通过学习它可以识别出哪些电子邮件对用户来说最重要，并自动将不重要的邮件重定向到一个单独的文件夹中，从而保持用户收件箱的整洁。</p>
<p>2015年年底，隶属于中国科学院的新松机器人自动化公司生产了智能复合型机器人，这个安装了眼睛和感知器件的智能机器人，可以在车间里自由地行走并十分精确地完成任务，当其他工位人手不足时，接到指令的他还会主动上前帮忙，马上进入角色并开始工作。</p>
<p>百度创造和完善了大规模机器学习的技术，搭建了一个能容纳万亿特征数据的、分钟级别模型更新的、高效训练的点击率预估系统；为进一步深入地发展机器学习技术，百度开始研究如何从“机器学习”到“复制人类大脑”；2016年年初，百度提出，百度的产品和服务都靠机器学习等技术来驱动。</p>
<h4 id="1-1-3-机器学习的未来"><a href="#1-1-3-机器学习的未来" class="headerlink" title="1.1.3 机器学习的未来"></a>1.1.3 机器学习的未来</h4><p>纵观人类文明的发展史，人类已经走过了石器时代、红铜时代、青铜时代、铁器时代、黑暗时代、启蒙时代、蒸汽时代、电气时代、原子时代等时代历程，未来近百年内，人类将从原子时代走向智能时代，而且对于机器学习的未来，人类已经提出了很多构想。</p>
<p>2013年4月的汉诺威工业博览会上，工业4.0战略的概念被首次提出，“工业4.0”是指以智能制造为主导的第四次工业革命，或者革命性的生产方法。该战略旨在通过充分利用信息通信技术和网络空间虚拟系统与信息物理系统相结合的手段，将制造业向智能化转型。根据机器学习等智能技术的未来发展趋势，工业4.0主要包括智能工厂（重点研究智能化生产系统及过程，以及网络化分布式生产设施的实现）、智能生产（主要涉及整个企业的生产物流管理、人机互动，以及3D技术在工业生产过程中的应用等）、智能物流（主要通过互联网、物联网、物流网，整合物流资源，充分发挥现有物流的效率）等应用。</p>
<p>2015年9月，美军军队医疗中心指挥官少将Steve Jones在美军陆军的一次会议上发言表示，未来可以让智能机器人代替人类上战场运送伤员，美国军方甚至高调宣布：未来战场上机器人救起的可能不是人，而是机器人，因为智能机器人军团将代替人类出征。</p>
<p>在21世纪以前，“人工智能大爆炸”的设想似乎还只是科幻小说家杞人忧天的幻想。到了今天，有越来越多的人开始严肃地思考一个问题：当技术奇点到来的时候，人类将会怎样？2009年，Kurzweil与X-Prize创始人Peter Diamandis共同建立了奇点大学（Singularity University），致力于“聚集、教育并激励一批核心的领导者，以应对人类在指数级增长的科技下遭遇到的重要挑战”，人类保卫战似乎已经迫在眉睫。这所大学由谷歌、欧特克、美国基因技术公司等联合支持创建，共有三个项目，覆盖范围包括机器人学、医学、生物科技、数据科学和企业管理等。</p>
<p>云计算带来了强大的运算能力，大数据算法也得到了广泛应用，虽然它们还不足以使计算机变得更智能，但它们创造了强人工智能产生的必要条件——大数据使得机器能够从海量的信息中进行学习，云计算拥有廉价且强大的接近人脑的运算能力。</p>
<p>在不久的将来，机器学习将走向强人工智能时代，将出现真正的能推理和解决问题的智能机器，这些机器将有知觉和自我意识，智能水平与人类相当。</p>
<h3 id="1-2-机器学习应用前景"><a href="#1-2-机器学习应用前景" class="headerlink" title="1.2 机器学习应用前景"></a>1.2 机器学习应用前景</h3><p>机器学习应用广泛，无论是在军事领域还是民用领域，都有机器学习算法施展的机会。</p>
<h4 id="1-2-1-数据分析与挖掘"><a href="#1-2-1-数据分析与挖掘" class="headerlink" title="1.2.1 数据分析与挖掘"></a>1.2.1 数据分析与挖掘</h4><p>“数据挖掘”和“数据分析”通常被相提并论，并在许多场合被认为是可以相互替代的术语。关于数据挖掘，现在已有多种文字不同但含义接近的定义，例如“识别出巨量数据中有效的、新颖的、潜在有用的、最终可理解的模式的非平凡过程”；百度百科将数据分析定义为：“数据分析是指用适当的统计方法对收集来的大量第一手资料和第二手资料进行分析，以求最大化地开发数据资料的功能，发挥数据的作用，它是为了提取有用信息和形成结论而对数据加以详细研究和概括总结的过程。”无论是数据分析还是数据挖掘，都是帮助人们收集、分析数据，使之成为信息，并作出判断，因此可以将这两项合称为“数据分析与挖掘”。</p>
<p>数据分析与挖掘技术是机器学习算法和数据存取技术的结合，利用机器学习提供的统计分析、知识发现等手段分析海量数据，同时利用数据存取机制实现数据的高效读写。机器学习在数据分析与挖掘领域中拥有无可取代的地位，2012年Hadoop进军机器学习领域就是一个很好的例子。</p>
<p>2012年，Cloudera收购Myrrix共创Big Learning，从此，机器学习俱乐部多了一名新会员。Hadoop和便宜的硬件使得大数据分析更加容易，随着硬盘和CPU越来越便宜，以及开源数据库和计算框架的成熟，创业公司甚至个人都可以进行TB级以上的复杂计算。Myrrix从Apache Mahout项目演变而来，是一个基于机器学习的实时可扩展的集群和推荐系统。</p>
<p>其他大公司也纷纷采用机器学习技术分析数据，以提高其产品和服务的质量。微软官方正式启动Azure机器学习平台，并已经在Xbox和Bing中使用，它能够支持R、Python、Hadoop、Spark等语言。福特用AI安排工作进度，通过AI解决其因员工日益增多而带来的工作安排问题。谷歌将大型机器学习技术应用于药物发现，将神经网络的深度学习应用于虚拟药物筛选，主要是试图替换或提高高通量筛选过程中的计算方法。雅虎使用机器学习算法挖掘160亿邮件数据，实验室的研究人员研究了两百万人之间的160亿封邮件，以分析用户的行为习惯。PayPal使用机器学习来打击诈骗，通过机器学习和统计模型来识别诈骗行为，将更复杂的算法用于过滤交易。AWS向欧洲开发商开放机器学习服务，可以通过AWS Dublin区域使用该服务，公司期望亚马逊的机器学习能够帮助解决限制问题，所有的分析和预测均通过在欧洲的数据完成，并且从不离开这个区域。</p>
<h4 id="1-2-2-模式识别"><a href="#1-2-2-模式识别" class="headerlink" title="1.2.2 模式识别"></a>1.2.2 模式识别</h4><p>模式识别起源于工程领域，而机器学习起源于计算机科学，这两个不同学科的结合带来了模式识别领域的调整和发展。模式识别研究主要集中在两个方面：一是研究生物体（包括人）是如何感知对象的，属于认识科学的范畴；二是在给定的任务下，如何用计算机实现模式识别的理论和方法，这些是机器学习的长项，也是机器学习研究的内容之一。</p>
<p>模式识别的应用领域广泛，包括计算机视觉、医学图像分析、光学文字识别、自然语言处理、语音识别、手写识别、生物特征识别、文件分类、搜索引擎等，而这些领域也正是机器学习的大展身手的舞台，因此模式识别与机器学习的关系越来越密切，以至于国外很多书籍把模式识别与机器学习综合在一本书里讲述。</p>
<h4 id="1-2-3-更广阔的领域"><a href="#1-2-3-更广阔的领域" class="headerlink" title="1.2.3 更广阔的领域"></a>1.2.3 更广阔的领域</h4><p>2015年是机器学习年，用机器学习改造人类社会的革命时代已经来临。不但谷歌、亚马逊、埃森哲、丰田、特斯拉、美国强生等大公司都在大规模地采用机器学习技术，而且，创业公司也加入了这场机器学习的革命，并拥有和大公司同等的地位。创业公司已经公布了机器学习的创新型应用，投资商对机器学习创业公司表示出浓厚的兴趣。已经有超过170家创业公司进入AI浪潮，谷歌、IBM等大型科技公司并对AI投入重金。</p>
<p>机器学习技术在全球各行各业的应用已经进入井喷时期，相关新闻比比皆是。Google DeepMind研究人员已经成功让计算机通过机器学习成为Atari视频游戏的大师。谷歌与美国强生合作发展的AI手术机器人，能够帮助外科医生减少对病人的伤害。Facebook开发了人工智能测试，能够判断AI的智能程度。Dato也加入了机器学习创业洪流，机器学习平台GraphLab（GraphLab是一个开源项目，旨在帮助机器分析图像，如社交关系图）改名Dato，获得了1850万美元的新融资。微软已经为“小娜”构建了聊天机制，机器学习使得“小娜”不仅能够识别玩笑并能预测运动赛事，还能够告诉你早点去开会（比如因为交通堵塞）。英特尔的18核Xeon芯片为机器学习专门做了调整，为快速变化的服务市场设计了E7芯片，该公司宣称，新的芯片在运作企业应用时要快6倍。Airbnb公布了机器学习包Aerosolve，Airbnb相信人与机器以共生的方式进行合作的效率会比只有人或机器高，这个包的设计本质是追求人性化。机器学习也进入了Gartner的2015 Hype Cycle报告，Hype Cycle只展示数字人文主义的技术并且它主要展示Gartner认为有重大影响的技术，而机器学习是报告中第一个出现的技术。</p>
<h3 id="1-3-小结"><a href="#1-3-小结" class="headerlink" title="1.3 小结"></a>1.3 小结</h3><p>机器学习作为一门多领域交叉学科，该领域的主要研究对象是人工智能，专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构，使之不断改善自身的性能，它是人工智能的核心，是使计算机具有智能的根本途径。</p>
<p>近年来，机器学习的研究与应用在国内外越来越重视。机器学习已经广泛应用于语音识别、图像识别、数据挖掘等领域。大数据时代的到来，使机器学习有了新的应用领域，从包含设备维护、借贷申请、金融交易、医疗记录、广告点击、用户消费、客户网络行为等数据中发现有价值的信息已经成为其研究与应用的热点。</p>
<p>我们以记者与雨果·德·加里斯教授的部分专访内容来结束这一章。</p>
<p>记者：为什么选择这个研究工作？</p>
<p>雨果·德·加里斯：对人类大脑的好奇心和人脑的想象力的好奇心。人类只是一个个分子构成的机器，像计算机的芯片一样，像编制程序一样。另一方面，作为生物人都会死亡消失的，但人工智能机器就不会。所以说，这个研究就像制造神一样。</p>
<p>当人类促使技术进步，让具有人工智能的机器人得以诞生和发展，但总有一天人工智能机器会实现自己进化，当这种技术达到一个奇点的时候，就不需要人类来推动了。比人类聪明得多的人工智能机器将在以年为单位的短时间里产生。</p>
<p>记者：预测一下未来人工智能机器的前景。</p>
<p>雨果·德·加里斯：下一个20年，它们很有可能出现在我们的家里，为我们打扫房间，照顾小孩，和我们聊天，给我们来自地球上知识库里面的无限知识。我们还将可以和它们有性关系，被它们教育，从它们那里得到娱乐和开怀大笑。20年后的大脑制造业，每年全球范围内将可能创造万亿美元的价值。人工智能机器有比我们聪明万亿倍的可能性，不夸张地说，人工智能机器和人类交流，就像人类试图和岩石交流一样艰难。不过，真正的人工智能在我死后的三四十年内不会被制造出来。我活着看不到工作的真正结果，这是让我沮丧和失望的一个根源。</p>
<h2 id="第2章-科学计算平台"><a href="#第2章-科学计算平台" class="headerlink" title="第2章 科学计算平台"></a>第2章 科学计算平台</h2><p>机器学习算法具有坚实的数学理论支持，机器学习的应用建立在科学计算的基础上，而数学计算又是科学计算的主要组成部分。计算机技术的飞速发展和计算数学方法及理论的日益成熟，使解决复杂的数学计算问题成为可能。这些问题在以前用一般的计算工具来解决非常困难，而现在用计算机来处理却非常容易。目前用计算机处理得较多的数学计算主要分为以下两类：</p>
<p>第一类是数值计算，它以数值数组作为运算对象，给出数值解；计算过程中可能会产生误差累积问题，影响了计算结果的精确性；计算速度快，占用资源少。</p>
<p>第二类是符号计算，它以符号对象和符号表达式作为运算对象，给出解析解；运算不受计算误差累积问题的影响；计算指令简单；占用资源多，计算耗时长。</p>
<p>数值计算方法成为了科学计算的重要手段，它研究怎样利用计算工具来求出数学问题的数值解。数值计算方法的计算对象是微积分、线性代数、插值与逼近及最小二乘拟合、数值积分与数值微分、矩阵的特征值与特征向量求解、线性方程组与非线性方程求根，以及微分方程数值解法等数学问题，这些是模式识别、数据分析及自动制造等机器学习领域需要应用的数学。</p>
<p>符号计算是专家系统等机器学习领域需要应用的数学，在符号计算中，计算机处理的数据和得到的结果都是符号。符号既可以是字母和公式，也可以是数值，其运算以推理解析的方式进行，不受计算误差积累问题困扰，计算结果为完全正确的封闭解或任意精度的数值解，这意味着符号计算给出的结果能避免因舍入误差而引起的问题。还有更多的数学分支正在进入机器学习领域，复杂的数学计算需要强大的科学计算平台。科学计算平台提供了机器学习算法应用的底层支持。</p>
<h3 id="2-1-科学计算软件平台概述"><a href="#2-1-科学计算软件平台概述" class="headerlink" title="2.1 科学计算软件平台概述"></a>2.1 科学计算软件平台概述</h3><p>现代科学研究的方法主要有三种：理论论证、科学实验、科学计算。近年来，科学计算方法逐步成为科学研究的主流方法，在金融工程、信息检索、基因研究、环境模拟、数值计算、数据分析、决策支持等领域得到了广泛使用。由于计算机技术的发展及其在各技术科学领域的应用推广与深化，这些应用领域不论其背景与含义如何，都要用计算机进行科学计算，都必须建立相应的数学模型，并研究其适合于计算机编程的计算方法。科学计算平台已经成为科学研究必要的基础条件平台，有力地推动了科学研究的发展和工程技术的进步。</p>
<p>机器学习应用需要科学计算的支持。大部分科学计算应用的领域都需要用到机器学习算法，科学计算平台与机器学习之间的关系就像鱼与水的关系。现代机器学习研究与应用早已经离不开科学计算平台的支撑，科学计算平台也因为机器学习的迅猛发展而进入了全新的百家争鸣时代。</p>
<h4 id="2-1-1-常用的科学计算软件"><a href="#2-1-1-常用的科学计算软件" class="headerlink" title="2.1.1 常用的科学计算软件"></a>2.1.1 常用的科学计算软件</h4><p>目前常用的科学计算软件有以下几种：</p>
<p>1.MATLAB</p>
<p>MATLAB是一种用于数值计算、可视化及编程的高级语言和交互式环境。使用MATLAB，可以分析数据、开发算法、创建模型和应用程序，通过矩阵运算、绘制函数和数据、实现算法、创建用户界面、连接其他编程语言等方式完成计算，比电子表格或传统编程语言（如C/C++或Java）更方便快捷。MATLAB具有强大的数值计算功能，可完成矩阵分析、线性代数、多元函数分析、数值微积分、方程求解、边值问题求解、数理统计等常见的数值计算，同时它也能进行符号计算。</p>
<p>2.GNU Octave</p>
<p>GNU Octave与MATLAB相似，它是自由软件基金会开发的一个自由再发布软件，以John W.Eaton为首的一些志愿者共同开发了叫作GNU Octave的高级语言，这种语言与MATLAB兼容，主要用于数值计算，同时它还提供了一个方便的命令行方式，可以数值求解线性和非线性问题，以及做一些数值模拟。</p>
<p>3.Mathematica</p>
<p>Mathematica系统是美国Wolfram研究公司开发的一个功能强大的计算机数学系统。它提供了范围广泛的数学计算功能，支持在各个领域工作的人们做科学研究的过程中的各种计算。这个系统是一个集成化的计算机软件系统，它的主要功能包括符号演算、数值计算和图形三个方面，可以帮助人们解决各种领域里比较复杂的符号计算和数值计算的理论和实际问题。</p>
<p>4.Maple</p>
<p>1980年9月，加拿大滑铁卢大学的符号计算研究小组研制出一种计算机代数系统，取名为Maple，如今Maple已演变成为优秀的数学软件，它具有良好的使用环境、强有力的符号计算能力、高精度的数字计算、灵活的图形显示和高效的可编程功能。Maple在符号计算方面功能强大，符号计算式可以直接以数学的形式来输入和输出，直观方便。</p>
<p>5.SPSS</p>
<p>SPSS预测分析是IBM公司的产品，它提供了统计分析、数据和文本挖掘、预测模型和决策优化等功能。IBM宣称，使用SPSS可获得5大优势：商业智能，利用强大而简单的分析功能，控制数据爆炸，满足组织灵活部署商业智能的需求，提升用户期望值；绩效管理，指导管理战略，使其朝着最能盈利的方向发展，并提供及时准确的数据、场景建模、浅显易懂的报告等；预测分析，通过发现细微的模式关联，开发和部署预测模型，以优化决策制定；分析决策管理，一线业务员工可利用该系统，与每位客户进行互动，从中获取丰富信息，提高业务成绩；风险管理，在合理的前提下，利用智能的风险管理程序和技术，制定规避风险的决策。</p>
<p>6.R</p>
<p>R语言是主要用于统计分析、绘图的语言和操作环境。R目前由“R开发核心团队”负责开发，它是基于S语言的一个GNU项目，语法来自Scheme，所以也可以当作S语言的一种实现，虽然R主要用于统计分析或者开发统计相关的软件，但也可用作矩阵计算，其分析速度堪比GNU Octave甚至MATLAB。R主要是以命令行操作，网上也有几种图形用户界面可供下载。R内建多种统计学及数字分析功能，还能透过安装套件（Packages）增强。</p>
<p>7.NumPy、SciPy、matplotlib等Python科学计算平台</p>
<p>Python是一种面向对象的、动态的程序设计语言，它具有非常简洁而清晰的语法，既可以用于快速开发程序脚本，也可以用于开发大规模的软件，特别适合于完成各种高层任务。随着NumPy、SciPy、matplotlib等众多程序库的开发，Python越来越适合用于科学计算。NumPy是一个基础科学的计算包，包括：一个强大的N维数组对象封装了C++和Fortran代码的工具、线性代数、傅立叶转换和随机数生成函数等其他复杂功能的计算包。SciPy是一个开源的数学、科学和工程计算包，能完成最优化、线性代数、积分、插值、特殊函数、快速傅里叶变换、信号处理和图像处理、常微分方程求解等计算。matplotlib是Python最著名的绘图库，它提供了一整套和MATLAB相似的命令API，十分适合交互式制图，它也可以方便地用作绘图控件，嵌入GUI应用程序中。</p>
<h4 id="2-1-2-本书使用的工程计算平台"><a href="#2-1-2-本书使用的工程计算平台" class="headerlink" title="2.1.2 本书使用的工程计算平台"></a>2.1.2 本书使用的工程计算平台</h4><p>MATLAB、Mathematica、Maple、SPSS等软件功能齐全、界面友好，同时内含多种强大的软件包，但价格昂贵，它们都是商业化软件，GNU Octave、R和Python科学计算包作为开源免费的工程计算平台，会是不错的选择。</p>
<p>本书选择R和Python科学计算包作为工程计算平台，Python和R都能在多种操作系统平台上运行。Python是一种非常流行的脚本语言，用户较多，容易掌握，也有成熟并行计算框架dispy等，测试成功的单机机器学习算法稍加修改就能应用于大规模分布式计算的工程之中。正是因为Python具有如此之多的优点，Google内部也经常使用它。R语言内置大量统计分析包，能访问部分系统函数，核心为解释执行的语言，大部分用户可见的R函数由R语言本身编写，出于效率原理，计算密集型任务通过在运行时链接与调用C、C++、FORTRAN代码完成。此外，通过Rcpp能把丰富的R环境与C/C++等结合，将R的API与数据对象封装成类以及类的方法，供外部C++程序调用。</p>
<h3 id="2-2-计算平台的配置"><a href="#2-2-计算平台的配置" class="headerlink" title="2.2 计算平台的配置"></a>2.2 计算平台的配置</h3><p>本章将以Windows平台和Linux平台为例，讲解R和Python科学计算平台的配置。Python和R具有跨平台运行的特点，Windows平台编写的Python和R代码只需修正兼容性问题即可正常运行在类UNIX平台上，如：中文字符的UTF8与GBK转换、Windows系统与类UNIX平台的文件路径差异等。</p>
<h4 id="2-2-1-Numpy等Python科学计算包的安装与配置"><a href="#2-2-1-Numpy等Python科学计算包的安装与配置" class="headerlink" title="2.2.1 Numpy等Python科学计算包的安装与配置"></a>2.2.1 Numpy等Python科学计算包的安装与配置</h4><p>Python科学计算包有两种安装方式，即：分别安装科学计算平台内的软件包和安装WinPython集成计算包。如果是开发环境，建议使用WinPython。</p>
<p>1.分别安装科学计算平台内的软件包</p>
<p>先安装Python，关于它的版本，推荐使用2.7版本，然后安装NumPy、SciPy、matplotlib等Python软件包，它们都有Windows系统下的安装包。</p>
<p>Python安装包的下载页面为<a href="http://www.python.org/download/" target="_blank" rel="noopener">http://www.python.org/download/</a> ，选择2.7版本的Windows安装可执行文件下载即可。</p>
<p>NumPy安装包下载页面为<a href="https://pypi.python.org/pypi/numpy" target="_blank" rel="noopener">https://pypi.python.org/pypi/numpy</a> ，下载Windows版本的安装可执行文件即可。</p>
<p>SciPy安装包下载页面为<a href="https://pypi.python.org/pypi/scipy/" target="_blank" rel="noopener">https://pypi.python.org/pypi/scipy/</a> ，该软件包目前没有Windows版本的安装执行文件，要用传统的Python安装第三方软件包的方式安装，将安装包下载解压，然后在命令行进入解压目录，输入以下命令：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

</details>

<p>Matplotlib软件包的下载页面为<a href="http://matplotlib.org/downloads.html" target="_blank" rel="noopener">http://matplotlib.org/downloads.html</a> ，下载Windows版本的安装可执行文件即可，注意应下载Latest stable version对应的软件包。Windows版本的安装可执行文件通常命名格式为：产品名称+平台名称+CPU型号+版本号。以Matplotlib为例，打开其下载页面，如图2-1所示。</p>
<p><img src="Image00000.jpg" alt></p>
<p>图2-1 Matplotlib下载页面</p>
<p>假设计算机的操作系统是32位，Python版本号为2.7，则下载安装matplotlib-1.3.0.win32-py2.7.exe，如果操作系统是64位的，Python版本号为2.7，则下载安装matplotlib-1.3.0.win-amd64-py2.7.exe。</p>
<p>在类UNIX平台上（以UBUNTU为例），可使用下面的命令安装Python及相关科学计算包：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose</span><br></pre></td></tr></table></figure>

</details>

<p>2.安装WinPython集成计算包</p>
<p>WinPython集成计算包集成了Numpy等第三方Python科学计算库，在winpython.sourceforge.net下载并安装WinPython后，Numpy等计算库和Python 2.7会一同被安装。此外，WinPython附带一款非常不错的IDE开发调试环境：Spyder，如图2-2所示是Spyder的界面截图。</p>
<p><img src="Image00001.jpg" alt></p>
<p>图2-2 Spyder界面</p>
<p>在图2-2所示的界面中，右上角是类似于MATLAB的“工作空间”，可很方便地观察和修改变量（包含多维数组）的值，同时还拥有方便用户的智能代码（Call-Tips和Auto-Complete）功能，如图2-3所示。</p>
<p>在IDE开发窗口下方的Console栏可以使用pdb（类似于C语言的GDB调试工具）调试Python代码，也可以通过Spyder的调试菜单进行调试。下面是pdb调试工具的使用帮助：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; debugfile(r&apos;K:\book_prog\zxecf.py&apos;，</span><br><span class="line"></span><br><span class="line"> wdir=r&apos;K:\book_prog&apos;)</span><br><span class="line">&gt; k:\book_prog\zxecf.py(7)&lt;module&gt;()</span><br><span class="line">-&gt; import matplotlib.pyplot as plt</span><br><span class="line">(pdb) help</span><br><span class="line">Documented commands (type help &lt;topic&gt;):</span><br><span class="line">========================================</span><br><span class="line">EOF    bt         cont      enable  jump  pp       run      unt   </span><br><span class="line">a      c          continue  exit    l     q        s        until</span><br><span class="line">alias  cl         d         h       list  quit     step     up    </span><br><span class="line">args   clear      debug     help    n     r        tbreak   w     </span><br><span class="line">b      commands   disable   ignore  next  restart  u        whatis</span><br><span class="line">break  condition  down      j       p     return   unalias  where</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00002.jpg" alt></p>
<p>图2-3 智能代码功能</p>
<p>常用的pdb调试命令如下：</p>
<p>·h(elp)：打印当前版本pdb可用的命令。</p>
<p>·disable/enable：禁用/启用断点。</p>
<p>·n(ext)：让程序运行下一行。</p>
<p>·c(ont(inue))：让程序正常运行，直到遇到断点。</p>
<p>·j(ump)：让程序跳转到指定的行数。</p>
<p>·b(reak)：设置断点，例如“b 23”，就是在当前脚本的23行打上断点，函数名也可作为参数。</p>
<p>·condition：设置条件断点。下面语句就是对第5个断点加上条件x&gt;=8：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(Pdb) condition 5 x&gt;=8</span><br></pre></td></tr></table></figure>

</details>

<p>·cl(ear)：清除指定参数的断点或所有断点。</p>
<p>·p：打印某个变量。比如：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(Pdb) p _file</span><br><span class="line">u’</span><br><span class="line"></span><br><span class="line">./pic/dog.jpg’</span><br></pre></td></tr></table></figure>

</details>

<p>·！：感叹号后面跟着语句，可以直接改变某个变量。</p>
<p>·q(uit)：退出调试。</p>
<p>综上所述，在Spyder的帮助下，能更高效地开发与调试Python代码，因此笔者推荐在开发环境中安装WinPython，方便快捷，有利于机器学习算法代码的编写。此外，安装好WinPython后，请在windows操作系统的“开始→程序→WinPython→WinPython Control Panel”中进行注册。</p>
<h4 id="2-2-2-OpenCV安装与配置"><a href="#2-2-2-OpenCV安装与配置" class="headerlink" title="2.2.2 OpenCV安装与配置"></a>2.2.2 OpenCV安装与配置</h4><p>OpenCV是Intel开源计算机视觉库，它由一系列C函数和少量C++类构成，实现了图像处理和计算机视觉方面的很多通用算法。OpenCV拥有包括300多个C函数的跨平台的中高层API。它不依赖于其他的外部库（尽管也可以使用某些外部库），对工程应用来说，OpenCV是一个非常好的计算平台，因为它遵守BSD开源协议，对非商业应用和商业应用都是免费。</p>
<p>OpenCV的主要功能有：图像数据操作，图像/视频的输入输出，矩阵/向量数据操作及线性代数运算，支持多种动态数据结构、基本图像处理、结构分析、摄像头定标、运动分析、目标识别、基本的GUI和图像标注。而且，OpenCV提供了官方的Python接口，其使用方法和C语言接口基本一致，只是一些函数和结构体可能会有不同。另外，函数通过参数来返回值时一次会返回多个值。</p>
<p>在Windows上下载安装OpenCV的可执行文件后可直接运行，下载页面为<a href="http://opencv.org/downloads.html" target="_blank" rel="noopener">http://opencv.org/downloads.html</a> 。</p>
<p>其在Linux平台上的安装方式在OpenCV官网上有介绍，具体安装顺序如下：</p>
<p>1）安装基本软件包。GCC 4.4.x或更高版本、CMake或更高版本、Git、GTK+2.x或更高版本、including headers(libgtk2.0-dev)、pkgconfig、Python 2.6或更高版本、Numpy 1.5或更高版本、python-dev、python-numpy、ffmpeg或libav开发包、ibavcodec-dev、libavformat-dev、libswscale-dev。</p>
<p>2）安装可选软件包。libdc13942.x、libjpeg-dev、libpng-dev、libtiff-dev、libjasper-dev。</p>
<p>3）在<a href="http://opencv.org/downloads.html" target="_blank" rel="noopener">http://opencv.org/downloads.html</a> 下载其源代码，解压后，进入目录以源代码编译方式安装OpenCV。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$cd ~/opencv</span><br><span class="line">$mkdir release</span><br><span class="line">$cd release</span><br><span class="line">$cmake -D CMAKE_BUILD_TYPE=RELEASE -D  CMAKE_INSTALL_PREFIX=/usr/local ..</span><br><span class="line">$make</span><br><span class="line">$sudo make install</span><br></pre></td></tr></table></figure>

</details>

<p>OpenCV官方提供了Python绑定库，以Python2.7为例讲述了安装绑定库的方法，在Windows下，将它复制到Python的目录下，将opencv\build\python\2.7下的cv2.pyd文件复制到python-2.7.5\Lib\site-packages目录下即可。在Linux下安装了Python后，要确保usr/lib/python2.7/site-packages下有cv.py和cv2.so文件，如果没有，将这两个文件复制过来即可。</p>
<h4 id="2-2-3-mlpy安装与配置"><a href="#2-2-3-mlpy安装与配置" class="headerlink" title="2.2.3 mlpy安装与配置"></a>2.2.3 mlpy安装与配置</h4><p>mlpy是基于NumPy/SciPy和GSL构建的Python模块，它提供了高层函数和类，允许使用少量代码来完成复杂的分类、特征提取、回归、聚类等任务。mply为免费软件，建立在GPL3开源协议之上。</p>
<p>mlpy在Windows下的安装方式较简单，可以直接在下面网址下载可执行文件安装：</p>
<p><a href="http://sourceforge.net/projects/mlpy/files/" target="_blank" rel="noopener">http://sourceforge.net/projects/mlpy/files/</a>  </p>
<p>在类Linux平台上，其安装方法稍稍复杂一些，以Linux、OSX和FreeBSD为例，安装配置mlpy，需要先安装配置好以下软件：</p>
<p>·GCC</p>
<p>·Python且版本&gt;=2.6或为3.X</p>
<p>·NumPy且版本&gt;=1.3.0</p>
<p>·SciPy且版本&gt;=0.7.0</p>
<p>·GSL且版本&gt;=1.11</p>
<p>然后，在上面网址中找到mlpy源代码包下载，并解压安装。假设GSL头文件和库文件没有安装在系统的标准位置，在这种情况下，mply的安装方式如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$python setup.py build_ext --include-dirs=/path/to/header --rpath=/path/to/lib</span><br><span class="line">$python setup.py install</span><br></pre></td></tr></table></figure>

</details>

<p>如果GSL安装在标准位置，则只需要运行上述命令中的最后一行。</p>
<h4 id="2-2-4-BeautifulSoup安装与配置"><a href="#2-2-4-BeautifulSoup安装与配置" class="headerlink" title="2.2.4 BeautifulSoup安装与配置"></a>2.2.4 BeautifulSoup安装与配置</h4><p>BeautifulSoup是用Python写的一个HTML/XML的解析器，它可以很好地处理不规范标记，并生成剖析树，通常用来分析“爬虫”抓取的Web文档，或者直接充当部分“爬虫”的角色。对于不规则的HTML文档，有补全功能。有了它，解析与分类网页就方便多了，节省了开发者的很多时间和精力。</p>
<p>安装BeautifulSoup很简单，在Windows平台和Linux平台上都是使用的传统第三方库安装方式。首先下载BeautifulSoup源码，其官网为：<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener">http://www.crummy.com/software/BeautifulSoup/</a> 。</p>
<p>然后解压后运行以下命令：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

</details>

<p>此外，在UBUNTU下还可以使用系统包管理器安装。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install python-bs4</span><br></pre></td></tr></table></figure>

</details>

<h4 id="2-2-5-Neurolab安装与配置"><a href="#2-2-5-Neurolab安装与配置" class="headerlink" title="2.2.5 Neurolab安装与配置"></a>2.2.5 Neurolab安装与配置</h4><p>NeuroLab是一个简单而强大的、用Python编写的神经网络库，包括基础神经网络、训练算法，并具有弹性的构架，可创建其他网络，它用纯Python和numpy写成。API的使用与MATLAB的神经网络工具箱类似，具有弹性的网络配置和学习算法，可以改变神经网络和学习算法的类型、训练、误差、初始函数和激活函数等神经网络参数。</p>
<p>Windows和Linux下的安装方式如下。</p>
<p>首先在下面的页面下载Neurolab：</p>
<p><a href="http://code.google.com/p/neurolab/downloads/list" target="_blank" rel="noopener">http://code.google.com/p/neurolab/downloads/list</a>  </p>
<p>然后解压后运行如下命令：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

</details>

<h4 id="2-2-6-R安装与配置"><a href="#2-2-6-R安装与配置" class="headerlink" title="2.2.6 R安装与配置"></a>2.2.6 R安装与配置</h4><p>R的原始码可自由下载使用，也有已编译的执行档版本可以下载，可在多种平台下运行，包括类UNIX（包含FreeBSD和Linux）、Windows和MacOS。</p>
<p>WINDOWS安装方式如下。</p>
<p>首先访问其官网下载页面：</p>
<p><a href="http://ftp.ctex.org/mirrors/CRAN/" target="_blank" rel="noopener">http://ftp.ctex.org/mirrors/CRAN/</a>  </p>
<p>然后下载安装可执行文件安装即可。</p>
<p>UBUNTU下的安装方式如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$  sudo apt-get update</span><br><span class="line">$  sudo apt-get install r-base</span><br><span class="line">$  sudo apt-get install r-base-dev</span><br></pre></td></tr></table></figure>

</details>

<h3 id="2-3-小结"><a href="#2-3-小结" class="headerlink" title="2.3 小结"></a>2.3 小结</h3><p>“不要重复造轮子”（Stop Trying to Reinvent the Wheel），这可能是每个软件工程师入行时被告知的第一条准则。在轮子适合“机器学习”这台车的情况下，机器学习算法才能跑得更好，适合的科学计算平台就是机器学习的“轮子”。</p>
<p>笔者认为，作为机器学习这驾马车的“轮子”应该具备以下特征：</p>
<p>·开源免费，且开源协议友好，例如：LGPL协议或BSD协议，这样更有利于商业应用。</p>
<p>·平台有文档，接口规范，能实际代码用例最好。</p>
<p>·配置简单灵活，支持的操作系统平台多，运行速度快。</p>
<p>·代码结构清晰、简单，便于使用者修改这个“轮子”，通俗地说：移植性强。</p>
<p>本书采用的计算平台在本章都一一列出其安装和配置方法。算法是一种计算思维的描述，万变不离其宗，好的工具原理都差不多。</p>
<p>也许随着时间的推移，算法在改进，更好的“轮子”将出现，所以不一定采用本书上所写的这些平台作为机器学习实验和应用的工具，但有一条原则：功能强大的计算平台不一定适合所有的工程，一切以适用为准。</p>
<h1 id="第二部分-基础篇"><a href="#第二部分-基础篇" class="headerlink" title="第二部分 基础篇"></a>第二部分 基础篇</h1><p>合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下。</p>
<p>——老子</p>
<h2 id="第3章-计算平台应用实例"><a href="#第3章-计算平台应用实例" class="headerlink" title="第3章 计算平台应用实例"></a>第3章 计算平台应用实例</h2><h3 id="3-1-Python计算平台简介及应用实例"><a href="#3-1-Python计算平台简介及应用实例" class="headerlink" title="3.1 Python计算平台简介及应用实例"></a>3.1 Python计算平台简介及应用实例</h3><p>目前，科学计算平台很多，在本书中，使用Python编写的机器学习算法用到的计算平台有：Numpy等科学计算包、OpenCV的Python绑定库、mlpy机器学习库、BeautifulSoup网页解析库、Neurolab神经网络库等，所有平台均为开源免费软件。本章将讲解这些计算平台的操作，并解析一些基础实例应用。</p>
<h4 id="3-1-1-Python语言基础"><a href="#3-1-1-Python语言基础" class="headerlink" title="3.1.1 Python语言基础"></a>3.1.1 Python语言基础</h4><p>1989年圣诞节期间，吉多·范罗苏姆为了打发假日时间，决心开发一个新的脚本解释程序，作为ABC语言的一种继承，就这样，Python在吉多手中诞生了。Python的设计哲学是优雅、明确、简单。Python提供了丰富的API和工具，使程序员能使用C语言、C++、Cython编写扩充模块。Python编译器本身也可以被集成到其他需要脚本语言的程序中。此外，很多人把Python作为一种“胶水语言”使用，用它将其他语言编写的程序进行集成和封装。</p>
<p>Python包含了一组完善而且容易理解的标准库，能够轻松地完成很多常见的任务，且代码语法简洁、清晰，使用缩进定义语句块，具备很高的可读性。由于Python语言具有简洁、易读以及可扩展性，在国内外用Python做科学计算的研究机构、商业公司日益增多，比如：三大经典科学计算库Numpy、SciPy和matplotlib均扩展了Python，通过Python可以轻松完成快速数组处理、数值运算和绘图任务。</p>
<p>1.Python基本数据类型</p>
<p>Python是解释运行的动态语言，解释器的提示符为“&gt;&gt;&gt;”。Python的基本数据类型包括数字型、字符串型和列表，此外还可以用类型表示函数、模块、类型本身、对象的方法、编译后的Python代码、运行时信息等。</p>
<p>1）数字型，可将Python作为一个计算器使用，在计算过程中可使用“+”（加）、“-”（减）、“*”（乘）、“/”（除）、“（”、“）”以及“%”（取余）等操作符。此外，Python用“#”表示其后的内容是注释。下面代码演示了其基本的计算功能和注释的使用。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 2+2</span><br><span class="line">4</span><br><span class="line">&gt;&gt;&gt; # 本行是注释</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">... 2+8</span><br><span class="line">10</span><br><span class="line">&gt;&gt;&gt; (50-5*6)/2</span><br><span class="line">10</span><br><span class="line">&gt;&gt;&gt; 17/-4</span><br><span class="line">-5</span><br><span class="line">&gt;&gt;&gt; 9%2</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

</details>

<p>Python使用“=”进行赋值操作，赋值操作不会返回任何结果，也可以在同一行中连接赋值，赋值语句将从右到左依次完成赋值。下面的代码对变量进行复数和实数的赋值。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c=5.2-6.5j###复数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">(5.2-6.5j)</span><br><span class="line">&gt;&gt;&gt; c.real###实部</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">5.2</span><br><span class="line">&gt;&gt;&gt; c.imag###虚部</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-6.5</span><br><span class="line">&gt;&gt;&gt;x = y = z = 0</span><br></pre></td></tr></table></figure>

</details>

<p>变量在使用前，要处于定义状态（即已经赋值），否则会出错。下面代码试图对未定义的变量myx进行操作结果出错了。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; myx  # 访问未定义的变量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;，</span><br><span class="line"></span><br><span class="line"> line 1，</span><br><span class="line"></span><br><span class="line"> in &lt;module&gt;</span><br><span class="line">NameError: name &apos;myx&apos; is not defined</span><br></pre></td></tr></table></figure>

</details>

<p>在Python计算中可使用浮点数。如果在计算过程中出现了浮点数，则整型会自动转换为浮点型计算；如果全是整型，则计算结果也为整型。在下面例子中，第一行代码两个操作数均为整型，返回的结果并不会精确为整型；而在第二行代码中，第一个操作数7.0为浮点型，返回的结果为浮点数。（以下代码请在Python解释器下运行）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 7/3</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; 7.0/3</span><br><span class="line">2.3333333333333335</span><br></pre></td></tr></table></figure>

</details>

<p>复数运算使用(real+imagj)的形式，也可使用complex(real，imag)创建一个复数对象，其中real表示实部，imag表示虚部。下面是一些复数计算的例子。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    &gt;&gt;&gt; 2+6J</span><br><span class="line">    (2+6j)</span><br><span class="line">    &gt;&gt;&gt; 2-6J</span><br><span class="line">    (2-6j)</span><br><span class="line">    &gt;&gt;&gt; 1j * complex(0，</span><br><span class="line"></span><br><span class="line">1)</span><br><span class="line">    (-1+0j)</span><br><span class="line">    &gt;&gt;&gt; 3+1j*3</span><br><span class="line">    (3+3j)</span><br><span class="line">&gt;&gt;&gt; a=1.5+0.5j</span><br><span class="line">&gt;&gt;&gt; a.real</span><br><span class="line">1.5</span><br><span class="line">&gt;&gt;&gt; a.imag</span><br><span class="line">0.5</span><br></pre></td></tr></table></figure>

</details>

<p>变量“_”表示刚计算的结果。下面代码通过计算（3+2）×6演示了该变量的使用。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 3+2</span><br><span class="line">5</span><br><span class="line">&gt;&gt;&gt; _*6</span><br><span class="line">30</span><br></pre></td></tr></table></figure>

</details>

<p>2）字符串型。Python的字符串通常用单引号和双引号包围的形式表示，通过print语句可将字符串输出到输出设备中（默认情况下输出到屏幕）。此外，Python 2.0及以后的版本支持Unicode字符串，中文字符一般使用Unicode编码（国际组织制定的容纳世界所有文字和符号的字符编码方案，用0~0x10FFFF映射字符，最多可以容纳1114112个字符），在前面加u表示后面是Unicode字符串。下面的代码演示了Unicode字符的定义与使用、字符串的输出等操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &apos;spam eggs&apos;</span><br><span class="line">&apos;spam eggs&apos;</span><br><span class="line">&gt;&gt;&gt; &apos;&quot;Yes，</span><br><span class="line"></span><br><span class="line">&quot; he said.&apos;</span><br><span class="line">&apos;&quot;Yes，</span><br><span class="line"></span><br><span class="line">&quot; he said.&apos;</span><br><span class="line">&gt;&gt;&gt; print u&quot;你好</span><br><span class="line"></span><br><span class="line">&quot;你好</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print u&quot;机器学习</span><br><span class="line"></span><br><span class="line">&quot;机器学习</span><br></pre></td></tr></table></figure>

</details>

<p>Python的字符串可视为列表（数组），使用“[索引]”的方式能对它进行切片操作（索引从0开始），使用“+”可对字符串进行连接。下面的代码演示了字符串的连接、切片等操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; word = &apos;Help&apos; + &apos;A&apos;</span><br><span class="line">&gt;&gt;&gt; word</span><br><span class="line">&apos;HelpA&apos;</span><br><span class="line">&gt;&gt;&gt; &apos;&lt;&apos; + word*5 + &apos;&gt;&apos;</span><br><span class="line">&apos;&lt;HelpAHelpAHelpAHelpAHelpA&gt;&apos;</span><br><span class="line">&gt;&gt;&gt; word[-2:]        #最后</span><br><span class="line"></span><br><span class="line">2个字符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&apos;pA&apos;</span><br><span class="line">&gt;&gt;&gt; word[:-2]        #除去最后</span><br><span class="line"></span><br><span class="line">2个字符以外的字符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &apos;Hel&apos;</span><br></pre></td></tr></table></figure>

</details>

<p>Python的字符串可使用转义字符，方法是在特殊字符前加上“\”。主要的转义字符有：</p>
<p>\’ 单引号</p>
<p>\” 双引号</p>
<p>\a 发出系统响铃声</p>
<p>\b 退格符</p>
<p>\n 换行符</p>
<p>\t 横向制表符</p>
<p>\v 纵向制表符</p>
<p>\r 回车符</p>
<p>\f 换页符</p>
<p>\\ \</p>
<p>\o 八进制数代表的字符</p>
<p>\x 十六进制数代表的字符</p>
<p>\000 终止符，\000后的字符串全部忽略</p>
<p>此外，Python的字符串相比其他程序语言多了一种描述方式，就是用3个引号标示字符串，其功能是将字符串内容原样输出，如果字符串本身包括换行，则输出换行，如果包括特殊字符，则字符串无需使用转义字符。下面的代码演示了中文字符串的输出、转义字符的使用、字符串切片、统计长度、三引号使用等操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &apos;doesn\&apos;t&apos;</span><br><span class="line">&quot;doesn&apos;t&quot;</span><br><span class="line">&gt;&gt;&gt; &quot;\&quot;Yes，</span><br><span class="line"></span><br><span class="line">\&quot; he said.&quot;</span><br><span class="line">&apos;&quot;Yes，</span><br><span class="line"></span><br><span class="line">&quot; he said.&apos;</span><br><span class="line">&gt;&gt;&gt; print u&quot;你好，</span><br><span class="line"></span><br><span class="line">Python\n机器学习</span><br><span class="line"></span><br><span class="line">&quot;你好，</span><br><span class="line"></span><br><span class="line">Python机器学习</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print u&quot;&quot;&quot;你好，</span><br><span class="line"></span><br><span class="line">Python</span><br><span class="line">... 机器学习</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;你好，</span><br><span class="line"></span><br><span class="line">Python机器学习</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; mystr=  u&quot;你好，</span><br><span class="line"></span><br><span class="line">Python\n机器学习</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">&gt;&gt;&gt; print mystr你好，</span><br><span class="line"></span><br><span class="line">Python机器学习</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print mystr[:5]你好，</span><br><span class="line"></span><br><span class="line">Py</span><br><span class="line">&gt;&gt;&gt; print mystr[3:5]</span><br><span class="line">Py</span><br><span class="line">&gt;&gt;&gt; len(mystr)###len函数计算字符串长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">14</span><br></pre></td></tr></table></figure>

</details>

<p>Python字符串的三引号表示方式意义重大，用它可以在CGI（CGI允许Web服务器执行外部程序，并将它们的输出发送给Web浏览器）程序中轻松输出HTML代码。下面是CGI的“Hello World”程序：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">print &quot;Content-Type: text/html&quot;</span><br><span class="line">print</span><br><span class="line">print &quot;&quot;&quot;&lt;html&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h2&gt;Hello World!&lt;/h2&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>3）列表。Python可将不同类型（包括复合类型本身）的值组成复合类型，列表就是复合类型之一。与字符串相同，列表可以使用切片操作，其索引也是从0开始的。此外，统计列表的长度使用len函数，使用“*”将生成新列表，其元素由源列表重复填充，使用“+”可连接列表。下面的代码演示了列表的定义、连接、重复填充、切片、统计长度等操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = [&apos;hello&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;world&apos;，</span><br><span class="line"></span><br><span class="line"> 100，</span><br><span class="line"></span><br><span class="line"> 1234]</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">[&apos;hello&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;world&apos;，</span><br><span class="line"></span><br><span class="line"> 100，</span><br><span class="line"></span><br><span class="line"> 1234]</span><br><span class="line">&gt;&gt;&gt; a[:2] + [&apos;-&apos;，</span><br><span class="line"></span><br><span class="line"> 2*2]###连接列表</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[&apos;hello&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;world&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;-&apos;，</span><br><span class="line"></span><br><span class="line"> 4]</span><br><span class="line">&gt;&gt;&gt; mylist=[1，</span><br><span class="line"></span><br><span class="line">23，</span><br><span class="line"></span><br><span class="line">45]</span><br><span class="line">&gt;&gt;&gt; mylist</span><br><span class="line">[1，</span><br><span class="line"></span><br><span class="line"> 23，</span><br><span class="line"></span><br><span class="line"> 45]</span><br><span class="line">&gt;&gt;&gt; mylist*2###重复填充列表</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1，</span><br><span class="line"></span><br><span class="line"> 23，</span><br><span class="line"></span><br><span class="line"> 45，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 23，</span><br><span class="line"></span><br><span class="line"> 45]</span><br><span class="line">&gt;&gt;&gt; mylist[:2]###列表切片</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1，</span><br><span class="line"></span><br><span class="line"> 23]</span><br><span class="line">&gt;&gt;&gt; x = [12，</span><br><span class="line"></span><br><span class="line"> 13]</span><br><span class="line">&gt;&gt;&gt; y = [11，</span><br><span class="line"></span><br><span class="line"> x，</span><br><span class="line"></span><br><span class="line"> 14]</span><br><span class="line">&gt;&gt;&gt; len(y)###求列表长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3</span><br><span class="line">&gt;&gt;&gt; y[1]</span><br><span class="line">[12，</span><br><span class="line"></span><br><span class="line"> 13]</span><br><span class="line">&gt;&gt;&gt; y[1][0]</span><br><span class="line">12</span><br></pre></td></tr></table></figure>

</details>

<p>列表和字符串也可称为序列，序列由若干个元素组成，每个元素的先后顺序明确，不能更改。</p>
<p>2.Python语句</p>
<p>1）条件语句。if语句的作用是判断条件是否成立，如果成立，则执行后面的语句块；if…elif…elif语句可用于对多个条件进行判断，并执行最先满足条件的语句块；else语句表示所有条件都不成立时执行。下面的例子展示了if语句的使用方法，功能是对输入数字的范围进行判断，并将其中的负数转变为0。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = int(raw_input(&quot;Please enter an integer: &quot;))</span><br><span class="line">Please enter an integer: -10</span><br><span class="line">&gt;&gt;&gt; if x &lt; 0:</span><br><span class="line">...      x = 0</span><br><span class="line">...      print &apos;Negative changed to zero&apos;</span><br><span class="line">... elif x == 0:</span><br><span class="line">...      print &apos;Zero&apos;</span><br><span class="line">... elif x == 1:</span><br><span class="line">...      print &apos;Single&apos;</span><br><span class="line">... else:</span><br><span class="line">...      print &apos;More&apos;</span><br><span class="line">...</span><br><span class="line">Negative changed to zero下面例子演示了判断非奇偶数。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...     for x in range(1，</span><br><span class="line"></span><br><span class="line"> 10):</span><br><span class="line">...         if x % 2 == 0:</span><br><span class="line">...             print x，</span><br><span class="line"></span><br><span class="line"> &apos;is an even number&apos;.</span><br><span class="line">...           </span><br><span class="line">...         else:</span><br><span class="line">...             # loop fell through without finding a factor</span><br><span class="line">...             print x，</span><br><span class="line"></span><br><span class="line"> &apos;is an odd number.&apos;</span><br><span class="line">...</span><br><span class="line">2 is an even number</span><br><span class="line">3 is an odd number</span><br><span class="line">4 is an even number</span><br><span class="line">5 is an odd number</span><br><span class="line">6 is an even number</span><br><span class="line">7 is an odd number</span><br><span class="line">8 is an even number</span><br><span class="line">9 is an odd number</span><br></pre></td></tr></table></figure>

</details>

<p>2）循环语句。for语句表示循环，它与C语言中的for语句略有不同。C语言的for语句可定义步长和终止循环条件，而Python的for语句在Python的序列（列表、字符串等）中迭代，每次只操作其中一项。下面的代码在单词列表中迭代，每次迭代输出单词及其长度。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; # Measure some strings:</span><br><span class="line">... words = [&apos;cat&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;window&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;hello&apos;]</span><br><span class="line">&gt;&gt;&gt; for w in words:</span><br><span class="line">...     print w，</span><br><span class="line"></span><br><span class="line"> len(w)</span><br><span class="line">...</span><br><span class="line">cat 3</span><br><span class="line">window 6</span><br><span class="line">hello 5</span><br></pre></td></tr></table></figure>

</details>

<p>也可以在迭代过程中修改序列。下面的例子运行结果是在列表迭代过程中修改了列表本身。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;words = [&apos;cat&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;window&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;defenestrate&apos;]</span><br><span class="line">&gt;&gt;&gt; for w in words[:]: </span><br><span class="line">...     if len(w) &gt; 6:</span><br><span class="line">...         words.insert(0，</span><br><span class="line"></span><br><span class="line"> w)</span><br><span class="line">...</span><br><span class="line">&gt;&gt;&gt; words</span><br><span class="line">[&apos;defenestrate&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;cat&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;window&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;defenestrate&apos;]</span><br></pre></td></tr></table></figure>

</details>

<p>3）range函数。for语句仅能在列表等序列中进行迭代，从表面上来看，它比C语言的for循环功能弱很多，其实不然，有了range函数，其功能远比C语言的for循环强大。range函数可产生符合某种规律的列表等序列。下面代码产生0~9共10个数字，增长步长为1。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; range(10)</span><br><span class="line">[0，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 4，</span><br><span class="line"></span><br><span class="line"> 5，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 7，</span><br><span class="line"></span><br><span class="line"> 8，</span><br><span class="line"></span><br><span class="line"> 9]</span><br></pre></td></tr></table></figure>

</details>

<p>range函数还可以产生更复杂的序列，常用调用格式为：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">range(起始值，终止值，步长</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

</details>

<p>其中起始值和步长可以省略，起始值默认为0，步长默认为1。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; range(5，</span><br><span class="line"></span><br><span class="line"> 10)</span><br><span class="line">[5，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 7，</span><br><span class="line"></span><br><span class="line"> 8，</span><br><span class="line"></span><br><span class="line"> 9]</span><br><span class="line">&gt;&gt;&gt; range(0，</span><br><span class="line"></span><br><span class="line"> 10，</span><br><span class="line"></span><br><span class="line"> 3)</span><br><span class="line">[0，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 9]</span><br><span class="line">&gt;&gt;&gt; range(-10，</span><br><span class="line"></span><br><span class="line"> -100，</span><br><span class="line"></span><br><span class="line"> -30)</span><br><span class="line">[-10，</span><br><span class="line"></span><br><span class="line"> -40，</span><br><span class="line"></span><br><span class="line"> -70]</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码是range函数与for语句组合的应用，输出列表元素的索引及值。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = [&apos;Mary&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;had&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;a&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;little&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;lamb&apos;]</span><br><span class="line">&gt;&gt;&gt; for i in range(len(a)):</span><br><span class="line">...     print i，</span><br><span class="line"></span><br><span class="line"> a[i]</span><br><span class="line">...</span><br><span class="line">0 Mary</span><br><span class="line">1 had</span><br><span class="line">2 a</span><br><span class="line">3 little</span><br><span class="line">4 lamb</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码完成1至10中奇数的累加。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">    &gt;&gt;&gt; mysum=0</span><br><span class="line">    &gt;&gt;&gt; for i in range(1，</span><br><span class="line"></span><br><span class="line">10，</span><br><span class="line"></span><br><span class="line">2):</span><br><span class="line">    ...    mysum=mysum+i</span><br><span class="line">    ...</span><br><span class="line">    &gt;&gt;&gt; mysum</span><br><span class="line">    25</span><br></pre></td></tr></table></figure>

</details>

<p>4）break与continue。break语句结束本层循环，continue语句忽略下面的语句继续本层的下次循环。下面的代码使用break语句，查找2至10以内（不含10）的素数，如果不是素数，则分解因数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for n in range(2，</span><br><span class="line"></span><br><span class="line"> 10):</span><br><span class="line">...     for x in range(2，</span><br><span class="line"></span><br><span class="line"> n):</span><br><span class="line">...         if n % x == 0:</span><br><span class="line">...             print n，</span><br><span class="line"></span><br><span class="line"> &apos;equals&apos;，</span><br><span class="line"></span><br><span class="line"> x，</span><br><span class="line"></span><br><span class="line"> &apos;*&apos;，</span><br><span class="line"></span><br><span class="line"> n/x</span><br><span class="line">...             break</span><br><span class="line">...         if n==x+1:</span><br><span class="line">...             # loop fell through without finding a factor</span><br><span class="line">...             print n，</span><br><span class="line"></span><br><span class="line"> &apos;is a prime number&apos;</span><br><span class="line">2 is a prime number</span><br><span class="line">3 is a prime number</span><br><span class="line">4 equals 2 * 2</span><br><span class="line">5 is a prime number</span><br><span class="line">6 equals 2 * 3</span><br><span class="line">7 is a prime number</span><br><span class="line">8 equals 2 * 4</span><br><span class="line">9 equals 3 * 3</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码使用了continue语句，判断50至60之间的数哪些是奇数，哪些是偶数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for num in range(50，</span><br><span class="line"></span><br><span class="line"> 60):</span><br><span class="line">...    if num % 2 == 0:</span><br><span class="line">...       print &quot;偶数</span><br><span class="line"></span><br><span class="line">&quot;，</span><br><span class="line"></span><br><span class="line">num</span><br><span class="line">...       continue</span><br><span class="line">...    print &quot;奇数</span><br><span class="line"></span><br><span class="line">&quot;，</span><br><span class="line"></span><br><span class="line">num</span><br><span class="line">...偶数</span><br><span class="line"></span><br><span class="line"> 50奇数</span><br><span class="line"></span><br><span class="line"> 51偶数</span><br><span class="line"></span><br><span class="line"> 52奇数</span><br><span class="line"></span><br><span class="line"> 53偶数</span><br><span class="line"></span><br><span class="line"> 54奇数</span><br><span class="line"></span><br><span class="line"> 55偶数</span><br><span class="line"></span><br><span class="line"> 56奇数</span><br><span class="line"></span><br><span class="line"> 57偶数</span><br><span class="line"></span><br><span class="line"> 58奇数</span><br><span class="line"></span><br><span class="line"> 59</span><br></pre></td></tr></table></figure>

</details>

<p>5）while循环。在while循环中会一直执行后面的语句块，直到条件不满足才终止。下面的代码用于在列表中循环，并输出元素。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a=range(10)</span><br><span class="line">    i=0</span><br><span class="line">&gt;&gt;&gt; while i&lt;10:</span><br><span class="line">...    print a[i]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...    i=i+1</span><br><span class="line">[0，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 4，</span><br><span class="line"></span><br><span class="line"> 5，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 7，</span><br><span class="line"></span><br><span class="line"> 8，</span><br><span class="line"></span><br><span class="line"> 9]</span><br></pre></td></tr></table></figure>

</details>

<p>6）函数定义。Python使用def关键字定义函数。下面的代码定义了屏幕输出函数show，参数是要输出的内容。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; def show(mess=&quot;hello&quot;):</span><br><span class="line">...    print mess</span><br><span class="line">...</span><br><span class="line">&gt;&gt;&gt; show()</span><br><span class="line">hello</span><br><span class="line">&gt;&gt;&gt; show(&quot;机器学习</span><br><span class="line"></span><br><span class="line">&quot;)机器学习</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码定义了斐波那契数列的计算函数fib。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; def fib(n):  </span><br><span class="line">...     &quot;&quot;&quot;Print a Fibonacci series up to n.&quot;&quot;&quot;</span><br><span class="line">...     a，</span><br><span class="line"></span><br><span class="line"> b = 0，</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line">...     while a &lt; n:</span><br><span class="line">...         print a，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...         a，</span><br><span class="line"></span><br><span class="line"> b = b，</span><br><span class="line"></span><br><span class="line"> a+b</span><br><span class="line">...</span><br><span class="line">&gt;&gt;&gt; fib(2000)</span><br><span class="line">0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597</span><br></pre></td></tr></table></figure>

</details>

<p>3.Python的元组、集合以及字典</p>
<p>1）tuple元组。tuple元组类似列表，不同的是它的内容不能修改。Python元组的定义方式是使用圆括号包含元素或直接列举元素。下面的代码将定义x为元组类型，当对x[0]（x的第一个元素）进行修改时，Python解释器提示错误。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = 10，</span><br><span class="line"></span><br><span class="line"> 20，</span><br><span class="line"></span><br><span class="line"> &apos;learn&apos;</span><br><span class="line">&gt;&gt;&gt; x[0]</span><br><span class="line">10</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">(10，</span><br><span class="line"></span><br><span class="line"> 20，</span><br><span class="line"></span><br><span class="line"> &apos;learn&apos;)</span><br><span class="line">&gt;&gt;&gt; x1，</span><br><span class="line"></span><br><span class="line">x2，</span><br><span class="line"></span><br><span class="line">x3=x</span><br><span class="line">&gt;&gt;&gt; x1</span><br><span class="line">10</span><br><span class="line">&gt;&gt;&gt; x2</span><br><span class="line">20</span><br><span class="line">&gt;&gt;&gt; x3</span><br><span class="line">&apos;learn&apos;</span><br><span class="line">&gt;&gt;&gt; x[0]=90</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;，</span><br><span class="line"></span><br><span class="line"> line 1，</span><br><span class="line"></span><br><span class="line"> in &lt;module&gt;</span><br><span class="line">TypeError: &apos;tuple&apos; object does not support item assignment</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>2）Sets集合。Python使用方括号定义Sets集合，集合的特点是无重复元素，集合中的元素无先后顺序，也不能用索引进行管理。下面的代码定义了一个水果列表，通过set函数转换为集合，去除重复元素。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; basket = [&apos;apple&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;orange&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;apple&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;pear&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;orange&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;banana&apos;]</span><br><span class="line">&gt;&gt;&gt; fruit = set(basket)      </span><br><span class="line">&gt;&gt;&gt; fruit</span><br><span class="line">set([&apos;orange&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;pear&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;apple&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;banana&apos;])</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码通过in操作检查成员与集合的关系。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; &apos;orange&apos; in fruit ###集合类是否有成员</span><br><span class="line"></span><br><span class="line"> &apos;orange&apos;</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; &apos;crabgrass&apos; in fruit###集合类是否有成员</span><br><span class="line"></span><br><span class="line">&apos;crabgrass&apos; </span><br><span class="line">False</span><br></pre></td></tr></table></figure>

</details>

<p>既然是集合，当然能对它进行集合的数学运算。Python集合支持union（联合或并）、intersection（交）、difference（差）和sysmmetric difference（对称差）等操作，可通过“-”、“|”、“&amp;”、“^”操作符计算集合的差集、并集、交集和对称差集。下面的代码演示了对集合a和b的运算。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = set(&apos;abracadabra&apos;)</span><br><span class="line">&gt;&gt;&gt; b = set(&apos;alacazam&apos;)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">set([&apos;a&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;r&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;b&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;c&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;d&apos;])</span><br><span class="line">&gt;&gt;&gt; a -b                                #差集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set([&apos;r&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;d&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;b&apos;])</span><br><span class="line">&gt;&gt;&gt; a | b                                # 并集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set([&apos;a&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;c&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;r&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;d&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;b&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;m&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;z&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;l&apos;])</span><br><span class="line">&gt;&gt;&gt; a &amp; b                                # 交集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set([&apos;a&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;c&apos;])</span><br><span class="line">&gt;&gt;&gt; a ^ b                                # 对称差集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set([&apos;r&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;d&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;b&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;m&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;z&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;l&apos;])</span><br></pre></td></tr></table></figure>

</details>

<p>3）Dictionaries字典。Dictionaries（字典）是一种散列结构，可理解为Hash（散列）类型。字典由若干个键值对组成，键值对是一种映射，一个键对应于一个值。键值对由两个部分组成，第一部分是键，键在字典中必须保持唯一，字典与列表和元组不同，列表和元组属于序列，元素以先后顺序来管理，而字典的元素是以键为单位对值进行管理的；第二部分为值，值与键一一对应，值可以彼此相同。</p>
<p>Python使用花括号定义字典，使用类似索引的方式存取值，但索引为键。此外，可使用del操作删除键值对，使用keys()方法返回字典变量存储的所有键。下面的代码演示了一个学生学号的字典变量，以及如何对学生信息进行删除、查询等操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; tel = &#123;&apos;张三</span><br><span class="line"></span><br><span class="line">&apos;: 4098，</span><br><span class="line"></span><br><span class="line"> &apos;李四</span><br><span class="line"></span><br><span class="line">&apos;: 4139&#125;</span><br><span class="line">&gt;&gt;&gt; tel</span><br><span class="line">&#123;&apos;\xd5\xc5\xc8\xfd&apos;: 4098，</span><br><span class="line"></span><br><span class="line"> &apos;\xc0\xee\xcb\xc4&apos;: 4139&#125;</span><br><span class="line">&gt;&gt;&gt; tel[&apos;张三</span><br><span class="line"></span><br><span class="line">&apos;]</span><br><span class="line">4098</span><br><span class="line">&gt;&gt;&gt; del tel[&apos;张三</span><br><span class="line"></span><br><span class="line">&apos;]</span><br><span class="line">&gt;&gt;&gt; tel[&apos;张三</span><br><span class="line"></span><br><span class="line">&apos;]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;，</span><br><span class="line"></span><br><span class="line"> line 1，</span><br><span class="line"></span><br><span class="line"> in &lt;module&gt;</span><br><span class="line">KeyError: &apos;\xd5\xc5\xc8\xfd&apos;</span><br><span class="line">&gt;&gt;&gt; tel.keys()</span><br><span class="line">[&apos;\xc0\xee\xcb\xc4&apos;]</span><br><span class="line">&gt;&gt;&gt; tel[&apos;王华</span><br><span class="line"></span><br><span class="line">&apos;]=1000</span><br><span class="line">&gt;&gt;&gt; tel.keys()</span><br><span class="line">[&apos;\xcd\xf5\xbb\xaa&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;\xc0\xee\xcb\xc4&apos;]</span><br><span class="line">&gt;&gt;&gt; print tel.keys()[0]王华</span><br></pre></td></tr></table></figure>

</details>

<p>上面代码中，“\xcd”等为汉字在Python内部的编码。</p>
<p>4.Python类</p>
<p>Python语言有强大的面向对象编程能力。Python和C++等语言一样拥有类机制，Python类的定义方式如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">class 类名</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">     #类成员变量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     变量</span><br><span class="line"></span><br><span class="line">A=A初始值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     变量</span><br><span class="line"></span><br><span class="line">B=B初始值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     ......</span><br><span class="line">     #下面定义了类成员函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     def _init_(self，</span><br><span class="line"></span><br><span class="line"> 参数</span><br><span class="line"></span><br><span class="line">1，参数</span><br><span class="line"></span><br><span class="line">2，</span><br><span class="line"></span><br><span class="line">...，参数</span><br><span class="line"></span><br><span class="line">n):</span><br><span class="line">        #类构造函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">     def _del_(self):</span><br><span class="line">        # 析构函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            ......</span><br><span class="line">     def 方法</span><br><span class="line"></span><br><span class="line">1(self，参数</span><br><span class="line"></span><br><span class="line">1，参数</span><br><span class="line"></span><br><span class="line">2，</span><br><span class="line"></span><br><span class="line">...，参数</span><br><span class="line"></span><br><span class="line">n):</span><br><span class="line">     #类的方法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">         ...... </span><br><span class="line">     ......</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码定义了一个复数类Complex，同时定义了类的实例变量x，最后输出该变量的实部和虚部。Complex类很简单，在类构造函数中对实部成员和虚部成员进行赋值。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; class Complex:</span><br><span class="line">...    r=0</span><br><span class="line">...    i=0</span><br><span class="line">...    def _init_(self，</span><br><span class="line"></span><br><span class="line"> realpart，</span><br><span class="line"></span><br><span class="line"> imagpart):</span><br><span class="line">...       self.r = realpart</span><br><span class="line">...       self.i = imagpart</span><br><span class="line">&gt;&gt;&gt; x = Complex(3.0，</span><br><span class="line"></span><br><span class="line"> -4.5)</span><br><span class="line">&gt;&gt;&gt; x.r，</span><br><span class="line"></span><br><span class="line"> x.i</span><br><span class="line">(3.0，</span><br><span class="line"></span><br><span class="line"> -4.5)</span><br></pre></td></tr></table></figure>

</details>

<p>5.Python异常处理</p>
<p>Python的异常处理能力很强大，可准确反馈出错信息。在Python中，异常是对象，可对它进行操作。所有异常都是基类Exception的成员，从基类Exception继承，在exceptions模块中定义。Python异常处理的格式如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">try :</span><br><span class="line">      #下面为可能发生异常的语句块</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      ......</span><br><span class="line">except 异常类型</span><br><span class="line"></span><br><span class="line">:</span><br><span class="line">      #下面为处理异常的语句块</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      ......</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码将检查输入是否为有效数字。程序通过将输入转换成整型来测试是否为数字，如果不是数字，int函数将触发异常ValueError，异常处理程序提示“哦！输入不是有效数字，请重新输入（Oops!That was no valid number.Try again…）”，直到输入正确格式的数字后，程序才退出。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; while True:</span><br><span class="line">...     try:</span><br><span class="line">...         x = int(raw_input(&quot;Please enter a number: &quot;))</span><br><span class="line">...         break</span><br><span class="line">...     except ValueError:</span><br><span class="line">...         print &quot;Oops!  That was no valid number.  Try again...&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

</details>

<p>前面演示了异常的被动触发，Python还能主动触发异常，处理方式为：先通过raise语句抛出异常，然后用except捕捉异常。下面的代码演示raise主动抛出NameError异常后被捕捉，输出“An exception flew by!”后，继续抛出异常，以便给更外层的异常处理函数继续处理。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; try:</span><br><span class="line">...     raise NameError(&apos;HiThere&apos;)</span><br><span class="line">... except NameError:</span><br><span class="line">...     print &apos;An exception flew by!&apos;</span><br><span class="line">...     raise</span><br><span class="line">...</span><br><span class="line">An exception flew by!</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;，</span><br><span class="line"></span><br><span class="line"> line 2，</span><br><span class="line"></span><br><span class="line"> in ?</span><br><span class="line">NameError: HiThere</span><br></pre></td></tr></table></figure>

</details>

<p>以上简要介绍了Python编程语言的基本语法，它和C++有几分相似，有一定编程基础的读者应该都能看懂。Python是一门上手很快的编程语言，它与其他语言最大的不同就是它区分语句块时使用的不是括号，而是每行语句前面的空格数量。因此，Python代码非常工整和漂亮，它严格遵守代码语句块的缩进原则，可依靠缩进判断语句块的范围。</p>
<h4 id="3-1-2-Numpy库"><a href="#3-1-2-Numpy库" class="headerlink" title="3.1.2 Numpy库"></a>3.1.2 Numpy库</h4><p>本书中介绍的机器学习算法大部分是调用Numpy库来完成基础数值计算的。下面了解一下Numpy库的基本使用方法。</p>
<p>1.ndarray数组基础</p>
<p>Python中用列表保存一组值，可将列表当成数组使用。此外，Python有array模块，但它不支持多维数组，无论是列表还是array模块都没有科学运算函数，不适合做矩阵等科学计算。因此，Numpy没有使用Python本身的数组机制，而是提供了ndarray数组对象，该对象不但能方便地存取数组，而且拥有丰富的数组计算函数，比如向量的加法、减法、乘法等。</p>
<p>使用ndarray数组，首先需要导入Numpy函数库，可以直接导入该函数库（本节频繁使用Numpy库的函数，因此采用这种方法）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from numpy  import *</span><br></pre></td></tr></table></figure>

</details>

<p>或者指定导入库的别名。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>

</details>

<p>下面正式进入Numpy的数组世界。如果没有说明，所称数组均为Numpy的数组对象，与Python的列表和array模块无关。</p>
<p>1）创建数组。创建数组是进行数组计算的先决条件，可通过array()函数定义数组实例对象，其参数为Python的序列对象（比如列表）。如果想定义多维数组，则传递多层嵌套的序列。例如下面这条语句定义了一个二维数组，其大小为（2，3），即共有2行，每行各3列。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[ 1.，</span><br><span class="line"></span><br><span class="line"> 7.，</span><br><span class="line"></span><br><span class="line"> 0.]，</span><br><span class="line"></span><br><span class="line">[ -2.，</span><br><span class="line"></span><br><span class="line"> 1.，</span><br><span class="line"></span><br><span class="line"> 2.]])</span><br></pre></td></tr></table></figure>

</details>

<p>上面语句定义了如表3-1所示的数组。</p>
<p>表3-1 二维数组结构</p>
<p><img src="Image00003.jpg" alt></p>
<p>接着使用array()函数创建一个（2，3）大小的数组变量x。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from numpy  import *</span><br><span class="line">&gt;&gt;&gt; x=array([[ 1.，</span><br><span class="line"></span><br><span class="line"> 0.，</span><br><span class="line"></span><br><span class="line"> 0.]，</span><br><span class="line"></span><br><span class="line">[ 0.，</span><br><span class="line"></span><br><span class="line"> 1.，</span><br><span class="line"></span><br><span class="line"> 2.]])</span><br></pre></td></tr></table></figure>

</details>

<p>以刚才定义的x变量为例，来熟悉ndarray数组对象的主要属性。ndarray数组对象拥有ndarray.ndim、ndarray.shape、ndarray.size、ndarray.dtype、ndarray.itemsize、ndarray.data等属性。</p>
<p>ndarray.ndim：数组的维度数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.ndim</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

</details>

<p>ndarray.shape：数组的维数，返回的格式为（n，m），其中n为行数，m为列数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.shape</span><br><span class="line">(2，</span><br><span class="line"></span><br><span class="line"> 3)</span><br></pre></td></tr></table></figure>

</details>

<p>ndarray.size：数组元素的总数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.size</span><br><span class="line">6</span><br></pre></td></tr></table></figure>

</details>

<p>ndarray.dtype：数组元素的类型，比如：numpy.int32（32位整型）、numpy.int16（16位整型）及numpy.float64（64位浮点型）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.dtype</span><br><span class="line">dtype(&apos;float64&apos;)</span><br></pre></td></tr></table></figure>

</details>

<p>ndarray.itemsize：数组中每个元素占有的字节大小。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.itemsize</span><br><span class="line">8</span><br></pre></td></tr></table></figure>

</details>

<p>ndarray.data：数组元素的缓冲区。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x.data</span><br><span class="line">&lt;read-write buffer for 0x0557EAE8，</span><br><span class="line"></span><br><span class="line"> size 48，</span><br><span class="line"></span><br><span class="line"> offset 0 at 0x0561BAE0&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>下面是一个关于Numpy的ndarray数组的例子，演示了ndarray数组的基本操作。</p>
<p>首先，创建a和b两个数组对象。其中，a对象使用Numpy的arange函数产生了等差序列数组（Numpy的arange函数与Python的range函数类似，其参数依次为开始值、结束值、步长），并用reshape函数创建了指定形状的新数组。a的大小为（3，5）；b的大小为（1，3）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = arange(15).reshape(3，</span><br><span class="line"></span><br><span class="line"> 5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[ 0，</span><br><span class="line"></span><br><span class="line">  1，</span><br><span class="line"></span><br><span class="line">  2，</span><br><span class="line"></span><br><span class="line">  3，</span><br><span class="line"></span><br><span class="line">  4]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 5，</span><br><span class="line"></span><br><span class="line">  6，</span><br><span class="line"></span><br><span class="line">  7，</span><br><span class="line"></span><br><span class="line">  8，</span><br><span class="line"></span><br><span class="line">  9]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [10，</span><br><span class="line"></span><br><span class="line"> 11，</span><br><span class="line"></span><br><span class="line"> 12，</span><br><span class="line"></span><br><span class="line"> 13，</span><br><span class="line"></span><br><span class="line"> 14]])</span><br><span class="line">&gt;&gt;&gt; b = array([6，</span><br><span class="line"></span><br><span class="line"> 7，</span><br><span class="line"></span><br><span class="line"> 8])</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([6，</span><br><span class="line"></span><br><span class="line"> 7，</span><br><span class="line"></span><br><span class="line"> 8])</span><br></pre></td></tr></table></figure>

</details>

<p>接着读取a和b的主要属性，如：shape、ndim、dtype、itemsize等。此外，下面的代码还演示了type函数的使用，type函数会返回对象的类型，对于ndarray对象而言，其类型为numpy.ndarray。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a.shape</span><br><span class="line">(3，</span><br><span class="line"></span><br><span class="line"> 5)</span><br><span class="line">&gt;&gt;&gt; a.ndim</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; a.dtype.name</span><br><span class="line">&apos;int32&apos;</span><br><span class="line">&gt;&gt;&gt; a.itemsize</span><br><span class="line">4</span><br><span class="line">&gt;&gt;&gt; a.size</span><br><span class="line">15</span><br><span class="line">&gt;&gt;&gt; type(a)</span><br><span class="line">numpy.ndarray</span><br><span class="line">&gt;&gt;&gt; type(b)</span><br><span class="line">numpy.ndarray</span><br></pre></td></tr></table></figure>

</details>

<p>最后，对a和b对象重新赋值，以便进一步了解ndarray数组的元素类型。下面分别演示了int32、float64等类型的使用方法，最后演示了不常见的复数作为数组元素（数组c的元素）的情况。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = array( [2，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">4] )</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([2，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 4])</span><br><span class="line">&gt;&gt;&gt; a.dtype</span><br><span class="line">dtype(&apos;int32&apos;)</span><br><span class="line">&gt;&gt;&gt; b = array([1.2，</span><br><span class="line"></span><br><span class="line"> 3.5，</span><br><span class="line"></span><br><span class="line"> 5.1])</span><br><span class="line">&gt;&gt;&gt; b.dtype</span><br><span class="line">dtype(&apos;float64&apos;)</span><br><span class="line">&gt;&gt;&gt; c = array( [ [1，</span><br><span class="line"></span><br><span class="line">2]，</span><br><span class="line"></span><br><span class="line"> [3，</span><br><span class="line"></span><br><span class="line">4] ]，</span><br><span class="line"></span><br><span class="line"> dtype=complex )</span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([[ 1.+0.j，</span><br><span class="line"></span><br><span class="line">  2.+0.j]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 3.+0.j，</span><br><span class="line"></span><br><span class="line">  4.+0.j]])</span><br></pre></td></tr></table></figure>

</details>

<p>2）特殊数组。Numpy的特殊数组主要有以下几种：</p>
<p>·zeros数组：全零数组，元素全为0，使用zeros函数创建。</p>
<p>·ones数组：全1数组，元素全为1，使用ones函数创建。</p>
<p>·empty数组：空数组，元素全近似为0，使用empty函数创建。</p>
<p>下面的代码依次演示了全零数组、全1数组、空数组的创建方法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; zeros( (3，</span><br><span class="line"></span><br><span class="line">4) )</span><br><span class="line">array([[0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.，</span><br><span class="line"></span><br><span class="line">  0.]])</span><br><span class="line">&gt;&gt;&gt; ones( (2，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">4)，</span><br><span class="line"></span><br><span class="line"> dtype=int16 )</span><br><span class="line">array([[[ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 1]]]，</span><br><span class="line"></span><br><span class="line"> dtype=int16)</span><br><span class="line">&gt;&gt;&gt; empty( (5，</span><br><span class="line"></span><br><span class="line">3) )</span><br><span class="line">array([[  1.42185083e-299，</span><br><span class="line"></span><br><span class="line">   1.41906197e-299，</span><br><span class="line"></span><br><span class="line">   5.77420410e-300]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [  6.02082633e-300，</span><br><span class="line"></span><br><span class="line">   1.41971817e-299，</span><br><span class="line"></span><br><span class="line">   5.77379398e-300]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [  5.77440917e-300，</span><br><span class="line"></span><br><span class="line">   5.77386233e-300，</span><br><span class="line"></span><br><span class="line">   5.77440917e-300]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [  5.77386233e-300，</span><br><span class="line"></span><br><span class="line">   5.77440917e-300，</span><br><span class="line"></span><br><span class="line">   5.77386233e-300]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [  1.42130399e-299，</span><br><span class="line"></span><br><span class="line">   5.77440917e-300，</span><br><span class="line"></span><br><span class="line">   5.77406740e-300]])</span><br></pre></td></tr></table></figure>

</details>

<p>3）序列数组。刚才已经提到过arange函数，它与Python的range函数相似，但它属于Numpy函数库，其参数依次为开始值、结束值、步长。此外，还可使用linspace函数创建等差序列数组，其参数分别为起始值、终止值、元素数量。下面的代码分别演示了arange函数和linspace函数的用法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; arange( 10，</span><br><span class="line"></span><br><span class="line"> 30，</span><br><span class="line"></span><br><span class="line"> 5 )</span><br><span class="line">array([10，</span><br><span class="line"></span><br><span class="line"> 15，</span><br><span class="line"></span><br><span class="line"> 20，</span><br><span class="line"></span><br><span class="line"> 25])</span><br><span class="line">&gt;&gt;&gt; arange( 0，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> 0.3 )</span><br><span class="line">array([ 0. ，</span><br><span class="line"></span><br><span class="line">  0.3，</span><br><span class="line"></span><br><span class="line">  0.6，</span><br><span class="line"></span><br><span class="line">  0.9，</span><br><span class="line"></span><br><span class="line">  1.2，</span><br><span class="line"></span><br><span class="line">  1.5，</span><br><span class="line"></span><br><span class="line">  1.8])</span><br><span class="line">&gt;&gt;&gt; linspace( 0，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> 9 )                        # 从</span><br><span class="line"></span><br><span class="line">0到</span><br><span class="line"></span><br><span class="line">2，</span><br><span class="line"></span><br><span class="line">9个数字</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([ 0.  ，</span><br><span class="line"></span><br><span class="line">  0.25，</span><br><span class="line"></span><br><span class="line">  0.5 ，</span><br><span class="line"></span><br><span class="line">  0.75，</span><br><span class="line"></span><br><span class="line">  1.  ，</span><br><span class="line"></span><br><span class="line">  1.25，</span><br><span class="line"></span><br><span class="line">  1.5 ，</span><br><span class="line"></span><br><span class="line">  1.75，</span><br><span class="line"></span><br><span class="line">  2.  ])</span><br><span class="line">&gt;&gt;&gt; x = linspace( 0，</span><br><span class="line"></span><br><span class="line"> 2*pi，</span><br><span class="line"></span><br><span class="line"> 100 )               #从</span><br><span class="line"></span><br><span class="line">0到</span><br><span class="line"></span><br><span class="line">2*pi共</span><br><span class="line"></span><br><span class="line">100个数字</span><br></pre></td></tr></table></figure>

</details>

<p>4）输出数组。可使用print输出Numpy的数组对象。下面的代码是一维数组的创建和输出。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = arange(6)                                # 一维数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print a</span><br><span class="line">[0 1 2 3 4 5]</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码是二维数组的创建和输出，从输出结果可清晰地看出b的大小为（4，3）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; b = arange(12).reshape(4，</span><br><span class="line"></span><br><span class="line">3)                # 二维数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print b</span><br><span class="line">[[ 0  1  2]</span><br><span class="line"> [ 3  4  5]</span><br><span class="line"> [ 6  7  8]</span><br><span class="line"> [ 9 10 11]]</span><br></pre></td></tr></table></figure>

</details>

<p>5）数组索引。Numpy数组的每个元素、每行元素、每列元素都可以用索引访问，不过要注意索引是从0开始的。比如，某数组大小为（2，3），则第2行第1列元素的索引是[1，0]。下面以三维数组为例，演示数组的创建、输出及索引。</p>
<p>首先创建三维数组c，并输出其元素。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = arange(24).reshape(2，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">4)         # 三维数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; print c</span><br><span class="line">[[[ 0  1  2  3]</span><br><span class="line">  [ 4  5  6  7]</span><br><span class="line">  [ 8  9 10 11]]</span><br><span class="line"> [[12 13 14 15]</span><br><span class="line">  [16 17 18 19]</span><br><span class="line">  [20 21 22 23]]]</span><br></pre></td></tr></table></figure>

</details>

<p>三维数组c可表示为如图3-1所示的形式。</p>
<p><img src="Image00004.jpg" alt></p>
<p>图3-1 三维数组c</p>
<p>图3-1中单元格上方标注了[0，0，:]、[0，1，:]等索引，索引中的“:”表示该维度内的所有元素。对照图3-1，查找索引[1，2，:]处（第2行第3列）的所有元素和索引[0，1，2]处的元素，可得出元素为[20，21，22，23]和6。下面编写代码验证一下。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print c[1，</span><br><span class="line"></span><br><span class="line">2，</span><br><span class="line"></span><br><span class="line">:]</span><br><span class="line">[20 21 22 23]</span><br><span class="line">&gt;&gt;&gt; print c[0，</span><br><span class="line"></span><br><span class="line">1，</span><br><span class="line"></span><br><span class="line">2]</span><br><span class="line">6</span><br></pre></td></tr></table></figure>

</details>

<p>6）数组运算。数组的加减乘除以及乘方运算方式为，相应位置的元素分别进行计算。比如：</p>
<p>数组加法：array([20，31，42，53])=array([20，30，40，50])+array([0，1，2，3])</p>
<p>数组减法：array([20，29，38，47])=array([20，30，40，50])-array([0，1，2，3])</p>
<p>数组乘法：array([[2，0]，[0，4]])=array([[1，1]，[0，1]])*array([[2，0]，[3，4]])</p>
<p>数组乘方：array([0，1，2，3])的二次方=array([0，1，4，9])</p>
<p>数组除法：array([20.，15.，13.33333333，12.5])=array([20，30，40，50])/array([1，2，3，4])</p>
<p>下面的代码演示了数组的加、减、乘、除及更多运算（关键代码处注释了运算类型）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = array( [20，</span><br><span class="line"></span><br><span class="line">30，</span><br><span class="line"></span><br><span class="line">40，</span><br><span class="line"></span><br><span class="line">50] )</span><br><span class="line">&gt;&gt;&gt; aa = arange(1，</span><br><span class="line"></span><br><span class="line"> 5)</span><br><span class="line">&gt;&gt;&gt; a/aa###除法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([ 20.        ，</span><br><span class="line"></span><br><span class="line">  15.        ，</span><br><span class="line"></span><br><span class="line">  13.33333333，</span><br><span class="line"></span><br><span class="line">  12.5       ])</span><br><span class="line">&gt;&gt;&gt; </span><br><span class="line">&gt;&gt;&gt; b = arange( 4 )</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([0，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> 3])</span><br><span class="line">&gt;&gt;&gt; c = a-b###减法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; c</span><br><span class="line">array([20，</span><br><span class="line"></span><br><span class="line"> 29，</span><br><span class="line"></span><br><span class="line"> 38，</span><br><span class="line"></span><br><span class="line"> 47])</span><br><span class="line">&gt;&gt;&gt; b**2###乘方</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([0，</span><br><span class="line"></span><br><span class="line"> 1，</span><br><span class="line"></span><br><span class="line"> 4，</span><br><span class="line"></span><br><span class="line"> 9])</span><br><span class="line">&gt;&gt;&gt; 10*sin(a)###数乘，</span><br><span class="line"></span><br><span class="line">sin函数为正弦函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([ 9.12945251，</span><br><span class="line"></span><br><span class="line"> -9.88031624，</span><br><span class="line"></span><br><span class="line">  7.4511316 ，</span><br><span class="line"></span><br><span class="line"> -2.62374854])</span><br><span class="line">&gt;&gt;&gt; a&lt;35###指定条件判断后生成相应的布尔数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([True，</span><br><span class="line"></span><br><span class="line"> True，</span><br><span class="line"></span><br><span class="line"> False，</span><br><span class="line"></span><br><span class="line"> False]，</span><br><span class="line"></span><br><span class="line"> dtype=bool)</span><br><span class="line">&gt;&gt;&gt; A = array( [[1，</span><br><span class="line"></span><br><span class="line">1]，</span><br><span class="line"></span><br><span class="line">[0，</span><br><span class="line"></span><br><span class="line">1]] )</span><br><span class="line">&gt;&gt;&gt; B = array( [[2，</span><br><span class="line"></span><br><span class="line">0]，</span><br><span class="line"></span><br><span class="line">[3，</span><br><span class="line"></span><br><span class="line">4]] )</span><br><span class="line">&gt;&gt;&gt; A*B###乘法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">array([[2，</span><br><span class="line"></span><br><span class="line"> 0]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [0，</span><br><span class="line"></span><br><span class="line"> 4]])</span><br><span class="line">&gt;&gt;&gt; #dot表示乘积。对一维数组计算的是点积，对二维数组计算的是矩阵乘积</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...#此处表示矩阵乘积</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">... dot(A，</span><br><span class="line"></span><br><span class="line">B)</span><br><span class="line">array([[5，</span><br><span class="line"></span><br><span class="line"> 4]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [3，</span><br><span class="line"></span><br><span class="line"> 4]])</span><br><span class="line">&gt;&gt;&gt; a = ones((2，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> dtype=int)###ones函数创建全</span><br><span class="line"></span><br><span class="line">1数组，指定元素类型为</span><br><span class="line"></span><br><span class="line">int</span><br><span class="line">&gt;&gt;&gt; b = random.random((2，</span><br><span class="line"></span><br><span class="line">3))###创建随机数组，指定大小为</span><br><span class="line"></span><br><span class="line">(2，</span><br><span class="line"></span><br><span class="line">3)</span><br><span class="line">&gt;&gt;&gt; a *= 3###数乘</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[3，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 3]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [3，</span><br><span class="line"></span><br><span class="line"> 3，</span><br><span class="line"></span><br><span class="line"> 3]])</span><br><span class="line">&gt;&gt;&gt; b += a###加法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[ 3.69092703，</span><br><span class="line"></span><br><span class="line">  3.8324276 ，</span><br><span class="line"></span><br><span class="line">  3.0114541 ]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 3.18679111，</span><br><span class="line"></span><br><span class="line">  3.3039349 ，</span><br><span class="line"></span><br><span class="line">  3.37600289]])</span><br><span class="line">&gt;&gt;&gt; a += b   ###加法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[6，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 6]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [6，</span><br><span class="line"></span><br><span class="line"> 6，</span><br><span class="line"></span><br><span class="line"> 6]])</span><br><span class="line">&gt;&gt;&gt; a = random.random((2，</span><br><span class="line"></span><br><span class="line">3))</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[ 0.6903007 ，</span><br><span class="line"></span><br><span class="line">  0.39168346，</span><br><span class="line"></span><br><span class="line">  0.16524769]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 0.48819875，</span><br><span class="line"></span><br><span class="line">  0.77188505，</span><br><span class="line"></span><br><span class="line">  0.94792155]])</span><br><span class="line">&gt;&gt;&gt; a.sum()###求和</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3.4552372100521485</span><br><span class="line">&gt;&gt;&gt; a.min()###求最小值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0.16524768654743593</span><br><span class="line">&gt;&gt;&gt; a.max()###求最大值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0.9479215542670073</span><br></pre></td></tr></table></figure>

</details>

<p>7）数组的拷贝。数组的拷贝分为浅拷贝和深拷贝两种，浅拷贝通过数组变量的赋值完成，深拷贝使用数组对象的copy方法。</p>
<p>浅拷贝只拷贝数组的引用，如果对拷贝进行修改，源数组也将修改。下面的代码演示了浅拷贝的方法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a=ones((2，</span><br><span class="line"></span><br><span class="line">3))</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]])</span><br><span class="line">&gt;&gt;&gt; b=a###b为</span><br><span class="line"></span><br><span class="line">a的浅拷贝</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; b[1，</span><br><span class="line"></span><br><span class="line">2]=2</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  2.]])</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  2.]])</span><br></pre></td></tr></table></figure>

</details>

<p>深拷贝会复制一份和源数组一样的数组，新数组与源数组不会存放在同一内存位置中，因此，对新数组的修改不会影响源数组。下面的代码演示了b使用copy方法从源数组a复制一份拷贝的情况。可以看到，修改b后，a仍然不变。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a=ones((2，</span><br><span class="line"></span><br><span class="line">3))</span><br><span class="line">&gt;&gt;&gt; b = a.copy()</span><br><span class="line">&gt;&gt;&gt; b[1，</span><br><span class="line"></span><br><span class="line">2]=2</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">array([[ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]])</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line">array([[ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  1.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [ 1.，</span><br><span class="line"></span><br><span class="line">  1.，</span><br><span class="line"></span><br><span class="line">  2.]])</span><br></pre></td></tr></table></figure>

</details>

<p>2.矩阵</p>
<p>1）创建矩阵。Numpy的矩阵对象与数组对象相似，主要不同之处在于，矩阵对象的计算遵循矩阵数学运算规律。矩阵使用matrix函数创建，以（2，2）大小的矩阵（2行2列）为例，可用以下两种方式定义参数：</p>
<p>‘第1行第1列元素第1行第2列元素；第2行第1列元素第2行第2列元素’</p>
<p>[[第1行第1列元素，第1行第2列元素]，[第2行第1列元素，第2行第2列元素]]</p>
<p>下面的代码演示了矩阵的创建及类型查询方法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; A = matrix(&apos;1.0 2.0; 3.0 4.0&apos;)###矩阵</span><br><span class="line"></span><br><span class="line">A</span><br><span class="line">&gt;&gt;&gt; A</span><br><span class="line">[[ 1.  2.]</span><br><span class="line"> [ 3.  4.]]</span><br><span class="line">&gt;&gt;&gt; B = matrix([[1.0，</span><br><span class="line"></span><br><span class="line">2.0]，</span><br><span class="line"></span><br><span class="line">[3.0，</span><br><span class="line"></span><br><span class="line">4.0]])###矩阵</span><br><span class="line"></span><br><span class="line">B</span><br><span class="line">&gt;&gt;&gt; B</span><br><span class="line">matrix([[ 1.，</span><br><span class="line"></span><br><span class="line">  2.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 3.，</span><br><span class="line"></span><br><span class="line">  4.]])</span><br><span class="line">&gt;&gt;&gt; type(A)  # 查询</span><br><span class="line"></span><br><span class="line">A变量的类型</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;class &apos;numpy.matrixlib.defmatrix.matrix&apos;&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>2）矩阵运算。矩阵的常用数学运算有转置、乘法、求逆等。下面的代码演示了矩阵的基本运算（请先导入numpy库再执行以下代码）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; A.T               #转置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[[ 1.  3.]</span><br><span class="line"> [ 2.  4.]]</span><br><span class="line">&gt;&gt;&gt; X = matrix(&apos;5.0 7.0&apos;)</span><br><span class="line">&gt;&gt;&gt; Y = X.T           #转置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Y</span><br><span class="line">[[5.]</span><br><span class="line"> [7.]]</span><br><span class="line">&gt;&gt;&gt; print A*Y         #矩阵乘法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[[19.]</span><br><span class="line"> [43.]]</span><br><span class="line">&gt;&gt;&gt; print A.I         #逆矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[[-2.   1. ]</span><br><span class="line"> [ 1.5 -0.5]]</span><br><span class="line">&gt;&gt;&gt; solve(A，</span><br><span class="line"></span><br><span class="line"> Y)      #解线性方程组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">matrix([[-3.]，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [ 4.]])</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00005.jpg" alt> 注意 关于Numpy及其函数的更多信息可查阅Numpy官网：</p>
<p><a href="http://wiki.scipy.org/Numpy_Example_List" target="_blank" rel="noopener">http://wiki.scipy.org/Numpy_Example_List</a>  </p>
<h4 id="3-1-3-pylab、matplotlib绘图"><a href="#3-1-3-pylab、matplotlib绘图" class="headerlink" title="3.1.3 pylab、matplotlib绘图"></a>3.1.3 pylab、matplotlib绘图</h4><p>为了验证算法的有效性，机器学习通常需要进行绘图，pylab、matplotlib等模块是专业的Python绘图模块。</p>
<p>1.sin函数绘制</p>
<p>在二维坐标系中绘图的基本方式是使用plot方法，其参数分别为x轴数值、y轴数值，这里的数值可以是单个数也可以是Numpy的一维数组对象。下面的代码演示了sin函数图像的绘制。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">x = np.arange(0，</span><br><span class="line"></span><br><span class="line"> 5，</span><br><span class="line"></span><br><span class="line"> 0.1);</span><br><span class="line">y = np.sin(x)</span><br><span class="line">plt.plot(x，</span><br><span class="line"></span><br><span class="line"> y)</span><br></pre></td></tr></table></figure>

</details>

<p>如图3-2所示为sin函数图像效果图，从效果图上观察，曲线清晰，坐标系的标尺根据绘制参数已进行自动调整。</p>
<p>2.cos函数绘制</p>
<p>下面的代码使用plot方法绘制cos函数图像。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">x = np.arange(0，</span><br><span class="line"></span><br><span class="line"> 5，</span><br><span class="line"></span><br><span class="line"> 0.1);</span><br><span class="line">y = np.cos(x)</span><br><span class="line">plt.plot(x，</span><br><span class="line"></span><br><span class="line"> y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p>绘图效果如图3-3所示。</p>
<p><img src="Image00006.jpg" alt></p>
<p>图3-2 sin函数图像效果图</p>
<p><img src="Image00007.jpg" alt></p>
<p>图3-3 cos函数图像效果图</p>
<p>进一步扩充图3-3所示cos函数绘制范围，将自变量x的范围扩大到[-8，8]，三角函数cos图像的周期性一目了然，如图3-4所示。下面是绘制代码。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">x = np.arange(-8，</span><br><span class="line"></span><br><span class="line"> 8，</span><br><span class="line"></span><br><span class="line"> 0.1);</span><br><span class="line">y = np.cos(x)</span><br><span class="line">plt.plot(x，</span><br><span class="line"></span><br><span class="line"> y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00008.jpg" alt></p>
<p>图3-4 cos函数周期图像</p>
<p><img src="Image00009.jpg" alt></p>
<p>图3-5 树叶写真</p>
<h4 id="3-1-4-图像基础"><a href="#3-1-4-图像基础" class="headerlink" title="3.1.4 图像基础"></a>3.1.4 图像基础</h4><p>1.数字图像</p>
<p>数字图像是指将二维图像用有限数字的数值像素表示，像素表面上看起来不像分离的点，但实质它们就是点。例如，图3-5所示的树叶写真就是由很多像素点组成的，但用肉眼无法观察到像素点的存在。</p>
<p>我们使用一款取像素的软件对图3-5进行分析，如图3-6所示。可以看到，线的十字交叉处就是一个像素点，软件显示，在图像的[459，530]处像素点的值为（64，77，67）。中间是放大的这部分图片区域，放大后，图像仿佛由一个个小的颗粒组成，将这些颗粒进一步放大，就能看到颗粒是由若干个像素点组成，如果将图像完全放大，就能看清每个像素点的存在了。</p>
<p>（64，77，67）就是图3-6中某点的像素值。每个像素点可有各自的颜色值，可采用三原色显示，因而又分成红、绿、蓝三个子像素（RGB色域），或者青、品红、黄和黑（CMYK色域），通常计算机的图像采用的像素标准为红、绿、蓝三个子色。图3-6所示十字交叉处的像素值含义为：红色值为64，绿色值为77，蓝色值为67。</p>
<p><img src="Image00010.jpg" alt></p>
<p>图3-6 树叶放大的颗粒效果（附彩图）</p>
<p>分辨率是度量图像内数据量多少的一个参数，通常表示成每英寸像素数和每英寸点数。分辨率越高，图像包含的数据越多，就越能表现更丰富的细节，图形文件就越大。从图3-7能较直观地看出这个效果，随着分辨率的增加，字母R越来越清晰。</p>
<p><img src="Image00011.jpg" alt></p>
<p>图3-7 R字母在不同分辨率下的效果</p>
<p>2.OpenCV的Python绑定库实例</p>
<p>假设图像的分辨率为800×600，则每一条水平线上包含有800个像素点，共有600条线，在计算机中可以使用一个800列600行的数组来表示该图像。数组的每个元素就是一个像素点，比如，第100行第200列的元素就是图像的第100条水平线第200个像素点的像素值。那么如何提取图像中的像素值呢？</p>
<p>可以使用OpenCV的Python绑定库完成这些操作。OpenCV作为跨平台的计算机视觉库，拥有包括500多个跨平台图像处理的中、高层API，对图像像素的读写自然不在话下。</p>
<p>使用OpenCV函数库之前，需要先导入其Python绑定库。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br></pre></td></tr></table></figure>

</details>

<p>OpenCV函数对像素点的读写操作可理解为对图像矩阵的存取，OpenCV图像矩阵中每个像素点的值由蓝色值、绿色值、红色值3个部分组成，三色值组合成一个一维数组。假设A图像的高度（行数）为H，宽度（列数）为W，则A图像对应的图像矩阵大小为H×W×3，A图像矩阵可表示H行W列（共H×W个）像素点的组合。</p>
<p>如果想读取A图像150行20列处的像素值（设A的图像矩阵变量为img_a），可进行如下访问：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img_a[150，</span><br><span class="line"></span><br><span class="line">20，</span><br><span class="line"></span><br><span class="line">:]</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码中第1行是150行20列处像素的蓝色值，第2行是150行20列处像素的绿色值，第3行是150行20列处像素的红色值。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">blue=img_a[150，</span><br><span class="line"></span><br><span class="line">20，</span><br><span class="line"></span><br><span class="line">0]</span><br><span class="line">green=img_a[150，</span><br><span class="line"></span><br><span class="line">20，</span><br><span class="line"></span><br><span class="line">1]</span><br><span class="line">red=img_a[150，</span><br><span class="line"></span><br><span class="line">20，</span><br><span class="line"></span><br><span class="line">2]</span><br></pre></td></tr></table></figure>

</details>

<p>下面以几个经典实例演示OpenCV的Python绑定库的使用方法。</p>
<p>1）显示图像。程序原理是，首先使用imread（文件名）读取图像文件，生成图像矩阵，然后调用imshow方法显示图像，调用waitKey()方法等待按键，最后调用destroyAllWindows()销毁窗口，这样可方便查看图像。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#3-1.py</span><br><span class="line">import cv2</span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;&lt;http://blog.csdn.net/myhaspl&gt;</span><br><span class="line"></span><br><span class="line">&apos;</span><br><span class="line">    print &apos;myhaspl@qq.com&apos;</span><br><span class="line">    print</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    cv2.imshow(&apos;preview&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>效果如图3-8所示。</p>
<p>2）随机生成像素。程序的原理是，首先产生空图像矩阵，然后确定矩阵的2000个随机位置，最后将随机位置处的像素值设置为随机数数组。下面是源代码。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#随机生成像素点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3-2.py</span><br><span class="line">#导入</span><br><span class="line"></span><br><span class="line">numpy和</span><br><span class="line"></span><br><span class="line">opencv函数库</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    #行数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz1 = 200</span><br><span class="line">    #列数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz2 = 300</span><br><span class="line">    print u&apos;产生空图像矩阵</span><br><span class="line"></span><br><span class="line">(%d*%d) ...&apos; % (sz1，</span><br><span class="line"></span><br><span class="line"> sz2)</span><br><span class="line">#产生空图像矩阵，大小为</span><br><span class="line"></span><br><span class="line">sz1*sz2(行数</span><br><span class="line"></span><br><span class="line">*列数</span><br><span class="line"></span><br><span class="line">)，本程序为</span><br><span class="line"></span><br><span class="line">200*300</span><br><span class="line">    img =np.zeros((sz1，</span><br><span class="line"></span><br><span class="line"> sz2，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> np.uint8)</span><br><span class="line">    pos1=np.random.randint(200，</span><br><span class="line"></span><br><span class="line">size=(2000，</span><br><span class="line"></span><br><span class="line"> 1))###行位置随机数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    pos2=np.random.randint(300，</span><br><span class="line"></span><br><span class="line">size=(2000，</span><br><span class="line"></span><br><span class="line"> 1))###列位置随机数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #在随机位置处设置像素点值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for i in range(2000):</span><br><span class="line">        img[pos1[i]，</span><br><span class="line"></span><br><span class="line">pos2[i]，</span><br><span class="line"></span><br><span class="line">[0]]=np.random.randint(0，</span><br><span class="line"></span><br><span class="line">255)</span><br><span class="line">        img[pos1[i]，</span><br><span class="line"></span><br><span class="line">pos2[i]，</span><br><span class="line"></span><br><span class="line">[1]]=np.random.randint(0，</span><br><span class="line"></span><br><span class="line">255)</span><br><span class="line">        img[pos1[i]，</span><br><span class="line"></span><br><span class="line">pos2[i]，</span><br><span class="line"></span><br><span class="line">[2]]=np.random.randint(0，</span><br><span class="line"></span><br><span class="line">255)</span><br><span class="line">    #显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.imshow(&apos;preview&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    #等待按键</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    #销毁窗口</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00012.jpg" alt></p>
<p>图3-8 显示图像</p>
<p>随机产生像素点后，创建新窗口并显示含彩色雪花点的图像，运行以上代码：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    产生空图像矩阵</span><br><span class="line"></span><br><span class="line">(200*300) ...</span><br></pre></td></tr></table></figure>

</details>

<p>效果如图3-9所示。</p>
<p><img src="Image00013.jpg" alt></p>
<p>图3-9 随机产生若干像素点（附彩图）</p>
<p>3）获取图像大小。程序通过图像矩阵的shape属性获取图像大小，shape返回tuple元组，元组的第1个元素为高度，第2个元素为宽度，第3个元素为3（像素值由三原色组成）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-3.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test2.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    #获取图像矩阵大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sp=img.shape</span><br><span class="line">    print sp</span><br><span class="line">    #高度，即行数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz1=sp[0]</span><br><span class="line">    #宽度，即列数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz2=sp[1]</span><br><span class="line">    print &apos;width:%d\nheight:%d&apos;%(sz2，</span><br><span class="line"></span><br><span class="line">sz1)</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如下，程序返回图像的高为435，宽为656。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">loading test1.jpg ...</span><br><span class="line">(435，</span><br><span class="line"></span><br><span class="line"> 656，</span><br><span class="line"></span><br><span class="line"> 3)</span><br><span class="line">width:656</span><br><span class="line">height:435</span><br></pre></td></tr></table></figure>

</details>

<p>4）调节图像亮度。调节的原理是，将像素值变小，则将亮度调小，全部色彩变暗；将像素值变大，则将亮度调大，全部色彩变亮。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-4.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0]</span><br><span class="line">    ii=0</span><br><span class="line">    #将全部色彩变暗</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for xi in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">        for xj in xrange (0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        #将像素值整体减少，设为原像素值的</span><br><span class="line"></span><br><span class="line">20%</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]*0.2)</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]*0.2)</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]*0.2)</span><br><span class="line">    #显示进度条</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if  xi%10==0 :print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)</span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line">    print&apos;&apos;</span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos; ，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #将全部色彩变亮</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for xi in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">        for xj in xrange (0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">            #将像素值整体增加，设为原像素值的</span><br><span class="line"></span><br><span class="line">1020%</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]*10.2)</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]*10.2)</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]*10.2)</span><br><span class="line">        if  xi%10==0 :print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)</span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>上面程序将图像每个像素值减少，实现图像亮度变暗的效果，如图3-10所示。然后每个像素值增大，实现图像亮度变亮的效果。</p>
<p>如图3-11所示为图像变亮效果，因为像素值过大，已经出现失真现象。</p>
<p><img src="Image00014.jpg" alt></p>
<p>图3-10 图像变暗（附彩图）</p>
<p><img src="Image00015.jpg" alt></p>
<p>图3-11 图像变亮（附彩图）</p>
<p>5）图像日落效果。日落效果的生成原理很简单，将蓝色值和绿色值设为原来的70%，红色值不变，设图像矩阵为img。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">    #生成日落效果</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for xi in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">        for xj in xrange (0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]*0.7)###蓝色值为原来的</span><br><span class="line"></span><br><span class="line">70%</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]*0.7)###绿色值为原来的</span><br><span class="line"></span><br><span class="line">70%</span><br></pre></td></tr></table></figure>

</details>

<p>完整代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-5.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0]</span><br><span class="line">    ii=0</span><br><span class="line">    #生成日落效果</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for xi in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">        for xj in xrange (0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]*0.7)###蓝色值为原来的</span><br><span class="line"></span><br><span class="line">70%</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= int(img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]*0.7)###绿色值为原来的</span><br><span class="line"></span><br><span class="line">70%</span><br><span class="line">        #显示进度条</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if  xi%10==0 :print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">    #显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)</span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-12所示。</p>
<p><img src="Image00016.jpg" alt></p>
<p>图3-12 图像日落效果（附彩图）</p>
<p>6）负片与水印效果。生成负片的原理是，将像素的三色值设为（255-原值）。设图像矩阵为img，代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   #生成负片</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">   b，</span><br><span class="line"></span><br><span class="line">g，</span><br><span class="line"></span><br><span class="line">r = cv2.split(img)</span><br><span class="line">   b=255-b</span><br><span class="line">   g=255-g</span><br><span class="line">   r=255-r</span><br></pre></td></tr></table></figure>

</details>

<p>水印效果的原理是，调用putText函数，以图像矩阵为第1个参数，输出内容为第2个参数，在图像上直接输出水印文字。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">    #加上水印</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv2.putText(img，</span><br><span class="line"></span><br><span class="line">&quot;machine learning&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">20)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2.0，</span><br><span class="line"></span><br><span class="line"> (0，</span><br><span class="line"></span><br><span class="line"> 0，</span><br><span class="line"></span><br><span class="line"> 0)，</span><br><span class="line"></span><br><span class="line"> thickness = 2)</span><br><span class="line">cv2.putText(img，</span><br><span class="line"></span><br><span class="line">&quot;Support Vector Machines(SVMs)is an algorithm </span><br><span class="line">of machine learning.&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">100)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 1.0，</span><br><span class="line"></span><br><span class="line"> (0，</span><br><span class="line"></span><br><span class="line"> 0，</span><br><span class="line"></span><br><span class="line"> 0)，</span><br><span class="line"></span><br><span class="line"> thickness = 2)</span><br></pre></td></tr></table></figure>

</details>

<p>负片与水印效果的完整代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-6.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #读取图像文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    #获取图像大小</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0]</span><br><span class="line">    ii=0</span><br><span class="line">    #生成负片</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    b，</span><br><span class="line"></span><br><span class="line"> g，</span><br><span class="line"></span><br><span class="line"> r = cv2.split(img)</span><br><span class="line">    b=255-b</span><br><span class="line">    g=255-g</span><br><span class="line">    r=255-r</span><br><span class="line">    #直接通过索引改变色彩分量</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    img[:，</span><br><span class="line"></span><br><span class="line">:，</span><br><span class="line"></span><br><span class="line">0]=b</span><br><span class="line">    img[:，</span><br><span class="line"></span><br><span class="line">:，</span><br><span class="line"></span><br><span class="line">1]=g</span><br><span class="line">    img[:，</span><br><span class="line"></span><br><span class="line">:，</span><br><span class="line"></span><br><span class="line">2]=r</span><br><span class="line">    #加上水印</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.putText(img，</span><br><span class="line"></span><br><span class="line">&quot;machine learning&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">20)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2.0，</span><br><span class="line"></span><br><span class="line"> (0，</span><br><span class="line"></span><br><span class="line"> 0，</span><br><span class="line"></span><br><span class="line"> 0)，</span><br><span class="line"></span><br><span class="line"> thickness = 2)</span><br><span class="line">    cv2.putText(img，</span><br><span class="line"></span><br><span class="line">&quot;Support Vector Machines(SVMs)is an algorithm </span><br><span class="line">of machine learning.&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">100)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 1.0，</span><br><span class="line"></span><br><span class="line"> (0，</span><br><span class="line"></span><br><span class="line"> 0，</span><br><span class="line"></span><br><span class="line"> 0)，</span><br><span class="line"></span><br><span class="line"> thickness = 2) </span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-13所示。</p>
<p><img src="Image00017.jpg" alt></p>
<p>图3-13 负片和水印效果（附彩图）</p>
<p>7）图像平铺。图像平铺的原理是，首先计算平铺后的图像大小，生成同样大小的空白图像，然后在空白图像中逐个像素复制图像，直接将空白图像像素值设置为平铺后该位置对应的像素值，复制的顺序是逐行复制，横向平铺5个图像，纵向平铺2个图像，最后显示图像效果。下面是完整代码：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-7.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test.png&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print &apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0]</span><br><span class="line">    #横向平铺</span><br><span class="line"></span><br><span class="line">5个图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz1=w*5</span><br><span class="line">    #纵向平铺</span><br><span class="line"></span><br><span class="line">2个图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz0=h*2</span><br><span class="line">    #创建空白图像，然后将图片排列</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    myimg1=np.zeros((sz0，</span><br><span class="line"></span><br><span class="line">sz1，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> np.uint8)   </span><br><span class="line">    #逐个像素复制</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img_x=0</span><br><span class="line">    img_y=0</span><br><span class="line">    for now_y in xrange(0，</span><br><span class="line"></span><br><span class="line">sz0):</span><br><span class="line">    #增加行数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for now_x in xrange(0，</span><br><span class="line"></span><br><span class="line">sz1):</span><br><span class="line">            #复制对应位置的图像像素点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            myimg1[now_y，</span><br><span class="line"></span><br><span class="line">now_x，</span><br><span class="line"></span><br><span class="line">0]=img[img_y，</span><br><span class="line"></span><br><span class="line">img_x，</span><br><span class="line"></span><br><span class="line">0]</span><br><span class="line">            myimg1[now_y，</span><br><span class="line"></span><br><span class="line">now_x，</span><br><span class="line"></span><br><span class="line">1]=img[img_y，</span><br><span class="line"></span><br><span class="line">img_x，</span><br><span class="line"></span><br><span class="line">1]</span><br><span class="line">            myimg1[now_y，</span><br><span class="line"></span><br><span class="line">now_x，</span><br><span class="line"></span><br><span class="line">2]=img[img_y，</span><br><span class="line"></span><br><span class="line">img_x，</span><br><span class="line"></span><br><span class="line">2]</span><br><span class="line">            #增加列数</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">            img_x+=1</span><br><span class="line">            if img_x&gt;=w:</span><br><span class="line">                img_x=0   </span><br><span class="line">        img_y+=1     </span><br><span class="line">        if img_y&gt;=h:</span><br><span class="line">            img_y=0         </span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img1&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img1&apos;，</span><br><span class="line"></span><br><span class="line"> myimg1) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-14所示。</p>
<p><img src="Image00018.jpg" alt></p>
<p>图3-14 图像平铺</p>
<p>8）转置并平铺图像。与刚才的例子相似，但多了一步转置操作。转置的原理是将图像矩阵转换为它的转置矩阵，转置算法是将新图像矩阵[h，w]处的像素设为原图像矩阵[w，h]处的值（这里的值是一维矩阵），相当于矩阵转置的算法。设myimg1为图像矩阵，编写代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    for now_y in xrange(0，</span><br><span class="line"></span><br><span class="line">sz0):</span><br><span class="line">        for now_x in xrange(0，</span><br><span class="line"></span><br><span class="line">sz1):</span><br><span class="line">             myimg1[now_x，</span><br><span class="line"></span><br><span class="line">now_y，</span><br><span class="line"></span><br><span class="line">:]=img[img_y，</span><br><span class="line"></span><br><span class="line">img_x，</span><br><span class="line"></span><br><span class="line">:]</span><br></pre></td></tr></table></figure>

</details>

<p>转置并平铺图像完整代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-8.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test.png&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print &apos;working&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0]</span><br><span class="line">    #w为宽度，</span><br><span class="line"></span><br><span class="line">h为高度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sz1=w*2</span><br><span class="line">    sz0=h*3</span><br><span class="line">    #创建空白图像，然后将图片排列</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    myimg1=np.zeros((sz1，</span><br><span class="line"></span><br><span class="line">sz0，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> np.uint8)   </span><br><span class="line">    #翻转并生成图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #逐个复制像素</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img_x=0</span><br><span class="line">    img_y=0</span><br><span class="line">    for now_y in xrange(0，</span><br><span class="line"></span><br><span class="line">sz0):</span><br><span class="line">        for now_x in xrange(0，</span><br><span class="line"></span><br><span class="line">sz1):</span><br><span class="line">            #旋转图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            myimg1[now_x，</span><br><span class="line"></span><br><span class="line">now_y，</span><br><span class="line"></span><br><span class="line">:]=img[img_y，</span><br><span class="line"></span><br><span class="line">img_x，</span><br><span class="line"></span><br><span class="line">:]        </span><br><span class="line">            img_x+=1</span><br><span class="line">            #新的一次平铺</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            if img_x&gt;=w:</span><br><span class="line">                img_x=0</span><br><span class="line">        img_y+=1</span><br><span class="line">        #新的一次平铺</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">        if img_y&gt;=h:</span><br><span class="line">            img_y=0         </span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    cv2.namedWindow(&apos;img1&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img1&apos;，</span><br><span class="line"></span><br><span class="line"> myimg1) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-15所示。</p>
<p><img src="Image00019.jpg" alt></p>
<p>图3-15 图像旋转和平铺</p>
<h4 id="3-1-5-图像融合与图像镜像"><a href="#3-1-5-图像融合与图像镜像" class="headerlink" title="3.1.5 图像融合与图像镜像"></a>3.1.5 图像融合与图像镜像</h4><p>本节的两个例子是对上节内容精华的总结，较好地综合了OpenCV的基础功能。</p>
<p>1.图像融合</p>
<p>图像融合的原理是，让新图像的每个像素成为两个源图像中对应像素的平均值之和，即：将两个图像的像素值取50%后相加。为简化计算，直接选取其中一个源图像作为新图像，设新图像矩阵为myimg2，编写代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    #每个像素为</span><br><span class="line"></span><br><span class="line">2个像素的平均值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for y in xrange(0，</span><br><span class="line"></span><br><span class="line">sz0):</span><br><span class="line">        for x in xrange(0，</span><br><span class="line"></span><br><span class="line">sz1):</span><br><span class="line">              myimg2[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]=myimg1[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]*0.5+myimg2[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]*0.5</span><br></pre></td></tr></table></figure>

</details>

<p>完整代码如下（关键之处有注释）：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-9.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn1=&quot;he1.jpg&quot;</span><br><span class="line">fn2=&quot;he2.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;working&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    myimg1 = cv2.imread(fn1)</span><br><span class="line">    myimg2 = cv2.imread(fn2)</span><br><span class="line">    #取得图像大小</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    w=myimg1.shape[1]</span><br><span class="line">    h=myimg1.shape[0]</span><br><span class="line">    sz1=w</span><br><span class="line">    sz0=h</span><br><span class="line">    #每个像素为</span><br><span class="line"></span><br><span class="line">2个像素的</span><br><span class="line"></span><br><span class="line">50%之和，进行图像融合</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for y in xrange(0，</span><br><span class="line"></span><br><span class="line">sz0):</span><br><span class="line">        for x in xrange(0，</span><br><span class="line"></span><br><span class="line">sz1):</span><br><span class="line">            myimg2[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]=myimg1[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]*0.5+myimg2[y，</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">:]*0.5</span><br><span class="line">            print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img2&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img2&apos;，</span><br><span class="line"></span><br><span class="line"> myimg2) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>效果如图3-16所示。</p>
<p><img src="Image00020.jpg" alt></p>
<p>图3-16 图像融合</p>
<p>2.图像镜像</p>
<p>图像纵向镜像的原理是，首先获取图像的宽度，将宽度的50%取整后作为图像的纵向中线；然后以中线为轴，将图像左边反向复制到图像右边，使图像最右边一列的像素点等于图像最左边一列的像素点。比如，图像大小为200×300（高200，宽300），第180行170列（索引为[180，170，:]）的像素点值为第180行第130列的像素点值（300-170=130）。</p>
<p>横向镜像与纵向镜像类似，不同之处在于将高度的50%取整后作为图像的横向中线，复制时是最下边一行的像素点值等于最上边一行的像素点值。</p>
<p>纵向镜像可按如下形式编写代码：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#纵向生成镜像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    mirror_w=w/2</span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">mirror_w):</span><br><span class="line">            img[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">:]=img[j，</span><br><span class="line"></span><br><span class="line">w-i-1，</span><br><span class="line"></span><br><span class="line">:]</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码演示了图像的纵向镜像。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-10.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    print &apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    w=img.shape[1]</span><br><span class="line">    h=img.shape[0] </span><br><span class="line">    ii=0</span><br><span class="line">    #纵向生成镜像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    mirror_w=w/2</span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">         for i in xrange (0，</span><br><span class="line"></span><br><span class="line"> mirror _w):</span><br><span class="line">        img[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">:]=img[j，</span><br><span class="line"></span><br><span class="line">w-i</span><br><span class="line">-1，</span><br><span class="line"></span><br><span class="line">:]</span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-17所示。</p>
<p><img src="Image00021.jpg" alt></p>
<p>图3-17 图像镜像</p>
<h4 id="3-1-6-图像灰度化与图像加噪"><a href="#3-1-6-图像灰度化与图像加噪" class="headerlink" title="3.1.6 图像灰度化与图像加噪"></a>3.1.6 图像灰度化与图像加噪</h4><p>1.图像灰度化</p>
<p>图像灰度化的原理是，彩色图像中的每个像素的颜色由R、G、B三个分量决定，而每个分量的取值范围为0~255。而灰度图像是R、G、B三个分量相同的一种特殊的彩色图像，其算法有以下两种：</p>
<p>1）求出每个像素点的R、G、B三个分量的平均值，然后将这个平均值赋予给这个像素的三个分量。</p>
<p>2）根据RGB和YUV颜色空间的变化关系，建立亮度Y与R、G、B三个颜色分量的对应关系：Y=0.3R+0.59G+0.11B，以这个亮度值表达图像的灰度值。</p>
<p>OpenCV有相关的函数cvtColor，用它可直接完成灰度化操作。设img为源图像矩阵，myimg1为灰度化后的目标图像矩阵，编写代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">     #复制并转换为灰度化图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    myimg1=cv2.cvtColor(img，</span><br><span class="line"></span><br><span class="line">cv2.COLOR_BGR2GRAY)</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码演示了图像的复制与图像的灰度化操作。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-11.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">fn=&quot;test2.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    sp=img.shape</span><br><span class="line">    print sp</span><br><span class="line">    #获取图像大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #height</span><br><span class="line">    sz1=sp[0]</span><br><span class="line">    #width</span><br><span class="line">    sz2=sp[1]</span><br><span class="line">    #显示图像大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print &apos;width:%d\nheight:%d&apos;%(sz2，</span><br><span class="line"></span><br><span class="line">sz1)</span><br><span class="line">    #创建一个窗口并显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img)</span><br><span class="line">    #复制图像矩阵，生成与源图像一样的图像，并显示</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    myimg2= img.copy();</span><br><span class="line">    cv2.namedWindow(&apos;myimg2&apos;)  </span><br><span class="line">    cv2.imshow(&apos;myimg2&apos;，</span><br><span class="line"></span><br><span class="line"> myimg2) </span><br><span class="line">    #复制并转换为灰度化图像，并显示</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    myimg1=cv2.cvtColor(img，</span><br><span class="line"></span><br><span class="line">cv2.COLOR_BGR2GRAY)</span><br><span class="line">    cv2.namedWindow(&apos;myimg1&apos;)  </span><br><span class="line">    cv2.imshow(&apos;myimg1&apos;，</span><br><span class="line"></span><br><span class="line"> myimg1) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码生成了与源图像一样的新图像，并生成了另一个源图像的灰度化图像，运行效果如图3-18所示。</p>
<p><img src="Image00022.jpg" alt></p>
<p>图3-18 图像灰度化（附彩图）</p>
<p>现在大部分的彩色图像都是采用RGB颜色模式，处理图像的时候，要分别对RGB三种分量进行处理。实际上RGB并不能反映图像的形态特征，只是从光学的原理进行颜色的调配。把图像转换成8位的灰度值图像直接进行处理，可以通过直方图、灰度变化及正交变换之类数学运算对图像做进一步处理，比如说图像识别等。如果有必要，可将图像二值化，这样有利于对图像进一步处理，使图像数据量减小，突显出感兴趣的目标的轮廓。如图3-19所示为某汽车图像二值化的效果。</p>
<p><img src="Image00023.jpg" alt></p>
<p>图3-19 图像二值化</p>
<p>2.图像加噪</p>
<p>给图像人为加噪的原理是，将图像若干个像素点的值设为噪声点的值。比如，为图像加上很多像素值为[25，20，20]的像素点，编写代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> for k in xrange(0，</span><br><span class="line"></span><br><span class="line">coutn):</span><br><span class="line">        xi = int(np.random.uniform(0，</span><br><span class="line"></span><br><span class="line">img.shape[1]))</span><br><span class="line">        xj = int(np.random.uniform(0，</span><br><span class="line"></span><br><span class="line">img.shape[0]))</span><br><span class="line">        if img.ndim == 2: </span><br><span class="line">                     #灰度图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi] = 255</span><br><span class="line">        elif img.ndim == 3: </span><br><span class="line">                     #非灰度图像，图像加噪</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= 25</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= 20</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]= 20</span><br></pre></td></tr></table></figure>

</details>

<p>上面的代码对img.ndim进行判断的用意在于，如果图像是灰度化图像，则img.ndim为2，灰度化图像的像素值不存在红、绿、蓝三色之分，仅有灰度值，因此像素值仅需要一个，将对应噪声点位置的值设为255即可。</p>
<p>下面的代码演示了图像加噪的算法，为彩色图像人为加上100000个色彩随机的噪声点。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#3-12.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">#需要加噪的图像文件名</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">fn=&quot;test1.jpg&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    #加载图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    print &apos;loading %s ...&apos; % fn</span><br><span class="line">    img = cv2.imread(fn)</span><br><span class="line">    #噪声点数量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    coutn=100000</span><br><span class="line">    for k in xrange(0，</span><br><span class="line"></span><br><span class="line">coutn):</span><br><span class="line">        #获取图像噪声点的随机位置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        xi = int(np.random.uniform(0，</span><br><span class="line"></span><br><span class="line">img.shape[1]))</span><br><span class="line">        xj = int(np.random.uniform(0，</span><br><span class="line"></span><br><span class="line">img.shape[0]))</span><br><span class="line">            #图像加噪声点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if img.ndim == 2: </span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi] = 255</span><br><span class="line">        elif img.ndim == 3: </span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">0]= 25</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">1]= 20</span><br><span class="line">            img[xj，</span><br><span class="line"></span><br><span class="line">xi，</span><br><span class="line"></span><br><span class="line">2]= 20</span><br><span class="line">    cv2.namedWindow(&apos;img&apos;)  </span><br><span class="line">    cv2.imshow(&apos;img&apos;，</span><br><span class="line"></span><br><span class="line"> img) </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行效果如图3-20所示。</p>
<p><img src="Image00024.jpg" alt></p>
<p>图3-20 图像加噪</p>
<p>上述程序的运行原理是将图像数据矩阵随机位置的像素点设为（25，20，20），当随机的像素点数量较大时，就在图像上生成了噪声。</p>
<p>加上噪声的图像是为了实验图像识别的效果，有些机器学习算法对没有噪声的图像识别的效果很好，但如图3-20这种噪声较多的情况效果就很不理想了，因为在实际工程应用中，很难保证采集到的图像清晰可靠，所以需要人为给图像加上噪声，以方便后期对算法效果进行验证。</p>
<h4 id="3-1-7-声音基础"><a href="#3-1-7-声音基础" class="headerlink" title="3.1.7 声音基础"></a>3.1.7 声音基础</h4><p>1.声音原理</p>
<p>声音是由物体的机械振动形成的，发生声音的振动源叫作“声源”。振动着的鼓皮、琴弦、扬声器等都是声源，人的声带也是声源。声音必须通过媒质才能传播，空气、水、金属、木材等是最常见的媒质。声波的频率是每秒钟往复振动的次数，一来一往为一次，又称一周，声波的频率也就是声音的频率，频率单位为赫兹（Hz），每秒振动一周为1Hz。“波长”是声源每振动一周声波所传播的距离，频率越高则波长越短，波长同频率成反比。</p>
<p>“相位”可简称为“相”。一般地说，相位是用来描述简谐振动的，在一个周波之内，任何一点的“相”都不相同，各对应于一个确定的相位角值；而在另一个周波，各种相位将会重复出现。所以在声波传播的路径上，每隔一个波长的距离，其相位相同。</p>
<p>声音的音调是由它的基频决定的，基频越高则音调也越高。如在音乐中中央C的基频是261.6Hz，而A调的基频则是440Hz。通常将声音分为以下频带：20Hz、25Hz、31.5Hz、40Hz、50Hz、63Hz、80Hz、100Hz、125Hz、160Hz、200Hz、250Hz、315Hz、400Hz、500Hz、630Hz、800Hz、1kHz、1.25kHz、1.60kHz、2.0kHz、2.5kHz、3.15kHz、4.0kHz、5.0kHz、6.3kHz、8.0kHz、10kHz、12.5kHz、16kHz、20kHz。一般来说，人耳可感受的正弦波的范围是从20Hz的低频声音到20kHz的高频声。</p>
<p>2.声音波形</p>
<p>声音波波形属于正弦波，拥有振幅和频率两个特征，振幅就是音量，频率就是音调。下面调用Python的WAV声音处理库以及Numpy科学计算库显示一段声音的波形。</p>
<p>显示声音波形数据的主要步骤如下：</p>
<p>1）打开WAV文件，使用wave库的open方法，主要参数为文件名和存取文件方式。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#以读方式打开</span><br><span class="line"></span><br><span class="line">WAV文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = wave.open(r&quot;back.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>2）读取格式信息，使用wave库的getparams方法。该方法返回的信息中比较重要的是前4项，依次为通道数、样本宽度、样本频率、波形数据长度。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#读取格式信息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#(nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes，</span><br><span class="line"></span><br><span class="line"> comptype，</span><br><span class="line"></span><br><span class="line"> compname)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br></pre></td></tr></table></figure>

</details>

<p>3）读取波形数据，波形数据是WAV文件采样后生成的采样数据，使用wave库的readframes方法读取，该方法返回的数据是字符类型。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#读取波形数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">str_data = f.readframes(nframes)</span><br></pre></td></tr></table></figure>

</details>

<p>4）转换波形数据为Numpy的整型数组对象。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#将波形数据转换为数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data = np.fromstring(str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">wave_data = wave_data.T</span><br></pre></td></tr></table></figure>

</details>

<p>5）计算时间轴。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br></pre></td></tr></table></figure>

</details>

<p>6）绘制波形，绘制前调用pylab的subplot方法创建两个上下形式的绘图区，每个绘图区各绘制一个声道的数据。下面程序中subplot方法的参数共3位整数，从左边开始每位依次表示绘图区总数、列数、创建区域所属绘图的索引，比如subplot(212)表示绘图区有2个，一共1列，当前索引为第2个绘图区。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#绘制波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建上边的绘图区</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pl.subplot(211)</span><br><span class="line">#绘制左声道</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[0])</span><br><span class="line">#创建下边的绘图区</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pl.subplot(212)</span><br><span class="line">#绘制右声道</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>上述绘制声音波形过程的完整代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python  </span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com </span><br><span class="line">#3-13.py</span><br><span class="line">import wave</span><br><span class="line">import pylab as pl</span><br><span class="line">import numpy as np </span><br><span class="line">print &apos;working...&apos; </span><br><span class="line">#打开</span><br><span class="line"></span><br><span class="line">WAV文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = wave.open(r&quot;back.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)</span><br><span class="line">#读取格式信息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#(nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes，</span><br><span class="line"></span><br><span class="line"> comptype，</span><br><span class="line"></span><br><span class="line"> compname)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br><span class="line">#读取波形数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">str_data = f.readframes(nframes)</span><br><span class="line">f.close()</span><br><span class="line">#将波形数据转换为数组</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data = np.fromstring(str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">wave_data = wave_data.T</span><br><span class="line">time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br><span class="line">#绘制波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pl.subplot(211)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[0])</span><br><span class="line">pl.subplot(212)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>程序读取声音文件后，绘制出如图3-21所示的波形。</p>
<p>这个波形表现出：声音信号较连续，随着时间的推移，变化不明显，没有停顿，因此，这是一段音乐或噪声等声音而不是人声，因为人说话的声音有个特点，就是每个字之间有少量停顿。语音停顿期间，声音采样软件采样不到数据，过了这个停顿期，波形会有明显的变化，如图3-22所示波形就是典型的说话声音波形。</p>
<h4 id="3-1-8-声音音量调节"><a href="#3-1-8-声音音量调节" class="headerlink" title="3.1.8 声音音量调节"></a>3.1.8 声音音量调节</h4><p>声音音量的调节方式与图像亮度调整类似，不同的是音量调节的是波形大小。音量调节通过调节采样波形的大小实现，采样数据变大时，声音音量放大，采样数据变小时，声音音量降低。音量不能无限调节，音量过大或过小，会形成难听的噪音，使声音失真。</p>
<p><img src="Image00025.jpg" alt></p>
<p>图3-21 声音波形绘制</p>
<p><img src="Image00026.jpg" alt></p>
<p>图3-22 说话声音波形</p>
<p>1.放大音量</p>
<p>下面编写代码演示音量的放大。为保证声音质量，需要对音量调节范围设置上限和下限（以原声音为基准计算上限、下限）。为此，编写wavechange函数，计算调整后的数据，其参数x为每次采样的波形数据，dwmax为上限，dwmin为下限，该函数仅会将上限与下限之间区域内的数据放大为原来的1.5倍，在此区域外的数据则设置为上限或下限。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def wavechange(x，</span><br><span class="line"></span><br><span class="line">dwmax，</span><br><span class="line"></span><br><span class="line">dwmin):</span><br><span class="line">    if x!=0:</span><br><span class="line">        if abs(x)&gt;dwmax:</span><br><span class="line">            x=x/abs(x)*dwmax</span><br><span class="line">        elif abs(x)&lt;dwmin:</span><br><span class="line">            x=x/abs(x)*dwmin</span><br><span class="line">        else:</span><br><span class="line">            x=x*1.5</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

</details>

<p>为保证放大后声音不失真，可采用以原声音为基准的放大策略，声音波形图像类似正弦函数图像，在以时间轴为X轴、采样数据为Y轴的坐标系中，波形数据可正可负，上下波动。因此，以原声音数据的最大值为依据计算上下限，上限为原声音数据最大值的88%，下限为原声音数据最大值的14%。</p>
<p>使用wave_data.max()获取原声音波形的最大数据值（max函数返回数组的最大值），然后通过frompyfunc函数设置调节音量的回调函数为刚刚定义的wavechange函数，最后对数据进行放大调节。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#放大音量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">change_dwmax=wave_data.max()/100*88</span><br><span class="line">change_dwmin=wave_data.max()/100*14</span><br><span class="line">wave_change = np.frompyfunc(wavechange，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">1)</span><br><span class="line">new_wave_data =wave_change(wave_data，</span><br><span class="line"></span><br><span class="line">change_dwmax，</span><br><span class="line"></span><br><span class="line">change_dwmin)</span><br></pre></td></tr></table></figure>

</details>

<p>声音数据放大后，需要将新数据写入新的声音文件中。首先以写方式新建新声音文件：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fo = wave.open(r&quot;jg.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;wb&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>然后，设置新文件的数据参数为源文件的数据参数，并写到新声音文件中。放大音量并没有改变格式信息，因此，放大后的声音与源声音的格式信息一样。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;save new wav files....&quot;</span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br></pre></td></tr></table></figure>

</details>

<p>最后调用writeframes()方法，以放大后声音数据为参数将数据写入新建的声音文件中。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fo.writeframes(new_str_data)</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码演示了放大音量的算法，并绘制出了源声音波形与放大后的声音波形。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python  </span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-14.py </span><br><span class="line">import wave</span><br><span class="line">import pylab as pl</span><br><span class="line">import numpy as np</span><br><span class="line">def wavechange(x，</span><br><span class="line"></span><br><span class="line">dwmax，</span><br><span class="line"></span><br><span class="line">dwmin):</span><br><span class="line">    if x!=0:</span><br><span class="line">        if abs(x)&gt;dwmax:</span><br><span class="line">            x=x/abs(x)*dwmax</span><br><span class="line">        elif abs(x)&lt;dwmin:</span><br><span class="line">            x=x/abs(x)*dwmin</span><br><span class="line">        else:</span><br><span class="line">            x=x*1.5</span><br><span class="line">    return x</span><br><span class="line">#打开</span><br><span class="line"></span><br><span class="line">WAV文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = wave.open(r&quot;speak.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)</span><br><span class="line">fo = wave.open(r&quot;jg.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;wb&quot;)</span><br><span class="line">#读取波形数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#(nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes，</span><br><span class="line"></span><br><span class="line"> comptype，</span><br><span class="line"></span><br><span class="line"> compname)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br><span class="line">print &quot;read wav data....&quot;</span><br><span class="line">str_data = f.readframes(nframes)</span><br><span class="line">#将波形数据转换为数组，并更改</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;update wav data....&quot;</span><br><span class="line">wave_data = np.fromstring(str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br><span class="line">str_data = f.readframes(nframes)</span><br><span class="line">#放大音量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">change_dwmax=wave_data.max()/100*88</span><br><span class="line">change_dwmin=wave_data.max()/100*14</span><br><span class="line">wave_change = np.frompyfunc(wavechange，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">1)</span><br><span class="line">new_wave_data =wave_change(wave_data，</span><br><span class="line"></span><br><span class="line">change_dwmax，</span><br><span class="line"></span><br><span class="line">change_dwmin)</span><br><span class="line">new_wave_data =new_wave_data.astype(wave_data.dtype)</span><br><span class="line">new_str_data=new_wave_data.tostring()</span><br><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;save new wav files....&quot;</span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br><span class="line">fo.writeframes(new_str_data)</span><br><span class="line">#绘制源声音波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">wave_data = wave_data.T</span><br><span class="line">time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br><span class="line">pl.subplot(221)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[0])</span><br><span class="line">pl.subplot(222)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">#绘制放大音量波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">new_wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">new_wave_data =new_wave_data.T</span><br><span class="line">new_time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br><span class="line">pl.subplot(223)</span><br><span class="line">pl.plot(new_time，</span><br><span class="line"></span><br><span class="line">new_wave_data[0])</span><br><span class="line">pl.subplot(224)</span><br><span class="line">pl.plot(new_time，</span><br><span class="line"></span><br><span class="line"> new_wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>如图3-23所示波形图中，上部为源声音，下部显示了音量放大后的波形。下部的波形数据范围为-20000~20000，而上部范围为-15000~15000，下部波形整体比上部大很多。下载本书的代码包运行后，可听到音量放大后的声音效果。</p>
<p><img src="Image00027.jpg" alt></p>
<p>图3-23 声音音量放大波形</p>
<p>2.降低音量</p>
<p>音量降低可通过将采样波形变小来实现，具体来说，就是把每个采样数据按指定比例缩小，同时将缩小幅度控制在合理的范围内，保证音量降低后声音仍然清晰。</p>
<p>1）根据上下限参数对波形数据进行调节，定义缩小波形数据的函数为wavechange。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def wavechange(x，</span><br><span class="line"></span><br><span class="line">dwmax，</span><br><span class="line"></span><br><span class="line">dwmin):</span><br><span class="line">    if x!=0:</span><br><span class="line">        if abs(x)&lt;dwmax and abs(x)&gt;dwmin:</span><br><span class="line">            x=x*0.5</span><br><span class="line">        else:</span><br><span class="line">            x=x*0.2</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

</details>

<p>2）与放大音量类似，以源声音波形数据的最大值为基准，计算上限和下限，以wavechange为回调函数，降低音量。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#降低音量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">change_dwmax=wave_data.max()/100*1</span><br><span class="line">change_dwmin=wave_data.max()/100*0.5</span><br><span class="line">wave_change = np.frompyfunc(wavechange，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">1)</span><br><span class="line">new_wave_data =wave_change(wave_data，</span><br><span class="line"></span><br><span class="line">change_dwmax，</span><br><span class="line"></span><br><span class="line">change_dwmin)</span><br></pre></td></tr></table></figure>

</details>

<p>3）生成新波形数据。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">new_wave_data =new_wave_data.astype(wave_data.dtype)</span><br><span class="line">new_str_data=new_wave_data.tostring()</span><br></pre></td></tr></table></figure>

</details>

<p>4）将数据写到新声音文件。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br><span class="line">fo.writeframes(new_str_data)</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码演示了降低音量算法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python  </span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com </span><br><span class="line">#3-15.py</span><br><span class="line">import wave</span><br><span class="line">import pylab as pl</span><br><span class="line">import numpy as np</span><br><span class="line">print &apos;working...&apos; </span><br><span class="line">def wavechange(x，</span><br><span class="line"></span><br><span class="line">dwmax，</span><br><span class="line"></span><br><span class="line">dwmin):</span><br><span class="line">    if x!=0:</span><br><span class="line">        if abs(x)&lt;dwmax and abs(x)&gt;dwmin:</span><br><span class="line">            x=x*0.5</span><br><span class="line">        else:</span><br><span class="line">            x=x*0.2</span><br><span class="line">    return x</span><br><span class="line">#打开</span><br><span class="line"></span><br><span class="line">WAV文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = wave.open(r&quot;back.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)</span><br><span class="line">fo = wave.open(r&quot;jg.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;wb&quot;)</span><br><span class="line">#读取波形数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#(nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes，</span><br><span class="line"></span><br><span class="line"> comptype，</span><br><span class="line"></span><br><span class="line"> compname)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br><span class="line">print &quot;read wav data....&quot;</span><br><span class="line">str_data = f.readframes(nframes)</span><br><span class="line">#将波形数据转换为数组，并更改</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;update wav data....&quot;</span><br><span class="line">wave_data = np.fromstring(str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">params = f.getparams()</span><br><span class="line">nchannels，</span><br><span class="line"></span><br><span class="line"> sampwidth，</span><br><span class="line"></span><br><span class="line"> framerate，</span><br><span class="line"></span><br><span class="line"> nframes = params[:4]</span><br><span class="line">str_data = f.readframes(nframes)</span><br><span class="line">#降低音量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">change_dwmax=wave_data.max()/100*1</span><br><span class="line">change_dwmin=wave_data.max()/100*0.5</span><br><span class="line">wave_change = np.frompyfunc(wavechange，</span><br><span class="line"></span><br><span class="line">3，</span><br><span class="line"></span><br><span class="line">1)</span><br><span class="line">new_wave_data =wave_change(wave_data，</span><br><span class="line"></span><br><span class="line">change_dwmax，</span><br><span class="line"></span><br><span class="line">change_dwmin)</span><br><span class="line">new_wave_data =new_wave_data.astype(wave_data.dtype)</span><br><span class="line">new_str_data=new_wave_data.tostring()</span><br><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;save new wav files....&quot;</span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br><span class="line">fo.writeframes(new_str_data)</span><br><span class="line">#绘制源声音波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">wave_data = wave_data.T</span><br><span class="line">time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br><span class="line">pl.subplot(221)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[0])</span><br><span class="line">pl.subplot(222)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">#绘制降低音量波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">new_wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">new_wave_data =new_wave_data.T</span><br><span class="line">new_time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes) * (1.0 / framerate)</span><br><span class="line">pl.subplot(223)</span><br><span class="line">pl.plot(new_time，</span><br><span class="line"></span><br><span class="line">new_wave_data[0])</span><br><span class="line">pl.subplot(224)</span><br><span class="line">pl.plot(new_time，</span><br><span class="line"></span><br><span class="line"> new_wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>如图3-24所示的波形图中，上面为源声音，下面为降低音量后的声音波形。可明显看出，音量缩小后，其波形幅度为-3000~3000，而源声音波形范围大很多，为-15000~15000。</p>
<p><img src="Image00028.jpg" alt></p>
<p>图3-24 声音音量缩小波形</p>
<h4 id="3-1-9-图像信息隐藏"><a href="#3-1-9-图像信息隐藏" class="headerlink" title="3.1.9 图像信息隐藏"></a>3.1.9 图像信息隐藏</h4><p>1.图像隐藏原理</p>
<p>信息隐藏是不让除预期接收者之外的任何人知晓信息的传递事件或者信息的内容，载体文件相对隐秘文件的大小越大，隐藏后者就越加容易。因此，数字图像在互联网和其他传媒上被广泛用于隐藏消息。</p>
<p>本节讲述的图像隐藏原理是：首先从源图中提取文字图像信息，并记录这个文字图像信息像素点在图像矩阵中的位置；然后，对载体文件进行预处理，将蓝色像素值全部设为偶数；最后，将记录的文字信息像素点在载体文件对应位置的蓝色像素值设为奇数。解密信息是隐藏信息的逆过程，其过程比较简单，即提取载体文件中蓝色像素值为奇数的像素点，将空白图像中这些像素点对应的位置赋予统一的着色。</p>
<p>2.图像隐藏实例</p>
<p>下面用实例来讲解图像信息隐藏技术。我们的目标是：将如图3-25所示的文字隐藏在如图3-26所示的载体图片里。要求隐藏后，无法察觉图中隐藏了信息。</p>
<p><img src="Image00029.jpg" alt></p>
<p>图3-25 含有待隐藏文字的图像</p>
<p><img src="Image00030.jpg" alt></p>
<p>图3-26 载体图像</p>
<p>本实例隐藏信息的主要过程如下：</p>
<p>1）读取源图像（将写上需隐藏文字的信息）和载体图像，构造图像矩阵。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img1 = cv2.imread(fn1)</span><br><span class="line">img2 = cv2.imread(fn2)</span><br><span class="line">w=img1.shape[1]</span><br><span class="line">h=img1.shape[0]</span><br></pre></td></tr></table></figure>

</details>

<p>2）在源图像中加上水印文字作为待隐藏文字。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">#加上需要隐藏的消息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;hello，</span><br><span class="line"></span><br><span class="line">world!&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">300)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 3.0，</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 2)</span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;code by myhaspl:myhaspl@qq.com&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">60)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_</span><br><span class="line">    HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2.0，</span><br><span class="line"></span><br><span class="line"> redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 2) </span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;Installing Python is generally easy. &quot;，</span><br><span class="line"></span><br><span class="line"> (1，</span><br><span class="line"></span><br><span class="line">90)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_</span><br><span class="line">    HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 1)</span><br></pre></td></tr></table></figure>

</details>

<p>3）处理隐藏载体图，将所有蓝色值变成偶数，以便加入隐藏信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">    #处理隐藏载体图</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #将所有蓝色值变成偶数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">            if (img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]%2)==1:</span><br><span class="line">                img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]=img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]-1</span><br></pre></td></tr></table></figure>

</details>

<p>4）读取源图像，将源图像的文字像素点在载体文件的对应位置的蓝色像素值设为奇数，将需要隐藏的信息写入目标载体图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#读取源图像，并将信息写入目标载体图</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">            if (img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]，</span><br><span class="line"></span><br><span class="line">img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">1]，</span><br><span class="line"></span><br><span class="line">img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">2])==redcolor:</span><br><span class="line">                img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]=img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]+1</span><br></pre></td></tr></table></figure>

</details>

<p>5）保存修改后的目标载体图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cv2.imshow(&apos;img2-2&apos;，</span><br><span class="line"></span><br><span class="line"> img2)      </span><br><span class="line">cv2.imwrite(fn3，</span><br><span class="line"></span><br><span class="line"> img2)</span><br></pre></td></tr></table></figure>

</details>

<p>下面的代码演示了隐藏信息的过程。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#3-16.py</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">#含有文字的图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fn1=&quot;test1.jpg&quot;</span><br><span class="line">#载体文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fn2=&quot;test2.jpg&quot;</span><br><span class="line">#包含隐藏信息的载体文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fn3=&quot;secret.png&quot;</span><br><span class="line">redcolor=(0，</span><br><span class="line"></span><br><span class="line"> 0，</span><br><span class="line"></span><br><span class="line"> 255)</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #图像大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    img1 = cv2.imread(fn1)</span><br><span class="line">    img2 = cv2.imread(fn2)</span><br><span class="line">    w=img1.shape[1]</span><br><span class="line">    h=img1.shape[0]  </span><br><span class="line">    #加上需要隐藏的消息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;hello，</span><br><span class="line"></span><br><span class="line">world!&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">300)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 3.0，</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 2)</span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;code by myhaspl:myhaspl@qq.com&quot;，</span><br><span class="line"></span><br><span class="line"> (20，</span><br><span class="line"></span><br><span class="line">60)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_</span><br><span class="line">    HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2.0，</span><br><span class="line"></span><br><span class="line"> redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 2) </span><br><span class="line">    cv2.putText(img1，</span><br><span class="line"></span><br><span class="line">&quot;Installing Python is generally easy. &quot;，</span><br><span class="line"></span><br><span class="line"> (1，</span><br><span class="line"></span><br><span class="line">90)，</span><br><span class="line"></span><br><span class="line">cv2.FONT_</span><br><span class="line">    HERSHEY_PLAIN，</span><br><span class="line"></span><br><span class="line"> 2，</span><br><span class="line"></span><br><span class="line"> redcolor，</span><br><span class="line"></span><br><span class="line"> thickness = 1)     </span><br><span class="line">    cv2.namedWindow(&apos;img1&apos;)     </span><br><span class="line">    cv2.imshow(&apos;img1&apos;，</span><br><span class="line"></span><br><span class="line"> img1)   </span><br><span class="line">    cv2.namedWindow(&apos;img2-1&apos;)     </span><br><span class="line">    cv2.imshow(&apos;img2-1&apos;，</span><br><span class="line"></span><br><span class="line"> img2)    </span><br><span class="line">    #处理隐藏载体图</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #将所有蓝色值变成偶数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">            if (img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]%2)==1:</span><br><span class="line">                img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]=img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]-1</span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        mirror_w=w/2</span><br><span class="line">    #读取源图，并将信息写入目标图，将有信息的像素点的蓝色值设为奇数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):</span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):</span><br><span class="line">            if (img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]，</span><br><span class="line"></span><br><span class="line">img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">1]，</span><br><span class="line"></span><br><span class="line">img1[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">2])==redcolor:</span><br><span class="line">                img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]=img2[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]+1</span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    #保存修改后的目标图，并显示</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cv2.namedWindow(&apos;img2-2&apos;)     </span><br><span class="line">    cv2.imshow(&apos;img2-2&apos;，</span><br><span class="line"></span><br><span class="line"> img2)         </span><br><span class="line">    cv2.imwrite(fn3，</span><br><span class="line"></span><br><span class="line"> img2)      </span><br><span class="line">    cv2.waitKey()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行上段代码将信息隐藏后，肉眼观察载体图像，仍无法察觉与之前相比有任何变化。</p>
<p>下面来看看解密信息过程。解密信息与隐藏信息相反，是隐藏信息的逆过程，主要步骤如下：</p>
<p>1）读取载体文件及其大小信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(fn)  </span><br><span class="line">w=img.shape[1]  </span><br><span class="line">h=img.shape[0]</span><br></pre></td></tr></table></figure>

</details>

<p>2）生成空白图像矩阵，以便绘制解密文字。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">imginfo =np.zeros((h，</span><br><span class="line"></span><br><span class="line">w，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> np.uint8)</span><br></pre></td></tr></table></figure>

</details>

<p>3）绘制解密的水印文字。如果蓝色值为奇数，则该像素点为文字。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):  </span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):  </span><br><span class="line">            if (img[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]%2)==1:  </span><br><span class="line">                imginfo[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">1]=255</span><br></pre></td></tr></table></figure>

</details>

<p>4）显示隐藏信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cv2.imshow(&apos;info&apos;，</span><br><span class="line"></span><br><span class="line"> imginfo)           </span><br><span class="line">cv2.imwrite(fn，</span><br><span class="line"></span><br><span class="line"> imginfo)</span><br></pre></td></tr></table></figure>

</details>

<p>下面代码演示了解密信息的过程。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python  </span><br><span class="line">#-*-coding: utf-8 -*- </span><br><span class="line">#code:myhaspl@qq.com  </span><br><span class="line">#解密文件</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">#3-17.py</span><br><span class="line">import cv2  </span><br><span class="line">import numpy as np  </span><br><span class="line">fn=&quot;secret.png&quot;  </span><br><span class="line">if __name__ == &apos;__main__&apos;:  </span><br><span class="line">    print &apos;loading  ...&apos;  </span><br><span class="line">    print u&apos;正在处理中</span><br><span class="line"></span><br><span class="line">&apos;，</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">    img = cv2.imread(fn)  </span><br><span class="line">    w=img.shape[1]  </span><br><span class="line">    h=img.shape[0]    </span><br><span class="line">    imginfo =np.zeros((h，</span><br><span class="line"></span><br><span class="line">w，</span><br><span class="line"></span><br><span class="line">3)，</span><br><span class="line"></span><br><span class="line"> np.uint8)     </span><br><span class="line">    for j in xrange(0，</span><br><span class="line"></span><br><span class="line">h):  </span><br><span class="line">        for i in xrange(0，</span><br><span class="line"></span><br><span class="line">w):  </span><br><span class="line">            if (img[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">0]%2)==1:  </span><br><span class="line">               #如果蓝色值为奇数，则该像素点为文字</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                imginfo[j，</span><br><span class="line"></span><br><span class="line">i，</span><br><span class="line"></span><br><span class="line">1]=255  </span><br><span class="line">        print &apos;.&apos;，</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    cv2.imshow(&apos;info&apos;，</span><br><span class="line"></span><br><span class="line"> imginfo)           </span><br><span class="line">    cv2.imwrite(fn，</span><br><span class="line"></span><br><span class="line"> imginfo)        </span><br><span class="line">    cv2.waitKey()  </span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

</details>

<p>运行解密代码，从载体文件中提取信息，效果如图3-27所示。</p>
<h4 id="3-1-10-声音信息隐藏"><a href="#3-1-10-声音信息隐藏" class="headerlink" title="3.1.10 声音信息隐藏"></a>3.1.10 声音信息隐藏</h4><p>1.声音信息隐藏原理</p>
<p>声音文件是一个不错的信息隐藏载体，声音文件数据量大，能隐藏信息的容量也大，假设每秒采集44100次，如果所有采样数据全部利用上，每秒的声音可以存储44100字节的数据，不过这样达不到信息隐藏的效果，只能利用其中一部分采样数据来存储信息，占有的采样数据越少，信息隐藏效果就越好。</p>
<p>比如，如图3-28所示的波形是一段音乐的声音波形，假设某个采样点的数据实际是信息中一个字节大小的数据，那么将这些字节解密后，能还原成一段信息。这种载体的隐藏信息的效果比图像好，一般很难被人发现。</p>
<p>这里采用的隐藏策略是：产生一段正弦波的噪声，然后，在这段噪声中隐藏一段文本文件的内容。下面以实例来讲解这个过程，我们的目标是：将本章前面讲述的Python代码文件3-1.py隐藏到一段噪声中，解密者如果不知道信息解密的规律，就无法从噪声文件还原这个Python代码文件。</p>
<p><img src="Image00031.jpg" alt></p>
<p>图3-27 解密后的文字</p>
<p><img src="Image00032.jpg" alt></p>
<p>图3-28 音乐的声音波形</p>
<p>2.声音信息隐藏实例</p>
<p>隐藏信息的具体过程如下：</p>
<p>1）读取需要隐藏的文本文件，提取其中的文字信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 打开文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fo = wave.open(r&quot;pltest.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;wb&quot;) </span><br><span class="line">file_object = open(&apos;3-1.py&apos;)</span><br><span class="line">try:</span><br><span class="line">     all_the_text = file_object.read( )</span><br><span class="line">finally:</span><br><span class="line">     file_object.close( )</span><br></pre></td></tr></table></figure>

</details>

<p>2）将文字转化为对应的内部编码（本例的文字为英文字母和符号，因此转换为ASCII码）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wdata=map(ord，</span><br><span class="line"></span><br><span class="line">all_the_text)</span><br><span class="line">wdata=np.array(wdata)</span><br></pre></td></tr></table></figure>

</details>

<p>3）设置噪声载体文件的波形参数。载体文件是程序人为生成，所以将幅度设置为适合的区域，为使载体噪声更接近于自然的噪声，将振幅范围设置为-25600~25600。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 设置波形参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#采样率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">framerate = 44100</span><br><span class="line">#声道数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nchannels=2</span><br><span class="line">#每位宽度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sampwidth=2</span><br><span class="line">#长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nframes =framerate*4</span><br><span class="line">#振幅</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_amplitude = 200</span><br><span class="line">max_amplitude=128*base_amplitude</span><br></pre></td></tr></table></figure>

</details>

<p>4）计算每个字符的间隔，需要隐藏的若干个字符以等间隔的形式分散在噪声数据中，即：在噪声波形数据中，每隔指定的间隔存放一个字符。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#每个字符的间隔</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">interval=(nframes-10)/lwdata</span><br></pre></td></tr></table></figure>

</details>

<p>5）生成空波形数据，以便写入噪声数据和字符信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#每周期样本数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data=np.zeros((nframes)，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br></pre></td></tr></table></figure>

</details>

<p>6）生成噪声数据，并将隐藏文字的字符写入噪声数据中，这一步是关键，也是算法的核心。算法把整个采样的线性区域分为两类，如果当前采样时间处于第4步计算的间隔处，则表示此处为加密字符区（每个字符区只能存放一个字符），写入的数据为经过加密的字符，在间隔之前的时间区域则为随机噪声区。</p>
<p>算法判断是否到了指定的间隔处，间隔处是字符区，否则是噪声区。如果是噪声区，则随机生成噪声；如果是字符区，则将字符进行加密，写入字符区。此处使用了简单的加密算法（实际应用可使用高强度的加密算法），加密方式为：将字符的ASCII码乘以指定的整数后，减去64与该整数的乘积。生成的信息隐藏格式如表3-2所示。</p>
<p>表3-2 信息隐藏格式</p>
<p><img src="Image00033.jpg" alt></p>
<p>算法代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#写噪声数据和隐藏文字的字符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myrand=np.random.rand(nframes)</span><br><span class="line">for curpos in xrange(0，</span><br><span class="line"></span><br><span class="line">nframes):</span><br><span class="line">   if curpos % interval==0 and count&lt;lwdata:</span><br><span class="line">   #将隐藏文字的字符通过一定的变化写入噪声数据中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        possamp=wdata[count]*base_amplitude-64*base_amplitude      </span><br><span class="line">        count+=1       </span><br><span class="line">   elif curpos%60==0:</span><br><span class="line">   #生成随机噪声数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        possamp=int(myrand[curpos]*max_amplitude-max_amplitude/2)</span><br><span class="line">    else:</span><br><span class="line">        possamp=0</span><br><span class="line">    wave_data[curpos]=possamp</span><br></pre></td></tr></table></figure>

</details>

<p>7）写波形数据。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;save new wav files....&quot;</span><br><span class="line">str_data=wave_data.tostring()</span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br><span class="line">fo.setnframes(nframes)</span><br><span class="line">fo.writeframes(str_data)</span><br></pre></td></tr></table></figure>

</details>

<p>下面来看看解码信息过程，解码信息是隐藏信息的逆算法，主要步骤如下：</p>
<p>1）读取噪声载体文件以及相关格式信息。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">new_wdata=[]</span><br><span class="line">print u&apos;正在从声音解码文件</span><br><span class="line"></span><br><span class="line">&apos;</span><br><span class="line">fi = wave.open(r&quot;pltest.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)  </span><br><span class="line">fi_params=fi.getparams()  </span><br><span class="line">fi_nframes = fi_params[3]  </span><br><span class="line">fi_str_data=fi.readframes(fi_nframes) </span><br><span class="line">fi_wave_data= np.fromstring(fi_str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br></pre></td></tr></table></figure>

</details>

<p>2）找到字符区，将其中的字符解密并还原成字符串。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for curpos in xrange(0，</span><br><span class="line"></span><br><span class="line">nframes):</span><br><span class="line">    if curpos % interval==0 and count&lt;lwdata:</span><br><span class="line">        possamp=(fi_wave_data[curpos]+64*base_amplitude)/base_amplitude</span><br><span class="line">        new_wdata.append(possamp)</span><br><span class="line">        count+=1</span><br></pre></td></tr></table></figure>

</details>

<p>3）整理还原字符串，将它们写入文件。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">my_the_text=&quot;&quot;.join(map(chr，</span><br><span class="line"></span><br><span class="line">new_wdata))</span><br><span class="line">fmy_the_text=&quot;&quot;.join(map(chr，</span><br><span class="line"></span><br><span class="line">new_wdata))</span><br><span class="line">file_object = open(&apos;mytext.txt&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;w&apos;)</span><br><span class="line">file_object.write(my_the_text)</span><br><span class="line">file_object.close( )</span><br></pre></td></tr></table></figure>

</details>

<p>下面程序读取名为3-1.py的Python源程序文件，将该文本隐藏在声音文件中，然后打开载体声音文件，将文本还原为Python程序文件。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python  </span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com </span><br><span class="line">#将文件隐藏在声音之中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3-18.py</span><br><span class="line">import wave</span><br><span class="line">import pylab as pl</span><br><span class="line">import numpy as np</span><br><span class="line">#编码</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&apos;正在将文件编码进声音</span><br><span class="line"></span><br><span class="line">&apos;</span><br><span class="line">print &quot;generate wav data....&quot;</span><br><span class="line">#打开文档</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fo = wave.open(r&quot;pltest.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;wb&quot;) </span><br><span class="line">file_object = open(&apos;3-1.py&apos;)</span><br><span class="line">try:</span><br><span class="line">     all_the_text = file_object.read( )</span><br><span class="line">finally:</span><br><span class="line">     file_object.close( )</span><br><span class="line">wdata=map(ord，</span><br><span class="line"></span><br><span class="line">all_the_text)</span><br><span class="line">wdata=np.array(wdata)</span><br><span class="line">lwdata=len(wdata)</span><br><span class="line">#设置波形参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#采样率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">framerate = 44100</span><br><span class="line">#声道数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nchannels=2</span><br><span class="line">#每位宽度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sampwidth=2</span><br><span class="line">#长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nframes =framerate*4</span><br><span class="line">#振幅</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_amplitude = 200</span><br><span class="line">max_amplitude=128*base_amplitude</span><br><span class="line">#每个字符的间隔</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">interval=(nframes-10)/lwdata</span><br><span class="line">#每周期样本数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data=np.zeros((nframes)，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">count=0</span><br><span class="line">#写噪声数据和隐藏文字的字符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myrand=np.random.rand(nframes)</span><br><span class="line">for curpos in xrange(0，</span><br><span class="line"></span><br><span class="line">nframes):</span><br><span class="line">    if curpos % interval==0 and count&lt;lwdata:</span><br><span class="line">        possamp=wdata[count]*base_amplitude-64*base_amplitude      </span><br><span class="line">        count+=1       </span><br><span class="line">    elif curpos%60==0:</span><br><span class="line">        possamp=int(myrand[curpos]*max_amplitude-max_amplitude/2)</span><br><span class="line">    else:</span><br><span class="line">        possamp=0</span><br><span class="line">    wave_data[curpos]=possamp</span><br><span class="line">#写波形数据参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print &quot;save new wav files....&quot;</span><br><span class="line">str_data=wave_data.tostring()</span><br><span class="line">fo.setnchannels(nchannels)</span><br><span class="line">fo.setframerate(framerate)</span><br><span class="line">fo.setsampwidth(sampwidth)</span><br><span class="line">fo.setnframes(nframes)</span><br><span class="line">fo.writeframes(str_data)</span><br><span class="line">fo.close()    </span><br><span class="line">#绘制波形</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">wave_data.shape = -1，</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line">wave_data = wave_data.T</span><br><span class="line">time = np.arange(0，</span><br><span class="line"></span><br><span class="line"> nframes/2)</span><br><span class="line">pl.subplot(211)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[0]，</span><br><span class="line"></span><br><span class="line"> c=&quot;r&quot;)</span><br><span class="line">pl.subplot(212)</span><br><span class="line">pl.plot(time，</span><br><span class="line"></span><br><span class="line"> wave_data[1]，</span><br><span class="line"></span><br><span class="line"> c=&quot;g&quot;)</span><br><span class="line">pl.xlabel(&quot;time (seconds)&quot;)</span><br><span class="line">#解码</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">new_wdata=[]</span><br><span class="line">print u&apos;正在从声音解码文件</span><br><span class="line"></span><br><span class="line">&apos;</span><br><span class="line">fi = wave.open(r&quot;pltest.wav&quot;，</span><br><span class="line"></span><br><span class="line"> &quot;rb&quot;)  </span><br><span class="line">fi_params=fi.getparams()  </span><br><span class="line">fi_nframes = fi_params[3]  </span><br><span class="line">fi_str_data=fi.readframes(fi_nframes) </span><br><span class="line">fi_wave_data= np.fromstring(fi_str_data，</span><br><span class="line"></span><br><span class="line"> dtype=np.short)</span><br><span class="line">count=0</span><br><span class="line">for curpos in xrange(0，</span><br><span class="line"></span><br><span class="line">nframes):</span><br><span class="line">    if curpos % interval==0 and count&lt;lwdata:</span><br><span class="line">        possamp=(fi_wave_data[curpos]+64*base_amplitude)/base_amplitude</span><br><span class="line">        new_wdata.append(possamp)</span><br><span class="line">        count+=1 </span><br><span class="line">my_the_text=&quot;&quot;.join(map(chr，</span><br><span class="line"></span><br><span class="line">new_wdata))</span><br><span class="line">file_object = open(&apos;mytext.txt&apos;，</span><br><span class="line"></span><br><span class="line"> &apos;w&apos;)</span><br><span class="line">file_object.write(my_the_text)</span><br><span class="line">file_object.close( )</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行这段代码，程序输出了编码和解码过程。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 正在将文件编码进声音</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">generate wav data....</span><br><span class="line">save new wav files....正在从声音解码文件</span><br></pre></td></tr></table></figure>

</details>

<p>上面程序演示了隐藏信息与解码信息的过程。程序运行后，先将Python源代码文件3-1.py隐藏在一段噪声中。然后，从噪声中解码信息，将文本内容输出到mytext.txt中，用记事本打开该文件，如图3-29所示。可以看到解码后的程序和源程序一样，包括空格、符号及字母等。</p>
<p><img src="Image00034.jpg" alt></p>
<p>图3-29 解码后文件</p>
<p>如图3-30所示是程序运行后生成的声音波形图像，很难看出来哪些采样点隐藏了文本信息。下载本书源码包后，可以播放这段声音（运行3-18.py后，会产生声音文件pltest.wav），只能听出声音是一段很平常的噪声。</p>
<p><img src="Image00035.jpg" alt></p>
<p>图3-30 隐藏了文本信息的波形</p>
<p>3.信息隐藏与解码总结</p>
<p>综上所述，隐藏信息的算法过程为：</p>
<p>1）读取程序文本文件，将字符转换为ASCII码。</p>
<p>2）确定声音文件的相关参数，生成2秒声音，其中采样数据用随机数代替，生成随机数的取值范围为-15000~15000，在某些采样点上用来自隐藏信息的字符字节代替，代替的方式是将字节对应的ASCII码乘上某个基数加一个调整参数，代替的过程是线性的。</p>
<p>3）将生成的声音数据写入载体文件中。</p>
<p>解码信息的算法过程为：</p>
<p>1）读取载体声音文件及其相关参数。</p>
<p>2）按照隐藏信息时的规律，在正确的位置读取字符，然后将读取的字符合成信息。</p>
<p>3）将信息写入恢复文件中。</p>
<h3 id="3-2-R语言基础"><a href="#3-2-R语言基础" class="headerlink" title="3.2 R语言基础"></a>3.2 R语言基础</h3><p>R是用于统计分析、绘图的语言和操作环境，是统计计算和统计制图的优秀工具，属于GNU系统的一个自由、免费、源代码开放的软件。其GUI界面主要包括菜单、命令控制台，在Windows平台下的界面如图3-31所示。</p>
<p><img src="Image00036.jpg" alt></p>
<p>图3-31 R的GUI界面</p>
<h4 id="3-2-1-基本操作"><a href="#3-2-1-基本操作" class="headerlink" title="3.2.1 基本操作"></a>3.2.1 基本操作</h4><p>1.提示符</p>
<p>R以“&gt;”为shell提示符，Windows、Linux、MAC均一致。</p>
<p>2.获得帮助的方式</p>
<p>在R中使用help函数获取某个命令或函数的帮助。下面是获取求平均值函数的帮助函数：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; help(mean)starting httpd help server ... done&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>输入上述命令后，显示如下HTML形式的帮助文档：</p>
<p><img src="Image00037.jpg" alt></p>
<p>如果想进一步获得这个函数的调用示例，可以通过example命令。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">   &gt; example(mean)mean&gt; x &lt;-c(0:10，</span><br><span class="line"></span><br><span class="line">50)mean&gt; xm &lt;-mean(x)mean&gt; c(xm，</span><br><span class="line"></span><br><span class="line">mean(x，</span><br><span class="line"></span><br><span class="line">trim = 0.10))[1] 8.75 5.50</span><br></pre></td></tr></table></figure>

</details>

<p>3.文件载入并执行代码</p>
<p>使用source函数载入并执行代码，把以下代码放在一个名为test.r的文件，用文本编辑工具录入。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x&lt;-c(22，</span><br><span class="line"></span><br><span class="line">23，</span><br><span class="line"></span><br><span class="line">44，</span><br><span class="line"></span><br><span class="line">66);     </span><br><span class="line">y&lt;-mean(x);y</span><br></pre></td></tr></table></figure>

</details>

<p>然后加载执行，查看输出结果。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; source(&quot;f:/pro/r/test.r&quot;)</span><br><span class="line">&gt; y</span><br><span class="line">[1] 38.75</span><br><span class="line">&gt; x</span><br><span class="line">[1] 22 23 44 66</span><br></pre></td></tr></table></figure>

</details>

<p>最后将执行结果写入文件。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; sink(&quot;f:/pro/r/test.lis&quot;)</span><br><span class="line">&gt; x</span><br><span class="line">&gt; y</span><br></pre></td></tr></table></figure>

</details>

<p>打开test.lis，可看到以下内容：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[1] 22 23 44 66</span><br><span class="line">[1] 38.75</span><br></pre></td></tr></table></figure>

</details>

<p>如果采用不带参数的sink，将恢复结果。示例如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; sink()</span><br><span class="line">&gt; x</span><br><span class="line">[1] 22 23 44 66</span><br></pre></td></tr></table></figure>

</details>

<p>4.代码续行</p>
<p>在行尾使用“+”可进行续行。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x&lt;-c(11，</span><br><span class="line"></span><br><span class="line">22，</span><br><span class="line"></span><br><span class="line">33+  </span><br><span class="line">+ 22+  </span><br><span class="line">+ 3333) </span><br><span class="line">&gt; x[1]   11   22 3388</span><br></pre></td></tr></table></figure>

</details>

<p>另外，需要提一下，R语言中的注释可以被放在任何地方，只要是以井号（#）开始，到行末结束就可以。</p>
<p>5.物件（对象集）</p>
<p>在R中创建的单元为物件（对象集），这些物件可以是变量、数字数组、字符串、函数，以及从这些物件中产生的更多结构。</p>
<p>objects()可用来显示存储在R中的对象集名字。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> &gt; objects()</span><br><span class="line">[1] &quot;x&quot;  &quot;xm&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>以上代码显示R目前运行环境中有x和xm两个变量，可以使用rm移除某个对象。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; rm(xm)</span><br><span class="line">&gt; objects()</span><br><span class="line">[1] &quot;x&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>退出R程序时，可以以.RData的方式保存这些对象集，如图3-32所示。</p>
<p><img src="Image00038.jpg" alt></p>
<p>图3-32 保存对象集对话框</p>
<p>当下次再启动R时，加载.RData文件后，这个对象集会被还原。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    R version 3.0.0 (2013-04-03) --&quot;Masked Marvel&quot;</span><br><span class="line">    Copyright (C) 2013 The R Foundation for Statistical Computing</span><br><span class="line">    Platform: i386-w64-mingw32/i386 (32-bit)</span><br><span class="line">    ...................</span><br><span class="line"></span><br><span class="line">* * *</span><br><span class="line"></span><br><span class="line">原来保存的工作空间已还原。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x
    [1]   11   22 3388 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.2.2 向量</span><br><span class="line"></span><br><span class="line">1.数据型向量及其运算</span><br><span class="line"></span><br><span class="line">最简单的数据结构是数字型向量，它是一个有序的数字集合（这里的序不是指按数字大小排序，是指数字之前的先后顺序都确定），关于这个序，数学上有一个很好的解释，叫作偏序关系。</span><br><span class="line"></span><br><span class="line">偏序关系又称半序关系。设A是一个非空集，P是A上的一个关系，P适合下列条件：</span><br><span class="line"></span><br><span class="line">1）对任意的a∈A，(a，a)∈P。</span><br><span class="line"></span><br><span class="line">2）若(a，b)∈P且(b，a)∈P，则a=b。</span><br><span class="line"></span><br><span class="line">3）若(a，b)∈P，(b，c)∈P，则（a，c)∈P，则称P是A上的一个偏序关系。带偏序关系的集合A称为偏序集或半序集。</span><br><span class="line"></span><br><span class="line">比如说（1，2）和（2，1），它们两个就不是同个向量，因为这两个集合的序不一样。</span><br><span class="line"></span><br><span class="line">向量的使用方法很简单，可使用&quot;c&quot;后跟括号将向量包围起来，即c()函数。如：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(12， 33， 12， 22)> y
    [1] 12 33 12 22 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">&quot;&lt;-&quot;可以相当于“=”，就是将这个向量组作为y这个对象的值，也可以使用assign()函数。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > assign("x"，

    c(11，

    22，

    15))
    > x
    [1] 11 22 15

* * *

“->”的作用与"<-"类似。 <details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; c(12，</span><br><span class="line"></span><br><span class="line">33，</span><br><span class="line"></span><br><span class="line">12，</span><br><span class="line"></span><br><span class="line">22)-&gt;z</span><br><span class="line">&gt; z</span><br><span class="line">[1] 12 33 12 22</span><br></pre></td></tr></table></figure>

</-"类似。></-c(12，></details>

<p>对向量操作，一般是对向量的每个元素进行操作，比如：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; z</span><br><span class="line">[1] 12 33 12 22</span><br><span class="line">&gt; z/2</span><br><span class="line">[1]  6.0 16.5  6.0 11.0</span><br></pre></td></tr></table></figure>

</details>

<p>向量也可以成为c()中的参数，向量中的元素，将合并成为c()函数中的元素：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; c(33，</span><br><span class="line"></span><br><span class="line">12，</span><br><span class="line"></span><br><span class="line">66)-&gt;x1</span><br><span class="line">&gt; y1=c(x1，</span><br><span class="line"></span><br><span class="line">111，</span><br><span class="line"></span><br><span class="line">x1)</span><br><span class="line">&gt; y1</span><br><span class="line">[1]  33  12  66 111  33  12  66</span><br></pre></td></tr></table></figure>

</details>

<p>再来看看数字型向量运算。向量之间的运算是每个元素分别进行的，比如：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; x</span><br><span class="line">[1]   11   22 3388</span><br><span class="line">&gt; 2*x-&gt;y</span><br><span class="line">&gt; y</span><br><span class="line">[1]   22   44 6776</span><br><span class="line">&gt; x+3*y-&gt;z</span><br><span class="line">&gt; z</span><br><span class="line">[1]    77   154 23716</span><br></pre></td></tr></table></figure>

</details>

<p>元素个数不一致的向量，元素个数较少的向量将循环扩充和元素个数最多的向量一致，这意味着元素数量最多的向量的元素个数必须是元素数量小的向量的元素个数的整数倍。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt; z</span><br><span class="line">[1]    77   154 23716</span><br><span class="line">&gt; bb&lt;-c(12，</span><br><span class="line"></span><br><span class="line">21，</span><br><span class="line"></span><br><span class="line">32，</span><br><span class="line"></span><br><span class="line">60，</span><br><span class="line"></span><br><span class="line">132，</span><br><span class="line"></span><br><span class="line">56)</span><br><span class="line">&gt; z/3+bb</span><br><span class="line">[1]   37.66667   72.33333 7937.33333   85.66667  183.33333 7961.33333</span><br></pre></td></tr></table></figure>

</details>

<p>对向量元素的操作，可以使用普通的+、-、*、/、^等操作符，也可以使用更多的函数，比如：log、sin、tan、max、mean、sum等，这些函数有些是对每个元素分别计算，有些是对所有元素一起计算。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; x</span><br><span class="line">[1]   11   22 3388</span><br><span class="line">&gt; cos(x)#cos三角函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1]  0.004425698 -0.999960826  0.206187272</span><br><span class="line">&gt; sin(x)#sin三角函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] -0.999990207 -0.008851309  0.978512549</span><br><span class="line">&gt; sum(x)#求和</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 3421</span><br><span class="line">&gt; mean(x)#求平均值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 1140.333</span><br></pre></td></tr></table></figure>

</details>

<p>可以使用sort、length、sqrt对向量进行排序，求长度，求平方根。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; c(4，</span><br><span class="line"></span><br><span class="line">8，</span><br><span class="line"></span><br><span class="line">9)-&gt;x</span><br><span class="line">&gt; sqrt(x)#平方根</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 2.000000 2.828427 3.000000</span><br><span class="line">&gt; length(x)#长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 3</span><br><span class="line">&gt; sort(x)-&gt;y#排序</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; y</span><br><span class="line">[1]  4  8  9</span><br></pre></td></tr></table></figure>

</details>

<p>2.复数向量与规则向量</p>
<p>复数向量的元素都是复数。复数的表示方法是：实部+虚部i。下面的代码演示了复数向量的使用方法。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    &gt;c(2+1i，</span><br><span class="line"></span><br><span class="line">    3-9i，</span><br><span class="line"></span><br><span class="line">    4)-&gt;b</span><br><span class="line">    &gt; y</span><br><span class="line">    [1]  4  8  9 </span><br><span class="line">    &gt; b+y-&gt;w#复数运算</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    &gt; w</span><br><span class="line">    [1]  6+1i 11-9i 13+0i</span><br><span class="line"></span><br><span class="line">* * *</span><br><span class="line"></span><br><span class="line">我们可以使用1:m-1和1:(m-1)产生规则的序列。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >c(1:(22))
     [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22
    > c(1:22)
     [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">冒号的优先权很高，看下面这个示例，它产生范围在3-30之内的公差为3的等差数列。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(3*(1:10))
     [1]  3  6  9 12 15 18 21 24 27 30
    > c(3*1:10)
     [1]  3  6  9 12 15 18 21 24 27 30 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">seq函数是生成序列的最好工具。可以使用它产生符合某种规则的序列，seq函数有5个参数，前4个参数分别是起始值（参数名称：from）、终止值（参数名称：to）、步长（参数名称：by）、长度即元素个数（参数名称：length.out）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > seq(1，

    5)
    [1] 1 2 3 4 5
    > seq(1，

    5，

    2)
    [1] 1 3 5 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">可以直接指定参数名称，传入参数。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > seq(from=1，

    to=15，

    by=2)
    [1]  1  3  5  7  9 11 13 15
    > 
    > seq(from=1，

    to=15，

    by=3)
    [1]  1  4  7 10 13
    > seq(from=1，

    to=15，

    length.out=3)
    [1]  1  8 15 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">第五个参数是along.with，使用along.with参数中序列的长度作为要产生序列的长度。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > seq(from=2，

    along.with=c(1:5))
    [1] 2 3 4 5 6
    > seq(from=2，

    by=2，

    along.with=c(1，

    2，

    5，

    8))
    [1] 2 4 6 8
    > seq(from=2，

    by=2，

    along.with=c(1，

    2，

    3，

    8))
    [1] 2 4 6 8 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00005.jpg) 注意 along.with参数中的序列仅取其长度，和序列的内容无关。</span><br><span class="line"></span><br><span class="line">rep函数对序列中的元素进行重复后拼接，拼接的方式是：使用times参数将所有元素作为整体拼接，使用each参数将元素分别进行拼接。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > rep(x，

    2)
    [1] 12 32 98 12 32 98
    > rep(x，

    3)
    [1] 12 32 98 12 32 98 12 32 98
    > rep(x，

    times=2)
    [1] 12 32 98 12 32 98
    > > rep(x，

    each=2)
    [1] 12 12 32 32 98 98 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.逻辑型向量</span><br><span class="line"></span><br><span class="line">了解了数字型向量，再来看看逻辑型向量。该向量的元素由逻辑型值组成，逻辑型的值有TRUE（可缩写成T）、FALSE（可缩写成F）、NA（即无效）等，可使用&gt;、&gt;=、==、!=等逻辑操作符，and操作用&amp;，or操作用|，逻辑非使用“!”。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

      C(12，

    33，

    51)->x
    > x
    [1] 12 33 51
    > x>20->y
    > y
    [1] FALSE  TRUE  TRUE
    > x>=12->y#x>12作为产生逻辑向量的依据


    > y
    [1] TRUE TRUE TRUE
    > x>=12&x<30->y
    > y
    [1]  TRUE FALSE FALSE
    > x>=12|x<30->y
    > y
    [1] TRUE TRUE TRUE
    >> !(x>=12&x<30)->y
    > y
    [1] FALSE  TRUE  TRUE <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">无效值或缺失值NA、NaN主要用于应付某操作没完成，结果未知的情况。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(1:4，

    NA，

    2:3)->x
    > x
    [1]  1  2  3  4 NA  2  3
    > is.na(x)
    [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面是数字计算对NAN的处理：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > 0/0
    [1] NaN
    > 0/0->y
    > is.na(y)
    [1] TRUE
    > y
    [1] NaN <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.字符串向量</span><br><span class="line"></span><br><span class="line">字符串用单引号或双引号包围，示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c("qq"，

    "bb")->z
    > z
    [1] "qq" "bb" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">可在字符串中使用转义符\：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    \n  新行


    \r  回车


    \t  tab
    \b  退格


    \a  鸣叫


    \\  \
    \'  '
    \"  " <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在字符串向量的运算中，paste()函数接受任意数量的参数，可将它们依次连接到字符串向量的元素中，sep指定连接时相隔的字符，默认为单个空格。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > paste(1:12)
     [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10" "11" "12"
    > paste("A"，

     1:6，

     sep = "")
    [1] "A1" "A2" "A3" "A4" "A5" "A6"
    > paste("A"，

     1:6)
    [1] "A 1" "A 2" "A 3" "A 4" "A 5" "A 6"
    > paste("A"，

     1:6，

     sep = "")
    [1] "A1" "A2" "A3" "A4" "A5" "A6"
    > paste(c("A"，

    "B")，

     1:10，

     sep="")
     [1] "A1"  "B2"  "A3"  "B4"  "A5"  "B6"  "A7"  "B8"  "A9"  "B10"
    > paste("今天是

    "，

     date())
    [1] "今天是

     Sun Apr 21 14:18:38 2013"
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5.索引向量</span><br><span class="line"></span><br><span class="line">在逻辑值型索引中，索引向量的元素为逻辑值型，逻辑值为TRUE的向量将被放在输出结果中。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x
    [1]   11   22 3388
    > x>22->jg
    > jg
    [1] FALSE FALSE  TRUE
    > x[jg]->y
    > y
    [1] 3388
    > x[x<100]->y
    > y
    [1] 11 22
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在正整数型索引中，索引向量是正整数类型，用于指示要哪些位置的元素要输出到结果中。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x[c(1，

    2，

    3，

    2，

    1)]#以向量作为索引


    [1]   11   22 3388   22   11
    > x
    [1]   11   22 3388
    > x[1]
    [1] 11
    > x[1:2]
    [1] 11 22
    > x[2:3]
    [1]   22 3388 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">对于负数索引，会将除开索引以外的所有元素输出到结果中。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(12，

    22，

    88)->X
    > X
    [1] 12 22 88
    > X
    [1] 12 22 88
    > X[-(1:2)]->Y
    > Y
    [1] 88
    > X[-(1)]->Y
    > Y
    [1] 22 88 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在字符串索引中，是以字符串来标注元素的位置的。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(23，

    26，

    27)->age
    > c("张三

    "，

    "李四

    "，

    "王五

    ")->names(age)
    > age[c("张三

    ")]#以字符串作为索引

    张三


      23 
    > age[c("张三

    "，

    "王五

    ")]->mystudent
    > mystudent张三

     王五


      23   27  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">带索引方式的向量对象可以直接作为被赋值的对象，所有在索引内的向量元素都会被赋值。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > age[c("张三

    "，

    "王五

    ")]张三

     王五


      26   28 
    > age[c("张三

    "，

    "王五

    ")]<-age[c("张三 "， "王五 ")]+1> age[c("张三

    "，

    "王五

    ")]张三

     王五


      27   29 
    >  age[c("张三

    "，

    "王五

    ")]<-32> age[c("张三

    "，

    "王五

    ")]张三

     王五


      32   32  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">再举个例子：给所有小于100的元素均加上20，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x
    [1]   11   22 3388
    > length(x)
    [1] 3
    > x[x<100]<-x[x<100]+20> x
    [1]   31   42 3388 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.2.3 对象集属性</span><br><span class="line"></span><br><span class="line">1.固有属性</span><br><span class="line"></span><br><span class="line">对象集的固有属性有mode和length两种，相关示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x
    [1]   11   22 3388
    > mode(x)
    [1] "numeric" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">其中mode可理解为对象集的类型，主要有numeric1、complex、logical、character和raw等类型。mode的用法如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > length(x)
    [1] 3
    > c(1.0-5i，

    20+51i)->a
    > mode(a)
    [1] "complex" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">mode属性转化可完成数据类型的转化。比如，使用as.character转化为字符型等。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > h<-5:12> h
    [1]  5  6  7  8  9 10 11 12
    > as.character(h)#转化为字符


    [1] "5"  "6"  "7"  "8"  "9"  "10" "11" "12"
    > c(1.0-5i，

    20+51i)->a
    > mode(a)
    [1] "complex"
    > as.character(a)->c_a
    > c_a
    [1] "1-5i"   "20+51i" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.设置对象属性</span><br><span class="line"></span><br><span class="line">可使用attr方法进行属性的自定义。具体方法为：使用attr(object，name)格式设置对象属性。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > h
    [1]  5  6  7  8  9 10 11 12
    >  attr(h，

    "name")<-"test" attr(h， "dim")<-c(2， 4)> h
         [，

    1] [，

    2] [，

    3] [，

    4]
    [1，

    ]    5    7    9   11
    [2，

    ]    6    8   10   12
    attr(，

    "name")
    [1] "test" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.2.4 因子和有序因子</span><br><span class="line"></span><br><span class="line">因子用来存储类别变量和有序变量，可用来分组或分类，因子表示分类变量，有序因子表示有序变量。</span><br><span class="line"></span><br><span class="line">在R语言中使用factor()函数生成因子对象，语法是factor(data，levels，labels，...)，其中data是数据，levels是因子水平向量，labels是因子的标签向量。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > my_num<-c(11， 22， 34， 71， 14， 68， 21)> factor(my_num)->nums#生成

    my_num分组向量

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">生成因子对象后，输入对象名称，可显示简单的分类情况。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > nums
    [1] 11 22 34 71 14 68 21
    Levels: 11 14 21 22 34 68 71
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">Levels函数用于生成因子向量中的水平（去除重复元素后的元素集）。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > my_num<-c(11， 22， 34， 71， 14， 68， 21， 11， 34)> factor(my_num)->nums
    > nums
     [1] 11 22 34 71 14 68 21 22 11 34
    Levels: 11 14 21 22 34 68 71
    > levels(nums)
    [1] "11" "14" "21" "22" "34" "68" "71" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">还可使用ordered函数生成有序因子。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > ordered(nums)
     [1] 11 22 34 71 14 68 21 22 11 34
    Levels: 11 < 14 < 21 < 22 < 34 < 68 < 71
    > age <-c(25， 12， 15， 25)> ordered(age，

     levels = c(25，

    12，

    15))
    [1] 25 12 15 12 25
    Levels: 25 < 12 < 15 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">cut()函数将数据转换成因子或有序因子，并进行分组。下面对一组学生成绩进行分组。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > score<-c( 88， 85， 75， 97， 92， 77， 74， 70， 63， 97)> cut(score，

     breaks = 3)#将成绩分为

    3组


     [1] (85.7，

    97]   (74.3，

    85.7] (74.3，

    85.7] (85.7，

    97]   (85.7，

    97]   (74.3，

    85.7]
     [7] (63，

    74.3]   (63，

    74.3]   (63，

    74.3]   (85.7，

    97]  
    Levels: (63，

    74.3] (74.3，

    85.7] (85.7，

    97]
    > cut(score，

     breaks = 2)#将成绩分为

    2组


     [1] (80，

    97] (80，

    97] (63，

    80] (80，

    97] (80，

    97] (63，

    80] (63，

    80] (63，

    80] (63，

    80]
     [10] (80，

    97]
    Levels: (63，

    80] (80，

    97]
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.2.5 循环语句</span><br><span class="line"></span><br><span class="line">1.for循环</span><br><span class="line"></span><br><span class="line">R语言的for循环与Python类似，都是通过在对象中进行迭代实现循环，但R语言中不能在该循环中直接设置起始值、终止值与步长。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > z<-c()> x<-(1:10)> y<-(11:20)> for (i in 1:length(x)){
    + z[i]=x[i]^2+y[i]^2
    + }
    > z
     [1] 122 148 178 212 250 292 338 388 442 500 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.while循环</span><br><span class="line"></span><br><span class="line">while语句每次会检查循环条件，如果条件不再满足，则终止循环。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > x<-c(1:10)> i=1
    > while (x[i]^2<10) + { i="i+1" x[i]="x[i]^2" }> x
     [1]  1  4  3  4  5  6  7  8  9 10 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.2.6 条件语句</span><br><span class="line"></span><br><span class="line">if...else...是R语言的条件语句。该语句通过检查执行条件来确定是否继续往下执行，如果条件满足，则执行if后面的对应语句，否则执行else后面的对应语句。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > z<-c()> x<-(1:10)> y<-(11:20)> for (i in 1:length(x)){
    + if ((x[i]^3>y[i]^2)) 
    + z[i]=x[i]^3
    + else
    + z[i]=y[i]^2
    + }
    > z
     [1]  121  144  169  196  225  256  343  512  729 1000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 3.3 R语言科学计算</span><br><span class="line"></span><br><span class="line">#### 3.3.1 分类（组）统计</span><br><span class="line"></span><br><span class="line">R语言分类统计主要包括数据分类整理、统计函数定义、数据分类统计3个过程。下面以对水果的价格进行分类统计为例说明。</span><br><span class="line"></span><br><span class="line">1.准备分组数据</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > fruit_class<-c("苹果 "， "梨子 "橘子 "草莓 "苹果 ")> fruit_prices<-c(3.5， 2.5， 1.5， 5.5， 4.2， 3.2， 2.8， 4.8， 2.9， 5.8) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.平均价格统计</span><br><span class="line"></span><br><span class="line">通过在tapply函数中指定mean函数为其参数，可实现分组求平均值。计算结果分2行，第1行为组名，第2行为tapply函数最后一个函数参数的运算结果。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > tapply(fruit_prices，

    fruit_class，

    mean)
        草莓

        橘子

          梨子

         苹果


    5.366667 2.600000 2.500000 3.850000  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.最低价格统计</span><br><span class="line"></span><br><span class="line">通过在tapply函数中指定min函数为其参数，可实现分组求最小值。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > tapply(fruit_prices，

    fruit_class，

    min)草莓

     橘子

     梨子

     苹果


     4.8  1.5  2.5  3.5  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.标准差统计</span><br><span class="line"></span><br><span class="line">通过在tapply函数中指定sd函数为其参数，可实现分组求标准差。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > tapply(fruit_prices，

    fruit_class，

    sd)
       草莓

          橘子

          梨子

          苹果


    0.5131601 0.7527727        NA 0.4949747 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5.标准误</span><br><span class="line"></span><br><span class="line">标准误即样本均数的标准差，是描述均数抽样分布的离散程度及衡量均数抽样误差大小的尺度，反映的是样本均数之间的变异。</span><br><span class="line"></span><br><span class="line">但是，请注意，标准误并不是标准差，而是样本均值的标准差，是用来衡量抽样误差的，其计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00039.jpg)</span><br><span class="line"></span><br><span class="line">其中，S为样本标准差。标准误越小，表明样本统计量与总体参数的值越接近，样本对总体越有代表性，用样本统计量推断总体参数的可靠程度越大。</span><br><span class="line"></span><br><span class="line">可通过在tapply函数中指定自定义函数stderr为其参数，来实现分组求标准误。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > stderr <-function(x) sqrt(var(x) length(x))#自定义 stderr函数> tapply(fruit_prices，

    fruit_class，

    stderr)
         草莓

          橘子

          梨子

          苹果


    0.2962731 0.3763863        NA 0.3500000  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.3.2 数组与矩阵基础</span><br><span class="line"></span><br><span class="line">R提供了简单的工具以处理数组和矩阵。</span><br><span class="line"></span><br><span class="line">1.数组与矩阵的维数</span><br><span class="line"></span><br><span class="line">数组与矩阵的维数是其行向量（或列向量）生成的向量空间的维数，可用维数向量表示，格式为（行数×列数），元素都非负。通常使用dim函数来定义数组维度。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > dim(my_num)<-c(2， 5)###指定数组维度> my_num
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]   11   34   14   21   11
    [2，

    ]   22   71   68   22   34
    > dim(my_num)<-c(10)> my_num
     [1] 11 22 34 71 14 68 21 22 11 34 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.切片</span><br><span class="line"></span><br><span class="line">切片是操作多维数据（矩阵、数组等）的主要手段，它以索引为参数获取数组或矩阵的一部分。比如：想要得到多维数组的一个切片，则以索引为下标进行访问，取得某块数组。使用[索引]格式的参数对数组和矩阵完成切片操作。</span><br><span class="line"></span><br><span class="line">索引的形式主要有以下几种：</span><br><span class="line"></span><br><span class="line">1）[index1，index2，...，indexn]。index1、index2等分别标明了元素在相应维数的索引，将索引组合成完整的位置，标注需要取出的元素，进行切片，形成数组块。比如：数组a的大小为3×5，a[2，4]表示第2行第4列的元素。</span><br><span class="line"></span><br><span class="line">2）[c(index1，index2，...，indexn)]。index1、index2等n个整数标注了元素的位置，将这些标注的元素取出后，组成数组块。这些元素的位置以列为顺序排列，比如，数组a的大小为3×2（3行2列），切片操作a[c(1，2，3，4，5，6)]依次取出以下元素：a[1，1]、a[2，1]，a[3，1]、a[1，2]、a[2，2]，a[3，2]。</span><br><span class="line"></span><br><span class="line">切片操作示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > h
         [，

    1] [，

    2] [，

    3]
    [1，

    ]   12   15  982
    [2，

    ]   32   67  321
    > c(h[1，

    2]，

    h[2，

    3])###获取第

    1行第

    2列数据（为

    15）、第

    2行第

    3列的数据（为

    321）


    [1]  15 321
    > h[2，

    ]
    [1]  32  67 321
    > h[c(1，

    2，

    3)]###逐列获取第

    1、

    2、

    3个数据


    [1] 12 32 15
    > h[6]###逐列获取第

    6个数据


    [1] 321
    > h[4]
    [1] 67 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.索引向量</span><br><span class="line"></span><br><span class="line">数组可作为索引使用，且数组也是向量，因此作为索引的数组可称为索引向量。下面的代码演示了向量c(1:3，5:4，3:5)作为索引的情况。</span><br><span class="line"></span><br><span class="line">1）创建数组x和i，x是被切片的数组，i是索引向量。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > array(10:20，

    dim=c(2，

    5))->x
    > x
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]   10   12   14   16   18
    [2，

    ]   11   13   15   17   19
    > array(c(1:3，

    5:4，

    3:5)，

    dim=c(2，

    3))->i
    > i
         [，

    1] [，

    2] [，

    3]
    [1，

    ]    1    3    4
    [2，

    ]    2    5    3 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）以i为索引向量提取数组块，索引向量每个元素代表切片的位置，将这些位置指向的元素提取出来，形成数组块（数组切片）。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > x[i]
    [1] 10 11 12 14 13 12 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）通过索引对数组某个元素赋值。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x[i]<-111> x
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]  111  111  111   16   18
    [2，

    ]  111  111   15   17   19 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.array函数</span><br><span class="line"></span><br><span class="line">array函数根据维数参数生成多维数组，它的参数主要有两个，第一个是需要形成数组元素的数据，第二个是dim参数提示维度。下面的代码演示了array函数创建数组的方法，并通过dim函数获取数组的大小。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(1:20)->h
    > mya<-array(h， dim="c(4，" 5))> mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    5    9   13   17
    [2，

    ]    2    6   10   14   18
    [3，

    ]    3    7   11   15   19
    [4，

    ]    4    8   12   16   20
    > mydim<-c(2， 10)> mya<-array(h， dim="c(2，" 10))> mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    1    3    5    7    9   11   13   15   17    19
    [2，

    ]    2    4    6    8   10   12   14   16   18    20
    > 
    > dim(mya)
    [1]  2 10 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">array函数的第一个参数既可以是向量也可以是单个值，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > mya<-array(1， dim="c(2，" 10))> mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    1    1    1    1    1    1    1    1    1     1
    [2，

    ]    1    1    1    1    1    1    1    1    1     1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5.数组转换为向量</span><br><span class="line"></span><br><span class="line">as.vector函数可将数组转换为向量。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x<-array(c(1:10)， dim="c(2，" 5))> x
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    > as.vector(x)
     [1]  1  2  3  4  5  6  7  8  9 10 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6.matrix矩阵</span><br><span class="line"></span><br><span class="line">使用matrix函数可创建矩阵（从数学角度定义的矩阵），主要参数为：data表示构造所需数据，nrow为行数，ncol为列数，byrow表示是否按行顺序分配元素（默认为FALSE，不按）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > matrix(c(1:10)，

    2，

    5，

    TRUE)
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    2    3    4    5
    [2，

    ]    6    7    8    9   10
    > matrix(c(1:10)，

    2，

    5)
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">7.对角矩阵</span><br><span class="line"></span><br><span class="line">对角矩阵是一个除主对角线上的元素之外皆为0的矩阵，对角线上的元素可以为0或其他值。通过diag函数可生成和分析对角矩阵，如果参数为一维数组，则将参数视为对角线元素，并生成对角矩阵；如果参数为一维以上数组，则将参数视为对角矩阵，对它进行分析，可提取对角线元素。相关示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a
    [1] 1 2 3 4 5 6 7 8
    > 
    > diag(a)###生成对角矩阵


         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8]
    [1，

    ]    1    0    0    0    0    0    0    0
    [2，

    ]    0    2    0    0    0    0    0    0
    [3，

    ]    0    0    3    0    0    0    0    0
    [4，

    ]    0    0    0    4    0    0    0    0
    [5，

    ]    0    0    0    0    5    0    0    0
    [6，

    ]    0    0    0    0    0    6    0    0
    [7，

    ]    0    0    0    0    0    0    7    0
    [8，

    ]    0    0    0    0    0    0    0    8
    > a<-array(c(1:16)， dim="c(4，" 4))> diag(a)###提取对角线元素


    [1]  1  6 11 16
    > a
         [，

    1] [，

    2] [，

    3] [，

    4]
    [1，

    ]    1    5    9   13
    [2，

    ]    2    6   10   14
    [3，

    ]    3    7   11   15
    [4，

    ]    4    8   12   16 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.3.3 数组运算</span><br><span class="line"></span><br><span class="line">1.四则运算</span><br><span class="line"></span><br><span class="line">数组四则运算的规律是：对应位置的元素分别计算，而不是依据矩阵的数学运算法则。运算符为“+”（加）、“-”（减）、“*”（乘）等，运算优先级与算术四则运算相同，先乘后加减。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    1    3    5    7    9   11   13   15   17    19
    [2，

    ]    2    4    6    8   10   12   14   16   18    20
    > myb
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    2    2    2    2    2    2    2    2    2     2
    [2，

    ]    2    2    2    2    2    2    2    2    2     2
    > mya+myb
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    3    5    7    9   11   13   15   17   19    21
    [2，

    ]    4    6    8   10   12   14   16   18   20    22
    > mya*myb
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    2    6   10   14   18   22   26   30   34    38
    [2，

    ]    4    8   12   16   20   24   28   32   36    40
    > 3*mya*myb
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    6   18   30   42   54   66   78   90  102   114
    [2，

    ]   12   24   36   48   60   72   84   96  108   120
    > 
    > mya*myb+mya#先乘后加


         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    3    9   15   21   27   33   39   45   51    57
    [2，

    ]    6   12   18   24   30   36   42   48   54    60
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.向量连接</span><br><span class="line"></span><br><span class="line">向量连接指的是将两个向量通过某种规律连接成一个数组。R语言的cbind和rbind函数可进行向量连接，其中cbind函数将向量的行转变为列后再连接，rbind函数将向量的列转变为行后再连接。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x2<-c(101:105)> x1<-c(1:10)> cbind(x1，

    x2)
           x1  x2
     [1，

    ]  1 101
     [2，

    ]  2 102
     [3，

    ]  3 103
     [4，

    ]  4 104
     [5，

    ]  5 105
     [6，

    ]  6 101
     [7，

    ]  7 102
     [8，

    ]  8 103
     [9，

    ]  9 104
    [10，

    ] 10 105
    > rbind(x1，

    x2)
       [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    x1    1    2    3    4    5    6    7    8    9    10
    x2  101  102  103  104  105  101  102  103  104   105 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.3.4 矩阵运算</span><br><span class="line"></span><br><span class="line">1.矩阵连接</span><br><span class="line"></span><br><span class="line">R语言的cbind函数完成矩阵的横向连接，rbind函数完成矩阵的纵向连接。下面是关于矩阵的连接操作示例。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > x3<-matrix(c(1:10)， 2， 5)> x4<-matrix(c(101:105)， 2， 5)> x3
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    > x4
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]  101  103  105  102  104
    [2，

    ]  102  104  101  103  105
    > cbind(x3，

    x4)
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5] [，

    6] [，

    7] [，

    8] [，

    9] [，

    10]
    [1，

    ]    1    3    5    7    9  101  103  105  102   104
    [2，

    ]    2    4    6    8   10  102  104  101  103   105
    >  rbind(x3，

    x4)
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    [3，

    ]  101  103  105  102  104
    [4，

    ]  102  104  101  103  105 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.矩阵转置</span><br><span class="line"></span><br><span class="line">线性代数将矩阵A的转置（记做AT ）定义为：</span><br><span class="line"></span><br><span class="line">把A的横行写为AT 的纵列；</span><br><span class="line"></span><br><span class="line">把A的纵列写为AT 的横行。</span><br><span class="line"></span><br><span class="line">根据上述计算法则，m×n矩阵A的转置生成n×m矩阵AT 。</span><br><span class="line"></span><br><span class="line">![](Image00040.jpg)</span><br><span class="line"></span><br><span class="line">R语言的t函数可完成矩阵转置计算。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > array(h，

    dim=c(2，

    5))->mya
    > mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    >  t(mya)###矩阵转置


         [，

    1] [，

    2]
    [1，

    ]    1    2
    [2，

    ]    3    4
    [3，

    ]    5    6
    [4，

    ]    7    8
    [5，

    ]    9   10 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">相对t函数而言，用aperm函数进行矩阵转置更灵活。aperm有两个常用的参数，第一个参数是需要转置的矩阵，第二个参数perm指示新矩阵相对于第一个参数矩阵的维度下标。需要特别注意的是，第二个参数perm是维度下标。比如，将行转换为列，将列转换为行，将行列次序更换，将第一维的元素与第二维的元素互换，则将perm设为c(2，1)。下面的代码演示了aperm函数的使用方法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > array(h，

    dim=c(2，

    5))->mya
    > mya
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    > 
    > aperm(mya，

    perm=c(2，

    1))->myb###以

    c(2，

    1)为维度下标进行转置


    > myb
         [，

    1] [，

    2]
    [1，

    ]    1    2
    [2，

    ]    3    4
    [3，

    ]    5    6
    [4，

    ]    7    8
    [5，

    ]    9   10
    > 
    > array(mya，

    c(2，

    2，

    5))->mya1
    > mya1，

     ，

     1
         [，

    1] [，

    2]
    [1，

    ]    1    3
    [2，

    ]    2    4，

     ，

     2
         [，

    1] [，

    2]
    [1，

    ]    5    7
    [2，

    ]    6    8，

     ，

     3
         [，

    1] [，

    2]
    [1，

    ]    9    1
    [2，

    ]   10    2，

     ，

     4
         [，

    1] [，

    2]
    [1，

    ]    3    5
    [2，

    ]    4    6，

     ，

     5
         [，

    1] [，

    2]
    [1，

    ]    7    9
    [2，

    ]    8   10
    > aperm(mya1，

    perm=c(2，

    1，

    3))->myb1###以

    c(2，

    1，

    3)为维度下标进行转置


    > myb1，

     ，

     1
         [，

    1] [，

    2]
    [1，

    ]    1    2
    [2，

    ]    3    4，

     ，

     2
         [，

    1] [，

    2]
    [1，

    ]    5    6
    [2，

    ]    7    8，

     ，

     3
         [，

    1] [，

    2]
    [1，

    ]    9   10
    [2，

    ]    1    2，

     ，

     4
         [，

    1] [，

    2]
    [1，

    ]    3    4
    [2，

    ]    5    6，

     ，

     5
         [，

    1] [，

    2]
    [1，

    ]    7    8
    [2，

    ]    9   10
    > aperm(mya1，

    perm=c(1，

    3，

    2))->myb1
    > myb1，

     ，

     1
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    5    9    3    7
    [2，

    ]    2    6   10    4    8，

     ，

     2
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    3    7    1    5    9
    [2，

    ]    4    8    2    6   10
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.矩阵乘积</span><br><span class="line"></span><br><span class="line">若A为m×n矩阵，B为n×r矩阵，则它们的乘积AB（有时记做A·B）会是一个m×r的矩阵，前提是m与n必须相同，矩阵乘积使用%*%操作符进行计算。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a
         [，

    1] [，

    2] [，

    3] [，

    4] [，

    5]
    [1，

    ]    1    3    5    7    9
    [2，

    ]    2    4    6    8   10
    > b
         [，

    1] [，

    2]
    [1，

    ]    1    6
    [2，

    ]    2    7
    [3，

    ]    3    8
    [4，

    ]    4    9
    [5，

    ]    5   10
    > a %*% b
         [，

    1] [，

    2]
    [1，

    ]   95  220
    [2，

    ]  110  260 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.内外积运算</span><br><span class="line"></span><br><span class="line">1）向量外积。向量的外积是矩阵的克罗内克积的特殊情况。给定m×1列向量u和1×n行向量v，它们的外积u![](Image00041.jpg) v被定义为m×n矩阵A。</span><br><span class="line"></span><br><span class="line">![](Image00042.jpg)</span><br><span class="line"></span><br><span class="line">向量外积u![](Image00041.jpg) v的计算定义为：</span><br><span class="line"></span><br><span class="line">![](Image00043.jpg)</span><br><span class="line"></span><br><span class="line">下面的代码演示了a和b数组作为向量的外积运算和普通乘法运算。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > b<-array(c(1:4))> a<-array(c(5:6))> b%o%a###外积


         [，

    1] [，

    2]
    [1，

    ]    5    6
    [2，

    ]   10   12
    [3，

    ]   15   18
    [4，

    ]   20   24
    > b
    [1] 1 2 3 4
    > a
    [1] 5 6
    > b<-array(c(1:4))> a<-array(c(5:8))> a*b###普通乘法


    [1]  5 12 21 32
    > b
    [1] 1 2 3 4
    > a
    [1] 5 6 7 8
    > a%o%b
         [，

    1] [，

    2] [，

    3] [，

    4]
    [1，

    ]    5   10   15   20
    [2，

    ]    6   12   18   24
    [3，

    ]    7   14   21   28
    [4，

    ]    8   16   24   32
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，还可以使用Outer(a，b，“*”)替代%o%运算符进行外积运算。</span><br><span class="line"></span><br><span class="line">2）向量内积。向量内积以实数R上定义的两个向量为运算对象，返回一个实数标量值，属于二元运算，它是欧几里得空间的标准内积。</span><br><span class="line"></span><br><span class="line">两个向量a=[a1 ，a2 ，…，an ]和b=[b1 ，b2 ，…，bn ]的内积定义为：</span><br><span class="line"></span><br><span class="line">![](Image00044.jpg)</span><br><span class="line"></span><br><span class="line">R语言通过crossprod函数完成向量内积计算。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a<-c(1:3)> b<-c(4:6)> crossprod(a，

    b)
         [，

    1]
    [1，

    ]   32
    > a<-c(1:3) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）矩阵内积。矩阵内积的计算方式相当于第一个参数的转置乘以第二个参数，就是前面提到的矩阵乘积。除了使用%*%操作符外，还可以使用crossprod函数完成矩阵内积计算。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > b<-array(c(4:6)， dim="c(1，" 3))> a<-array(c(1:3)， dim="c(1，" 3))> a
         [，

    1] [，

    2] [，

    3]
    [1，

    ]    1    2    3
    > b
         [，

    1] [，

    2] [，

    3]
    [1，

    ]    4    5    6
    > crossprod(a，

    b)###a与

    b完成矩阵内积计算


         [，

    1] [，

    2] [，

    3]
    [1，

    ]    4    5    6
    [2，

    ]    8   10   12
    [3，

    ]   12   15   18
    > t(a) %*% b###a的转置与

    b完成矩阵内积计算


         [，

    1] [，

    2] [，

    3]
    [1，

    ]    4    5    6
    [2，

    ]    8   10   12
    [3，

    ]   12   15   18 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5.求解线性方程组</span><br><span class="line"></span><br><span class="line">一般通过solve函数来求解a%*%x=b中的x向量值，求解线性方程组仅使用solve函数的前两个参数，第一个a为系数矩阵，第二个b为常数项，当b缺失时，默认为单位矩阵。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > b
         [，

    1]
    [1，

    ]    8
    [2，

    ]    9
    > a
         [，

    1] [，

    2]
    [1，

    ]    1    3
    [2，

    ]    2    4
    > solve(a，

    b)
         [，

    1]
    [1，

    ] -2.5
    [2，

    ]  3.5 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6.矩阵求逆</span><br><span class="line"></span><br><span class="line">通过solve函数可进行矩阵求逆计算，只指定1个参数（待求逆的矩阵）即可。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a
         [，

    1] [，

    2]
    [1，

    ]    1    3
    [2，

    ]    2    4
    > solve(a)
         [，

    1] [，

    2]
    [1，

    ]   -2  1.5
    [2，

    ]    1 -0.5
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">7.矩阵的特征值求解</span><br><span class="line"></span><br><span class="line">1）特征值概念。λ是A的特征值等价于线性系统（A–λI）v=0（其中I是单位矩阵）有非零解v（一个特征向量），特征值存在等价于下面行列式成立：</span><br><span class="line"></span><br><span class="line">det(A-λI)=0</span><br><span class="line"></span><br><span class="line">函数pA (λ)=det(A-λI)是一个关于λ的多项式，称为A的特征多项式。矩阵的特征值也就是其特征多项式的零点。</span><br><span class="line"></span><br><span class="line">求一个矩阵A的特征值可以通过求解方程pA (λ)=0来得到。</span><br><span class="line"></span><br><span class="line">2）R语言求解特征值。利用R语言的eigen函数可求解特征值，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    eigen(x，

     symmetric，

     only.values = FALSE) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">其中，x为需要求特征值的矩阵；symmetric是逻辑型，表示是否为对称矩阵，对称矩阵是一个方形矩阵，其转置矩阵和自身相等，即：A=AT ，对称矩阵A=(aij )从右上至左下方向的元素以主对角线（左上至右下）为轴对称，即：aij =aji 。only.values如果为TRUE，则只返回特征值，否则返回特征值和特征向量。</span><br><span class="line"></span><br><span class="line">下面的代码演示了eigen函数计算特征值的方法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a<-array(c(1:16)， dim="c(4，" 4))> eigen(a)###计算

    a的特征值


    $values
    [1]  3.620937e+01 -2.209373e+00  1.599839e-15  7.166935e-16
    $vectors
              [，

    1]        [，

    2]       [，

    3]       [，

    4]
    [1，

    ] 0.4140028  0.82289268 -0.5477226  0.1125155
    [2，

    ] 0.4688206  0.42193991  0.7302967  0.2495210
    [3，

    ] 0.5236384  0.02098714  0.1825742 -0.8365883
    [4，

    ] 0.5784562 -0.37996563 -0.3651484  0.4745519
    > 
    > eigen(a，

    only.values=FALSE)
    $values
    [1]  5.3722813 -0.3722813
    $vectors
               [，

    1]       [，

    2]
    [1，

    ] -0.5657675 -0.9093767
    [2，

    ] -0.8245648  0.4159736 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">8.求解矩阵行列式</span><br><span class="line"></span><br><span class="line">行列式是线性代数中的一个概念，将一个n×n的矩阵A映射到一个标量，记作det(A)或|A|。行列式可看作是有向面积的概念在一般的欧几里得空间中的推广。</span><br><span class="line"></span><br><span class="line">比如，假设矩阵A定义为：</span><br><span class="line"></span><br><span class="line">![](Image00045.jpg)</span><br><span class="line"></span><br><span class="line">则矩阵A的行列式|A|可定义为：</span><br><span class="line"></span><br><span class="line">![](Image00046.jpg)</span><br><span class="line"></span><br><span class="line">R语言的det函数可求解矩阵对应的行列式值，即：已知矩阵A，求解|A|。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > a<-array(c(1:4)， dim="c(2，" 2))> det(x)
    [1] -2
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">9.奇异分解</span><br><span class="line"></span><br><span class="line">奇异值分解是线性代数中一种重要的矩阵分解，在信号处理、统计学等领域有重要应用。假设M是一个m×n阶矩阵，其中的元素全部属于域K（实数域或复数域）。设存在一个分解使得：</span><br><span class="line"></span><br><span class="line">M=UΣV*</span><br><span class="line"></span><br><span class="line">其中U是m×m阶酉矩阵；Σ是半正定m×n阶对角矩阵；V*（即V的共轭转置）是n×n阶酉矩阵。</span><br><span class="line"></span><br><span class="line">这种分解称作M的奇异值分解，Σ对角线上的元素Σi，i 即为M的奇异值。</span><br><span class="line"></span><br><span class="line">使用R语言的svd函数可完成奇异分解。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > array(c(1:16)，

    dim=c(4，

    4))->a
    > a
         [，

    1] [，

    2] [，

    3] [，

    4]
    [1，

    ]    1    5    9   13
    [2，

    ]    2    6   10   14
    [3，

    ]    3    7   11   15
    [4，

    ]    4    8   12   16
    > svd(a)###奇异分解


    $d
    [1] 3.862266e+01 2.071323e+00 1.291897e-15 6.318048e-16
    $u
               [，

    1]       [，

    2]       [，

    3]       [，

    4]
    [1，

    ] -0.4284124 -0.7186535  0.5462756 -0.0397869
    [2，

    ] -0.4743725 -0.2738078 -0.6987120  0.4602190
    [3，

    ] -0.5203326  0.1710379 -0.2414027 -0.8010772
    [4，

    ] -0.5662928  0.6158835  0.3938391  0.3806452
    $v
               [，

    1]        [，

    2]       [，

    3]       [，

    4]
    [1，

    ] -0.1347221  0.82574206 -0.4654637 -0.2886928
    [2，

    ] -0.3407577  0.42881720  0.4054394  0.7318599
    [3，

    ] -0.5467933  0.03189234  0.5855124 -0.5976414
    [4，

    ] -0.7528288 -0.36503251 -0.5254881  0.1544743 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 3.4 R语言计算实例</span><br><span class="line"></span><br><span class="line">#### 3.4.1 学生数据集读写</span><br><span class="line"></span><br><span class="line">下面演示R语言对学生数据集的操作。R语言可以使用list（列表）组件创建与读写学生数据，该组件通常用来容纳一个数据集，其中包含不同的数据类型。</span><br><span class="line"></span><br><span class="line">1）创建学生数据集（创建列表的语法是：list（字段1=组件1，字段2=组件2，…）），学生数据集由3个不同类型的数据组成：name（姓名，类型为字符型）、class（班级，类型为字符型）、ages（年龄，类型为数值型）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > list(name="students"，

    class="101"，

    stdt.ages=c(22，

    25，

    20)，

    stdt.name=c("zhangsang"，

    "lisi"，

    "wangwu"))->mystudents <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）读取列表。下面的代码读取刚才创建的学生数据集：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > mystudents
    $name
    [1] "students"
    $class
    [1] "101"
    $stdt.ages
    [1] 22 25 20
    $stdt.name
    [1] "zhangsang" "lisi"      "wangwu" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）获取学生数据集的字段总数（通过length返回list组件的数量）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > length(mystudents)
    [1] 4 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4）查看数据集中所有学生的姓名和年龄（通过“列表变量名$字段名”提取组件内容）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > c(mystudents$stdt.name，

    mystudents$stdt.ages)
    [1] "zhangsang" "lisi"      "wangwu"    "22"        "25"        "20"        <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，R语言还提供了一个很不错的list组件data.frame，它内部可拥有很多组件。下面接着以学生数据为例讲解data.frame。</span><br><span class="line"></span><br><span class="line">1）创建data.frame组件，存储学生数据。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > 
    data.frame(name=mystudents$stdt.name，

    age=mystudents$stdt.ages)->mysts
    > mysts
           name age
    1 zhangsang  22
    2      lisi  25
    3    wangwu  20 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）将数据集中的年龄都增长1岁（随着新的一年到来，学生们都长大了1岁），完成这个操作可使用attach和detach方法。</span><br><span class="line"></span><br><span class="line">前面一直用$符号访问list列表的字段，当R语言的代码较多时，列表组件名前缀访问字段很不方便，因此，R语言提供了另一对非常有用的工具attach和detach：attach把数据集的所有字段复制一份副本，绑定在搜索路径，这样可以直接读取它们（仅能读取，写回没有意义，因为这只是副本而已），无需显示表明列表名字；detach则进行解绑。</span><br><span class="line"></span><br><span class="line">1）用attach将学生数据集的字段副本绑定在搜索路径中。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > attach(mysts)
    > age
    [1] 22 25 20
    > name
    [1] zhangsang lisi      wangwu   
    Levels: lisi wangwu zhangsang <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）将绑定的age字段副本加1，并显示更新后的学生数据。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > age+1->mysts$age
    > mysts
           name age
    1 zhangsang  23
    2      lisi  26
    3    wangwu  21 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）使用detach将字段副本从搜索路径上删除（解绑）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > detach(mysts)
    > age错误

    : 找不到对象

    'age'
    > name错误

    : 找不到对象

    'name' <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.4.2 最小二乘法拟合</span><br><span class="line"></span><br><span class="line">1.最小二乘法与回归</span><br><span class="line"></span><br><span class="line">最小二乘法是一种数学优化技术，它通过最小化误差的平方和找到一组数据的最佳函数匹配。</span><br><span class="line"></span><br><span class="line">假设存在（x，y）这两个变量，对于一系列的x变量值，有一系列的y值与其对应，可以找到这两个变量之间的相互关系。比如：对于一次函数来说，可将这些（x，y）值标注在直角坐标系统，从而得到一条直线，这些点就在这条直线附近。那么，直线方程的定义为：</span><br><span class="line"></span><br><span class="line">y=kx+b</span><br><span class="line"></span><br><span class="line">其中：k、b是任意实数，k为斜率，b为截距。</span><br><span class="line"></span><br><span class="line">下面以y1 =3x+12和y2 =6x+12为例进行分析。如图3-33所示，实线为y1 的图像，虚线为y2 的图像。从图像能直观看出，斜率越大，直线越陡。y1 的斜率是3，载距为12；y2 的斜率是6，截距为12，y2 方程的图像明显比y1 陡。</span><br><span class="line"></span><br><span class="line">![](Image00047.jpg)</span><br><span class="line"></span><br><span class="line">图3-33 直线的图像</span><br><span class="line"></span><br><span class="line">图3-33中标注的圆圈和星号为（x，y）格式表示的二维数据点，很明显，圆圈的数据点位于y1 =3x+12上，而星号的数据点位于y2 =6x+12上。这些二维数据点被y1 =3x+12和y2 =6x+12方程的图像连接。这样做的好处是，我们不需要记忆这些数据点的坐标就能预测类似数据点的位置。比如说，已知x为1.5时，想要求圆圈数据点的坐标，可直接将x=1.5代入y1 方程得到：</span><br><span class="line"></span><br><span class="line">y=1.5×3+12=16.5</span><br><span class="line"></span><br><span class="line">这样就可用y=kx+b形式的一次方程拟合数据点，这个过程为线性拟合。拟合的目标是这些点到这条直线的距离的平方和最小。最小二乘法是效果较好的线性拟合方法，最小二乘法拟合数据点的过程就是对数据做回归分析，我们把类似图中的这几条直线称为回归线。</span><br><span class="line"></span><br><span class="line">2.最小二乘法拟合</span><br><span class="line"></span><br><span class="line">R语言提供了lsift函数，可完成最小二乘法拟合，其主要参数如下。</span><br><span class="line"></span><br><span class="line">·X：一个矩阵的行对应的情况和其列对应为变量。</span><br><span class="line"></span><br><span class="line">·Y：结果，可以是一个矩阵。</span><br><span class="line"></span><br><span class="line">·Wt：可选参数，加权最小二乘法的执行权重向量。</span><br><span class="line"></span><br><span class="line">·Intercept：是否应使用截距项。</span><br><span class="line"></span><br><span class="line">·Tolerance：公差将用于矩阵分解。</span><br><span class="line"></span><br><span class="line">·Yname：用于响应变量的名称。</span><br><span class="line"></span><br><span class="line">下面来看看y=2x回归方程拟合，这里以x=（1，2，3，4），y=（2，4，6，8）为例在R中进行数据拟合。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(2， 4， 6， 8)> x<-c(1， 2， 3， 4)> lsfit(x，

    y)###下面的

    x为常数项，

    Intercept为截距


    $coefficients
    Intercept         X 
            0         2 
    ...... <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述拟合结果中，Intercept项表示截距，x项表示方程的x变量的常数项，因此，回归方程为y=2x+0=2x。</span><br><span class="line"></span><br><span class="line">再来看看y=2x+3回归方程拟合，设截距为3。修改刚才的方程，假设回归线为：y=2x+3。</span><br><span class="line"></span><br><span class="line">1）根据回归线构造x和y值。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(5， 7， 9， 11)> x<-c(1， 2， 3， 4) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）执行lsfit()函数进行拟合。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > lsfit(x，

    y)
    $coefficients
    Intercept         X 
            3         2  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面lsfit()函数的运行结果表明，这些数据点的回归方程为y=2x+3。</span><br><span class="line"></span><br><span class="line">#### 3.4.3 交叉因子频率分析</span><br><span class="line"></span><br><span class="line">交叉因子频率分析的作用在于分析数据的分布区间及其统计指标。下面举例说明分析过程。</span><br><span class="line"></span><br><span class="line">1）划分数据分布区间。使用cut函数将变量y中存储的数字划分到5个分布区间：[11，15]、[15，19]、[19，23]、[23，27]、[27，31]示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(11， 22， 13， 14， 11， 31， 14)> cut(y，

    5)->cuty
    > cuty
     [1] (11，

    15] (19，

    23] (11，

    15] (11，

    15] (11，

    15] (19，

    23] (27，

    31] (27，

    31] (27，

    31]
    [10] (11，

    15]
    Levels: (11，

    15] (15，

    19] (19，

    23] (23，

    27] (27，

    31] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）使用table函数统计数据在每个区间出现的频率。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > table(cuty)
    cuty
    [11，

    15] (15，

    19] (19，

    23] (23，

    27] (27，

    31] 
          5       0       2       0       3  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）使用hist函数生成分布直方图，以便更直观地观察数据分布情况，如图3-34所示。通过指定breaks参数（设置为各区间的边界值）和axes参数（设置为FALSE表示手动画刻度），将数据在table函数生成的区间内进行划分。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > bins<-seq(min(y)， max(y)， by="4)"> hist(y，

    breaks=bins，

    col="lightblue"，

    axes=FALSE) 
    > axis(1，

    bins)
    > axis(2) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">结合table函数的执行结果以及hist函数生成的直方图，可得到以下结论：</span><br><span class="line"></span><br><span class="line">1）分析table函数的执行结果可看出，数据主要集中在[11，15]区间中，[11，15]区间内分布的数字最多，该区间内有5个数字。此外，在[15，19]、[23，27]区间中没有数据分布，变量y中的数据在这两个区间内出现频率为0。</span><br><span class="line"></span><br><span class="line">2）从图3-34中可观察到，数据分布情况与table函数执行结果相吻合。</span><br><span class="line"></span><br><span class="line">![](Image00048.jpg)</span><br><span class="line"></span><br><span class="line">图3-34 分布直方图</span><br><span class="line"></span><br><span class="line">#### 3.4.4 向量模长计算</span><br><span class="line"></span><br><span class="line">向量模长即欧几里得范数，在n维欧几里得空间Rn 上，向量x=（x1 ，x2 ，…，xn ）的长度定义为：![](Image00049.jpg) 。</span><br><span class="line"></span><br><span class="line">根据勾股定理，它给出了从原点到点x之间的距离。</span><br><span class="line"></span><br><span class="line">1.模长函数定义</span><br><span class="line"></span><br><span class="line">R拥有自定义函数功能，可按如下格式定义：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    函数名

    <-function(参数 1，参数 2， ...，参数 n){ 函数体 } <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面定义求三维向量模长的vector_length函数，完成模长计算。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > vector_length<-function(x1， x2， x3){ + vlength<-sqrt (x1^2+x2^2+x3^2) vlength } <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.模长计算</span><br><span class="line"></span><br><span class="line">调用vector_length函数，计算向量[12，33，19]的模长。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > vector_length(12，

    33，

    19)
    [1] 39.92493
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">N维向量的模长计算与三维模长类似。下面重新定义vectorn_length函数，并调用它计算任意维度向量的模长。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > vectorn_length<-function(x){ + temp<-0 for (i in 1:length(x)){ temp<-temp+x[i]^2 } vlength<-sqrt(temp) vlength>#下面调用新的

    vectorn_length函数计算模长


    > vectorn_length(c(11，

    22，

    33，

    44，

    55))
    [1] 81.57818
    > vectorn_length(c(11，

    22，

    33，

    55))
    [1] 68.69498 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 3.4.5 欧氏距离计算</span><br><span class="line"></span><br><span class="line">欧氏距离（Euclid Distance）是在n维空间中两个点之间的真实距离，n维欧氏空间的每个点可以表示为(x[1]，x[2]，…，x[n])，X=(x[1]，x[2]，…，x[n])和Y=(y[1]，y[2]，…，y[n])这两个点之间的距离d(X，Y)定义为下面的公式：</span><br><span class="line"></span><br><span class="line">d(X，Y)=sqrt(∑((x[i]-y[i])^2))其中i=1，2，…，n</span><br><span class="line"></span><br><span class="line">利用R语言的操作符自定义功能完成欧氏距离计算，操作符的定义使用%符号%的方式定义，实际使用时，%也属于操作符的一部分。操作符的定义格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    操作符名

    <-function(参数 1，参数 2， ...，参数 n){ 语句 } <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面定义%~%操作符，并计算二维空间的欧氏距离。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

     > "%~%"<-function(x1， x2){ + temp<-0 for (i in 1:length(x1)){ temp<-temp+(x1[i]-x2[i])^2 } edis<-sqrt(temp) edis>#使用

    %~%操作符，计算二维空间的欧氏距离


    > c(1，

    2，

    3) %~% c(5，

    6，

    7)
    [1] 6.928203
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">可以将计算扩展到n维空间中。使用R语言的不定数量的函数参数机制，来定义n维空间的欧氏距离函数mycount。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > mycount<-function(...){ + temp="0" for (i in c(...)){ }> mycount(11，

    22，

    33)
    [1] 3
    > mycount(11，

    22，

    33，

    66)
    [1] 4
    > mycount(11，

    22，

    66)
    [1] 3 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 3.5 小结</span><br><span class="line"></span><br><span class="line">本章对Python语言和R语言的语法基础以及相关计算平台API进行了讲述，同时，用大量实例讲解了相关计算平台的实际操作。</span><br><span class="line"></span><br><span class="line">Python语言和R语言是本书讲解机器学习用到的主要语言，也是机器学习工程应用中可能用到的编程语言，在此建议大家平时多阅读R语言和Python语言的官网教程和相关计算平台资料，加深对它们的理解。</span><br><span class="line"></span><br><span class="line">因本书篇幅有限，更多的关于R语言和Python语言的资料可以查询相关官网。下面列举了常用的官网链接。</span><br><span class="line"></span><br><span class="line">R语言文档资料链接：</span><br><span class="line"></span><br><span class="line">&lt;http://cran.r-project.org/manuals.html&gt;  </span><br><span class="line"></span><br><span class="line">Python科学计算库文档资料链接：</span><br><span class="line"></span><br><span class="line">&lt;http://docs.python.org/2/&gt;  </span><br><span class="line"></span><br><span class="line">&lt;http://docs.scipy.org/doc/&gt;  </span><br><span class="line"></span><br><span class="line">&lt;http://docs.opencv.org/master/modules/refman.html&gt;  </span><br><span class="line"></span><br><span class="line">从下章开始，我们将正式进入机器学习和统计分析的实战。建议大家在浏览器中将上面的文档链接收藏，以便更好地理解本书内容。此外，从本章开始，每章小结后均有思考题，希望大家在阅读本书的过程中，多动手，多上机操作，理论联系实践才是王道。</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">（1）本章中提到了Python将信息隐藏在声音和图像载体文件的方法，能不能将隐藏了信息的图像载体文件隐藏在一段音乐之中？</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 可以考虑先将隐藏了信息的图像矩阵读入，然后将其作为原始数据混进WAV格式的音乐文件之中，再用原始音乐文件作为解码的密钥，解码图像数据后，用本章介绍的方法从图像数据中恢复文字信息。</span><br><span class="line"></span><br><span class="line">（2）用R语言分析一个数据集的数据，将数据分为适当的区间，然后统计数据在每个区间的分布数量，并作出直方图。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 用因子频率分析方法实现。</span><br><span class="line"></span><br><span class="line">（3）用R语言在x和y之间建立回归模型，得出回归直线方程，x=[1，3，8，9]，y=[2，8，23，80]</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 使用R语言的回归计算函数分析。</span><br><span class="line"></span><br><span class="line">## 第4章 生产环境基础</span><br><span class="line"></span><br><span class="line">机器学习的任务是研究计算机怎样模拟或实现人类的学习行为，重新组织已有的知识结构使之不断改善自身的性能，它是人工智能的核心，是使计算机具有智能的根本途径。</span><br><span class="line"></span><br><span class="line">从目前的发展情形来看，机器学习主要依靠各种算法来实现，比如：神经网络、SVM、决策树、K近邻、K-Means、回归算法等。而算法是对特定问题求解过程的描述，是为解决某一特定问题而采取的具体有限的操作步骤。随着计算机科学技术的发展，算法在计算机方面已有了广泛的发展及应用。算法可理解为计算机指令的有限序列，每条指令完成一个或多个操作，它是描述计算机程序行为的语言，是让程序变得最为简洁的思考方式。程序在调试完毕后，需要投入到实际运行阶段，这个阶段需要一个运行平台，这就是生产环境。</span><br><span class="line"></span><br><span class="line">在工业界，生产环境主要指生产现场中进行制造的地点，包括生产工装、量具、工艺过程、材料、操作者、环境和过程设置。在软件工程领域界，“生产环境”一词是指软件调试完毕并正式启用后实际运行的环境。在该环境下，软件系统运行的目标是稳定、安全、可靠。目前，生产环境中最常用的是Windows Server和Linux/UNIX两种，考虑到读者普遍比较熟悉Windows系统，本章将重点讲解Linux下的生产环境基础。</span><br><span class="line"></span><br><span class="line">### 4.1 Windows Server 2008基础</span><br><span class="line"></span><br><span class="line">以Windows Server 2008作为生产环境，可开发、提供和管理丰富的企业级应用程序，充分利用其提供的高度安全的网络基础架构，提高和增加技术的效率与价值。Windows Server 2008建立在网络和虚拟化技术之上，可提高基础服务器设备的可靠性和灵活性。新的虚拟化工具、网络资源和增强的安全性等均可降低成本，为动态和优化的数据中心提供平台。故障转移集群的改进可简化集群，提高集群的稳定性并使得它们更加安全，新的故障转移集群验证向导可用于测试存储。此外，Windows Server 2008还包括一个新的TCP/IP协议栈，称为下一代TCP/IP协议栈。下一代TCP/IP协议栈完全重新设计了TCP/IP功能，兼容了互联网协议第4版（IPv4）和互联网协议第6版（IPv6），符合不同的网络环境和技术的连通性和性能需要。</span><br><span class="line"></span><br><span class="line">#### 4.1.1 Windows Server 2008 R2概述</span><br><span class="line"></span><br><span class="line">Windows Server 2008是专为强化下一代网络、应用程序和Web服务的功能而设计的，是有史以来最先进的Windows Server操作系统。与Windows Server 2008相比，Windows Server 2008 R2继续拓展了虚拟化、系统管理弹性、网络存取方式，以及信息安全等领域的应用。Windows Server 2008 R2中重要的新功能包含：Hyper-V加入了动态迁移的功能，作为最初发布版中快速迁移功能的一个改进，Hyper-V将以毫秒计算迁移时间，与VMware公司的ESX或其他管理程序相比，它是Hyper-V功能的一个强项。此外，它还强化了PowerShell对各个服务器角色的管理指令。该系统具有以下特色：</span><br><span class="line"></span><br><span class="line">·Hyper-V 2.0：使虚拟化的功能与可用性更完备。Hyper-V 2.0不仅支持Live Migration动态迁移，还能支持更多的Linux操作系统安装在VM上。Windows Server 2008推出半年后，微软就推出了内建在Windows Server 2008上的虚拟化平台Hyper-V 1.0，这个版本虽然具有基本的虚拟化功能，但是相比于其他虚拟化平台却薄弱许多，如缺乏动态迁移功能，因此无法在不停止虚拟主机（VM）的情况下，将VM转移到其他实体服务器上。目前，这项功能在Windows Server 2008 R2的Hyper-V 2.0上开始支持，使得这项虚拟化平台的可用性迈进了一大步。</span><br><span class="line"></span><br><span class="line">·Active Directory Administrative Center：可离线加入网域、AD资源回收筒（AD可强化管理接口与部署弹性）。Active Directory(AD)在Windows Server操作系统中从来都是举足轻重的服务器角色，Windows Server 2008 R2对此也强化了不少功能。例如具有新的AD管理接口，同时还能使用PowerShell指令操作；可让计算机离线加入网域，并有AD资源回收站，增加了AD成员的增删弹性。</span><br><span class="line"></span><br><span class="line">·Windows PowerShell 2.0与Server Core：Server Core模式支持.NET，R2改善了Server Core不支持.NET Framework且不能使用PowerShell的缺点。现在在指令操作为主要要求的Server Core中，可以搭配PowerShell，从而使服务器管理的操作更有效率。Server Core安装选项是安装Windows Server 2008操作系统的一种新的选择。Server Core安装提供了一个最小的运行环境作为特定的服务器角色，降低了服务器的维护管理强度，同时降低了服务器角色被黑客攻击的可能性。</span><br><span class="line"></span><br><span class="line">·Remote Desktop Services：可提升桌面与应用程序的虚拟化功能。在新版的RDS中，也增加了新的Remote Desktop Connection Broker（RDCB）。这项功能可整合RDS所有的应用程序服务器，包含实体主机和VM。</span><br><span class="line"></span><br><span class="line">·DirectAcess：可提供更方便、更安全的远程联机通道。DirectAccess让VPN通道的建立变得更加简便，可整合多种验证机制及NAP，有助于提高联机过程中的安全性。</span><br><span class="line"></span><br><span class="line">·BranchCache：可加快分公司之间档案存取的新做法。利用档案快取的方式，可以就近存取先前已经下载过的档案，除了能更快地取得分享数据之外，也能减少对外联机频宽的浪费。</span><br><span class="line"></span><br><span class="line">·URL-based QoS：企业可进一步控管网页存取频宽。企业可以针对所有个人计算机连接特定网站的联机定义优先权，加快重要网页的存取速度。</span><br><span class="line"></span><br><span class="line">·BitLocker to Go：支持可移除式存储装置加密。BitLocker to Go加密随身碟这一步骤的特别之处在于可以整合智能卡验证使用者身份的真实性，使得存储装置的控管变得更加安全。</span><br><span class="line"></span><br><span class="line">·AppLocke：可提高个人端应用程序的控管度。AppLockers可称为软件限制原则的加强版本，除了具备一切旧有功能，最为重要的是企业可以通过不可随意修改的发行者信息，有效地禁止或允许应用程序的执行，同时也更加完善了其自身的安全性能。</span><br><span class="line"></span><br><span class="line">#### 4.1.2 Windows PowerShell</span><br><span class="line"></span><br><span class="line">Windows PowerShell是微软公司为Windows环境所开发的壳程序（Shell）及脚本语言技术，采用的是命令行界面。这项全新的技术提供了丰富的控制选项与自动化的系统管理能力。Microsoft推出Windows PowerShell的目的是：使Windows PowerShell成为相当于UNIX/Linux系统的命令行壳程序（如sh、bash或csh），同时还可内置脚本语言及辅助脚本程序的工具。</span><br><span class="line"></span><br><span class="line">Windows PowerShell以.NET Framework技术为基础，并且与现有的WSH保持向后兼容，因此它的脚本程序不仅能访问.NET CLR，也能使用现有的COM技术。同时还包含了数种系统管理工具，简易且一致的语法，可提升管理者的处理能力，常见的如登录数据库、WMI等。Windows PowerShell具有以下优势：</span><br><span class="line"></span><br><span class="line">·一致性的设计让所有的工具和系统数据的使用语法、命名原则都相同。</span><br><span class="line"></span><br><span class="line">·脚本语言简单易学，而且还能支持现有的脚本程序和命令行工具。</span><br><span class="line"></span><br><span class="line">·内含129种被称为cmdlet的标准工具，可用来处理常见的系统管理工作。</span><br><span class="line"></span><br><span class="line">·具备完整的可扩展性，独立软件商或开发者都能很容易地根据需求自行扩充。</span><br><span class="line"></span><br><span class="line">·进程间数据传递的内容具有强类型特征。</span><br><span class="line"></span><br><span class="line">以下示例演示了Windows PowerShell的基本使用方法。</span><br><span class="line"></span><br><span class="line">获取所有命令：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> Get-Command <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">查看Get-Command命令的用法：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> Get-Help Get-Command <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">停止目前正在运行的以&apos;p&apos;字符开头来命名的所有程序：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> get-process p* | stop-process <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">停止目前正在运行的使用大于1000MB存储器的所有程序：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> get-process | where { $_.WS -gt 1000MB } | stop-process <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">计算某个目录下文件内的字节大小：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> get-childitem | measure-object -property length -sum <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">等待一个名为“notepad”的程序运行退出：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> $processToWatch = get-process notepad
    PS> $processToWatch.WaitForExit() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">将&quot;hello，world!&quot;字符串转为英文大写字符，使其变成&quot;HELLO，WORLD!&quot;：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> "hello, world!".ToUpper() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在字符串&quot;string&quot;的第1个字符后插入字符串&quot;ABC&quot;，使其变成&quot;sABCtring&quot;：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> "string".Insert(1, "ABC") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">订阅一个指定的RSS Feed并显示它最近的8个主题：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> $rssUrl = "<http: blogs.msdn.com powershell rss.aspx>

    "
    PS> $blog = [xml](new-object System.Net.WebClient).DownloadString($rssUrl)
    PS> $blog.rss.channel.item | select title -first 8 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">将&quot;$UserProfile&quot;设置成数值&quot;UserProfile&quot;的环境变量：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    PS> $UserProfile = $env:UserProfile <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 更多的Windows PowerShell资料可查阅如下网址：</span><br><span class="line"></span><br><span class="line">&lt;http://www.pstips.net/powershell-online-tutorials&gt;  </span><br><span class="line"></span><br><span class="line">&lt;http://msdn.microsoft.com/en-us/library/dd835506(VS.85).aspx&gt;  </span><br><span class="line"></span><br><span class="line">### 4.2 Linux基础</span><br><span class="line"></span><br><span class="line">Linux最初是作为支持英特尔x86架构的个人计算机的一个自由操作系统，目前Linux已经被移植到更多的计算机硬件平台上，远远超出其他的任何操作系统。Linux发行版一直被用来作为服务器的主流操作系统，并且已经在该领域中占据了重要的地位，世界上500个最快的超级计算机90%以上运行的均是Linux发行版或其变种，包括最快的前10名超级计算机运行的都是基于Linux内核的操作系统。曾经是世界上最强大的超级计算机——IBM的红杉（IBM Sequoia），已于2011年交付劳伦斯利福摩尔国家实验室，并于2012年6月开始运作，也是选择Linux作为操作系统。Linux也广泛应用于嵌入式系统上，如手机、平板电脑、路由器、电视和电子游戏机等。广泛使用于移动设备上的Android操作系统就是创建于Linux内核之上的。4.2.1节将以常用的Linux版本CentOS为例，来讲解Linux命令。</span><br><span class="line"></span><br><span class="line">#### 4.2.1 Linux命令</span><br><span class="line"></span><br><span class="line">1.Linux命令基础</span><br><span class="line"></span><br><span class="line">Linux命令是对Linux系统进行管理的命令。对于Linux系统来说，无论是中央处理器、内存、磁盘驱动器、键盘、鼠标，还是用户等都是文件，Linux系统管理的命令是它正常运行的核心，与之前的DOS命令类似。Linux命令在系统中有两种类型：内置Shell命令和Linux命令。本节讲解Linux命令，Shell命令将在4.2.2节讲解。</span><br><span class="line"></span><br><span class="line">Linux命令通常具有以下格式：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    命令名

     [命令选项

    ] [命令参数

    ] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">先来看一个最简单的命令“su”，该命令用于用户的身份转换。su命令可以转换用户身份，su用户名表示转到某用户，若su命令不带参数则表示直接转到超级用户root。命令提示符“$”表示普通用户状态，“#”表示超级用户状态。下面的操作将演示身份转换：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ 
    $ su <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">密码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.常用Linux命令</span><br><span class="line"></span><br><span class="line">以下是系统信息与系统管理中常用的Linux命令的示例：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # arch                        显示机器的处理器架构


    # cal 2007                    显示

    2007年的日历表


    # cat /proc/cpuinfo           显示

    CPU info的信息


    # cat /proc/interrupts        显示中断


    # cat /proc/meminfo           校验内存使用


    # cat /proc/swaps             显示哪些

    swap被使用


    # cat /proc/version           显示内核的版本


    # cat /proc/net/dev           显示网络适配器及统计


    # cat /proc/mounts            显示已加载的文件系统


    # clock -w                    将对时间的修改保存到

     BIOS 
    # date                        显示系统日期


    # lsusb -tv                   显示

     USB 设备


    # uname -m                    显示机器的处理器架构


    # uname -r                    显示正在使用的内核版本


    # logout                      注销


    # reboot                      重启


    # shutdown -h now             关闭系统


    # shutdown -h 22:50 &         按预定时间

    22:50关闭系统


    # shutdown -c                 取消按预定时间关闭系统


    # shutdown -r now             重启

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">以下是文件和目录管理中常用的Linux命令：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # cd /home                                  进入

    \home目录


    # cp file1 file2                            复制一个文件


    # ls                                        查看目录中的文件


    # mkdir dir                                 创建

    dir目录


    # mv mydir new_mydir                        重命名

    /移动一个目录


    # pwd                                       显示工作路径


    # rm -f file                                删除

    file文件


    # find / -name myfile                       从

     '/' 开始进入根文件系统搜索

    myfile文件


    # mount -o loop myfile.iso /mnt/cdrom       挂载一个文件或

    ISO镜像文件


    # df -h                                     显示已经挂载的分区列表


    # cat file1                                 从第一个字节开始正向查看文件的内容

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">以下是用户与用户组管理中常用的Linux命令：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # groupadd [group]                        创建一个新用户组


    # groupdel [group]                        删除一个用户组


    # passwd                                  修改口令


    # passwd myuser                           修改用户的口令


    # useradd myuser                          创建一个新用户


    # userdel myuser                          删除一个用户


    # chgrp mygroup  myfile                   改变文件的群组

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.主要命令解析及技巧</span><br><span class="line"></span><br><span class="line">（1）ls命令</span><br><span class="line"></span><br><span class="line">ls命令将指定目录的文件及目录输出在屏幕中。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls
    hadoop-2.4.1  hadoop-2.4.1-src.tar.gz  hadoop-2.4.1.tar.gz  numpy  pypy-2.3.1-src <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，通过加上“-la”参数可表示：以长格式的形式查看当前目录下的所有文件，包括隐藏文件。文件各字段的含义如下：</span><br><span class="line"></span><br><span class="line">·文件属性：drwxr-xr-x</span><br><span class="line"></span><br><span class="line">·文件硬链接数或目录子目录数：3（一个空目录的该字段是2，表示该目录下有两个子目录，因为每一个目录都有一个指向它本身的子目录&quot;.&quot;和指向它上级目录的子目录&quot;..&quot;）</span><br><span class="line"></span><br><span class="line">·所有者：user</span><br><span class="line"></span><br><span class="line">·所属用户组：group</span><br><span class="line"></span><br><span class="line">·文件大小：102 byte</span><br><span class="line"></span><br><span class="line">·修改时间：Mar11 22:56</span><br><span class="line"></span><br><span class="line">·文件名：Filename</span><br><span class="line"></span><br><span class="line">下例演示了该参数的用法：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls -la ~总用量

     150484
    drwx------.  6 myhaspl myhaspl      4096 9月

      10 16:55 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl       220 9月

      10 17:59 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    drwxr-xr-x.  8 myhaspl myhaspl      4096 9月

      10 17:02 numpy
    drwxr-----.  3 myhaspl myhaspl        18 9月

      10 16:21 .pki
    drwxrwxr-x. 14 root    root         4096 9月

      10 16:25 pypy-2.3.1-src <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）cd命令及多条命令同行</span><br><span class="line"></span><br><span class="line">cd命令的功能是切换当前目录，示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $cd ..
    $cd /home/
    $cd /opt <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，还可以将多个命令写在同一行，一次使用，用分号隔开，比如：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls -la ;cd numpy;ls总用量

     150484
    drwx------.  6 myhaspl myhaspl      4096 9月

      10 16:55 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl       220 9月

      10 17:59 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    drwxr-xr-x.  8 myhaspl myhaspl      4096 9月

      10 17:02 numpy
    drwxr-----.  3 myhaspl myhaspl        18 9月

      10 16:21 .pki
    drwxrwxr-x. 14 root    root         4096 9月

      10 16:25 pypy-2.3.1-src
    BENTO_BUILD.txt  build              INSTALL.txt  pavement.py  setupegg.py
                 THANKS.txt
    bento.info        COMPATIBILITY     LICENSE.txt  README.txt   setup.py    tools
    branding    DEV_README.txt  MANIFEST.in  release.sh   site.cfg.example  tox.ini
    bscript        doc        numpy        runtests.py    TEST_COMMIT
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如上面的结果所示，首先，先执行第1条ls命令，输出当前目录下的文件列表，然后，执行第2条cd命令，进入numpy目录后，执行第3条ls命令，输出numpy目录下的内容。</span><br><span class="line"></span><br><span class="line">（3）命令后台执行</span><br><span class="line"></span><br><span class="line">可以让进程在后台运行，执行命令后立即返回，这样还可以继续执行其他命令，只要在命令行的最后加上“&amp;”即可。下面的示例是查找含有字符串“doc”的文件，因查找过程比较漫长，故而直接在后台执行并返回，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ find ~ -name doc &
    [1] 5453
    $ /home/myhaspl/hadoop-2.4.1/share/doc
    /home/myhaspl/pypy-2.3.1-src/site-packages/numpy/doc
    /home/myhaspl/pypy-2.3.1-src/ctypes_configure/doc
    /home/myhaspl/pypy-2.3.1-src/pypy/doc
    /home/myhaspl/numpy/doc
    /home/myhaspl/numpy/build/lib.linux-x86_64-2.7/numpy/doc
    /home/myhaspl/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/f2py/doc <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（4）重定向与管道</span><br><span class="line"></span><br><span class="line">重定向是指对原来系统命令的默认执行方式进行改变，比如将原本在显示器中的输出改为输出到某一文件中。常用的重定向命令如下所示（cmd表示命令，file表示文件或设备）：</span><br><span class="line"></span><br><span class="line">cmd&gt;file 把stdout重定向到file文件中。</span><br><span class="line"></span><br><span class="line">cmd&gt;&gt;file 把stdout重定向到file文件中（追加）。</span><br><span class="line"></span><br><span class="line">cmd 1&gt;file 把stdout重定向到file文件中。</span><br><span class="line"></span><br><span class="line">cmd&gt;file 2&gt;&amp;1 把stdout和stderr一起重定向到file文件中。</span><br><span class="line"></span><br><span class="line">cmd 2&gt;file 把stderr重定向到file文件中。</span><br><span class="line"></span><br><span class="line">cmd 2&gt;&gt;file 把stderr重定向到file文件中（追加）。</span><br><span class="line"></span><br><span class="line">下面以实例来讲解主要的重定向操作。首先来讲解重定向操作符“&gt;”，下面的例子演示了先使用find命令来查找含有“doc”的文件，然后使用“&gt;”将结果列表重定向到一个文件中：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ find ~ -name doc >mydoclist &
    [1] 5461
    $ ls
    hadoop-2.4.1               hadoop-2.4.1.tar.gz  numpy
    hadoop-2.4.1-src.tar.gz  mydoclist          pypy-2.3.1-src
    [1]+  完成

                     find ~ -name doc > mydoclist
    $ cat mydoclist
    /home/myhaspl/hadoop-2.4.1/share/doc
    /home/myhaspl/pypy-2.3.1-src/site-packages/numpy/doc
    /home/myhaspl/pypy-2.3.1-src/ctypes_configure/doc
    /home/myhaspl/pypy-2.3.1-src/pypy/doc
    /home/myhaspl/numpy/doc
    /home/myhaspl/numpy/build/lib.linux-x86_64-2.7/numpy/doc
    /home/myhaspl/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/f2py/doc
    /home/myhaspl/numpy/numpy/build/lib.linux-x86_64-2.7/numpy/doc
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接下来讲解重定向操作符“&gt;&gt;”，下面的例子先使用find命令查找文件，然后使用“&gt;&gt;”将查找结果重定向到文件mydoclist中：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ find ~ -name hadoop >>mydoclist &
    [1] 5466
    $ cat mydoclist
    /home/myhaspl/hadoop-2.4.1/share/doc
    /home/myhaspl/pypy-2.3.1-src/site-packages/numpy/doc
    /home/myhaspl/pypy-2.3.1-src/ctypes_configure/doc
    /home/myhaspl/pypy-2.3.1-src/pypy/doc
    /home/myhaspl/numpy/doc
    /home/myhaspl/numpy/build/lib.linux-x86_64-2.7/numpy/doc
    /home/myhaspl/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/doc
    /home/myhaspl/numpy/numpy/numpy/f2py/doc
    /home/myhaspl/numpy/numpy/build/lib.linux-x86_64-2.7/numpy/doc
    /home/myhaspl/hadoop-2.4.1/bin/hadoop
    /home/myhaspl/hadoop-2.4.1/etc/hadoop
    /home/myhaspl/hadoop-2.4.1/share/hadoop
    /home/myhaspl/hadoop-2.4.1/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/classes/org/apache/hadoop
    /home/myhaspl/hadoop-2.4.1/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/classes/org/apache/hadoop/lib/service/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/api/src-html/org/apache/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/api/org/apache/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/api/org/apache/hadoop/lib/service/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/src-html/org/apache/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/src-html/org/apache/hadoop/lib/service/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop
    /home/myhaspl/hadoop-2.4.1/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">再接下来，看一个I/O重定向的例子。在Linux系统中，标准输入（stdin）的文件描述符为0，标准输出（stdout）的文件描述符为1，标准错误输出（stderr）的文件描述符为2。</span><br><span class="line"></span><br><span class="line">标准输出重定向命令格式如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    1>filename或

    1>>filename <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了I/O重定向的使用方法，将标准输出重定向到文件abc中：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ echo "aaa" 1> abc
    $ cat abc
    aaa
    $ echo "aaa" 1>> abc
    $ cat abc
    aaa
    aaa
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">标准错误输出重定向命令格式如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    2>filename或

    2>>filename <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何将标准错误输出重定向到文件error.log中：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ rm /root/* 2>error.log
    $ cat error.log
    rm: 无法删除

    "/root/*": 权限不够


    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，还可以使用“i&gt;&amp;j”将文件描述符i表示的输出文件重定向到文件描述符j表示的文件中。</span><br><span class="line"></span><br><span class="line">最后，讲解tee命令与管道操作符“|”的合并使用，实现在输出的同时，再输出一份同样的内容给管道。下例演示了如何列出目录的内容并输出给mylist文件：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls |tee mylist
    hadoop-2.4.1
    hadoop-2.4.1-src.tar.gz
    hadoop-2.4.1.tar.gz
    mydoclist
    numpy
    pypy-2.3.1-src
    $ cat mylist
    hadoop-2.4.1
    hadoop-2.4.1-src.tar.gz
    hadoop-2.4.1.tar.gz
    mydoclist
    numpy
    pypy-2.3.1-src
    $  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 管道是Linux中很重要的一种通信方式，是将一个程序的输出直接连接到另一个程序的输入。</span><br><span class="line"></span><br><span class="line">（5）通配符</span><br><span class="line"></span><br><span class="line">在文件管理等操作中，可以使用通配符，最常用的通配符如下：</span><br><span class="line"></span><br><span class="line">·*：多个字符</span><br><span class="line"></span><br><span class="line">·?：单个字符</span><br><span class="line"></span><br><span class="line">此外，还可以使用“~”来表示当前用户的主目录。</span><br><span class="line"></span><br><span class="line">下例演示了如何使用ls命令加通配符的模式列出指定目录“~/numpy/”的内容：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls ~/numpy/*.py
    /home/myhaspl/numpy/pavement.py  /home/myhaspl/numpy/setupegg.py
    /home/myhaspl/numpy/runtests.py  /home/myhaspl/numpy/setup.py
    $ ls ~/numpy/*.txt
    /home/myhaspl/numpy/BENTO_BUILD.txt  /home/myhaspl/numpy/LICENSE.txt
    /home/myhaspl/numpy/DEV_README.txt   /home/myhaspl/numpy/README.txt
    /home/myhaspl/numpy/INSTALL.txt      /home/myhaspl/numpy/THANKS.txt
    $ ls ~/numpy/setup*.py
    /home/myhaspl/numpy/setupegg.py  /home/myhaspl/numpy/setup.py
    $ ls ~/numpy/setup.??
    /home/myhaspl/numpy/setup.py
    $  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（6）作业管理</span><br><span class="line"></span><br><span class="line">可以使用jobs命令显示当前作业，grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本。下例将这二者结合起来，输出文件列表中包括字符串&quot;se&quot;的文件名，并将输出结果放到myse文件中：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ find ~ -name "*.py"|grep se >myse &
    [1] 2258
    $ jobs
    [1]+  运行中

                   find ~ -name "*.py" | grep se > myse &
    $ jobs
    [1]+  完成

                     find ~ -name "*.py" | grep se > myse
    $ cat myse
    /home/myhaspl/pypy-2.3.1-src/dotviewer/graphparse.py
    /home/myhaspl/pypy-2.3.1-src/dotviewer/graphserver.py <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了使用kill命令来停止作业，其中sleep表示该作业休眠，后面的时间参数可以是s（秒）、h（小时）、m（分钟）或d（日数）：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ (find ~ -name "*.?y"|grep se >myse;sleep 10s )&
    [1] 2365
    $ jobs
    [1]+  运行中

            ( find ~ -name "*.?y" | grep --color=auto se > myse; sleep 10s ) &
    $ kill %1
    $ jobs
    [1]+  已终止

            ( find ~ -name "*.?y" | grep --color=auto se > myse; sleep 10s )
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（7）查询命令使用方式</span><br><span class="line"></span><br><span class="line">可以使用man命令行的方式来查询命令帮助，下面演示了查询ls命令的帮助信息：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    man ls <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">目录：</span><br><span class="line"></span><br><span class="line">·~表示当前用户的主目录。</span><br><span class="line"></span><br><span class="line">·.表示当前目录。</span><br><span class="line"></span><br><span class="line">·..表示上级目录。</span><br><span class="line"></span><br><span class="line">（8）链接文件</span><br><span class="line"></span><br><span class="line">在Linux中，可用不同的文件名引用同一个数据或程序，称为硬链接，可在同一物理文件系统中，创建硬链接。下例演示了硬链接的使用方法：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls -la总用量

     151228
    drwx------.  6 myhaspl myhaspl      4096 9月

      18 08:55 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl      1915 9月

      16 18:05 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl      1454 9月

      16 10:53 mydoclist
    -rw-rw-r--.  1 myhaspl myhaspl        88 9月

      16 17:25 mylist
    -rw-rw-r--.  1 myhaspl myhaspl    357304 9月

      18 08:55 mypylist
    -rw-rw-r--.  1 myhaspl myhaspl     31954 9月

      16 18:02 myse
    drwxr-xr-x.  8 myhaspl myhaspl      4096 9月

      16 10:39 numpy
    drwxr-----.  3 myhaspl myhaspl        18 9月

      10 16:21 .pki
    drwxrwxr-x. 14 root    root         4096 9月

      10 16:25 pypy-2.3.1-src
    -rw-rw-r--.  1 myhaspl myhaspl    357304 9月

      16 17:57 se
    $ ln mypylist mypylist1
    $ ls -la总用量

     151580
    drwx------.  6 myhaspl myhaspl      4096 9月

      18 08:56 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl      1915 9月

      16 18:05 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl      1454 9月

      16 10:53 mydoclist
    -rw-rw-r--.  1 myhaspl myhaspl        88 9月

      16 17:25 mylist
    -rw-rw-r--.  2 myhaspl myhaspl    357304 9月

      18 08:55 mypylist
    -rw-rw-r--.  2 myhaspl myhaspl    357304 9月

      18 08:55 mypylist1
    -rw-rw-r--.  1 myhaspl myhaspl     31954 9月

      16 18:02 myse
    drwxr-xr-x.  8 myhaspl myhaspl      4096 9月

      16 10:39 numpy
    drwxr-----.  3 myhaspl myhaspl        18 9月

      10 16:21 .pki
    drwxrwxr-x. 14 root    root         4096 9月

      10 16:25 pypy-2.3.1-src
    -rw-rw-r--.  1 myhaspl myhaspl    357304 9月

      16 17:57 se
    $ ln mypylist mypylist2
    $ ls -la总用量

     151932
    drwx------.  6 myhaspl myhaspl      4096 9月

      18 09:27 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl      1915 9月

      16 18:05 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl      1454 9月

      16 10:53 mydoclist
    -rw-rw-r--.  1 myhaspl myhaspl        88 9月

      16 17:25 mylist
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist1
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist2
    -rw-rw-r--.  1 myhaspl myhaspl     31954 9月

      16 18:02 myse
    drwxr-xr-x.  8 myhaspl myhaspl      4096 9月

      16 10:39 numpy
    drwxr-----.  3 myhaspl myhaspl        18 9月

      10 16:21 .pki
    drwxrwxr-x. 14 root    root         4096 9月

      10 16:25 pypy-2.3.1-src
    -rw-rw-r--.  1 myhaspl myhaspl    357304 9月

      16 17:57 se <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从几条命令的执行结果可以看到：mypylist的硬链接数量在增加。</span><br><span class="line"></span><br><span class="line">在Linux下也可以创建软链接，这种链接跨越了不同的物理文件系统，也称为符号链接文件，与硬链接不同的是，它是一个单独的文件，存放着目标文件的路径名。下例演示了软链接的使用方式：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ln -s mypylist mypylists
    $ ls -la总用量

     151932
    drwx------.  6 myhaspl myhaspl      4096 9月

      18 09:35 .
    drwxr-xr-x.  3 root    root           20 9月

      10 08:23 ..
    -rw-------.  1 myhaspl myhaspl      1915 9月

      16 18:05 .bash_history
    drwxr-xr-x.  9 myhaspl myhaspl      4096 6月

      21 14:38 hadoop-2.4.1
    -rw-r--r--.  1 myhaspl myhaspl  15417097 6月

      21 14:42 hadoop-2.4.1-src.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl 138656756 6月

      21 14:42 hadoop-2.4.1.tar.gz
    -rw-r--r--.  1 myhaspl myhaspl      1454 9月

      16 10:53 mydoclist
    -rw-rw-r--.  1 myhaspl myhaspl        88 9月

      16 17:25 mylist
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist1
    -rw-rw-r--.  3 myhaspl myhaspl    357304 9月

      18 08:55 mypylist2
    lrwxrwxrwx.  1 myhaspl myhaspl         8 9月

      18 09:35 mypylists -> mypylist <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（9）文件权限</span><br><span class="line"></span><br><span class="line">对于一般的Linux文件而言，权限如下所示：</span><br><span class="line"></span><br><span class="line">·r：允许读文件内容。</span><br><span class="line"></span><br><span class="line">·w：允许修改文件内容。</span><br><span class="line"></span><br><span class="line">·x：允许执行该文件。</span><br><span class="line"></span><br><span class="line">对于Linux目录而言，权限如下所示：</span><br><span class="line"></span><br><span class="line">·r：允许列出该目录下的文件和子目录。</span><br><span class="line"></span><br><span class="line">·w：允许生成和删除该目录下的文件。</span><br><span class="line"></span><br><span class="line">·x：允许访问该目录。</span><br><span class="line"></span><br><span class="line">·u：代表所有者（user）。</span><br><span class="line"></span><br><span class="line">·g：代表所有者所在的组群（group）。</span><br><span class="line"></span><br><span class="line">·o：代表其他人，但不是u和g（other）。</span><br><span class="line"></span><br><span class="line">·a：代表全部的人，也就是包括u、g和o。</span><br><span class="line"></span><br><span class="line">此外，还可以通过chmod命令来改变权限。该命令的格式如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    chmod [用户类型

    ](+/-)访问权限的格式文件或目录名

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何改变权限，将mytext设置为所有的人可写为：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    chmod a+w mytext <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了文件myrun的生成、权限的授予及最后执行的过程：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ echo "ls;echo \"ok\"" >myrun
    $ cat myrun
    ls;echo "ok"
    $ chmod +x ./myrun
    $ ./myrun
    abc       hadoop-2.4.1             mydoclist  mypylist1  myrun  pypy-2.3.1-src
    abd       hadoop-2.4.1-src.tar.gz  mylist     mypylist2  myse     se
    error.log  hadoop-2.4.1.tar.gz     mypylist   mypylists  numpy
    ok <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（10）进程管理</span><br><span class="line"></span><br><span class="line">可通过ps命令显示当前进程，通过kill命令杀死进程，kill命令终止进程的调用格式如下（pid为进程号）：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    kill -9 pid <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了显示进程及杀死进程的过程：首先，执行ls命令后开始休眠，整个过程处于一个进程内，然后在该进程休眠后，通过ps命令查找该进程的PID号，最后用kill命令终止该进程。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls;sleep 20&
    $ ps -a
      PID TTY          TIME CMD
     2245 pts/0    00:00:00 sleep
     2246 pts/0    00:00:00 ps
    $ ps -ef
    UID        PID  PPID  C STIME TTY         TIME CMD
    root         1     0  0 16:07   ?     00:00:01 /usr/lib/systemd/systemd
    --switched-root -
    root         2     0  0 16:07   ?     00:00:00 [kthreadd]
    root         3     2  0 16:07   ?     00:00:00 [ksoftirqd/0]
    root         5     2  0 16:07   ?     00:00:00 [kworker/0:0H]
    root         6     2  0 16:07   ?     00:00:00 [kworker/u2:0]……

    .……

    .
    myhaspl   2245  2176  0 17:04 pts/0     00:00:00  sleep 20
    myhaspl   2247  2176  0 17:04 pts/0     00:00:00  ps –

    ef
    $ kill -9 2287
    myhaspl   2289  2261  0 17:11 pts/1     00:00:00  ps -ef
    [1]+  已杀死

                   sleep 20
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（11）用户管理</span><br><span class="line"></span><br><span class="line">下例演示了通过useradd命令、userdel命令进行增加或删除用户的操作：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # useradd -m test1
    # ls /home/
    myhaspl  test1
    # su test1
    $ su
    # userdel test1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（12）磁盘空间管理</span><br><span class="line"></span><br><span class="line">下例演示了通过df命令来查看空间的使用情况：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # df文件系统

                      1K-块

        已用

        可用

        已用

    %  挂载点


    /dev/mapper/centos-root 7022592 2545964 4476628   37%  /
    devtmpfs                 632192       0  632192    0%  /dev
    tmpfs                    638148       0  638148    0%  /dev/shm
    tmpfs                    638148    8320  629828    2%  /run
    tmpfs                    638148       0  638148    0%  /sys/fs/cgroup
    /dev/sda1                508588  126640  381948   25%  /boot
    # <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了通过du命令来查看某个目录或文件的占用空间：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ du -h myrun
    4.0K    myrun
    $ du -h numpy
    4.0K    numpy/.git/refs/heads
    0    numpy/.git/refs/tags
    4.0K    numpy/.git/refs/remotes/origin
    4.0K    numpy/.git/refs/remotes
    8.0K    numpy/.git/refs
    0    numpy/.git/branches
    44K    numpy/.git/hooks
    4.0K    numpy/.git/info
    28M    numpy/.git/objects/pack <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 4.2.2 Shell基础</span><br><span class="line"></span><br><span class="line">Shell是Linux系统的用户界面，为用户与内核进行交互操作提供的一种接口。它接收用户输入的命令并把它送入内核执行。实际上Shell是一个命令解释器，它解释用户输入的命令并且把它们送到内核中。不仅如此，Shell还有自己的编程语言，用于对命令进行编辑，它允许用户编写由Shell命令组成的程序。Shell编程语言具有普通编程语言的很多特点，比如它也有循环结构和分支控制结构等，用这种编程语言编写的Shell程序与其他应用程序具有同样的效果。</span><br><span class="line"></span><br><span class="line">1.建立和运行Shell文件</span><br><span class="line"></span><br><span class="line">什么是Shell程序呢？简单地说Shell程序就是一个包含若干行Shell或Linux命令的文件。下面以实例来说明如何建立并运行Shell文件。</span><br><span class="line"></span><br><span class="line">首先编辑如下Shell文件test1.sh，并将扩展名命名为&quot;.sh&quot;：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/bin/sh
    ls -la
    cd numpy
    ls <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，对Shell文件进行权限授权，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ chmod a+rx test1.sh <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后运行该Shell文件，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ./test1.sh <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.Shell的命令行参数</span><br><span class="line"></span><br><span class="line">1）读取某个命令行参数。可使用$0到$n表示对第0到第n个参数进行操作。下面演示了依次输出程序的命令行参数：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    echo "$0  "
    echo "$1  "
    echo "$2  "
    $ ./test1.sh a b c
    ./test1.sh  
    a
    b <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）弹出所有命令行参数。shift从命令行参数中弹出第1个参数，until开始循环，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    until [ -z "$1" ]
    do
        echo "$1  "
        shift
    done
    $ ./test1.sh a b c d e f
    a  
    b
    c
    d
    e
    f <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）使用$*和$@表示所有参数。下例演示了通过for循环依次读取命令行参数列表中的元素并输出：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    index=1
    for myarg in $*
    do
       echo "NO#$index=$myarg"
       let "index+=1"
    done
    $ ./test1.sh a b c d e f
    NO#1=a
    NO#2=b
    NO#3=c
    NO#4=d
    NO#5=e
    NO#6=f <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.Shell变量</span><br><span class="line"></span><br><span class="line">1）读写变量。可以通过在变量名的前面加“$”取变量的值或以“$&#123;变量名&#125;”的方式对变量进行操作。</span><br><span class="line"></span><br><span class="line">下面例子首先定义了a、b两个变量，然后将a变量的值赋值给b变量，最后输出b变量：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=12
    b=$a
    echo $b
    $ ./test1.sh
    12
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）变量的间接引用。下例演示了通过“$&#123;!变量名&#125;”的方式对变量进行间接引用，读取变量值：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=12
    b=a
    echo ${!b}
    $ ./test1.sh
    12
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.条件表达式</span><br><span class="line"></span><br><span class="line">1）下面的例子演示了如何通过“if…then..else..fi”的方式来完成条件选择，如果a&gt;b，则输出GT，否则输出LT：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=1
    b=2
    if [ $a -gt $b ]
    then
        echo "GT"
    else
        echo "LT"
    fi
    $ ./test1.sh
    LT
    $  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）下面的例子演示了如何通过“if…then..elif…then…else..fi”的方式来完成条件选择，如果a&gt;b，则输出GT，如果a==b则输出eq，否则输出LT：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=2
    b=2
    if [ $a -gt $b ]
    then
       echo "GT"
    elif [ $a -eq $b ]
    then
       echo "eq"
    else
       echo "LT"
    fi
    $ ./test1.sh
    eq
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）下面的例子演示了如何通过“case…in…esac…”语句来完成条件选择，程序输出菜单后，用户选择适合的菜单项，然后通过case系列语句读取用户的选择并输出：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    echo "====================="
    echo "1.a"
    echo "2.b"
    echo "3.c"
    read  mychoice
    case $mychoice in
         1 ) echo "a";;
         2 ) echo "b";;
         3 ) echo "c";;
    esac
    exit 0
    $ ./test1.sh
    =====================
    1.a
    2.b
    3.c
    2
    b
    $  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5.循环</span><br><span class="line"></span><br><span class="line">（1）for循环</span><br><span class="line"></span><br><span class="line">下例演示了如何通过“for…in…do…done”的语句来完成循环的操作：程序首先执行ls命令，读取当前目录下的文件列表，然后使用for语句逐个读取文件列表并输出文件名。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    for filename in 'ls'
    do
        echo $filename
    done
    $ ./test1.sh
    1
    abc
    abd
    error.log
    hadoop-2.4.1
    hadoop-2.4.1-src.tar.gz
    hadoop-2.4.1.tar.gz
    hello
    mydoclist <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何列出非目录性质的文件的操作：程序首先执行ls命令，读取当前目录下的文件列表，然后使用for语句逐个读取文件列表，对列表中的每个文件使用“-f”进行检测，如果是文件，则输出文件名，否则跳过不处理。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    for filename in 'ls'
    do
        if [ -f $filename ]
        then
           echo $filename
        fi
    done
    $ ./test1.sh
    1
    abc
    abd
    error.log
    hadoop-2.4.1-src.tar.gz
    hadoop-2.4.1.tar.gz
    hello
    mydoclist
    myl2
    mylist
    mypylst
    mypylst1
    mypylst2
    myrun
    myse
    se
    test1.sh
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）while循环</span><br><span class="line"></span><br><span class="line">下例演示了while循环的操作，程序通过while循环来完成将变量a的值由1递增到9，并输出：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=1
    while [ $a -lt 10 ]
    do
        echo $a
        a='expr $a + 1'
    done
    $ ./test1.sh
    1
    2
    3
    4
    5
    6
    7
    8
    9
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何使用while循环来显示所有的偶数，其中，将条件设为“:”或“true”，表示恒为真的意思：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    a=0
    while : 
    do
       let "a=$a + 1"
       if [ $a -gt 20 ]
       then
          break
       fi
       if [ $(($a%2)) -eq  1 ]
       then
          continue
       fi
       echo $a
    done   
    $ ./test1.sh
    2
    4
    6
    8
    10
    12
    14
    16
    18
    20
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何使用while循环来实现重定向I/O的功能：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    while read name age
    do 
       echo $name
       echo $age
    done<student.txt 18 19 20 $ cat student.txt zhangsan lisi liumi . test1.sh <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（3）until循环</span><br><span class="line"></span><br><span class="line">下例演示了如何通过until循环来完成变量a的递增，并在满足条件（a&gt;10）后退出：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ cat test1.sh
    #!/bin/sh
    a=1
    until [ $a -gt 10 ]
    do
        echo $a
        a='expr $a + 1'
    done
    $ ./test1.sh
    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    $ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下例演示了如何通过until循环来进行重定向：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat test1.sh
    #!/bin/sh
    until ! read name age
    do 
       echo $name
       echo $age
    done<student.txt 18 19 20 $ . test1.sh zhangsan lisi liumi <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6.select菜单</span><br><span class="line"></span><br><span class="line">select使用PS3环境变量的值作为提示符，下例演示了如何使用select来实现类似菜单的功能，用户在年龄为“&lt;18”、“&lt;28”和&lt;“60”之间选择：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ cat test1.sh
    #!/bin/sh
    PS3="choice:"
    echo
    select age in "<18" 0 "<28" "<60" do echo "age is $age" break done exit $ . test1.sh 1) <18 2) <28 3) <60 choice:2 age <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">until的重定向示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ cat test1.sh
    #!/bin/sh
    until ! read name age
    do 
       echo $name
       echo $age
    done<student.txt 18 19 20 $ . test1.sh zhangsan lisi liumi <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">7.Shell函数</span><br><span class="line"></span><br><span class="line">下例定义了函数isodd，用于判断奇偶数：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ cat test1.sh
    #!/bin/sh
    isodd(){
      if [ $(($1%2)) -eq  1 ]
      then
         return 1
      else
         return 0
      fi
    }
    read mynum
    isodd $mynum
    myodd=$?
    if [  $myodd  -eq  1 ]
    then
       echo "$mynum is an odd number"
    else
       echo "$mynum is an  even number"
    fi
    $ ./test1.sh
    12
    12 is an  even number
    $ ./test1.sh
    33
    33 is an odd number <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 4.3 Vim编辑器</span><br><span class="line"></span><br><span class="line">#### 4.3.1 Vim编辑器概述</span><br><span class="line"></span><br><span class="line">Vim是从Vi发展出来的一个文本编辑器。代码补充、编译及错误跳转等便于编程的功能特别丰富，在程序员中被广泛使用。与Emacs并列成为类UNIX系统用户最喜欢的编辑器。Vim的操作模式很特别，它强大的编辑能力中有很大一部分是来自于模式和命令的组合。</span><br><span class="line"></span><br><span class="line">命令的组合是指通过一些非常简短的字符（包括英文、数字、符号等）组合成各种命令。比如：普通模式命令“dd”表示删除当前行，“dj”表示删除到下一行，原理是第一个“d”的含义是删除，“j”键表示移动到下一行，组合后“dj”表示删除当前行和下一行。另外还可以指定命令的重复次数，“2dd”（重复“dd”两次）和“dj”的效果是一样的。“d^”，其中“^”代表行首，故组合后的含义是删除从光标开始到行首间的内容（不包含光标）；“d$”，其中“$”代表行尾，删除从光标到行尾的内容（包含光标）；用户若学习了各种各样的文本间移动或跳转的命令和其他的普通模式的编辑命令，并且能够灵活地组合使用的话，那么就能够比那些没有模式的编辑器更加高效地进行文本编辑。</span><br><span class="line"></span><br><span class="line">模式的组合是指通过一些非常简短的英语字符就可转换进入各种模式。比如：在普通模式中，有很多方法可以进入插入模式。比较普通的方式是按“a”（append/追加）键或“i”（insert/插入）键。</span><br><span class="line"></span><br><span class="line">可通过下面的方式来启动Vim：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $vim <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">启动后，显示界面如图4-1所示。</span><br><span class="line"></span><br><span class="line">启动后可进行一些简单的操作。首先，可按i键进入插入模式，输入字符，如图4-2所示。</span><br><span class="line"></span><br><span class="line">然后，按Esc键退出插入模式，输入“:wq!hello”，并以“hello”为文件名，存盘退出。</span><br><span class="line"></span><br><span class="line">![](Image00051.jpg)</span><br><span class="line"></span><br><span class="line">图4-1 Vim界面</span><br><span class="line"></span><br><span class="line">最后，可通过cat命令显示文件内容，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat hello
    hello
    world! <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00052.jpg)</span><br><span class="line"></span><br><span class="line">图4-2 插入模式</span><br><span class="line"></span><br><span class="line">#### 4.3.2 Vim常用命令</span><br><span class="line"></span><br><span class="line">1.模式转换命令</span><br><span class="line"></span><br><span class="line">模式间切换的方法有如下三种情况。</span><br><span class="line"></span><br><span class="line">·其他模式转普通模式：Esc键。</span><br><span class="line"></span><br><span class="line">·普通模式转插入模式，如下列命令所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    i 在光标前插入

      I 在行首插入


    a 在光标后插入

        A 在行末插入


    o 在当前行之下新建行

      O 在当前行之上新建行


    r 替换当前字符

        R 从当前字符开始替换

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">·普通模式转命令模式：按“:”键。</span><br><span class="line"></span><br><span class="line">2.常用命令</span><br><span class="line"></span><br><span class="line">1）可以使用以下方式来移动光标：</span><br><span class="line"></span><br><span class="line">j向下 k向上</span><br><span class="line"></span><br><span class="line">l向右 h向左</span><br><span class="line"></span><br><span class="line">w下一个单词词首 W将特殊符号视为单词的一部分</span><br><span class="line"></span><br><span class="line">b上一个单词词首 B同上</span><br><span class="line"></span><br><span class="line">e单词末尾 E同上（忽略标点）</span><br><span class="line"></span><br><span class="line">0行首 ^行首文字（行首空格之后）</span><br><span class="line"></span><br><span class="line">$行末</span><br><span class="line"></span><br><span class="line">2）可用以下方式进行编辑：</span><br><span class="line"></span><br><span class="line">x剪切当前字符 dd剪切当前行</span><br><span class="line"></span><br><span class="line">y复制可视模式选取字符 yy复制当前行</span><br><span class="line"></span><br><span class="line">p在光标后粘贴 P在光标前粘贴</span><br><span class="line"></span><br><span class="line">u撤消 r字符所有字符替换为新字符</span><br><span class="line"></span><br><span class="line">u U~分别是所有字母变小写、变大写、反转大小写</span><br><span class="line"></span><br><span class="line">&gt;&lt;分别是缩进和反缩进 &lt;Ctrl+r&gt;重做</span><br><span class="line"></span><br><span class="line">&lt;Ctrl+y&gt;逐字克隆上一行内容 &lt;Ctrl+e&gt;逐字克隆下一行内容</span><br><span class="line"></span><br><span class="line">### 4.4 虚拟化平台</span><br><span class="line"></span><br><span class="line">维基百科将虚拟化（Virtualization）定义为：“虚拟化是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换，然后呈现出来，打破实体结构间的不可切割的障碍，使用户能以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部分是不受现有资源的架设方式、地域或物理组态所限制的，一般所指的虚拟化资源包括计算能力和数据存储。可以看到它始终如一的目标就是实现对IT资源的充分利用。”与多任务及超线程技术不同的是，虚拟化技术允许同时运行多个操作系统，而且每一个操作系统中都有多个程序在运行，每一个操作系统都运行在一个虚拟的CPU或是虚拟主机上。而超线程技术只是单CPU模拟双CPU来平衡程序运行性能，这两个模拟出来的CPU是不能分离的，只能协同工作；多任务则是指在一个操作系统中多个程序同时一起运行。</span><br><span class="line"></span><br><span class="line">1959年，克里斯托弗（Christopher Strachey）发表了一篇学术报告，名为“大型高速计算机中的时间共享”，他在文中提出了虚拟化的基本概念，这篇文章也被认为是虚拟化技术的最早论述。可以说虚拟化作为一个概念被正式提出就是从此时开始的。最早在商业系统上实现虚拟化的是IBM公司在1965年发布的IBM 7044，它允许用户在一台主机上运行多个操作系统，让用户尽可能充分地利用昂贵的大型机资源，之后IBM还开发了型号为Model 67的System/360主机，Model 67主机通过虚拟机监视器（Virtual Machine Monitor）虚拟所有的硬件接口。在早期的计算中，操作系统被称为Supervisor，能够运行在其他操作系统之上的操作系统被称为hypervisor，VMM直接运行在底层硬件上，允许执行多个虚拟机（VM），每一个VM运行自己的操作系统实例（CMS，Conversational Monitor System）。1999年，VMware在X86平台上推出了可以流畅运行的商业虚拟化软件，从此，虚拟化技术由大型机领域进入了PC服务器的世界。</span><br><span class="line"></span><br><span class="line">纵观虚拟化技术的发展，虚拟化技术的初衷就是为了实现更高的设备利用率，使用户能够尽可能多地利用系统资源，这样就能够在单个服务器上虚拟多个系统，然后以少数几台计算机来完成所有的工作，显然可以节省耗电、空间、冷却和管理的开支，此外，考虑到确定服务器利用状况的困难，虚拟化技术需要支持动态迁移（Live Migration），因为动态迁移允许将操作系统迁移到另一台全新的服务器上，从而减少当前主机的负载。展望虚拟化技术的未来，很可能将整个数据中心全面虚拟化，使用户能够获得一个随需应变的云数据平台。</span><br><span class="line"></span><br><span class="line">#### 4.4.1 Citrix Xenserver概述</span><br><span class="line"></span><br><span class="line">Citrix Xenserver是思杰基于Linux的虚拟化服务器。它是一种全面的、易于管理的服务器虚拟化平台，基于强大的Xen Hypervisor程序之上。Xen技术被广泛认为是业界最快速、最安全的虚拟化软件，而XenServer则是为了高效地管理Windows和Linux虚拟服务器而设计的，可提供经济高效的服务器整合，并能保证业务的连续性。</span><br><span class="line"></span><br><span class="line">XenServer可提供在云计算环境中经过验证的企业级虚拟化平台，可提供创建和管理虚拟基础架构所需的所有功能，深得很多要求苛刻的企业的信赖，被广泛用来运行最关键的应用，而且被最大规模的云计算环境和xSP所采用。</span><br><span class="line"></span><br><span class="line">XenServer分为免费版和Premium版，它们各自的特征如下：</span><br><span class="line"></span><br><span class="line">·免费版XenServer配备有64位系统管理程序和集中管理、实时迁移及转换工具，可创建一个虚拟化平台来最大限度地提高虚拟机的密度和性能。</span><br><span class="line"></span><br><span class="line">·Premium版XenServer对平台进行了更深层的扩展，可帮助任何规模的企业实现管理流程的集成和自动化，是一种先进的虚拟数据中心解决方案。</span><br><span class="line"></span><br><span class="line">XenServer可整合服务器工作负载，进而节约电源、冷却和管理成本，能更有效地适应不断变化的IT环境，优化利用现有的硬件设备并提高IT的可靠性，主要拥有以下优势：</span><br><span class="line"></span><br><span class="line">·将IT成本降低50%甚至更多。虽然服务器整合通常是实施服务器虚拟化的主要驱动因素，但企业可以获得更多的优势，而不仅仅只是服务器总数量的减少。XenServer虚拟化管理工具可以将服务器的要求降低10倍。数据中心内的服务器整合可以降低功耗和管理成本，同时还可以打造更绿色环保的IT环境。</span><br><span class="line"></span><br><span class="line">·提高IT灵活性。虚拟化使数据中心能够灵活地适应不断变化的IT要求。例如，XenServer可以创建出能够无缝集成现有存储环境的虚拟基础架构。这样就可以缩短IT部门满足用户需求所需的时间。</span><br><span class="line"></span><br><span class="line">·确保服务器性能。XenServer可以优化服务器工作负载的位置，提高性能和利用率，同时改进资源池内的服务器准备情况。这样便可确保始终能够达到应用的要求和预期的性能标准，帮助企业加快向生产环境中交付新应用的速度。</span><br><span class="line"></span><br><span class="line">·最大限度地减少服务器宕机。XenServer可以有效地减少计划内服务器宕机，减小故障的影响，预防灾难并搭建始终可用的虚拟基础架构。服务器和应用的升级可以在正常的工作时间内完成。这样就可以减小对用户生产率的影响，节约成本，使IT人员在晚上和周末都能正常休息。</span><br><span class="line"></span><br><span class="line">#### 4.4.2 Citrix Xenserver部署</span><br><span class="line"></span><br><span class="line">Citrix Xenserver与传统虚拟机类软件不同，它无需底层原生操作系统的支持，也就是说XenServer本身就具备了操作系统的功能，是能直接安装在服务器上引导启动并运行的，其稳定性较Hyper-V高，对Windows 2008 R2及Linux Server提供了良好的支持，此外，Citrix还提供了XenCenter工具，可通过图形化的控制界面，直观地管理和监控XenServer服务器的工作。例如：将一台性能强劲的服务器划分成多台服务器，让这些服务器同时运行以提供各种应用服务，节省硬件投资，也方便管理。假设公司只有一台Web服务器，因为公司业务发展，现在需要增加邮件服务、BBS客户服务，实际上无须购买三台物理服务器来分别实现上述功能，而只须使用XenServer在一台物理服务器上创建三台虚拟的服务器，运行各自的操作系统和应用服务，某台虚拟服务器的宕机也不会影响到其他虚拟服务器。</span><br><span class="line"></span><br><span class="line">XenServer的部署很简单，安装界面人性化且有详细的提示，前提是：安装XenServer的PC服务器没有安装任何操作系统，且拥有至少一块网卡。下载XenServer的安装ISO文件，刻录成光盘插入服务器的光驱后，启动服务器即可安装。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 XenServer官网地址为：&lt;http://www.citrix.com/products/xenserver/&gt;</span><br><span class="line"></span><br><span class="line">XenServerg下载地址为：&lt;http://downloadns.citrix.com.edgesuite.net/7281/XenServer-6.2.0-install-cd.iso&gt;</span><br><span class="line"></span><br><span class="line">XenServer官方安装文档可以从如下网址下载：&lt;http://www.citrix.com/content/dam/citrix/en_us/documents/products-solutions/citrix-xenserver-quick-installation-and-licensing-guide.pdf&gt;</span><br><span class="line"></span><br><span class="line">#### 4.4.3 基于XenCenter的虚拟服务器管理</span><br><span class="line"></span><br><span class="line">XenServer可通过客户机安装管理工具XenCenter进行管理。XenCenter采用基于图形用户界面的管理控制台，该控制台可安装在任何Windows PC或服务器上。XenServer安装完毕后，直接使用浏览器访问XenServer的IP地址，下载XenCenter并安装。也可在XenServer的安装光盘或ISO文件内找到XenCenter的安装程序，双击执行文件XenCenter.msi后，按提示一步步安装即可，如图4-3和图4-4所示。</span><br><span class="line"></span><br><span class="line">![](Image00053.jpg)</span><br><span class="line"></span><br><span class="line">图4-3 XenCenter安装包</span><br><span class="line"></span><br><span class="line">![](Image00054.jpg)</span><br><span class="line"></span><br><span class="line">图4-4 XenCenter安装程序</span><br><span class="line"></span><br><span class="line">安装完XenCenter后启动，其界面如图4-5所示。</span><br><span class="line"></span><br><span class="line">在XenCenter处点击鼠标右键，选择Add或点击上方工具条中的Add New Server按钮增加一台XenServer服务器，输入服务器IP和root账户密码。如图4-6所示。</span><br><span class="line"></span><br><span class="line">![](Image00055.jpg)</span><br><span class="line"></span><br><span class="line">图4-5 XenCenter界面</span><br><span class="line"></span><br><span class="line">![](Image00056.jpg)</span><br><span class="line"></span><br><span class="line">图4-6 增加一台XenServer服务器</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 一台XenServer服务器即一台物理服务器，而不是指虚拟服务器，XenCenter可同时管理多台XenServer服务器及运行在XenServer服务器上的虚拟服务器。</span><br><span class="line"></span><br><span class="line">当XenCenter成功连接服务器后，可看到服务器的信息，如图4-7所示，在此XenServer服务器上一共建立了三台虚拟服务器，服务器前面的小图标表示服务器当前的状态，其中ddb-template服务器正在运行中，另外两台服务器处于关机状态。</span><br><span class="line"></span><br><span class="line">![](Image00057.jpg)</span><br><span class="line"></span><br><span class="line">图4-7 服务器的信息</span><br><span class="line"></span><br><span class="line">选择某台虚拟服务器，点击鼠标右键，将出现管理菜单，可对虚拟服务器进行管理，比如重启、关机等，如图4-8、图4-9所示。</span><br><span class="line"></span><br><span class="line">![](Image00058.jpg)</span><br><span class="line"></span><br><span class="line">图4-8 对虚拟服务器进行启动、拷贝、创建快照等操作</span><br><span class="line"></span><br><span class="line">![](Image00059.jpg)</span><br><span class="line"></span><br><span class="line">图4-9 对虚拟服务器进行重启、关机等操作</span><br><span class="line"></span><br><span class="line">选择某台虚拟服务器后，点击Console选项卡，可查看当前虚拟服务器的运行情况，如图4-10所示。</span><br><span class="line"></span><br><span class="line">![](Image00060.jpg)</span><br><span class="line"></span><br><span class="line">图4-10 虚拟服务器的运行情况</span><br><span class="line"></span><br><span class="line">虚拟服务器的创建很简单，只须点击上方工具条的New VM按钮即可，如图4-11至图4-19所示。创建完虚拟服务器后，将操作系统的安装光盘放入XenServer服务器的光驱，即可继续在该虚拟服务器上安装操作系统。</span><br><span class="line"></span><br><span class="line">![](Image00061.jpg)</span><br><span class="line"></span><br><span class="line">图4-11 选择虚拟机模板，可不选择已有模板</span><br><span class="line"></span><br><span class="line">![](Image00062.jpg)</span><br><span class="line"></span><br><span class="line">图4-12 虚拟服务器命名</span><br><span class="line"></span><br><span class="line">![](Image00063.jpg)</span><br><span class="line"></span><br><span class="line">图4-13 选择系统安装光盘的位置</span><br><span class="line"></span><br><span class="line">![](Image00064.jpg)</span><br><span class="line"></span><br><span class="line">图4-14 选择虚拟服务器空间占有的物理硬盘</span><br><span class="line"></span><br><span class="line">![](Image00065.jpg)</span><br><span class="line"></span><br><span class="line">图4-15 选择虚拟服务器需要使用的CPU和内存数量</span><br><span class="line"></span><br><span class="line">![](Image00066.jpg)</span><br><span class="line"></span><br><span class="line">图4-16 为虚拟服务器分配硬盘空间</span><br><span class="line"></span><br><span class="line">![](Image00067.jpg)</span><br><span class="line"></span><br><span class="line">图4-17 硬盘空间分配完毕，可继续分配</span><br><span class="line"></span><br><span class="line">![](Image00068.jpg)</span><br><span class="line"></span><br><span class="line">图4-18 选择虚拟服务器使用的物理网卡</span><br><span class="line"></span><br><span class="line">![](Image00069.jpg)</span><br><span class="line"></span><br><span class="line">图4-19 创建成功后的虚拟服务器centos7</span><br><span class="line"></span><br><span class="line">### 4.5 Linux环境下的NumPy安装</span><br><span class="line"></span><br><span class="line">NumPy（Numeric Python）是用Python实现的一个科学计算包，提供了许多高级的数值编程工具，如：矩阵数据类型、矢量处理，以及精密的运算库。下面以CentOS为例，讲解NumPy在Linux下的安装，安装过程如下所示。</span><br><span class="line"></span><br><span class="line">1）下载NumPy，网址为：&lt;http://www.scipy.org/scipylib/download.html&gt; 。</span><br><span class="line"></span><br><span class="line">2）系统更新：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [myhaspl@localhost ~]$ su <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">密码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [root@localhost myhaspl]# yum install update <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）安装相关工具：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [root@localhost myhaspl]# yum install wget
    [root@localhost myhaspl]# yum install unzip
    [root@localhost myhaspl]# yum install gcc
    [root@localhost numpy-1.9.0]# yum install python-devel <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4）下载NumPy源码并解压：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [root@localhost myhaspl]# wget 
    <http: jaist.dl.sourceforge.net project numpy 1.9.0 numpy-1.9.0.zip>

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5）安装NumPy：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [root@localhost myhaspl]# unzip numpy-1.9.0.zip
    [root@localhost myhaspl]# cd numpy-1.9.0
    [root@localhost numpy-1.9.0]# python setup.py install <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6）安装完毕后重启：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [root@localhost numpy-1.9.0]# reboot <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">7）测试安装是否成功，如果能导入NumPy库，则表示安装成功：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [myhaspl@localhost ~]$ python
    Python 2.7.5 (default, Jun 17 2014, 18:11:42) 
    [GCC 4.8.2 20140120 (Red Hat 4.8.2-16)] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import numpy as np
    >>> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 4.6 Linux环境下的R运行环境</span><br><span class="line"></span><br><span class="line">R语言是一套完整的数据处理、计算和制图软件系统，主要用于统计分析。以CentOS为例，可依次输入以下命令，安装R运行环境：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # yum install gcc-gfortran
    # yum install gcc gcc-c++
    # yum install readline-devel
    # yum install libXt-devel
    # wget <http: mirror.bjtu.edu.cn cran src base r-3 r-3.1.1.tar.gz>


    # tar zxvf R-3.1.1.tar.gz
    #cd R-3.1.1
    #./configure
    #make
    #make install
    #make check
    #ln -s /home/myhaspl/R-3.1.1/bin/R /usr/local/bin/R
    $R <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 4.7 PyPy编译器</span><br><span class="line"></span><br><span class="line">#### 4.7.1 PyPy概述</span><br><span class="line"></span><br><span class="line">CPython是用C语言实现的Python解释器，也是官方的并且是最广泛使用的Python解释器。但它并不是唯一的选择，它使用字节码的解释器，任何的程序源代码在执行之前都要先编译成字节码，这样必然会影响到Python程序的执行效率。此外，CPython还存在一个问题，在多处理器的计算机上使用CPython要受GIL（Global Interpreter Lock）的约束，GIL使得CPython不能进行并发编程，要做到并发编程，就必须为每一个线程运行一个解释器，但是它们之间的通信就会非常困难。</span><br><span class="line"></span><br><span class="line">PyPy是Python开发者为了更好地Hack Python而创建的项目，它比CPython更加灵活、更容易实施。PyPy支持Python语言的所有核心部分及大多数的Python语言标准库函数模块，并且通过了Python语言的test suite。更为重要的是PyPy实现了动态编译，提供了JIT编译器和沙盒功能，运行速度比CPython要快很多，还可以安全地运行一些不被信任的代码，此外，PyPy还有支持微线程的版本。目前PyPy的最新版本主要拥有以下特征：</span><br><span class="line"></span><br><span class="line">·更快的速度。在JIT（Just-in-Time）编译器的帮助下，Python程序能在PyPy下跑得更快。</span><br><span class="line"></span><br><span class="line">·更高的内存使用效率。相对CPython来说，PyPy能更有效地利用内存，尤其是几百兆或更多的内存。</span><br><span class="line"></span><br><span class="line">·兼容性。PyPy对现有的Python程序有更好的兼容性，它不仅支持cffi，还能运行流行的Python库，比如Twisted、Django等。</span><br><span class="line"></span><br><span class="line">·沙盒。PyPy可以安全地运行一些不被信任的代码。</span><br><span class="line"></span><br><span class="line">·Stackless。PyPy原生支持Stackless模式，提供了真正的多线程并发。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 关于PyPy的更多资料可以在官网&lt;http://www.pypy.org/&gt; 中查看。</span><br><span class="line"></span><br><span class="line">#### 4.7.2 PyPy安装与配置</span><br><span class="line"></span><br><span class="line">下面以64位centos7（最小化安装）为例，讲解如何安装和配置PyPy。</span><br><span class="line"></span><br><span class="line">首先，依次输入以下命令，下载并编译PyPy：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # yum install gcc
    # yum install wget
    # wget <https: bitbucket.org pypy downloads pypy-2.3.1-src.tar.bz2>


    # tar jxvf pypy-2.3.1-src.tar.bz2
    # yum install libffi-devel
    # yum install expat-devel
    # yum install ncurses-devel
    # yum install bzip2-devel
    # yum install openssl-devel
    [root@localhost myhaspl]# cd pypy-2.3.1-src/pypy/goal
    # python ../../rpython/bin/rpython -Ojit targetpypystandalone <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，安装适用于PyPy的numpy包：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # git clone <https: bitbucket.org pypy numpy.git>


    # cd numpy
    # pypy setup.py install <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后，为方便PyPy的调用，可以使用ln命令建立软链接，ln是Linux中一个非常重要的命令，它的功能是为某一个文件在另外一个位置建立一个不同的链接，具体用法如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ln –

    s 源文件

     目标文件

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 4.7.3 PyPy性能</span><br><span class="line"></span><br><span class="line">PyPy执行Python程序的速度比CPython要快很多。下面以除法与累加混合计算为例，验证PyPy的效率。测试用Python程序如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    import  time
    start=time.clock()
    sum=0
    i=1.0
    while (i<10000000): sum+="i/2.22" i="i+1" print "sum:%f"%sum end="time.clock()" "seconds:%f"%( end-start) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分别用CPython和PyPy运行上面的程序，结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ python pythontest.py
    sum:22522520270270.273438
    seconds:4.090000
    $ ./pypy  pythontest.py
    sum:22522520270270.273438
    seconds:0.256000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从上面的程序运行效果来看，PyPy计算只用了0.256000秒，而CPython则花了4.090000秒，PyPy对运行效率的提升是数量级的，也是显而易见的。</span><br><span class="line"></span><br><span class="line">#### 4.7.4 PyPy实践之Lempel-Ziv压缩</span><br><span class="line"></span><br><span class="line">Lempel-Ziv算法采用动态无损数据压缩算法对字符串进行动态编码和解码，以达到压缩和解压文本的目的。Lempel-Ziv算法基于在正文流中很可能会出现词汇和短语重复的情况而开发的，当出现一个重复时，将重复的序列用一个短的编码来代替，压缩程序扫描这样的重复，同时生成编码来代替重复序列，随着时间的推移，编码可以重用来捕获新的序列，此外，Lempel-Ziv算法设计成解压程序能够以编码和原始数据序列推导出当前的映射。</span><br><span class="line"></span><br><span class="line">Lempel-Ziv算法的关键在于查找重复的序列，当碰到一个重复时，算法继续扫描直到该重复序列终止为止。以下面这段文本为例对Lempel-Ziv编码进行讲解，假设需要压缩的文本如下：</span><br><span class="line"></span><br><span class="line">abaaaabaabaaabbbbbbbabbbbbbbabbbbbaababaababa…</span><br><span class="line"></span><br><span class="line">应用Lempel-Ziv算法逐步对上述文本进行编码：</span><br><span class="line"></span><br><span class="line">1）建立一个码表空字典DICT。</span><br><span class="line"></span><br><span class="line">2）读入第1个字符“a”，DICT中无“a”字符，且为空，因此将“a”增加到DICT中，索引为1，编码为“0a”。最终编码结果为：“0a”。</span><br><span class="line"></span><br><span class="line">3）读入第2个字符“b”，DICT中无“b”字符，因此将“b”增加到DICT中，索引为2，编码为“0b”。最终编码结果为：“0a0b”。</span><br><span class="line"></span><br><span class="line">4）读入第3个字符“a”，DICT中有“a”字符且索引为1，此时，将紧跟其后的第4个字符“a”与第3个字符“a”合并成一个码段“aa”，编码为“1a”，然后将“aa”增加到DICT中，索引为3。最终编码结果为：“0a0b1a”。</span><br><span class="line"></span><br><span class="line">5）第4步已经处理过第4个字符了，因此从第5个字符开始，读入第5个字符“a”和第6个字符“a”，DICT中有“aa”字符且索引为3，此时，将紧跟其后的第7个字符“b”与第5、6个字符组成的串“aa”合并成一个码段“aab”，编码为“3b”，然后将“aab”增加到DICT中，索引为4。最终编码结果为：“0a0b1a3b”。</span><br><span class="line"></span><br><span class="line">接下来，按类似的方法继续处理，直到读取完毕所有需要压缩的字符才结束，最终形成表4-1所示的编码结果。</span><br><span class="line"></span><br><span class="line">表4-1 Lempel-Ziv算法编码</span><br><span class="line"></span><br><span class="line">![](Image00070.jpg)</span><br><span class="line"></span><br><span class="line">下面用Python来实现Lempel-Ziv压缩算法，程序如下所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #lempel-ziv算法


    #code:myhaspl@myhaspl.com
    #4-1.py
    #待压缩字符串


    my_str="""Ubuntu 14.04 LTS includes a wealth of smart filters to make it faster and easier to find the content you need, whether it’

    s stored on your computer or on the web.Type any query into the Dash home and the Smart Scopes server will determine which categories of content are the most relevant to your search, returning only the best results. The server constantly improves its results by learning which categories and results are most useful to you over time."""
    #码表


    codeword_dictionary={}
    #待压缩文本长度


    str_len=len(my_str)
    #码字最大长度


    dict_maxlen=1
    #将解析文本段的位置（下一次解析文本的起点）


    now_index=0
    #码表的最大索引


    max_index=0
    #
    compressed_str=""
    while (now_index<str_len): #向后移动步长 mystep="0" #当前匹配长度 now_len="dict_maxlen" if>str_len-now_index:
            now_len=str_len-now_index
        #查找到的码表索引，

    0表示没有找到


        cw_addr=0   
        while (now_len>0):
            cw_index=codeword_dictionary.get(my_str[now_index:now_index+now_len])
            if cw_index!=None:
                #找到码字


                cw_addr=cw_index
                mystep=now_len  
                break
            now_len-=1    
        if cw_addr==0:
            #没有找到码字

    ,增加新的码字


            max_index+=1
            mystep=1
            codeword_dictionary[my_str[now_index:now_index+mystep]]=max_index
            print "don't find the Code word,add Code word:%s index:%d"%(my_str[now_index:now_index+mystep],max_index)
        else:
            #找到码字

    ,增加新的码字


            max_index+=1    
            codeword_dictionary[my_str[now_index:now_index+mystep+1]]=max_index
            if mystep+1>dict_maxlen:
                dict_maxlen=mystep+1      
            print "find the Code word:%s  add Code word:%s index:%d"%(my_str[now_index:now_index+now_len],my_str[now_index:now_index+mystep+1],max_index)
        #计算压缩后的结果


        cwdindex='%d'%cw_addr
        if cw_addr==0:
            cwlater=my_str[now_index:now_index+1] 
            now_index+=1
        else:
            now_index+=mystep     
            cwlater=my_str[now_index:now_index+1] 
            now_index+=1
        cw=cwdindex+cwlater
        compressed_str+=cw
    print "\n------------------------------------\n"     
    print my_str
    print "\n************************************\n"
    print compressed_str
    print "\n------------------------------------\n" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">现在用以上程序将下面的文本进行压缩：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    Ubuntu 14.04 LTS includes a wealth of smart filters to make it faster and easier to find the content you need, whether it’

    s stored on your computer or on the web.Type any query into the Dash home and the Smart Scopes server will determine which categories of content are the most relevant to your search, returning only the best results. The server constantly improves its results by learning which categories and results are most useful to you over time. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">压缩结果为：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    0U0b0u0n0t3 01040.008 0L0T0S0 0i4c0l3d0e0s15a15w20a18t0h15o0f15s0m0a0r5 28i25e32s15t0o15m31k20 16t15f31s5e32 31n0d15e44i20r37o43i4d37h41c38n45n33y38u15n20e48,
    23h20t26e46i501 21t38r20d27n15y60r15c38m0p3t51 73 57 5h41w20b9T0y80e22n89 0q3e32y15i4t38 85e15D44h15h79e91d55e15S30a32t106c38p20s29e32v82w16l18 48e45r30i4e64i0c26 122a45g73i111 38f78o97e97 31r41t66 30o72 32e18e0v47t52 89o3r112a32c26,15r65u32n16n0g75l92t134b111t147e21u25s9 13h41s51v82c57s5a97l92i30p32o139e71i5s156s3l172 2y15l24r4i4g121c123c31t20g126e71a54 137s174t186r41m38s33u21e28u116t98y60 38v82t16m20. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面使用PyPy运行程序4-1.py，将程序依次读入文本，扩充码表字典，最终输出压缩结果，如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $pypy  4-1.py
    don't find the Code word,add Code word:U index:1
    don't find the Code word,add Code word:b index:2
    don't find the Code word,add Code word:u index:3
    don't find the Code word,add Code word:n index:4
    don't find the Code word,add Code word:t index:5
    find the Code word:u  add Code word:u  index:6
    don't find the Code word,add Code word:1 index:7
    don't find the Code word,add Code word:4 index:8
    don't find the Code word,add Code word:. index:9…

    …


    137s174t186r41m38s33u21e28u116t98y60 38v82t16m20. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序4-1.py在压缩时生成了码表，这就带来了一个问题：码表字典文件会很大，而每个压缩文件都要将码表附带上，这样就无法达到压缩文件尺寸的作用。实际上Lempel-Ziv算法在压缩文件中并不需要存放码表，可在解压时自动生成码表，此外，同时还可根据被压缩文件的大小确定索引是整型、长整型还是字节型，这样就可动态地调整在压缩文件中索引所占有的空间，保证了压缩率。下面用Python实现对文本文件进行Lempel-Ziv压缩与解压缩，程序如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #lempel-ziv压缩与解压缩文件


    #code:myhaspl@myhaspl.com
    #4-2.py
    import struct
    import sys
    txtfilename=sys.argv[1]
    compressfn=sys.argv[2]
    mystr=""
    print "\n读取源文件

    ".decode("utf8")
    mytextfile= open(txtfilename,'r')
    try:
         mystr=mytextfile.read( )
    finally:
         mytextfile.close()
    my_str=mystr
    #码表


    codeword_dictionary={}
    #待压缩文本长度


    str_len=len(my_str)
    #码字最大长度


    dict_maxlen=1
    #将解析文本段的位置（下一次解析文本的起点）


    now_index=0
    #码表的最大索引


    max_index=0
    #压缩后的数据


    print "\n生成压缩数据中

    ".decode("utf8") 
    compresseddata=[]
    while (now_index<str_len): #向后移动步长 mystep="0" #当前匹配长度 now_len="dict_maxlen" if>str_len-now_index:
            now_len=str_len-now_index
        #查找到的码表索引，

    0表示没有找到


        cw_addr=0   
        while (now_len>0):
            cw_index=codeword_dictionary.get(my_str[now_index:now_index+now_len])
            if cw_index!=None:
                #找到码字


                cw_addr=cw_index
                mystep=now_len  
                break
            now_len-=1    
        if cw_addr==0:
            #没有找到码字

    ,增加新的码字


            max_index+=1
            mystep=1
            codeword_dictionary[my_str[now_index:now_index+mystep]]=max_index
            print "don't find the Code word,add Code word:%s index:%d"%(my_str[now_index:now_index+mystep],max_index)
        else:
            #找到码字

    ,增加新的码字


            if now_index+mystep+1<str_len: #如果文件尾部正好是字典中的码字，后面再无内容时，这部分将不会被执行 max_index+="1" codeword_dictionary[my_str[now_index:now_index+mystep+1]]="max_index" if mystep+1>dict_maxlen:
                    dict_maxlen=mystep+1      
                print "find the Code word:%s  add Code word:%s index:%d"%(my_str[now_index:now_index+now_len],my_str[now_index:now_index+mystep+1],max_index)  
        #压缩后的结果


        cwdindex=cw_addr
        if cwdindex==0:
            cwlater=my_str[now_index:now_index+1] 
            now_index+=1
        else:
            now_index+=mystep     
            if now_index>=str_len:
            #文件已经读取完毕，后面无内容


               cwlater=""          
            else:
               cwlater=my_str[now_index:now_index+1] 
            now_index+=1        
        cw=(cwdindex,cwlater)
        compresseddata.append(cw)
    print "\n生成压缩数据头部

    ".decode("utf8")  
    #生成数据压缩大小格式

    ,65535为

    H能容纳的最大数据


    if len(codeword_dictionary)<=65535: flag_fmt="H" flag_len="2" else: #压缩数据写入文件 print "\n将压缩数据写入压缩文件中 ".decode("utf8"), lzv_file="open(compressfn,'wb')" try: #写入压缩数据的头部信息 #压缩数据长度 lzv_len="len(compresseddata)" lzv_file.write(struct.pack('i',lzv_len)) #数据解码大小格式： lzv_file.write(struct.pack('1s1s',flag_fmt,flag_len)) #写入压缩数据 for temp_data in compresseddata: temp_key,temp_later="temp_data" temp_wdata="struct.pack(FLAG_FMT+'1s',temp_key,temp_later)" lzv_file.write(temp_wdata) ".", finally: lzv_file.close() #解压缩数据 "\n读入压缩数据中 my_compresseddata="[]" my_codeword_dictionary="{}" #读入压缩数据的长度 lzv_len,="struct.unpack(" i",lzv_file.read(4))" #读入数据解码大小格式 my_flag_fmt,my_flag_len="struct.unpack('1s1s',lzv_file.read(2))" #读入压缩数据 tmp_count="1" while tmp_count<="lzv_len:" my_compresseddata.append((temp_key,temp_later)) tmp_count+="1" "\n读入压缩数据成功 ".decode("utf8") lzv_file.close( ) "\n解压中 #解压缩 uncompress_str #解码后的数据 uncompressdata="[]" my_maxindex="0" #解码，同时重构码表 (cwkey,cwlaster) my_compresseddata: if cwkey="=0:" my_maxindex+="1" my_codeword_dictionary[my_maxindex]="cwlaster" uncompressdata.append(cwlaster) uncompressdata.append(my_codeword_dictionary[cwkey]) cwlaster!="\0" : uncompressstr="uncompress_str" "\n将解压结果写入文件中 ..\n".decode("utf8") uncompress_file="open('uncompress.txt','w')" uncompress_file.write(uncompressstr) "\n解压成功，已解压到 uncompress.txt！ \n".decode("utf8") uncompress_file.close() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面以图4-20所示的文本为例进行压缩和解压缩操作。</span><br><span class="line"></span><br><span class="line">![](Image00071.jpg)</span><br><span class="line"></span><br><span class="line">图4-20 python.txt内容</span><br><span class="line"></span><br><span class="line">首先，调用PyPy运行4-2.py，该程序先进行压缩形成压缩文件，再打开压缩文件解压将文件还原为uncompress.txt。运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    $ pypy 4-2.py python.txt python.lzv………………

    ..
    find the Code word: C  add Code word: CP index:9938
     index:9939de word:ython  add Code word:ython
    find the Code word:
    ^   add Code word:
    ^ h index:9940
    find the Code word:ttp  add Code word:ttp: index:9941
    find the Code word://  add Code word://e index:9942
    find the Code word:dit  add Code word:ditr index:9943
    find the Code word:a.  add Code word:a.o index:9944生成压缩数据头部

    将压缩数据写入压缩文件中

    …………

    将解压结果写入文件中

    解压成功，已解压到

    uncompress.txt！

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，查看一下解压缩效果，可见解压缩成功，结果如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ cat uncompress.txt <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">Python（英国发音：![](Image00072.jpg) ；美国发音：![](Image00073.jpg)</span><br><span class="line">）是一种面向对象、直译式计算机编程语言，具有近二十年的发展历史，成熟且稳定。它包含了一组完善而且容易理解的标准库，能够轻松完成很多常见的任务。它的语法简洁和清晰，尽量使用无异义的英语单词，与其他大多数程序设计语言使用大括号不一样，它使用缩进来定义语句块。</span><br><span class="line"></span><br><span class="line">最后，运行ls命令查看算法压缩效果，结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls -l -h……………

    .
    -rw-rw-r--1 deep deep 5.0K Jul  1 20:55 5-2.py
    -rw-rw-r--1 deep deep  30K Jul  1 20:55 python.lzv
    -rw-rw-r--1 deep deep  36K Jul  1 20:57 python.txt
    -rw-rw-r--1 deep deep  36K Jul  1 20:55 uncompress.txt <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从上面显示的结果可以看到，未压缩前为36KB，压缩后为30KB，压缩效果不太明显，Lempel-Ziv算法对于大的文件压缩效果更好，以sqlite 3.8.5的全部源码为例，对它进行压缩，调用PyPy再次运行4-2.py程序：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ pypy 4-2.py sqlitesrc.txt sqlitesrc.lzv <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行完毕后，查看压缩效果，结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    $ ls -l -h……………

    .
    -rw-rw-r--1 deep deep 3.2M Jul  1 21:18 sqlitesrc.lzv
    -rw-rw-r--1 deep deep 5.2M Jul  1 21:16 sqlitesrc.txt
    -rw-rw-r--1 deep deep 5.2M Jul  1 21:18 uncompress.txt没压缩前为

    5.2M，压缩后为

    3.2M，压缩效果较明显。

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 4.8 小结</span><br><span class="line"></span><br><span class="line">目前，机器学习主要依靠算法来实现，而算法依靠程序来实现，程序在调试完毕后，就需要投入到实际运行阶段，当人们创造性地将“生产环境”一词拓展到软件工程领域后，软件运行平台的定义就变得严谨、可靠和安全，它特指软件调试完毕并正式启用后实际运行的环境。软件生产环境中最常用的是Windows Server和Linux/UNIX两种。本章首先分别介绍了这两种生产环境下的基本命令、Shell脚本及各自的特性，然后重点介绍了虚拟化平台的搭建与管理，最后讲解了Linux环境下Vim编辑器的使用及相关软件工具的配置。值得一提的是，本章结尾讲述了PyPy编译器，PyPy实现了动态编译，提供了JIT编译器和沙盒功能，运行速度比CPython要快很多，还可以安全地运行一些不被信任的代码，对于Python程序来说，是一个很不错的运行平台。</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">在家中找一台闲置不用的PC，将硬盘格式化，然后下载Citrix Xenserver免费版和Windows Server 2008 R2免费试用180天版，将本章内容亲自实践一次，按以下步骤进行操作：</span><br><span class="line"></span><br><span class="line">（1）安装和配置好Citrix Xenserver与XenCenter。</span><br><span class="line"></span><br><span class="line">（2）建立至少两台虚拟服务器，一台用于安装Windows Server 2008 R2，一台用于安装Citrix Xenserver。</span><br><span class="line"></span><br><span class="line">（3）在其中一台虚拟服务器中安装CentOS系统。</span><br><span class="line"></span><br><span class="line">（4）在CentOS系统中安装好R、PyPy、NumPy等工具软件包，安装完毕后，测试一下各软件包是否能正常运行相关的程序。</span><br><span class="line"></span><br><span class="line">（5）在CentOS系统中编写各种Linux命令和Shell脚本进行测试和学习。</span><br><span class="line"></span><br><span class="line">（6）在CentOS系统中打开Vim编辑器，编辑以下文件内容，并存盘为R.txt。</span><br><span class="line"></span><br><span class="line">R is a language and environment for statistical computing and graphics.It is a GNU project which is similar to the S language and environment which was developed at Bell Laboratories(formerly AT&amp;T，now Lucent Technologies)by John Chambers and colleagues.R can be considered as a different implementation of S.There are some important differences，but much code written for S runs unaltered under R.</span><br><span class="line"></span><br><span class="line">R provides a wide variety of statistical(linear and nonlinear modelling，classical statistical tests，time-series analysis，classification，clustering，...)and graphical techniques，and is highly extensible.The S language is often the vehicle of choice for research in statistical methodology，and R provides an Open Source route to participation in that activity.</span><br><span class="line"></span><br><span class="line">（7）在另一台虚拟服务器中安装Windows Server 2008 R2。</span><br><span class="line"></span><br><span class="line">（8）在Windows Server 2008 R2中运行Windows PowerShell脚本，并配置好R、Pypy、Python、NumPy等工具软件包，并测试各软件包是否能正常运行相关的程序。</span><br><span class="line"></span><br><span class="line"># 第三部分 统计分析实战篇</span><br><span class="line"></span><br><span class="line">在终极的分析中，一切知识都是历史；在抽象的意义下，一切科学都是数学；在理性的基础上，所有的判断都是统计。</span><br><span class="line"></span><br><span class="line">——C.R.劳</span><br><span class="line"></span><br><span class="line">## 第5章 统计分析基础</span><br><span class="line"></span><br><span class="line">统计学用于研究对象的数量性、总体性、变异性，具体说来，就是通过各种统计指标和指标体系来反映对象总体的规模、水平、速度、比例、效益、差异和趋势等。海量数据分析需要一个科学的理论基础，统计学是理论基础之一，统计分析方法也是主要的数据分析方法。</span><br><span class="line"></span><br><span class="line">机器学习涉及许多统计分析理论。机器学习应用的统计分析强调实际应用效果，检测损失函数即描述预测与实际之间的偏差；数据分析领域也以统计学为基础，统计学善于对数据建立模型，并对模型做出假设。由此可见，无论是在机器学习方面还是数据分析领域，统计分析理论都有着举足轻重的地位。</span><br><span class="line"></span><br><span class="line">本章将以R语言为统计分析计算工具讲述统计分析基础，在此之前，请各位读者按照第一部分准备篇中的指导，将R语言计算平台搭建好。</span><br><span class="line"></span><br><span class="line">### 5.1 数据分析概述</span><br><span class="line"></span><br><span class="line">随着数据分析技术的不断发展，数据分析的定义众说纷纭。作者尝试将数据分析定义为：“数据分析是将数据转化成知识，对数据加以详细的研究和概括总结的过程，它用适当的统计方法对收集来的大量数据进行分析，发现数据的价值，挖掘数据的表征的知识。”</span><br><span class="line"></span><br><span class="line">在第二次世界大战中，数据分析第一次登上世界舞台。在Budiansky、Stephen所著的《Blackett’s War》中，讲述了一个由数学家、物理学家组成的团体，通过对数据进行收集和分析，使用数据引导战争的故事。该团队运用数据分析技术对付纳粹潜艇舰队，并把原始雷达系统收集的数据与实际战争结合起来分析，从而使海岸司令部的飞机拥有恰当的飞行路线，实现最高效的监视。同时他们还证明了一个论断：在一个15~24艘船的舰队中，每艘船有2.3%被击沉的概率；而在舰队船数高于45时，被击沉的概率只有1.1%。</span><br><span class="line"></span><br><span class="line">随着社会的发展，数据库已经深入到各行各业，成为了社会信息记录的重要载体。为了解决数据的查询问题，在数据库发展的早期，SQL语言诞生并迅速发展，目前它仍然活跃在数据库领域。近年来，“大数据”一词被炒得很热，大数据已被用于承载数据相关的绝大部分概念，包括：数据海洋、社交媒体分析、下一代数据管理能力、实时数据等。各大公司已经开始理解并实践探索如何处理并分析大量信息。</span><br><span class="line"></span><br><span class="line">无限风光在险峰，只有登上山顶，才能看到真正的风光，既然如此，那我们就开始攀登数据分析这座“大山”吧！</span><br><span class="line"></span><br><span class="line">### 5.2 数学基础</span><br><span class="line"></span><br><span class="line">统计分析建立在概率与统计的数学基础之上，在此，先简要介绍一下相关数学公式。</span><br><span class="line"></span><br><span class="line">1.概率</span><br><span class="line"></span><br><span class="line">概率是数学概率论的基本概念。设随机事件的样本空间为Ω，对于Ω中的每一个事件A，都有实函数P(A)，满足：</span><br><span class="line"></span><br><span class="line">非负性：P(A)≥0</span><br><span class="line"></span><br><span class="line">规范性：P(Ω)=1</span><br><span class="line"></span><br><span class="line">可加性：对n个两两互斥事件A1，…，An有：![](Image00074.jpg)</span><br><span class="line"></span><br><span class="line">任意一个满足上述条件的函数P都可以作为样本空间Ω的概率函数，称函数值P(A)为Ω中事件A的概率。</span><br><span class="line"></span><br><span class="line">上面的定义严谨但不易理解，通俗来说，概率是一个0到1之间的实数，是对随机事件发生的可能性的度量。人们有时候会问：“明天会更冷吗？”、“今天的比赛我们会赢得冠军吗？”等，他们是在关注“天气变冷”、“比赛取胜”等事件发生的机会。在数学上，这些事件发生的机会可用一个数来表示，称为概率。概率的主要公式如下。</span><br><span class="line"></span><br><span class="line">设事件A发生的概率（可能性）为P(A)，它不发生的概率（可能性）为P(A)，它们之间的关系为：</span><br><span class="line"></span><br><span class="line">![](Image00075.jpg)</span><br><span class="line"></span><br><span class="line">n个事件A1 ，…，An 发生的概率为：</span><br><span class="line"></span><br><span class="line">![](Image00076.jpg)</span><br><span class="line"></span><br><span class="line">条件概率是事件A在另外一个事件B已经发生条件下的发生概率。条件概率记为P（A|B），读作“在B条件下A的概率”。比如，“如果明天更冷，需要多穿一件外套吗？”可用条件概率描述为：假设明天天气更冷为事件B，多穿一件外套为事件A，在事件B（天气更冷）发生的情况下，事件A（多穿外套）发生的概率为多少。下面是条件概率的数学定义。</span><br><span class="line"></span><br><span class="line">在同一个样本空间Ω中的事件或者子集A与B，如果随机从Ω中选出的一个元素属于B，那么这个随机选择的元素还属于A的概率就定义为在B的前提下A的条件概率。定义为：</span><br><span class="line"></span><br><span class="line">P(A|B)=|A∩B|/|B|</span><br><span class="line"></span><br><span class="line">再将上式中的分子、分母都除以|Ω|，得到</span><br><span class="line"></span><br><span class="line">![](Image00077.jpg)</span><br><span class="line"></span><br><span class="line">其中，P(A∩B)表示联合概率，指A和B两个事件共同发生的概率，也可以记为P(A，B)或P(AB)。</span><br><span class="line"></span><br><span class="line">条件概率在贝叶斯统计中也称为后验概率，即在考虑和给出相关证据或数据后所得到的条件概率。</span><br><span class="line"></span><br><span class="line">现实生活中，使某事件发生的前提（条件概率中的“条件”）可能不止一个。比如：在事件B1 ，…，Bn 发生的前提下，事件A发生的概率是多少？将其定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00078.jpg)</span><br><span class="line"></span><br><span class="line">前面几个公式都是根据前提来推测事件发生的概率的，能不能根据事件发生的概率推测其前提出现的概率呢？当然可以，实质上，这就是根据结论推测原因发生的概率。比如，为什么前面堵车了（事件A），是因为发生了交通事故（事件B1</span><br><span class="line">）还是路上车辆太多以致拥塞（事件B2 ），或是下完大雨道路状况很差（事件B3 ）？</span><br><span class="line"></span><br><span class="line">下面的公式定义了事件A（结论）发生了，事件Bk （原因）发生的概率，</span><br><span class="line"></span><br><span class="line">![](Image00079.jpg)</span><br><span class="line"></span><br><span class="line">2.概率分布</span><br><span class="line"></span><br><span class="line">概率分布简称分布，是数学概率论的一个概念，广义上指随机变量的概率性质，狭义上是指随机变量的概率分布函数，使用最为普遍的是狭义上的定义。在此只讲解狭义概率分布。</span><br><span class="line"></span><br><span class="line">1）随机变量分布。随机变量的实质是函数，其数学定义为：设函数X对于概率空间S中每一个事件e都有定义X(e)，其中函数值为实数，同时，每一个实数r都有一个事件集合Ar 与其对应，其中Ar =&#123;e:X(e)≤r&#125;，则将X称作随机变量。</span><br><span class="line"></span><br><span class="line">通俗地说，一个随机试验可能结果（基本事件）的全体组成一个基本空间Ω，随机变量X是定义在基本空间Ω上的取值为实数的函数，即基本空间Ω中每一个点，也就是每个基本事件都有实轴上的点与之对应。比如：在一次扔硬币事件中，将获得的国徽的次数作为随机变量X，则X可以取两个值，分别是0和1。</span><br><span class="line"></span><br><span class="line">如果随机变量X的取值是有限的或是以下可数无穷尽的值：</span><br><span class="line"></span><br><span class="line">X=&#123;x1 ，x2 ，x3 ，…&#125;</span><br><span class="line"></span><br><span class="line">则称X为离散随机变量。</span><br><span class="line"></span><br><span class="line">如果X由全部实数或者由一部分区间组成：</span><br><span class="line"></span><br><span class="line">X=&#123;x|a≤x≤b&#125;，-∞&lt;a&lt;b&lt;∞</span><br><span class="line"></span><br><span class="line">则称X为连续随机变量，连续随机变量的值是不可数并无穷尽的。</span><br><span class="line"></span><br><span class="line">设P为概率测度，X为随机变量，则函数F(x)=P(X≤x)(X∈R)称为X的概率分布函数。将随机变量区间的下限定义为a，上限定义为b，则分布概率P(a≤X≤b)的定义为：</span><br><span class="line"></span><br><span class="line">p(a≤X≤b)=P(X≤b)-P(X≤a)</span><br><span class="line"></span><br><span class="line">=F(b)-F(a)</span><br><span class="line"></span><br><span class="line">2）离散随机变量分布。离散型随机变量X的所有取值与其对应的概率间的关系，称为离散型随机变量X的概率分布，或称为概率函数。可用列表法表示离散随机变量的分布，如表5-1所示。</span><br><span class="line"></span><br><span class="line">表5-1 离散随机变量分布</span><br><span class="line"></span><br><span class="line">![](Image00080.jpg)</span><br><span class="line"></span><br><span class="line">表5-1中第1行是随机变量的值，第2行是每个值出现的概率。比如：用随机变量描述投掷一枚骰子点数的概率分布，用随机变量X表示投掷一枚骰子出现的点数，概率分布![](Image00081.jpg) ，可用如表5-2所示的列表描述。</span><br><span class="line"></span><br><span class="line">表5-2 骰子点数的概率分布</span><br><span class="line"></span><br><span class="line">![](Image00082.jpg)</span><br><span class="line"></span><br><span class="line">离散随机变量的概率分布具有以下两个性质：</span><br><span class="line"></span><br><span class="line">![](Image00083.jpg)</span><br><span class="line"></span><br><span class="line">3）0-1分布。伯努利试验是只有两种可能结果的单次随机试验，即随机变量X只有两个值0或1，0-1分布又名伯努利分布或者两点分布，是一个离散型概率分布。若伯努利试验成功，则随机变量取值为1，否则随机变量取值为0，成功概率为p(0≤p≤1)，失败概率为q=1-p。0-1分布的概率质量函数（概率质量函数的值就是离散随机变量分布的概率）定义如下：</span><br><span class="line"></span><br><span class="line">P(X=k)=pk (1-p)1-k ，k=0，1</span><br><span class="line"></span><br><span class="line">4）二项分布。二项分布即重复n次独立的伯努利试验，在每次试验中只有两种可能的结果，而且两种结果发生与否互相对立，并且相互独立，与其他各次试验结果无关。每次试验的成功概率为p，当n=1时，二项分布就是0-1分布。</span><br><span class="line"></span><br><span class="line">如果随机变量X服从参数为n和p的二项分布，可记为X~B(n，p)，n次试验正好得到k次成功的概率为下面的概率质量函数：</span><br><span class="line"></span><br><span class="line">![](Image00084.jpg)</span><br><span class="line"></span><br><span class="line">5）Poisson分布。Poisson分布又名泊松分布，主要描述单位时间内随机事件发生的次数的概率分布。比如：某服务设施在一定时间内收到的服务请求的次数、电话交换机接到呼叫的次数、机器出现的故障次数等。泊松分布的概率质量函数为：</span><br><span class="line"></span><br><span class="line">![](Image00085.jpg)</span><br><span class="line"></span><br><span class="line">若X服从参数为λ的泊松分布，记为X~π(λ)，或记为X~P(λ)。</span><br><span class="line"></span><br><span class="line">在了解了概率基础知识后，再来看看连续型随机变量。对于随机变量X，若存在非负可积函数p(x)(-∞&lt;x&lt;+∞)，使得对任意实数a，b(a&lt;b)，都有![](Image00086.jpg) ，则X为连续型随机变量，P(a&lt;X≤b)为累积分布函数（概率密度函数的积分，可完整描述实随机变量X的概率分布），函数p(x)为随机变量的概率密度函数，p(x)的图像为概率密度曲线，如图5-1所示。</span><br><span class="line"></span><br><span class="line">![](Image00087.jpg)</span><br><span class="line"></span><br><span class="line">图5-1 概率密度曲线</span><br><span class="line"></span><br><span class="line">概率密度函数p(x)有如下性质：</span><br><span class="line"></span><br><span class="line">·p(x)≥0</span><br><span class="line"></span><br><span class="line">·![](Image00088.jpg)  </span><br><span class="line"></span><br><span class="line">定积分的几何意义为：对于一个给定的正实值函数f(x)，f(x)在一个实数区间[a，b]上的定积分![](Image00089.jpg) 是在Oxy坐标平面上，由曲线(x，f(x))、直线x=a，x=b以及x轴围成的曲边梯形的面积值，如图5-2中的阴影部分。</span><br><span class="line"></span><br><span class="line">![](Image00090.jpg)</span><br><span class="line"></span><br><span class="line">图5-2 定积分的几何意义</span><br><span class="line"></span><br><span class="line">根据图5-2所示的定积分几何意义，![](Image00091.jpg) 为图5-1中的阴影部分，其中p(x)为概率密度函数，而![](Image00092.jpg) ，因此，连续随机变量X在a与b之间分布的概率为概率密度函数在区间[a，b]上的定积分。</span><br><span class="line"></span><br><span class="line">概率质量函数和概率密度函数不同之处在于：概率质量函数针对离散随机变量定义，本身代表随机变量在确定取值点处的概率；概率密度函数针对连续随机变量定义，代表随机变量在确定取值点附近可能性的概率，只有对连续随机变量的概率密度函数在某区间内进行积分（积分后得到累积分布函数）后才能完成概率的计算。</span><br><span class="line"></span><br><span class="line">6）连续型均匀分布。连续型随机变量在等长度的每个空间上取值的概率都相同，则称X服从[a，b]上的均匀分布，记作X~U[a，b]，它的概率密度函数为：</span><br><span class="line"></span><br><span class="line">![](Image00093.jpg)</span><br><span class="line"></span><br><span class="line">累积分布函数为：</span><br><span class="line"></span><br><span class="line">![](Image00094.jpg)</span><br><span class="line"></span><br><span class="line">连续型均匀分布函数的期望值和中值等于区间[a，b]上的中间点：</span><br><span class="line"></span><br><span class="line">![](Image00095.jpg)</span><br><span class="line"></span><br><span class="line">方差为：</span><br><span class="line"></span><br><span class="line">![](Image00096.jpg)</span><br><span class="line"></span><br><span class="line">7）指数分布。指数分布可用来表示独立随机事件发生的时间间隔，比如旅客进机场的时间间隔等。它的概率度函数随着取值的变大而指数减小，定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00097.jpg)</span><br><span class="line"></span><br><span class="line">其中，λ是指每单位时间发生该事件的次数，λ&gt;0。</span><br><span class="line"></span><br><span class="line">累积分布函数定义为：</span><br><span class="line"></span><br><span class="line">![](Image00098.jpg)</span><br><span class="line"></span><br><span class="line">8）正态分布。若随机变量X服从一个位置参数为μ、尺度参数为σ的概率分布，记为：X~N(μ，σ2 )，服从正态分布的随机变量的概率规律为：与μ越邻近的值的概率越大，离μ越远的值的概率越小；σ越小，分布越集中在μ附近，σ越大，分布越分散。正态分布的概率密度函数曲线呈钟形，又经常被称为钟形曲线，密度函数为：</span><br><span class="line"></span><br><span class="line">![](Image00099.jpg)</span><br><span class="line"></span><br><span class="line">累积分布函数为：</span><br><span class="line"></span><br><span class="line">![](Image00100.jpg)</span><br><span class="line"></span><br><span class="line">正态分布密度具有如下性质：</span><br><span class="line"></span><br><span class="line">·曲线关于直线x=μ对称。</span><br><span class="line"></span><br><span class="line">·当x=μ时，f(x)取得最大值![](Image00101.jpg) ，</span><br><span class="line"></span><br><span class="line">·f(x)有渐近线y=0。</span><br><span class="line"></span><br><span class="line">·f(x)有两个拐点![](Image00102.jpg) 。</span><br><span class="line"></span><br><span class="line">·![](Image00103.jpg) 。</span><br><span class="line"></span><br><span class="line">3.随机变量数字特征相关公式</span><br><span class="line"></span><br><span class="line">分布函数完全刻画了随机变量取值的概率规律，因此，在实践中，我们需要知道随机变量的某些分布指标，比如变量的分布趋势、分布均匀程度等，以便分析随机变量的数字特征。</span><br><span class="line"></span><br><span class="line">1）数学期望。数学期望反映了随机变量的平均取值。离散性随机变量的数学期望是试验中每次可能结果的概率乘以其结果的总和，离散型随机变量X的数学期望为：</span><br><span class="line"></span><br><span class="line">![](Image00104.jpg)</span><br><span class="line"></span><br><span class="line">连续型随机变量X的数学期望为：</span><br><span class="line"></span><br><span class="line">![](Image00105.jpg)</span><br><span class="line"></span><br><span class="line">2）方差。方差刻画了随机变量对它的均值的偏离程度，如果E[X]是随机变量X的期望值（平均数μ=E[X]），则随机变量X或者分布F的方差为：</span><br><span class="line"></span><br><span class="line">![](Image00106.jpg)</span><br><span class="line"></span><br><span class="line">3）协方差。协方差表示的是两个变量的总体的误差，如果两个变量的变化趋势一致，也就是说，如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。如果X与Y是统计独立的，那么二者之间的协方差就是0。</span><br><span class="line"></span><br><span class="line">期望值分别为E(X)=μ与E(Y)=ν的两个实数随机变量X与Y之间的协方差，定义为：</span><br><span class="line"></span><br><span class="line">cov(X，Y)=E[(X-μ)(Y-ν)]</span><br><span class="line"></span><br><span class="line">其中E是期望值，也可表示为：</span><br><span class="line"></span><br><span class="line">cov(X，Y)=E(XY)-μν</span><br><span class="line"></span><br><span class="line">### 5.3 回归分析</span><br><span class="line"></span><br><span class="line">在进行回归分析时，通常利用数理统计中的回归方法，确定两种或两种以上变量间相互依赖的定量关系。</span><br><span class="line"></span><br><span class="line">#### 5.3.1 单变量线性回归</span><br><span class="line"></span><br><span class="line">在第3章中曾谈到数据的线性回归，可能会出现一种情况，所有的数据点都准确地落在了回归线上。但在现实中，很难有如此精确的模型，比如有两个变量x和y，其中，x=[5，7，9，11，16，20]，y=[1，2，3，4，7，9]，现在要在x与y之间建立回归模型，该如何实现？</span><br><span class="line"></span><br><span class="line">先用R语言构造数据点。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(5,7,9,11,16,20)> x<-c(1,2,3,4,7,9) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在建立回归线之前，先通过R语言的plot函数绘制这些点的位置，观察分布规律，如图5-3所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

     > plot(x,y) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">图5-3称为散点图，能清晰地在坐标系中查看数据点位置，横轴为x，纵轴为y。</span><br><span class="line"></span><br><span class="line">![](Image00107.jpg)</span><br><span class="line"></span><br><span class="line">图5-3 散点图</span><br><span class="line"></span><br><span class="line">从散点图上可以看出x和y之间存在线性关系，可以表示为y=kx+b这种一次函数的模型。不过想要画一条直线完全穿过这些点是不可能的，但能保证这些点到这条直线的距离最小，这个距离就是残差。残差是观测值与预测值之间的差。下面来具体看一下。</span><br><span class="line"></span><br><span class="line">首先，通过lsfit函数计算回归直线方程的斜率和截距以及残差。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > lsfit(x,y)
    $coefficients
    Intercept         X 
     3.338028  1.845070 
    $residuals
    [1] -0.18309859 -0.02816901  0.12676056  0.28169014 -0.25352113  0.05633803 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面代码中出现的residuals表示残差，残差分别反映了这些点与直线的差异，残差越小越好。残差直接反映了数据点到回归直线的距离，-0.18309859、-0.02816901、0.12676056、0.28169014、-0.25352113、0.05633803分别是当x值为[1，2，3，4，7，9]时，用y=1.845070x+3.338028回归方程求得的y值与实际y值[5，7，9，11，16，20]的差额。残差ei 的计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00108.jpg)</span><br><span class="line"></span><br><span class="line">其中，yi 表示实际值，![](Image00109.jpg) 为按回归方程预测的值。</span><br><span class="line"></span><br><span class="line">例如，将x=2代入该例中的回归方程，即为y=1.845070×2+3.338028，计算可得到y的预测值，然后得到残差，如下所示：</span><br><span class="line"></span><br><span class="line">实际y值-预测y值≈1.845070×2+3.338028-7≈-0.02816901</span><br><span class="line"></span><br><span class="line">然后，绘制散点图及回归线。命令如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >abline(lsfit(x,y)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">刚才将2代入回归方程后，计算1.845070×2+3.338028-7，得到残差仅为-0.02816901，在图5-4中找到回归线上x=2时y的值，能看出，圆圈代表的y值几乎贴近回归线。再看x=1、3、4、7、9时，回归线对应的y值都比较贴近回归线，这些数据点紧靠在回归线周围，显然回归效果不错。</span><br><span class="line"></span><br><span class="line">残差不应该有某种趋势，若残差中出现一种明显的趋势，则意味着模型不适合。如图5-4所示的残差分布较均匀，没有明显的趋势显示大量数据点偏离了回归线。</span><br><span class="line"></span><br><span class="line">![](Image00110.jpg)</span><br><span class="line"></span><br><span class="line">图5-4 散点图及回归线</span><br><span class="line"></span><br><span class="line">事实上，也可以使用lm函数进行更详细的回归分析。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x<-c(1,2,3,4,7,9)> y<-c(5,7,9,11,16,20)> lm(y~x)->xy
    > summary(xy)
    Call:
    lm(formula = y ~ x)
    Residuals:
           1       2       3       4       5       6 
    -0.18310 -0.02817  0.12676  0.28169 -0.25352  0.05634 
    Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
    (Intercept)  3.33803    0.16665   20.03 3.67e-05 ***
    x            1.84507    0.03227   57.17 5.60e-07 ***
    ---
    Signif. codes:  0 ‘

    ***’

     0.001 ‘

    **’

     0.01 ‘

    *’

     0.05 ‘

    .’

     0.1 ‘

     ’

     1
    Residual standard error: 0.222 on 4 degrees of freedom
    Multiple R-squared:  0.9988,    Adjusted R-squared:  0.9985 
    F-statistic:  3269 on 1 and 4 DF,  p-value: 5.604e-07
    >plot(x,y)
    >abline( lm(y~x)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在上述代码中，Coefficients栏的内容如下。</span><br><span class="line"></span><br><span class="line">·Estimate：斜率与截距的估计值。</span><br><span class="line"></span><br><span class="line">·Std.Error：斜率与截距的估计标准差。</span><br><span class="line"></span><br><span class="line">·t value：斜率与截距的假设检验的t值。</span><br><span class="line"></span><br><span class="line">·Pr(&gt;|t|)：与显著性水平比较，决定是否接受该假设检验。</span><br><span class="line"></span><br><span class="line">在Coefficients每行的最后一列有星号，这个星号的含义表示线性关系是否显著：*的数量是0~3，*的数量越多则线性关系越显著。本例中，Coefficients栏的Pr(&gt;|t|)字段（3.67e-05以及5.60e-07）后标注有***，说明x与y之间的线性关系很强。</span><br><span class="line"></span><br><span class="line">#### 5.3.2 多元线性回归</span><br><span class="line"></span><br><span class="line">多元性回归可建立多个自变量和应变量之间的关系，其回归模型方程一般为：</span><br><span class="line"></span><br><span class="line">y=b0 +b1 x1 +b2 x2 +…+bk xk +e</span><br><span class="line"></span><br><span class="line">其中，y为因变量，x1 ，x2 ，…，xk 为自变量，b0 为常数项，b1 ，b2 ，…，xk 为回归系数。</span><br><span class="line"></span><br><span class="line">在进行多元线性回归分析时，可使用lm函数，在上节例子的基础上增加一个自变量x2=[3，4，5，6，8，10]，来看看会有什么效果。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y<-c(5,7,9,11,16,20)> x<-c(1,2,3,4,7,9)> x2<-c(6,8,10,12,16,20)> lm(y~x+x2)->xy2
    >  summary(xy2)
    Call:
    lm(formula = y ~ x + x2)
    Residuals:
             1          2          3          4          5          6 
    -7.495e-16  9.195e-16  4.172e-17 -2.117e-16  1.839e-16 -1.839e-16 
    Coefficients:
                 Estimate Std. Error   t value Pr(>|t|)    
    (Intercept) 1.000e+00  3.787e-15 2.640e+14   <2e-16 0 1 2 3 *** x 1.000e+00 1.359e-15 7.357e+14 <2e-16 x2 5.000e-01 8.019e-16 6.236e+14 --- signif. codes: ‘ ***’ 0.001 **’ 0.01 *’ 0.05 .’ 0.1 ’ residual standard error: 7.121e-16 on degrees of freedom multiple r-squared: 1, adjusted f-statistic: 1.591e+32 and df, p-value: < 2.2e-16 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">通过上述回归分析，得出该回归方程为y=x+0.5×x2+1，Std.Error、t value、Pr(&gt;|t|)以及线性相关程度等指标的含义同单变量线性回归类似。</span><br><span class="line"></span><br><span class="line">#### 5.3.3 非线性回归</span><br><span class="line"></span><br><span class="line">非线性回归模型较多，其中应用得较多的有以下模型：</span><br><span class="line"></span><br><span class="line">1）多项式模型：</span><br><span class="line"></span><br><span class="line">y=β0 +β1 x+β2 x2 +…+βk xk +ε</span><br><span class="line"></span><br><span class="line">2）指数模型：</span><br><span class="line"></span><br><span class="line">y=aebx ε</span><br><span class="line"></span><br><span class="line">3）幂函数模型：</span><br><span class="line"></span><br><span class="line">y=ax1 b1 x2 b2 ε</span><br><span class="line"></span><br><span class="line">4）成长曲线模：</span><br><span class="line"></span><br><span class="line">y=1/(β0 +β1 e-x +ε)</span><br><span class="line"></span><br><span class="line">实际应用中，除上述模型外，还有很多非线性回归模型，但无论是哪种非线性回归模型，最后都可以通过变量变换转化为线性模型，从而用最小二乘法进行回归分析。下面以y=β0</span><br><span class="line">+β1 ebx +ε模型为例讲解非线性回归的方法。</span><br><span class="line"></span><br><span class="line">1）准备回归分析用数据（假设已预先知道回归方程，通过回归方程精确计算y值），</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    >x<-c(1,2,3,4,7,8,9)>y <-100 10 + * exp(x 2) rnorm(x) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）使用R语言的nls函数，应用最小二乘法原理，实现非线性回归分析。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    >nlmod <-nls(y ~ const + a * exp(b x)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）使用summary函数分析拟合结果。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > summary(nlmod)
    Formula: y ~ Const + A * exp(B * x)
    Parameters:
           Estimate Std. Error t value Pr(>|t|)    
    Const 1.001e+02  8.377e-01   119.4 2.95e-08 ***
    A     1.006e+01  1.759e-01    57.2 5.59e-07 ***
    B     4.995e-01  1.925e-03   259.5 1.32e-09 ***
    ---
    Signif. codes:  0 ‘

    ***’

     0.001 ‘

    **’

     0.01 ‘

    *’

     0.05 ‘

    .’

     0.1 ‘

     ’

     1
    Residual standard error: 1.1 on 4 degrees of freedom
    Number of iterations to convergence: 8 
    Achieved convergence tolerance: 4.887e-07
    >  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">其中，在Parameters栏，对方程涉及的以下3个参数进行了预测：</span><br><span class="line"></span><br><span class="line">β0 =Const=1.001e+02</span><br><span class="line"></span><br><span class="line">β1 =A=1.006e+01</span><br><span class="line"></span><br><span class="line">b=B=4.995e-01</span><br><span class="line"></span><br><span class="line">将以上参数与程序中y值的生成规则进行对比，可以看见，拟合效果还是不错的。</span><br><span class="line"></span><br><span class="line">前面为解释非线性回归过程，将x代入参数确定的非线性回归方程计算y值，然后，依据x和y推出非线性回归方程的参数。但实践应用中，往往需要依据一组x值和y值，推导非线性方程的参数，因此，尝试通过rnorm函数产生较小的随机数，加在精确计算的y值上，这样计算后形成的非线性回归模型拥有一定的残差，较接近真实环境。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >y <-100 10 + * exp(x 2) rnorm(x) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4）绘制拟合效果图。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    >plot(x,y, main = "nls(o)")
    >curve(100 + 10 * exp(x / 2), col = 4, add = TRUE)
    >lines(x, predict(nlmod), col = 2,type='b') <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图5-5所示为拟合效果图，显示出拟合效果不错。其中，偏上的线为预测的回归线，偏下的线为实际方程。回归在[4，7]的区间内拟合效果较差，这是样本数据太少的原因，因为样本数据仅有9个。</span><br><span class="line"></span><br><span class="line">参与拟合的样本数据量决定了拟合效果的好坏。可以加大自变量的数量，重新应用nls函数进行拟合，来看看效果如何。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >x<-seq(1,10,0.1)>y <-100 10 + * exp(x 2) rnorm(x)>nlmod <-nls(y ~ const + a * exp(b x))>plot(x,y, main = "nls(o)")
    >curve(100 + 10 * exp(x / 2), col = 4, add = TRUE)
    >lines(x, predict(nlmod), col = 2) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图5-6所示是相应的效果图，从中可以看出，回归线与实际方程线很接近。</span><br><span class="line"></span><br><span class="line">不过，图5-6所示的回归效果仍存在一个问题，就是样本过于集中在回归线上了，为使回归分析更接近真实应用环境，需要继续加大随机数的范围，增加非线性回归的残差，使样本点散布在回归线周围。</span><br><span class="line"></span><br><span class="line">![](Image00111.jpg)</span><br><span class="line"></span><br><span class="line">图5-5 拟合效果图</span><br><span class="line"></span><br><span class="line">![](Image00112.jpg)</span><br><span class="line"></span><br><span class="line">图5-6 非线性回归效果图</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >x<-seq(1,10,0.1)>y <-100 10 + * exp(x 2) rnorm (x)*100>nlmod <-nls(y ~ const + a * exp(b x))>plot(x,y, main = "nls(o)")
    >curve(100 + 10 * exp(x / 2), col = 4, add = TRUE)
    >lines(x, predict(nlmod), col = 2) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从图5-7可以看出，样本点虽然没有集中在回归线上，而是散落在回归线周围的区域，产生的残差较大，但样本点的整体走向与回归线一致，此外，回归线与实际方程这两条线几乎重叠，说明回归分析较准确地预测出回归方程的各个参数。因此，从整体上观察，拟合效果不错，回归模型适当。</span><br><span class="line"></span><br><span class="line">![](Image00113.jpg)</span><br><span class="line"></span><br><span class="line">图5-7 接近真实环境的非线性回归</span><br><span class="line"></span><br><span class="line">### 5.4 数据分析基础</span><br><span class="line"></span><br><span class="line">#### 5.4.1 区间频率分布</span><br><span class="line"></span><br><span class="line">下面是美国地震台网公布的全球2013年5月20日22点到24点发生的所有地震的震级。</span><br><span class="line"></span><br><span class="line">![](Image00114.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00115.jpg)</span><br><span class="line"></span><br><span class="line">下面就以上面的数据为例，来讲述区间频率分布。现在的任务是完成地震震级分析。</span><br><span class="line"></span><br><span class="line">1）将地震震级数据放入一个向量中。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >mag<-c(1.6,0.9,2.1,2.2,2.3,1.7,1.3,1.6,4.7,1.2,0.9,4.7,0.6,5.3,1.1,4.8,4,4.2, 4.6,1.3,2.1,1.5,3)> mag
     [1] 1.6 0.9 2.1 2.2 2.3 1.7 1.3 1.6 4.7 1.2 0.9 4.7 0.6 5.3 1.1 4.8 4.0 4.2
    [19] 4.6 1.3 2.1 1.5 3.0 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）使用cut函数将震级分成5个区间，并建立因子。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >factor(cut(mag,5))
     [1] (1.54,2.48]  (0.595,1.54] (1.54,2.48]  (1.54,2.48]  (1.54,2.48] 
     [6] (1.54,2.48]  (0.595,1.54] (1.54,2.48]  (4.36,5.3]   (0.595,1.54]
    [11] (0.595,1.54] (4.36,5.3]   (0.595,1.54] (4.36,5.3]   (0.595,1.54]
    [16] (4.36,5.3]   (3.42,4.36]  (3.42,4.36]  (4.36,5.3]   (0.595,1.54]
    [21] (1.54,2.48]  (0.595,1.54] (2.48,3.42] 
    Levels: (0.595,1.54] (1.54,2.48] (2.48,3.42] (3.42,4.36] (4.36,5.3] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）统计因子频率。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >factor(cut(mag,5))->magfactor
    > table(magfactor)
    magfactor
    (0.595,1.54]  (1.54,2.48]  (2.48,3.42]  (3.42,4.36]   (4.36,5.3] 
               8            7            1            2            5  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">可以看出2013年5月20日22点到24点期间，全球发生的地震在(0.595，1.54]内有8起，在(1.54，2.48]内有7起等。</span><br><span class="line"></span><br><span class="line">4）绘制直方图。在R语言中，可使用hist函数绘制直方图。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > hist(mag,breaks=5) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制结果如图5-8所示。</span><br><span class="line"></span><br><span class="line">![](Image00116.jpg)</span><br><span class="line"></span><br><span class="line">图5-8 直方图</span><br><span class="line"></span><br><span class="line">#### 5.4.2 数据直方图</span><br><span class="line"></span><br><span class="line">直方图又称柱状图、质量分布图，是一种对数据分布情况的图形表示，由一系列高度不等的纵向条纹或线段表示数据分布的情况，它根据从生产过程中收集来的质量数据分布情况，组成以组距为底边、以频数为高度的一系列连接起来的直方型矩形图。</span><br><span class="line"></span><br><span class="line">地震数据是一种次数直方图，是由若干宽度相等、高度不一的直方条紧密排列在同一基线上构成的图形，其中基线上每个区间代表了一段震级，高度代表了这段震级发生地震的次数（频率）。</span><br><span class="line"></span><br><span class="line">1）用R语言的read.table函数读取地震震级的文件（read.table方法可读取文件，生成list组件类型的数据集，并且，通过指定header=TRUE参数，可将文件头作为字段变量名）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > read.table("eqweek.csv",header=TRUE,sep=",")->earthquake <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）显示读取的地震数据（2013.5.14~2013.5.20），验证读取内容是否完整。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > earthquake     DateTime.Latitude.Longitude.Depth.Magnitude.MagType.NbStations.Gap.Distance.RMS.Source.EventID.Version
    1                   2013-05-20T23:57:12.000+00:00,63.45,-148.291,5.5,1.6,Ml,,,,0.8,ak,ak10720946,1.3691E+12
    2                   2013-05-20T23:52:59.000+00:00,61.337,-152.069,81.4,2.1,Ml,,,,
    1.15,ak,ak10720941,1.36909E+12
    3                   2013-05-20T23:49:15.100+00:00,19.99,-155.426,38.2,2.2,Md,,133,0.1,0.
    11,hv,hv60501711,1.3691E+12
    4                   2013-05-20T23:46:36.000+00:00,60.498,-142.974,4.2,2.3,Ml,,,,
    0.43,ak,ak10720934,1.36909E+12
    ..........................  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）绘制数据直方图，观察从2013年5月14日至2013年5月20日这周内全球地震震级的分布情况。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > hist(earthquake$Magnitude,5) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">生成的直方图如图5-9所示。其中横轴是震级，纵轴是频率分析。通过观察可得出结论：震级在1~2级的地震发生频率最高，因为在x为1~2时，长方形柱体最高；2~3级的柱体高度仅次于1~2级，发生频率排名第二；发生频率最小的是6~7级的地震，柱体高度很小。总体来说，1~3级和4~5级的地震发生较频繁。</span><br><span class="line"></span><br><span class="line">![](Image00117.jpg)</span><br><span class="line"></span><br><span class="line">图5-9 震级分布直方图</span><br><span class="line"></span><br><span class="line">数据直方图能直观地说明数据在每个区间的分布频率，但如果需要精确的分布频率，则需要使用R语言的因子对象。先通过cut函数将数据分组，然后通过factor()函数生成因子对象，最后使用table函数分析频率。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >  table(factor(cut(earthquake$Magnitude,5)))
    (0.995,2.1]   (2.1,3.2]   (3.2,4.3]   (4.3,5.4]  (5.4,6.51] 
            693         200          46         126          10  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述结果的最后两行，每个区间的震级频率一目了然，(0.995，2.1]区间的震级频率是693次，(2.1，3.2]区间的震级频率是200次等。</span><br><span class="line"></span><br><span class="line">#### 5.4.3 数据散点图</span><br><span class="line"></span><br><span class="line">数据散点图是指数据点在直角坐标系平面上的分布图，通过直接观察图形辨认某现象的测量值与可能原因因素之间的关系，具有快捷、易于交流和易于理解的特点。</span><br><span class="line"></span><br><span class="line">数据散点图表示因变量随自变量而变化的大致趋势，将序列显示为一组点，值由点在图表中的位置表示，类别由图表中的不同标记表示。通常用垂直轴表示现象值Y，用水平轴表示可能有关系的原因因素X，通过对其观察分析，来判断两个变数之间的相关关系。此外，依据散点图可选择函数对数据点进行拟合，建立回归模型。</span><br><span class="line"></span><br><span class="line">下面继续以全球一周地震数据为例，来讲解数据散点图。</span><br><span class="line"></span><br><span class="line">1）将变量放到搜索路径上。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

      > attach(earthquake) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）分析地震震深。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

       > summary(Depth)
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
       0.10    5.80   12.15   30.82   38.00  630.70      39  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在上述结果中，Min表示地震震深的最小值，Max表示最大值，Median为中位数，Mean为平均值。我们试着从下面的散点图中分析一下地震震深与震级的关系，如图5-10所示。</span><br><span class="line"></span><br><span class="line">在图5-10中，Depth是震深，Magnitude是震级，从表面上看一周中Depth和Magnitude之间没有关系，但仔细观察这个图，可发现一个有趣的结果：在这一周里当震深超过300后，震级都接近5或在5以上，而在300以内时，震级并不确定。</span><br><span class="line"></span><br><span class="line">3）对震深的直方图进行分析。先来绘制相关直方图，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >hist(Depth) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制的图形如图5-11所示。</span><br><span class="line"></span><br><span class="line">![](Image00118.jpg)</span><br><span class="line"></span><br><span class="line">图5-10 震深与震级关系的散点图</span><br><span class="line"></span><br><span class="line">![](Image00119.jpg)</span><br><span class="line"></span><br><span class="line">图5-11 震深的直方图</span><br><span class="line"></span><br><span class="line">观察图5-11可得出结论：这个星期内发生的绝大部分地震的震深在100以内，这个区间的代表频率的柱体高度最高，而发生最少的350~550段和250~300段，这两个区间的柱体几乎贴近X轴，高度很小。</span><br><span class="line"></span><br><span class="line">4）分析带数据点的震级直方图。为提高直方图的表示能力，有时需要在直方图中显示实际的数据点，通过观察这些数据点的数量，可分析数据点在每个区间的分布密集程度，可通过R语言的rug函数绘制数据点。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > hist(Magnitude)
    > rug(Magnitude) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的图形如图5-12所示。</span><br><span class="line"></span><br><span class="line">仔细观察图5-12能看出：在3~4震级区域内，数据点分布并不均匀，在靠近3的区域内，数据更为密集，数据点集中分布在偏向于3的区域；此外，在5~6级震级区域也出现类似现象，数据点偏向于5，这说明3~4级或5~6级震级范围内，大部分地震的震级不是非常大，偏向于3或5。</span><br><span class="line"></span><br><span class="line">这些只是根据一个星期的数据进行分析得到的结果，不一定就代表真正的答案。答案要通过分析大量数据以及数据各个指标关系，同时结合地球物理知识的研究才能得出。</span><br><span class="line"></span><br><span class="line">由于图形直观性很强，浅显且易于理解，因此在数据分析中，经常需要绘制图表和直线。前面已经讲解过绘图的方法，在此补充一下画线方法，在R语言中使用lines函数完成绘制直线。比如要绘制一个（10，40）、（20，50）、（30，60）的散点图，并将点连成线，可如下编写代码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(c(10,20,30),c(40,50,60))
    > lines(c(10,20,30),c(40,50,60)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的散点及直线如图5-13所示。</span><br><span class="line"></span><br><span class="line">![](Image00120.jpg)</span><br><span class="line"></span><br><span class="line">图5-12 带数据点的震级直方图</span><br><span class="line"></span><br><span class="line">![](Image00121.jpg)</span><br><span class="line"></span><br><span class="line">图5-13 散点及直线图</span><br><span class="line"></span><br><span class="line">#### 5.4.4 五分位数</span><br><span class="line"></span><br><span class="line">分位数是描述数据位置的一种方法，它将一个随机变量的分布范围分为几个等份的数值点。分位数法被用来识别某临界值，一般情况下可使用分位数（或分位点）描述小于等于这个临界值的观测值数量占整个数据中的某个具体比率（小于等于该值的数据为一给定的比率）。</span><br><span class="line"></span><br><span class="line">常用的分位数有中位数、四分位数、五分位数、十分位数、百分位数等，其中，中位数将数据分布范围分成了相等的两个部分。此外，我们还能将数据分布范围分成更小尺寸的分割线，四分位数将一个分布分成4等份，而五分位数将其分成5等份，十分位数将其分成10等份，百分位数将其分成100等份等。</span><br><span class="line"></span><br><span class="line">五分位数法是数据分析的常用方法，在R语言中，可使用fivenum函数计算五分位数（fivenum函数会返回以下数据：minimum、lower-hinge、median、upper-hinge、maximum）。下面用fivenum函数对地震数据进行分析。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > fivenum(Magnitude)
    [1] 1.0 1.3 1.7 2.5 6.5 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分析结果表明，震级最小为1.0，最大为6.5，中位数为1.7，通过1.7将一组数据分为上下两组，然后再计算上下两组的中位数1.3与2.5。</span><br><span class="line"></span><br><span class="line">#### 5.4.5 累积分布函数</span><br><span class="line"></span><br><span class="line">累积分布函数完整地描述出了一个实数随机变量X的概率分布，是概率密度函数的积分，与概率密度函数相对。它被定义为随机变量小于或者等于某个数值的概率P(X≤x)，即F(x)=P(X≤x)。我们计算一下震级的累积分布。</span><br><span class="line"></span><br><span class="line">1）通过R语言的ecdf函数计算累积分布。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >ecdf(Magnitude)->mag_ecdf
    >mag_ecdf
    Empirical CDF 
    Call: ecdf(Magnitude)
     x[1:50] =      1,    1.1,    1.2,  ...,      6,    6.5 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）通过plot函数绘制累积概率图，直观展示震级累积分布。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(mag_ecdf,do.points=FALSE, verticals=TRUE) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的图形如图5-14所示。</span><br><span class="line"></span><br><span class="line">![](Image00122.jpg)</span><br><span class="line"></span><br><span class="line">图5-14 震级累积分布概率</span><br><span class="line"></span><br><span class="line">图5-14的x轴是震级，y轴是累积分布概率，当震级升高时，累积分布概率也随之提高，这个趋势很正常，因为累积分布概率是指小于或等于某个震级的概率。比如：从图5-14观察，发生地震的震级在3以内的概率接近80%，震级在2以内的概率接近60%。</span><br><span class="line"></span><br><span class="line">#### 5.4.6 核密度估计</span><br><span class="line"></span><br><span class="line">1.核密度原理</span><br><span class="line"></span><br><span class="line">利用前面所说的直方图估计数据分布密度是有局限性的，因为数据分布的密度函数是不平滑的，它受子区间宽度影响较大，当数据维数超过二维时就有局限。</span><br><span class="line"></span><br><span class="line">什么是密度函数呢？连续型随机变量的概率密度函数（不至于混淆时可简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数，而随机变量落在某个区域之内的概率为概率密度函数在这个区域上的积分，当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。</span><br><span class="line"></span><br><span class="line">如何由给定样本点集合求解随机变量的分布密度函数？解决这一问题的方法包括参数估计和非参数估计。参数估计中常用的是参数回归分析，它假定数据分布符合某种特定的性态，如线性、可化线性或指数性态等，然后确定回归模型的未知参数。但参数模型的这种基本假定与实际的物理模型之间常常存在较大的差距，于是Rosenblatt和Parzen提出了核密度估计方法，它可估计未知的密度函数，是非参数估计方法之一。</span><br><span class="line"></span><br><span class="line">假设样本数据值在D维空间服从一个未知的概率密度函数，那么在区域R内的概率为：</span><br><span class="line"></span><br><span class="line">![](Image00123.jpg)</span><br><span class="line"></span><br><span class="line">上式中，P是每个样本数据点落入区域R的概率，假设在N个样本数据点中，有K个落入了区域R，那么就应该服从二项分布。公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00124.jpg)</span><br><span class="line"></span><br><span class="line">在N的样本数据很大时，K约等于N×P。而另一方面，假设区域R足够小，那么P约等于p(x)×V（V为区域R的空间）。</span><br><span class="line"></span><br><span class="line">于是，结合两个不等式子可得：</span><br><span class="line"></span><br><span class="line">![](Image00125.jpg)</span><br><span class="line"></span><br><span class="line">根据上式，来估算p(x)就有两种方式：第一，K不变，通过决定区域V的大小来估算密度函数，采用K-nearer-neighbour方法；第二，V不变，通过决定K的大小来估算密度函数，采用kernel方法。这里选择第二种方式，假设区域R是一个以x为中心、边长为h的极小立方体（也就是V不变），定义kernel函数（数据维数为D维，当样本数据点落入小立方体时，函数值为1，其他情况下为0）的公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00126.jpg)</span><br><span class="line"></span><br><span class="line">落入立方体数据点的总个数K就可以表示为：</span><br><span class="line"></span><br><span class="line">![](Image00127.jpg)</span><br><span class="line"></span><br><span class="line">根据式（5-1），把式（5-2）代入式（5-1）中，可得：</span><br><span class="line"></span><br><span class="line">![](Image00128.jpg)</span><br><span class="line"></span><br><span class="line">上式中，V=hD 。</span><br><span class="line"></span><br><span class="line">2.核密度计算</span><br><span class="line"></span><br><span class="line">R语言可使用density函数进行核密度估计，density函数默认情况下在512个点上估计密度值。下面就用它来计算一下地震数据中的震级核密度。首先，指定hist函数的prob参数为TRUE，绘制核密度直方图；然后通过lines函数，绘制核密度曲线。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > hist(Magnitude,prob=TRUE)
    > lines(density(Magnitude)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的核密度如图5-15所示，图中曲线就是核密度曲线。</span><br><span class="line"></span><br><span class="line">![](Image00129.jpg)</span><br><span class="line"></span><br><span class="line">图5-15 震级核密度</span><br><span class="line"></span><br><span class="line">### 5.5 数据分布分析</span><br><span class="line"></span><br><span class="line">这里以老年常见病数据为例，来讲解数据分布的分析。如表5-3所示是一些老年常见病数据。</span><br><span class="line"></span><br><span class="line">表5-3 老年常见病数据</span><br><span class="line"></span><br><span class="line">![](Image00130.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00131.jpg)</span><br><span class="line"></span><br><span class="line">1）在R中加载数据，然后查看老年病的老人年龄分布情况及概率密度分布，绘制年龄直方图。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > read.table("aged_patients.csv",header=TRUE,sep=",")->agedpatients
     > hist(agedpatients$年龄

    ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的年龄分布直方图如图5-16所示。</span><br><span class="line"></span><br><span class="line">2）对年龄进行核密度估计，并绘制核密度曲线。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > hist(agedpatients$年龄

    ,prob=TRUE)
    > lines(density(agedpatients$年龄

    )) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制出的核密度曲线，如图5-17所示。</span><br><span class="line"></span><br><span class="line">![](Image00132.jpg)</span><br><span class="line"></span><br><span class="line">图5-16 年龄分布直方图</span><br><span class="line"></span><br><span class="line">![](Image00133.jpg)</span><br><span class="line"></span><br><span class="line">图5-17 年龄的核密度曲线</span><br><span class="line"></span><br><span class="line">3）通过min和max两个函数分析患者的最小年龄和最大年龄，通过mean函数分析年龄的平均值，通过var函数计算年龄的方差。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > min(agedpatients$年龄

    )
    [1] 60
    > max(agedpatients$年龄

    )
    [1] 90
    > mean(agedpatients$年龄

    )
    [1] 69.09839
    > var(agedpatients$年龄

    )
    [1] 38.60801 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">由上述分析可得出一个结论：63~72岁这个阶段的老人必须要注意身体，坚持运动，保持健康，这个年龄段是急腹症和肿瘤两种老年病的高发期，发生概率较大。从60到90岁的老人都有可能患上这两种老年病，患者的平均年龄是69岁。标准差比较大，看来这两种老年病在老人的各个年龄段中发生得比较普遍。</span><br><span class="line"></span><br><span class="line">4）按年龄分类汇总肿瘤和急腹症的数量。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > attach(agedpatients)
    > tapply(肿瘤

    ,年龄

    ,sum)
    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 87 88 90 
    19 26 26 28 21 35 37 22 21 23 29 26 31 16 19 12 13 19  8  5  4  3  7  2  1  1  0  3  1 
    > tapply(急腹症

    ,年龄

    ,sum)
    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 87 88 90 
     2  0  0  2  0  0  1  0  1  2  4  1  1  0  3  1  2  2  0  2  0  1  0  1  0  1  2  0  0  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5）分年龄统计肿瘤患者的数量。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > table(factor(cut(agedpatients$年龄

    [agedpatients$肿瘤

    ==1],5)))
    (60,66] (66,72] (72,78] (78,84] (84,90] 
    155     158     118      22       5  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6）分年龄统计急腹症患者的数量。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > table(factor(cut(agedpatients$年龄

    [agedpatients$急腹症

    ==1],5)))
      (60,65.4] (65.4,70.8] (70.8,76.2] (76.2,81.6]   (81.6,87] 
              4           8           8           5           4  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述分析结果表明：急腹症患者在65岁到77岁之间发病率较高，其中70岁时发病率最高；而肿瘤患者在60岁到72岁之间发病率较高，其中69岁时发病率最高。</span><br><span class="line"></span><br><span class="line">### 5.6 小结</span><br><span class="line"></span><br><span class="line">本章对统计学基础进行阐述，介绍了数据分析的概念、发展以及需要的基础知识，同时从线性回归和非线性回归两个方面讲述了数据分析基本方法——回归分析，并以实例说明了用R语言进行数据分布情况分析的方法。</span><br><span class="line"></span><br><span class="line">统计分析在机器学习和数据分析中有着举足轻重的地位。李开复在攻读博士期间主攻语音识别。他的导师坚持的方向是发展和完善专家系统。而他最终发现，专家系统是有严重局限性的，无法延伸到做不特定语者的语音识别。他认为有数据支持的统计模式是唯一的希望，于是改用统计的方法来进行语音识别。3年中，他用统计的方法把语音识别的准确率从40%逐步提高到80%、90%，最后达到了96%，《商业周刊》把他的发明选为1988年最重要的科学发明。他用统计学方法做出的语音识别博士论文至今还被用作语音识别产品的理论基础。</span><br><span class="line"></span><br><span class="line">Google在2006年面对广大用户推出了关键词统计分析系统：Google Trends，链接为：&lt;http://www.google.com/trends&gt; 。这是一个非常有意思和价值的产品，有兴趣的读者不妨一试。下面是利用这个系统对“machine learning”这个搜索关键词进行的统计分析，从图5-18和图5-19中可以明显看出，机器学习越来越受人关注，尤其是从2011年年底开始，人们对机器学习的热衷度在持续上升，因为这段时期的曲线呈稳步上扬趋势。</span><br><span class="line"></span><br><span class="line">![](Image00134.jpg)</span><br><span class="line"></span><br><span class="line">图5-18 “机器学习”在Google Trends中的搜索结果</span><br><span class="line"></span><br><span class="line">![](Image00135.jpg)</span><br><span class="line"></span><br><span class="line">图5-19 “机器学习”在Google Trends中的搜索结果</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">1.本章中介绍了用R语言进行回归分析的方法。请对下列几组数据进行回归分析。</span><br><span class="line"></span><br><span class="line">（1）x=[2，5，8，9，12，15]，y=[18，52，78，101，125，148]</span><br><span class="line"></span><br><span class="line">（2）x=[2，5，8，9，12，15]，y=[5，120，502，739，1708，3415]</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 第一组数据适用线性回归，第二组数据适用非线性回归，回归方程为y=x×20+exp(x/5)。</span><br><span class="line"></span><br><span class="line">2.在Google关键词统计分析中搜索“机器学习”的中文关键词，描述人们对该关键词兴趣的发展趋势，目前机器学习的哪些分支领域正在成为人们关注的热点。</span><br><span class="line"></span><br><span class="line">3.下载本书例子中的美国地震台数据earthquakes.csv，分析2013.3~2013.4期间的数据，分震级统计这段时期全球发生的地震，同时做出这段时间的震深与震级散点图，计算震级的累积分布，并显示累积分布图。</span><br><span class="line"></span><br><span class="line">## 第6章 描述性分析案例</span><br><span class="line"></span><br><span class="line">本章将以R语言为分析工具对描述性分析案例进行剖析，对于其中涉及的统计分析知识也会做简单介绍，请各位读者按准备篇的指导将R语言计算平台搭建好。</span><br><span class="line"></span><br><span class="line">### 6.1 数据图形化案例解析</span><br><span class="line"></span><br><span class="line">数据是事实，也称观测值，是实验、测量、观察、调查等活动的结果，常以数量的形式给出。数据分析的目的是把隐没在一大批看似杂乱无章的数据中的有用信息集中、萃取和提炼出来，以找出所研究对象的内在规律。</span><br><span class="line"></span><br><span class="line">#### 6.1.1 点图</span><br><span class="line"></span><br><span class="line">下面以2010年全国各行业就业调查数据（部分数据如表6-1所示，完整数据在本书下载包中）为依据，以点图分析为手段，剖析电子行业劳动报酬水平。</span><br><span class="line"></span><br><span class="line">表6-1 全国各行业就业调查部分数据</span><br><span class="line"></span><br><span class="line">![](Image00136.jpg)</span><br><span class="line"></span><br><span class="line">读入如表6-1所示的数据文件。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >  read.table("youxiangz.csv",,header=TRUE,sep=",")->jiuye <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分析行业报酬水平，以电子行业的劳动报酬为例进行讲解，主要步骤如下。</span><br><span class="line"></span><br><span class="line">1）从数据集中筛选电子行业的劳动报酬。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > jiuye$行业名称

    [grepl("电子

    ",jiuye$行业名称

    )]->jyhy
    > jiuye$平均劳动报酬

    [grepl("电子

    ",jiuye$行业名称

    )]->jygz
    > names(jygz)<-jyhy <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）绘制电子行业薪水点图，如图6-1所示。从图6-1中可清楚地看到7个电子行业的薪水分布情况。可将图6-1分为若干行，每一行代表一个行业，点在每行的不同位置代表不同的报酬，所有行的数值遵循同一刻度（刻度尺在点图的最下方，从40000到120000分成4个区域）。</span><br><span class="line"></span><br><span class="line">3）找到薪水最高、最低的行业。首先找到图6-1中相应行业代表的行，然后在该行找到由点代表的刻度值（点在某行的位置），最后在刻度尺中找到相应数值，读取数值。很明显，代表“电子计算机制造”行业报酬的点在所有行中最贴近右端，属于薪水最高的行业，而“家用电器及电子产品专门零售”行业的数值在最左端，属于电子行业中薪水最低的行业。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > dotchart(jygz) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00137.jpg)</span><br><span class="line"></span><br><span class="line">图6-1 电子行业薪水点图</span><br><span class="line"></span><br><span class="line">#### 6.1.2 饼图和条形图</span><br><span class="line"></span><br><span class="line">下面以饼图和条形图为分析手段，对中介行业的平均劳动报酬进行剖析。</span><br><span class="line"></span><br><span class="line">1）以条形图来表示平均劳动报酬。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > jiuye$平均劳动报酬

    [grepl("中介

    ",jiuye$行业名称

    )]->jygz
    > jiuye$行业名称

    [grepl("中介

    ",jiuye$行业名称

    )]->jyhy
    > names(jygz)<-jyhy> barplot(jygz,horiz = TRUE) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制结果如图6-2所示。</span><br><span class="line"></span><br><span class="line">从图6-2可明显观察到，“科技中介服务”行业的平均劳动报酬位居第一，“职业中介服务”位居最后。</span><br><span class="line"></span><br><span class="line">2）除了条形图，还可以用饼图分析平均劳动报酬。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > pie(jygz) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制结果如图6-3所示。</span><br><span class="line"></span><br><span class="line">![](Image00138.jpg)</span><br><span class="line"></span><br><span class="line">图6-2 中介行业的平均劳动报酬条形图</span><br><span class="line"></span><br><span class="line">![](Image00139.jpg)</span><br><span class="line"></span><br><span class="line">图6-3 中介行业的平均劳动报酬饼图</span><br><span class="line"></span><br><span class="line">观察图6-3，代表“科技中介服务”的面积所占比重最大，因此属于平均劳动报酬最高的中介服务行业。</span><br><span class="line"></span><br><span class="line">#### 6.1.3 茎叶图和箱线图</span><br><span class="line"></span><br><span class="line">本节将要讲解的茎叶图和箱线图，可能大家平时接触得比较少，但在数据分析中经常用到。茎叶图和箱线图不同于前面的图表，表面看上去比较抽象，一旦掌握了读图的方法后，会发现它们表现数据的能力还是很强的。</span><br><span class="line"></span><br><span class="line">1.茎叶图分析</span><br><span class="line"></span><br><span class="line">茎叶图又称“枝叶图”，它的思路是将数组中的数按位数进行比较，然后将数的大小基本不变或变化不大的位作为一个主干，并将变化大的位的数作为分枝，列在主干的后面，这样就可以清楚地看到每个主干后面有几个数，每个数具体是多少。下面以产品单位成本数据为例，分析它的茎叶图，如表6-2所示。</span><br><span class="line"></span><br><span class="line">表6-2 产品单位成本数据</span><br><span class="line"></span><br><span class="line">![](Image00140.jpg)</span><br><span class="line"></span><br><span class="line">在R语言中，使用stem函数进行茎叶图分析，其格式为：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >  stem(变量，

    scale=长度，

    width=绘图宽度，

    atom=容差）

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">首先调用read.table方法读取数据文件，然后调用stem函数绘制茎叶图。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >read.table("cp.csv",,header=TRUE,sep=",")->cp
    > stem(cp$单机成本

    .元

    .台

    .,scale=2)
      The decimal point is 1 digit(s) to the right of the | <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">stem函数的scale参数为2，表示将图的长度设置为2。stem函数生成的成本数据茎叶图如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

      29 | 68
      30 | 1356778
      31 | 1135
      32 | 7
      33 | 
      34 | 36 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">茎叶图的每一行表示每个茎与它的叶子，“|”前面是茎，而“|”后面是叶。以最后一行“34|36”为例，“|”前面的“34”是茎，后面的“36”是叶，这行的意思是：百位数为3，十位数为4的数据有两个，分别是：345和346。</span><br><span class="line"></span><br><span class="line">从茎叶图中可看出，单位成本主要集中在300~309元，因为代表茎30的行拥有的叶子最多。此外，茎33的行没有一个叶子，这说明没有一件产品的单位成本在330~339元这个范围内。</span><br><span class="line"></span><br><span class="line">2.箱线图分析</span><br><span class="line"></span><br><span class="line">箱形图提供了一种只用5个点来对数据集做简单总结的方式，这5个点包括最大值、最小值、中位数、下四分位数和上四分位数。箱形图中最重要的内容是对相关统计点的计算，相关统计点可以通过百分位计算方法进行实现。</span><br><span class="line"></span><br><span class="line">以2010年全国就业调查数据为例，绘制“平均教育经费”的箱形图并进行分析。R语言中，实现箱线图分析的相应函数为boxplot。下面的代码绘制平均教育经费的箱形图。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > boxplot(jiuye$平均教育经费

    ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图6-4所示的箱形图将平均教育经费很形象地分为中心、延伸以及分部状态的全部范围。中间那个箱子的顶部是上四分位数，底部是下四分位数，中间的粗线是中位数位置，箱体由上下伸出的垂直部分表示数据的散布范围。另外在散布范围外还有一些小圆点，那些是异常点，可见平均教育经费有一些特大值，最大的异常值超过了12000。</span><br><span class="line"></span><br><span class="line">![](Image00141.jpg)</span><br><span class="line"></span><br><span class="line">图6-4 平均教育经费的箱形图</span><br><span class="line"></span><br><span class="line">除了箱形图外，在R语言中，还可以使用fivenum函数来分析前面说的5个点的概要。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > fivenum(cp$单机成本

    .元

    .台

    .) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分析结果如下，它们分别是最小值、下四分位数、中位数、上四分位数、最大值。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [1] 296.210 304.275 307.225 313.915 346.230 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 6.2 数据分布趋势案例解析</span><br><span class="line"></span><br><span class="line">本节继续以产品成本和全国就业调查数据为例，剖析这两类数据的分布趋势。</span><br><span class="line"></span><br><span class="line">#### 6.2.1 平均值</span><br><span class="line"></span><br><span class="line">下面使用R语言的mean函数统计就业调查数据中的“平均劳动报酬”。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > mean(jiuye[["平均劳动报酬

    "]])
    [1] 42365.36 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">同时，还可以统计一下“平均劳动报酬”和“平均教育经费”。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > cbind(jiuye[["平均劳动报酬

    "]],jiuye[["平均教育经费

    "]])
    > apply(jiuyeinfo,2,mean)
    [1] 42365.365   391.035 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 6.2.2 加权平均值</span><br><span class="line"></span><br><span class="line">加权平均数与算术平均数类似，但数据集中的每个数据对于平均数的贡献并不是相等的，有些数据要比其他的数据更加重要。因此，在加权平均法中，每个数据都有其相对应的权重。</span><br><span class="line"></span><br><span class="line">以产品成本数据为例，剖析加权平均值。首先读取产品成本数据。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > read.table("cp.csv",,header=TRUE,sep=",")->cp
    > cp
       序号

     产量

    .台

    . 单机成本

    .元

    .台

    .
    1     1     4300          346.23
    2     2     4004          343.34
    3     3     4300          327.46
    4     4     5016          313.27
    5     5     5511          310.75
    6     6     5648          307.61
    7     7     5876          314.56
    8     8     6651          305.72
    9     9     6024          310.82
    10   10     6194          306.83
    11   11     7558          305.11
    12   12     7381          300.71
    13   13     6950          306.84
    14   14     6471          303.44
    15   15     6354          298.03
    16   16     8000          296.21 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，求产品平均单位成本。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > weighted.mean(cp$单机成本

    .元

    .台

    . ,cp$产量

    .台

    .)
    [1] 309.9866

* * *

#### 6.2.3 数据排序

在R语言中，使用sort函数进行数据排序。比如，要对“平均教育经费”进行排序，可采用如下代码：

<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; sort(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">  [1]     0     0     0     2     2     2     6     7     7     8    10    13</span><br><span class="line"> [13]    27    30    31    31    31    32    35    37    38    42    42    44</span><br><span class="line"> [25]    46    50    51    55    55    62    63    65    66    66    67    71</span><br><span class="line"> [37]    72    72    75    75    76    80    89    92    93    93    95    95</span><br><span class="line"> [49]   100   100   100   100   100   105   109   110   111   115   118   119</span><br><span class="line"> [61]   125   136   138   143   144   145   146   147   147   149   149   157</span><br><span class="line"> [73]   159   161   161   162   162   166   168   168   168   172   177   177</span><br><span class="line"> [85]   182   184   186   188   190   196   196   196   200   201   206   210</span><br><span class="line"> [97]   210   212   212   221   224   225   230   230   241   241   247   247</span><br><span class="line">[109]   258   260   267   267   276   276   277   282   295   295   298   299</span><br><span class="line">[121]   303   304   305   306   308   314   315   317   330   332   337   340</span><br><span class="line">[133]   341   342   348   367   369   371   374   374   389   389   396   402</span><br><span class="line">[145]   405   409   416   422   422   423   431   436   443   454   455   461</span><br><span class="line">[157]   466   470   486   502   522   524   535   551   551   554   555   557</span><br><span class="line">[169]   563   571   582   645   679   682   692   722   738   753   768   782</span><br><span class="line">[181]   818   830   832   840   840   858   890   890   890   986   995  1096</span><br><span class="line">[193]  1131  1198  1255  1469  1553  2087  2564 12645</span><br></pre></td></tr></table></figure>

</details>

<p>排序后，可以初步发现，这些行业的教育经费中，最大的有12645，而最小的除0之外还有2，不同行业之间的教育经费差异很大。</p>
<p>也可以改变排序顺序，通过指定decreasing参数为TRUE，实现按从大到小的顺序排列。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  &gt; sort(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">,decreasing=TRUE)</span><br><span class="line">  [1] 12645  2564  2087  1553  1469  1255  1198  1131  1096   995   986   890</span><br><span class="line"> [13]   890   890   858   840   840   832   830   818   782   768   753   738</span><br><span class="line"> [25]   722   692   682   679   645   582   571   563   557   555   554   551</span><br><span class="line"> [37]   551   535   524   522   502   486   470   466   461   455   454   443</span><br><span class="line"> [49]   436   431   423   422   422   416   409   405   402   396   389   389</span><br><span class="line"> [61]   374   374   371   369   367   348   342   341   340   337   332   330</span><br><span class="line"> [73]   317   315   314   308   306   305   304   303   299   298   295   295</span><br><span class="line"> [85]   282   277   276   276   267   267   260   258   247   247   241   241</span><br><span class="line"> [97]   230   230   225   224   221   212   212   210   210   206   201   200</span><br><span class="line">[109]   196   196   196   190   188   186   184   182   177   177   172   168</span><br><span class="line">[121]   168   168   166   162   162   161   161   159   157   149   149   147</span><br><span class="line">[133]   147   146   145   144   143   138   136   125   119   118   115   111</span><br><span class="line">[145]   110   109   105   100   100   100   100   100    95    95    93    93</span><br><span class="line">[157]    92    89    80    76    75    75    72    72    71    67    66    66</span><br><span class="line">[169]    65    63    62    55    55    51    50    46    44    42    42    38</span><br><span class="line">[181]    37    35    32    31    31    31    30    27    13    10     8     7</span><br><span class="line">[193]     7     6     2     2     2     0     0     0</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-4-中位数"><a href="#6-2-4-中位数" class="headerlink" title="6.2.4 中位数"></a>6.2.4 中位数</h4><p>中位数比平均值更有稳健性，因为它不受偏态分布的影响。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; median(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)#中位数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 222.5</span><br><span class="line">&gt; mean(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)#平均数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[1] 391.035</span><br></pre></td></tr></table></figure>

</details>

<p>教育经费的中位数222.5与它的平均值391.035有一定差距，这说明平均教育经费不是对称分布的。</p>
<h4 id="6-2-5-极差、半极差"><a href="#6-2-5-极差、半极差" class="headerlink" title="6.2.5 极差、半极差"></a>6.2.5 极差、半极差</h4><p>极差是一组数据中最大数据与最小数据的差，用来刻画一组数据的离散程度，反映变量分布的变异范围和离散幅度，在样本总体中任何两个单位的标准值之差都不能超过极差。同时，它还能体现一组数据波动的范围。下面的代码计算“平均教育经费”的极差。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; max(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-min(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 12645</span><br></pre></td></tr></table></figure>

</details>

<p>相对极差而言，四分位数间距（上四分位数与下四分位数之差）更稳定，它不受两端个别极大值或极小值的影响，可理解为中间50%观察值的极差，因此又被称为半极差。</p>
<p>四分位数是统计学中分位数的一种，即把所有数值由小到大排列并分成4等份，处于3个分隔点位置的得分就是四分位数，下四分位数是所有数据由小到大排列后处于25%位置的数，上四分位数是所有数据由小到大排列后处于75%位置的数。四分位数在R语言中用quantile函数求解，下面的代码计算了“平均教育经费”和“平均劳动报酬”的四分位数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; quantile(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">     0%     25%     50%     75%    100% </span><br><span class="line">0.0   100.0   222.5   425.0 12645.0 </span><br><span class="line">&gt; quantile(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">      0%      25%      50%      75%     100% </span><br><span class="line"> 13624.0  28607.5  37681.0  51762.0 150098.0</span><br></pre></td></tr></table></figure>

</details>

<p>变异度反映数据围绕中心位的离散度，四分位数间距数值越大，变异度越大，反之，变异度越小。在R语言中使用IQR函数求解四分位数间距，下面的代码计算“平均教育经费”和“平均劳动报酬”的四分位数间距。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; IQR(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 325</span><br><span class="line">&gt; IQR(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 23154.5</span><br></pre></td></tr></table></figure>

</details>

<p>从执行结果来看，“平均教育经费”相比“平均劳动报酬”变异度小很多。</p>
<h4 id="6-2-6-方差"><a href="#6-2-6-方差" class="headerlink" title="6.2.6 方差"></a>6.2.6 方差</h4><p>方差是重要的数据分散程度度量指标。其计算公式为：</p>
<p><img src="Image00142.jpg" alt></p>
<p>在R语言中，可使用var函数统计方差。下面的代码计算“平均教育经费”的方差。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> &gt; var(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 883263.6</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-7-标准差"><a href="#6-2-7-标准差" class="headerlink" title="6.2.7 标准差"></a>6.2.7 标准差</h4><p>标准差也是重要的数据分散程度度量指标。其计算公式为：</p>
<p><img src="Image00143.jpg" alt></p>
<p>在R语言中使用sd函数统计标准差。下面的代码计算“平均教育经费”的标准差。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> &gt; sd(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 939.821</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-8-变异系数、样本平方和"><a href="#6-2-8-变异系数、样本平方和" class="headerlink" title="6.2.8 变异系数、样本平方和"></a>6.2.8 变异系数、样本平方和</h4><p>1.变异系数</p>
<p>变异系数，又称“离散系数”，是概率分布离散程度的一个归一化量度，其定义为标准差与平均值之比。变异系数的计算公式为：</p>
<p><img src="Image00144.jpg" alt></p>
<p>上式中S表示标准差，x表示平均值。变异系数越小，变异程度越小；反之，变异系数越大，变异程度越大。下面的代码计算了“平均教育经费”的变异系数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; sd(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)/mean(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 2.403419</span><br></pre></td></tr></table></figure>

</details>

<p>再看看“平均劳动报酬”的变异系数。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; sd(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)/mean(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">[1] 0.4916487</span><br></pre></td></tr></table></figure>

</details>

<p>可见，“平均教育经费”相对于“平均劳动报酬”分布更分散，因为它的变异系数更高。</p>
<p>2.样本平方和</p>
<p>样本校正平方和（CSS）为样本与均值差的平方求和。下面的代码计算“平均教育经费”的样本校正平方和。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; sum((jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">-mean(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">))^2)</span><br><span class="line">[1] 175769451</span><br></pre></td></tr></table></figure>

</details>

<p>样本未校正平方和（USS）为样本值平方的求和。下面的代码计算了“平均教育经费”的样本未校正平方和。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; sum(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">^2)</span><br><span class="line">[1] 206351125</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-2-9-偏度系数、峰度系数"><a href="#6-2-9-偏度系数、峰度系数" class="headerlink" title="6.2.9 偏度系数、峰度系数"></a>6.2.9 偏度系数、峰度系数</h4><p>1.偏度系数</p>
<p>在统计学中，偏度系数是用于衡量实数随机变量概率分布的不对称性的。偏度的值可以为正，可以为负，是无量纲的量，其取值通常为-3~+3，其绝对值越大，表明偏斜程度越大。均值右侧更分散的数据偏度系数为正，左侧更分散的数据偏度系数为负。</p>
<p>偏度系数的计算公式为：</p>
<p><img src="Image00145.jpg" alt></p>
<p>在R语言中，可用如下代码计算“平均教育经费”的偏度系数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;mymean</span><br><span class="line">&gt; sd(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;mysd</span><br><span class="line">&gt; length(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;myn</span><br><span class="line">&gt; jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">-&gt;x</span><br><span class="line">&gt; myn/((myn-1)*(myn-2))*sum((x-mymean)^3)/mysd^3</span><br><span class="line">[1] 11.36649</span><br></pre></td></tr></table></figure>

</details>

<p>2.峰度系数</p>
<p>峰度系数衡量实数随机变量概率分布的峰态，峰度高就意味着方差增大是由低频度的大于或小于平均值的极端差值引起的。当数据分布为正态分布时，峰度系数近似为0；当数据分布较正态分布的尾部更分散时，峰度系数为正，两侧的极端数据较多；除此以外，峰度系数为负，两侧的极端数据较少。</p>
<p>峰度系数计算公式为：</p>
<p><img src="Image00146.jpg" alt></p>
<p>在R语言中，可用如下代码计算“平均教育经费”的峰度系数。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;mymean</span><br><span class="line">&gt; sd(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;mysd</span><br><span class="line">&gt; length(jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">)-&gt;myn</span><br><span class="line">&gt; jiuye$平均教育经费</span><br><span class="line"></span><br><span class="line">-&gt;x</span><br><span class="line">&gt;((myn*(myn+1))/((myn-1)*(myn-2)*(myn-3))*sum((x-mymean)^4)/mysd^4-(3*(myn-1)^2)/((myn-2)*(myn-3)))</span><br><span class="line">[1] 146.8809</span><br></pre></td></tr></table></figure>

</details>

<h3 id="6-3-正态分布案例解析"><a href="#6-3-正态分布案例解析" class="headerlink" title="6.3 正态分布案例解析"></a>6.3 正态分布案例解析</h3><h4 id="6-3-1-正态分布函数"><a href="#6-3-1-正态分布函数" class="headerlink" title="6.3.1 正态分布函数"></a>6.3.1 正态分布函数</h4><p>对于一维实随机变量X，设它的累积分布函数是FX (x)。如果存在可测函数fX (x)，满足：</p>
<p><img src="Image00147.jpg" alt></p>
<p>那么X是一个连续型随机变量，并且fX (x)是它的概率密度函数。</p>
<p>累积分布函数，又叫累计分布函数，是概率密度函数的积分，能完整地描述一个实随机变量X的概率分布情况。对于所有实数x，累积分布函数的定义如下：</p>
<p><img src="Image00148.jpg" alt></p>
<p>正态分布的累积分布函数为：</p>
<p><img src="Image00149.jpg" alt></p>
<p>其中，μ是均值，σ是方差。</p>
<p>正态分布的概率密度曲线通常如图6-5所示。</p>
<p><img src="Image00150.jpg" alt></p>
<p>图6-5 正态分布的概率密度曲线</p>
<p>说到正态分布，不得不提一下偏态分布，偏态分布是指频数分布不对称，集中位置偏向于一侧，若集中位置偏向数值小的一侧，则称为正偏态分布；如果集中位置偏向数值大的一侧，则称为负偏态分布。如图6-6所示，左边为负偏态，右边为正偏态。</p>
<p><img src="Image00151.jpg" alt></p>
<p>图6-6 偏态分布</p>
<h4 id="6-3-2-峰度系数分析"><a href="#6-3-2-峰度系数分析" class="headerlink" title="6.3.2 峰度系数分析"></a>6.3.2 峰度系数分析</h4><p>可用峰度系数计算“平均劳动报酬”相对于“平均教育经费”哪个更接近正态分布。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)-&gt;mymean</span><br><span class="line">&gt; sd(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)-&gt;mysd</span><br><span class="line">&gt;  length(jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">)-&gt;myn</span><br><span class="line">&gt; jiuye$平均劳动报酬</span><br><span class="line"></span><br><span class="line">-&gt;x</span><br><span class="line">&gt;((myn*(myn+1))/((myn-1)*(myn-2)*(myn-3))*sum((x-mymean)^4)/mysd^4-(3*(myn-1)^2)/((myn-2)*(myn-3)))</span><br><span class="line">[1] 5.417817</span><br></pre></td></tr></table></figure>

</details>

<p>上面计算出了“平均劳动报酬”的峰度系数为5.417817，“平均教育经费”的峰度系数为146.8809（见6.2.9节）。这两个峰度系数表明，“平均劳动报酬”相对于“平均教育经费”更接近正态分布。</p>
<p>从下面的分析中可以发现，产品产量最适合正态分布模型，因为它的峰度系数仅为-0.6830728，非常接近正态分布。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt; sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt; length(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;myn</span><br><span class="line">&gt; cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.-&gt;x</span><br><span class="line">&gt;((myn*(myn+1))/((myn-1)*(myn-2)*(myn-3))*sum((x-mymean)^4)/mysd^4-(3*(myn-1)^2)/((myn-2)*(myn-3)))</span><br><span class="line">[1] -0.6830728</span><br></pre></td></tr></table></figure>

</details>

<h4 id="6-3-3-累积分布概率"><a href="#6-3-3-累积分布概率" class="headerlink" title="6.3.3 累积分布概率"></a>6.3.3 累积分布概率</h4><p>在使用pnorm求产品产量的分布函数时，对应的每个实数随机变量都有其累积分布概率。下面的代码计算产品产量的累积分布概率。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt; sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt; length(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;myn</span><br><span class="line">&gt; cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.-&gt;x</span><br><span class="line">&gt;x</span><br><span class="line"> [1] 4300 4004 4300 5016 5511 5648 5876 6651 6024 6194 7558 7381 6950 6471</span><br><span class="line">[15] 6354 8000</span><br><span class="line">&gt; pnorm(x,mymean,mysd)</span><br><span class="line"> [1] 0.07435941 0.04519643 0.07435941 0.20013522 0.33567136 0.37868351</span><br><span class="line"> [7] 0.45345196 0.70390728 0.50306546 0.55994848 0.90310411 0.87500925</span><br><span class="line">[13] 0.78449233 0.64954647 0.61239714 0.95270286</span><br></pre></td></tr></table></figure>

</details>

<p>为了更好地观察效果，再绘制一张产品产量的累积分布概率的散点图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; plot(x,pnorm(x,mymean,mysd))</span><br></pre></td></tr></table></figure>

</details>

<p>绘制结果如图6-7所示。</p>
<p><img src="Image00152.jpg" alt></p>
<p>图6-7 产品产量累积分布</p>
<h4 id="6-3-4-概率密度函数"><a href="#6-3-4-概率密度函数" class="headerlink" title="6.3.4 概率密度函数"></a>6.3.4 概率密度函数</h4><p>1.概率密度概述</p>
<p>一个连续型随机变量的概率密度函数（简称为密度函数）是描述这个随机变量的输出值在某一个确定的取值点附近的可能性的函数。随机变量的取值落在某个区域之内的概率则是概率密度函数在这个区域上的积分，当概率密度函数存在的时候，累积分布函数则是概率密度函数的积分。</p>
<p>正态分布的概率密度函数为：</p>
<p><img src="Image00153.jpg" alt></p>
<p>其中，μ是均值，σ是方差。</p>
<p>其概率密度曲线关于x=μ对称。</p>
<p>2.概率密度函数计算</p>
<p>在R语言中，使用dnorm（变量，平均值，标准差）求解正态分布概率密度函数。下面的代码计算产品产量的概率密度。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt; sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt; length(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;myn</span><br><span class="line">&gt; cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.-&gt;x </span><br><span class="line">&gt; dnorm(x,mymean,mysd)</span><br><span class="line"> [1] 1.184240e-04 8.009886e-05 1.184240e-04 2.358477e-04 3.070239e-04</span><br><span class="line"> [6] 3.202882e-04 3.336542e-04 2.910430e-04 3.359337e-04 3.321435e-04</span><br><span class="line">[11] 1.444115e-04 1.733374e-04 2.463862e-04 3.120546e-04 3.225207e-04</span><br><span class="line">[16] 8.307503e-05</span><br></pre></td></tr></table></figure>

</details>

<p>查看产品产量均值，得到如下结果：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; mymean</span><br><span class="line">[1] 6014.875</span><br></pre></td></tr></table></figure>

</details>

<p>绘制散点图如图6-8所示。可以看到该曲线接近于以6014.875为对称点的对称分布。绘制代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;plot(x,dnorm(x,mymean,mysd))</span><br></pre></td></tr></table></figure>

</details>

<p>此外，rnorm还可以返回正态分布随机数，调用格式为rnorm（长度，平均值，标准差）。比如：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;rnorm(50,0,1)-&gt;rx</span><br><span class="line">&gt; plot(rx,dnorm(rx))</span><br></pre></td></tr></table></figure>

</details>

<p>如图6-9所示是一个经典的正态密度曲线，从曲线上看就像一个驼峰。</p>
<p><img src="Image00154.jpg" alt></p>
<p>图6-8 产品产量概率密度图</p>
<p><img src="Image00155.jpg" alt></p>
<p>图6-9 正态密度曲线</p>
<h4 id="6-3-5-分位点"><a href="#6-3-5-分位点" class="headerlink" title="6.3.5 分位点"></a>6.3.5 分位点</h4><p>分位点分为上α分位点与下α分位点。</p>
<p>1.下α分位点</p>
<p>可从概率密度函数的角度理解下α分位点。设连续随机变量X的累积分布函数为F(x)，密度函数为f(x)，则有：</p>
<p><img src="Image00156.jpg" alt></p>
<p>上式的含义为：连续随机变量X小于等于Zα 的概率为α。在这里，称Zα 是X的下α分位点。</p>
<p>下面计算产量分布的下α分位点。设下α分位点的α=25%=0.25，需要分析产量小于多少的概率为25%。</p>
<p>计算产量分布的下α分位点（α=25%），可如下调用qnorm函数（其中，mean为平均值，sd为标准差）：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qnorm(0.25,mean,sd)</span><br></pre></td></tr></table></figure>

</details>

<p>具体代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt;qnorm(0.25,mean=mymean,sd=mysd)</span><br><span class="line">[1] 5213.9</span><br></pre></td></tr></table></figure>

</details>

<p>上面的计算结果表明，产量&lt;5213.9的概率为25%。</p>
<p>2.上α分位点</p>
<p>上α分位点的公式为：</p>
<p><img src="Image00157.jpg" alt></p>
<p>其中，Zα 为X的上α分位点。</p>
<p>分析上α分位点的公式可发现，上α分位点的计算与下α分位点有关，比如：计算上α分位点（α=25%）可转化为计算下α分位点（α=1-25%=75%）。</p>
<p>下面计算产量分布的上α分位点。设上α分位点的α=25%，需要分析产量大于多少的概率为25%。</p>
<p>计算产量分布的上α分位点（α=25%），可如下调用qnorm函数（其中，mean为平均值，s d为标准差）：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qnorm(1-0.25,mean,sd)</span><br></pre></td></tr></table></figure>

</details>

<p>具体代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt;sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt;qnorm(0.75,mean=mymean,sd=mysd)</span><br><span class="line">[1] 6815.85</span><br></pre></td></tr></table></figure>

</details>

<p>上面的计算结果表明，产量&gt;6815.85的概率为25%，即上α分位点的公式中，Zα 为产量6815.85，上α分位点的α为0.25，可用下式表示：</p>
<p>P(x&gt;Zα )=p(x&gt;6815.85)=0.25</p>
<p>3.绘效果图</p>
<p>1）通过下面R语句绘制如图6-10所示的产品产量的概率密度图，P(x&gt;0.25)为图6-10中的阴影面积（根据积分的几何意义，累积分布函数F(x)是密度函数f(x)的积分，图中若干点组成了密度函数曲线，而曲线与X轴围成的面积则为累积分布）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt;sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt; cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.-&gt;x </span><br><span class="line">&gt;plot(x,dnorm(x,mymean,mysd))</span><br><span class="line">&gt;abline(v=6815.85)</span><br></pre></td></tr></table></figure>

</details>

<p>2）绘制产品产量的累积分布图（如图6-11所示）。可绘制一个产品产量的上α(α=0.25）分位点和下α(α=0.25）分位点的效果图。绘制代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; mean(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mymean</span><br><span class="line">&gt;sd(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)-&gt;mysd</span><br><span class="line">&gt; cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.-&gt;x </span><br><span class="line">&gt;plot(x,pnorm(x,mymean,mysd)) </span><br><span class="line">&gt;abline(v=6815.85)</span><br><span class="line">&gt;abline(v=5213.85)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00158.jpg" alt></p>
<p>图6-10 产品产量的上α分位点</p>
<p><img src="Image00159.jpg" alt></p>
<p>图6-11 产量的上α分位点和下α分位点</p>
<p>分析绘制图6-10与图6-11所示的结果，能较直观地验证刚才得到的结论：上α(α=0.25）分位点表明产量&gt;6815.85的概率为25%，而下α(α=0.25）分位点表明产量&lt;5213.9的概率为25%。</p>
<h4 id="6-3-6-频率直方图"><a href="#6-3-6-频率直方图" class="headerlink" title="6.3.6 频率直方图"></a>6.3.6 频率直方图</h4><p>在R语言中，可使用hist语句（设freq参数为TRUE）生成频率直方图。下面的代码绘制“平均劳动报酬”的频率直方图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> &gt; hist(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]],freq=TRUE)</span><br></pre></td></tr></table></figure>

</details>

<p>绘制结果如图6-12所示。</p>
<h4 id="6-3-7-核概率密度与正态概率分布图"><a href="#6-3-7-核概率密度与正态概率分布图" class="headerlink" title="6.3.7 核概率密度与正态概率分布图"></a>6.3.7 核概率密度与正态概率分布图</h4><p>1.核概率密度与正态概率</p>
<p>下面考虑让“平均劳动报酬”的概率密度与正态分布在一张图中显示出来，这样就能更好地看清数据的分布情况。示例代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; hist(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]],freq=FALSE)</span><br><span class="line">&gt; lines(density(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]]),col=&quot;red&quot;)</span><br><span class="line">&gt; x&lt;-c(0:ceiling(max(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]])))</span><br><span class="line">&gt; lines(x,dnorm(x,mean(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]]),sd(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]])),col=&quot;blue&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>绘制结果如图6-13所示。</p>
<p><img src="Image00160.jpg" alt></p>
<p>图6-12 平均劳动报酬的频率直方图</p>
<p><img src="Image00161.jpg" alt></p>
<p>图6-13 平均劳动报酬的概率密度与正态分布</p>
<p>从图6-13中可以看到，“平均劳动报酬”的偏度大于0，直方图偏左，属于偏态分布。</p>
<p>2.经验累积分布与正态分布</p>
<p>经验分布函数是指根据样本构造的概率分布函数。设x1 ，x2 ，…，xn 为一组样本，定义函数m(x)表示样本中小于或者等于x的样本个数，则称函数</p>
<p><img src="Image00162.jpg" alt></p>
<p>为样本x1 ，x2 ，…，xn 的经验分布函数。</p>
<p>下面的代码绘制“平均劳动报酬”的经验累积分布与正态分布。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; plot(ecdf(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]]),verticals=TRUE,do.p=FALSE)</span><br><span class="line">&gt; lines(x,pnorm(x,mean(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]]),sd(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]])),col=&quot;blue&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>绘制结果如图6-14所示。其中，光滑的线为累积正态分布曲线，不光滑的线为经验累积分布曲线。</p>
<h4 id="6-3-8-正态检验与分布拟合"><a href="#6-3-8-正态检验与分布拟合" class="headerlink" title="6.3.8 正态检验与分布拟合"></a>6.3.8 正态检验与分布拟合</h4><p>1.QQ图</p>
<p>QQ图可以测试数据分布是否近似为某种类型分布。如果近似于正态分布，则数据点接近下面方程表示的直线。</p>
<p>y=σx+μ</p>
<p>其中，σ为标准差，μ为平均数。</p>
<p>比如，可用它来测试“平均劳动报酬”分布是否近似于正态分布。在R语言中，使用qqnorm函数来画数据点图，使用qqline函数画这根直线，如图6-15所示。代码如下：</p>
<p><img src="Image00163.jpg" alt></p>
<p>图6-14 平均劳动报酬的经验累积分布与正态分布</p>
<p><img src="Image00164.jpg" alt></p>
<p>图6-15 平均劳动报酬分布QQ图</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; qqnorm([&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]])</span><br><span class="line">&gt; qqline(jiuye[[&quot;平均劳动报酬</span><br><span class="line"></span><br><span class="line">&quot;]])</span><br></pre></td></tr></table></figure>

</details>

<p>从图6-15来看，平均劳动报酬离标准正态分布还是有差距的。</p>
<p>相对于“平均劳动报酬”，产品产量就非常接近正态分布。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; qqnorm(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)</span><br><span class="line">&gt; qqline(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)</span><br></pre></td></tr></table></figure>

</details>

<p>绘制出的QQ图如图6-16所示。</p>
<p><img src="Image00165.jpg" alt></p>
<p>图6-16 产品产量QQ图</p>
<p>2.正态检验与分布拟合</p>
<p>1）W检验。W检验可以检验数据是否符合正态分布。在R语言中使用函数shapiro.test()进行正态W检验。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; shapiro.test(cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.)</span><br><span class="line">    Shapiro-Wilk normality test</span><br><span class="line">data:  cp$产量</span><br><span class="line"></span><br><span class="line">.台</span><br><span class="line"></span><br><span class="line">.</span><br><span class="line">W = 0.9671, p-value = 0.7903</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码中出现了p值，其作用是：当p值小于某个显著水平a（如0.05）时，认为样本不是来自于正态分布的总体。此例中，0.7903&gt;0.05，可认为产量是正态分布的。</p>
<p>2）Kolmogorov-Smirnov检验。Kolmogorov-Smirnov检验用于检验单一样本是否来自某一特定分布，比如检验一组数据是否为正态分布。它的检验方法是以样本数据的累计频数分布与特定理论分布做比较，若两者间的差距很小，则该样本取自某特定分布族。可比较一个频率分布f(x)与理论分布g(x)，或者两个观测值分布来完成检验。</p>
<p>可以从假设检验的角度来理解Kolmogorov-Smirnov检验，假设检验使用了一种类似于“反证法”的推理方法，它先假设总体中的某项假设成立，计算其会导致什么结果产生。若导致不合理现象发生，拒绝原先的假设；若没有导致不合理的现象发生，即不拒绝原假设，从而接受原假设。</p>
<p>对Kolmogorov-Smirnov检验而言，将原假设H0确定为：两个数据分布一致或者数据符合特定理论分布。用F0 (x)表示分布函数，Fn<br>(x)表示一组随机样本的累积概率函数，设D为F0 (x)与Fn (x)差距的最大值，定义如下：</p>
<p>D=max|Fn (x)-F0 (x)|</p>
<p>当实际观测值D&gt;D(n，α)时，则拒绝H0，否则接受H0假设。</p>
<p>在R语言中使用ks.test函数完成正态性检验。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ks.test(x, y, ...,alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;),</span><br><span class="line">exact = NULL)</span><br></pre></td></tr></table></figure>

</details>

<p>上述代码中有4个参数，第一个参数x为观测值向量；第二个参数y为第二观测值向量或者累计分布函数，或者一个真正的累积分布函数，如pnorm，只对连续CDF有效；第三个参数指明是单侧检验还是双侧检验；exact参数为NULL或者一个逻辑值，表明是否需要计算精确的P值。比如：要生成两个随机的正态分布，然后检验这两个分布是否是同一类型的分类。其示例代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; ks.test(rnorm(80),rnorm(40))</span><br><span class="line">        Two-sample Kolmogorov-Smirnov test</span><br><span class="line">data:  rnorm(80) and rnorm(40)</span><br><span class="line">D = 0.125, p-value = 0.7874</span><br><span class="line">alternative hypothesis: two-sided</span><br></pre></td></tr></table></figure>

</details>

<p>从上述代码可见，p值大于0.05，不拒绝原假设，因此可认为这两个分布是同一类型。</p>
<p>Kolmogorov-Smirnov检验要求待验分布是连续的，连续分布出现相同值的概率为0，也就是说，数据中若出现相同值，则连续分布的假设不成立。</p>
<h4 id="6-3-9-其他分布及其拟合"><a href="#6-3-9-其他分布及其拟合" class="headerlink" title="6.3.9 其他分布及其拟合"></a>6.3.9 其他分布及其拟合</h4><p>前面几节介绍了R语言函数对正态分布的支持（函数名除前缀外为norm）。除了正态分布外，R语言还支持对其他数据分布的分析和拟合，如下所示：</p>
<p>指数分布 rexp(n,rate=1)</p>
<p>gama分布 rgamma(n,shape,scale=1)</p>
<p>泊松分布 rpois(n,lambda)</p>
<p>Weibull分布 rweibull(n,shape,scale=1)</p>
<p>Cauchy分布 rcauchy(n,location=0,scale=1)</p>
<p>beta分布 rbeta(n,shape1,shape2)</p>
<p>S(tudent)分布 rt(n,df)  </p>
<p>Fisher-Snedecor rf(n,df1,df2)</p>
<p>Pearson rchisq(n,df)</p>
<p>二项式分布 rbinom(n,size,prob)</p>
<p>多项式分布 rmultinom(n,size,prob)</p>
<p>几何分布 rgeom(n,prob)</p>
<p>hypergeometric rhyper(nn,m,n,k)</p>
<p>logistic rlogis(n,location=0,scale=1)</p>
<p>lognormal rlnorm(n,meanlog=0,sdlog=1)</p>
<p>negative binomial rnbinom(n,size,prob)</p>
<p>uniform runif(n,min=0,max=1)</p>
<p>Wilcoxon’s statistics rwilcox(nn,m,n),rsignrank(nn,n)</p>
<p>对这些函数的调用格式是：前缀+函数名。</p>
<p>前缀规则如下：</p>
<p>密度函数：d</p>
<p>累计概率分布函数：p</p>
<p>分布函数的反函数：q</p>
<p>相同分布的随机数：r</p>
<h3 id="6-4-多变量分析"><a href="#6-4-多变量分析" class="headerlink" title="6.4 多变量分析"></a>6.4 多变量分析</h3><p>多变量分析是统计分析方法中的一种，通常应用于数据同时存在多个变量（因素、指标）的场景，是对单变量统计分析的发展。</p>
<h4 id="6-4-1-多变量数据分析"><a href="#6-4-1-多变量数据分析" class="headerlink" title="6.4.1 多变量数据分析"></a>6.4.1 多变量数据分析</h4><p>多变量数据分析也称为多元数据分析，是指对多个变量同时进行分析和可视化操作。</p>
<p>1.求职情况散点图矩阵</p>
<p>在R语言中，当A是一个数值型矩阵或数据框时，可使用pairs(A)语句绘制两列之间的散点图矩阵。下面以求职情况为例，讲解如何使用散点图矩阵来展示多变量数据，表6-3为第二季度市场求职指数情况表。</p>
<p>表6-3 第二季度市场求职指数情况表</p>
<p><img src="Image00166.jpg" alt></p>
<p><img src="Image00167.jpg" alt></p>
<p>输入以下R代码对表6-3的求职数据进行分析：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&gt; ejdqz&lt;-read.csv(&quot;ejdqz.csv&quot;)</span><br><span class="line">&gt; ejdqz</span><br><span class="line">   年度</span><br><span class="line"></span><br><span class="line"> 求职人数</span><br><span class="line"></span><br><span class="line"> 绝对求职指数</span><br><span class="line"></span><br><span class="line"> 相对求职指数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1 2008年</span><br><span class="line"></span><br><span class="line">  3045412          100          100</span><br><span class="line">2 2009年</span><br><span class="line"></span><br><span class="line">  3413202          112          112</span><br><span class="line">3 2010年</span><br><span class="line"></span><br><span class="line">  3902961          128          121</span><br><span class="line">4 2011年</span><br><span class="line"></span><br><span class="line">  3675531          121          106</span><br><span class="line">5 2012年</span><br><span class="line"></span><br><span class="line">  3765853          124          107</span><br><span class="line">6 2013年</span><br><span class="line"></span><br><span class="line">  3562515          117          100</span><br><span class="line">7 2014年</span><br><span class="line"></span><br><span class="line">  3350834          110           94</span><br><span class="line">&gt; pairs(ejdqz)#绘制散点图矩阵，结果如图</span><br><span class="line"></span><br><span class="line">6-17所示</span><br></pre></td></tr></table></figure>

</details>

<p>表6-3中求职数据的散点图矩阵如图6-17所示。</p>
<p>查看散点图矩阵有以下两种方式：</p>
<p>1）首先，固定代表某一变量的某一列（或代表某些变量的某几列），然后查看与代表其他某变量的某一行（或代表其他变量的某几行）交叉处的图。</p>
<p>2）首先，固定代表某一变量的某一行（或代表某些变量的某几行），然后查看与代表其他某变量的某一列（或代表其他变量的某几列）交叉处的图。</p>
<p>例如，可以定位于年度，假设需要查看图6-17所示的2012年的数据，就将目光定位于第一行，求职人数接近380万，而绝对求职指数略高于120，相对求职指数在105到110之间。又比如假设需要查看求职人数在340万以上，绝对求职指数在115以上的年份，这样就定位于求职人数和年份，先锁定于第1列和第3列，在第2列（求职人数）的第1行找到340万以上（刻度从左到右数的第2个位置以右）的部分，将该部分设为A区，第3列（绝对求职指数）的第1行找到115万以上（下面最后一行绝对求职指数列对应的刻度表上，从左到右数第4个位置以右）的部分，将该部分设为B区，在A区和B区分别可以找到3个点，A区和B区的3个点互相一一对应，这3个点都属于A、B两个区的共同点，查找这3个点对应的年份（右上角的年份刻度表）为2010、2011、2012。如果A区和B区仅能找到两个共同点，那么就查找这两个共同点所对应的年份。</p>
<p><img src="Image00168.jpg" alt></p>
<p>图6-17 求职散点图矩阵</p>
<p>分析图6-17可以看出，2008年到2010年期间的求职指数在上升，市场求职人数出现了扩张态势，在经历2011年到2012年的小波动后，从2012年开始相对求职指数在逐年下降，市场求职人数呈现收缩态势。</p>
<p>2.学生成绩散点图矩阵</p>
<p>首先，输入如下的R代码加载并显示学生成绩数据：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt; source&lt;-read.csv(&quot;xscj.csv&quot;)</span><br><span class="line">&gt; source</span><br><span class="line">   学号</span><br><span class="line"></span><br><span class="line"> 期末考试</span><br><span class="line"></span><br><span class="line"> 平时成绩</span><br><span class="line"></span><br><span class="line"> 性别</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1   201       60       74    1</span><br><span class="line">2   202       66       64    1</span><br><span class="line">3   203       91       82    0</span><br><span class="line">4   204       94       49    0</span><br><span class="line">5   205       60       88    0</span><br><span class="line">6   206       48       48    0</span><br><span class="line">7   207       74       84    0</span><br><span class="line">8   208       45       35    0</span><br><span class="line">9   209       97       89    1</span><br><span class="line">10  210       74       98    0</span><br><span class="line">11  211       67       64    0</span><br><span class="line">12  212       50       50    0</span><br><span class="line">13  213       85       94    1</span><br><span class="line">14  214       70       64    0</span><br></pre></td></tr></table></figure>

</details>

<p>然后，绘制散点图矩阵，代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; pairs(source)#如图</span><br><span class="line"></span><br><span class="line">6-18所示，性别为</span><br><span class="line"></span><br><span class="line">1则表示男，性别为</span><br><span class="line"></span><br><span class="line">0则表示女。</span><br></pre></td></tr></table></figure>

</details>

<p>学生成绩散点图矩阵如图6-18所示。</p>
<p><img src="Image00169.jpg" alt></p>
<p>图6-18 学生成绩散点图矩阵</p>
<p>从图6-18可以看出，第3行第2列的散点图表明：平时成绩与期末考试成绩有很大的线性相关性，平时成绩较好的，期末考试成绩也较好；平时成绩较差的，期末考试成绩普遍也较差。观察第3行第4列的散点图，可以看到男生（性别为1）的成绩分布比较均匀，范围大致为40分到95分，而女生（性别为0）的成绩分布则集中在两部分，第一部分为60分以下不及格的，这部分的比例相对于第二部分略小，第二部分集中在80分以上，这部分的比例较大。</p>
<p>3.学生成绩协同图</p>
<p>协同图（coplot）是一种多变量的探索性分析图形，R语句的基本形式为coplot(y~x|z)，其中x和y是数值型向量，z是同长度的因子，对于z的每一水平，均绘制相应组的x和y的散点图。下面按性别分组来绘制学生成绩的协同图。</p>
<p>首先，设置因子，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">&gt; source&lt;-read.csv(&quot;xscj.csv&quot;)</span><br><span class="line">&gt; attach(source)</span><br><span class="line">&gt; factor(性别</span><br><span class="line"></span><br><span class="line">,labels = c(&quot;女</span><br><span class="line"></span><br><span class="line">&quot;,&quot;男</span><br><span class="line"></span><br><span class="line">&quot;))-&gt;sex</span><br><span class="line">&gt; sex</span><br><span class="line"> [1] 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[25] 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 女</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"> 男</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Levels: 女</span><br><span class="line"></span><br><span class="line"> 男</span><br></pre></td></tr></table></figure>

</details>

<p>然后，以性别来分组，绘制图形，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; coplot(平时成绩~期末考试</span><br><span class="line"></span><br><span class="line">|sex)</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-19所示。</p>
<p>从图6-19可以看出，男生的平时成绩与期末考试成绩更成线性关系，若男生平时成绩不错，期末考试的成绩也不错。而女生对于这点则不是非常明显，尤其是在平时成绩及格的情况下，平时成绩好并不意味着期末考试的成绩一定会好。</p>
<p>4.学生成绩点图</p>
<p>首先，设置因子，R代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; source&lt;-read.csv(&quot;xscj.csv&quot;)</span><br><span class="line">&gt; attach(source)</span><br><span class="line">&gt; factor(cut(平时成绩</span><br><span class="line"></span><br><span class="line">,5))-&gt;pjcj</span><br></pre></td></tr></table></figure>

</details>

<p>然后，分区段绘制全部学生平时成绩的点图：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; dotchart(table(pjcj))</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-20所示。</p>
<p>5.产品销量三维图</p>
<p>首先，读入产品销量数据，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; goods&lt;-read.csv(&quot;goods.csv&quot;)</span><br><span class="line">&gt; goods</span><br><span class="line">   地区编码</span><br><span class="line"></span><br><span class="line"> 月份</span><br><span class="line"></span><br><span class="line"> 销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1         1    1 1200</span><br><span class="line">2         1    2 3210</span><br><span class="line">3         1    3  123</span><br><span class="line">4         1    4 1111</span><br><span class="line">5         1    5  688</span><br><span class="line">6         1    6 2110</span><br><span class="line">7         1    7 1123</span><br><span class="line">8         1    8 6894</span><br><span class="line">9         1    9 1470</span><br><span class="line">10        1   10 1071</span><br><span class="line">11        1   11 2250</span><br><span class="line">12        1   12 1241</span><br><span class="line">13        2    1 2222</span><br><span class="line">14        2    2 1500</span><br><span class="line">15        2    3 3200</span><br><span class="line">16        2    4 1580</span><br><span class="line">17        2    5 5562……</span><br><span class="line"></span><br><span class="line">……</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;attach(goods)</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00170.jpg" alt></p>
<p>图6-19 成绩协同图</p>
<p><img src="Image00171.jpg" alt></p>
<p>图6-20 平时成绩的点图</p>
<p>然后，检查是否安装scatterplot3d库，安装过程如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;  source(&quot;&lt;http://bioconductor.org/biocLite.R&gt;</span><br><span class="line"></span><br><span class="line">&quot;)</span><br><span class="line">&gt;  biocLite(&quot;scatterplot3d&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>再然后，显示三维数据图：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; library(scatterplot3d)</span><br><span class="line">&gt; scatterplot3d(地区编码</span><br><span class="line"></span><br><span class="line">,月份</span><br><span class="line"></span><br><span class="line">,销量</span><br><span class="line"></span><br><span class="line">, highlight.3d=TRUE,pch=20,col.axis=&quot;blue&quot;, col.grid=&quot;lightblue&quot;,grid=TRUE,type=&quot;h&quot;,main=&quot;销量一览表</span><br><span class="line"></span><br><span class="line">&quot;,lab=c(4,12))</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-21所示。</p>
<p><img src="Image00172.jpg" alt></p>
<p>图6-21 销量一览表</p>
<p>由图6-21可见，销量比较好的主要是地区1的8月、地区2的5月与6月，地区3的销量不容乐观，处于滞销状态，地区4的销量稍微好一点，但销售情况仍然很差，地区1与地区2的销量不错，最高销量接近7000。</p>
<p>最后分析一下1号地区的销售形势，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt; subset(goods,地区编码</span><br><span class="line"></span><br><span class="line">==1)-&gt;diqu1</span><br><span class="line">&gt; diqu1[2:3]-&gt;no1fx</span><br><span class="line">&gt; no1fx</span><br><span class="line">   月份</span><br><span class="line"></span><br><span class="line"> 销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1     1 1200</span><br><span class="line">2     2 3210</span><br><span class="line">3     3  123</span><br><span class="line">4     4 1111</span><br><span class="line">5     5  688</span><br><span class="line">6     6 2110</span><br><span class="line">7     7 1123</span><br><span class="line">8     8 6894</span><br><span class="line">9     9 1470</span><br><span class="line">10   10 1071</span><br><span class="line">11   11 2250</span><br><span class="line">12   12 1241</span><br><span class="line">&gt; plot(no1fx,type=&quot;o&quot;,main=&quot;1号地区形势</span><br><span class="line"></span><br><span class="line">&quot;)</span><br><span class="line">&gt; abline(h=mean(no1fx$销量</span><br><span class="line"></span><br><span class="line">))</span><br><span class="line">&gt; axis(4,mean(no1fx$销量</span><br><span class="line"></span><br><span class="line">))</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-22所示。</p>
<p><img src="Image00173.jpg" alt></p>
<p>图6-22 1号地区销售形势图</p>
<p>观察图6-22可以看出，1号地区在2月和8月的销售情况不错，而3月和5月的销售形势则不容乐观。</p>
<p>6.产品销量气泡图</p>
<p>气泡图是一个将点表示为圆圈的散点图，与XY散点图类似，但可表现的数据信息量更多，最典型的应用是通过更改气泡的大小和颜色，使数据的探索更加方便。在R语言中，用symbols()函数作气泡图，具体的调用格式如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Symbols（</span><br><span class="line"></span><br><span class="line">x，</span><br><span class="line"></span><br><span class="line">y=NULL，</span><br><span class="line"></span><br><span class="line">circles，</span><br><span class="line"></span><br><span class="line">squares，</span><br><span class="line"></span><br><span class="line">rectangles，</span><br><span class="line"></span><br><span class="line">stars，</span><br><span class="line"></span><br><span class="line">thermometers，</span><br><span class="line"></span><br><span class="line">boxplots，</span><br><span class="line"></span><br><span class="line">inches=TRUE，</span><br><span class="line"></span><br><span class="line">add=FALSE，</span><br><span class="line"></span><br><span class="line">fg=par（</span><br><span class="line"></span><br><span class="line">&quot;col&quot;），</span><br><span class="line"></span><br><span class="line">bg=NA，</span><br><span class="line"></span><br><span class="line">xlab=NULL，</span><br><span class="line"></span><br><span class="line">ylab=NULL，</span><br><span class="line"></span><br><span class="line">main=NULL, xlim=NULL，</span><br><span class="line"></span><br><span class="line">ylim=NULL，</span><br><span class="line"></span><br><span class="line">...）</span><br></pre></td></tr></table></figure>

</details>

<p>以刚才的产品销量为例，输入以下R语言代码绘制产品销量气泡图：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt; symbols(月份</span><br><span class="line"></span><br><span class="line">,地区编码</span><br><span class="line"></span><br><span class="line">,circles =销量</span><br><span class="line"></span><br><span class="line">,xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,inches = .55)#绘制图，但不显示刻度。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; axis(1,at=1:12,las=3)        #x轴刻度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; axis(2,at=1:4,las=3)         #y轴刻度</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-23所示。</p>
<p><img src="Image00174.jpg" alt></p>
<p>图6-23 产品销量气泡图</p>
<p>观察图6-23可以看出，代表1号地区8月销量的气泡最大，表示销量最好，2号地区的5月和6月的销量差不多，且都比较大。</p>
<p>7.产品销量星图</p>
<p>星图的绘制方法如下：</p>
<p>1）若设变量数目为n个，则将圆周n等分，连接圆心和这n个分点，将形成n条半径，这些半径依次定义为变量的坐标轴，标以适当的刻度。</p>
<p>2）对给定的一次观测值，把n个变量值分别取在相应的坐标轴上，将它们连接成n个圆弧。</p>
<p>下面使用星图来分析4个地区各月份的销量，R代码如下：</p>
<p>首先，调用和整理数据。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">&gt; goods&lt;-read.csv(&quot;goods.csv&quot;)</span><br><span class="line">&gt; goods</span><br><span class="line">   地区编码</span><br><span class="line"></span><br><span class="line"> 月份</span><br><span class="line"></span><br><span class="line"> 销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1         1    1 1200</span><br><span class="line">2         1    2 3210</span><br><span class="line">3         1    3  123</span><br><span class="line">4         1    4 1111</span><br><span class="line">5         1    5  688</span><br><span class="line">6         1    6 2110</span><br><span class="line">7         1    7 1123</span><br><span class="line">8         1    8 6894</span><br><span class="line">9         1    9 1470</span><br><span class="line">10        1   10 1071</span><br><span class="line">11        1   11 2250</span><br><span class="line">12        1   12 1241</span><br><span class="line">13        2    1 2222</span><br><span class="line">14        2    2 1500……</span><br><span class="line"></span><br><span class="line">..</span><br><span class="line">&gt; yue4&lt;-subset(goods, 地区编码</span><br><span class="line"></span><br><span class="line">==4, select = c(销量</span><br><span class="line"></span><br><span class="line">))</span><br><span class="line">&gt; yue3&lt;-subset(goods, 地区编码</span><br><span class="line"></span><br><span class="line">==3, select = c(销量</span><br><span class="line"></span><br><span class="line">))</span><br><span class="line">&gt; yue2&lt;-subset(goods, 地区编码</span><br><span class="line"></span><br><span class="line">==2, select = c(销量</span><br><span class="line"></span><br><span class="line">))</span><br><span class="line">&gt; yue1&lt;-subset(goods, 地区编码</span><br><span class="line"></span><br><span class="line">==1, select = c(销量</span><br><span class="line"></span><br><span class="line">))</span><br><span class="line">&gt; row.names(mygoods)&lt;-c(1:4)</span><br><span class="line">&gt; mygoods</span><br><span class="line">     1    2    3    4    5    6    7    8    9   10   11   12</span><br><span class="line">1 1200 3210  123 1111  688 2110 1123 6894 1470 1071 2250 1241</span><br><span class="line">2 2222 1500 3200 1580 5562 5841 1860  981  658  789 1020 1120</span><br><span class="line">3 2144 2243  134  235  486  985  235 1020  558  995  886  398</span><br><span class="line">4 1820 1588 5440  470 1500  720  845  476  984  745  368  872</span><br></pre></td></tr></table></figure>

</details>

<p>然后调用stars函数绘制图形，通过将draw.segments参数设置为TRUE，指定绘制的星图是由圆弧连接而成的。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;stars(mygoods,draw.segments=TRUE)</span><br></pre></td></tr></table></figure>

</details>

<p>结果如图6-24所示。</p>
<p><img src="Image00175.jpg" alt></p>
<p>图6-24 产品销量星图</p>
<p>观察图6-24可以看出，1号地区和2号地区的销量最好。</p>
<h4 id="6-4-2-多元数据相关性分析"><a href="#6-4-2-多元数据相关性分析" class="headerlink" title="6.4.2 多元数据相关性分析"></a>6.4.2 多元数据相关性分析</h4><p>1.皮尔森相关系数与协方差</p>
<p>（1）皮尔森相关系数</p>
<p>皮尔森相关系数（Pearson correlation coefficient）也称皮尔森积矩相关系数，是一种线性相关系数，皮尔森相关系数是用来反映两个变量线性相关程度的统计量，用于度量两个变量X和Y之间的相关（线性相关），如表6-4所示。其值介于-1~1之间，负数为负相关，正数为正相关。</p>
<p>表6-4 皮尔森相关系数</p>
<p><img src="Image00176.jpg" alt></p>
<p>皮尔森相关系数的计算公式如下：</p>
<p><img src="Image00177.jpg" alt></p>
<p>上式中，分子是协方差，分子是两个变量标准差的乘积，X和Y的标准差都不为0。</p>
<p><img src="Image00178.jpg" alt></p>
<p>因此，也可将皮尔森相关系数的计算公式写成如下形式：</p>
<p><img src="Image00179.jpg" alt></p>
<p>皮尔森相关系数是对称的，即：ρX,Y =ρY,X 。</p>
<p>此外，可基于样本对协方差和标准差进行估计，可以得到样本相关系数r如下：</p>
<p><img src="Image00180.jpg" alt></p>
<p>利用样本相关系数推断总体中的两个变量是否相关，可以用t统计量对总体相关系数为0的原假设进行检验。若t检验显著，则拒绝原假设，即两个变量是线性相关的；若t检验不显著，则不能拒绝原假设，即两个变量不是线性相关的。</p>
<p>（2）协方差</p>
<p>协方差表示的是两个变量总体误差的方差，这与只表示一个变量误差的方差不同。如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么这两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么这两个变量之间的协方差就是负值。</p>
<p>（3）实例剖析</p>
<p>下面以某商品的销量及原料分析数据为例，分析原料对某商品销量的影响，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">&gt; read.csv(&quot;ABCgoods.csv&quot;)-&gt;mygoods</span><br><span class="line">&gt; mygoods</span><br><span class="line">  A原料</span><br><span class="line"></span><br><span class="line"> B原料</span><br><span class="line"></span><br><span class="line"> C原料</span><br><span class="line"></span><br><span class="line"> 商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1  0.85  0.13  0.02     4500</span><br><span class="line">2  0.33  0.23  0.44     1800</span><br><span class="line">3  0.64  0.24  0.12     3900</span><br><span class="line">4  0.38  0.12  0.50     1000</span><br><span class="line">5  0.10  0.20  0.70      740</span><br><span class="line">6  0.28  0.17  0.55      990</span><br><span class="line">7  0.15  0.80  0.05      910</span><br><span class="line">8  0.18  0.70  0.12      930 </span><br><span class="line">&gt; cov(mygoods)-&gt;myanalysis.cov# cov为协方差矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; cor(mygoods)-&gt;myanalysis.cor# cor为相关系数矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; myanalysis.cov</span><br><span class="line">                A原料</span><br><span class="line"></span><br><span class="line">         B原料</span><br><span class="line"></span><br><span class="line">         C原料</span><br><span class="line"></span><br><span class="line">     商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">A原料</span><br><span class="line"></span><br><span class="line">      0.06716964   -0.03470179   -0.03246786     368.2161</span><br><span class="line">B原料</span><br><span class="line"></span><br><span class="line">     -0.03470179    0.07174107   -0.03703929    -147.3554</span><br><span class="line">C原料</span><br><span class="line"></span><br><span class="line">     -0.03246786   -0.03703929    0.06950714    -220.8607商品销量</span><br><span class="line"></span><br><span class="line"> 368.21607143 -147.35535714 -220.86071429 2235941.0714</span><br><span class="line">&gt; myanalysis.cor</span><br><span class="line">              A原料</span><br><span class="line"></span><br><span class="line">      B原料</span><br><span class="line"></span><br><span class="line">      C原料</span><br><span class="line"></span><br><span class="line">   商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">A原料</span><br><span class="line"></span><br><span class="line">     1.0000000 -0.4998980 -0.4751737  0.9501366</span><br><span class="line">B原料</span><br><span class="line"></span><br><span class="line">    -0.4998980  1.0000000 -0.5245223 -0.3679187</span><br><span class="line">C原料</span><br><span class="line"></span><br><span class="line">    -0.4751737 -0.5245223  1.0000000 -0.5602393商品销量</span><br><span class="line"></span><br><span class="line">  0.9501366 -0.3679187 -0.5602393  1.0000000</span><br></pre></td></tr></table></figure>

</details>

<p>在R中可调用cor.test进行检测，它默认采用pearson检验（method参数），置信区间水平默认为0.95(conf.level)，p值&lt;0.05则拒绝原假设，并认为两变量线性相关。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">&gt; cor.test(~A原料</span><br><span class="line"></span><br><span class="line">+B原料</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  A原料</span><br><span class="line"></span><br><span class="line"> and B原料</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = -1.4138, df = 6, p-value = 0.2071</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> -0.8907805  0.3161398</span><br><span class="line">sample estimates:</span><br><span class="line">      cor </span><br><span class="line">-0.499898</span><br><span class="line">&gt; cor.test(~A原料</span><br><span class="line"></span><br><span class="line">+C原料</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  A原料</span><br><span class="line"></span><br><span class="line"> and C原料</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = -1.3228, df = 6, p-value = 0.2341</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> -0.8838848  0.3450297</span><br><span class="line">sample estimates:</span><br><span class="line">       cor </span><br><span class="line">-0.4751737</span><br><span class="line">&gt; cor.test(~A原料</span><br><span class="line"></span><br><span class="line">+商品销量</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  A原料</span><br><span class="line"></span><br><span class="line"> and 商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = 7.4634, df = 6, p-value = 0.0002985</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.7427838 0.9911796</span><br><span class="line">sample estimates:</span><br><span class="line">      cor </span><br><span class="line">0.9501366</span><br><span class="line">&gt;  cor.test(~C原料</span><br><span class="line"></span><br><span class="line">+商品销量</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  C原料</span><br><span class="line"></span><br><span class="line"> and 商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = -1.6567, df = 6, p-value = 0.1487</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> -0.9068866  0.2386486</span><br><span class="line">sample estimates:</span><br><span class="line">       cor </span><br><span class="line">-0.5602393</span><br><span class="line">&gt; cor.test(~B原料</span><br><span class="line"></span><br><span class="line">+商品销量</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  B原料</span><br><span class="line"></span><br><span class="line"> and 商品销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = -0.9692, df = 6, p-value = 0.3699</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> -0.8517618  0.4546201</span><br><span class="line">sample estimates:</span><br><span class="line">       cor </span><br><span class="line">-0.3679187</span><br><span class="line">&gt; cor.test(~B原料</span><br><span class="line"></span><br><span class="line">+C原料</span><br><span class="line"></span><br><span class="line">,data=mygoods)</span><br><span class="line">        Pearson&apos;s product-moment correlation</span><br><span class="line">data:  B原料</span><br><span class="line"></span><br><span class="line"> and C原料</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = -1.5091, df = 6, p-value = 0.182</span><br><span class="line">alternative hypothesis: true correlation is not equal to 0</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> -0.8974739  0.2857795</span><br><span class="line">sample estimates:</span><br><span class="line">       cor </span><br><span class="line">-0.5245223</span><br></pre></td></tr></table></figure>

</details>

<p>分析以上cor.test的调用结果，可以看出：</p>
<p>·A原料、B原料、C原料互相线性无关，应属于不需要按指定配比配置的。</p>
<p>·A原料与商品销量线性相关。</p>
<p>2.影响因素分组</p>
<p>下面利用相关性分析，来分析某类商品的网络销售情况，并将影响因素分组。</p>
<p>首先，读入数据：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt; read.csv(&quot;sales2.csv&quot;)-&gt;mysales</span><br><span class="line">&gt; mysales</span><br><span class="line">   价格</span><br><span class="line"></span><br><span class="line"> 好评率</span><br><span class="line"></span><br><span class="line"> 月平均评论数</span><br><span class="line"></span><br><span class="line"> 包装精美程度</span><br><span class="line"></span><br><span class="line">.1.3. 品牌知名度</span><br><span class="line"></span><br><span class="line">.1.3. 月平均销量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1    50     94          150                 3               3        350</span><br><span class="line">2   150     68          120                 2               2        290</span><br><span class="line">3   190     88          100                 2               2        160</span><br><span class="line">4  1500     85            5                 1               1         40</span><br><span class="line">5    69     98           40                 2               2         64</span><br><span class="line">6   800     73            3                 2               1         20</span><br><span class="line">7    32     88          180                 3               3        400</span><br><span class="line">8   500     90            6                 2               1         10</span><br><span class="line">9   182     68           19                 2               2         70</span><br><span class="line">10   23     89          190                 3               2        500</span><br></pre></td></tr></table></figure>

</details>

<p>然后，计算相关系数：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&gt; cor(mysales)</span><br><span class="line">                        价格</span><br><span class="line"></span><br><span class="line">     好评率</span><br><span class="line"></span><br><span class="line"> 月平均评论数</span><br><span class="line"></span><br><span class="line"> 包装精美程度</span><br><span class="line"></span><br><span class="line">.1.3.价格</span><br><span class="line"></span><br><span class="line">               1.0000000 -0.1648994   -0.6538897        -0.7769090好评率</span><br><span class="line"></span><br><span class="line">            -0.1648994  1.0000000    0.2529134         0.2933271月平均评论数</span><br><span class="line"></span><br><span class="line">      -0.6538897  0.2529134    1.0000000         0.8197505包装精美程度</span><br><span class="line"></span><br><span class="line">.1.3. -0.7769090  0.2933271    0.8197505         1.0000000品牌知名度</span><br><span class="line"></span><br><span class="line">.1.3.   -0.7531132  0.2556607    0.7921685         0.7619048月平均销量</span><br><span class="line"></span><br><span class="line">        -0.5897317  0.1777546    0.9798662         0.8104570</span><br><span class="line">                  品牌知名度</span><br><span class="line"></span><br><span class="line">.1.3. 月平均销量</span><br><span class="line"></span><br><span class="line">价格</span><br><span class="line"></span><br><span class="line">                   -0.7531132 -0.5897317好评率</span><br><span class="line"></span><br><span class="line">                  0.2556607  0.1777546月平均评论数</span><br><span class="line"></span><br><span class="line">            0.7921685  0.9798662包装精美程度</span><br><span class="line"></span><br><span class="line">.1.3.       0.7619048  0.8104570品牌知名度</span><br><span class="line"></span><br><span class="line">.1.3.         1.0000000  0.7291934月平均销量</span><br><span class="line"></span><br><span class="line">              0.7291934  1.0000000</span><br></pre></td></tr></table></figure>

</details>

<p>再然后，对各个指标的相关度进行分析。按相关度将指标进行分组，使相关系数高的指标归为同一组，找到出现除开1以外的绝对值最大相关度——月平均评论数与月平均销量的相关系数为0.9798662，包装精美程度.1.3.与月平均销量的相关系数为0.8104570，将这3个指标归为一组，然后找到价格与品牌知名度的相关系数0.7531132，将这两个指标归为一组，好评率为一组，这样一共分为了三组。</p>
<p>将每一个组内部的每个指标的权值设为不同的值（保证权值之和为1），分别设置如下：</p>
<p>1）第1组中月平均销量的权值为0.8，月平均评论数的权值为0.15，包装精美程度.1.3.的权值为0.05（计算时为3-包装精美程度，因为包装精美程度数字越小，表示越精美，指标是这样设计的）。</p>
<p>2）第2组，价格的权值为0.8，品牌知名度.1.3.的权值为0.2（计算时为3-品牌知名度，因为品牌知名度数字越小，表示越知名，指标是这样设计的）</p>
<p>3）第3组就一个指标好评率。不设权值。</p>
<p>最后，计算这3组的得分。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&gt; attach(mysales)</span><br><span class="line">&gt; group1&lt;-(月平均评论数</span><br><span class="line"></span><br><span class="line">*0.15+(3-包装精美程度</span><br><span class="line"></span><br><span class="line">.1.3.)*0.05+月平均销量</span><br><span class="line"></span><br><span class="line">*0.8)/3</span><br><span class="line">&gt; group2&lt;-((3-品牌知名度</span><br><span class="line"></span><br><span class="line">.1.3.)*0.2+价格</span><br><span class="line"></span><br><span class="line">*0.8)/2</span><br><span class="line">&gt; group3&lt;-好评率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; myavg=(group1*0.45+group2*0.1+group3*0.45)/3</span><br><span class="line">&gt; names(myavg)&lt;-c(1:10)</span><br><span class="line">&gt; sort(myavg,decreasing=TRUE)</span><br><span class="line">      10        4        7        1        2        3        6        8 </span><br><span class="line">35.08500 34.39917 30.97667 29.89167 24.70583 22.88917 22.44833 20.62083 </span><br><span class="line">  5        9 </span><br><span class="line">18.48583 15.57500分析</span><br><span class="line"></span><br><span class="line">sort函数的结果，可看出，按综合排名，从高到低的商品序号如下：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">10       4       7       1       2       3       6       8       5       9</span><br></pre></td></tr></table></figure>

</details>

<h3 id="6-5-小结"><a href="#6-5-小结" class="headerlink" title="6.5 小结"></a>6.5 小结</h3><p>对于统计中的描述性分析来说，最好的学习方法就是实践，光看理论比较难于理解。本章首先以实例的形式分折了正态分布函数、峰度系数、累计分布概率、概率密度函数及曲线、分位点、正态检验与分布拟合等数据统计指标；然后介绍了正态分布等分布模型；最后，讲解了多变量数据分析和可视化、数据相关性分析等知识。</p>
<h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><p>（1）下载本书例子中的美国地震台数据earthquakes.csv，对于其中震深Depth进行分析，绘制累计分布概率的散点图。</p>
<p>（2）下载本书例子中的美国地震台数据earthquakes.csv，对于其中震级Magnitude进行分析，分析概率密度。</p>
<p>（3）下载本书例子中的全国就业调查情况数据youxiangz.csv，分析“平均劳动报酬”的正态分析函数、峰度系数、累计分布概率、概率密度函数及曲线、直方图。</p>
<p>（4）下载本书例子中的商品销售情况数据sales2.csv，以价格为X轴，以月平均评论数为Y轴，绘制关于月平均销量的气泡图，分析价格和月平均评论数处于哪些区间内时，月平均销量较好。</p>
<p>（5）下载本书例子中的学生成绩数据xscj.csv，以性别、学号、期末考试为指标，绘制关于期末考试的三维图，分析哪些学生成绩比较好。</p>
<h2 id="第7章-假设检验与回归模型案例"><a href="#第7章-假设检验与回归模型案例" class="headerlink" title="第7章 假设检验与回归模型案例"></a>第7章 假设检验与回归模型案例</h2><h3 id="7-1-假设检验"><a href="#7-1-假设检验" class="headerlink" title="7.1 假设检验"></a>7.1 假设检验</h3><p>假设检验是除参数估计之外的另一类重要的统计推断问题，它认为小概率事件在一次试验中几乎是不可能发生的，即：对总体的某个假设是真实的，那么不利于或不能支持这一假设的事件在一次试验中几乎是不可能发生的；要是在一次试验中小概率事件发生了，那么就有理由怀疑这一假设的真实性，拒绝这一假设。具体来说，想检验其正确性的称为零假设（null hypothesis），零假设通常反映的是研究者对未知参数的看法，相对于零假设的其他论述则是对立假设（alternative hypothesis），它反映了执行检验者对参数可能数值的对立的看法，也就是说，对立假设通常才是研究者最想知道的。</p>
<p>假设检验的过程，可以用法庭审理的例子来说明：如果现在法庭上有一名被告，假设该被告是清白的，那么检察官必须要提出足够的证据证明被告的确有罪。在证明被告有罪前，被告是被假设为清白的，假设被告是清白的这个假设，就相当于零假设，假设被告是有罪的这个假设，则是对立假设。检察官提出的证据，是否足以确定该被告有罪，则需要经过检验。</p>
<h4 id="7-1-1-二项分布假设检验"><a href="#7-1-1-二项分布假设检验" class="headerlink" title="7.1.1 二项分布假设检验"></a>7.1.1 二项分布假设检验</h4><p>考察由n次随机试验组成的随机现象，它要同时满足以下条件：</p>
<p>·重复进行n次随机试验。</p>
<p>·n次试验相互独立。</p>
<p>·每次试验仅有两个可能的结果。</p>
<p>·每次试验成功的概率为p，失败的概率为1-p。</p>
<p>在上述四个条件下，假设X表示n次独立重复试验中成功出现的次数，显然X是可以取0，1，…，n等n+1个值的离散随机变量，这个分布称为二项分布，记为B(n，p)。</p>
<p>在二项分布中，设有k次成功和n-k次失败，k次成功可以出现于n次试验的任何一次，n次试验中正好得到k次成功的概率如下：</p>
<p><img src="Image00181.jpg" alt></p>
<p>在假设检验中，经常遇到非正态总体的统计数据，这类数据可使用二项分布的总体假设检验方法，下面以实例进行讲解。</p>
<p>1.游戏策略调整</p>
<p>某游戏的某区域内经常发生暴力PK事件，从而给在这个区域内做任务的新手玩家和某些老玩家带来了很多困扰，以往发生这类事件的概率为25%，对这个区域的游戏策略进行调整后，随机抽取了300多个玩家进行测试，结果有20个被迫卷入暴力PK，那么这个游戏策略的调整是否有效？</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; binom.test(x=20,n=300,p=0.25,alternative=&quot;less&quot;)</span><br><span class="line">        Exact binomial test</span><br><span class="line">data:  20 and 300</span><br><span class="line">number of successes = 20, number of trials = 300, p-value &lt; 2.2e-16</span><br><span class="line">alternative hypothesis: true probability of success is less than 0.25</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.00000000 0.09540198</span><br><span class="line">sample estimates:</span><br><span class="line">probability of success </span><br><span class="line">            0.06666667</span><br></pre></td></tr></table></figure>

</details>

<p>这里将原假设H0设为p≥0.25，而备择假设H1设为p&lt;0.25。观察以上结果，在95%的置信率基础上，p值&lt;2.2e-16&lt;0.05，因此可以认为该游戏策略的调整对维护这个区域的秩序起到了一定的效果。</p>
<p>2.游戏宝石出产检测</p>
<p>某网络游戏中有一区域为宝石采矿区，玩家在此开采宝石的比例应为高级宝石∶中级宝石∶低级宝石=3∶11∶23，抽取671个玩家的采矿记录，开采数量为70∶190∶411，请问实际出产比例是否符合理论要求？</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; chisq.test(c(70,190,411),p=c(3,11,23)/37)</span><br><span class="line">        Chi-squared test for given probabilities</span><br><span class="line">data:  c(70, 190, 411)</span><br><span class="line">X-squared = 5.0106, df = 2, p-value = 0.08165</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值为0.08165，结果大于0.05接受原假设，实际出产比例符合理论要求。</p>
<h4 id="7-1-2-数据分布检验"><a href="#7-1-2-数据分布检验" class="headerlink" title="7.1.2 数据分布检验"></a>7.1.2 数据分布检验</h4><p>1.正态分布检测</p>
<p>使用shapiro.test函数可检测数据的正态分布。例如，设显著性水平为0.05，检查以下数据是否为正态分布。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">12,22,67,89,56,10,124,235,77,88,66,79,80,82</span><br></pre></td></tr></table></figure>

</details>

<p>R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-c(12,22,67,89,56,10,124,235,77,88,66,79,80,82)</span><br><span class="line">&gt; shapiro.test(x)</span><br><span class="line">        Shapiro-Wilk normality test</span><br><span class="line">data:  x</span><br><span class="line">W = 0.8173, p-value = 0.008236</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值小于显著性水平0.05，因此可拒绝原假设，因为原假设为符合正态分布，因此可认为该数据不符合正态分布。</p>
<p>再来看一个例子，如下面R代码所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; shapiro.test(rnorm(100, mean = 5, sd = 3))</span><br><span class="line">        Shapiro-Wilk normality test</span><br><span class="line">data:  rnorm(100, mean = 5, sd = 3)</span><br><span class="line">W = 0.9914, p-value = 0.7787</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值大于显著性水平0.05，不能拒绝原假设，因此可认为该数据符合正态分布。</p>
<p>2.Kolmogorov-Smirnov检验</p>
<p>Kolmogorov-Smirnov检验（K-S检验）基于累积分布函数，用于检验一个经验分布是否符合某种理论分布或比较两个经验分布是否有显著性差异。下面以对某后台服务程序的稳定性检测为例进行讲解。</p>
<p>现对某服务器的某后台服务程序进行稳定性检测，记录8次无故障稳定工作的小时数，分别为：240、180、320、190、160、60、400、340，经估计它符合λ=1/290的指数分布，下面来验证一下稳定性的分布：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; ks.test(servtime,&quot;pexp&quot;,1/290)</span><br><span class="line">        One-sample Kolmogorov-Smirnov test</span><br><span class="line">data:  servtime</span><br><span class="line">D = 0.299, p-value = 0.394</span><br><span class="line">alternative hypothesis: two-sided</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值&gt;0.05，无法拒绝原假设，因此无故障稳定工作小时数符合该分布。</p>
<p>提示：R语言中，pexp是一个指数分布函数，指数分布有以下系列的R函数：</p>
<p>·dexp给出了密度：dpexp(x，rate=1，t=0，log=FALSE)</p>
<p>·pexp给出了分布函数：ppexp(q，rate=1，t=0，lower.tail=TRUE，log.p=FALSE)</p>
<p>·qexp给出了分位数功能：qpexp(p，rate=1，t=0，lower.tail=TRUE，log.p=FALSE)</p>
<p>·rexp给出了随机产生的偏离：rpexp(n，rate=1，t=0)</p>
<h4 id="7-1-3-正态总体均值检验"><a href="#7-1-3-正态总体均值检验" class="headerlink" title="7.1.3 正态总体均值检验"></a>7.1.3 正态总体均值检验</h4><p>假设某游戏服务器接受游戏客户端发来的报告，内容是某场景载入时间的报告（载入时间符合正态分布），平均载入时间要求小于225。现提取报告的部分数据，检验载入时间是否正常，设显著性水平为0.05，用R语言分析，代码如下（x为时间）：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-c(220,218,210,220,215,221,212,225,209,230,180,182,150,190,230,227,240,225)</span><br><span class="line">&gt; t.test(x, alternative = &quot;less&quot;, mu = 225)</span><br><span class="line">        One Sample t-test</span><br><span class="line">data:  x</span><br><span class="line">t = -2.5922, df = 17, p-value = 0.009493</span><br><span class="line">alternative hypothesis: true mean is less than 225</span><br><span class="line">95 percent confidence interval:</span><br><span class="line">     -Inf 220.5051</span><br><span class="line">sample estimates:</span><br><span class="line">mean of x </span><br><span class="line"> 211.3333</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述结果，p值为0.009493，小于显著性水平0.05，有理由拒绝原假设，原假设为平均载入时间大于225，因此，可选择备择假设，即：平均载入时间小于225。</p>
<p>也可将平均载入时间大于225设为备择假设，而平均载入时间小于225设为原假设，用R语言分析，代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; t.test(x, alternative = &quot;greater&quot;, mu = 225)</span><br><span class="line">        One Sample t-test</span><br><span class="line">data:  x</span><br><span class="line">t = -2.5922, df = 17, p-value = 0.9905</span><br><span class="line">alternative hypothesis: true mean is greater than 225</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 202.1616      Inf</span><br><span class="line">sample estimates:</span><br><span class="line">mean of x </span><br><span class="line"> 211.3333</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述结果，p值为0.9905，大于显著性水平0.05，无法拒绝原假设，原假设为平均载入时间小于225，因此，可认为平均载入时间小于225，载入时间正常。</p>
<h4 id="7-1-4-列联表"><a href="#7-1-4-列联表" class="headerlink" title="7.1.4 列联表"></a>7.1.4 列联表</h4><p>列联表是观测数据按两个或更多个属性（定性变量）分类时所列出的频数表。比如：对随机抽取的1000人按性别（男或女）及色觉（正常或色盲）两个属性分类，可以得到如表7-1所示的二行二列的列联表。</p>
<p>表7-1 性别与色觉列联表</p>
<p><img src="Image00182.jpg" alt></p>
<p>下面以满意度列联表为例进行讲解，表7-2是某类商品价格与客户满意度的列联表。</p>
<p>表7-2 满意度与价格列联表</p>
<p><img src="Image00183.jpg" alt></p>
<p>可通过列联表数据的独立性对价格与客户满意度之间的关系进行分析，在R语言中可通过chisq.test函数来完成检测：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; c(20,56,34,10,33,21,32,66,24)-&gt;x</span><br><span class="line">&gt; c(3,3)-&gt;dim(x)</span><br><span class="line">&gt; x</span><br><span class="line">     [,1] [,2] [,3]</span><br><span class="line">[1,]   20   10   32</span><br><span class="line">[2,]   56   33   66</span><br><span class="line">[3,]   34   21   24</span><br><span class="line">&gt;</span><br><span class="line">&gt; chisq.test(x)</span><br><span class="line">        Pearson&apos;s Chi-squared test</span><br><span class="line">data:  x</span><br><span class="line">X-squared = 6.8985, df = 4, p-value = 0.1413</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p&gt;0.05说明不拒绝原假设，两个变量独立无关，价格与客户的满意度之间没有关系。</p>
<p>此外，当列联表中有频数低于4时，最好使用fisher进行精确检测。例如：某网上商场对某种高档商品进行了一次短期的测试，验证自动导购系统的有效性，商场分别提供了普通购买通道和自动导购系统通道，表7-3为该测试的列联表。</p>
<p>表7-3 高档商品测试列联表</p>
<p><img src="Image00184.jpg" alt></p>
<p>对表7-3的数据进行fisher检测，R语言代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt; c(11,3,9,12)-&gt;x</span><br><span class="line">&gt; dim(x)&lt;-c(2,2)</span><br><span class="line">&gt; fisher.test(x)</span><br><span class="line">        Fisher&apos;s Exact Test for Count Data</span><br><span class="line">data:  x</span><br><span class="line">p-value = 0.04614</span><br><span class="line">alternative hypothesis: true odds ratio is not equal to 1</span><br><span class="line">95 percent confidence interval:</span><br><span class="line">  0.8730177 33.8560814</span><br><span class="line">sample estimates:</span><br><span class="line">odds ratio </span><br><span class="line">  4.662271 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p<0.05拒绝原假设，因此认为自动导购系统有效，odds ratio>1表示存在正相关关系，即通过自动导购系统通道进入的顾客越多，该商品的购买率就越大。</0.05拒绝原假设，因此认为自动导购系统有效，odds></p>
<h4 id="7-1-5-符号检测"><a href="#7-1-5-符号检测" class="headerlink" title="7.1.5 符号检测"></a>7.1.5 符号检测</h4><p>符号检测通过观察样本值与总体中某个位置（比如中位数）的差实现，将样本观察值与总体中位数的差之间的关系用符号表示为大于、小于或正、负关系，从而进行检测。</p>
<p>1.某商场VIP客户信息推送</p>
<p>以某商场VIP客户广告推送为例，某商场需要针对某类商品建立该类商品的VIP大客户，以便定期向该类客户推送相关广告。客户服务部门推荐了客户A，从数据库中随机抽取了100个客户资料，统计他们前4个季度的平均季消费数据（在这里用平均随机数模拟数据），检测客户A的平均季消费是否处于中上水平（位于中位数以上）。首先，构造数据，R语言代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; sample(200:50000,100)-&gt;sale</span><br><span class="line">&gt; sale</span><br><span class="line">  [1]  8447 13987  8809 44437 22973 28093 30594 28060 21101 45155 36128 30129</span><br><span class="line"> [13]   556 33977  9283 35094   903 32885 11639 15533 29150 47368  4993  5376</span><br><span class="line"> [25]  1869 15975 25120 33530 31767 41845 39623  3586 22671 16128 14814 24993</span><br><span class="line"> [37] 45830 10349 43989 35650 45179 35282 27204  5485 22990 21475 14533 42852</span><br><span class="line"> [49] 15986 28411 16683 15832 27207 19062 10256 34549 46159 16315 43097 40038</span><br><span class="line"> [61] 27758 14936 26161 18694 25139 13208 26837 30171 13663 14082 46909 26498</span><br><span class="line"> [73]  7830 35810 15183 41769  8880 47928 13387 33231 28978 39486  6309 19344</span><br><span class="line"> [85] 12935 41976 13429 16291 31159 33646  1742 48160 43169 40165 38915 24941</span><br><span class="line"> [97] 25181 30077 19475 26836</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>然后，使用sum(sale&gt;29900)表示所有大于该客户平均消费水平的样本数，进行binom.test检测：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt; binom.test(sum(sale&gt;29900),length(sale),al=&quot;less&quot;)</span><br><span class="line">        Exact binomial test</span><br><span class="line">data:  sum(sale &gt; 29900) and length(sale)</span><br><span class="line">number of successes = 38, number of trials = 100, p-value = 0.01049</span><br><span class="line">alternative hypothesis: true probability of success is less than 0.5</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.0000000 0.4667535</span><br><span class="line">sample estimates:</span><br><span class="line">probability of success </span><br><span class="line">                  0.38 </span><br><span class="line">&gt;</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.0000000 0.4667535</span><br></pre></td></tr></table></figure>

</details>

<p>这里，binom.test使用的是二项分布B（100，1/2）的检测，每次抽样要么M&gt;=M0，要么M&lt;M0，成功的概率为1/2，即在中位数以上（含中位数）和中位数以下的概率均为0.5。单侧区间估计的上界为0.4667535，小于原假设出现的概率0.5，因此拒绝了原假设。</p>
<p>本例中的假设为：H0:M&gt;=M0，H1:M&lt;M0。其中，M0为该客户的消费金额，M为样本的中位数，代表平均消费水平，原假设为平均消费水平比该客户的消费金额大，备择假设为平均消费水平比该客户的消费金额小，如果备择假设成立，则代表拒绝原假设，且该客户在这类商品的消费能力处于中上。</p>
<p>最后，观察binom.test分析结果的p值，它等于0.01049，小于0.05，拒绝原假设，再观察95%的置信区间（95 percent confidence interval），其上限为0.4667535，低于0.5，仍拒绝原假设，因此，该客户的消费金额高于该类商品的客户中间水平，处于中上层消费，可以考虑将其设为VIP客户。</p>
<p><img src="Image00050.jpg" alt> 提示 sum函数的参数可设置条件，完成条件计数功能。比如下面的代码：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-c(1,3,9,20,41)</span><br><span class="line">&gt; x&gt;7</span><br><span class="line">[1] FALSE FALSE  TRUE  TRUE  TRUE</span><br><span class="line">&gt; sum(x&gt;7)</span><br><span class="line">[1] 3</span><br></pre></td></tr></table></figure>

</details>

<p>2.虚拟道具促销</p>
<p>某游戏公司对X游戏的某类虚拟道具进行了为期6周的促销测试，以增加其销量，采用了以下两种促销手段，请问这两种促销手段的效果相同吗，如果效果相同，则可以定期采用这两种促销手段，搞类似的促销活动，数据如表7-4所示。</p>
<p>表7-4 相对未促销前两种促销手段所增加的销量</p>
<p><img src="Image00185.jpg" alt></p>
<p>编写R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> &gt; a&lt;-c(50,60,45,62,48,59)</span><br><span class="line">&gt; b&lt;-c(39,68,58,64,52,61)</span><br><span class="line">&gt; binom.test(sum(a&gt;b),length(a))</span><br><span class="line">        Exact binomial test</span><br><span class="line">data:  sum(a &gt; b) and length(a)</span><br><span class="line">number of successes = 1, number of trials = 6, p-value = 0.2188</span><br><span class="line">alternative hypothesis: true probability of success is not equal to 0.5</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.004210745 0.641234579</span><br><span class="line">sample estimates:</span><br><span class="line">probability of success </span><br><span class="line">             0.1666667 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值为0.1666667，大于0.05，不能拒绝原假设，原假设是促销手段A的销量增加数比促销手段B多，且有明显差距，因此可认为，A比B的促销效果好。</p>
<p><img src="Image00050.jpg" alt> 提示 sum(a&gt;b)表示a大于b的数量，</p>
<p>sum(a&lt;b)表示a小于b的数量。</p>
<p>3.某商场顾客群分析</p>
<p>某网上商场对购买A类商品的顾客群进行分析，发现他们更喜欢同时购买B类或C类商品，下面随机抽取了其中的20个顾客作为样本，购买B类商品的为b，购买C类商品的为c，1表示购买，0表示没购买。部分数据如表7-5所示。（完整数据可参见本书源码包的sale3.csv文件。）</p>
<p>表7-5 顾客群购买情况</p>
<p><img src="Image00186.jpg" alt></p>
<p><img src="Image00187.jpg" alt></p>
<p>可将原假设定为这类顾客群更喜欢同时购买C商品，而备择假设是更喜欢同时购买B商品。此外，以95%的置信度进行检测，显著水平取0.05。编写如下R代码：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; read.csv(&quot;sale3.csv&quot;)-&gt;mysale</span><br><span class="line">&gt; c_count&lt;-sum(mysale$b==0 &amp; mysale$c==1)</span><br><span class="line">&gt; b_count&lt;-sum(mysale$b==1 &amp; mysale$c==0)</span><br><span class="line">&gt; binom.test(c_count,b_count+c_count,p=1/2,al=&quot;less&quot;,conf.level=0.95)</span><br><span class="line">        Exact binomial test</span><br><span class="line">data:  c_count and b_count + c_count</span><br><span class="line">number of successes = 4, number of trials = 17, p-value = 0.02452</span><br><span class="line">alternative hypothesis: true probability of success is less than 0.5</span><br><span class="line">95 percent confidence interval:</span><br><span class="line"> 0.0000000 0.4605494</span><br><span class="line">sample estimates:</span><br><span class="line">probability of success </span><br><span class="line">             0.2352941 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>分析上述结果，p=0.02452，p值小于0.05(100%-95%=5%=0.05)，可拒绝原假设（更喜欢同时购买C商品），而备择假设成立，购买A商品的客户更喜欢同时购买B商品。同时可以看到单侧区间上界为0.4605494（低于0.5），这里也表明要拒绝原假设。</p>
<p><img src="Image00050.jpg" alt> 提示 该案例中，同时购买B和C商品的客户不用列入样本容量进行计算。</p>
<h4 id="7-1-6-秩相关检验"><a href="#7-1-6-秩相关检验" class="headerlink" title="7.1.6 秩相关检验"></a>7.1.6 秩相关检验</h4><p>1.spearman秩相关检验</p>
<p>spearman秩相关检验根据计算得到的秩统计量产生秩相关系数r，相互独立时，E(r)=0；正相关时，r为正值；负相关时，r为负值；可检测分布无关性。下面对某商品每周的点击次数与每周的销量进行统计，表7-6是连续6周的统计数据。</p>
<p>表7-6 每周的点击次数与销量</p>
<p><img src="Image00188.jpg" alt></p>
<p>编写R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; sales&lt;-c(150,210,90,190,230,211)</span><br><span class="line">&gt; hits&lt;-c(310,480,190,400,590,520)</span><br><span class="line">&gt; cor.test(hits,sales,method=&quot;spearman&quot;)</span><br><span class="line">        Spearman&apos;s rank correlation rho</span><br><span class="line">data:  hits and sales</span><br><span class="line">S = 0, p-value = 0.002778</span><br><span class="line">alternative hypothesis: true rho is not equal to 0</span><br><span class="line">sample estimates:</span><br><span class="line">rho </span><br><span class="line">  1 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，p值0.002778<0.05，因此拒绝原假设，认为两个变量是相关的。此外，rho>1表示正相关，rho&lt;1表示负相关，E(rho)=0表示相互独立无关。综上所述，每周的点击次数与每周的销量是正相关的，点击的次数越多，销量就越多。</0.05，因此拒绝原假设，认为两个变量是相关的。此外，rho></p>
<p>2.Wilcoxon秩检验</p>
<p>Wilcoxon秩检验考虑了符号检测（如样本观测值与总体中位数差的符号），而且考虑了观测值与原假设某位置的具体差距的大小。</p>
<p>以购物网站的网页改版为例进行讲解，假设购物网站对某类商品的访问网页进行了改版，并能同时保留改版前的网页和改版后的网页供顾客选择浏览，通过一段时间的测试后，对通过两种网页进行购买的行为进行分析，抽取其中的7个商品进行检测，查看改版的效果。销量如表7-7所示。</p>
<p>表7-7 网页改版前后的销量数据</p>
<p><img src="Image00189.jpg" alt></p>
<p>首先，检测网页改版后该类商品的销量提升是否达到了期待的水平，即销量中位数在400以上。设定原假设为销量提升达到期待水平，该类商品中有一半商品的销量在400以上（即销量中位数在400以上），而备择假设为销量中位数在400以下。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;sales&lt;-c(530,500,506,497,280,388,124)</span><br><span class="line">&gt;wilcox.test(sales,mu=400,alternative=&quot;less&quot;,correct=FALSE,exact=FALSE,conf.</span><br><span class="line">int=TRUE)</span><br><span class="line">        Wilcoxon signed rank test</span><br><span class="line">data:  sales</span><br><span class="line">V = 15, p-value = 0.5671</span><br><span class="line">alternative hypothesis: true location is less than 400</span><br><span class="line">95 percent confidence interval:</span><br><span class="line">     -Inf 506.0001</span><br><span class="line">sample estimates:</span><br><span class="line">(pseudo)median </span><br><span class="line">      406.0668 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>p值为0.5671，P&gt;0.05，不能拒绝原假设，再观察置信度为95%的区间的估计上限为506.001。因此，销量中位数在改版后达到了400以上。</p>
<p><img src="Image00050.jpg" alt> 提示 以上代码中，alternative表示备择假设，correct表示在计算P值时是否采用连续性修正，exact表示是否精确计算P值，conf.int设定是否输出置信区间。</p>
<p>那能不能再乐观些，销量中位数能否达到600以上呢？编写如下R代码进行检测：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; wilcox.test(sales,mu=600,alternative=&quot;less&quot;,correct=FALSE,exact=FALSE,conf.</span><br><span class="line">int=TRUE)</span><br><span class="line">        Wilcoxon signed rank test</span><br><span class="line">data:  sales</span><br><span class="line">V = 0, p-value = 0.00898</span><br><span class="line">alternative hypothesis: true location is less than 600</span><br><span class="line">95 percent confidence interval:</span><br><span class="line">     -Inf 506.0001</span><br><span class="line">sample estimates:</span><br><span class="line">(pseudo)median </span><br><span class="line">      406.0668 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>p=0.00898小于0.05，显然需要拒绝原假设（销量中位数大于600），不能如此乐观地将销量中位数估计到600以上。</p>
<p>然后，验证新版网页是否提高了该类商品的销量。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; salesnew&lt;-c(530,500,506,497,280,388,124)</span><br><span class="line">&gt; salesold&lt;-c(380,410,290,375,186,300,60)</span><br><span class="line">&gt; wilcox.test(salesnew,salesold,alternative=&quot;greater&quot;,paired=TRUE)</span><br><span class="line">        Wilcoxon signed rank test</span><br><span class="line">data:  salesnew and salesold</span><br><span class="line">V = 28, p-value = 0.007813</span><br><span class="line">alternative hypothesis: true location shift is greater than 0</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述结果，可以看出，原假设为新版网页与老版网页效果相同，备择假设为新版网页能提高销量。p=0.007813，小于0.05，因此拒绝原假设，新版网页能提高该类商品的销量。</p>
<p><img src="Image00050.jpg" alt> 提示 paired参数表示样本是否属于成对样本，TRUE表示是成对样本。</p>
<p>下面以某游戏的区域策略调整为例，假设某游戏在某区域内调整了策略（更新地图、怪物等），使该区域相对于B职业玩家来说，更适合于A职业玩家进行升级和活动，游戏开发商对在该游戏区域内活动的A职业玩家和B职业玩家采取了随机有奖问卷方式，收集该区域的活动满意度，调查评分（满分为100分）如表7-8所示。</p>
<p>表7-8 两类职业玩家满意度调查表</p>
<p><img src="Image00190.jpg" alt></p>
<p>将原假设H0设为调整策略后，A职业玩家与B职业玩家无差异，备择假设H1是A职业玩家比B职位玩家更满意。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; a&lt;-c(80,96,84,79,81,92,75,85)</span><br><span class="line">&gt; b&lt;-c(68,75,71,92,66)</span><br><span class="line">&gt; wilcox.test(a,b,alternative=&quot;greater&quot;,exact=FALSE,correct=TRUE)</span><br><span class="line">        Wilcoxon rank sum test with continuity correction</span><br><span class="line">data:  a and b</span><br><span class="line">W = 33, p-value = 0.03326</span><br><span class="line">alternative hypothesis: true location shift is greater than 0</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述检测结果，p=0.03326&lt;0.05，因此拒绝原假设，游戏策略调整效果较显著，A职业玩家更愿意在该区域内活动和升级。</p>
<h4 id="7-1-7-Kendall相关检验"><a href="#7-1-7-Kendall相关检验" class="headerlink" title="7.1.7 Kendall相关检验"></a>7.1.7 Kendall相关检验</h4><p>Kendall相关检验通过协同进行检测，设x和y两个变量进行检测，如果(xj-xi)(yj-yi)&gt;0，则称对子(xi，yi)、(xj，yj)有同样的倾向；反之，如果(xj-xi)(yj-yi)&lt;0，则称对子是不协同的。通过将协同对子代入Kendall相关系数，再计算变量之间的相关性。对表7-6的数据进行分析，首先，构造数据。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; sales&lt;c(150,210,90,190,230,211)</span><br><span class="line">&gt; hits&lt;-c(310,480,190,400,590,520)</span><br></pre></td></tr></table></figure>

</details>

<p>然后，将method参数设为kendall，进行分析：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;  cor.test(hits,sales,method=&quot;kendall&quot;)</span><br><span class="line">        Kendall&apos;s rank correlation tau</span><br><span class="line">data:  hits and sales</span><br><span class="line">T = 15, p-value = 0.002778</span><br><span class="line">alternative hypothesis: true tau is not equal to 0</span><br><span class="line">sample estimates:</span><br><span class="line">tau</span><br><span class="line">   1</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，结论仍是正相关，p值0.002778小于0.05，因此拒绝原假设。</p>
<h3 id="7-2-回归模型"><a href="#7-2-回归模型" class="headerlink" title="7.2 回归模型"></a>7.2 回归模型</h3><p>回归是研究一个随机变量Y对另一个变量(X)或一组变量(X1，X2，…，Xk)的相依关系的统计分析方法，它通过规定因变量和自变量的关系来确定变量之间的因果关系，建立回归模型，并根据实测数据来求解模型的各个参数，并评价回归模型是否能够很好地拟合实测数据。</p>
<h4 id="7-2-1-回归预测与显著性检验"><a href="#7-2-1-回归预测与显著性检验" class="headerlink" title="7.2.1 回归预测与显著性检验"></a>7.2.1 回归预测与显著性检验</h4><p>下面按方程y=β0 +β1 x+ε进行一元线性回归和预测。</p>
<p>首先，建立回归模型。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-c(12,9,3,7,17,19)</span><br><span class="line">&gt; y&lt;-c(28,20,8,13,36,39)</span><br><span class="line">&gt; lm(y~1+x)-&gt;mylm.lm</span><br><span class="line">&gt; mylm.lm</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ 1 + x)</span><br><span class="line">Coefficients:</span><br><span class="line">(Intercept)            x  </span><br><span class="line">      1.284        2.034  </span><br><span class="line">&gt; summary(mylm.lm)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ 1 + x)</span><br><span class="line">Residuals:</span><br><span class="line">      1       2       3       4       5       6 </span><br><span class="line"> 2.3048  0.4076  0.6132 -2.5239  0.1335 -0.9351 </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept)   1.2840     1.6609   0.773 0.482617    </span><br><span class="line">x             2.0343     0.1332  15.273 0.000107 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">Residual standard error: 1.811 on 4 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.9831,    Adjusted R-squared:  0.9789 </span><br><span class="line">F-statistic: 233.3 on 1 and 4 DF,  p-value: 0.0001072</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，从summary给出的回归模型信息可以看出，Residuals部分指出x6个值的残差，Coefficients部分指出β0 预测为1.2840，其标准差（Std.Error）为1.6609；x的参数（β1 部分）预测为2.0343，其标准差（Std.Error）为0.1332。</p>
<p>然后，指定自变量（如x值）后，对因变量（如y值）进行预测，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; myx&lt;-data.frame(x=c(20,28,19))</span><br><span class="line">&gt; predict(mylm.lm,myx,interval=&quot;prediction&quot;,level=0.95)</span><br><span class="line">       fit      lwr      upr</span><br><span class="line">1 41.96934 35.63207 48.30661</span><br><span class="line">2 58.24346 49.98260 66.50432</span><br><span class="line">3 39.93508 33.78026 46.08989</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，在置信度为95%的情况下，如果x=20，则y值预测为41.96934，y值预测落在区间[35.63207，48.30661]，如果x=19，则y值预测落在区间[33.78026，46.08989]。</p>
<p>此外，还可对回归模型中的参数进行预测。</p>
<p>以一元线性回归模型y=β0 +β1 x+ε为例，ε是随机误差，β0 和β1 是参数。设α为显著水平，则置信度为1-α，其参数的区间估计如下：</p>
<p><img src="Image00191.jpg" alt></p>
<p>按照上述公式，计算上述回归模型参数在95%置信度（显著水平a=0.05）的预计区间，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&gt; summary(mylm.lm)-&gt;mylm.summary</span><br><span class="line">&gt;# 取出参数预测部分</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; mylm.summary$coefficients-&gt;mycof</span><br><span class="line">&gt; mycof</span><br><span class="line">            Estimate Std. Error  t value   Pr(&gt;|t|)</span><br><span class="line">(Intercept) 1.284040  1.6609290  0.7730852 0.4826172233</span><br><span class="line">x           2.034265  0.1331944 15.2729058 0.0001071897</span><br><span class="line">#显著水平</span><br><span class="line"></span><br><span class="line">a</span><br><span class="line">&gt; a&lt;-0.05</span><br><span class="line">&gt;#  mylm.lm$df.residual为模型的自由度，其值为</span><br><span class="line"></span><br><span class="line">n-2，</span><br><span class="line"></span><br><span class="line">n为</span><br><span class="line"></span><br><span class="line">x向量或</span><br><span class="line"></span><br><span class="line">y向量包括元素的个数</span><br><span class="line"></span><br><span class="line">.</span><br><span class="line">&gt; mylm.lm$df.residual-&gt;mydf</span><br><span class="line">&gt; lower_bound&lt;-mycof[,1]-mycof[,2]*qt(1-a/2,mydf)</span><br><span class="line">&gt; upper_bound&lt;-mycof[,1]+mycof[,2]*qt(1-a/2,mydf)</span><br><span class="line">&gt; dimnames(mycof)[[1]]-&gt;myrowname</span><br><span class="line">&gt; c(&quot;预计值</span><br><span class="line"></span><br><span class="line">&quot;,&quot;下界值</span><br><span class="line"></span><br><span class="line">&quot;,&quot;上界值</span><br><span class="line"></span><br><span class="line">&quot;)-&gt;mycolname</span><br><span class="line">&gt;# 显示参数预测区间</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; matrix(c(mycof[,1],lower_bound,upper_bound),ncol=3,dimnames=list(myrowname,my</span><br><span class="line">colname))</span><br><span class="line">              预计值</span><br><span class="line"></span><br><span class="line">    下界值</span><br><span class="line"></span><br><span class="line">   上界值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(Intercept) 1.284040 -3.327439 5.895518</span><br><span class="line">x           2.034265  1.664458 2.404072</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>分析以上结果，x的系数参数预计在[1.664458，2.404072]的范围内。</p>
<h4 id="7-2-2-回归诊断"><a href="#7-2-2-回归诊断" class="headerlink" title="7.2.2 回归诊断"></a>7.2.2 回归诊断</h4><p>通过对回归进行显著性检验，可检测回归效果，尤其是在多元线性回归分析中，无法用散点图直观地判断众多变量x1 ，x2 ，…，xj-1 ，xj+1 ，…，xp 与y之间是否存在线性关系的时候。回归效果的显著性检验可分为回归方程的显著性检验和回归系数的显著性检验。</p>
<p>以lm函数结果为参数，调用summary函数，将返回很多回归检验分析信息。我们以2元线性回归y=β0 +β1 x1 +β2 x2 1 +ε为例。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; x1&lt;-c(9,223,83,21,193)</span><br><span class="line">&gt; x2&lt;-c(98,52,185,263,76)</span><br><span class="line">&gt;c(237,415,479,630,438)-&gt;y</span><br><span class="line">&gt; lm(y~x1+x2)-&gt;mylm.lm</span><br><span class="line">&gt; summary(mylm.lm)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ x1 + x2)</span><br><span class="line">Residuals:</span><br><span class="line">      1       2       3       4       5 </span><br><span class="line">  2.462   2.037 -39.732  23.131  12.102 </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)  </span><br><span class="line">(Intercept)  10.9635    57.2566   0.191   0.8658  </span><br><span class="line">x1            1.2985     0.2341   5.547   0.0310 *</span><br><span class="line">x2            2.1621     0.2622   8.246   0.0144 *</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">Residual standard error: 33.69 on 2 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.9714,    Adjusted R-squared:  0.9429 </span><br><span class="line">F-statistic:    34 on 2 and 2 DF,  p-value: 0.02857</span><br></pre></td></tr></table></figure>

</details>

<p>依次分析summary函数的结果，进行显著性检验：</p>
<p>1）分析Coefficients部分。β0 的预测值为10.9635，β1 的预测值为1.2985，标准差为0.2341，β2 的预测值为2.1621，标准差为0.2622；β1 的t值为5.547，β2 的t值为8.246。Pr(&gt;|t|)值即P值，为T统计量的显著水平，将该值与显著性水平比较，可决定该自变量是否接受回归系数的假设检验，该值越小越显著，回归效果越好，β1 和β2 的Pr(&gt;|t|)值均小于显著性水平0.05，但线性不显著，后面的一个星号也说明了这一点，自变量系数勉强通过显著性检验。</p>
<p>如果Pr(&gt;|t|)值&gt;0.05，表明该自变量的回归系数不显著，这种情况下有必要考虑回归方程是否正确，或者剔除一些不显著的变量，重新建立更简单更精确的线性回归方程。</p>
<p>2）分析Residual standard error部分，该数值若较小则比较适合，本例中残差的标准差为33.69，数值较大效果不理想。</p>
<p>3）分析Multiple R-squared部分，该部分为相关系数的平方，该数值越大，说明回归效果越理想。本例中相关系数的平方值为0.9714。</p>
<p>4）分析F-statistic部分的p-value值，该值为F统计量的显著水平，可用该值进行回归方程显著性检测，数值越小越好，越小则说明回归方程越显著。本例中的p值为0.02857，回归效果一般。</p>
<p>此外，R还提供了influence.measures进行回归诊断。下面建立了一个效果显著的回归模型：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; x1&lt;-c(9,223,83,21,193)</span><br><span class="line">&gt; x2&lt;-c(98,52,185,263,76)</span><br><span class="line">&gt; y&lt;-x1+3*x2+runif(5,2,18)</span><br><span class="line">&gt; lm(y~x1+x2)-&gt;mylm.lm</span><br><span class="line">&gt; summary(mylm.lm)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ x1 + x2)</span><br><span class="line">Residuals:</span><br><span class="line">       1        2        3        4        5 </span><br><span class="line"> 0.03635  2.17997  1.16226 -0.40196 -2.97661 </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept)  3.06344    4.67353   0.655 0.579476    </span><br><span class="line">x1           1.03200    0.01911  54.010 0.000343 ***</span><br><span class="line">x2           3.02659    0.02140 141.412    5e-05 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">Residual standard error: 2.75 on 2 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.9999,    Adjusted R-squared:  0.9998 </span><br><span class="line">F-statistic: 1.163e+04 on 2 and 2 DF,  p-value: 8.595e-05</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，Pr(&gt;|t|)值和p值远小于0.05，说明回归方程和回归系数都非常显著，回归效果非常好。</p>
<h4 id="7-2-3-回归优化"><a href="#7-2-3-回归优化" class="headerlink" title="7.2.3 回归优化"></a>7.2.3 回归优化</h4><p>通常可通过逐步回归来优化回归方程，从可供选择的所有自变量中选出对Y有显著影响的变量建立方程，忽略对Y无显著影响的变量。使用R的step函数可以完成逐步回归，该函数以AIC信息统计量为准则，选择最小的AIC信息统计量来删除自变量。</p>
<p>下面举例说明：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; x1&lt;-c(9,223,83,21,193)</span><br><span class="line">&gt; x2&lt;-c(98,52,185,263,76)</span><br><span class="line">&gt;X3&lt;-c(25,35,48,58,42)</span><br><span class="line">&gt; y&lt;-c(841,1570,2774,3923,2137)</span><br><span class="line">&gt; lm(y~x1+x2+x3)-&gt;mylm.lm</span><br><span class="line">&gt; summary(mylm.lm)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ x1 + x2 + x3)</span><br><span class="line">Residuals:</span><br><span class="line">       1        2        3        4        5 </span><br><span class="line">   8.075   39.072 -103.947   64.654   -7.854 </span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)</span><br><span class="line">(Intercept) -1.395e+03  2.824e+02  -4.938    0.127</span><br><span class="line">x1           4.873e-02  3.330e+00   0.015    0.991</span><br><span class="line">x2           2.386e+00  6.309e+00   0.378    0.770</span><br><span class="line">x3           7.973e+01  3.262e+01   2.444    0.247</span><br><span class="line">Residual standard error: 129 on 1 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.997,     Adjusted R-squared:  0.988 </span><br><span class="line">F-statistic: 110.5 on 3 and 1 DF,  p-value: 0.06978</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，从summary的分析结果可以看出，效果很不理想，x1、x2、x3的系数P值全部大于0.05，回归系数不显著，回归方程F分布的p值更不显著。</p>
<p>下面调用step函数进行优化。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; step(mylm.lm)-&gt;mylm.step</span><br><span class="line">Start:  AIC=48.55</span><br><span class="line">y ~ x1 + x2 + x3</span><br><span class="line">       Df Sum of Sq    RSS    AIC</span><br><span class="line">-x1    1         4  16642 46.551</span><br><span class="line">-x2    1      2380  19018 47.219</span><br><span class="line">&lt;none&gt;               16638 48.550</span><br><span class="line">-x3    1     99409 116048 56.262</span><br><span class="line">Step:  AIC=46.55</span><br><span class="line">y ~ x2 + x3</span><br><span class="line">       Df Sum of Sq     RSS    AIC</span><br><span class="line">&lt;none&gt;                16642 46.551</span><br><span class="line">-x2    1     55362   72004 51.875</span><br><span class="line">-x3    1   1388382 1405024 66.731</span><br></pre></td></tr></table></figure>

</details>

<p>从以上step结果可以看出，选择去掉x1，可以使AIC的值为最小值46.551，因此在最终的回归方程中删除x1。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt; summary(mylm.step)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = y ~ x2 + x3)</span><br><span class="line">Residuals:</span><br><span class="line">       1        2        3        4        5 </span><br><span class="line">   7.660   40.327 -103.459   64.579   -9.108 </span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">(Intercept) -1396.4131   180.3749  -7.742  0.01628 * </span><br><span class="line">x2              2.2954     0.8899   2.579  0.12314   </span><br><span class="line">x3             80.1922     6.2082  12.917  0.00594 **</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">Residual standard error: 91.22 on 2 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.997,     Adjusted R-squared:  0.994 </span><br><span class="line">F-statistic: 331.5 on 2 and 2 DF,  p-value: 0.003007</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，从summary函数对优化后的回归方程的分析结果可以看出，相对没优化前，Residual standard error值减少为91.22，x2、x3系数的P值减少为0.12314、0.00594，x3的系数通过检测，x1因为不显著最终没有加入回归方程中，F分布的p-value值也减少为0.003007，总体来说优化后回归方程和回归系数更加显著，回归效果更好。</p>
<h4 id="7-2-4-主成分回归"><a href="#7-2-4-主成分回归" class="headerlink" title="7.2.4 主成分回归"></a>7.2.4 主成分回归</h4><p>主成分分析将多个指标中少数几个综合指标，通过降维技术，将多个变量简化成少数几个主成分的方法，这些主成分能反映原始变量的绝大部分信息，表示为原始变量的线性组合。以网上商场的购物满意度为例进行回归，表7-9是某网上商场的购物满意度指标。</p>
<p>表7-9 某网上商场的购物满意度指标</p>
<p><img src="Image00192.jpg" alt></p>
<p>1.主成分分析</p>
<p>首先，使用R语言的princomp函数进行主成分分析：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;  buy&lt;-data.frame(</span><br><span class="line">+ X1&lt;-c(200,600,60,400,150),</span><br><span class="line">+  X2&lt;-c(120,480,20,320,80),</span><br><span class="line">+  X3&lt;-c(800,3000,300,2200,450),</span><br><span class="line">+ X4&lt;-c(210,320,50,260,130),</span><br><span class="line">+ Y&lt;-c(4,5,2,4,3)</span><br><span class="line">+ )</span><br><span class="line">&gt; princomp(~X1+X2+X3+X4,cor=TRUE)-&gt;mypr</span><br><span class="line">&gt; summary(mypr,loadings=TRUE)</span><br><span class="line">Importance of components:</span><br><span class="line">                          Comp.1     Comp.2      Comp.3       Comp.4</span><br><span class="line">Standard deviation     1.9711809 0.32537035 0.092379136 6.793839e-03</span><br><span class="line">Proportion of Variance 0.9713885 0.02646647 0.002133476 1.153906e-05</span><br><span class="line">Cumulative Proportion  0.9713885 0.99785498 0.999988461 1.000000e+00</span><br><span class="line">Loadings:</span><br><span class="line">   Comp.1 Comp.2 Comp.3 Comp.4</span><br><span class="line">X1 -0.506 -0.164  0.644  0.550</span><br><span class="line">X2 -0.505 -0.289  0.203 -0.788</span><br><span class="line">X3 -0.502 -0.381 -0.726  0.274</span><br><span class="line">X4 -0.487  0.863 -0.130</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，summary函数输出了主成分分析信息，该信息主要包括以下内容：</p>
<p>·Standard deviation行表示的是主成分的标准差（主成分的方差的开方）。</p>
<p>·Proportion of Variance行表示的是方差的贡献率。</p>
<p>·Cumulative Proportion行表示的是方差的累积贡献率。</p>
<p>·Loadings栏表示降维后主成分对应于原始变量X1、X2、X3、X4的系数。在调用summary函数时，可以将参数loadings设为TRUE，才能输出loadings信息。</p>
<p>2.降维</p>
<p>该网上商场的满意度指标有网友评论次数（X1）、好评次数（X2）、商品浏览人数（X3）和商品已上市天数（X4）共4个，其中第1个主成分Comp.1的贡献率为0.9713885，第2个主成分Comp.2的贡献率为0.02646647，这两个主成分的累积贡献率已经达到99.79%，并且后面两个主成分的方差贡献率很小，因此，可将后面两个主成分去掉，实现降维。</p>
<p><img src="Image00193.jpg" alt></p>
<p>图7-1 网上商场满意度指标碎石图</p>
<p>此外，还可做出碎石图（如图7-1所示），可直观地看出X1和X2的贡献率较大。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screeplot(mypr,type=&quot;lines&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>再观察对满意度指标分析结果中的loadings栏，可以将前两个主成分写成以下形式：</p>
<p><img src="Image00194.jpg" alt></p>
<p>3.回归模型建立</p>
<p>接着，可以建立这几个指标与满意度的回归模型，根据前面的主成分分析结果，只选择前两个贡献率高的主成分X1与X2，建立回归模型，消除变量的多重共线性。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&gt; pre&lt;-predict(mypr)   </span><br><span class="line">&gt; pre[,1]-&gt;buy$Z1#第一主成分</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; pre[,2]-&gt;buy$Z2#第二主成分</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; lm(Y~Z1+Z2,data=buy)-&gt;mylm#建立回归模型</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; summary(mylm)</span><br><span class="line">Call:</span><br><span class="line">lm(formula = Y ~ Z1 + Z2, data = buy)</span><br><span class="line">Residuals:</span><br><span class="line">       1        2        3        4        5 </span><br><span class="line"> 0.06267  0.15488  0.01870 -0.25828  0.02203 </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept)  3.60000    0.09770  36.847 0.000736 ***</span><br><span class="line">Z1          -0.47551    0.04956  -9.594 0.010691 *  </span><br><span class="line">Z2           1.15957    0.30028   3.862 0.060988 .  </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">Residual standard error: 0.2185 on 2 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.9816,    Adjusted R-squared:  0.9633 </span><br><span class="line">F-statistic: 53.48 on 2 and 2 DF,  p-value: 0.01836</span><br></pre></td></tr></table></figure>

</details>

<p>分析上述summary函数的执行结果，可得到如下回归方程：</p>
<p><img src="Image00195.jpg" alt></p>
<p>4.主成分变量变换</p>
<p>最后，可将主成分变量进行变换：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; coef(mylm)-&gt;beta#回归系数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; loadings(mypr)-&gt;myloading#载荷</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; mypr$center-&gt;mybar#均值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; mypr$scale-&gt;mysd#标准差</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; (beta[2]*myloading[,1]+beta[3]*myloading[,2])/mysd-&gt;mycoef</span><br><span class="line">&gt; beta[1]-sum(mybar*mycoef)-&gt;beta0</span><br><span class="line">&gt; c(beta0,mycoef)</span><br><span class="line">  (Intercept)            X1            X2            X3            X4 </span><br><span class="line"> 1.3870124896  0.0002572658 -0.0005545049 -0.0001905035  0.0129419446</span><br></pre></td></tr></table></figure>

</details>

<p>该网上商场的购物满意度的最终回归模型如下：</p>
<p>Y=1.3870124896+0.0002572658×X1 -0.0005545049×X2 -0.0001905035×X3<br>+0.0129419446×X4</p>
<h4 id="7-2-5-广义线性模型"><a href="#7-2-5-广义线性模型" class="headerlink" title="7.2.5 广义线性模型"></a>7.2.5 广义线性模型</h4><p>1.广义线性模型概述</p>
<p>广义线性模型（Generalized Linear Model，GLM）是一种被广泛应用的线性回归模式，它是线性模型的扩展，其特点是不强行改变数据的自然度量，因为变量的总体均值可通过非线性或线性连接函数依赖于线性预测值，建立起可解释随机变量相关性的函数。</p>
<p>GLM是简单最小二乘回归的扩展，主要是通过连接函数，建立响应变量的数学期望值与自变量线性组合的预测变量之间的关系。假设每个样本的观测值Y来自某个指数族分布，该分布的平均数μ可由与该点独立的X来解释：</p>
<p>E(y)=μ=g-1 (Xβ)</p>
<p>上式中，E(y)为y的期望值，Xβ是由未知待估计参数β与已知自变量X构成的线性估计式，g为连接函数，g-1 则为连接函数反函数。表7-10是经典的连接函数及其反函数（也可称为均值函数）。</p>
<p>表7-10 经典的连接函数及其反函数</p>
<p><img src="Image00196.jpg" alt></p>
<p>简而言之，GLM不但适用于连续数据，还适用于诸如属性数据、计数数据等离散数据，它通过连接函数将因变量的期望值与线性自变量联系，自变量的线性预测值是因变量的估计值，并对误差的分布给出误差函数，在GLM模型中，需要指定分布类型和连接函数。</p>
<p>在R中通常使用GLM函数构造广义线性模型，其中分布参数包括binomaial（二项分布）、gaussian（正态分布）、gamma（伽马分布）、poisson（泊松分布）等。</p>
<p>2.广义线性模型实例</p>
<p>下面以二项分布（binomaial）的logistic回归模型为例进行讲解。假设某网上商场试图建立某类商品的购买率（购买量/商品页面浏览次数）与气候之间的关系模型，这样就可根据当地气候的预测情况，推断该类商品的购买率，从而向消费者推荐该类商品。样本数据如表7-11所示。</p>
<p>表7-11 雨量与购买率</p>
<p><img src="Image00197.jpg" alt></p>
<p><img src="Image00198.jpg" alt></p>
<p>首先，建立广义线性模型。R代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; mysale&lt;-data.frame(</span><br><span class="line">temperature&lt;-c(22,38,12,33,6,9,29,17,33,31,35,19,13,8),</span><br><span class="line">rainfall&lt;-c(0,0,0,0,0,1,1,1,1,2,2,2,2,2),</span><br><span class="line">n&lt;-rep(100,14),</span><br><span class="line">buy&lt;-c(15,27,11,20,9,18,32,22,35,69,78,39,29,25)</span><br><span class="line">)</span><br><span class="line">&gt; mysale$y&lt;-cbind(mysale$buy,mysale$n-mysale$buy)</span><br><span class="line">&gt; glm(y~temperature+rainfall,family=binomial,data=mysale)-&gt;myglm</span><br><span class="line">&gt; summary(myglm)</span><br><span class="line">Call:</span><br><span class="line">glm(formula = y ~ temperature + rainfall, family = binomial, </span><br><span class="line">    data = mysale)</span><br><span class="line">Deviance Residuals: </span><br><span class="line">    Min       1Q   Median       3Q      Max  </span><br><span class="line">-1.5231  -0.8861  -0.1604   1.1531   2.3457  </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error z value Pr(&gt;|z|)    </span><br><span class="line">(Intercept) -3.23592    0.20961 -15.438   &lt;2e-16 ***</span><br><span class="line">temperature  0.06136    0.00633   9.694   &lt;2e-16 ***</span><br><span class="line">rainfall     0.90678    0.08067  11.240   &lt;2e-16 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">(Dispersion parameter for binomial family taken to be 1)</span><br><span class="line">    Null deviance: 243.940  on 13  degrees of freedom</span><br><span class="line">Residual deviance:  19.553  on 11  degrees of freedom</span><br><span class="line">AIC: 90.86</span><br><span class="line">Number of Fisher Scoring iterations: 4</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上分析结果可以发现，回归参数为β0 =-3.23592、β1 =0.06136、β2 =-0.90678，系数参数通过了显著性水平a=0.05的检验，回归模型如下：</p>
<p><img src="Image00199.jpg" alt></p>
<p>其中temperature是温度，rainfall是雨量。</p>
<p>接着，可根据该回归模型进行预测。比如温度为30℃，大雨时，该类商品的购买率为多少？</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; predict(myglm,data.frame(temperature=30,rainfall=2))-&gt;mypre</span><br><span class="line">&gt; mypre</span><br><span class="line">      1 </span><br><span class="line">0.41857 </span><br><span class="line">&gt; exp(mypre)/(1+exp(mypre))-&gt;mybuy</span><br><span class="line">&gt; mybuy</span><br><span class="line">       1 </span><br><span class="line">0.603141</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上结果，最后一行表明，大雨且温度为30℃时，购买率估计为60.3%。</p>
<p>再来看一个例子，表7-12是网上商场某类商品的若干名回头客的数据。</p>
<p>表7-12 某类商品的若干名回头客的数据</p>
<p><img src="Image00200.jpg" alt></p>
<p><img src="Image00201.jpg" alt></p>
<p>对表7-12的数据运用GLM进行分析，得到购买率（Y）和商品打折（X1）、赠品数量（X2）的回归模型。</p>
<p>首先，建立广义线性模型，R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">mysale&lt;-data.frame(</span><br><span class="line">X1=c(0.82,0.92,0.68,0.7,0.62,0.52,0.42,0.85,0.95,0.65,0.75,0.7,0.5,0.38,0.85,</span><br><span class="line">0.95,0.65,0.75,0.6,0.48,0.98,0.3),</span><br><span class="line">X2=rep(c(0,1,2),c(7,7,8)),</span><br><span class="line">Y=c(0,0,0,0,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,0,1))</span><br><span class="line">&gt;</span><br><span class="line">&gt; glm(Y~X1+X2,family=binomial,data=mysale)-&gt;myglm</span><br><span class="line">&gt; summary(myglm)</span><br><span class="line">Call:</span><br><span class="line">glm(formula = Y ~ X1 + X2, family = binomial, data = mysale)</span><br><span class="line">Deviance Residuals: </span><br><span class="line">     Min        1Q    Median        3Q       Max  </span><br><span class="line">-1.72890  -0.04535   0.00108   0.08745   1.28906  </span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error z value Pr(&gt;|z|)  </span><br><span class="line">(Intercept)   24.388     14.086   1.731   0.0834 .</span><br><span class="line">X1           -39.360     22.348  -1.761   0.0782 .</span><br><span class="line">X2             6.373      3.751   1.699   0.0893 .</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 &apos;***&apos; 0.001 &apos;**&apos; 0.01 &apos;*&apos; 0.05 &apos;.&apos; 0.1 &apos; &apos; 1</span><br><span class="line">(Dispersion parameter for binomial family taken to be 1)</span><br><span class="line">    Null deviance: 28.841  on 21  degrees of freedom</span><br><span class="line">Residual deviance:  7.054  on 19  degrees of freedom</span><br><span class="line">AIC: 13.054</span><br><span class="line">Number of Fisher Scoring iterations: 8</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>观察以上分析结果可以看出，回归参数为β0 =24.388、β1 =-39.360，β2 =6.373，系数参数通过了显著性水平a=0.1的检验，回归模型如下：</p>
<p><img src="Image00202.jpg" alt></p>
<p>其中X1是商品打折，X2是赠品数量。</p>
<p>然后，根据该回归模型进行预测，分别从以下几种情况进行预测。</p>
<p>1）在商品打折73%、赠品数量是1的情况下，该类商品的购买率为88.37%。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; predict(myglm,data.frame(X1=0.73,X2=1))-&gt;mypre</span><br><span class="line">&gt; exp(mypre)/(1+exp(mypre))-&gt;mybuy</span><br><span class="line">&gt; mybuy</span><br><span class="line">        1 </span><br><span class="line">0.8836742 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>2）在商品打85折、赠品数量是1的情况下，该类商品很可能不会被回头客购买。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; predict(myglm,data.frame(X1=0.85,X2=1))-&gt;mypre</span><br><span class="line">&gt; exp(mypre)/(1+exp(mypre))-&gt;mybuy</span><br><span class="line">&gt; mybuy</span><br><span class="line">         1 </span><br><span class="line">0.06323925</span><br></pre></td></tr></table></figure>

</details>

<p>3）在商品打85折、赠品数量是2的情况下，该类商品非常有可能被回头客购买。R代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; predict(myglm,data.frame(X1=0.85,X2=2))-&gt;mypre</span><br><span class="line">&gt; exp(mypre)/(1+exp(mypre))-&gt;mybuy</span><br><span class="line">&gt; mybuy</span><br><span class="line">        1 </span><br><span class="line">0.9753328 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

</details>

<h3 id="7-3-小结"><a href="#7-3-小结" class="headerlink" title="7.3 小结"></a>7.3 小结</h3><p>本章首先讲述了假设检验，通过设立零假设（想检验其正确性）与对立假设（通常反映研究者对未知参数的看法，相对于零假设的其他论述），研究某事件发生的可能性，如果可能发生的话，分析其预测区间值，具体介绍了二项分布假设检验、数据分布检验、正态总体均值检验、列联表、符号检测、秩相关检验、Kendall相关检验等。然后，讲解了回归模型的若干问题，回归通过规定因变量和自变量的关系来确定变量之间的因果关系，具体介绍了回归预测、回归显著性检验、回归诊断与优化、主成分回归与广义线性回归等。</p>
<h3 id="思考题-1"><a href="#思考题-1" class="headerlink" title="思考题"></a>思考题</h3><p>（1）对某服务器进行稳定性检测，记录8次无故障稳定工作的小时数，分别为：210、190、320、230、160、67、400、340，经估计它符合λ=1/280的指数分布，验证一下稳定性的分布。</p>
<p>（2）网上商场某类些商品经常发生投诉问题，以往发生投诉的概率为35%，对这类商品的供应商进行规范和约束调整后，随机抽取了400多个客户，其中有40个投诉，策略调整是否有效果？</p>
<p>（3）对下面的X和Y进行Kendall相关检验，检测其相关性。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; X&lt;-c(150,210,90,190,230,211)</span><br><span class="line">&gt; Y&lt;-c(40, 20,30,18,28,22)</span><br></pre></td></tr></table></figure>

</details>

<p>（4）对因变量y和自变量x1、x2、x3建立线性回归模型，并进行优化。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; x1&lt;-c(9,223,83,21,193)</span><br><span class="line">&gt; x2&lt;-c(108,52,180,259,82)</span><br><span class="line">&gt; x3&lt;-c(8,5,10, 9, 2)</span><br><span class="line">&gt;c(237,415,479,630,438)-&gt;y</span><br></pre></td></tr></table></figure>

</details>

<h1 id="第四部分-机器学习实战篇"><a href="#第四部分-机器学习实战篇" class="headerlink" title="第四部分 机器学习实战篇"></a>第四部分 机器学习实战篇</h1><p>自古圣贤之言学也，咸以躬行实践为先，识见言论次之。</p>
<p>——林希元</p>
<h2 id="第8章-机器学习算法"><a href="#第8章-机器学习算法" class="headerlink" title="第8章 机器学习算法"></a>第8章 机器学习算法</h2><p>学习就是在不断重复的工作中使自己的能力不断增强或改进，在下一次执行相同或类似的任务时，会比原来做得更好或效率更高。机器学习研究指的是用计算机来模拟或实现人类学习活动，研究如何使机器通过识别和利用现有的知识来获取新知识和新技能。机器学习的内部表现为从未知到已知这样一个知识增长过程，其外部表现为某些性能和适应性得到系统的改善。机器学习形成了一套算法理论，这些算法使系统能完成原来不能完成的任务，或者能更好地完成原来可以完成的任务。</p>
<h3 id="8-1-神经网络"><a href="#8-1-神经网络" class="headerlink" title="8.1 神经网络"></a>8.1 神经网络</h3><p>1.神经网络基本原理</p>
<p>人脑由上千亿条神经组成，每条神经平均又会连接到几千条其他的神经，通过这种连接方式，神经可以收发不同数量的能量。神经一个非常重要的功能就是，它们对能量的接收并不是立即作出响应，而是将它们累加起来，当这个累加的总和达到某个临界阈值时，它们才将自己的那部分能量发送给其他的神经。大脑通过调节这些连接的数目和强度来进行学习。</p>
<p>如图8-1所示是一个神经元的模型，神经网络复杂多样，由大量与该图类似的神经元及突触组成。神经科学界的共识是，人类大脑包含1000亿个神经元，每个神经元有1万个突触，数量巨大，组合方式复杂，联系广泛。也就是说，突触传递的机制复杂。</p>
<p>现在已经发现和阐明的突触传递机制有：突触后兴奋、突触后抑制、突触前抑制、突触前兴奋，以及远程抑制等。在突触传递机制中，释放神经递质是实现突触传递机能的中心环节，而不同的神经递质有着不同的作用性质和特点。</p>
<p><img src="Image00203.jpg" alt></p>
<p>图8-1 大脑神经元</p>
<p>人工神经网络（ANN）是一种模仿生物神经网络结构和功能的数学模型，它使用大量的人工神经元连接来进行计算，该网络由大量的“神经元”相互连接构成，每个“神经元”代表一种特定的输出函数。又称为激励函数。每两个“神经元”间的连接代表一个通过该连接信号的加权值，称之为权重，这相当于人工神经网络的记忆。网络的输出则根据网络的连接规则来确定，输出因权重值和激励函数的不同而不同。人工神经网络可理解为对自然界某种算法或者函数的逼近。</p>
<p>如图8-2所示是一个简单的人工神经元示意图。其中，x1 (t)等数据为这个神经元的输入，代表其他神经元或外界对该神经元的输入；wi1 等数据为这个神经元的权重，ui =Σj wij ·xj (t)是对输入的求和，为诱导局部域；yi =f(ui<br>(t))为输出函数，也称激励函数，是对诱导局部域的再加工，也是最终的输出。</p>
<p><img src="Image00204.jpg" alt></p>
<p>图8-2 人工神经元</p>
<p>2.神经网络发展历史</p>
<p>20世纪40年代，心理学家Mcculloch和数学家Pitts联合提出了兴奋与抑制型神经元模型，另外，Hebb提出了神经元连接强度的修改规则；到20世纪五六十年代，该领域具有代表性的工作是Rosenblatt的感知机和Widrow的自适应性元件Adaline；1969年，Minsky和Papert合作出版了颇有影响力的著作《感知器》，书中暗示感知器具有严重局限，得出了消极悲观的论点，使感知器与连接主义遭到冷落，而感知器是神经网络的一种重要形式。在20世纪70年代，人工神经网络的研究处于低潮，20世纪70年代末，传统的冯·诺依曼（Von Neumann）数字计算机在模拟视听觉的人工智能方面遇到了物理上不可逾越的极限。但与此同时，Rumelhart、Mcclelland和Hopfield等人在神经网络领域取得了突破性进展，神经网络的热潮再次掀起。</p>
<h4 id="8-1-1-Rosenblatt感知器"><a href="#8-1-1-Rosenblatt感知器" class="headerlink" title="8.1.1 Rosenblatt感知器"></a>8.1.1 Rosenblatt感知器</h4><p>Rosenblatt感知器是由美国计算机科学家罗森布拉特（F.Rosenblatt）于1957年提出的。F.Rosenblatt经过证明得出结论，如果两类模式是线性可分的（指存在一个超平面将它们分开），则算法一定收敛。Rosenblatt感知器特别适用于简单的模式分类问题，也可用于基于模式分类的学习控制。</p>
<p>Rosenblatt感知器建立在一个线性神经元之上，神经元模型的求和节点计算作用于突触输入的线性组合，同时结合外部作用的偏置，对若干个突触的输入项求和后进行调节。</p>
<p>1.基本计算过程</p>
<p>Rosenblatt感知器的基本计算步骤如下：</p>
<p>1）将数据作为输入送入神经元。</p>
<p>2）通过权值和输入共同计算诱导局部域，诱导局部域是指求和节点计算得到的结果，计算公式如下：</p>
<p><img src="Image00205.jpg" alt></p>
<p>3）以硬限幅器为输出函数，诱导局部域被送入硬限幅器，形成最终的输出硬限幅器的工作原理如下。</p>
<p>硬限幅器输入为正时，神经元输出+1，反之输出-1。计算公式为：</p>
<p><img src="Image00206.jpg" alt></p>
<p>硬限幅器函数图像如图8-3所示。</p>
<p><img src="Image00207.jpg" alt></p>
<p>图8-3 硬限幅器函数图像</p>
<p>从图8-3可以看出，在最终的计算结果中，把外部的输入x1 ，x2 ，…，xm 输出为两类，分类规则是：如果输出函数是+1，则为类1；如果输出为-1，则为类2。感知器被超平面分为两类，这个超平面为：</p>
<p><img src="Image00208.jpg" alt></p>
<p>2.权值修正</p>
<p>在上述计算过程中，第二步涉及一个重要的参数，即权值。如何确定权值才能保证输出能被正确地分类到+1和-1呢？</p>
<p>首先，会产生一个初始权值，由初始权值计算得到的输出结果肯定会有误差。接着，要想办法让误差减少，这个过程就是权值w修正的过程。</p>
<p>新的问题产生了，哪些数据用来输入呢？在用神经网络进行机器学习时，输入数据是确定的，但输出结果是未知的，这些输出结果正是我们需要用神经网络预测的结果。解决这个问题的关键在于样本。样本是研究中实际观测或调查的一部分，研究对象的全部称为总体，样本必须能够正确反映总体情况。所以，首先要用样本将神经网络训练好，在确定权值后，再用训练好的神经网络对未知输入所属的输出进行预测。权值修正方法分为单样本修正算法和批量修正算法。</p>
<p>单样本修正算法的步骤为：神经网络每次读入一个样本，进行修正，样本读取完毕，修正过程结束。算法过程描述如下：</p>
<p>1）设置如下参数：</p>
<p><img src="Image00209.jpg" alt></p>
<p>其中，b为偏置，x为输入向量，w为权值。</p>
<p>2）感知器激活。</p>
<p>对于每个时间步n，通过输入向量x(n)和期望输出d(n)激活感知器。</p>
<p>3）计算感知器的输出。</p>
<p><img src="Image00210.jpg" alt></p>
<p>其中，n为时间步，x(n)为输入向量，w(n)为权值向量，sgn为硬限幅函数，v为硬限幅函数的输入值。</p>
<p>4）更新感知器的权值向量。</p>
<p><img src="Image00211.jpg" alt></p>
<p>其中，η为学习速率（调整更新的步伐）。</p>
<p>下面用神经网络学习逻辑或的运算，用Python实现上述算法。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-1.py</span><br><span class="line">import numpy as np</span><br><span class="line">b=0</span><br><span class="line">a=0.5</span><br><span class="line">x = np.array([[0,1,1],[0,1,0],[0,0,0],[0,0,1]])</span><br><span class="line">d =np.array([1,1,0,1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return 0</span><br><span class="line">def comy(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        return oldw+a*(myd-comy(oldw,myx))*myx</span><br><span class="line">i=0</span><br><span class="line">for xn in x:</span><br><span class="line">        w=neww(w,d[i],xn,a)</span><br><span class="line">        i+=1   </span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d or %d =&gt; %d &quot;%(xn[1],xn[2],comy(w,xn))</span><br></pre></td></tr></table></figure>

</details>

<p>如下程序输出结果正确。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 or 1 =&gt; 1 </span><br><span class="line">1 or 0 =&gt; 1 </span><br><span class="line">0 or 0 =&gt; 0 </span><br><span class="line">0 or 1 =&gt; 1</span><br></pre></td></tr></table></figure>

</details>

<p>现在来测试一个更复杂的例子。针对下面两类函数训练神经网络，将一组（x，y）值划分为以下两类函数之一：</p>
<p>·2x+1=y为第1类。</p>
<p>·7x+1=y为第2类。</p>
<p>代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#8-2.py</span><br><span class="line">import numpy as np</span><br><span class="line">b=1</span><br><span class="line">a=0.3</span><br><span class="line">x=np.array([[1,1,3],[1,2,5],[1,1,8],[1,2,15],[1,3,7],[1,4,29]])</span><br><span class="line">d=np.array([1,1,-1,-1,1,-1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;=0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def comy(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        print comy(oldw,myx)</span><br><span class="line">        return oldw+a*(myd-comy(oldw,myx))*myx</span><br><span class="line">i=0</span><br><span class="line">for xn in x:</span><br><span class="line">        print xn</span><br><span class="line">        w=neww(w,d[i],xn,a)</span><br><span class="line">        i+=1</span><br><span class="line">        print w       </span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d  %d =&gt; %d &quot;%(xn[1],xn[2],comy(w,xn))</span><br><span class="line">test=np.array([b,9,19])</span><br><span class="line">print &quot;%d  %d =&gt; %d &quot;%(test[1],test[2],comy(w,test))</span><br><span class="line">test=np.array([b,9,64])</span><br><span class="line">print &quot;%d  %d =&gt; %d &quot;%(test[1],test[2],comy(w,test))</span><br></pre></td></tr></table></figure>

</details>

<p>在上面代码中，使用了［1，3］、［2，5］、［1，8］、［2，15］、［3，7］、［4，29］这几组数据对该神经网络进行训练。运行该程序，对从未在样本中出现过的数据［9，19］、［9，64］进行分类。通过前面的函数定义可以知道，［9，19］属于第1类，［9，64］属于第2类。如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">9   19 =&gt; 1 </span><br><span class="line">9   64 =&gt; -1</span><br></pre></td></tr></table></figure>

</details>

<p>接着输出训练之后的神经网络权值参数，代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; w</span><br><span class="line">array([ 1. ,  1.2, -0.6])</span><br></pre></td></tr></table></figure>

</details>

<p>根据上述参数，可以确定神经网络的分类线方程为：</p>
<p>1.2x-0.6y+1=0=&gt;1.2x+1=0.6y=&gt;y≈2x+1.68</p>
<p>那么对于不完全符合上述两个函数定义的数据，通过训练好的神经网络也能近似地划分到上述函数中。试着将前面的代码修改一下，加入两个不太规则的测试数据点［9，16］、［9，60］，并把样本［b，2，5］改为不规则的［b，2，3］，同时加入绘图命令，同时加入绘图命令，绘制数据点，然后使用上面计算的分类线方程绘制分类线（这样能直观地观察结果），如图8-4所示。</p>
<p><img src="Image00212.jpg" alt></p>
<p>图8-4 神经网络分类（附彩图）</p>
<p>在如图8-4所示的样本数据点中，大的圆点属于第2类，输出为-1，星号属于第1类，输出为1；在测试数据点中，叉号属于第2类，输出为-1，小点属于第1类，输出为1。中间的虚线就是分类线，这条分类线把坐标系内的点分成为两类，分类线以上的点输出为-1，以下的点输出为1，训练好的神经网络通过这条分类线决定如何对输入所属的分类进行预测。</p>
<p>修改后的Python代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#8-3.py</span><br><span class="line">import numpy as np</span><br><span class="line">import pylab as pl</span><br><span class="line">b=1</span><br><span class="line">a=0.3</span><br><span class="line">x=np.array([[1,1,3],[1,2,3],[1,1,8],[1,2,15],[1,3,7],[1,4,29]])</span><br><span class="line">d=np.array([1,1,-1,-1,1,-1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;=0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def comy(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        return oldw+a*(myd-comy(oldw,myx))*myx</span><br><span class="line">i=0</span><br><span class="line">for xn in x:</span><br><span class="line">        w=neww(w,d[i],xn,a)</span><br><span class="line">        i+=1</span><br><span class="line">myx=x[:,1]</span><br><span class="line">myy=x[:,2]</span><br><span class="line">pl.subplot(111)                  </span><br><span class="line">x_max=np.max(myx)+15</span><br><span class="line">x_min=np.min(myx)-5</span><br><span class="line">y_max=np.max(myy)+50  </span><br><span class="line">y_min=np.min(myy)-5</span><br><span class="line">pl.xlabel(u&quot;x&quot;)</span><br><span class="line">pl.xlim(x_min, x_max)</span><br><span class="line">pl.ylabel(u&quot;y&quot;)</span><br><span class="line">pl.ylim(y_min, y_max)</span><br><span class="line">for i in xrange(0,len(d)):</span><br><span class="line">    if d[i]&gt;0:</span><br><span class="line">        pl.plot(myx[i], myy[i], &apos;r*&apos;)</span><br><span class="line">    else:</span><br><span class="line">        pl.plot(myx[i], myy[i], &apos;ro&apos;)        </span><br><span class="line">#绘制测试点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test=np.array([b,9,19])</span><br><span class="line">if comy(w,test)&gt;0:</span><br><span class="line">    pl.plot(test[1],test[2], &apos;b.&apos;)</span><br><span class="line">else:</span><br><span class="line">    pl.plot(test[1],test[2],&apos;bx&apos;) </span><br><span class="line">test=np.array([b,9,64])</span><br><span class="line">if comy(w,test)&gt;0:</span><br><span class="line">    pl.plot(test[1],test[2], &apos;b.&apos;)</span><br><span class="line">else:</span><br><span class="line">    pl.plot(test[1],test[2],&apos;bx&apos;)</span><br><span class="line">test=np.array([b,9,16])</span><br><span class="line">if comy(w,test)&gt;0:</span><br><span class="line">    pl.plot(test[1],test[2], &apos;b.&apos;)</span><br><span class="line">else:</span><br><span class="line">    pl.plot(test[1],test[2],&apos;bx&apos;)</span><br><span class="line">test=np.array([b,9,60])</span><br><span class="line">if comy(w,test)&gt;0:</span><br><span class="line">    pl.plot(test[1],test[2], &apos;b.&apos;)</span><br><span class="line">else:</span><br><span class="line">    pl.plot(test[1],test[2],&apos;bx&apos;)</span><br><span class="line">#绘制分类线</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testx=np.array(range(0,20))</span><br><span class="line">testy=testx*2+1.68</span><br><span class="line">pl.plot(testx,testy,&apos;g--&apos;)   </span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>上面给出的是单样本感知器算法，算法仅读取一次样本，每读取一个样本，就是一次迭代。每次迭代时，只考虑了用一个训练模式修正权矢量。实际上，可以将几个训练模式一起考虑，而批量修正算法则考虑了使用代价函数来进行分类误差率的控制。批量修正算法要对样本进行多次读取，直到神经网络的误差率降到合适的程度才停止样本的训练，这是它与单样本修正算法本质的区别。算法中的误差率使用最直观的被错分类的样本数量准则。</p>
<p>批量修正算法的核心在于其权值更新策略。批量修正算法采用的是梯度下降原理，其计算公式为：</p>
<p><img src="Image00213.jpg" alt></p>
<p>其中，η(k)称为学习率，<img src="Image00214.jpg" alt> J(w(k))为梯度，计算方法为：</p>
<p><img src="Image00215.jpg" alt></p>
<p>其中，</p>
<p>Yk =被错分类的样本输出值集合</p>
<p>最终得出权值更新策略为：</p>
<p><img src="Image00216.jpg" alt></p>
<p>在上式中，d为样本实际输出值，y为被错分类的样本的输出值。</p>
<p>具体算法过程如下：</p>
<p>1）初始化权值、学习率，以及期望误差率。</p>
<p>2）读取所有样本数据。</p>
<p>3）依次对样本进行训练，更新权值，其更新策略如式（8-1）所示。</p>
<p>4）检查<img src="Image00217.jpg" alt> 是否小于指定误差率，或者训练次数是否已到，如果没有达到误差率的要求且训练次数未到，转到第2步执行。</p>
<p>继续使用单样本修正法的样本，将一组（x，y）的输入划分为以下两类函数之一：</p>
<p>·2x+1=y为第1类。</p>
<p>·7x+1=y为第2类。</p>
<p>下面用Python实现这个神经网络，其中加入了一个不规则的样本数据［1，2，3］，最后用［9，19］和［3，22］对训练成功后的网络进行测试。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-4.py</span><br><span class="line">import numpy as np</span><br><span class="line">b=1</span><br><span class="line">a=0.5</span><br><span class="line">x = np.array([[1,1,3],[1,2,3],[1,1,8],[1,2,15]])</span><br><span class="line">d =np.array([1,1,-1,-1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">wucha=0</span><br><span class="line">ddcount=50</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def comy(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def tiduxz(myw,myx,mya):</span><br><span class="line">        i=0</span><br><span class="line">        sum_x=np.array([0,0,0])</span><br><span class="line">        for xn in myx:</span><br><span class="line">                if comy(myw,xn)!=d[i]:</span><br><span class="line">                        sum_x+=d[i]*xn</span><br><span class="line">                i+=1</span><br><span class="line">        return mya*sum_x        </span><br><span class="line">i=0                </span><br><span class="line">while  True:</span><br><span class="line">        tdxz=tiduxz(w,x,a)</span><br><span class="line">        w=w+tdxz</span><br><span class="line">        i=i+1</span><br><span class="line">        if abs(tdxz.sum())&lt;=wucha or i&gt;=ddcount:break</span><br><span class="line">test=np.array([1,9,19])</span><br><span class="line">print &quot;%d %d =&gt; %d &quot;%(test[1],test[2],comy(w,test))</span><br><span class="line">test=np.array([1,3,22])</span><br><span class="line">print &quot;%d %d =&gt; %d &quot;%(test[1],test[2],comy(w,test))</span><br></pre></td></tr></table></figure>

</details>

<p>运行程序后可发现，训练效果很好，测试数据被正确分类。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">9 19 =&gt; 1 </span><br><span class="line">3 22 =&gt; -1</span><br></pre></td></tr></table></figure>

</details>

<p>3.LMS算法</p>
<p>LMS算法全称为least mean square算法，中文是最小均方算法。在ANN领域内，均方误差是指样本预测输出值与实际输出值之差平方的期望值，记为MSE。设observed为样本真值，predicted为样本预测值，计算公式如下：</p>
<p><img src="Image00218.jpg" alt></p>
<p>LMS算法的策略是使均方误差最小，该算法运行在一个线性神经元上，使用的是批量修正算法，其误差信号为：</p>
<p><img src="Image00219.jpg" alt></p>
<p>然后在误差信号的基础上计算梯度向量，公式如下：</p>
<p><img src="Image00220.jpg" alt></p>
<p>最后，生成权值调整方案。公式如下：</p>
<p><img src="Image00221.jpg" alt></p>
<p>在上式中，η表示学习率，该值越小，LMS算法执行得越精确，但同时算法收敛速度越慢。</p>
<p>下面使用LMS算法实现逻辑或运算，将学习率设为0.1。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-5.py</span><br><span class="line">import numpy as np</span><br><span class="line">b=1</span><br><span class="line">a=0.1</span><br><span class="line">x = np.array([[1,1,1],[1,1,0],[1,0,1],[1,0,0]])</span><br><span class="line">d =np.array([1,1,1,0])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">expect_e=0.005</span><br><span class="line">maxtrycount=20</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return 0</span><br><span class="line">def get_v(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        mye=get_e(oldw,myx,myd)</span><br><span class="line">        return (oldw+a*mye*myx,mye)</span><br><span class="line">def get_e(myw,myx,myd):</span><br><span class="line">        return myd-get_v(myw,myx)</span><br><span class="line">mycount=0</span><br><span class="line">while True:</span><br><span class="line">        mye=0</span><br><span class="line">        i=0          </span><br><span class="line">        for xn in x:</span><br><span class="line">                w,e=neww(w,d[i],xn,a)</span><br><span class="line">                i+=1</span><br><span class="line">                mye+=pow(e,2)  </span><br><span class="line">        mye/=float(i)</span><br><span class="line">        mycount+=1</span><br><span class="line">        print u&quot;第</span><br><span class="line"></span><br><span class="line"> %d 次调整后的权值：</span><br><span class="line"></span><br><span class="line">&quot;%mycount</span><br><span class="line">        print w</span><br><span class="line">        print u&quot;误差：</span><br><span class="line"></span><br><span class="line">%f&quot;%mye        </span><br><span class="line">        if mye&lt;expect_e or mycount&gt;maxtrycount:break </span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d or %d =&gt; %d &quot;%(xn[1],xn[2],get_v(w,xn))</span><br></pre></td></tr></table></figure>

</details>

<p>下面是程序的运行结果，可以看出，通过13次迭代，训练结束，对测试值的输出正确。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">..........</span><br><span class="line">..........第</span><br><span class="line"></span><br><span class="line"> 12 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[-0.1  0.1  0.1]误差：</span><br><span class="line"></span><br><span class="line">0.500000第</span><br><span class="line"></span><br><span class="line"> 13 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[-0.1  0.1  0.1]误差：</span><br><span class="line"></span><br><span class="line">0.000000</span><br><span class="line">1 or 1 =&gt; 1 </span><br><span class="line">1 or 0 =&gt; 1 </span><br><span class="line">0 or 1 =&gt; 1 </span><br><span class="line">0 or 0 =&gt; 0 </span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

</details>

<p>另外，可应用LMS算法实现比逻辑与更复杂的算法，比如：在输入矩阵中，如果x向量的整除结果为6，则表示为一类，输出为1；若结果为3则是另一类，输出为-1。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-6.py</span><br><span class="line">import numpy as np</span><br><span class="line">b=1</span><br><span class="line">a=0.1</span><br><span class="line">x = np.array([[1,1,6],[1,2,12],[1,3,9],[1,8,24]])</span><br><span class="line">d =np.array([1,1,-1,-1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">expect_e=0.005</span><br><span class="line">maxtrycount=20</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def get_v(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        mye=get_e(oldw,myx,myd)</span><br><span class="line">        return (oldw+a*mye*myx,mye)</span><br><span class="line">def get_e(myw,myx,myd):</span><br><span class="line">        return myd-get_v(myw,myx)</span><br><span class="line">mycount=0</span><br><span class="line">while True:</span><br><span class="line">        mye=0</span><br><span class="line">        i=0          </span><br><span class="line">        for xn in x:</span><br><span class="line">                w,e=neww(w,d[i],xn,a)</span><br><span class="line">                i+=1</span><br><span class="line">                mye+=pow(e,2)  </span><br><span class="line">        mye/=float(i)              </span><br><span class="line">        mycount+=1</span><br><span class="line">        print u&quot;第</span><br><span class="line"></span><br><span class="line"> %d 次调整后的权值：</span><br><span class="line"></span><br><span class="line">&quot;%mycount</span><br><span class="line">        print w</span><br><span class="line">        print u&quot;误差：</span><br><span class="line"></span><br><span class="line">%f&quot;%mye        </span><br><span class="line">        if abs(mye)&lt;expect_e or mycount&gt;maxtrycount:break               </span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d    %d =&gt; %d &quot;%(xn[1],xn[2],get_v(w,xn))</span><br><span class="line">test=np.array([1,9,27])  </span><br><span class="line">print &quot;%d     %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))  </span><br><span class="line">test=np.array([1,11,66])  </span><br><span class="line">print &quot;%d     %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))</span><br></pre></td></tr></table></figure>

</details>

<p>通过9次训练后，误差率为0，用样本数据和测试数据进行验证，准确无误。下面是执行结果：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">................</span><br><span class="line">.................第</span><br><span class="line"></span><br><span class="line"> 8 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.4 -2.8  0.6]误差：</span><br><span class="line"></span><br><span class="line">3.000000第</span><br><span class="line"></span><br><span class="line"> 9 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.4 -2.8  0.6]误差：</span><br><span class="line"></span><br><span class="line">0.000000</span><br><span class="line">1    6 =&gt; 1 </span><br><span class="line">2    12 =&gt; 1 </span><br><span class="line">3    9 =&gt; -1 </span><br><span class="line">8    24 =&gt; -1 </span><br><span class="line">9     27 =&gt; -1 </span><br><span class="line">11     66 =&gt; 1</span><br></pre></td></tr></table></figure>

</details>

<p>4.Rosenblatt感知器的局限性</p>
<p>不是所有的数据都能被Rosenblatt感知器正确分类。比如说下面的样本数据：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[1,1,6],[1,3,12],[1,3,9],[1,3,21],[1,2,16],[1,3,15]]) d =np.array([1,1,-1,-1,1,-1])</span><br></pre></td></tr></table></figure>

</details>

<p>应用LMS算法对这些数据训练200次，效果仍非常差，样本数据和测试数据都无法正确分类。如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">............</span><br><span class="line">............第</span><br><span class="line"></span><br><span class="line"> 199 次调整后的权值：</span><br><span class="line"></span><br><span class="line">[ 18.  -17.2   0.8]误差：</span><br><span class="line"></span><br><span class="line">2.666667第</span><br><span class="line"></span><br><span class="line"> 200 次调整后的权值：</span><br><span class="line"></span><br><span class="line">[ 18.  -17.4  -0.8]误差：</span><br><span class="line"></span><br><span class="line">2.666667第</span><br><span class="line"></span><br><span class="line"> 201 次调整后的权值：</span><br><span class="line"></span><br><span class="line">[ 18.4 -16.8   1.8]误差：</span><br><span class="line"></span><br><span class="line">2.6666671    6 =&gt; 1 3    12 =&gt; -1 3    9 =&gt; -1 3    21 =&gt; 1 2    16 =&gt; 1 3    15 =&gt; -1 9     27 =&gt; -1 </span><br><span class="line">11     66 =&gt; -1</span><br></pre></td></tr></table></figure>

</details>

<p>为什么会出现这种情况？试着修改8-6.py的样本数据，同时绘制包括这些点的散点图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-7.py</span><br><span class="line">import numpy as np</span><br><span class="line">import pylab as pl</span><br><span class="line">b=1</span><br><span class="line">a=0.1</span><br><span class="line">x = np.array([[1,1,6],[1,3,12],[1,3,9],[1,3,21],[1,2,16],[1,3,15]]) </span><br><span class="line">d =np.array([1,1,-1,-1,1,-1]) </span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">expect_e=0.005</span><br><span class="line">maxtrycount=200</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def get_v(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        mye=get_e(oldw,myx,myd)</span><br><span class="line">        return (oldw+a*mye*myx,mye)</span><br><span class="line">def get_e(myw,myx,myd):</span><br><span class="line">        return myd-get_v(myw,myx)</span><br><span class="line">mycount=0</span><br><span class="line">while True:</span><br><span class="line">        mye=0</span><br><span class="line">        i=0          </span><br><span class="line">        for xn in x:</span><br><span class="line">                w,e=neww(w,d[i],xn,a)</span><br><span class="line">                i+=1</span><br><span class="line">                mye+=pow(e,2)  </span><br><span class="line">        mye/=float(i)              </span><br><span class="line">        mycount+=1</span><br><span class="line">        print u&quot;第</span><br><span class="line"></span><br><span class="line"> %d 次调整后的权值：</span><br><span class="line"></span><br><span class="line">&quot;%mycount</span><br><span class="line">        print w</span><br><span class="line">        print u&quot;误差：</span><br><span class="line"></span><br><span class="line">%f&quot;%mye        </span><br><span class="line">        if abs(mye)&lt;expect_e or mycount&gt;maxtrycount:break                </span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d    %d =&gt; %d &quot;%(xn[1],xn[2],get_v(w,xn))</span><br><span class="line">test=np.array([1,9,27])  </span><br><span class="line">print &quot;%d     %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))  </span><br><span class="line">test=np.array([1,11,66])  </span><br><span class="line">print &quot;%d     %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))</span><br><span class="line">myx=x[:,1]</span><br><span class="line">myy=x[:,2]</span><br><span class="line">pl.subplot(111)</span><br><span class="line">x_max=np.max(myx)+10</span><br><span class="line">x_min=np.min(myx)-5</span><br><span class="line">y_max=np.max(myy)+50  </span><br><span class="line">y_min=np.min(myy)-5</span><br><span class="line">pl.xlabel(u&quot;x&quot;)</span><br><span class="line">pl.xlim(x_min, x_max)</span><br><span class="line">pl.ylabel(u&quot;y&quot;)</span><br><span class="line">pl.ylim(y_min, y_max)</span><br><span class="line">#绘制样本点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in xrange(0,len(d)):</span><br><span class="line">    if d[i]&gt;0:</span><br><span class="line">        pl.plot(myx[i], myy[i], &apos;r*&apos;)</span><br><span class="line">    else:</span><br><span class="line">        pl.plot(myx[i], myy[i], &apos;ro&apos;)</span><br><span class="line">#绘制测试点</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test=np.array([1,9,27]) </span><br><span class="line">pl.plot(test[1],test[2], &apos;bx&apos;)</span><br><span class="line">test=np.array([1,11,66]) </span><br><span class="line">pl.plot(test[1],test[2], &apos;bx&apos;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>在如图8-5所示的散点图中，实心圆圈和星号是两类不同的样本点，叉号为测试点。在这张图中，无法画出一条线来将两类点分开，只有曲线才能将它们分开，但线性方程根本不可能产生的曲线，因此Rosenblatt感知器不适用于非线性分类。</p>
<p><img src="Image00222.jpg" alt></p>
<p>图8-5 散点图</p>
<p>5.LMS的学习率退火算法</p>
<p>模拟退火算法来源于固体退火原理。退火就是将材料加热后再经特定速率冷却，目的是增大晶粒的体积，并且减少晶格中的缺陷。材料中的原子原来会停留在使内能有局部最小值的位置，加热使能量变大，原子会离开原来位置，而随机在其他位置中移动。退火冷却时速度较慢，徐徐冷却时粒子渐趋有序，原子有可能找到内能比原先更低的位置，最后在常温时达到基态，内能减为最小。</p>
<p>根据Metropolis准则，粒子在温度T时趋于平衡的概率为e-ΔE/(kT)，其中E为温度T时的内能，ΔE为其改变量，k为Boltzmann常数。用固体退火模拟组合优化问题，将内能E模拟为目标函数值f，温度T演化成控制参数t，即得到解组合优化问题的模拟退火算法：由初始解i和控制参数初值t开始，对当前解重复进行“产生新解→计算目标函数差→接受或舍弃”的迭代，并逐步衰减t值，算法终止时的当前解即为所得近似最优解，这是基于蒙特卡罗迭代求解法的一种启发式随机搜索过程。退火过程由冷却进度表控制，包括控制参数的初值t及其衰减因子Δt、每个t值时的迭代次数L和停止条件S。</p>
<p>针对学习率不变化、收敛速度较慢的情况，即可使用退火算法方案，让学习率随时间而变化。学习率计算公式为：</p>
<p><img src="Image00223.jpg" alt></p>
<p>下面应用退火算法对代码8-6.py做一些改动，代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-8.py</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">b=1</span><br><span class="line">a0=0.1</span><br><span class="line">a=0.0</span><br><span class="line">r=5.0</span><br><span class="line">x = np.array([[1,1,6],[1,2,12],[1,3,9],[1,8,24]])</span><br><span class="line">d =np.array([1,1,-1,-1])</span><br><span class="line">w=np.array([b,0,0])</span><br><span class="line">expect_e=0.05</span><br><span class="line">maxtrycount=20</span><br><span class="line">mycount=0</span><br><span class="line">def sgn(v):</span><br><span class="line">        if v&gt;0:</span><br><span class="line">                return 1</span><br><span class="line">        else:</span><br><span class="line">                return -1</span><br><span class="line">def get_v(myw,myx):</span><br><span class="line">        return sgn(np.dot(myw.T,myx))</span><br><span class="line">def neww(oldw,myd,myx,a):</span><br><span class="line">        mye=get_e(oldw,myx,myd)</span><br><span class="line">        a=a0/(1+float(mycount)/r)</span><br><span class="line">        return (oldw+a*mye*myx,mye)</span><br><span class="line">def get_e(myw,myx,myd):</span><br><span class="line">        return myd-get_v(myw,myx)</span><br><span class="line">while True:</span><br><span class="line">        mye=0</span><br><span class="line">        i=0          </span><br><span class="line">        for xn in x:</span><br><span class="line">                w,e=neww(w,d[i],xn,a)</span><br><span class="line">                i+=1</span><br><span class="line">                mye+=pow(e,2)</span><br><span class="line">        mye=math.sqrt(mye)</span><br><span class="line">        mycount+=1</span><br><span class="line">        print u&quot;第</span><br><span class="line"></span><br><span class="line"> %d 次调整后的权值：</span><br><span class="line"></span><br><span class="line">&quot;%mycount</span><br><span class="line">        print w</span><br><span class="line">        print u&quot;误差：</span><br><span class="line"></span><br><span class="line">%f&quot;%mye        </span><br><span class="line">        if abs(mye)&lt;expect_e or mycount&gt;maxtrycount:break</span><br><span class="line">for xn in x:</span><br><span class="line">        print &quot;%d   %d =&gt; %d &quot;%(xn[1],xn[2],get_v(w,xn))</span><br><span class="line">test=np.array([1,9,27])  </span><br><span class="line">print &quot;%d   %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))  </span><br><span class="line">test=np.array([1,11,66])  </span><br><span class="line">print &quot;%d   %d =&gt; %d &quot;%(test[1],test[2],get_v(w,test))</span><br></pre></td></tr></table></figure>

</details>

<p>从程序运行结果来看，仅仅7次就完成了训练，训练次数大大减少。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">...........</span><br><span class="line">...........第</span><br><span class="line"></span><br><span class="line"> 6 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.28888889 -1.55238095  0.29642857]误差：</span><br><span class="line"></span><br><span class="line">3.464102第</span><br><span class="line"></span><br><span class="line"> 7 次调整后的权值：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.28888889 -1.55238095  0.29642857]误差：</span><br><span class="line"></span><br><span class="line">0.000000</span><br><span class="line">1   6 =&gt; 1 </span><br><span class="line">2   12 =&gt; 1 </span><br><span class="line">3   9 =&gt; -1 </span><br><span class="line">8   24 =&gt; -1 </span><br><span class="line">9   27 =&gt; -1 </span><br><span class="line">11   66 =&gt; 1 </span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

</details>

<h4 id="8-1-2-梯度下降"><a href="#8-1-2-梯度下降" class="headerlink" title="8.1.2 梯度下降"></a>8.1.2 梯度下降</h4><p>1.梯度下降概述</p>
<p>上一节中曾提到梯度的概念，究竟什么是梯度和梯度下降呢？</p>
<p>梯度是一个向量场，标量场中某一点上的梯度指向标量场增长最快的方向，梯度的长度是这个最大的变化率。梯度下降，就是利用负梯度方向来决定每次迭代的新的搜索方向，从而使得在每次迭代过程中，都能让待优化的目标函数逐步减小。梯度下降法使用的是二范数下的最速下降法。最速下降法的一种简单形式如下：</p>
<p>x(k+1)=x(k)-a*g(k)</p>
<p>其中，a称为学习速率，可以是较小的常数。g(k)是x(k)的梯度。</p>
<p>机器学习算法效果究竟如何，或者说误差为多少，可以用误差函数J(θ)来度量。其中的参数θ在神经网络中可以理解为权值。如何调整权值θ以使得J(θ)取得最小值有很多方法，梯度下降法是按下面的步骤进行的：</p>
<p>1）对θ赋值，这个值可以是随机的，也可以让θ是一个全零的向量。</p>
<p>2）改变θ的值，使得J(θ)按梯度下降的方向进行减少。</p>
<p>为了更清楚地表达，先来看一下如图8-6所示的误差曲面及梯度下降图。</p>
<p>图8-6是表示参数θ与误差函数J(θ)关系的图，也称误差曲面图。该图上的方向表明，随着迭代次数的增加，误差走向了曲面的最小误差点。</p>
<p>红色较凸起的部分是表示J(θ)有着比较高的取值，对其进行神经网络训练时，最完美的目标是：让J(θ)的值尽量低，降到最低处，也就是最凹的部分。θ0 、θ1 表示θ向量的两个维度。</p>
<p>梯度下降法的第一步是给θ一个初值，假设随机给的初值是在最高的十字点处；然后将θ按照梯度下降的方向进行调整，就会使得J(θ)往更低的方向变化，如图8-7所示。算法的结束将是在θ下降到无法继续下降为止。当然，可能梯度下降的最终点并非是全局最小点（图8-6的路径中的最后一个点），而是一个局部最小点（图8-7的路径中的最后一个点），比如图8-7所示的情况，而图8-6中的曲线路径则是完美的梯度下降过程。</p>
<p>图8-7中所示的这种情况是在神经网络训练中要尽量避免出现的，这里的梯度下降到局部最小点后停止，神经网络在一个不正确的位置收敛了，训练停止，这时即使继续训练也没有任何效果。</p>
<p><img src="Image00224.jpg" alt></p>
<p>图8-6 误差曲面及梯度下降（附彩图）</p>
<p><img src="Image00225.jpg" alt></p>
<p>图8-7 落到局部最小点的梯度下降（附彩图）</p>
<p>2.梯度下降法涉及的数学知识</p>
<p>1）导数的几何意义：导数的几何意义在于，函数在某一点的导数等于它的图像上这一点处之切线的斜率，如图8-8所示。</p>
<p><img src="Image00226.jpg" alt></p>
<p>图8-8 导数</p>
<p>其斜率为：</p>
<p><img src="Image00227.jpg" alt></p>
<p>2）积分的几何意义：对于一个给定的正实值函数f(x)，f(x)在一个实数区间［a，b］上的定积分为：</p>
<p><img src="Image00228.jpg" alt></p>
<p>定积分的几何意义可以理解为在Oxy坐标平面上，由曲线(x，f(x))、直线x=a，x=b以及x轴围成的曲边梯形的面积，这个面积可以是一块面积，也可以是多块面积的和（注意，这里的面积有正负之分）。</p>
<p>3）微分的几何意义：一元函数的微分与自变量的微分之商等于该函数的导数，所以导数也叫做微商。</p>
<p>设Δx是曲线y=f(x)上的点P在横坐标上的增量，Δy是曲线在点P处相对于Δx的纵坐标增量，dy是曲线在点P的切线对应Δx在纵坐标上的增量，如图8-9所示。</p>
<p><img src="Image00229.jpg" alt></p>
<p>图8-9 微分</p>
<p>4）偏导数：拥有多个自变量的函数的偏导数是指在保持其他自变量恒定的情况下，该函数相对于其中某个自变量的导数。函数f关于变量x的偏导数写为f’x 或<img src="Image00230.jpg" alt> 。</p>
<p>f是一个多元函数。例如：</p>
<p>f(x，y)=x2 +xy+y2</p>
<p>因为曲面上的每一点都有无穷多条切线，描述这种函数的导数相当困难。偏导数就是选择其中一条切线，并求出它的斜率。</p>
<p>多自变量函数f(x1 ，…，xn )在点（a1 ，…，an ）处，对于某个自变量xi 的偏导数，其定义为：</p>
<p><img src="Image00231.jpg" alt></p>
<p>5）梯度：欧几里得空间Rn 中的函数f(x1 ，…，xn )对每个自变量xj 具有偏导数<img src="Image00232.jpg" alt> ，在点a处，这些偏导数定义了一个向量：</p>
<p><img src="Image00233.jpg" alt></p>
<p>这个向量称为f在点a处的梯度。</p>
<p>3.梯度下降的原理</p>
<p>如果实值函数F(x)在点a处可微且有定义，那么该函数在a点沿着梯度相反的方向下降最快，从函数F对局部极小值的初始估计值x0 出发，存在如下序列x0 ，x1 ，x2 ，…，使得</p>
<p><img src="Image00234.jpg" alt></p>
<p>因此可得到</p>
<p>F(x0 )≥F(x1 )≥F(x2 )≥…</p>
<p>如果顺利的话，序列（Xn ）将收敛到期望的极值。</p>
<p>4.梯度下降和delta法则</p>
<p>delta法则克服了感应器法则的不足，在线性不可分的训练样本上，可以有效地收敛，并接近目标的最佳近似值。delta法则的关键思想是：使用梯度下降来搜索可能的权向量假设空间，以找到最佳拟合训练样例的权向量。</p>
<p>delta法则为反向传播算法提供了基础，而反向传播算法能够学习多个单元的互连网络，在包含多种不同类型的连续参数化假设的空间中，梯度下降是必须遍历这样的空间的所有算法的基础。</p>
<p>误差曲面是一个抛物面，存在一个单一全局最小值，梯度下降搜索从一个任意的初始权向量开始，然后沿误差曲面最陡峭下降的方向，以很小的步伐反复修改这个向量，直到得到全局的最小误差点。</p>
<p>5.基于梯度下降的线性分类器</p>
<p>下面总结一下前面介绍的线性神经网络代码，并将它们整理成Python模块mplannliner，然后引入这个模块，实现对一组输入的线性分类。以下程序有详细的注释说明。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-9.py</span><br><span class="line">import mplannliner as nplann                         </span><br><span class="line">traindatal=[[[9,25],-1],[[5,8],-1,[[15,31],-1],[[35,62],-1],[[19,40],-1],[[28,6</span><br><span class="line">5],1],[[20,59],1],[[9,41],1],[[12,60],1],[[2,37],1]]</span><br><span class="line">myann=nplann.Mplannliner()</span><br><span class="line">#样本初始化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.samples_init(traindata1)</span><br><span class="line">#学习率初始化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.a_init(0.1)</span><br><span class="line">#搜索时间常数初始化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.r_init(50)</span><br><span class="line">#最大训练次数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.maxtry_init(500)</span><br><span class="line">#期望最小误差</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.e_init(0.05)</span><br><span class="line">#训练</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.train()</span><br><span class="line">#仿真，测试，对未知样本分类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myc=myann.simulate([35,68])</span><br><span class="line">print &quot;[35,68]&quot;</span><br><span class="line">if myc==1:</span><br><span class="line">    print u&quot;正类</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">else:</span><br><span class="line">    print u&quot;负类</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">#将测试点在最终效果图上显示出来，将它加入</span><br><span class="line"></span><br><span class="line">drawponint集，测试点表现为</span><br><span class="line"></span><br><span class="line">&quot;*&quot;,并且色彩由其最终的分类结果而决定</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">myann.drawponint_add([35,68])</span><br><span class="line">myc=myann.simulate([35,82])</span><br><span class="line">print &quot;[35,82]&quot;</span><br><span class="line">if myc==1:</span><br><span class="line">    print u&quot;正类</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">else:</span><br><span class="line">    print u&quot;负类</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">myann.drawponint_add([35,82])    </span><br><span class="line">myann.draw2d()</span><br><span class="line">#下面直接使用默认参数进行训练</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">traindata2=[[[9,25,30],-1],[[5,8,12],-1],[[15,31,49],-1],[[35,62,108],</span><br><span class="line">-1],[[19,40,60],-1],[[28,65,98],1],[[20,59,72],1],[[9,41,38],1],[[12,60,46],1],[[2,37,</span><br><span class="line">18],1]]</span><br><span class="line">myann2=nplann.Mplannliner()</span><br><span class="line">myann2.samples_init(traindata2)</span><br><span class="line">myann2.train()</span><br><span class="line">myc=myann2.simulate([35,68,110])</span><br><span class="line">print &quot;[35,68,110]&quot;</span><br><span class="line">if myc==1:</span><br><span class="line">    print u&quot;正类</span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">else:</span><br><span class="line">    print u&quot;负类</span><br><span class="line"></span><br><span class="line">&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>如图8-10所示是程序运行生成的效果图，虚线是分类线，它清晰地将不同类的点分成了上下两部分。星号为测试数据，可以看到，已被正确分类。Rosenblatt感知器对线性分类效果还是不错的。</p>
<p><img src="Image00235.jpg" alt></p>
<p>图8-10 线性分类效果</p>
<p>mplannliner模块的代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#author:麦好</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2013-07-25</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">class Mplannliner:</span><br><span class="line">        def __init__(self):</span><br><span class="line">                self.b=1</span><br><span class="line">                self.a0=0.1</span><br><span class="line">                self.a=0.0</span><br><span class="line">                self.r=20.0</span><br><span class="line">                self.expect_e=0.05</span><br><span class="line">                self.traincount=100</span><br><span class="line">                self.testpoint=[]</span><br><span class="line">        def testpoint_init(self):</span><br><span class="line">                self.testpoint=[]</span><br><span class="line">        def e_init(self,mye):</span><br><span class="line">                self.expect_e=mye</span><br><span class="line">        def samples_init(self,mysamples):</span><br><span class="line">                my_x =[]</span><br><span class="line">                my_d =[]</span><br><span class="line">                my_w =[self.b] </span><br><span class="line">                myexamp=mysamples</span><br><span class="line">                for mysmp in myexamp:</span><br><span class="line">                        tempsmp=[1]+mysmp[0]</span><br><span class="line">                        my_x.append(tempsmp)</span><br><span class="line">                        my_d.append(mysmp[1])</span><br><span class="line">                for i in range(len(my_x[0])-1):</span><br><span class="line">                        my_w.append(0.0)        </span><br><span class="line">                self.x = np.array(my_x)</span><br><span class="line">                self.d = np.array(my_d)</span><br><span class="line">                self.w = np.array(my_w)</span><br><span class="line">        def a_init(self,mya):</span><br><span class="line">                self.a0=mya</span><br><span class="line">        def r_init(self,myr):</span><br><span class="line">                self.r=myr</span><br><span class="line">        def maxtry_init(self,maxc):</span><br><span class="line">                self.traincount=maxc                </span><br><span class="line">        def sgn(self,v):</span><br><span class="line">                if v&gt;0:</span><br><span class="line">                        return 1</span><br><span class="line">                else:</span><br><span class="line">                        return -1</span><br><span class="line">        def get_v(self,myw,myx):</span><br><span class="line">                return self.sgn(np.dot(myw.T,myx))</span><br><span class="line">        def neww(self,oldw,myd,myx,a,mycount):</span><br><span class="line">                mye=self.get_e(oldw,myx,myd)</span><br><span class="line">                self.a=self.a0/(1+mycount/float(self.r))</span><br><span class="line">                return (oldw+a*mye*myx,mye)</span><br><span class="line">        def get_e(self,myw,myx,myd):</span><br><span class="line">                return myd-self.get_v(myw,myx)</span><br><span class="line">        def train(self):         </span><br><span class="line">                mycount=0</span><br><span class="line">                while True:</span><br><span class="line">                        mye=0</span><br><span class="line">                        i=0          </span><br><span class="line">                        for xn in self.x:</span><br><span class="line">                       self.w,e=self.neww(self.w,self.d[i],\</span><br><span class="line">                  xn,self.a,mycount)</span><br><span class="line">                               i+=1</span><br><span class="line">                               mye+=pow(e,2)</span><br><span class="line">                        mye=math.sqrt(mye)</span><br><span class="line">                        mycount+=1</span><br><span class="line">                        print u&quot;第</span><br><span class="line"></span><br><span class="line">%d次调整中…误差：</span><br><span class="line"></span><br><span class="line">%f&quot;%(mycount,mye)   </span><br><span class="line">                        if abs(mye)&lt;self.expect_e or mycount&gt;self.traincount:</span><br><span class="line">                            if mycount&gt;self.traincount:</span><br><span class="line">                      print &quot;已经达到最大训练次数</span><br><span class="line"></span><br><span class="line">:%d&quot;%mycount</span><br><span class="line">                            break</span><br><span class="line">        def simulate(self,testdata):</span><br><span class="line">                if self.get_v(self.w,np.array([1]+testdata))&gt;0:</span><br><span class="line">                    return 1</span><br><span class="line">                else:</span><br><span class="line">                    return -1</span><br><span class="line">        def drawponint_add(self,point):</span><br><span class="line">                self.testpoint.append(point)</span><br><span class="line">        def draw2d(self):</span><br><span class="line">                temp_x=[]</span><br><span class="line">                temp_y=[]</span><br><span class="line">                i=0</span><br><span class="line">                for mysamp in self.x:</span><br><span class="line">                                temp_x.append(mysamp[1])</span><br><span class="line">                                temp_y.append(mysamp[2])</span><br><span class="line">                                if self.d[i] &gt; 0:</span><br><span class="line">                                   plt.plot(mysamp[1],mysamp[2],&quot;or&quot;)</span><br><span class="line">                                else:</span><br><span class="line">                                   plt.plot(mysamp[1],mysamp[2],&quot;og&quot;)</span><br><span class="line">                                i+=1</span><br><span class="line">                mytestpointx=[]</span><br><span class="line">                mytestpointy=[]</span><br><span class="line">                for addpoint in self.testpoint:</span><br><span class="line">                    if self.simulate(addpoint)==&quot;+&quot;:</span><br><span class="line">                        plt.plot(addpoint[0],addpoint[1], &apos;*r&apos;)</span><br><span class="line">                    else:</span><br><span class="line">                        plt.plot(addpoint[0],addpoint[1], &apos;*g&apos;)</span><br><span class="line">                    mytestpointx.append(addpoint[0])</span><br><span class="line">                    mytestpointy.append(addpoint[1])</span><br><span class="line">                x_max=max(max(temp_x),max(mytestpointx))+5</span><br><span class="line">                x_min=min(min(temp_x),min(mytestpointx))</span><br><span class="line">                y_max=max(max(temp_y),max(mytestpointy))+5</span><br><span class="line">                y_min=min(min(temp_y),min(mytestpointy))</span><br><span class="line">                if x_min &gt;0:</span><br><span class="line">                   x_min=0</span><br><span class="line">                if y_min &gt;0:</span><br><span class="line">                   y_min=0      </span><br><span class="line">                plt.xlabel(u&quot;x1&quot;)</span><br><span class="line">                plt.xlim(x_min, x_max)</span><br><span class="line">                plt.ylabel(u&quot;x2&quot;)</span><br><span class="line">                plt.ylim(y_min, y_max)</span><br><span class="line">                plt.title(&quot;ANN-LINER[red:+ green:-]&quot; )</span><br><span class="line">                lp_x1 = [x_min, x_max]</span><br><span class="line">                lp_x2 = []</span><br><span class="line">                myb=self.w[0]</span><br><span class="line">                myw1=self.w[1]</span><br><span class="line">                myw2=self.w[2]</span><br><span class="line">                myy=(-myb-myw1*lp_x1[0])/float(myw2)</span><br><span class="line">                lp_x2.append(myy)</span><br><span class="line">                myy=(-myb-myw1*lp_x1[1])/float(myw2)</span><br><span class="line">                lp_x2.append(myy)</span><br><span class="line">                plt.plot(lp_x1, lp_x2, &apos;b--&apos;)</span><br><span class="line">                plt.show()</span><br></pre></td></tr></table></figure>

</details>

<h4 id="8-1-3-反向传播与多层感知器"><a href="#8-1-3-反向传播与多层感知器" class="headerlink" title="8.1.3 反向传播与多层感知器"></a>8.1.3 反向传播与多层感知器</h4><p>1.反向传播算法</p>
<p>反向传播算法对梯度下降法进行了改进，主要由两个环节（激励传播、权重更新）反复循环迭代，直到网络对输入的响应达到预定的目标范围为止。它可用来学习多层网络的权值，通过搜索一个巨大的假设空间（这个空间由网络中所有单元的所有可能权值定义）得到误差曲面。在多层神经网络中，误差曲面存在全局最小值，但也可能存在多个局部极小值，梯度下降法不能保证收敛到全局极小值，但反向传播算法较好地解决了这个问题，在实践中有出色的效果。反向传播算法有以下特点：</p>
<p>1）网络中的每个神经元模型包括一个非线性激活函数，非线性是光滑的（即处处可微）也是必要的，否则网络的输入输出关系会被归结为单层感知器。</p>
<p>2）网络包括一层或多层神经元的隐层，它不负责网络的输入输出。这些隐层神经元逐步从输入向量中提取有用特征，使网络学习复杂的任务。</p>
<p>3）网络的连接强度由网络突触决定。</p>
<p>反向传播算法的主要过程如下：</p>
<p>1）激励传播过程。在神经元j的激活函数输入处应用诱导局部域υj (n)，定义如下：</p>
<p><img src="Image00236.jpg" alt></p>
<p>这个过程完成逐层从输入层传播至输出层的任务。</p>
<p>2）权重更新过程。对每层的神经元的权值进行修正，公式如下：</p>
<p>Δwji (n)=ηδj (n)yi (n)</p>
<p>其中，Δwji (n)是指神经元i连接到神经元j的突触ji的权值的校正值，η是学习率，δj (n)是局部梯度。</p>
<p>反向传播算法的过程如下：</p>
<p>从建立一个具有期望数量的隐藏单元和输出单元的网络开始，初始化所有的网络的权值为较小的随机数（0~1的实数）；然后，给定一个固定的网络结构；最后，算法的主循环对训练样例进行反复迭代，对于每一个训练样例，它会应用目前的网络到这个样例中，并计算出对这个样例网络输出的误差，更新网络中所有的权值，然后对这样的梯度下降步骤进行迭代，直到网络的性能达到可接受的精度为止。</p>
<p>但该算法存在局限性，仍然无法摆脱陷入局部最小误差的地步。因此，要在此基础上增加冲量（动量）项。通过修改权值更新法则，使第n次迭代时权值的更新受到第n-1次迭代的影响，即本次迭代的更新值的计算，有部分参数来自于上次迭代的更新值，这样，冲量有时会滚过误差曲面的局部极小值，并在梯度不变的区域内逐渐增大搜索步长，加快收敛，从而减少训练次数。</p>
<p>2.多层感知器网络</p>
<p>多层感知器利用非线性神经元作为中间隐藏层神经元，输出端可以直接使用非线性神经元，也可以使用线性神经元。如图8-11所示是一个拥有两个隐藏层的多层感知器网络。</p>
<p>在图8-11中，网络由输入层、隐藏层及输出层构成，它能够表示种类繁多的非线性曲面，多层网络能在隐藏层自动发现并被有效表示。它允许学习器创造出设计者没有明确引入的特征，网络中使用的单元层越多，可以创造出的特征越复杂。</p>
<p>多层感知器的激活函数及局域梯度如下。</p>
<p><img src="Image00237.jpg" alt></p>
<p>图8-11 多层感知器网络</p>
<p>1）logistic函数。logistic函数的定义为：</p>
<p><img src="Image00238.jpg" alt></p>
<p>它又称sigmoid曲线（S形曲线），如图8-12所示是它的图像，很像字母S。</p>
<p><img src="Image00239.jpg" alt></p>
<p>图8-12 sigmoid曲线（附彩图）</p>
<p>在多层感知器中，logistic函数可作为神经元j的激活函数φ’j (υj (n))，它定义为：</p>
<p><img src="Image00240.jpg" alt></p>
<p>其中，υj (n)是神经元j的诱导局部域。</p>
<p>logistic函数的局部梯度需要分两种情况定义：</p>
<p>第一种情况，神经j没有位于隐藏层，则局部梯度定义为：</p>
<p>δj (n)=a(dj (n)-oj (n))oj (n)(1-oj (n))</p>
<p>第二种情况，神经j位于隐藏层，则局部梯度定义为：</p>
<p><img src="Image00241.jpg" alt></p>
<p>2）tanh函数。tanh（双曲正切）函数的数学定义为：</p>
<p><img src="Image00242.jpg" alt></p>
<p>双曲正切函数的图像如图8-13所示。</p>
<p><img src="Image00243.jpg" alt></p>
<p>图8-13 双曲正切函数</p>
<p>在多层感知器中，双曲正切函数可作为神经元j的激活函数φ’j (υj (n))，它定义为：</p>
<p>φj (υj (n))=atanh(bυj (n))</p>
<p>其中，a和b为正的常数值，υj (n)是神经元j的诱导局部域。</p>
<p>双曲正切函数的局部梯度需要分两种情况定义：</p>
<p>第一种情况，神经元j没有位于隐藏层，则局部梯度定义为：</p>
<p><img src="Image00244.jpg" alt></p>
<p>第二种情况，神经j位于隐藏层，则局部梯度定义为：</p>
<p><img src="Image00245.jpg" alt></p>
<p>前面说过，多层感知器利用非线性神经元作为中间隐藏层神经元，非线性神经元使用双曲正切函数或logistic函数作为激活函数，使用非线性神经元或使用线性神经元组成输出层。多层感知器的训练需要很多样本，其中每个样本的学习过程分为前向计算和反向计算。</p>
<p>前向计算根据权值矩阵由前向后一层层神经元地推进，每次推进根据权值计算每层的输出值；反向计算根据输出结果与目标输出的误差来由后向前调整神经网络的权值，引入冲量作为神经网络权值调整的依据之一，冲量（动量）参数既可以调整学习速度，还能体现时间延迟。</p>
<p>整个算法过程也是反向传播算法的过程，通过使用梯度下降方法搜索可能假设的空间，迭代减小网络的误差以拟合训练数据。</p>
<p>如果不调用神经网络的中间库，自己编写所有的代码，需要把握好以下要点：</p>
<p>1）学习率和动量参数。输入层、输出层、中间层的学习率和动量参数不同。输出层的学习率较低，动量参数较高；输入层的学习率较低，动量参数较低。</p>
<p>2）权值。权值矩阵非常重要，一个好的权值矩阵能使网络快速收敛，让网络更稳定。关于权值初始化的策略，可以选择以下几种方法：</p>
<p>·随机初始化。</p>
<p>·逐步搜索法。</p>
<p>·Nguyen-Widrow初始化算法，MATLAB使用Nguyen-Widrow权值矩阵初始化算法。</p>
<p>3）输出层处理，为了确保输出层输出的数据符合预测结果的要求，需要另外的函数对输出层进行处理。在线性神经网络中，通常使用硬限幅函数，在多层感知器这种非线性神经网络中既可以使用硬限幅，也可以使用其他函数，具体使用什么函数要看训练效果如何。</p>
<p>4）数据预处理。输入数据五花八门，在训练之前对数据进行预处理是非常必要的。通过预处理权值矩阵使进入神经网络的数值不会过大或过小，以保证通过中间层的非线性神经元时，输出不逼近其极限。</p>
<p>先来看图8-14，上面显示的数据散乱且不均匀。</p>
<p><img src="Image00246.jpg" alt></p>
<p>图8-14 散乱的数据</p>
<p>数据预处理的目标是：将图8-14中的数据转化为如图8-15所示的形式，数据均匀地分布在坐标系中，4个象限均有数据存在。</p>
<p><img src="Image00247.jpg" alt></p>
<p>图8-15 均匀分布的数据</p>
<p>前面讲述了多层感知器的理论基础，下面用Python实现一个多层感知器，理论联系实践，这样才能更好地理解反向传播算法和多层感知器。这里要实现的是使用感知器将一组数据进行非线性分类，具体要求为：对下面这组输入数据和输出目标进行训练，对未知数据进行仿真测试。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [[4,11],[7,340],[10,95],[3,29],[7,43],[5,128]]</span><br><span class="line">d =[[1,0],[0,1],[1,0],[0,1],[1,0],[0,1]]</span><br></pre></td></tr></table></figure>

</details>

<p>为了简化实现过程，使用原始的纯随机生成方法产生多层感知器网络的权值矩阵。权值初始值既要保证权值矩阵实现输入项在网络中均匀分布，又要保证权值矩阵本身的均匀分布。为达到这个目的，随机生成若干个权值矩阵，然后从中选择最优化的权值矩阵。最优化的标准为：</p>
<p>1）对于输入层的权值设计，要尽量使输入数据的方差接近1。此外，对于相差较大的样本，将它们处理为分布不太接近饱和的可供训练的输入数据。</p>
<p>2）权值矩阵的均值要尽可能小，其方差尽可能与神经元的突触连接数成反比。</p>
<p>同时，要考虑到数据的预处理，需要在输入层前设置一个预处理权值矩阵，所有的输入经过预处理权值矩阵处理后进入多层感知器的输入层。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line">#对输入数据进行预处理</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ann_max=[]</span><br><span class="line">for m_ani in xrange(0,warray_txn):</span><br><span class="line">    temp_x=np.array(train_x)</span><br><span class="line">    ann_max.append(np.max(temp_x[:,m_ani]))</span><br><span class="line">ann_max=np.array(ann_max)</span><br><span class="line">def getnowsx(mysx,in_w):</span><br><span class="line">        &apos;&apos;&apos;生成本次的扩维输入数据</span><br><span class="line"></span><br><span class="line">  &apos;&apos;&apos;</span><br><span class="line">        global warray_n</span><br><span class="line">        mysx=np.array(mysx)</span><br><span class="line">        x_end=[]   </span><br><span class="line">        for i in xrange(0,warray_n):</span><br><span class="line">                x_end.append(np.dot(mysx,in_w[:,i]))</span><br><span class="line">        return x_end</span><br><span class="line">def get_inlw(my_train_max,w_count,myin_x):</span><br><span class="line">        &apos;&apos;&apos;计算对输入数据预处理的权值</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        #对随机生成的多个权值进行优化选择，选择最优的权值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        global warray_txn</span><br><span class="line">        global warray_n</span><br><span class="line">        mylw=[]</span><br><span class="line">        y_in=[]</span><br><span class="line">        #生成测试权值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        mylw=np.random.rand(w_count,warray_txn,warray_n)</span><br><span class="line">        for ii in xrange (0,warray_txn):</span><br><span class="line">            mylw[:,ii,:]=mylw[:,ii,:]*1/float(my_train_max[ii])-\</span><br><span class="line">     1/float(my_train_max[ii])*0.5</span><br><span class="line">        #计算输出</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for i in xrange(0,w_count):</span><br><span class="line">                y_in.append([])</span><br><span class="line">                for  xj in xrange(0,len(myin_x)):</span><br><span class="line">                        y_in[i].append(getnowsx(myin_x[xj],mylw[i]))</span><br><span class="line">        #计算均方差</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        mymin=10**5</span><br><span class="line">        mychoice=0</span><br><span class="line">        for i in xrange(0,w_count):</span><br><span class="line">                myvar=np.var(y_in[i])</span><br><span class="line">                if abs(myvar-1)&lt;mymin:</span><br><span class="line">                        mymin=abs(myvar-1)</span><br><span class="line">                        mychoice=i</span><br><span class="line">        #返回数据整理的权值矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        return mylw[mychoice]</span><br><span class="line">mylnww=get_inlw(ann_max,300,train_x)</span><br><span class="line">def get_inputx(mytrain_x,myin_w):</span><br><span class="line">        &apos;&apos;&apos;将训练数据通过输入权数，扩维后形成输入数据</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        end_trainx=[]</span><br><span class="line">        for i in xrange(0,len(mytrain_x)):</span><br><span class="line">                end_trainx.append(getnowsx(mytrain_x[i],myin_w))        </span><br><span class="line">        return end_trainx        </span><br><span class="line">x=get_inputx(train_x,mylnww)</span><br><span class="line">def get_siminx(sim_x):</span><br><span class="line">        global mylnww</span><br><span class="line">        myxx=np.array(sim_x)</span><br><span class="line">        return get_inputx(myxx,mylnww) </span><br><span class="line">def getlevelw(myin_x,wo_n,wi_n,w_count):</span><br><span class="line">        &apos;&apos;&apos;计算一层的初始化权值矩阵</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        mylw=[]</span><br><span class="line">        y_in=[]</span><br><span class="line">        #生成测试权值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        mylw=np.random.rand(w_count,wi_n,wo_n)</span><br><span class="line">        mylw=mylw*2.-1</span><br><span class="line">       #计算输出</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for i in xrange(0,w_count):</span><br><span class="line">                y_in.append([])</span><br><span class="line">                for  xj in xrange(0,len(myin_x)):</span><br><span class="line">                    x_end=[]   </span><br><span class="line">                    for myii in xrange(0,wo_n):</span><br><span class="line">                        x_end.append(np.dot(myin_x[xj],mylw[i,:,myii]))</span><br><span class="line">                    y_in[i].append(x_end)</span><br><span class="line">        #计算均方差</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        mymin=10**3</span><br><span class="line">        mychoice=0</span><br><span class="line">        for i in xrange(0,w_count):</span><br><span class="line">                myvar=np.var(y_in[i])</span><br><span class="line">                if abs(myvar-1)&lt;mymin:</span><br><span class="line">                        mymin=abs(myvar-1)</span><br><span class="line">                        mychoice=i</span><br><span class="line">        #返回数据整理的权值矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        csmylw=mylw[mychoice]</span><br><span class="line">        return csmylw,y_in[mychoice]        </span><br><span class="line">ann_w=[]</span><br><span class="line">def init_annw():</span><br><span class="line">    global x</span><br><span class="line">    global hidelevel_count</span><br><span class="line">    global warray_n</span><br><span class="line">    global d</span><br><span class="line">    global ann_w</span><br><span class="line">ann_w=[]    </span><br><span class="line">    lwyii=np.array(x)</span><br><span class="line">    for myn in xrange(0,hidelevel_count):               </span><br><span class="line">        #层数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ann_w.append([])  </span><br><span class="line">        if myn==hidelevel_count-1:</span><br><span class="line">            for iii in xrange(0,warray_n):</span><br><span class="line">                ann_w[myn].append([])</span><br><span class="line">                for jjj  in xrange(0,warray_n):</span><br><span class="line">                                ann_w[myn][iii].append(0.0)</span><br><span class="line">        elif myn==hidelevel_count-2:            </span><br><span class="line">            templw,lwyii=getlevelw(lwyii,len(d[0]),warray_n,200)</span><br><span class="line">            for xii in xrange(0,warray_n):</span><br><span class="line">                ann_w[myn].append([])</span><br><span class="line">                for xjj in xrange(0,len(d[0])): </span><br><span class="line">                    ann_w[myn][xii].append(templw[xii,xjj]) </span><br><span class="line">                for xjj in xrange(len(d[0]),warray_n):</span><br><span class="line">                    ann_w[myn][xii].append(0.0)</span><br><span class="line">        else: </span><br><span class="line">            templw,lwyii=getlevelw(lwyii,warray_n,warray_n,200)</span><br><span class="line">            for xii in xrange(0,warray_n):</span><br><span class="line">                ann_w[myn].append([])</span><br><span class="line">                for xjj in xrange(0,warray_n): </span><br><span class="line">                    ann_w[myn][xii].append(templw[xii,xjj])                </span><br><span class="line">    ann_w=np.array(ann_w)</span><br><span class="line">def generate_lw(trycount):</span><br><span class="line">    global ann_w</span><br><span class="line">    print u&quot;产生权值初始矩阵</span><br><span class="line"></span><br><span class="line">&quot;,             </span><br><span class="line">    meanmin=1 </span><br><span class="line">    myann_w=ann_w       </span><br><span class="line">    alltry=30</span><br><span class="line">    tryc=0</span><br><span class="line">    while tryc&lt;alltry:</span><br><span class="line">        for i_i in range(trycount):</span><br><span class="line">            print &quot;.&quot;,</span><br><span class="line">            init_annw()</span><br><span class="line">            if abs(np.mean(np.array(ann_w)))&lt;meanmin:</span><br><span class="line">                meanmin=abs(np.mean(np.array(ann_w)))</span><br><span class="line">                myann_w=ann_w</span><br><span class="line">        tryc+=1</span><br><span class="line">        if abs(np.mean(np.array(myann_w)))&lt;0.008:break       </span><br><span class="line">    ann_w=myann_w</span><br><span class="line">    print</span><br><span class="line">    print u&quot;权值矩阵平均</span><br><span class="line"></span><br><span class="line">:%f&quot;%(np.mean(np.array(ann_w)))</span><br><span class="line">    print u&quot;权值矩阵方差</span><br><span class="line"></span><br><span class="line">:%f&quot;%(np.var(np.array(ann_w)))        </span><br><span class="line">generate_lw(15)</span><br></pre></td></tr></table></figure>

</details>

<p>此外，只需要输出一个值，在这里不使用硬限幅函数，而是返回最大值的索引，因此需要编写对输出值进行最后加工的函数（注意，为了由浅入深讲解，从现在直到后面明确声明，误差率的计算以最后此函数的输出结果为标准）。该函数的定义如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def o_func(myy):</span><br><span class="line">       myresult=[]</span><br><span class="line">       for i in xrange(0,len(myy)):</span><br><span class="line">               mean=np.mean(myy)</span><br><span class="line">               if myy[i]&gt;mean:</span><br><span class="line">                       myresult.append(1.0)</span><br><span class="line">               else:</span><br><span class="line">                       myresult.append(0.0)</span><br><span class="line">       return np.array(myresult)</span><br></pre></td></tr></table></figure>

</details>

<p>另外，可选择tanh函数作为非线性神经元的激活函数，它的输出值在［-1，1］范围内。下面代码完成激活函数（ann_atanh函数）及其局部梯度（ann_delta_atanh函数）的计算。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def ann_atanh(myv):</span><br><span class="line">    atanh_a=1.7159#&gt;0</span><br><span class="line">    atanh_b=2/float(3)#&gt;0</span><br><span class="line">    temp_rs=atanh_a*np.tanh(atanh_b*myv)</span><br><span class="line">    return temp_rs</span><br><span class="line">def ann_delta_atanh(myy,myd,nowlevel,level,n,mydelta,myw):</span><br><span class="line">    anndelta=[]</span><br><span class="line">    atanh_a=1.7159#&gt;0</span><br><span class="line">    atanh_b=2/float(3)#&gt;0  </span><br><span class="line">    if nowlevel==level:</span><br><span class="line">       #输出层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        anndelta=(float(atanh_b)/atanh_a)*(myd-myy)*(atanh_a-myy)*(atanh_a+myy)</span><br><span class="line">    else:</span><br><span class="line">       #隐藏层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        anndelta=(float(atanh_b)/atanh_a)*(atanh_a-myy)*(atanh_a+myy)            </span><br><span class="line">        temp_rs=[]</span><br><span class="line">        for j in xrange(0,n):</span><br><span class="line">                temp_rs.append(sum(myw[j]*mydelta))                </span><br><span class="line">        anndelta=anndelta*temp_rs       </span><br><span class="line">    return anndelta</span><br></pre></td></tr></table></figure>

</details>

<p>下面介绍反向传播的核心算法，算法分为前向计算和反向计算两个过程。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line">def sample_train(myx,myd,n,sigmoid_func,delta_sigfun):</span><br><span class="line">        &apos;&apos;&apos;一个样本的前向和后向计算</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        global ann_yi</span><br><span class="line">        global ann_delta</span><br><span class="line">        global ann_w</span><br><span class="line">        global ann_wj0</span><br><span class="line">        global ann_y0</span><br><span class="line">        global hidelevel_count</span><br><span class="line">        global alllevel_count</span><br><span class="line">        global learn_r</span><br><span class="line">        global train_a</span><br><span class="line">        global ann_oldw</span><br><span class="line">        level=hidelevel_count</span><br><span class="line">        allevel=alllevel_count       </span><br><span class="line">        #清空</span><br><span class="line"></span><br><span class="line">yi输出信号数组</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        hidelevel=hidelevel_count</span><br><span class="line">        alllevel=alllevel_count</span><br><span class="line">        for i in xrange(0,alllevel):</span><br><span class="line">                #第一维是层数，从</span><br><span class="line"></span><br><span class="line">0开始</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                for j in xrange(0,n):</span><br><span class="line">                        #第二维是神经元</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        ann_yi[i][j]=0.0</span><br><span class="line">        ann_yi=np.array(ann_yi)</span><br><span class="line">        yi=ann_yi</span><br><span class="line">        #清空</span><br><span class="line"></span><br><span class="line">delta矩阵</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for i in xrange(0,hidelevel-1):    </span><br><span class="line">                for j in xrange(0,n):</span><br><span class="line">                        ann_delta[i][j]=0.0</span><br><span class="line">        delta=ann_delta    </span><br><span class="line">        #保留</span><br><span class="line"></span><br><span class="line">W的拷贝，以便下一次迭代</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ann_oldw=copy.deepcopy(ann_w)</span><br><span class="line">        oldw=ann_oldw</span><br><span class="line">        #前向计算</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if isdebug:print u&quot;前向计算中</span><br><span class="line"></span><br><span class="line">...&quot;</span><br><span class="line">        #对输入变量进行预处理</span><br><span class="line"></span><br><span class="line">              </span><br><span class="line">        myo=np.array([])</span><br><span class="line">        for nowlevel in xrange(0,alllevel):</span><br><span class="line">                #一层层向前计算</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                #计算诱导局部域</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                my_y=[]</span><br><span class="line">                myy=yi[nowlevel-1] </span><br><span class="line">                myw=ann_w[nowlevel-1]                </span><br><span class="line">                if nowlevel==0:</span><br><span class="line">                        #第一层隐藏层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        my_y=myx</span><br><span class="line">                        yi[nowlevel]=my_y                        </span><br><span class="line">                elif nowlevel==(alllevel-1):</span><br><span class="line">                        #输出层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        my_y=o_func(yi[nowlevel-1,:len(myd)])</span><br><span class="line">                        yi[nowlevel,:len(myd)]=my_y</span><br><span class="line">                elif nowlevel==(hidelevel-1):</span><br><span class="line">                        #最后一层输出层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        for i in xrange(0,len(myd)):</span><br><span class="line">                                temp_y=sigmoid_func(np.dot(myw[:,i],myy))</span><br><span class="line">                                my_y.append(temp_y)                        </span><br><span class="line">                        yi[nowlevel,:len(myd)]=my_y </span><br><span class="line">                else:</span><br><span class="line">                        #中间隐藏层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        for i in xrange(0,len(myy)):</span><br><span class="line">                                  temp_y=sigmoid_func(np.dot(myw[:,i],myy))</span><br><span class="line">                                my_y.append(temp_y)</span><br><span class="line">                        yi[nowlevel]=my_y</span><br><span class="line">        if isdebug:</span><br><span class="line">            print u&quot;******本样本训练的输出矩阵</span><br><span class="line"></span><br><span class="line">**********&quot;  </span><br><span class="line">            print yi</span><br><span class="line">            print u&quot;**********************************&quot;               </span><br><span class="line">        #计算误差与均方误差</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #因为线性输出层为直接复制，所以取非线性隐藏输出层的结果</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        myo=yi[hidelevel-1][:len(myd)]</span><br><span class="line">        myo_end=yi[alllevel-1][:len(myd)]</span><br><span class="line">        mymse=get_e(myd,myo_end)</span><br><span class="line">        #反向计算</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #输入层不需要计算</span><br><span class="line"></span><br><span class="line">delta,输出层不需要计算</span><br><span class="line"></span><br><span class="line">W</span><br><span class="line">        if isdebug:print u&quot;反向计算中</span><br><span class="line"></span><br><span class="line">...&quot;</span><br><span class="line">        #计算</span><br><span class="line"></span><br><span class="line">delta</span><br><span class="line">        for nowlevel in xrange(level-1,0,-1):</span><br><span class="line">                if nowlevel==level-1:</span><br><span class="line">                        mydelta=delta[nowlevel]</span><br><span class="line">                        my_n=len(myd)</span><br><span class="line">                else:</span><br><span class="line">                        mydelta=delta[nowlevel+1]</span><br><span class="line">                        my_n=n</span><br><span class="line">                myw=ann_w[nowlevel]                </span><br><span class="line">                if nowlevel==level-1:</span><br><span class="line">                        #输出层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        mydelta=delta_sigfun(myo,myd,None,None,None,None,None)</span><br><span class="line">##                        mydelta=mymse*myo</span><br><span class="line">                elif nowlevel==level-2:</span><br><span class="line">                        #输出隐藏层的前一层，传输相当于输出隐藏层的神经元数目的数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        mydelta=delta_sigfun(yi[nowlevel],myd,nowlevel,level-1,my_n,mydelta[:len(myd)],myw[:,:len(myd)])</span><br><span class="line">                else:</span><br><span class="line">                        mydelta=delta_sigfun(yi[nowlevel],myd,nowlevel,level-1,my_n,mydelta,myw)</span><br><span class="line">                delta[nowlevel][:my_n]=mydelta</span><br><span class="line">        #计算与更新权值</span><br><span class="line"></span><br><span class="line">W </span><br><span class="line">        for nowlevel in xrange(level-1,0,-1):</span><br><span class="line">                #每个层的权值不一样</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                if nowlevel==level-1:</span><br><span class="line">                        #输出层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        my_n=len(myd)</span><br><span class="line">                        mylearn_r=learn_r*0.8</span><br><span class="line">                        mytrain_a=train_a*1.6</span><br><span class="line">                elif nowlevel==1:</span><br><span class="line">                        #输入层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        my_n=len(myd)</span><br><span class="line">                        mylearn_r=learn_r*0.9</span><br><span class="line">                        mytrain_a=train_a*0.8                       </span><br><span class="line">                else:</span><br><span class="line">                        #其他层</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        my_n=n</span><br><span class="line">                        mylearn_r=learn_r</span><br><span class="line">                        mytrain_a=train_a</span><br><span class="line">                pre_level_myy=yi[nowlevel-1]</span><br><span class="line">                pretrain_myww=oldw[nowlevel-1]</span><br><span class="line">                pretrain_myw=pretrain_myww[:,:my_n]</span><br><span class="line">                #第二个调整参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                temp_i=[]                </span><br><span class="line">                for i in xrange(0,n):</span><br><span class="line">                        temp_i.append([])</span><br><span class="line">                        for jj in xrange(0,my_n):</span><br><span class="line">                              temp_i[i].append(mylearn_r*delta[nowlevel,jj]*pre_level_myy[i])</span><br><span class="line">                temp_rs2=np.array(temp_i)</span><br><span class="line">                temp_rs1=mytrain_a*pretrain_myw</span><br><span class="line">                #总调整参数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                temp_change=temp_rs1+temp_rs2               </span><br><span class="line">                my_ww=ann_w[nowlevel-1]                </span><br><span class="line">                my_ww[:,:my_n]+=temp_change</span><br><span class="line">        if isdebug:</span><br><span class="line">            print &quot;=============&quot;</span><br><span class="line">            print u&quot;***权值矩阵</span><br><span class="line"></span><br><span class="line">***&quot;  </span><br><span class="line">            print ann_w</span><br><span class="line">            print u&quot;***梯度矩阵</span><br><span class="line"></span><br><span class="line">***&quot; </span><br><span class="line">            print delta</span><br><span class="line">            print &quot;=============&quot;</span><br><span class="line">        return mymse</span><br></pre></td></tr></table></figure>

</details>

<p>还需要训练神经网络，并读取测试数据，验证效果。其中，训练神经网络的代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">train()</span><br><span class="line">delta_sigfun=ann_delta_atanh</span><br><span class="line">sigmoid_func=ann_atanh</span><br><span class="line">i=0</span><br><span class="line">for xn in xrange(0,len(x)):</span><br><span class="line">        print u&quot;样本：</span><br><span class="line"></span><br><span class="line">%d~%d =&gt; &quot;%(train_x[xn][0],train_x[xn][1])</span><br><span class="line">        print simulate(x[xn],sigmoid_func,delta_sigfun)</span><br><span class="line">        print u&quot;=====正确目标值</span><br><span class="line"></span><br><span class="line">=====&quot;</span><br><span class="line">        print d[i]</span><br><span class="line">        i+=1</span><br></pre></td></tr></table></figure>

</details>

<p>验证神经网络的代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">test=np.array(get_siminx([[8,70]]))</span><br><span class="line">print u&quot;测试值：</span><br><span class="line"></span><br><span class="line">%f     %f &quot;%(8,70)</span><br><span class="line">print simulate(test,sigmoid_func,delta_sigfun)</span><br><span class="line">print u&quot;正确目标值</span><br><span class="line"></span><br><span class="line">:[1,0]&quot;</span><br><span class="line">test=np.array(get_siminx([[6.5,272]]))</span><br><span class="line">print u&quot;测试值：</span><br><span class="line"></span><br><span class="line">%f     %f &quot;%(6.5,272)</span><br><span class="line">print simulate(test,sigmoid_func,delta_sigfun)  </span><br><span class="line">print u&quot;正确目标值</span><br><span class="line"></span><br><span class="line">:[0,1]&quot;</span><br><span class="line">exitstr=raw_input(u&quot;按回车键退出</span><br><span class="line"></span><br><span class="line">&quot;)</span><br></pre></td></tr></table></figure>

</details>

<p>运行上述程序，经过78次训练，神经网络达到了训练目标，误差率为0。从以下运行结果来看，效果不错。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">......................</span><br><span class="line">......................</span><br><span class="line">-------开始第</span><br><span class="line"></span><br><span class="line">76次训练</span><br><span class="line"></span><br><span class="line">---------# # # # # # 误差为：</span><br><span class="line"></span><br><span class="line">0.816497</span><br><span class="line">-------开始第</span><br><span class="line"></span><br><span class="line">77次训练</span><br><span class="line"></span><br><span class="line">---------# # # # # # 误差为：</span><br><span class="line"></span><br><span class="line">0.577350</span><br><span class="line">-------开始第</span><br><span class="line"></span><br><span class="line">78次训练</span><br><span class="line"></span><br><span class="line">---------# # # # # # 误差为：</span><br><span class="line"></span><br><span class="line">0.000000训练成功，正在进行检验</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">仿真计算中</span><br><span class="line"></span><br><span class="line">训练成功</span><br><span class="line"></span><br><span class="line">,误差为：</span><br><span class="line"></span><br><span class="line">0.000000样本：</span><br><span class="line"></span><br><span class="line">4~11 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.  0.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[1, 0]样本：</span><br><span class="line"></span><br><span class="line">7~340 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 0.  1.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[0, 1]样本：</span><br><span class="line"></span><br><span class="line">10~95 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.  0.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[1, 0]样本：</span><br><span class="line"></span><br><span class="line">3~29 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 0.  1.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[0, 1]样本：</span><br><span class="line"></span><br><span class="line">7~43 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.  0.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[1, 0]样本：</span><br><span class="line"></span><br><span class="line">5~128 =&gt; 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 0.  1.]</span><br><span class="line">=====正确目标值</span><br><span class="line"></span><br><span class="line">=====</span><br><span class="line">[0, 1]测试值：</span><br><span class="line"></span><br><span class="line">8.000000     70.000000 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 1.  0.]正确目标值</span><br><span class="line"></span><br><span class="line">:[1,0]测试值：</span><br><span class="line"></span><br><span class="line">6.500000     272.000000 仿真计算中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ 0.  1.]正确目标值</span><br><span class="line"></span><br><span class="line">:[0,1]按回车键退出</span><br></pre></td></tr></table></figure>

</details>

<p>上述多层感知器的完整源代码见本书资源包中的“多层感知器神经网络源代码.doc”文件或8-10.py文件。</p>
<p>前面用例子说明了Rosenblatt感知器的局限性，现在在多层感知器上对Rosenblatt感知器无法分类的数据进行测试。将“多层感知器神经网络源代码.doc”文件中的代码中的样本数据进行修改，并加上绘制散点图的代码。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#x和</span><br><span class="line"></span><br><span class="line">d样本初始化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_x = np.array([[1,6],[3,12],[3,9],[3,21],[2,16],[3,15]])</span><br><span class="line">d =np.array([[1,0],[1,0],[0,1],[0,1],[1,0],[0,1]])</span><br><span class="line">.............</span><br><span class="line">.............</span><br><span class="line">for xn in xrange(0,len(x)):</span><br><span class="line">        if simulate(x[xn],sigmoid_func,delta_sigfun)[0] &gt; 0:</span><br><span class="line">            pl.plot(train_x[xn][0],train_x[xn][1],&quot;bo&quot;)</span><br><span class="line">        else:</span><br><span class="line">            pl.plot(train_x[xn][0],train_x[xn][1],&quot;b*&quot;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>运行代码对神经网络进行训练，训练成功后，误差为0。如图8-16所示为训练效果，实心圆圈与星号分别表示两类样本点，多层感知器网络的非线性分类成功完成了Rosenblatt感知器无法完成的任务。</p>
<p><img src="Image00248.jpg" alt></p>
<p>图8-16 多层感知器网络的非线性分类</p>
<p>现在在上述代码基础上，加上若干随机数据点，将学习率设得较小，进一步观察多层感知器的非线性分类能力。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line">#-*-coding: utf-8 -*-</span><br><span class="line">#code:myhaspl@qq.com</span><br><span class="line">#8-11.py</span><br><span class="line">import pylab as pl</span><br><span class="line">import numpy as np</span><br><span class="line">import random</span><br><span class="line">import copy</span><br><span class="line">isdebug=False</span><br><span class="line">#x和</span><br><span class="line"></span><br><span class="line">d样本初始化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_x = np.array([[1,6],[3,12],[3,9],[3,21],[2,16],[3,15]])</span><br><span class="line">d =np.array([[1,0],[1,0],[0,1],[0,1],[1,0],[0,1]])</span><br><span class="line">.....................</span><br><span class="line">.....................</span><br><span class="line">train()</span><br><span class="line">delta_sigfun=ann_delta_atanh</span><br><span class="line">sigmoid_func=ann_atanh</span><br><span class="line">temp_x=np.random.rand(20)*10</span><br><span class="line">temp_y=np.random.rand(20)*20+temp_x</span><br><span class="line">myx=temp_x</span><br><span class="line">myy=temp_y</span><br><span class="line">pl.subplot(111)</span><br><span class="line">x_max=np.max(myx)+5</span><br><span class="line">x_min=np.min(myx)-5</span><br><span class="line">y_max=np.max(myy)+5 </span><br><span class="line">y_min=np.min(myy)-5</span><br><span class="line">pl.xlabel(u&quot;x1&quot;)</span><br><span class="line">pl.xlim(x_min, x_max)</span><br><span class="line">pl.ylabel(u&quot;x2&quot;)</span><br><span class="line">pl.ylim(y_min, y_max)</span><br><span class="line">i=0</span><br><span class="line">for mysamp in myx:</span><br><span class="line">    test=get_siminx([[mysamp,myy[i]]])</span><br><span class="line">    if simulate(test,sigmoid_func,delta_sigfun)[0] &gt; 0:</span><br><span class="line">        pl.plot(mysamp,myy[i],&quot;ro&quot;)</span><br><span class="line">    else:</span><br><span class="line">        pl.plot(mysamp,myy[i],&quot;g*&quot;)</span><br><span class="line">    i+=1</span><br><span class="line">for xn in xrange(0,len(x)):</span><br><span class="line">        if simulate(x[xn],sigmoid_func,delta_sigfun)[0] &gt; 0:</span><br><span class="line">            pl.plot(train_x[xn][0],train_x[xn][1],&quot;bo&quot;)</span><br><span class="line">        else:</span><br><span class="line">            pl.plot(train_x[xn][0],train_x[xn][1],&quot;b*&quot;)</span><br><span class="line">pl.show()</span><br></pre></td></tr></table></figure>

</details>

<p>从如图8-17所示的分类效果中，能直观感受到多层感知器的非线性分类能力。其中，星号与实心圆圈表示的数据点被分成了两类，它们之间的界限是非线性表示的曲线，而不是线性表示的直线。</p>
<p><img src="Image00249.jpg" alt></p>
<p>图8-17 非线性分类</p>
<p>在多层感知器学习中，经常需要用到一个概念：误差曲线。误差曲线体现在一个二维坐标系中，X轴表示训练次数，Y轴表示每次训练的误差率。理想的误差曲线是随着X的增加，Y值不断平滑减少，这与误差曲面相似，误差曲面以参数为自变量，这些都形象地体现了梯度下降的概念。它们都说明了一个道理：一个设计良好的多层感知器，随着训练次数的增多，模型会越来越精确，误差曲面会朝着最小点向下滑动，而且误差曲线也在下降。</p>
<p>前面为了讲述的需要，“多层感知器神经网络源代码.doc”文件所示代码对误差率的计算以最终输出结果为依据计算，现在在神经网络输出层的后面再增加一层最终输出层，对原输出层的结果进行再次加工后输出。本书在以后涉及的相关代码中，如未特别说明，最终输出结果是指新增的最终输出层的输出结果。在此，将误差率的计算公式定义为：</p>
<p><img src="Image00250.jpg" alt></p>
<p>设置好网络的相关参数，将期望误差率设置为0.3，然后加入绘制误差曲线的代码。在列出代码之前，先介绍一下前面没有具体涉及的问题：中间隐藏层、学习率及动量参数。</p>
<p>一般认为，增加隐藏层数可以降低网络误差，提高精度，但也可使网络复杂化。当然也有学者提出了反对意见，但从实践经验来看，隐藏层的数目过少无法实现对复杂数据的学习，隐藏层的增多增加了网络的训练时间和出现“过拟合”的概率。</p>
<p>设计神经网络至少应考虑3层网络，其中有一层隐藏层，在这里将隐藏层的层数及每层节点数定义为如下形式：</p>
<p>隐藏层的层数=每个样本的元素个数×4-2</p>
<p>每个隐藏层的节点数=训练样本数-1</p>
<p>目前仍有学者在对学习率和动量参数进行研究。什么样的学习率能既加快神经网络的训练时间，同时又能提高训练精度呢？动量参数设置为多少，更适合当前学习率，让误差曲线在下降过程中尽可能地跳出局部最小值的陷阱呢？</p>
<p>如果学习率设得过大，可能造成训练过早停止，错过了误差曲线的全局最小值；而设得过小则会造成训练时间加长，同时容易陷入误差曲线的局部最小值。动量参数也存在类似的问题。笔者认为这些参数需要在实践应用中进行调试和测试，通过对训练效果反复对比，才能得到最适合的参数。</p>
<p>根据以上设计思路，用Python在“多层感知器神经网络源代码.doc”文件代码的基础上实现。代码如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">    #!/usr/bin/env python</span><br><span class="line">    #-*-coding: utf-8 -*-</span><br><span class="line">    #code:myhaspl@qq.com</span><br><span class="line">    #8-12.py</span><br><span class="line">    import numpy as np</span><br><span class="line">    import matplotlib.pyplot as plt</span><br><span class="line">    import random</span><br><span class="line">    import copy</span><br><span class="line">    isdebug=False</span><br><span class="line">    #x和</span><br><span class="line"></span><br><span class="line">    d样本初始化</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    train_x = [[4,11],[7,340],[10,95],[3,29],[7,43],[5,128]]</span><br><span class="line">    d =[[1,0],[0,1],[1,0],[0,1],[1,0],[0,1]]</span><br><span class="line">    warray_txn=len(train_x[0])</span><br><span class="line">    warray_n=len(train_x)-1</span><br><span class="line">    #基本参数初始化</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    oldmse=10**100</span><br><span class="line">    fh=1</span><br><span class="line">    maxtrycount=500</span><br><span class="line">    mycount=0.0</span><br><span class="line">    if maxtrycount&gt;=20:</span><br><span class="line">    r=maxtrycount/10</span><br><span class="line">    else:</span><br><span class="line">    r=maxtrycount/2</span><br><span class="line">    #sigmoid函数</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    ann_sigfun=None</span><br><span class="line">    ann_delta_sigfun=None</span><br><span class="line">    #总层数初始化，比非线性导数多一层线性层</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    alllevel_count=warray_txn*4</span><br><span class="line">    # 非线性层数初始化</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    hidelevel_count=alllevel_count-1</span><br><span class="line">    #学习率参数</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    learn_r0=0.02</span><br><span class="line">    learn_r0*=2.5</span><br><span class="line">    learn_r=learn_r0</span><br><span class="line">    #动量参数</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    train_a0=learn_r0*1.2</span><br><span class="line">    train_a0*=0.0015</span><br><span class="line">    train_a=train_a0</span><br><span class="line">    #误差率</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    expect_e=0.3</span><br><span class="line">    .....................</span><br><span class="line">    .....................</span><br><span class="line">    x_max=len(err)</span><br><span class="line">    x_min=1</span><br><span class="line">    y_max=max(err)+0.2</span><br><span class="line">    y_min=0.</span><br><span class="line">    plt.xlabel(u&quot;traincount&quot;)</span><br><span class="line">    plt.xlim(x_min, x_max)</span><br><span class="line">    plt.ylabel(u&quot;mse&quot;)</span><br><span class="line">    plt.ylim(y_min, y_max)</span><br><span class="line">    lp_x1 = xrange(1,len(err)+1)</span><br><span class="line">    lp_x2 = err</span><br><span class="line">    plt.plot(lp_x1,lp_x2,&apos;g-&apos;)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">* * *</span><br><span class="line"></span><br><span class="line">运行代码，执行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ................
    .................
    -------开始第

    137次训练

    ---------# # # # # # 误差为：

    0.309623
    -------开始第

    138次训练

    ---------# # # # # # 误差为：

    0.330235
    -------开始第

    139次训练

    ---------# # # # # # 误差为：

    0.284128训练成功，正在进行检验

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    训练成功

    ,输出误差为：

    0.000000样本：

    4~11 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    7~340 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]样本：

    10~95 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    3~29 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]样本：

    7~43 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    5~128 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]测试值：

    8.000000~70.000000 仿真计算中


    [ 1.  0.]正确目标值

    :[1,0]测试值：

    6.500000~272.000000 仿真计算中


    [ 0.  1.]正确目标值

    :[0,1] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从上述代码执行结果中不难看出，网络在139次训练后，达到了训练误差的期望值0.3，对测试数据和样本数据的验证均成功。再来看看如图8-18所示的误差曲线，总体呈现下滑趋势。</span><br><span class="line"></span><br><span class="line">![](Image00251.jpg)</span><br><span class="line"></span><br><span class="line">图8-18 误差曲线（附彩图）</span><br><span class="line"></span><br><span class="line">图8-18中的曲线并不平滑，如果将学习率设得更小，曲线将平滑很多，训练次数也将增多。现在修改代码，将学习率减少，重新绘制误差曲线图。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-13.py
    import numpy as np
    import matplotlib.pyplot as plt
    import random
    import copy
    isdebug=False
    #x和

    d样本初始化


    train_x = [[4,11],[7,340],[10,95],[3,29],[7,43],[5,128]]
    d =[[1,0],[0,1],[1,0],[0,1],[1,0],[0,1]]
    warray_txn=len(train_x[0])
    warray_n=len(train_x)-1
    #基本参数初始化


    oldmse=10**100
    fh=1
    maxtrycount=2000
    mycount=0.0
    if maxtrycount>=20:
    r=maxtrycount/10
    else:
    r=maxtrycount/2
    #sigmoid函数


    ann_sigfun=None
    ann_delta_sigfun=None
    #总层数初始化，比非线性导数多一层线性层


    alllevel_count=warray_txn*4
    # 非线性层数初始化


    hidelevel_count=alllevel_count-1
    #学习率参数


    learn_r0=0.005
    learn_r0*=2.5
    learn_r=learn_r0 
    ...............
    .............. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序执行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ..............
    ..............
    -------开始第

    354次训练

    ---------# # # # # # 误差为：

    0.344559
    -------开始第

    355次训练

    ---------# # # # # # 误差为：

    0.347000
    -------开始第

    356次训练

    ---------# # # # # # 误差为：

    0.338863
    -------开始第

    357次训练

    ---------# # # # # # 误差为：

    0.342834
    -------开始第

    358次训练

    ---------# # # # # # 误差为：

    0.353655
    -------开始第

    359次训练

    ---------# # # # # # 误差为：

    0.280097训练成功，正在进行检验

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    仿真计算中

    训练成功

    ,输出误差为：

    0.000000样本：

    4~11 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    7~340 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]样本：

    10~5 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    3===29 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]样本：

    7~43 => 仿真计算中


    [ 1.  0.]
    =====正确目标值

    =====
    [1, 0]样本：

    5~128 => 仿真计算中


    [ 0.  1.]
    =====正确目标值

    =====
    [0, 1]测试值：

    8.000000~70.000000 仿真计算中


    [ 1.  0.]正确目标值

    :[1,0]测试值：

    6.500000~272.000000 仿真计算中


    [ 0.  1.]正确目标值

    :[0,1] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从执行结果可看出，如果将学习率设得更小，训练次数确实增多了，由100多次变成了300多次，相比上次的训练，每次训练的误差率降低幅度变小，如图8-19所示为误差曲线。</span><br><span class="line"></span><br><span class="line">![](Image00252.jpg)</span><br><span class="line"></span><br><span class="line">图8-19 误差曲线</span><br><span class="line"></span><br><span class="line">相比图8-18的误差曲线，图8-19所示的误差曲线下降趋势更加明显，平滑很多，上下摆动的幅度也减小了不少。</span><br><span class="line"></span><br><span class="line">#### 8.1.4 Python神经网络库</span><br><span class="line"></span><br><span class="line">前面几节设计和完善了线性和非线性神经网络，并通过Python实现了神经网络，逐步阐述了怎样设计一个神经网络，如何改进神经网络，如何应用神经网络完成分类等。后面的章节还将对这些程序代码进行改进，介绍如何应用神经网络进行数据拟合。</span><br><span class="line"></span><br><span class="line">“不用重复造轮子”，实践中除非条件限制（比如：受限嵌入式环境等应用）必须编写所有的神经网络代码，否则可以直接调用神经网络相关的库。</span><br><span class="line"></span><br><span class="line">目前Python关于神经网络的库较多，这里选择纯Python库实现的神经网络库Neurolab，在第2章中已经介绍过它的安装与配置方法，在此不再介绍，下面直接讲述如何应用它。首先进入Python的控制台，以前几节的数据为例，熟悉一下Neurolab的基本使用方法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> import neurolab as nl
    >>> train_x = [[4,11],[7,340],[10,95],[3,29],[7,43],[5,128]]
    >>> input=np.array(train_x)
    >>> d =[[1],[0],[1],[0],[1],[0]]
    >>> target=np.array(d)
    >>> target
    array([[1],
           [0],
           [1],
           [0],
           [1],
           [0]])
    >>> input
    array([[  4,  11],
           [  7, 340],
           [ 10,  95],
           [  3,  29],
           [  7,  43],
           [  5, 128]])
    >>> net = nl.net.newff([[3, 10], [11, 400]], [5, 1])
    >>> err = net.train(input, target, show=15)
    Epoch: 15; Error: 0.326594518922;
    Epoch: 30; Error: 0.0242485565317;
    The goal of learning is reached <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">训练完毕后，再用数据测试该网络。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> net.sim([[3, 10]])
    array([[ 0.99999326]])
    >>> net.sim([[9, 80]])
    array([[ 0.89054486]])
    >>> net.sim([[6.5,272]])
    array([[ 0.05707987]])
    >>> net.sim([[10,80]])
    array([[ 0.9448553]])
    >>> net.sim([[5,125]])
    array([[ 0.12198103]])
    >>> net.sim([[5,100]])
    array([[ 0.18880761]]) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码显示，训练很成功，测试数据也被正确分类。</span><br><span class="line"></span><br><span class="line">拥有中间隐藏层的多层感知器在输入与输出之间建立了映射关系，这种映射关系不一定是某种数学模型明确定义的。如果随机生成无规律的输入值和输出值，这些值之前的关系完全未知，那么是不能建立拥有确定数学公式的映射的，但可通过神经网络来建立它们之间的数学模型。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> import numpy as np
    >>> import neurolab as nl
    >>> input = np.random.uniform(-0.5, 0.5, (10, 2))
    >>> output = np.random.uniform(-0.5, 0.5, (10, 1))
    >>> err = net.train(input, output, show=15)
    >>> net = nl.net.newff([[-0.5, 0.5], [-0.5, 0.5]], [8, 1])
    >>> err = net.train(input, output, show=15)
    Epoch: 15; Error: 0.0676764691815;
    Epoch: 30; Error: 0.0131047452439;
    The goal of learning is reached
    >>> err[len(err)-1]
    0.0097660775986454906 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码中的err[len(err)-1]表示训练停止后的误差率。可以看到，训练后精度很高，误差率小于0.01。下面来编写代码绘制误差曲线。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> import matplotlib.pyplot as plt
    >>> plt.plot(err)
    [<matplotlib.lines.line2d object at 0x04c173b0>] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图8-20所示是生成的误差曲线，能明显看到误差曲线很平滑。但此处的误差来源数据是训练15次采集一次，前几节中的误差曲线是每训练一次采集一次。因此，图8-20比前几节的误差曲线更为平滑。</span><br><span class="line"></span><br><span class="line">![](Image00253.jpg)</span><br><span class="line"></span><br><span class="line">图8-20 误差曲线</span><br><span class="line"></span><br><span class="line">通过多层感知器神经网络，在这组没有联系的随机生成的输入和输出之间“强行”建立了一种映射关系。在测试时，通过未在样本中出现的输入数据，能得到符合这种映射关系的输出。这种映射能力非常重要，是后面几章提到的数据拟合、模式识别等机器学习任务的基础。</span><br><span class="line"></span><br><span class="line">### 8.2 统计算法</span><br><span class="line"></span><br><span class="line">统计分析算法在机器学习中占有重要地位，在此，仅介绍几种常用算法。</span><br><span class="line"></span><br><span class="line">#### 8.2.1 平均值</span><br><span class="line"></span><br><span class="line">平均值是统计学中最常用的统计量，用来表明资料中各观测值集中较多的中心位置，用于反映现象总体的一般水平，或分布的集中趋势。有限总体的平均值定义为：</span><br><span class="line"></span><br><span class="line">![](Image00254.jpg)</span><br><span class="line"></span><br><span class="line">式中，μ表示总体平均值，N表示总体所包含的个体数。</span><br><span class="line"></span><br><span class="line">平均值的意义在于：不仅可用它来反映一组数据的一般情况，还可以进行不同数据组之间的比较，以看出组与组之间的差别。下面随机生成两组随机数，对它们进行分析。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> y = np.random.uniform(-0.5, 0.5, (10, 1))
    >>> x = np.random.uniform(-0.5, 0.5, (10, 1))
    >>> x
    array([[-0.46954884],
           [-0.39078561],
           [ 0.05531789],
           [-0.06414516],
           [-0.00511995],
           [-0.41105398],
           [-0.23416933],
           [ 0.1369419 ],
           [-0.45076555],
           [ 0.1808625 ]])
    >>> y
    array([[ 0.38100971],
           [ 0.12510564],
           [ 0.0540655 ],
           [-0.25050503],
           [ 0.13180995],
           [ 0.32953768],
           [-0.35940215],
           [-0.00294618],
           [-0.23359633],
           [-0.49808591]])
    >>> np.mean(y)
    -0.032300713545130311
    >>> np.mean(x)
    -0.16524661414915703 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述代码的执行结果可以看到，y的平均值为-0.032300713545130311，x的平均值为-0.16524661414915703，y的平均值更趋向于0，因此，我们预言：y的总体分布要比x偏右，更趋向于0。继续在Python控制台中绘制它们在坐标系中的分布，以验证这个预言。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> z=np.zeros(10)
    >>> z
    array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
    >>> xx=np.array(zip(z,x));yy=np.array(zip(z,y))
    >>> xx
    array([[ 0.        , -0.46954884],
           [ 0.        , -0.39078561],
           [ 0.        ,  0.05531789],
           [ 0.        , -0.06414516],
           [ 0.        , -0.00511995],
           [ 0.        , -0.41105398],
           [ 0.        , -0.23416933],
           [ 0.        ,  0.1369419 ],
           [ 0.        , -0.45076555],
           [ 0.        ,  0.1808625 ]])
    >>>import matplotlib.pyplot as plt
    >>> plt.xlim(-0.5, 0.5)
    (-0.5, 0.5)
    >>> plt.ylim(-0.01, 0.01)
    (-0.01, 0.01)
    >>> plot(yy[:,0],yy[:,1],'or')
    [<matplotlib.lines.line2d object at 0x04eb44d0>]
    >>> plot(xx[:,0],xx[:,1],'*b')
    [<matplotlib.lines.line2d object at 0x04ce2810>]
    >>>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">x用星号表示，y用实心圆圈表示，绘制图形如图8-21所示。从图8-21所示的效果图可以看出，星号表示的数据比实心圆圈表示的数据整体更偏左，更偏向X轴的负方向，这个趋势证实了我们刚才的预言。</span><br><span class="line"></span><br><span class="line">![](Image00255.jpg)</span><br><span class="line"></span><br><span class="line">图8-21 数据点分布</span><br><span class="line"></span><br><span class="line">#### 8.2.2 方差与标准差</span><br><span class="line"></span><br><span class="line">1.标准差</span><br><span class="line"></span><br><span class="line">标准差是一组数据平均值分散程度的一种度量方式，其计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00256.jpg)</span><br><span class="line"></span><br><span class="line">其中，μ为平均值。</span><br><span class="line"></span><br><span class="line">较大的标准差，代表大部分数值和其平均值之间差异较大；较小的标准差，代表这些数值较接近平均值。</span><br><span class="line"></span><br><span class="line">2.方差</span><br><span class="line"></span><br><span class="line">标准差的平方就是方差，其计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00257.jpg)</span><br><span class="line"></span><br><span class="line">其中，μ为平均值。</span><br><span class="line"></span><br><span class="line">方差与标准差的统计意义差不多，都是反映数据平均值分散程度。</span><br><span class="line"></span><br><span class="line">3.Python实现</span><br><span class="line"></span><br><span class="line">下面用Python来实现标准差和方差的计算。在Python控制台操作，随机生成一组x和y值，y是均匀分布，x是高斯分布。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> y = np.random.rand(100)
    >>> x = np.random.normal(0.5,  0.00001, 100)
    >>>import matplotlib.pyplot as plt <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察x的分布趋势，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> z=np.zeros(100)
    >>> xx=np.array(zip(x,z))
    >>> plot(xx[:,0],xx[:,1],'*b')
    [<matplotlib.lines.line2d object at 0x04e06bf0>] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">x的分布如图8-22所示，数据点在X轴上分布不均匀，主要点集中在0.5附近（图8-22的基值是4.9997e-1），少量点散布在两边，这是预料之中的。</span><br><span class="line"></span><br><span class="line">x是高斯分布，随机生成x时，指定了参数为：平均值0.5，最大标准差为0.00001。高斯分布就是正态分布，具有集中性的特点，即：正态曲线的高峰位于正中央，即平均值所在的位置，如果是一维空间，则集中在X轴中平均值附近。</span><br><span class="line"></span><br><span class="line">观察y的分布趋势，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> z=np.zeros(100)
    >>> yy=np.array(zip(y,z))
    >>> plot(yy[:,0],yy[:,1],'*b')
    [<matplotlib.lines.line2d object at 0x04e06bf0>] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从分布图8-23来看，y均匀分布在X轴上，没出现大量数据点聚集的情况。</span><br><span class="line"></span><br><span class="line">![](Image00258.jpg)</span><br><span class="line"></span><br><span class="line">图8-22 数据点分布</span><br><span class="line"></span><br><span class="line">![](Image00259.jpg)</span><br><span class="line"></span><br><span class="line">图8-23 数据点分布（附彩图）</span><br><span class="line"></span><br><span class="line">现在分别求出x和y的平均值、方差与标准差。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> np.mean(x)#平均值


    0.50000063672402462
    >>> np.var(x)#方差


    9.791184624177845e-11
    >>> np.std(x)#标准差


    9.8950414977289737e-06
    >>> np.mean(y)#平均值


    0.52212510115195176
    >>> np.std(y)#标准差


    0.28755684683792165
    >>> np.var(y)#方差


    0.082688940163367933 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">y的平均值与x接近，但其方差和标准差不一样，x的方差和标准差都比y小很多，比x小很多，这说明x相对于y来说，有更多的数值集中在平均值0.5附近，这就是方差和标准差的统计意义。</span><br><span class="line"></span><br><span class="line">#### 8.2.3 贝叶斯算法</span><br><span class="line"></span><br><span class="line">1.贝叶斯定理</span><br><span class="line"></span><br><span class="line">贝叶斯定理是关于随机事件A和B条件概率的一则定理，下式定义了在事件B发生的情况下事件A发生的条件概率：</span><br><span class="line"></span><br><span class="line">![](Image00260.jpg)</span><br><span class="line"></span><br><span class="line">假设&#123;Ai &#125;是事件集合里的部分集合，其中，A1 ，A2 ，…，An 是某个过程中若干可能的前提，则P(Ai )是对各前提条件出现可能性的事先估计，称之为先验概率。如果在这个过程得到了结果B，贝叶斯公式定义了P(Ai |B)，它是对以B为前提下Ai 出现概率的估计，则称P(Ai |B)为后验概率。</span><br><span class="line"></span><br><span class="line">对于任意的Ai ，贝叶斯定理用下式来表示：</span><br><span class="line"></span><br><span class="line">![](Image00261.jpg)</span><br><span class="line"></span><br><span class="line">下面是一个贝叶斯算法的经典例子。</span><br><span class="line"></span><br><span class="line">已知某种疾病的发病率是0.001，即1000人中会有1个人得病，现有一种试剂可以检验患者是否得病，它的准确率是0.99，即在患者确实得病的情况下，它有99%的可能呈现阳性。它的误报率是5%，即在患者没有得病的情况下，它有5%的可能呈现阳性。现有一个病人的检验结果为阳性，请问他确实得病的可能性有多大？</span><br><span class="line"></span><br><span class="line">假定A事件表示得病，那么P(A)为0.001，这就是“先验概率”，即没有做试验之前预计的发病率；假定B事件表示阳性，那么要计算的就是P(A|B)，即“后验概率”，表示做了试验以后对发病率的估计。计算过程如下：</span><br><span class="line"></span><br><span class="line">![](Image00262.jpg)</span><br><span class="line"></span><br><span class="line">通过计算，得知P(A|B)约等于0.019，即使检验呈现阳性，病人得病的概率也只是不到2%，也就是说，呈现“假阳性”，阳性结果完全不足以说明病人得病。</span><br><span class="line"></span><br><span class="line">贝叶斯算法在机器学习中主要用于分类，其基本原理是：已知样本X，首先计算P(X|Ci )，得出Ci 类别包含样本X的先验概率；然后根据贝叶斯定理求后验概率P(Ci |X)，得到X属于Ci 类别的后验概率；最后根据最大后验概率判断所属类别。</span><br><span class="line"></span><br><span class="line">2.朴素贝叶斯</span><br><span class="line"></span><br><span class="line">贝叶斯算法的基础是概率推理，是在各种条件的存在不确定、仅知其出现概率的情况下，完成推理和决策任务。而朴素贝叶斯算法是基于独立假设的，即假设样本每个特征与其他特征都不相关。</span><br><span class="line"></span><br><span class="line">尽管实际上独立假设常常是不准确的，但朴素贝叶斯分类器的若干特性让其在实践中能够取得令人惊奇的效果，各类条件特征之间的解耦意味着每个特征的分布都可以独立地被当作一维分布来估计，减轻了由于维数灾带来的阻碍，避免了样本规模呈指数增长。在本书的第10章中有关于朴素贝叶斯算法的应用实例。</span><br><span class="line"></span><br><span class="line">朴素贝叶斯算法通常在自动分类中使用，算法的主要过程为：首先，计算待分类样本特征的后验概率，然后使用最大似然比贝叶斯分类法或最小风险贝叶斯分类法完成分类。</span><br><span class="line"></span><br><span class="line">当待分类样本拥有若干特征变量F1 ，F2 ，…，Fn 时，该待分类样本属于类C的后验概率为：</span><br><span class="line"></span><br><span class="line">![](Image00263.jpg)</span><br><span class="line"></span><br><span class="line">其中，证据因子Z是一个仅依赖F1 ，…，Fn 的缩放因子，当特征变量的值已知时是一个常数。</span><br><span class="line"></span><br><span class="line">在朴素贝叶斯算法中，后验概率仅依赖于两个因素：类先验概率p(C)和基于独立假设的先验概率p(Fi |C)。</span><br><span class="line"></span><br><span class="line">上面的推导结果解决了待分类样本后验概率的计算问题，余下的问题是：既然得到了属于每个类别的后验概率，如何知道待分类样本究竟属于哪个类别呢？有两个方法：使用最大似然比贝叶斯分类法和最小风险贝叶斯分类法。</span><br><span class="line"></span><br><span class="line">目前普遍使用的是最大似然比贝叶斯分类方法，即：选出最有可能的那个，将待分类样本划归到后验概率最大的那一类中，也称为最大后验概率（MAP）决策准则。当采取最大后验概率决策时，相应的分类器公式定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00264.jpg)</span><br><span class="line"></span><br><span class="line">为了便于理解，去除这些繁杂的数学符号，将最终的分类器定义为：</span><br><span class="line"></span><br><span class="line">样本所属类别=arg max(P(类型)×样本每个单独属性先验概率的累乘)</span><br><span class="line"></span><br><span class="line">其中，argmax表示选择最大概率的类别为最终类别，P（类别）为类别先验概率，是指该类别本身的可能性有多少。</span><br><span class="line"></span><br><span class="line">朴素贝叶斯虽然是基于独立假设的，但实践证明这种方法确实很有效。创建了Viaweb（1998年，Viaweb成为最流行的电子商务软件，被雅虎收购，改称雅虎商店）的美国著名程序员Paul Graham提出使用朴素贝叶斯识别垃圾邮件的方法，它通过使用字词等标记与垃圾邮件、非垃圾邮件的关联，计算一封邮件为垃圾邮件的可能性，以实现对垃圾邮件的判别。有兴趣的读者可以查阅下面网址：</span><br><span class="line"></span><br><span class="line">&lt;http://www.paulgraham.com/spam.html&gt;  </span><br><span class="line"></span><br><span class="line">一个有趣的例子如下：假设有一台智能机器，负责将一堆未知水果分为3类：苹果、桂圆、香蕉。已知，这一堆水果中，苹果的数量约占60%，桂圆的数量约占35%，香蕉的数量约占5%。</span><br><span class="line"></span><br><span class="line">现在需要一位工程师为这台机器设计一个机器学习算法，这位工程师选择了朴素贝叶斯分类算法，将算法过程定义为如下形式：</span><br><span class="line"></span><br><span class="line">首先，计算P（类别）。</span><br><span class="line"></span><br><span class="line">P(苹果)=0.6，P(桂圆)=0.35，P(香蕉)=0.05</span><br><span class="line"></span><br><span class="line">然后，分别准备几个苹果、桂圆、香蕉的样本，分析其重量、颜色、形状，得出它们的先验概率。接着，重头戏开始了，识别未知水果。机器面前摆了一个这样的水果（用人类的“智能”，识别出这是一个香蕉，但机器识别出来不容易，目前人工智能水平远没达到期望的水平），如图8-24所示。</span><br><span class="line"></span><br><span class="line">![](Image00265.jpg)</span><br><span class="line"></span><br><span class="line">图8-24 香蕉</span><br><span class="line"></span><br><span class="line">机器要做的识别过程是：</span><br><span class="line"></span><br><span class="line">1）提取这个未知样本的特征：重量、颜色、形状。重量测量使用称重仪器，颜色靠色敏元件，形状使用图像识别算法。</span><br><span class="line"></span><br><span class="line">2）从存储器中取出事先计算好的重量、颜色、形状的先验概率，设这个未知水果的重量、颜色、形状特征值为a1 、a2 、a3 ，它们各自的先验概率为：</span><br><span class="line"></span><br><span class="line">P(a1 |苹果）=0.6，P(a2 |苹果)=0.4，P(a3 |苹果)=0.001</span><br><span class="line"></span><br><span class="line">P(a1 |桂圆）=0.001，P(a2 |桂圆)=0.9，P(a3 |桂圆)=0.001</span><br><span class="line"></span><br><span class="line">P(a1 |香蕉）=0.6，P(a2 |香蕉)=0.9，P(a3 |香蕉)=0.95</span><br><span class="line"></span><br><span class="line">其中，a1 =重量，a2 =颜色，a3 =形状。</span><br><span class="line"></span><br><span class="line">3）计算后验概率。</span><br><span class="line"></span><br><span class="line">设这个未知水果为x，计算x属于每个类别的概率。</span><br><span class="line"></span><br><span class="line">P(苹果|x)=P(苹果|a1 ，a2 ，a3 )</span><br><span class="line"></span><br><span class="line">=P(苹果)×(P(a1 |苹果)×P(a2 |苹果）×P(a3 |苹果）</span><br><span class="line"></span><br><span class="line">=0.6×(0.6×0.4×0.001)</span><br><span class="line"></span><br><span class="line">=0.6×0.00024</span><br><span class="line"></span><br><span class="line">=0.000144</span><br><span class="line"></span><br><span class="line">P(桂圆|x)=P(桂圆|a1 ，a2 ，a3 )</span><br><span class="line"></span><br><span class="line">=P(桂圆)×(P(a1 |桂圆)×P(a2 |桂圆）×P(a3 |桂圆）</span><br><span class="line"></span><br><span class="line">=0.35×(0.001×0.9×0.001)</span><br><span class="line"></span><br><span class="line">=0.000000315</span><br><span class="line"></span><br><span class="line">P(香蕉|x)=P(香蕉|a1 ，a2 ，a3 )</span><br><span class="line"></span><br><span class="line">=P(香蕉)×(P(a1 |香蕉)×P(a2 |香蕉）×P(a3 |香蕉）</span><br><span class="line"></span><br><span class="line">=0.05×(0.6×0.9×0.95)</span><br><span class="line"></span><br><span class="line">=0.02565</span><br><span class="line"></span><br><span class="line">4）寻找最大后验概率得到所属类别，假设所属类别为C。</span><br><span class="line"></span><br><span class="line">P(C|x)=argmax(P(苹果|x)，P(桂圆|x)，P(香蕉|x)</span><br><span class="line"></span><br><span class="line">=argmax(0.000144，0.000000315，0.02565)</span><br><span class="line"></span><br><span class="line">3个概率中，0.02565是最大的概率，因此C=香蕉。</span><br><span class="line"></span><br><span class="line">5）将这个水果分到香蕉堆中。</span><br><span class="line"></span><br><span class="line">在本书的12.3节将进一步讲解贝叶斯算法。</span><br><span class="line"></span><br><span class="line">### 8.3 欧氏距离</span><br><span class="line"></span><br><span class="line">1.数学原理</span><br><span class="line"></span><br><span class="line">以R表示实数域。对任意一个正整数n，实数的n元组的全体构成了R上的一个n维向量空间，用Rn 来表示，也称之为实数坐标空间。Rn 中的元素写作X=(x1 ，x2 ，…，xn )，这里的xi 都是实数。</span><br><span class="line"></span><br><span class="line">欧氏范数定义Rn 上的距离函数（或称度量）：</span><br><span class="line"></span><br><span class="line">![](Image00266.jpg)</span><br><span class="line"></span><br><span class="line">这个距离函数称为欧几里得度量，也称欧氏距离。欧氏距离通常用于衡量两个点之间的距离，这两个点可以是定义在二维空间的，也可以是定义在三维空间或者n维空间的。</span><br><span class="line"></span><br><span class="line">2.计算实例</span><br><span class="line"></span><br><span class="line">假设在二维空间中，已定义两个点：（3，8）和（2，5），其欧氏距离如下：</span><br><span class="line"></span><br><span class="line">![](Image00267.jpg)</span><br><span class="line"></span><br><span class="line">经过计算，该距离为3.1623，两点在空间的表示如图8-25所示。该距离为直线的长度。</span><br><span class="line"></span><br><span class="line">![](Image00268.jpg)</span><br><span class="line"></span><br><span class="line">图8-25 二维空间中两点的距离</span><br><span class="line"></span><br><span class="line">假设有两点：（2，5，7）和（3，8，2），它们在三维空间的欧氏距离定义为：</span><br><span class="line"></span><br><span class="line">![](Image00269.jpg)</span><br><span class="line"></span><br><span class="line">经过计算，该距离为5.9161，如图8-26所示，该距离为直线的长度。</span><br><span class="line"></span><br><span class="line">![](Image00270.jpg)</span><br><span class="line"></span><br><span class="line">图8-26 三维空间中两点的距离</span><br><span class="line"></span><br><span class="line">n维欧氏空间是一个点集，它的每个点X可以表示为（x[1]，x[2]，…，x[n]），其中x[i](i=1，2，…，n)是实数，称为X的第i个坐标，两个点A=(a[1]，a[2]，…，a[n])和B=(b[1]，b[2]，…，b[n])之间的距离d(A，B)计算方式如下：</span><br><span class="line"></span><br><span class="line">![](Image00271.jpg)</span><br><span class="line"></span><br><span class="line">### 8.4 余弦相似度</span><br><span class="line"></span><br><span class="line">1.数学原理</span><br><span class="line"></span><br><span class="line">1）向量。空间中有两个点A和B，A-&gt;B就是一个向量，可以读成从A到B。它既有大小又有方向，设原点是O，给定空间中任意一点A，OA是从O到A的向量。如图8-27所示就是一个定义在三维空间上的向量OA。</span><br><span class="line"></span><br><span class="line">![](Image00272.jpg)</span><br><span class="line"></span><br><span class="line">图8-27 向量</span><br><span class="line"></span><br><span class="line">2）点积（内积）。对任意两个向量x、y，点积〈x，y〉(x·y)定义为：</span><br><span class="line"></span><br><span class="line">![](Image00273.jpg)</span><br><span class="line"></span><br><span class="line">Rn 中的两个向量通过点积的方式映射成一个实数值，Rn 及其点积称为Rn 上的欧几里得结构，可以将Rn 称为n维欧几里得空间，点积〈，〉称为欧氏点积。</span><br><span class="line"></span><br><span class="line">3）向量长度。向量X的长度定义为：</span><br><span class="line"></span><br><span class="line">![](Image00274.jpg)</span><br><span class="line"></span><br><span class="line">上式又称为Rn 上的欧氏范数。</span><br><span class="line"></span><br><span class="line">4）余弦相似性。在欧氏内积和欧氏范数基础上定义向量A和B之间的θ余弦相似性如下：</span><br><span class="line"></span><br><span class="line">![](Image00275.jpg)</span><br><span class="line"></span><br><span class="line">其中θ为x和y所夹的内角。</span><br><span class="line"></span><br><span class="line">2.算法原理</span><br><span class="line"></span><br><span class="line">余弦相似性通过测量两个向量点积空间夹角的余弦值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1，并且其最小值是-1。</span><br><span class="line"></span><br><span class="line">两个向量之间的角度余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。</span><br><span class="line"></span><br><span class="line">余弦相似度通常用于两个向量的夹角在90°之内的情况，余弦相似度的值为0~1。余弦相似度可用在任何维度的向量比较中，因此在高维空间中的应用非常广泛。</span><br><span class="line"></span><br><span class="line">在实际应用中，通常会先提取两个数据的特征，每个数据各形成一个n维向量，然后通过计算这两个向量的余弦相似度来判定这两个向量是否是同一类型。例如：文本分类、图像识别等都能使用余弦相似度算法。</span><br><span class="line"></span><br><span class="line">设定一个常数C（0≤C≤1），OA与OB之间形成了夹角a，余弦相似度如果大于C，就认为OA与OB属于同一类，如图8-28所示。</span><br><span class="line"></span><br><span class="line">![](Image00276.jpg)</span><br><span class="line"></span><br><span class="line">图8-28 余弦相似度</span><br><span class="line"></span><br><span class="line">### 8.5 SVM</span><br><span class="line"></span><br><span class="line">1992~1995年，Vapnik等在SLT的基础上发展了SVM算法。它在解决小样本、非线性及高维模式识别问题中都表现出了许多特有的优势，目前已经成为与神经网络地位齐名的算法，在样本量较小的情况下，其实际运用效果甚至超过了神经网络。</span><br><span class="line"></span><br><span class="line">#### 8.5.1 数学原理</span><br><span class="line"></span><br><span class="line">SVM中文名为支持向量机，英文全称为Support Vector Machine，是一种监督式学习的方法。它拥有坚实的数学基础，数学原理较复杂，涉及的数学知识很多，如果将其相关理论以及推导完全展开来，能写成一本超过300页的书。因此，这里仅简单介绍SVM的基本原理。</span><br><span class="line"></span><br><span class="line">1.算法策略</span><br><span class="line"></span><br><span class="line">SVM首先将向量映射到一个更高维的空间里，在其中建立最大间隔超平面，将数据分开；然后，在超平面两边再设立两个互相平行的超平面；最后分隔超平面，使两个平行超平面的距离最大化。SVM假定平行超平面间的距离或差距越大，分类器的总误差越小。</span><br><span class="line"></span><br><span class="line">![](Image00277.jpg)</span><br><span class="line"></span><br><span class="line">图8-29 超平面</span><br><span class="line"></span><br><span class="line">2.超平面</span><br><span class="line"></span><br><span class="line">超平面的数学形式可以写作：</span><br><span class="line"></span><br><span class="line">w·x-b=0</span><br><span class="line"></span><br><span class="line">其中x是超平面上的点，w是垂直于超平面的向量。</span><br><span class="line"></span><br><span class="line">由图8-29可知，平行超平面可表示为以下两个方程：</span><br><span class="line"></span><br><span class="line">w·x-b=1</span><br><span class="line"></span><br><span class="line">w·x-b=-1</span><br><span class="line"></span><br><span class="line">其中，w为超平面的法向量，是一个变量。</span><br><span class="line"></span><br><span class="line">如果数据是线性可分的，可找到两个超平面，在它们之间没有任何样本点，并且这两个超平面之间的距离也最大。</span><br><span class="line"></span><br><span class="line">这两个超平面之间的距离是2/|w|，因此需要最小化|w|，因为这两个超平面之间没有任何样本点，所以xi还需要满足以下两个条件中的一个：</span><br><span class="line"></span><br><span class="line">w·xi -b≥1</span><br><span class="line"></span><br><span class="line">w·xi -b≤-1</span><br><span class="line"></span><br><span class="line">把上面两个式子合写，将变成：</span><br><span class="line"></span><br><span class="line">Ci (w·xi -b)≥-1， 1≤i≤n</span><br><span class="line"></span><br><span class="line">3.二次规划最优化</span><br><span class="line"></span><br><span class="line">二次规划问题可以用以下形式来描述。</span><br><span class="line"></span><br><span class="line">1）函数f(x)定义为：</span><br><span class="line"></span><br><span class="line">f(x)=(1/2)xT Qx+cT x</span><br><span class="line"></span><br><span class="line">其中，xT 是x的转置。</span><br><span class="line"></span><br><span class="line">2）函数受到一个或更多如下形式的限制条件：</span><br><span class="line"></span><br><span class="line">Ax≤b</span><br><span class="line"></span><br><span class="line">Ex=d</span><br><span class="line"></span><br><span class="line">如果Q是半正定矩阵，那么f(x)是一个凸函数。如果有至少一个向量x满足约束而且f(x)在可行域有下界，二次规划问题就有一个全局最小值x。如果Q是正定矩阵，那么全局最小值就是唯一的。如果Q=0，二次规划问题就变成线性规划问题。</span><br><span class="line"></span><br><span class="line">再来看SVM算法，该算法提出了两个要求：第一，超平面之间没有任何样本点；第二，超平面之间的距离最大。这样就形成了二次规划最优化问题。</span><br><span class="line"></span><br><span class="line">![](Image00278.jpg)</span><br><span class="line"></span><br><span class="line">这也是一个二次凸规划问题。</span><br><span class="line"></span><br><span class="line">根据优化理论，一个点x成为全局最小值的必要条件是满足Karush-Kuhn-Tucker（KKT）条件，当f(x)是凸函数时，KKT条件也是充分条件。因此通过拉格朗日变换以及KKT定理推导，二次凸规划最优化问题转变为：</span><br><span class="line"></span><br><span class="line">![](Image00279.jpg)</span><br><span class="line"></span><br><span class="line">然后引入核函数，最后的目标函数为：</span><br><span class="line"></span><br><span class="line">![](Image00280.jpg)</span><br><span class="line"></span><br><span class="line">改写为矩阵相乘的格式，得到：</span><br><span class="line"></span><br><span class="line">![](Image00281.jpg)</span><br><span class="line"></span><br><span class="line">最终的目标变成了：通过训练样本寻找α，使得下式最小：</span><br><span class="line"></span><br><span class="line">![](Image00282.jpg)</span><br><span class="line"></span><br><span class="line">核函数可以是线性的或非线性的，线性核函数仅能完成线性分类，而非线性核函数既可以完成线性分类，也可以完成非线性分类。</span><br><span class="line"></span><br><span class="line">#### 8.5.2 SMO算法</span><br><span class="line"></span><br><span class="line">SMO（最小贯序列方法）是改进的SVM训练算法，同其他SVM训练算法一样，SMO会将一个大的QP问题分解为一系列小的QP问题。与其他算法不一样的是，SMO处理的是规模最小的QP问题，因此能够快速解决并获得解析解，而且能够有效地改善空间和时间复杂度。</span><br><span class="line"></span><br><span class="line">SMO基本原理是：每次仅选择两个元素共同优化，在其他参数固定的前提下，找到这两个参数的最优值，并更新相应的α向量，而这两个点乘子的优化可以获得解析解。</span><br><span class="line"></span><br><span class="line">#### 8.5.3 算法应用</span><br><span class="line"></span><br><span class="line">SVM算法的数学原理较难懂，推导过程复杂，掌握SVM算法的关键在于动手实践。通过编写代码，运用SVM算法解决机器学习问题才能真正理解它。mlpy库提供了SVM算法的相关函数，本节将以mlpy库为例进行阐述，请按第2章的指导安装mlpy库。</span><br><span class="line"></span><br><span class="line">1.核函数</span><br><span class="line"></span><br><span class="line">mlpy的SVM算法库提供以下核函数。</span><br><span class="line"></span><br><span class="line">线性核函数通常表现为直线方程，函数名为linear。</span><br><span class="line"></span><br><span class="line">非线性核函数如下：</span><br><span class="line"></span><br><span class="line">1）多项式函数，函数名为poly。</span><br><span class="line"></span><br><span class="line">2）径向基函数，函数名为rbf。</span><br><span class="line"></span><br><span class="line">3）sigmoid函数，函数名为sigmoid。</span><br><span class="line"></span><br><span class="line">2.线性分类</span><br><span class="line"></span><br><span class="line">下面使用线性核作为SVM的核函数，对下面的数据进行分类。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x = [[1,8],[3,20],[1,15],[3,35],[5,35],[4,40],[7,80],[6,49]]  
    Y = [1,1,0,0,1,0,0,1]  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">创建SVM类的实例，并使用learn方法训练SVM。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x=np.array(x)
    y=np.array(y)
    svm = mlpy.LibSvm()
    svm.learn(x, y) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">使用pred方法对未知数据进行分类。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ty=svm.pred(tlp_x[ii]) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #email:myhaspl@qq.com
    #author:麦好


    #8-14.py
    import numpy as np
    import matplotlib.pyplot as plt
    import mlpy
    print 'loading  ...'
    x = [[1,8],[3,20],[1,15],[3,35],[5,35],[4,40],[7,80],[6,49]]
    y=[1,1,0,0,1,0,0,1]
    showpoint=['ro','r*']
    tshowpoint=['bo','b*']
    x=np.array(x)
    y=np.array(y)
    svm = mlpy.LibSvm()
    svm.learn(x, y)
    lp_x1 = x[:,0]
    lp_x2 = x[:,1]
    xmin, xmax = np.min(lp_x1)-1, np.max(lp_x1)+1
    ymin, ymax = np.min(lp_x2)-1, np.max(lp_x2)+1
    plt.subplot(111)
    plt.xlabel(u"x")
    plt.xlim(xmin, xmax)
    plt.ylabel(u"y")
    plt.ylim(ymin, ymax)
    #显示样本点


    for ii in xrange(0,len(x)):
        ty=svm.pred(x[ii])
        if ty>0:
            plt.plot(lp_x1[ii], lp_x2[ii], showpoint[int(ty)])
        else:
            plt.plot(lp_x1[ii], lp_x2[ii], showpoint[int(ty)])        
    #未知样本分类


    tlp_x1=np.random.rand(50)*(xmax-xmin)+xmin
    tlp_x2=np.random.rand(50)*(ymax-ymin)+xmin
    tlp_x=np.array(zip(tlp_x1,tlp_x2))
    for ii in xrange(0,len(tlp_x)):
        ty=svm.pred(tlp_x[ii])
        if ty>0:
            plt.plot(tlp_x1[ii],tlp_x2[ii], tshowpoint[int(ty)])
        else:
            plt.plot(tlp_x1[ii],tlp_x2[ii], tshowpoint[int(ty)]) 
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码中，随机生成了50个数据作为待分类未知样本。如图8-30所示是程序生成的分类散点图，实心圆圈和星号分别代表两类数据。运行程序后，将出现图8-30的彩图，其中红色的是样本数据，蓝色的是测试数据。从图上能直观看到，从图上能直观看到，分类很成功。</span><br><span class="line"></span><br><span class="line">![](Image00283.jpg)</span><br><span class="line"></span><br><span class="line">图8-30 分类散点图</span><br><span class="line"></span><br><span class="line">3.非线性分类</span><br><span class="line"></span><br><span class="line">非线性分类需要选择非线性核函数，这里选择poly作为SVM的核函数。尝试将分属于下面两个函数的坐标点分开：</span><br><span class="line"></span><br><span class="line">第一类：y=x^a+b （a&lt;=2，abs(b)&lt;10）</span><br><span class="line"></span><br><span class="line">第二类：y=x^a+b （a&gt;=3，abs(b)&lt;10）</span><br><span class="line"></span><br><span class="line">1）设置样本数据。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x= [[1,1],[2,4],[3,12],[9,70],[5,130],[4,13],[5,29],[5,135],[4,68],[10,1000],[8,520],[7,340],[6,40],[10,150]] 
    y=[1,1,1,1,0,1,1,0,0,0,0,0,1,1] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）设置SVM的核函数，进行训练。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x=np.array(x)  
    y=np.array(y)  
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly', gamma=10)  
    svm.learn(x, y) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）随机产生待分类数据，进行测试。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    tlp_x10=np.random.rand(100)*(xmax-xmin)+xmin  
    tlp_x20=tlp_x10**3+np.random.rand(100)*20-10  
    tlp_x11=np.random.rand(100)*(xmax-xmin)+xmin  
    tlp_x21=tlp_x11**2+np.random.rand(100)*20-10  
    tlp_x30=np.random.rand(50)*(xmax-xmin)+xmin  
    tlp_x31=tlp_x30**(round(np.random.rand()*6,0)+3)+np.random.rand(50)*10-5  
    tlp_x40=np.random.rand(50)*(xmax-xmin)+xmin  
    tlp_x41=tlp_x30**(round(np.random.rand(),0)+1)+np.random.rand(50)*10-5 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图8-31所示是程序生成的散点图，实心圆圈和星号分别代表不同类的数据。数据点被成功划分为两类：图的左上部呈现递增曲线趋势的数据点划分到了第2类函数，其余被划分到第1类。</span><br><span class="line"></span><br><span class="line">![](Image00284.jpg)</span><br><span class="line"></span><br><span class="line">图8-31 分类散点图</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #email:myhaspl@qq.com
    #author:麦好


    #8-15.py
    import numpy as np
    import matplotlib.pyplot as plt
    import mlpy
    print 'loading  ...'
    x = [[1,1],[2,4],[3,12],[9,70],[5,130],[4,13],[5,29],[5,135],[4,65],[10,1000],[8,520],[7,340],[6,40],[10,150]]
    y=[1,1,1,1,0,1,1,0,0,0,0,0,1,1]
    showpoint=['ro','r*']
    tshowpoint=['bo','b*']
    x=np.array(x)
    y=np.array(y)
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly', gamma=50)
    svm.learn(x, y)
    lp_x1 = x[:,0]
    lp_x2 = x[:,1]
    xmin, xmax = np.min(lp_x1)-0.5, np.max(lp_x1)+0.5
    ymin, ymax = np.min(lp_x2)-0.5, np.max(lp_x2)+0.5
    plt.subplot(111)
    plt.xlabel(u"x")
    plt.xlim(xmin, xmax)
    plt.ylabel(u"y")
    plt.ylim(ymin, ymax)
    #显示样本点


    for ii in xrange(0,len(x)):
        ty=svm.pred(x[ii])
        if ty>0:
            plt.plot(lp_x1[ii], lp_x2[ii], showpoint[int(ty)])
        else:
            plt.plot(lp_x1[ii], lp_x2[ii], showpoint[int(ty)])        
    #未知样本分类


    tlp_x10=np.random.rand(100)*(xmax-xmin)+xmin
    tlp_x20=tlp_x10**3+np.random.rand(100)*20-10
    tlp_x11=np.random.rand(100)*(xmax-xmin)+xmin
    tlp_x21=tlp_x11**2+np.random.rand(100)*20-10
    tlp_x30=np.random.rand(50)*(xmax-xmin)+xmin
    tlp_x31=tlp_x30**(round(np.random.rand()*6,0)+3)+np.random.rand(50)*10-5
    tlp_x40=np.random.rand(50)*(xmax-xmin)+xmin
    tlp_x41=tlp_x30**(round(np.random.rand(),0)+1)+np.random.rand(50)*10-5
    tlp_x1=tlp_x10.tolist()+tlp_x11.tolist()+tlp_x30.tolist()+tlp_x40.tolist()
    tlp_x2=tlp_x20.tolist()+tlp_x21.tolist()+tlp_x31.tolist()+tlp_x41.tolist()
    tlp_x=np.array(zip(tlp_x1,tlp_x2))
    for ii in xrange(0,len(tlp_x)):
        ty=svm.pred(tlp_x[ii])
        if ty>0:
            plt.plot(tlp_x1[ii],tlp_x2[ii], tshowpoint[int(ty)])
        else:
            plt.plot(tlp_x1[ii],tlp_x2[ii], tshowpoint[int(ty)]) 
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面以rbf为核函数完成螺旋型空间下的分类。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #8-16.py
    import numpy as np
    import matplotlib.pyplot as plt
    import mlpy
    f = np.loadtxt("spiral.data")
    x, y = f[:, :2], f[:, 2]
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='rbf', gamma=100)
    svm.learn(x, y)
    xmin, xmax = x[:,0].min()-0.1, x[:,0].max()+0.1
    ymin, ymax = x[:,1].min()-0.1, x[:,1].max()+0.1
    xx, yy = np.meshgrid(np.arange(xmin, xmax, 0.01), np.arange(ymin, ymax, 0.01))
    xnew = np.c_[xx.ravel(), yy.ravel()]
    ynew = svm.pred(xnew).reshape(xx.shape)
    fig = plt.figure(1)
    plt.pcolormesh(xx, yy, ynew)
    plt.scatter(x[:,0], x[:,1], c=y)
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图8-32所示为分类的效果图。两类数据被螺旋形分界线划分。</span><br><span class="line"></span><br><span class="line">![](Image00285.jpg)</span><br><span class="line"></span><br><span class="line">图8-32 SVM分类的效果图</span><br><span class="line"></span><br><span class="line">### 8.6 回归算法</span><br><span class="line"></span><br><span class="line">回归分析是统计学上分析数据的一种方法，目的在于了解两个或多个变量间是否相关，以及相关的方向与强度，并建立数学模型，以便观察特定变量来预测研究者感兴趣的变量，它建立了因变量与自变量之间的关系模型。</span><br><span class="line"></span><br><span class="line">#### 8.6.1 线性代数基础</span><br><span class="line"></span><br><span class="line">线性代数是数学的一个分支，它的研究对象是向量、向量空间（或称线性空间）、线性变换和有限维的线性方程组。向量空间是现代数学的一个重要课题，线性代数广泛地应用于抽象代数和泛函分析中，并能通过解析几何具体表示。线性代数在机器学习理论体系中的地位举足轻重。</span><br><span class="line"></span><br><span class="line">1.伴随矩阵</span><br><span class="line"></span><br><span class="line">在线性代数中，一个方形矩阵的伴随矩阵是一个类似于逆矩阵的概念。如果矩阵可逆，那么它的逆矩阵和它的伴随矩阵之间只差一个系数。</span><br><span class="line"></span><br><span class="line">矩阵A的伴随矩阵是A的余子矩阵的转置矩阵，具体定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00286.jpg)</span><br><span class="line"></span><br><span class="line">即AA*=A*A=|A|E</span><br><span class="line"></span><br><span class="line">其中，</span><br><span class="line"></span><br><span class="line">![](Image00287.jpg)</span><br><span class="line"></span><br><span class="line">若A可逆，则A的伴随矩阵![](Image00288.jpg) 。</span><br><span class="line"></span><br><span class="line">2.方阵的行列式运算</span><br><span class="line"></span><br><span class="line">设A、B为n阶方阵，则|AB|=|A||B|=|B||A|=|BA|</span><br><span class="line"></span><br><span class="line">但|A±B|=|A|±|B|不一定成立。</span><br><span class="line"></span><br><span class="line">3.矩阵与方阵</span><br><span class="line"></span><br><span class="line">m×n个数aij 排成m行n列的表格![](Image00289.jpg) 称为矩阵，简记为A，或(aij )m×n 。若m=n，则称A是n阶矩阵或n阶方阵。</span><br><span class="line"></span><br><span class="line">4.矩阵的基本运算</span><br><span class="line"></span><br><span class="line">设A=(aij )，B=(bij )是两个m×n矩阵，则m×n矩阵C=(cij )=aij +bij 称为矩阵A与B的和，记为A+B=C。</span><br><span class="line"></span><br><span class="line">设A=(aij )是m×n矩阵，k是一个常数，则m×n矩阵(kaij )称为数k与矩阵A的数乘，记为kA。</span><br><span class="line"></span><br><span class="line">设A=(aij )是m×n矩阵，B=(bij )是n×s矩阵，那么m×s矩阵C=(cij )，其中，cij =ai1 b1j +ai2 b2j +…+ain bnj =![](Image00290.jpg) 称为A与B的乘积，记为C=AB。</span><br><span class="line"></span><br><span class="line">5.矩阵的秩</span><br><span class="line"></span><br><span class="line">若A为n阶方阵，则r(A*)=![](Image00291.jpg)</span><br><span class="line"></span><br><span class="line">6.线性相关与线性无关</span><br><span class="line"></span><br><span class="line">α1 ，α2 ，…，αs 线性相关至少有一个向量可以用其余向量线性表示。</span><br><span class="line"></span><br><span class="line">若α1 ，α2 ，…，αs 线性无关，α1 ，α2 ，…，αs ，β线性相关![](Image00292.jpg) b可以由α1，α2 ，…，αs 唯一线性表示。</span><br><span class="line"></span><br><span class="line">#### 8.6.2 最小二乘法原理</span><br><span class="line"></span><br><span class="line">1.范数</span><br><span class="line"></span><br><span class="line">在向量空间Rn (Cn )中，设x=(x1 ，x2 ，…，xn )T ，向量范数定义如下：</span><br><span class="line"></span><br><span class="line">x的2-范数或欧氏范数计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00293.jpg)</span><br><span class="line"></span><br><span class="line">x的1-范数计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00294.jpg)</span><br><span class="line"></span><br><span class="line">x的∞范数或最大范数计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00295.jpg)</span><br><span class="line"></span><br><span class="line">x的p范数计算公式为：</span><br><span class="line"></span><br><span class="line">![](Image00296.jpg)</span><br><span class="line"></span><br><span class="line">A的行范数计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00297.jpg)</span><br><span class="line"></span><br><span class="line">A的列范数计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00298.jpg)</span><br><span class="line"></span><br><span class="line">A的2-范数或谱范数计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00299.jpg)</span><br><span class="line"></span><br><span class="line">其中λmax (AT A)为AT A的最大特征值。</span><br><span class="line"></span><br><span class="line">2.算法目标</span><br><span class="line"></span><br><span class="line">线性回归算法通过适合的参数，使函数与观测值之差的平方和最小，即：</span><br><span class="line"></span><br><span class="line">![](Image00300.jpg)</span><br><span class="line"></span><br><span class="line">1）二元线性回归。首先将线性回归函数定义为如下形式：</span><br><span class="line"></span><br><span class="line">y=x0 +x1 t</span><br><span class="line"></span><br><span class="line">根据其算法目标，得到下式：</span><br><span class="line"></span><br><span class="line">![](Image00301.jpg)</span><br><span class="line"></span><br><span class="line">解上式，得到如下形式：</span><br><span class="line"></span><br><span class="line">![](Image00302.jpg)</span><br><span class="line"></span><br><span class="line">其中![](Image00303.jpg) ，为t值的算术平均值。</span><br><span class="line"></span><br><span class="line">2）多元线性回归。将多个不相关变量t1 ，…，tq ，组成下面线性函数：</span><br><span class="line"></span><br><span class="line">y(t1 ，…，tq ；x0 ，x1 ，…，xq )=x0 +x1 t1 +…+xq tq</span><br><span class="line"></span><br><span class="line">上式可写成Ax=b的形式，如下所示：</span><br><span class="line"></span><br><span class="line">![](Image00304.jpg)</span><br><span class="line"></span><br><span class="line">接着求解目标函数：</span><br><span class="line"></span><br><span class="line">![](Image00305.jpg)</span><br><span class="line"></span><br><span class="line">其特解为A的广义逆矩阵与b的乘积，这同时也是2-范数极小的解，其通解为特解加上A的零空间。</span><br><span class="line"></span><br><span class="line">#### 8.6.3 线性回归</span><br><span class="line"></span><br><span class="line">1.回归模型求解</span><br><span class="line"></span><br><span class="line">上节讲述了一些多元线性回归模型，可表示为Ax=b的形式，求解回归模型就是求解A代表的参数值的估计值，求解过程就是线性回归的过程。根据最小二乘原理及相关数学推导，参数估计值为：</span><br><span class="line"></span><br><span class="line">![](Image00306.jpg)</span><br><span class="line"></span><br><span class="line">2.一元线性回归</span><br><span class="line"></span><br><span class="line">如果随机变量y与变量x之间呈现某种线性关系，则y与x之间一元线性回归模型为：</span><br><span class="line"></span><br><span class="line">![](Image00307.jpg)</span><br><span class="line"></span><br><span class="line">上式也称变量y对变量x的一元线性回归方程，a、b称为回归系数。</span><br><span class="line"></span><br><span class="line">根据前面讲述的最小二乘法原理，用Python编码实现。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-17.py
    import matplotlib.pyplot as plt
    x =[1,2,3,3,6,12,11]
    y =[3,5,8,5,12,26,20]
    average_x=float(sum(x))// len(x)
    average_y=float(sum(y))/len(y)
    x_sub=map((lambda x:x-average_x),x)
    y_sub=map((lambda x:x-average_y),y)
    x_sub_pow2=map((lambda x:x**2),x_sub)
    y_sub_pow2=map((lambda x:x**2),y_sub)
    x_y=map((lambda x,y:x*y),x_sub,y_sub)
    a=float(sum(x_y))/sum(x_sub_pow2)
    b=average_y-a*average_x
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.plot(x, y, '*')
    plt.plot([0,15],[0*a+b,15*a+b])
    plt.grid()
    plt.title("{0}*x+{1}".format(a,b))
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图8-33所示为程序绘制的散点图，这些数据点呈明显的线性趋势，程序将它们的线性趋势绘制成一条回归线，回归效果不错。</span><br><span class="line"></span><br><span class="line">![](Image00308.jpg)</span><br><span class="line"></span><br><span class="line">图8-33 散点图</span><br><span class="line"></span><br><span class="line">3.多元线性回归</span><br><span class="line"></span><br><span class="line">一元线性回归是指将一个主要影响因素作为自变量，分析自变量的变化如何引起因变量的变化。在现实问题的研究中，因变量的变化往往受几个重要因素的影响，此时就需要用两个或两个以上的影响因素作为自变量来解释因变量的变化，这就是多元回归。</span><br><span class="line"></span><br><span class="line">设y为因变量，x1 ，x2 ，…，xk 为自变量，并且自变量与因变量之间为线性关系时，则多元线性回归模型为：</span><br><span class="line"></span><br><span class="line">y=b0 +b1 x1 +b2 x2 +…+bk xk +e</span><br><span class="line"></span><br><span class="line">根据最小二乘法，使用Python来实现这个回归模型。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-18.py
    import numpy as np
    x =np.matrix([[7,2,3],[3,7,17],[11,3,5]],dtype=np.float64)
    y =np.matrix([28,40,44],dtype=np.float64).T
    b=(x.T*x).I*x.T*y
    print u"参数项矩阵为

    {0}".format(b)
    i=0
    cb=[]
    while  i<3: cb.append(b[i,0]) i+="1" temp_e="y-x*b" mye="temp_e.sum()/temp_e.size" e="np.matrix([mye,mye,mye]).T" print "y="%f*x1+%f*x2+%f*x3+%f" %(cb[0],cb[1],cb[2],mye)" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码计算了参数估计值，并列出了多元线性回归方程。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    参数项矩阵为

    [[ 3.]
     [ 2.]
     [ 1.]]
    y=3.000000*x1+2.000000*x2+1.000000*x3+-0.000000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 8.6.4 多元非线性回归</span><br><span class="line"></span><br><span class="line">如果自变量X1 ，X2 ，…，Xm 与因变量Y皆具有非线性关系，或者有的为非线性，有的为线性，则需要选择多元非线性回归模型。非线性回归方程很难求解，通常把非线性回归转化为线性回归，然后应用最小二乘法求解。</span><br><span class="line"></span><br><span class="line">例如，非线性回归方程模型为：</span><br><span class="line"></span><br><span class="line">![](Image00309.jpg)</span><br><span class="line"></span><br><span class="line">首先，进行变量变换。</span><br><span class="line"></span><br><span class="line">![](Image00310.jpg)</span><br><span class="line"></span><br><span class="line">经过变换后，将其化为线性模型。</span><br><span class="line"></span><br><span class="line">![](Image00311.jpg)</span><br><span class="line"></span><br><span class="line">然后，再用最小二乘法求出参数的估计值。最后经过适当的变换，得到所求回归曲线。</span><br><span class="line"></span><br><span class="line">1.一元三次回归模型</span><br><span class="line"></span><br><span class="line">一元三次回归模为：</span><br><span class="line"></span><br><span class="line">![](Image00312.jpg)</span><br><span class="line"></span><br><span class="line">用Python代码实现：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-19.py 
    #y=b1*x+b2*(x^2)+b3*(x^3)
    import numpy as np
    import matplotlib.pyplot as plt
    z=np.matrix([3,1.4,1.9]).T
    myx =np.matrix([[7],[3],[9]],dtype=np.float64)
    x = np.matrix([[myx[0,0],myx[0,0]**2,myx[0,0]**3],\
                   [myx[1,0],myx[1,0]**2,myx[1,0]**3],\
                   [myx[2,0],myx[2,0]**2,myx[2,0]**3]],\
                   dtype=np.float64)
    y =x*z
    b=(x.T*x).I*x.T*y
    print u"参数项矩阵为

    {0}".format(b)
    i=0
    cb=[]
    while  i<3: cb.append(b[i,0]) i+="1" temp_e="y-x*b" mye="temp_e.sum()/temp_e.size" e="np.matrix([mye,mye,mye]).T" print "y="%f*x+%f*x^2+%f*x^3+%f" %(cb[0],cb[1],cb[2],mye)" pltx="np.linspace(0,10,1000)" plty="cb[0]*pltx+cb[1]*(pltx**2)+cb[2]*(pltx**3)+mye" plt.plot(myx,y,"*") plt.plot(pltx,plty) plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行后，计算参数估计值以及最终的回归方程。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

     参数项矩阵为

    [[ 3. ]
     [ 1.4]
     [ 1.9]]
    y=3.000000*x+1.400000*x^2+1.900000*x^3+0.000000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">非线性回归方程表现为曲线，如图8-34所示是上述代码生成的回归曲线。</span><br><span class="line"></span><br><span class="line">![](Image00313.jpg)</span><br><span class="line"></span><br><span class="line">图8-34 回归曲线</span><br><span class="line"></span><br><span class="line">2.二元二次多项式回归方程</span><br><span class="line"></span><br><span class="line">二元二次多项式回归方程为：</span><br><span class="line"></span><br><span class="line">![](Image00314.jpg)</span><br><span class="line"></span><br><span class="line">这样上式即可化为以下五元一次线性回归方程：</span><br><span class="line"></span><br><span class="line">![](Image00315.jpg)</span><br><span class="line"></span><br><span class="line">根据推导结果来看，可以按多元线性回归方法计算各偏回归系数，建立二元二次多项式回归方程。</span><br><span class="line"></span><br><span class="line">下面用Python求解二元二次多项式回归方程。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-20.py 
    #y=b1*x1+b2*(x2^2)+b3*x1*x2
    import numpy as np
    z=np.matrix([3,1.4,1.9]).T
    myx =np.matrix([[7,3],[3,17],[11,5]],dtype=np.float64)
    x = np.matrix([[myx[0,0],myx[0,1]**2,myx[0,0]*myx[0,1]],\
                   [myx[1,0],myx[1,1]**2,myx[1,0]*myx[1,1]],\
                   [myx[2,0],myx[2,1]**2,myx[2,0]*myx[2,1]]],\
                   dtype=np.float64)
    y =x*z
    b=(x.T*x).I*x.T*y
    print u"参数项矩阵为

    {0}".format(b)
    i=0
    cb=[]
    while  i<3: cb.append(b[i,0]) i+="1" temp_e="y-x*b" mye="temp_e.sum()/temp_e.size" e="np.matrix([mye,mye,mye]).T" print "y="%f*x1+%f*x2^2+%f*x1*x2+%f" %(cb[0],cb[1],cb[2],mye)" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序计算回归方程的参数后，列出回归方程，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    参数项矩阵为

    [[ 3. ]
     [ 1.4]
     [ 1.9]]
    y=3.000000*x1+1.400000*x2^2+1.900000*x1*x2+-0.000000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 8.6.5 岭回归方法</span><br><span class="line"></span><br><span class="line">只有正方形（n×n）的矩阵（也称为方阵），才可能有但非必然有逆矩阵。若方阵A的逆矩阵存在，则称A为非奇异方阵或可逆方阵。回顾一下参数项的求解公式：</span><br><span class="line"></span><br><span class="line">![](Image00316.jpg)</span><br><span class="line"></span><br><span class="line">这样就产生了一个问题：如果奇异矩阵或非方阵的矩阵不存在逆矩阵，即上式中的逆矩阵不存在了，怎样求解参数项呢？</span><br><span class="line"></span><br><span class="line">此外，某些自变量之间可能存在共线性，这也给求逆带来了麻烦。岭回归方法可以解决这个问题，它是一种专用于共线性数据分析的有偏估计回归方法，实质上它是一种改良的最小二乘估计法，是通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价，获得回归系数更为符合实际、更可靠的回归方法，对病态数据的耐受性远远强于最小二乘法。其基本原理是：</span><br><span class="line"></span><br><span class="line">给参数项求解公式中的X&apos;X部分加上正常数矩阵kI（k&gt;0），则X&apos;X+kI接近奇异的程度较小，如果X&apos;X+kI可逆，则参数的求解公式变为：</span><br><span class="line"></span><br><span class="line">![](Image00317.jpg)</span><br><span class="line"></span><br><span class="line">其中k称为岭参数。![](Image00318.jpg) (k)作为B的估计应比最小二乘估计![](Image00318.jpg) 稳定，当k=0时，岭回归估计就是普通的最小二乘估计。因为岭参数k不是唯一确定的，所以得到的岭回归估计![](Image00318.jpg)</span><br><span class="line">(k)实际是对回归参数B的估计值。</span><br><span class="line"></span><br><span class="line">选择一个适合的岭参数很重要，岭迹法是方法之一。选择的原则是：</span><br><span class="line"></span><br><span class="line">·各回归系数的岭估计基本稳定。</span><br><span class="line"></span><br><span class="line">·系数符号变得合理。</span><br><span class="line"></span><br><span class="line">·残差平方和。</span><br><span class="line"></span><br><span class="line">·取使方程基本稳定的最小K值。</span><br><span class="line"></span><br><span class="line">#### 8.6.6 伪逆方法</span><br><span class="line"></span><br><span class="line">除了岭回归方法，伪逆方法也是一种不错的方法，它是对逆阵的推广。一般所说的伪逆是指MoorePenrose伪逆，它是由E.H.Moore和Roger Penrose分别独立提出的。</span><br><span class="line"></span><br><span class="line">一个与A的转置矩阵AT 同型的矩阵X，满足：AXA=A，XAX=X。此时，称矩阵X为矩阵A的伪逆，也称为广义逆矩阵。</span><br><span class="line"></span><br><span class="line">numpy提供了求伪逆的函数linalg.pinv()，可调用numpy的这个方法对一组数据进行回归分析，这组数据不适合用前面介绍的非线性回归算法计算。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-21.py 
    #y=b1*x1+b2*x2+b3*(x1^2)+b4*(x2^2)+b5*x1*x2
    import numpy as np
    z=np.matrix([1.4,1.9,1.7,0.8,1.1]).T
    myx =np.matrix([[7,3],[3,17],[11,5]],dtype=np.float64)
    x = np.matrix([[myx[0,0],myx[0,1],myx[0,0]**2,myx[0,1]**2,myx[0,0]*myx[0,1]],\
                   [myx[1,0],myx[1,1],myx[1,0]**2,myx[1,1]**2,myx[1,0]*myx[1,1]],\
                   [myx[2,0],myx[2,1],myx[2,0]**2,myx[2,1]**2,myx[2,0]*myx[2,1]]],\
                   dtype=np.float64)
    y =x*z
    wn=np.linalg.pinv(x.T*x)
    b=wn*x.T*y
    print u"参数项矩阵为

    {0}".format(b)
    i=0
    cb=[]
    while  i<5: cb.append(b[i,0]) i+="1" temp_e="y-x*b" mye="temp_e.sum()/temp_e.size" e="np.matrix([mye,mye,mye]).T" print "y="%f*x1+%f*x2+%f*(x1^2)+%f*(x2^2)+%f*x1*x2+%f" %(cb[0],cb[1],cb[2],cb[3],cb[4],mye)" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行后，输出的参数矩阵及回归方程如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    参数项矩阵为

    [[ 1.59659657]
     [ 0.69002152]
     [ 2.01029166]
     [ 0.9820693 ]
     [ 0.4052783 ]]
    y=1.596597*x1+0.690022*x2+2.010292*(x1^2)+0.982069*(x2^2)+0.405278*x1*x2+-0.000000 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 8.7 PCA降维</span><br><span class="line"></span><br><span class="line">PCA主要用于数据降维。由一系列特征组成的多维向量，其中某些元素本身没有区分性，比如某个元素在所有的样本中都相等，或者彼此差距不大，那么这个元素本身就没有区分性，如果用它做特征来区分，贡献会非常小。我们的目的是找到那些变化大的元素，即方差大的维，而去除掉那些变化不大的维。</span><br><span class="line"></span><br><span class="line">使用PCA的好处在于，可以对新求出的“主元”向量的重要性进行排序。根据需要取前面最重要的部分，将后面的维数省去，从而达到降维、简化模型或对数据进行压缩的效果。同时最大程度地保持了原有数据的信息，较低的维数意味着运算量的减少，在数据较多的情况带来的性能提高更明显。</span><br><span class="line"></span><br><span class="line">PCA通过将主成分分析的问题转化为求解协方差矩阵的特征值和特征向量来计算。其目标是寻找r(r&lt;n)个新变量，使它们反映事物的主要特征，压缩原有数据矩阵的规模，每个新变量是原有变量的线性组合，体现原有变量的综合效果，这r个新变量称为“主成分”，它们可以在很大程度上反映原来n个变量的影响，并且这些新变量是互不相关的，也是正交的。</span><br><span class="line"></span><br><span class="line">以将数据的维数从N降到5为例，PCA算法过程如下：</span><br><span class="line"></span><br><span class="line">1）计算样本矩阵X协方差矩阵。</span><br><span class="line"></span><br><span class="line">2）计算协方差矩阵S的特征向量e1 ，e2 ，…，eN 及其特征值i=1，2，…，N。</span><br><span class="line"></span><br><span class="line">3）把特征值按从大到小排序，取前5位特征值对应的特征向量组成投影矩阵W。</span><br><span class="line"></span><br><span class="line">4）投影数据到W组成的空间之中。</span><br><span class="line"></span><br><span class="line">上述算法过程较抽象，理解它的最好方式就是动手实现它。下面编写一段Python程序，使用mlpy库提供的PCA类，实现PCA算法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    # -*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #8-22.py
    import numpy as np
    import matplotlib.pyplot as plt
    import mlpy
    np.random.seed(0)
    mean, cov, n = [0, 0], [[1,1],[1,1.5]], 100
    x = np.random.multivariate_normal(mean, cov, n)
    pca = mlpy.PCA()
    pca.learn(x)
    coeff = pca.coeff()
    fig = plt.figure(1)
    plot1 = plt.plot(x[:, 0], x[:, 1], 'o')
    plot2 = plt.plot([0,coeff[0, 0]], [0, coeff[1, 0]], linewidth=4, color='r')
    plot3 = plt.plot([0,coeff[0, 1]], [0, coeff[1, 1]], linewidth=4, color='g')
    xx = plt.xlim(-4, 4)
    yy = plt.ylim(-4, 4)
    z = pca.transform(x, k=1)
    xnew = pca.transform_inv(z)
    fig2 = plt.figure(2)
    plot1 = plt.plot(xnew[:, 0], xnew[:, 1], 'o')
    xx = plt.xlim(-4, 4)
    yy = plt.ylim(-4, 4)
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图8-35所示是程序生成的两张散点图，左边是数据降维前的效果，右边是数据降维后的效果。能明显看出数据降维后，数据的整体趋势并没有改变，最大程度地保持了原有数据的信息。</span><br><span class="line"></span><br><span class="line">![](Image00319.jpg)</span><br><span class="line"></span><br><span class="line">图8-35 数据降维</span><br><span class="line"></span><br><span class="line">### 8.8 关联规则</span><br><span class="line"></span><br><span class="line">#### 8.8.1 关联规则概述</span><br><span class="line"></span><br><span class="line">以购买商品为例进行分析，假设某顾客同时购买了A商品和B商品，然后又购买了C商品，也就是说此次共买了商品&#123;A，B，C&#125;，则可把&#123;A，B&#125;、&#123;C&#125;、&#123;A，B，C&#125;称为项集（购买项目的集合），可以建立一条规则，同时买了A和B两种商品的顾客可能会买C商品，记为&#123;A，B&#125;-&gt;&#123;C&#125;，这样通过一定数量的购买记录就能分析出用户的购买习惯。可将这一过程用形式化语言进行如下定义：</span><br><span class="line"></span><br><span class="line">项集I由若干个项目组成，事务t由若干个项集组成，事务集T由若干个事务t组成，设项集X是事务ti ∈T的一个子集，也可记为x∈ti ，分析事务集，在指定支持度和置信度满足的情况下，认为规则X-&gt;Y成立（X和Y均为项集），则称X为前件，Y为后件。</span><br><span class="line"></span><br><span class="line">支持度的计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00320.jpg)</span><br><span class="line"></span><br><span class="line">其中n为事务集T的事务数量，count表示数量。</span><br><span class="line"></span><br><span class="line">置信度的计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00321.jpg)</span><br><span class="line"></span><br><span class="line">其中count表示数量。</span><br><span class="line"></span><br><span class="line">置信度可理解为条件概率，即：在事务集中，X项集存在的前提下，项集Y存在的可能性；支持度可理解为事务集T中X和Y项集同时存在的概率。可给支持度和置信度设置一个阈值，若这两个指标均大于这个阈值，则可生成关联规则。</span><br><span class="line"></span><br><span class="line">#### 8.8.2 频繁项集算法</span><br><span class="line"></span><br><span class="line">1.Apriori算法</span><br><span class="line"></span><br><span class="line">Apriori算法是一种挖掘布尔关联规则频繁项集的算法，其核心是基于两阶段频集思想的递推。该关联规则在分类上属于单维、单层、布尔关联规则，所有支持度大于最小支持度的项集称为频繁项集，简称频集。算法的目标是寻找最大的频繁项集，算法过程如下：</span><br><span class="line"></span><br><span class="line">1）简单统计所有包含一个元素的项集出现的频数，并找出那些不小于最小支持度的项集，即一维最大项集。</span><br><span class="line"></span><br><span class="line">2）继续循环处理直到再没有最大项集生成为止。循环过程是：第k步中，根据第k-1步生成的k-1维最大项集产生k维侯选项集，然后对数据库进行搜索，得到侯选项集的项集支持度，并与最小支持度进行比较，从而找到k维最大项集。</span><br><span class="line"></span><br><span class="line">下面以一个例子来直观说明算法的过程。假设有一个数据库表sales，其中有4个购买事务，如图8-36所示。</span><br><span class="line"></span><br><span class="line">1）将最小支持度Minsup设定为2，算法的运行过程如图8-37所示。</span><br><span class="line"></span><br><span class="line">![](Image00322.jpg)</span><br><span class="line"></span><br><span class="line">图8-36 数据库表sales的购买事务</span><br><span class="line"></span><br><span class="line">![](Image00323.jpg)</span><br><span class="line"></span><br><span class="line">图8-37 Apriori算法过程：设定最小支持度</span><br><span class="line"></span><br><span class="line">2）扫描上述sales表，对每个候选项进行支持度计数，得到表C1，如图8-38所示。</span><br><span class="line"></span><br><span class="line">3）比较候选项支持度计数与最小支持度Minsup，产生1维最大项集L1，如图8-39所示。</span><br><span class="line"></span><br><span class="line">![](Image00324.jpg)</span><br><span class="line"></span><br><span class="line">图8-38 Apriori算法过程：候选项支持度计数</span><br><span class="line"></span><br><span class="line">![](Image00325.jpg)</span><br><span class="line"></span><br><span class="line">图8-39 Apriori算法过程：产生1维最大项集</span><br><span class="line"></span><br><span class="line">4）由L1产生候选项集C2，如图8-40所示。</span><br><span class="line"></span><br><span class="line">5）扫描sales表，对每个候选项集进行支持度计数，如图8-41所示。</span><br><span class="line"></span><br><span class="line">![](Image00326.jpg)</span><br><span class="line"></span><br><span class="line">图8-40 Apriori算法过程：产生2维候选项集</span><br><span class="line"></span><br><span class="line">![](Image00327.jpg)</span><br><span class="line"></span><br><span class="line">图8-41 Apriori算法过程：2维候选项集支持度计数</span><br><span class="line"></span><br><span class="line">6）比较候选项支持度计数与最小支持度Minsup，产生2维最大项集L2，如图8-42所示。</span><br><span class="line"></span><br><span class="line">![](Image00328.jpg)</span><br><span class="line"></span><br><span class="line">图8-42 Apriori算法过程：产生2维最大项集</span><br><span class="line"></span><br><span class="line">7）由L2产生候选项集C3，如图8-43所示。</span><br><span class="line"></span><br><span class="line">![](Image00329.jpg)</span><br><span class="line"></span><br><span class="line">图8-43 Apriori算法过程：产生3维候选项集</span><br><span class="line"></span><br><span class="line">8）比较候选项支持度计数与最小支持度Minsup，产生3维最大项集L3，如图8-44所示。</span><br><span class="line"></span><br><span class="line">![](Image00330.jpg)</span><br><span class="line"></span><br><span class="line">图8-44 Apriori算法过程：产生3维最大项集</span><br><span class="line"></span><br><span class="line">9）至此，算法终止。</span><br><span class="line"></span><br><span class="line">Apriori算法的主要缺点如下：</span><br><span class="line"></span><br><span class="line">·每一步都要产生候选项集，循环产生的组合过多，没有排除不应该参与组合的元素，组合随着数据库记录的增加呈现出几何级数的增加。</span><br><span class="line"></span><br><span class="line">·每次计算项集的支持度时，都对事务集中的全部记录进行了一遍扫描，从而增加了计算机系统的I/O开销。</span><br><span class="line"></span><br><span class="line">2.FP-growth算法</span><br><span class="line"></span><br><span class="line">针对Apriori算法的性能瓶颈问题——需要产生大量的候选项集和重复地扫描数据库，2000年Jiawei Han等人提出了基于FP树生成频繁项集的FP-growth算法。该算法只需要进行两次数据库扫描且它不必使用侯选集，直接将数据库压缩成一棵频繁模式树，最后通过这棵树生成关联规则。研究表明它比Apriori算法大约快一个数量级。</span><br><span class="line"></span><br><span class="line">FP-growth算法是一种不产生候选模式而采用频繁模式增长的方法挖掘频繁模式的算法。算法只需要两次数据扫描：</span><br><span class="line"></span><br><span class="line">第一次扫描数据库，得到1维频繁项集。</span><br><span class="line"></span><br><span class="line">第二次扫描数据库，利用1维频繁项集过滤数据库中的非频繁项，同时生成FP树。</span><br><span class="line"></span><br><span class="line">由于FP树蕴涵了所有的频繁项集，其后频繁项集的挖掘只需要在FP树上进行即可。FP树挖掘由以下两个阶段组成：</span><br><span class="line"></span><br><span class="line">第一阶段建立FP树，即将数据库中的事务构造成一棵FP树。</span><br><span class="line"></span><br><span class="line">第二阶段为挖掘FP树，即针对FP树挖掘频繁模式和关联规则。</span><br><span class="line"></span><br><span class="line">FP-growth算法可具体描述如下：</span><br><span class="line"></span><br><span class="line">·输入：事务数据集D，最小支持度Minsup。</span><br><span class="line"></span><br><span class="line">·输出：频繁模式的完全集。</span><br><span class="line"></span><br><span class="line">具体方法如下。</span><br><span class="line"></span><br><span class="line">首先，按如下方法构建FP树。</span><br><span class="line"></span><br><span class="line">1）扫描事务数据库，收集频繁项集F并统计支持度，对F按支持度降序排序，得到频率排序好的项表L。</span><br><span class="line"></span><br><span class="line">2）创建FP树的根节点，用“null”标记它。对于D中的每个事务T，执行：选择T中的频繁项，并按L中的顺序排序。设排序后的频繁项表为[p|P]，其中p是第一个元素，而P是剩余元素的表。调用insert_tree([p|P]，T)。该过程执行情况如下：</span><br><span class="line"></span><br><span class="line">如果T有子女N使得N.itemName=p.itemName，则N的计数增加1；否则创建一个新节点N，将其计数设置为1，链接到它的父节点T，并且通过节点链结构将其链接到具有相同itemName的节点。如果P非空，则递归地调用insert_tree(P，N)。</span><br><span class="line"></span><br><span class="line">其次，通过FP-growth(Tree，α)函数来实现FP树的规则，初始调用FP-growth(Tree，null))的描述如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

        if Tree含单个路径

    P then {
        for 路径

    P中节点的每个组合

    (记作β

    )
            产生模式β∪α，其支持度为

    support=β中节点的最小支持度

    ;
        }
        else for each α

    i 在

    Tree的头部

     do {产生模式β

    =α

    i ∪

     α

    ,其支持度为

    support=α

    i.support;构造β的条件模式

    ,然后构造β的条件

    FP树

    Treeβ

    ;
    if  Treeβ≠空集

     then
        调用

    FP_growth(Treeβ

    ,β

    ) 
        }
        end <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 8.8.3 关联规则生成</span><br><span class="line"></span><br><span class="line">1.关联规则生成算法</span><br><span class="line"></span><br><span class="line">设f为一个频繁项集，a为后件，f-a为前件，可将（f-a）-&gt;a设为一条关联规则。如果（f-a）是关联规则，则（f-asub ）→asub 也是关联规则，asub 为a的某个非空子集，所有以asub 为后件的规则都成为候选关联规则，候选关联规则在支持度和置信度都大于指定阈值时，可生成关联规则。</span><br><span class="line"></span><br><span class="line">支持度的计算方式如下：</span><br><span class="line"></span><br><span class="line">![](Image00331.jpg)</span><br><span class="line"></span><br><span class="line">其中，n为事务集中事务的数量。</span><br><span class="line"></span><br><span class="line">置信度的计算方式如下：</span><br><span class="line"></span><br><span class="line">![](Image00332.jpg)</span><br><span class="line"></span><br><span class="line">当支持度conf&gt;最小支持度minconf、置信度sup&gt;最小置信度minsup时，可生成如下规则：</span><br><span class="line"></span><br><span class="line">(f-a)-&gt;a</span><br><span class="line"></span><br><span class="line">产生频繁项集后，就可计算关联规则了，具体算法可采用如下方式。</span><br><span class="line"></span><br><span class="line">第一步，从频繁项集f中生成1项后件的候选关联规则，并从中挑选conf&gt;minconf和sup&gt;minsup的候选规则作为关联规则。</span><br><span class="line"></span><br><span class="line">第二步，利用现有k-1项后件的关联规则，生成k项后件的候选关联规则，从中挑选conf&gt;minconf和sup&gt;minsup的候选规则作为关联规则。</span><br><span class="line"></span><br><span class="line">2.关联规则生成例子</span><br><span class="line"></span><br><span class="line">下面以图8-36所示的sales数据表中的频繁项集为例，讲解如何使用最大频繁项集L3生成关联规则。设定minconf为60%，minsup为70%，在此仅分析一次频繁项集L3，如图8-45所示。</span><br><span class="line"></span><br><span class="line">![](Image00333.jpg)</span><br><span class="line"></span><br><span class="line">图8-45 频繁项集L3</span><br><span class="line"></span><br><span class="line">首先，从1项后件的候选关联规则开始。根据L3生成以下候选关联规则：</span><br><span class="line"></span><br><span class="line">（1）&#123;I2，I3&#125;-&gt;&#123;I5&#125; [sup=2/4，conf=2/2]</span><br><span class="line"></span><br><span class="line">（2）&#123;I2，I5&#125;-&gt;&#123;I3&#125; [sup=2/4，conf=2/3]</span><br><span class="line"></span><br><span class="line">（3）&#123;I3，I5&#125;-&gt;&#123;I2&#125; [sup=2/4，conf=2/2]</span><br><span class="line"></span><br><span class="line">根据minconf和minsup的限制，选择规则（2）作为生成规则H1，如下所示。</span><br><span class="line"></span><br><span class="line">&#123;I2，I5&#125;-&gt;&#123;I3&#125;</span><br><span class="line"></span><br><span class="line">然后，根据H1，生成2项后件候选关联规则，如下所示。</span><br><span class="line"></span><br><span class="line">&#123;I2&#125;-&gt;&#123;I3，I5&#125; [sup=2/4，conf=2/3]</span><br><span class="line"></span><br><span class="line">上述候选关联规则满足minconf和minsup的要求，因此将它作为生成规则H2。</span><br><span class="line"></span><br><span class="line">最后，根据频繁项集L3生成以下两条关联规则：</span><br><span class="line"></span><br><span class="line">H1:&#123;I2，I5&#125;-&gt;&#123;I3&#125;</span><br><span class="line"></span><br><span class="line">H2:&#123;I2&#125;-&gt;&#123;I3，I5&#125;</span><br><span class="line"></span><br><span class="line">#### 8.8.4 实例分析</span><br><span class="line"></span><br><span class="line">下面以分析购买记录为例，分别就Apriori算法和FP-growth算法讲解频繁项集和关联规则。</span><br><span class="line"></span><br><span class="line">1.Apriori算法</span><br><span class="line"></span><br><span class="line">假设某超级市场的小吃和饮料信息如表8-1所示。</span><br><span class="line"></span><br><span class="line">表8-1 超级市场的小吃和饮料清单</span><br><span class="line"></span><br><span class="line">![](Image00334.jpg)</span><br><span class="line"></span><br><span class="line">表8-1的第1列表示食品编号ID，之后的列依次是口味、品种、价格、类别。</span><br><span class="line"></span><br><span class="line">商品购买记录如表8-2所示。</span><br><span class="line"></span><br><span class="line">表8-2 小吃和饮料的购买记录</span><br><span class="line"></span><br><span class="line">![](Image00335.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00336.jpg)</span><br><span class="line"></span><br><span class="line">表8-2中第一列为订单编号ID，以后各列依次为每个订单所点的食品ID。比如第一个订单的记录为“1，7，15，44，49”，表示订单1购买了Coffeeéclair、a Blackberry Tart、Bottled Water和Single Espresso。</span><br><span class="line"></span><br><span class="line">首先，下载Apriori程序包并解压。本书源码包中附带了apriori.py程序以及相关数据，也可以直接去github.com下载：&lt;https://github.com/BastinRobin/apriori-python&gt; 。本书源码包的下载地址见前言。</span><br><span class="line"></span><br><span class="line">然后，打开命令行，以最小支持度3%及最小置信度70%为标准，分析顾客的食品消费习惯：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python apriori.py data/1000/1000-out1.csv .03 .7 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    Dataset:  data/1000/1000-out1.cs   MinSup:   0.03   MinConf:   0.7
    ==================================================================
    1 :        Berry Tart (14),              Bottled Water (44)               support= 0.034
    2 :        Strawberry Cake (4),          Napoleon Cake (9)                support= 0.049
    3 :        Chocolate Cake (0),           Casino Cake (2)                  support= 0.04
    4 :        Raspberry Cookie (23),        Lemon Lemonade (40)              support= 0.031
    5 :        Marzipan Cookie (27),         Tuile Cookie (28)                support= 0.053
    6 :        Blueberry Tart (16),          Apricot Croissant (32)           support= 0.04
    7 :        Blueberry Tart (16),          Hot Coffee (45)                  support= 0.033
    8 :        Gongolais Cookie (22),        Truffle Cake (5)                 support= 0.058
    9 :        Cherry Tart (18),             Opera Cake (3)                   support= 0.041
    10 :       Cheese Croissant (33),       Orange Juice (42)                 support= 0.038
    11 :       Raspberry Cookie (23),       Lemon Cookie (24)                 support= 0.033
    12 :       Lemon Cookie (24),           Lemon Lemonade (40)               support= 0.031
    13 :       Apricot Croissant (32),      Hot Coffee (45),                Blueberry Tart (16)
    support= 0.032
    14 :       Apple Croissant (31),        Apple Tart (12),               Apple Danish (36),
                                             Cherry Soda (48)                 support= 0.031
            Skyline Itemsets:  14
    Rule 1 :    Apricot Croissant (32),      Hot Coffee (45)        --> Blue
                berry Tart (16)              [sup= 0.032                conf= 1.0 ]
    Rule 2 :    Apple Croissant (31),        Apple Tart (12),        Apple Danish (36)
                --> Cherry Soda (48)      [sup= 0.031                conf= 0.775 ]
    Rule 3 :    Apple Croissant (31),        Apple Danish (36),        Cherry Soda (48)
                --> Apple Tart (12)       [sup= 0.031                conf= 1.0 ]
    Rule 4 :    Apple Tart (12),             Apple Danish (36),        Cherry Soda (48)
                --> Apple Croissant (31)  [sup= 0.031                conf= 1.0 ] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序的上半部分为频繁项集，下半部分为关联规则。</span><br><span class="line"></span><br><span class="line">首先，观察这14个频繁项集，第1个频繁项集表明ID号为14的Berry Tart经常和ID号为44的Bottled Water被顾客一起购买（有0.034的支持度），而拥有最大支持度的是第8个频繁项集，即：Gongolais Cookie和Truffle Cake是顾客相对其他食品组合而言最喜欢一起购买的。</span><br><span class="line"></span><br><span class="line">然后，观察关联规则，第1条关联规则是点了Apricot Croissant和Hot Coffee的顾客一般会来上一个Blue berry Tart，这条关联规则的置信度为1.0，说明顾客常有该规则表明的消费习惯。而置信度最小（为77.5%）的是第2条规则，点Apple Croissant、Apple Tart及Apple Danish的顾客会选择Cherry Soda，这个消费习惯可能会成为这部分顾客的选择。</span><br><span class="line"></span><br><span class="line">2.FP-growth算法</span><br><span class="line"></span><br><span class="line">首先，下载FP-growth程序包并解压，本书源码包中提供有该程序包，也可以直接在github.com下载：&lt;https://github.com/enaeseth/python-fp-growth&gt; 。该算法包需要安装，安装命令如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python setup.py install <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，可直接运行程序fp_growth，该程序将自动分析其中的一个简单的数据集tsk.csv，生成频繁项集。</span><br><span class="line"></span><br><span class="line">tsk数据集中的数据如表8-3所示。</span><br><span class="line"></span><br><span class="line">表8-3 tsk数据集</span><br><span class="line"></span><br><span class="line">![](Image00337.jpg)</span><br><span class="line"></span><br><span class="line">运行程序的命令如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python -m fp_growth -s 4 examples/tsk.csv <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行完毕后，输出支持数support≥4的频繁项集，结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    {a} 8
    {c} 6
    {a, c} 4
    {b, c} 5
    {b} 7
    {a, b} 5
    {d} 5
    {a, d} 4 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">fp_growth程序的调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python -m fp_growth -s {minimum support} {path to CSV file} <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">其中，minimum support为最小支持度，path to CSV file为数据集的csv文件名。</span><br><span class="line"></span><br><span class="line">最后，以某网上商场的购买数据sales.csv（共1000条记录，本书附带的源码包中提供了该文件）为例，计算支持数（支持数量）≥200的频繁项集。sales.csv文件共有1000条记录，记载了每笔订单的商品ID号，内容如下所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    2,5,27,29
    15,27,31,33
    9,16,22,
    12,14,16,
    2,9,44,
    9,26,39,
    10,31,,
    1,47,49,
    12,14,16,
    12,14,16,
    1,19,25,49
    15,23,36,
    15,17,36,
    15,18,36,37
    1,46,48,49
    1,49,,
    12,14,16,
    9,22,26,
    12,14,15,16
    2,24,47,
    9,22,23,
    3,15,21,47
    21,32,41,48……

    .. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">编写程序8-23.py，调用fp_growth程序库函数，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #code:myhaspl@myhaspl.com
    #8-23.py
    from fp_growth import find_frequent_itemsets
    import csv
    myminsup=200#设定最小支持度


    if __name__ == '__main__':
        f = open("sales.csv")
        try:
            for itemset, support in find_frequent_itemsets(csv.reader(f), myminsup, True):
                print '{' + ','.join(itemset) + '} ' + str(support)
        finally:
            f.close() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序，输出支持数≥200的频繁项集，结果如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    {9} 224
    {12} 300
    {14} 291
    {12,14} 266
    {22} 203
    {16} 274
    {12,16} 250
    {14,16} 249
    {12,14,16} 248 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分析上面的频繁项集，&#123;12&#125;300在1项组合中的支持数最多，表示很多顾客都喜欢购买12号商品；&#123;12，14&#125;266在2项组合中的支持数最多，表示12和14号商品是较常见的2项购买组合，&#123;12，14，16&#125;248在3项组合中的支持数最多，表示12、14和16号商品是较常见的3项购买组合。</span><br><span class="line"></span><br><span class="line">程序8-23.py读取的sales.csv文件格式与在github.com下载的fp_growth算法包所使用的CSV文件格式有所不同，因此，需要修改一下源码包中的fp_growth.py，使之兼容sales.csv和tsk.csv这两种文件的格式。修改方式为：在fp_growth.py文件的find_frequent_itemsets函数中增加对空项目的判断，代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    for transaction in transactions:
        processed = []
        for item in transaction:
            if item.strip()!='':
                items[item] += 1
                processed.append(item)
        processed_transactions.append(processed) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">修改完毕后，需要重新安装fp_growth包，安装命令如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python setup.py install <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 8.9 自动分类</span><br><span class="line"></span><br><span class="line">自动分类是指由计算机系统按照被考察对象的内部或外部特征，根据一定的分类标准或分类参考（如类别的数量限制，同类对象的亲近程度等），将相近、相似或相同特征的对象聚合在一起或划分到不同种类的过程。</span><br><span class="line"></span><br><span class="line">#### 8.9.1 聚类算法</span><br><span class="line"></span><br><span class="line">聚类分析又称群分析，它是研究（样品或指标）分类问题的一种统计分析方法，同时也是数据挖掘的一个重要算法。它以相似性为基础，相比于不同聚类的模式，同一聚类中的模式之间具有更多的相似性，聚类所要求划分的类是未知的。聚类算法应用相当广泛，已经被广泛用于考古学、地质勘探调查、天气预报、作物品种分类、土壤分类、微生物分类、经济管理、社会经济统计等应用中。通俗地说，聚类就是把相似的对象通过静态分类的方法分成不同的组别或更多的子集，让在同一个子集中的成员对象都有一些相似的属性。</span><br><span class="line"></span><br><span class="line">1.系统聚类</span><br><span class="line"></span><br><span class="line">系统聚类法分析的对象是大量的样本，可合理地对所有样品进行分类，同时没有任何模式可供参考或依循，是在没有先验知识的情况下进行的。系统聚类法的原理是：同类事物具有很强的相似性，即同类事物之间的距离应该很小，可用距离统计量作为分类依据。具体算法思想如下：</span><br><span class="line"></span><br><span class="line">首先假定各个样本各自成一类，这时各类间的距离就是各样品之间的距离，将距离最近的两类合并成一个新的类；然后计算新类与其他类间的距离，并将距离最近的两类合并，如此每次缩小一类，直至所有的样本都成为一类为止；最后根据需要或根据给出的距离临界值（或阈值）确定分类数及最终要分的类。其中的关键是距离计算，可采用如下距离函数来计算：</span><br><span class="line"></span><br><span class="line">·最短距离法，定义类与类之间的距离为两类最近样本间的距离。</span><br><span class="line"></span><br><span class="line">·最长距离法，定义类与类之间的距离为两类最远样本间的距离。</span><br><span class="line"></span><br><span class="line">·中间距离法，定义类与类之间的距离为两类中间样本间的距离。</span><br><span class="line"></span><br><span class="line">·类平均法，定义类与类之间的距离为两类样本对之间的平均距离或两类样本对之间平均距离的平均值。</span><br><span class="line"></span><br><span class="line">·Mcquitty相似法，与类平均法类似，但在类平均法的基础上增加了加权方法。</span><br><span class="line"></span><br><span class="line">·重心法，定义类与类之间的距离为两类重心（平均值）之间的距离。</span><br><span class="line"></span><br><span class="line">·离差平方和法，如果分类正确，同类样本之间的离差平方和应较小，不同样本之间的离差平方和应较大。</span><br><span class="line"></span><br><span class="line">下面以某类型的13种商品的平均月销量为例，按销售数量分级聚类。销售数量如表8-4所示。</span><br><span class="line"></span><br><span class="line">表8-4 某类型商品的销售数量</span><br><span class="line"></span><br><span class="line">![](Image00338.jpg)</span><br><span class="line"></span><br><span class="line">可使用R语言的hclust函数进行聚类，R语言代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > buy<-c(500,600,200,12,38,59,482,295,260,279,410,552,677)> dim(buy)<-c(13,1)> buy
          [,1]
     [1,]  500
     [2,]  600
     [3,]  200
     [4,]   12
     [5,]   38
     [6,]   59
     [7,]  482
     [8,]  295
     [9,]  260
    [10,]  279
    [11,]  410
    [12,]  552
    [13,]  677
    > d<-dist(buy) #最短距离法> hclust(d,"single")->dshort
    #最长距离法


    > hclust(d,"complete")->dlong
    #中间距离法


    > hclust(d,"median")->dmedian
    #Mcquitty相似法


    > hclust(d,"mcquitty")->dmcquitty
    #类平均法


    > hclust(d,"average")->daverage
    #重心法


    > hclust(d,"centroid")->dcentroid
    #离差平方和法


    > hclust(d,"ward.D")->dward
    #画聚类树形图（谱系图）


    > plot(dshort,hang=-1)
    > plot(dlong,hang=-1)
    > plot(dmedian,hang=-1)
    > plot(dmcquitty,hang=-1)
    > plot(daverage,hang=-1)
    > plot(dcentroid,hang=-1)
    > plot(dward,hang=-1) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码的最后是用plot函数绘制所有聚类的谱系图，如图8-46至图8-52所示。</span><br><span class="line"></span><br><span class="line">![](Image00339.jpg)</span><br><span class="line"></span><br><span class="line">图8-46 最短距离法</span><br><span class="line"></span><br><span class="line">![](Image00340.jpg)</span><br><span class="line"></span><br><span class="line">图8-47 最长距离法</span><br><span class="line"></span><br><span class="line">分析图8-52所示的谱系图，以离差平方和法为例，观察聚类分析的结果：按这13种商品的平均月销量进行聚类，1、7、11号商品归为一组，而12、2、13号商品为一组，4、5、6号商品可归为一组，3、8、9、10号商品可归为一组。</span><br><span class="line"></span><br><span class="line">![](Image00341.jpg)</span><br><span class="line"></span><br><span class="line">图8-48 中间距离法</span><br><span class="line"></span><br><span class="line">![](Image00342.jpg)</span><br><span class="line"></span><br><span class="line">图8-49 Mcquitty相似法</span><br><span class="line"></span><br><span class="line">![](Image00343.jpg)</span><br><span class="line"></span><br><span class="line">图8-50 类平均法</span><br><span class="line"></span><br><span class="line">![](Image00344.jpg)</span><br><span class="line"></span><br><span class="line">图8-51 重心法</span><br><span class="line"></span><br><span class="line">再来看一个例子，假设某游戏公司打算针对某游戏服务器内1级到70级之间的玩家按对某些VIP特殊虚拟商品的消费能力进行聚类，分别有以下4个指标。</span><br><span class="line"></span><br><span class="line">·x1：外部时装</span><br><span class="line"></span><br><span class="line">·x2：防具、武器、饰品及相关加强配料</span><br><span class="line"></span><br><span class="line">·x3：宠物及相关加强配件</span><br><span class="line"></span><br><span class="line">·x4：交通工具</span><br><span class="line"></span><br><span class="line">然后，将每10级玩家设定为一个等级区（共有7级），随机抽取若干个该等级区内的典型玩家样本，计算在该等级区内平均每人每月消费的金额（游戏币）作为指标，生成以下数据样本，如表8-5所示。</span><br><span class="line"></span><br><span class="line">![](Image00345.jpg)</span><br><span class="line"></span><br><span class="line">图8-52 离差平方和法</span><br><span class="line"></span><br><span class="line">表8-5 VIP特殊虚拟商品的消费</span><br><span class="line"></span><br><span class="line">![](Image00346.jpg)</span><br><span class="line"></span><br><span class="line">下面用类平均法进行系统聚类分析，R语言代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > gamebuy<-data.frame( + x1<-c(10,20,50,700,180,200,1000), x2<-c(300,400,600,1200,1500,3000,4000), x3<-c(10,20,500,300,300,900,1200), x4<-c(20,20,82,320,1000,120,400)+ , row.names="c(" 1等级玩家" ","2等级玩家 ","3等级玩家 ","4等级玩家 ","5等级玩家 ","6等级玩家 ","7等级玩家 ") )> dist(scale(gamebuy))->d
    > hclust(d,"average")->daverage
    > plot(daverage,hang=-1) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从图8-53可以看出，在此类虚拟商品消费能力方面，1~50级是一大组，其中1~20级玩家消费能力类似，可归为一组；51~70级是另一大组，玩家以50级为一个明显的界限。</span><br><span class="line"></span><br><span class="line">![](Image00347.jpg)</span><br><span class="line"></span><br><span class="line">图8-53 类平均法</span><br><span class="line"></span><br><span class="line">2.K均值算法</span><br><span class="line"></span><br><span class="line">（1）K均值算法概述</span><br><span class="line"></span><br><span class="line">系统聚类法一次成型以后就不能再改变，计算量较大，而K均值（K-means）算法属于动态聚类法，具有计算量较小、占计算机内存较少和方法简单的优点。K均值算法是很典型的基于距离的聚类算法，采用距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。该算法认为簇是由距离较近的对象组成的，因此将获得紧凑且独立的簇作为最终目标。</span><br><span class="line"></span><br><span class="line">K均值算法会将n个对象根据它们的属性分为k个分割，k&lt;n，试图找到数据中自然聚类的中心，使各个样本与所在类均值的误差平方和达到最小，并以此为标准评价K均值算法最后的聚类效果。k个初始类聚类中心点的选取对聚类结果具有较大的影响，因为该算法的第一步是随机地选取任意k个对象作为初始聚类的中心，初始地代表一个簇。该算法在每次迭代中都会对数据集中剩余的每个对象根据其与各个簇中心的距离将其重新赋给最近的簇。当考察完所有数据对象后，一次迭代运算完成，新的聚类中心被计算出来。如果在一次迭代前后，J的值没有发生变化，说明算法已经收敛。</span><br><span class="line"></span><br><span class="line">K均值算法的具体过程如下：</span><br><span class="line"></span><br><span class="line">1）从n个数据对象中任意选择k个对象作为初始聚类的中心。</span><br><span class="line"></span><br><span class="line">2）根据每个聚类对象的均值（中心对象），计算每个对象与这些中心对象的距离；并根据最小距离重新对相应的对象进行划分。</span><br><span class="line"></span><br><span class="line">3）重新计算每个（有变化）聚类的均值（中心对象）。</span><br><span class="line"></span><br><span class="line">4）循环步骤2和步骤3直到每个聚类不再发生变化为止。</span><br><span class="line"></span><br><span class="line">K均值算法接受输入量k；然后将n个数据对象划分为k个聚类，以便使得所获得的聚类满足：同一聚类中对象的相似度较高；而不同聚类中对象的相似度较小。聚类相似度是利用各聚类中对象的均值获得一个中心对象来进行计算的。</span><br><span class="line"></span><br><span class="line">（2）R语言的kmeans聚类</span><br><span class="line"></span><br><span class="line">下面针对表8-5所示的虚拟商品数据，调用R语言的kmeans函数进行聚类：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > kmeans(scale(gamebuy),3)->mykmean
    > mykmean
    K-means clustering with 3 clusters of sizes 3, 2, 2
    Cluster means:
      x1....c.10..20..50..700..180..200..1000.
    1                                        -0.7283260
    2                                        0.7529316
    3                                        0.3395574
      x2....c.300..400..600..1200..1500..3000..4000.
    1                                        -0.8042763
    2                                        1.3628949
    3                                        -0.1564805
      x3....c.10..20..500..300..300..900..1200.
    1                                        -0.6393938
    2                                        1.3215563
    3                                        -0.3624657
      x4....c.20..20..82..320..1000..120..400.
    1                                        -0.68490386
    2                                        -0.05798272
    3                                        1.08533851
    Clustering vector:
    1等级玩家

     2等级玩家

     3等级玩家

     4等级玩家

     5等级玩家

     6等级玩家

     7等级玩家

      1        1          1         3                3        2         2
    Within cluster sum of squares by cluster:
    [1] 0.8408947 2.9328150 2.8138040
     (between_SS / total_SS =  72.6 %)
    Available components:
    [1]        "cluster"             "centers"          "totss"       "withinss"
    [5]        "tot.withinss"        "betweenss"        "size"        "iter"
    [9]        "ifault"
    > sort(mykmean$cluster)
    1等级玩家

     2等级玩家

     3等级玩家

     6等级玩家

     7等级玩家

     4等级玩家

     5等级玩家

       1        1          1         2                2        3         3 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从以上分析结果可以看出，1、2、3等级（1~30级）玩家是一组，4、5等级（31~50级）玩家是一组，6、7等级（51~70级）玩家是一组。</span><br><span class="line"></span><br><span class="line">（3）Python库milk的kmeans聚类</span><br><span class="line"></span><br><span class="line">再来看一个例子，某网站对用户随机抽样，以抽取用户每周登录的次数作为用户对本网站热忱程度的分类标准，共随机抽取了6位用户，登录次数分别为：12、24、67、90、34、120，在此使用Python来完成这个任务，通过调用milk库函数实现K-means分类，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #样本矩阵声明


    >>myx= np.array([12,24,67,90,34,120])
    >>myx.shape=(6,1)
    #建立

    k-means分类器，第二个参数

    3表示分成

    3类。


    >>learner =milk.kmeans(myx,3)
    >>learner
    (array([1, 1, 2, 0, 1, 0]), array([[ 105.     ], [  23.33333333], [  67.     ]])) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后一行程序返回了两个结果，第1个结果是分类完成后样本所属的类别，第2个结果是每个类别的重心，观察结果可发现，第1、2、5号用户属于一类，重心为105；而3号用户属于第2类，重心为23.33333333；4、6号用户属于第3类，重心为67。</span><br><span class="line"></span><br><span class="line">milk是一种可供Python调用的机器学习工具包。在Linux环境中，需要首先下载milk，网址如下：</span><br><span class="line"></span><br><span class="line">&lt;https://pypi.python.org/pypi/milk/&gt;  </span><br><span class="line"></span><br><span class="line">下载完毕后，解压并进行安装，安装命令如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    python setup.py install <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在Windows环境中，可直接下载安装包进行安装，下载时请选择与Python版本对应的文件。下载地址如下：</span><br><span class="line"></span><br><span class="line">&lt;http://www.lfd.uci.edu/~gohlke/pythonlibs/#milk&gt;  </span><br><span class="line"></span><br><span class="line">此外，有关milk的相关文档和资料可在&lt;http://luispedro.org/software/milk&gt; 中找到。</span><br><span class="line"></span><br><span class="line">（4）Python库mlpy的kmeans聚类</span><br><span class="line"></span><br><span class="line">以下代码（程序8-24.py）调用mlpy库的kmeans函数对若干个随机数进行聚类，并生成效果图（如图8-54所示）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #8-24.py
    import numpy as np
    import matplotlib.pyplot as plt
    import mlpy
    np.random.seed(0)
    mean1, cov1, n1 = [1, 5], [[1,1],[1,2]], 200            # 200 points, mean=(1,5)
    x1 = np.random.multivariate_normal(mean1, cov1, n1)
    mean2, cov2, n2 = [2.5, 2.5], [[1,0],[0,1]], 300        # 300 points, mean=(2.5,2.5)
    x2 = np.random.multivariate_normal(mean2, cov2, n2)
    mean3, cov3, n3 = [5, 8], [[0.5,0],[0,0.5]], 200        # 200 points, mean=(5,8)
    x3 = np.random.multivariate_normal(mean3, cov3, n3)
    x = np.concatenate((x1, x2, x3), axis=0)                # concatenate the samples
    cls, means, steps = mlpy.kmeans(x, k=3, plus=True)
    fig = plt.figure(1)
    plot1 = plt.scatter(x[:,0], x[:,1], c=cls, alpha=0.75)
    plot2 = plt.scatter(means[:,0], means[:,1], c=np.unique(cls), s=128, marker='d')                                             # plot the means
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00348.jpg)</span><br><span class="line"></span><br><span class="line">图8-54 kmeans聚类效果图</span><br><span class="line"></span><br><span class="line">#### 8.9.2 决策树</span><br><span class="line"></span><br><span class="line">1.决策树概述</span><br><span class="line"></span><br><span class="line">决策树是一个预测模型，代表了对象属性与对象值之间的一种映射关系。树中的每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，每个叶节点则对应从根节点到该叶节点的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，则可以建立独立的决策树以处理不同的输出。在数据挖掘中决策树是一种经常要用到的技术，可用于分析数据，同样也可用来预测。图8-55展示了一个决策树。</span><br><span class="line"></span><br><span class="line">![](Image00349.jpg)</span><br><span class="line"></span><br><span class="line">图8-55 决策树</span><br><span class="line"></span><br><span class="line">通常来说，决策树包含以下三种类型的节点。</span><br><span class="line"></span><br><span class="line">·决策节点：通常用矩形框来表示。</span><br><span class="line"></span><br><span class="line">·机会节点：通常用圆圈来表示。</span><br><span class="line"></span><br><span class="line">·终节点：通常用三角形来表示。</span><br><span class="line"></span><br><span class="line">剪枝是决策树停止分支的方法之一，剪枝又分预先剪枝和后剪枝两种。预先剪枝是在树的生长过程中设定一个指标，当达到该指标时就停止生长，这样做容易产生“视界局限”，也就是说一旦停止分支，使得节点N成为叶节点，就断绝了其后继节点进行“好”的分支操作的任何可能性。不严格地说，这些已停止的分支会误导学习算法，导致产生的树的不纯度降差最大的地方过分靠近根节点。后剪枝中，树首先要充分生长，直到叶节点都有最小的不纯度值为止，这样可以避免“视界局限”的问题。然后对所有相邻的成对叶节点考虑是否消去它们，如果消去能引起令人满意的不纯度增长，那么执行消去，并令它们的公共父节点成为新的叶节点。</span><br><span class="line"></span><br><span class="line">决策树法的决策算法如下：</span><br><span class="line"></span><br><span class="line">1）绘制树状图，根据已知条件排列出各个方案和每一方案的各种自然状态。</span><br><span class="line"></span><br><span class="line">2）将各状态的概率及损益值标于概率枝上。</span><br><span class="line"></span><br><span class="line">3）计算各个方案的期望值并将其标于与该方案对应的状态节点上。</span><br><span class="line"></span><br><span class="line">4）进行剪枝，比较各个方案的期望值，并标于方案枝上，将最后所剩的期望值小的（即劣等方案剪掉）方案作为最佳方案。</span><br><span class="line"></span><br><span class="line">2.决策树算法实例</span><br><span class="line"></span><br><span class="line">下面以实例来说明决策树算法，首先从最简单的1个属性的数据开始。假设某游戏公司在其官网的某游戏论坛中随机抽取了6位用户的资料为样本，以玩家平均每月所发游戏截图的数量为特征，进行决策树训练，训练好的决策树模型可将其他玩家分为热心玩家和非热心玩家。这6位用户平均每月所发游戏截图的数量为：12、24、67、90、34、120。</span><br><span class="line"></span><br><span class="line">首先，训练决策树，Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>features = np.array([12,24,67,90,34,120])                #样本矩阵数据建立


    >>features.shape=(6,1)
    >>labels=np.array([False,False,False,True,False,True])     #样本标签

    ,False为非热心玩家，

    True为热心玩家。


    >>learner=milk.supervised.tree_learner()                   #建立决策树分类器


    >>model=learner.train(features, labels)                    #样本数据训练，返回分类器模型

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，对其他8位玩家的数据进行分类，Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>testx=np.array([10,20,40,90,33,89,199,200])              #建立测试样本数据，即测试玩家所发游戏截图的数量


    >>testx.shape=(8,1)
    >>> model.apply([50])                                   #应用刚才建立的决策树分类模型，对某个测试样本进行分类


    False
    >> model.apply_many(testx)                              #应用刚才建立的决策树分类模型，对成批测试样本进行分类


    [False, False, False, True, False, False, True, True] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察最后两行程序代码的返回结果，倒数第二行的程序代码对50进行了测试，通过决策树模型判别，发游戏截图50次的用户为非热心玩家，倒数第一行程序代码对一批测试样本进行判断，其中发游戏截图为90、199、200次的玩家值返回为True，表示这些用户为热心玩家。</span><br><span class="line"></span><br><span class="line">接下来，看一个较复杂的例子。假设某公司针对其赊账客户进行分类，通过随机抽取7位赊账客户进行评估，之后将其分成可容忍客户和非容忍客户，并以这些客户为样本数据，尝试对更多的赊账客户进行决策树分类。7位赊账客户的数据如表8-6所示。</span><br><span class="line"></span><br><span class="line">表8-6 赊账客户的数据</span><br><span class="line"></span><br><span class="line">![](Image00350.jpg)</span><br><span class="line"></span><br><span class="line">应用Python对以上数据进行决策树算法分类，代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >> 
    x=np.arr ay([[5600,58000,1300,2900,800,35000,9800],[4,6,1,3,2,4,2],[50,120,8,12,
    5,190,10]])#建立样本数据


    >> features=x.T
    >> features
    array([[ 5600,        4,        50],
           [58000,        6,        120],
           [ 1300,        1,        8],
           [ 2900,        3,        12],
           [  800,        2,        5],
           [35000,        4,        190],
           [ 9800,        2,        10]])
    #建立决策树模型


    >> learner=milk.supervised.tree_learner()
    >> model=learner.train(features, labels)
    #对到目前为止仍欠款

    1200，欠款笔数为

    3，到目前为止累计拖欠

    13天的客户进行判断，确定其是否属于可容忍客户，经决策树模型分析，可以容忍。


    >> model.apply([1200,3,13])
    True
    #对到目前为止仍欠款

    12000，欠款笔数为

    13，到目前为止累计拖欠

    103天的客户进行判断，确定其是否属于可容忍客户，经决策树模型分析，不能容忍。


    >> model.apply([12000,13,103])
    False <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 8.9.3 AdaBoost</span><br><span class="line"></span><br><span class="line">AdaBoost分类算法是一种迭代分类算法，它会在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率为止。每一个训练样本都被赋予一个权重，表明它被某个分类器选入训练集的概率。如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它被选中的概率就会被降低；相反，如果某个样本点没有被准确地分类，那么它的权重就得到了提高。通过这种方式，AdaBoost方法能聚焦于那些较难分（更富信息）的样本上。该算法的核心思想如下：</span><br><span class="line"></span><br><span class="line">最初令每个样本的权重都相等，对于第k次迭代操作，我们就根据这些权重来选取样本点，进而训练分类器Ck</span><br><span class="line">；然后就根据这个分类器，来提高被它分错的样本的权重，并降低被正确分类的样本的权重；最后，更新过权重的样本集被用于训练下一个分类器Ck+1 。整个训练过程如此迭代地进行下去。</span><br><span class="line"></span><br><span class="line">AdaBoost算法的具体过程如下：</span><br><span class="line"></span><br><span class="line">1）先通过对N个训练样本的学习得到第一个弱分类器。</span><br><span class="line"></span><br><span class="line">2）将分错的样本和其他的新数据一起构成一个新的N个的训练样本，通过对这个样本的学习得到第二个弱分类器。</span><br><span class="line"></span><br><span class="line">3）将步骤1和2中分错了的样本加上其他的新样本构成另一个新的N个的训练样本，通过对这个样本的学习得到第三个弱分类器。</span><br><span class="line"></span><br><span class="line">4）如此迭代，最终经过提升得到强分类器。</span><br><span class="line"></span><br><span class="line">继续以上一节的赊账客户为例进行说明，假设该公司随机抽取7位赊账客户进行评估，之后按信用等级对其进行分类（共分为3级，1级信用等级最差，3级信用等级最好）并以这些客户为样本数据，尝试对更多的赊账客户进行AdaBoost算法分类。7位赊账客户的数据如表8-7所示。</span><br><span class="line"></span><br><span class="line">表8-7 赊账客户的数据</span><br><span class="line"></span><br><span class="line">![](Image00351.jpg)</span><br><span class="line"></span><br><span class="line">首先，建立分类器，Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #导入相关库


    >> import milk.supervised.tree
    >> import milk.supervised.adaboost
    >> import milk.supervised.multi
    #建立分类器


    >> weak = milk.supervised.tree.stump_learner()
    >> learner = milk.supervised.adaboost.boost_learner(weak)
    >> learner = milk.supervised.multi.one_against_one(learner)
    #样本数据及样本分类


    >> 
    x=np.array([[5600,58000,1300,2900,800,35000,9800],[4,6,1,3,2,4,2],[50,120,8,
    12,5,190,10]])
    >> features=x.T
    >> labels=np.array([2,1,3,2,3,1,2])
    >> learner.train(features,labels) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，对测试样本进行预测，返回信用等级，测试数据的第一个元素是到目前为止仍欠款，第二个元素是欠款笔数，第三个元素是到目前为止累计拖欠天数。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> model.apply([1000,3,10])
    3
    >>> model.apply([10000,3,10])
    2
    >>> model.apply([10000,5,10])
    2
    >>> model.apply([10000,5,100])
    2
    >>> model.apply([50000,5,100])
    1
    >>> model.apply([50000,5,10])
    1
    >>> model.apply([5000,15,100])
    2
    >>> model.apply([5000,15,100])
    2
    >>> model.apply([28000,15,100])
    2
    >>> model.apply([38000,15,10])
    1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分析以上结果，以model.apply([38000，15，10])为例，返回1表示目前为止仍欠款38000，欠款笔数15次，目前为止累计拖欠10天的信用等级为1级，信用等级最差。</span><br><span class="line"></span><br><span class="line">#### 8.9.4 竞争型神经网络</span><br><span class="line"></span><br><span class="line">神经生物学的研究结果表明：生物视网膜有许多特定的细胞，对特定的图形输入模式比较敏感，并使得大脑皮层中的特定细胞产生较大的兴奋，而与其相邻的神经细胞的兴奋程度则被抑制。竞争型神经网络对此进行了模拟，对于某一个输入模式，通过竞争在输出层中只激活一个相应的输出神经元；若有许多输入模式，则在输出层中激活许多个神经元，从而形成一个反映输入数据的“特征图形”，可实现对输入模式自动进行分类。</span><br><span class="line"></span><br><span class="line">竞争型神经网络一般是由输入层（模拟视网膜神经元）和竞争层（模拟大脑皮层神经元，也叫输出层）构成的两层网络，两层中的各神经元之间实现双向全连接，而且网络中没有隐含层，有时竞争层各神经元之间还存在横向连接，对于某一输入模式，在竞争型神经网络中，和该模式最相近的学习输入模式相对应的竞争层神经元将有最大的输出值，即以竞争层获胜神经元来表示分类结果。竞争型神经网络结构如图8-56所示。</span><br><span class="line"></span><br><span class="line">![](Image00352.jpg)</span><br><span class="line"></span><br><span class="line">图8-56 竞争型神经网络</span><br><span class="line"></span><br><span class="line">程序8-25.py演示了竞争型神经网络：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #8-25.py
    import numpy as np
    import neurolab as nl
    import numpy.random as rand
    #每一类的中心


    centr = np.array([[0.2, 0.2], [0.4, 0.4], [0.7, 0.3]])
    #以每类的中心为基础，产生随机点。


    rand_norm = 0.05 * rand.randn(100, 3, 2)
    inp = np.array([centr + r for r in rand_norm])
    inp.shape = (100 * 3, 2)
    rand.shuffle(inp) 
    # Create net with 2 inputs and 3 neurons
    net = nl.net.newc([[0.0, 1.0],[0.0, 1.0]], 3)
    #训练该神经网络


    # train with rule: Conscience Winner Take All algoritm (CWTA)
    error = net.train(inp, epochs=200, show=20)
    # Plot results:
    import pylab as pl
    pl.title('Classification Problem')
    pl.subplot(211)
    pl.plot(error)
    pl.xlabel('Epoch number')
    pl.ylabel('error (default MAE)')
    w = net.layers[0].np['w']
    pl.subplot(212)
    pl.plot(inp[:,0], inp[:,1], '.', \
            centr[:,0], centr[:, 1] , 'yv', \
            w[:,0], w[:,1], 'p')
    pl.legend(['train samples', 'real centers', 'train centers'],loc=2)
    pl.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序8-25.py创建了3个神经元，接受2个输入，输出为3类。运行程序8-25.py，输出结果如图8-57所示。</span><br><span class="line"></span><br><span class="line">![](Image00353.jpg)</span><br><span class="line"></span><br><span class="line">图8-57 竞争型神经网络分类</span><br><span class="line"></span><br><span class="line">观察图8-57，程序将训练用样本点聚集为3个类别，其中，train samples表示训练样本，real centers表示真实中心，train centers表示训练中心。</span><br><span class="line"></span><br><span class="line">下面在程序8-25.py的基础上加入测试用的平均随机分布点，检查其分类效果，如程序8-26.py所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #8-26.py
    import numpy as np
    import neurolab as nl
    import numpy.random as rand
    #每一类的中心


    centr = np.array([[0.2, 0.2], [0.4, 0.4], [0.7, 0.8]])
    #以每类的中心为基础，产生随机点。


    rand_norm = 0.05 * rand.randn(100, 3, 2)
    inp = np.array([centr + r for r in rand_norm])
    inp.shape = (100 * 3, 2)
    rand.shuffle(inp) 
    # Create net with 2 inputs and 3 neurons
    net = nl.net.newc([[0.0, 1.0],[0.0, 1.0]], 3)
    #训练该神经网络


    # train with rule: Conscience Winner Take All algoritm (CWTA)
    error = net.train(inp, epochs=200, show=20)
    # Plot results:
    import pylab as pl
    pl.title('Classification Problem')
    pl.subplot(211)
    pl.plot(error)
    pl.xlabel('Epoch number')
    pl.ylabel('error (default MAE)')
    w = net.layers[0].np['w']
    #生成

    100个

    [0,1)之间的平均分布的随机数


    rand_array=np.random.random((100,2))
    result=net.sim(rand_array)
    plotshape=[]
    colorindex=['r','y','g']
    for myres in result:
        index=0
        for tmp in myres:
            if tmp==1:
                plotshape.append(colorindex[index]+'p')
                break 
            index+=1
    pl.subplot(212)
    pl.plot(inp[:,0], inp[:,1], '.')
    for i in range(len(result)-1):
        pl.plot(rand_array[i,0],rand_array[i, 1],plotshape[i])
    pl.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序8-26.py生成了100个［0，1）之间的平均分布的随机数，然后由训练完成的神经网络进行分类。运行程序8-26.py，效果如图8-58所示，训练样本点为蓝色圆形，测试样本点为多边形，测试样本点的不同色彩代表了被分为不同的类。此外，图8-58上方的图表示误差，从误差曲线来看，神经网络训练过程顺利，呈平滑下降趋势。</span><br><span class="line"></span><br><span class="line">![](Image00354.jpg)</span><br><span class="line"></span><br><span class="line">图8-58 测试点聚类</span><br><span class="line"></span><br><span class="line">表8-8 网站的访问量情况</span><br><span class="line"></span><br><span class="line">![](Image00355.jpg)</span><br><span class="line"></span><br><span class="line">设某网站的访问量比较稳定，无突出变化，以某周所有地区对该网站的访问情况为例，对来访地区进行聚类，数据如表8-8所示（PV为总访问量，UV为总访问客数，area为地区编号）。</span><br><span class="line"></span><br><span class="line">编写程序8-27.py，实现对表8-8所示的来访地区的聚类，此外，再增加100个随机点，检测聚类效果。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #8-27.py
    import numpy as np
    import neurolab as nl
    #读取数据


    import csv
    datacluster=[]
    file = open("access_area.csv",'r')
    file.readline() 
    reader = csv.reader(file)
    for datarow in reader:
        datacluster.append([float(datarow[1]),float(datarow[2])])
    accessdata=np.array(datacluster)
    # Create net with 2 inputs and 7 neurons，分为

    7类


    net = nl.net.newc([[0.0, max(accessdata[:,0])],[0.0, max(accessdata[:,1])]],7)
    #训练该神经网络


    # train with rule: Conscience Winner Take All algoritm (CWTA)
    error = net.train(accessdata, epochs=200, show=20)
    # Plot results:
    import pylab as pl
    pl.title('Classification Problem')
    pl.subplot(211)
    pl.plot(error)
    pl.xlabel('Epoch number')
    pl.ylabel('error (default MAE)')
    w = net.layers[0].np['w']
    #生成

    100个平均分布的随机数


    rand_array=np.random.random((100,2))*np.array([max(accessdata[:,0]),max(accessdata[:,1])])
    result=net.sim(rand_array)
    plotshape=[]
    colorindex=['r','y','g','c ','m','k','b']
    for myres in result:
        index=0
        for tmp in myres:
            if tmp==1:
                plotshape.append(colorindex[index]+'p')
                break 
            index+=1
    w = net.layers[0].np['w']
    pl.subplot(212)
    pl.xlabel('PV')
    pl.ylabel('UV')
    pl.plot(accessdata[:,0], accessdata[:,1], '.')
    for i in range(len(result)-1):
        pl.plot(rand_array[i,0],rand_array[i, 1],plotshape[i])
    for i in xrange(7):    
        pl.plot(w[i,0], w[i,1],colorindex[i]+'v')
    pl.show()
    Epoch: 20; Error: 786.921489826;
    Epoch: 40; Error: 784.125494497;
    Epoch: 60; Error: 783.165674735;
    Epoch: 80; Error: 782.677433443;
    Epoch: 100; Error: 782.381170541;
    Epoch: 120; Error: 782.182073001;
    Epoch: 140; Error: 782.039000206;
    Epoch: 160; Error: 781.931187336;
    Epoch: 180; Error: 781.84701229;
    Epoch: 200; Error: 781.77945951;
    The maximum number of train epochs is reached
    >>> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序8-27.py，将样本聚成7类，同时将测试点较好地完成分类。效果如图8-59所示。</span><br><span class="line"></span><br><span class="line">![](Image00356.jpg)</span><br><span class="line"></span><br><span class="line">图8-59 地区聚类</span><br><span class="line"></span><br><span class="line">观察图8-59，不同色彩的多边形代表了测试点被分成了7类，此外，程序还绘制了样本点及倒三角代表的类别中心点，总体来看，效果还不错。</span><br><span class="line"></span><br><span class="line">#### 8.9.5 Hamming神经网络</span><br><span class="line"></span><br><span class="line">图8-60是最典型的Hamming神经网络，第一层上面的方框是输入数据，每个输入数据都会与神经元相连。每个神经元的一组连接权值存储的是一个识别对象的模板，神经元的作用就是计算输入数据与其连接权值所存模板的匹配距离，匹配程度由神经元输出，匹配度越高，输出值越大。</span><br><span class="line"></span><br><span class="line">![](Image00357.jpg)</span><br><span class="line"></span><br><span class="line">图8-60 Hamming神经网络</span><br><span class="line"></span><br><span class="line">假设销售某虚拟物品时，向客户展示了一些相关的畅销虚拟物品，以吸引客户点击购买，以表8-9所示的数据为例，将消费兴趣类似的客户分类。</span><br><span class="line"></span><br><span class="line">表8-9 点击数据</span><br><span class="line"></span><br><span class="line">![](Image00358.jpg)</span><br><span class="line"></span><br><span class="line">表8-9中，A1表示A类虚拟物品的1号商品，B2表示B类虚拟物品的2号商品，以此类推。每一行代表一类，每列数据代表该类客户浏览的虚拟商品，如果该虚拟商品点击量较多，则为1，否则为-1。</span><br><span class="line"></span><br><span class="line">编写Python代码进行聚类（sales4.csv在本书源代码包中），如程序8-28.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #code:myhaspl@myhaspl.com
    #8-28.py
    import numpy as np
    import neurolab as nl
    #读取数据


    import csv
    datatarget=[]
    file = open("sales4.csv",'r')
    file.readline() 
    reader = csv.reader(file)
    ii=0
    for datarow in reader:
        datatarget.append([])
        for data in datarow:
            datatarget[ii].append(int(data))
        ii=ii+1
    datatarget=np.array(datatarget)
    input = [[1,1,1,1,-1,1,1,-1,-1,-1,-1,-1],
            [1,-1,1,-1,1,-1,1,1,-1,-1,-1,1],
            [1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1]]
    # Create and train network
    net = nl.net.newhem(datatarget)
    output = net.sim(datatarget)
    print u"样本数据，结果必须为

    [0, 1, 2, 3, 4]" 
    print np.argmax(output, axis=0) 
    output = net.sim(input)
    print u"测试数据的神经网络最终输出

    " 
    print output  
    print u"测试数据的分类结果如下：

    "
    ii=0 
    for test in output:
        print  input[ii],
        print  u"分类如下

    :"
        print np.argmax(test)
        ii+=1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序8-28.py首先读取样本sales4.csv文件；然后将样本数据送入Hamming神经网络中进行训练，匹配程度由神经元输出，匹配度越高，输出值越大，通常来说最大值对应的位置即最终分类；最后，用测试数据进行验证。执行程序8-28.py，结果如下。</span><br><span class="line"></span><br><span class="line">样本数据的结果必须为［0，1，2，3，4］。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [0 1 2 3 4] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">测试数据神经网络的最终输出如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [[ 0.52608        0.        0.        0.        0.        ]
     [ 0.             0.        0.        0.464     0.        ]
     [ 0.             0.        0.        0.        0.4992    ]] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">来看看测试数据的分类结果。</span><br><span class="line"></span><br><span class="line">［1，1，1，1，-1，1，1，-1，-1，-1，-1，-1］分类如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    0 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">［1，-1，1，-1，1，-1，1，1，-1，-1，-1，1］分类如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    3 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">［1，1，-1，-1，1，-1，-1，-1，-1，1，1，-1］分类如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    4 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述结果，三组测试数据均分类准确，效果不错。</span><br><span class="line"></span><br><span class="line">### 8.10 小结</span><br><span class="line"></span><br><span class="line">机器学习算法是机器学习的灵魂。本章首先介绍神经网络，由浅入深地讲述了基于Rosenblatt感知器的线性神经网络、反向传播算法及基于多层感知器的非线性神经网络；然后介绍了平均值与方差、贝叶斯分类等统计算法；接着阐述了相似度算法的两个常用方法：欧氏距离和余弦相似度；再然后讲解了SVM、回归算法、PCA降维等机器学习算法；最后讲解了关联规则算法、常用聚类算法、决策树算法、AdaBoost算法、竞争型神经网络、Hamming神经网络等算法知识。</span><br><span class="line"></span><br><span class="line">在讲述算法的同时，笔者理论联系实际，讲解了如何用Python及相关库、R语言来实践机器学习算法。此外，为帮助读者更好地理解算法，在解说每一节的算法之前，均介绍了算法涉及的数学基础知识。</span><br><span class="line"></span><br><span class="line">每一种机器学习算法不一定能完成所有机器学习的任务。因此，应在实践中应用这些算法，观察算法的实际效果，以求选择最合适的算法。</span><br><span class="line"></span><br><span class="line">此外，本章介绍的机器学习相关库的官方文档的网址如下：</span><br><span class="line"></span><br><span class="line">·mlpy：&lt;http://sourceforge.net/projects/mlpy/files/mlpy%203.5.0/mlpy.pdf/download&gt;</span><br><span class="line"></span><br><span class="line">·neurolab：&lt;https://pythonhosted.org/neurolab/index.html&gt;</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">（1）编写Python代码实现一个Rosenblatt感知器，随机产生一组X和Y的样本值，这些样本值分别属于以下两类函数：</span><br><span class="line"></span><br><span class="line">5x-3=y为第1类</span><br><span class="line"></span><br><span class="line">2x+6=y为第2类</span><br><span class="line"></span><br><span class="line">然后用随机生成的测试数据进行分类，并绘制出分类线。</span><br><span class="line"></span><br><span class="line">（2）编写Python代码实现多层感知器，随机产生一组X和Y的样本值，用随机数据对训练后的网络进行测试绘制散点图和误差曲线，计算X和Y的方差和平均值，分析其分布趋势。</span><br><span class="line"></span><br><span class="line">（3）编写Python代码实现多层感知器，绘制样本散点图和误差曲线。随机产生一组X样本值，并将Y的样本值函数定义为：</span><br><span class="line"></span><br><span class="line">Y=sin(x)*0.7</span><br><span class="line"></span><br><span class="line">（4）编写Python代码实现SVM算法，随机产生一组X和Y的样本值，这些样本值分别属于以下两类函数：</span><br><span class="line"></span><br><span class="line">y=x^a+b (a&lt;=3，abs(b)&lt;20)为第一类</span><br><span class="line"></span><br><span class="line">y=x^a+b (a&gt;=5，abs(b)&lt;10)为第二类</span><br><span class="line"></span><br><span class="line">然后用随机生成的测试数据进行分类，并绘制出散点图。</span><br><span class="line"></span><br><span class="line">（5）选择一组数据，用Python实现下面的回归方程：</span><br><span class="line"></span><br><span class="line">y=b1*x2+b2*x12 +b3*x1*x2</span><br><span class="line"></span><br><span class="line">（6）下载本书的sales4.csv文件，加入更多类别的样本数据，并生成一些随机测试数据，进行Hamming神经网络分类，并测试分类效果。</span><br><span class="line"></span><br><span class="line">（7）生成0~9共9个数字的印刷体样本，并生成一些测试样本数据，进行Hamming神经网络分类，检查分类效果。</span><br><span class="line"></span><br><span class="line">提示：可将数字的像素点组成矩阵，然后展开成特征向量。比如：8可表示为以下由像素点组成的矩阵（1表示有像素点，-1表示无像素点）：</span><br><span class="line"></span><br><span class="line">![](Image00359.jpg)</span><br><span class="line"></span><br><span class="line">将8的像素点矩阵由左到右、由上到下依次展开，生成特征值如下：［1，1，1，1，-1，1，1，1，1，1，-1，1，1，1，1］。</span><br><span class="line"></span><br><span class="line">（8）下表是某些顾客对A~D四类商品的季度消费金额，对这些顾客运用本章讲解的各种聚类方法进行聚类。</span><br><span class="line"></span><br><span class="line">![](Image00360.jpg)</span><br><span class="line"></span><br><span class="line">## 第9章 数据拟合案例</span><br><span class="line"></span><br><span class="line">在科学和工程问题上可通过采样、实验等方法获得若干离散的数据，分析这些数据能得到一个连续的函数（曲线）或者更加密集的离散方程，且这个方程与已知数据相吻合，这个过程叫做数据拟合。数据拟合实质是针对一组未知规律的数据建立数学方程，通过数学方法建立一个函数映射方式。</span><br><span class="line"></span><br><span class="line">前面几章涉及了很多回归分析算法，都是先根据样本建立模型，然后分析回归效果，最终目的是弄清楚两个或两个以上变量之间的因果关系，因此，这些算法都是对数据的拟合。</span><br><span class="line"></span><br><span class="line">### 9.1 数据拟合</span><br><span class="line"></span><br><span class="line">分析一个自变量和一个因变量之间的关系，可通过图像分析法与神经网络拟合法建立数学模型进行映射。</span><br><span class="line"></span><br><span class="line">#### 9.1.1 图像分析法</span><br><span class="line"></span><br><span class="line">顾名思义，图像分析法就是将样本数据中的自变量X和因变量Y的值映射为平面直角坐标系中的点，其X轴坐标和Y轴坐标的值分别为自变量和因变量的值，这些点共同形成一个散点图。通过分析散点图中这些点的几何分布趋势，对照常见函数图像，选择最接近的、最适合的数学函数作为拟合方程。</span><br><span class="line"></span><br><span class="line">既然是图像分析法，那么就需要对常见的数学函数及其图像有一个直观的认识。因此，这里先介绍常见的数学函数。</span><br><span class="line"></span><br><span class="line">1.幂函数</span><br><span class="line"></span><br><span class="line">幂函数是形如f(x)=xa 的函数，函数以底数为自变量，幂为因变量，指数a为常量，a可以是自然数、有理数、任意实数或复数。下面是几个经典的幂函数。</span><br><span class="line"></span><br><span class="line">·指数为1、2、1/2的幂函数，它们分别为y=x、y=x2 、y=x1/2 ，图像如图9-1所示。</span><br><span class="line"></span><br><span class="line">·指数为3、1/3的幂函数，它们分别为y=x3 、y=x1/3 ，图像如图9-2所示。</span><br><span class="line"></span><br><span class="line">![](Image00361.jpg)</span><br><span class="line"></span><br><span class="line">图9-1 指数为1、2、1/2的幂函数图像</span><br><span class="line"></span><br><span class="line">![](Image00362.jpg)</span><br><span class="line"></span><br><span class="line">图9-2 指数为3、1/3的幂函数图像</span><br><span class="line"></span><br><span class="line">·指数为-1的幂函数，函数为y=x-1 ，图像如图9-3所示。</span><br><span class="line"></span><br><span class="line">2.一次函数</span><br><span class="line"></span><br><span class="line">一次函数又称线性函数，是指拥有一个变量的一阶多项式函数。一次函数可以表达为以下斜截式的格式：</span><br><span class="line"></span><br><span class="line">f(x)=kx+b</span><br><span class="line"></span><br><span class="line">其中，k是斜率，b是截距。</span><br><span class="line"></span><br><span class="line">一次函数在二维坐标系中表现为一条直线，以自变量为X轴，以因变量为Y轴。如：y=2x+1和y=-x+1属于一次函数，它们的图像如图9-4所示。</span><br><span class="line"></span><br><span class="line">![](Image00363.jpg)</span><br><span class="line"></span><br><span class="line">图9-3 指数为-1的幂函数图像</span><br><span class="line"></span><br><span class="line">![](Image00364.jpg)</span><br><span class="line"></span><br><span class="line">图9-4 一次函数图像</span><br><span class="line"></span><br><span class="line">3.一元二次函数</span><br><span class="line"></span><br><span class="line">如果y=ax2 +bx+c（a、b、c为常数，a不为0），则称y为x的一元二次函数，其中，a称为二次项系数，b为一次项系数，c为常数项。</span><br><span class="line"></span><br><span class="line">一元二次函数是抛物线，是轴对称图形，它的对称轴为直线![](Image00365.jpg) ，它的顶点坐标为![](Image00366.jpg) 。此外，一元二次函数还可写成交点式：y=a(x-x1)(x-x2 )，交点式仅限于与x轴有交点的抛物线，与x轴的交点坐标是（x1 ，0）和（x2 ，0）。</span><br><span class="line"></span><br><span class="line">如图9-5所示为一元二次函数y=2x2 +x+1和y=-2x2</span><br><span class="line">+x+2的图像。从图像上观察，一元二次函数是一个开口向上或开口向下的抛物线，二次项系数a决定抛物线的开口方向和大小，当a&gt;0时，抛物线向上开口；当a&lt;0时，抛物线向下开口。|a|越大，则抛物线的开口越小。</span><br><span class="line"></span><br><span class="line">4.指数函数</span><br><span class="line"></span><br><span class="line">指数函数y=ex 是数学中重要的函数，这里的e是数学常数，就是自然对数的底数，近似等于2.718281828。y=ex 的图像总在x轴之上并从左向右递增，它接近x轴但不会与x轴相交。</span><br><span class="line"></span><br><span class="line">此外，还可定义更一般的指数函数y=ax ，对于a&gt;0和实数x，该函数可称为底数为a的指数函数。ax 可如下变换为以e为底的指数函数。</span><br><span class="line"></span><br><span class="line">ax =(elna )x =exln a</span><br><span class="line"></span><br><span class="line">观察图9-7所示的指数函数y=ax ，当a&gt;1时，从左到右函数是递增的，否则函数是递减的。指数函数遵循以下运算规律：</span><br><span class="line"></span><br><span class="line">![](Image00367.jpg)</span><br><span class="line"></span><br><span class="line">图9-5 二次函数图像</span><br><span class="line"></span><br><span class="line">![](Image00368.jpg)</span><br><span class="line"></span><br><span class="line">图9-6 指数函数y=ex</span><br><span class="line"></span><br><span class="line">![](Image00369.jpg)</span><br><span class="line"></span><br><span class="line">图9-7 指数函数y=ax</span><br><span class="line"></span><br><span class="line">![](Image00370.jpg)</span><br><span class="line"></span><br><span class="line">5.对数函数</span><br><span class="line"></span><br><span class="line">相对于底数α数x的对数是αy 的指数y，使得x=αy ，相对于底数α的数x的对数通常记为y=logα x，在工程计算中常用e、10和2来做底数，如表9-1所示。</span><br><span class="line"></span><br><span class="line">观察图9-8所示的对数函数图像，可看出：当α&gt;1时，函数是递增的，否则，函数是递减的。自然对数的底e大于1，它的函数图像是递增的，如图9-9所示。</span><br><span class="line"></span><br><span class="line">表9-1 常用对数函数表示</span><br><span class="line"></span><br><span class="line">![](Image00371.jpg)</span><br><span class="line"></span><br><span class="line">6.三角函数</span><br><span class="line"></span><br><span class="line">三角函数中使用得最多的是正弦（如图9-10所示）、余弦（如图9-10所示）、正切（如图9-11所示）、余切（如图9-12所示）。</span><br><span class="line"></span><br><span class="line">![](Image00372.jpg)</span><br><span class="line"></span><br><span class="line">图9-8 y=logα x</span><br><span class="line"></span><br><span class="line">![](Image00373.jpg)</span><br><span class="line"></span><br><span class="line">图9-9 自然对数</span><br><span class="line"></span><br><span class="line">![](Image00374.jpg)</span><br><span class="line"></span><br><span class="line">图9-10 正弦函数与余弦函数</span><br><span class="line"></span><br><span class="line">![](Image00375.jpg)</span><br><span class="line"></span><br><span class="line">图9-11 正切函数</span><br><span class="line"></span><br><span class="line">![](Image00376.jpg)</span><br><span class="line"></span><br><span class="line">图9-12 余切函数</span><br><span class="line"></span><br><span class="line">7.多项式函数</span><br><span class="line"></span><br><span class="line">多项式的函数图像呈现连续曲线，以多项式![](Image00377.jpg) 和y=x2 -x-2为例，其函数图像如图9-13和图9-14所示。</span><br><span class="line"></span><br><span class="line">仔细观察前面列举的函数图像，可发现常见的函数分为两种：线性函数与非线性函数。其中，线性函数是变量与自变量成一次方的函数关系，在函数图上呈现一条直线；而非线性函数是指两个变量间的关系不成简单比例，函数图像呈现为曲线。</span><br><span class="line"></span><br><span class="line">线性拟合是以一条直线来拟合自变量与因变量的关系，而非线性拟合用连续曲线来拟合自变量与因变量之间的关系。下面以几个具体实例说明图像分析法在线性与非线性拟合中的应用。</span><br><span class="line"></span><br><span class="line">![](Image00378.jpg)</span><br><span class="line"></span><br><span class="line">图9-13 ![](Image00379.jpg) 的函数图像</span><br><span class="line"></span><br><span class="line">![](Image00380.jpg)</span><br><span class="line"></span><br><span class="line">图9-14 y=x2 -x-2的函数图像</span><br><span class="line"></span><br><span class="line">1）多项式是非线性函数，如图9-15所示的图像为两类样本数据生成的散点图，其中虚线和实线各代表一类。</span><br><span class="line"></span><br><span class="line">![](Image00381.jpg)</span><br><span class="line"></span><br><span class="line">图9-15 多项式非线性拟合</span><br><span class="line"></span><br><span class="line">从图9-15看，X轴的区域为［0，5］，两条曲线代表的数据都比较接近多项式函数图像y=xa</span><br><span class="line">+b，因此，可选用幂函数作为数据拟合的模型。此外，从图像可判定，虚线函数的导数要比实线函数的导数增长得快，虚线数据表示的方程参数a要比实线表示的方程参数a大，原因是：导数即切线的斜率，导数越大，切线越陡，而虚线函数的切线明显要比实线函数陡很多，它的曲线在后期更加上扬。事实上，图9-15所代表的两类数据的模型分别为：虚线是y=x5</span><br><span class="line">+6，实线是y=x3 +6。</span><br><span class="line"></span><br><span class="line">2）大学生身高与体重线性拟合。从某大学中随机选取9名女大学生，其身高和体重数据如表9-2所示。下面分析这些数据并建立女大学生身高与体重模型，从而指导女大学生通过简易的公式查询自己的体重是否标准。</span><br><span class="line"></span><br><span class="line">表9-2 女大学生身高与体重数据</span><br><span class="line"></span><br><span class="line">![](Image00382.jpg)</span><br><span class="line"></span><br><span class="line">首先，使用R语言输入数据（本例只有9个数据，可手工录入。当数据量很大时，可使用第6章介绍的read.table函数读取数据）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >c(58,63,57,65,62,66,58,59,62)->y
    >c(160,165,158,172,159,176,160,162,171)->x <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着，用自变量身高（x）与因变量体重（y）组成9个数据点，绘制在直角坐标系中，生成散点图。</span><br><span class="line"></span><br><span class="line">观察分析散点图趋势，图9-16表明，随着x的增长，y也增长，数据点呈一条直线分布（线性拟合）。</span><br><span class="line"></span><br><span class="line">![](Image00383.jpg)</span><br><span class="line"></span><br><span class="line">图9-16 女大学生身高体重散点图</span><br><span class="line"></span><br><span class="line">下面以直线模型对数据进行拟合，可通过R语言进行拟合分析。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > lm(y~x)->xy
    > summary(xy)
    Call:
    lm(formula = y ~ x)
    Residuals:
        Min      1Q  Median      3Q     Max 
    -1.7317 -1.0989 -0.9412  0.8471  3.3223 
    Coefficients:
                Estimate Std. Error t value Pr(>|t|)   
    (Intercept) -8.28830   15.94636  -0.520  0.61926   
    x            0.42117    0.09671   4.355  0.00333 **
    ---
    Signif. codes:  0 ‘

    ***’

     0.001 ‘

    **’

     0.01 ‘

    *’

     0.05 ‘

    .’

     0.1 ‘

     ’

     1
    Residual standard error: 1.808 on 7 degrees of freedom
    Multiple R-squared:  0.7304,    Adjusted R-squared:  0.6919 
    F-statistic: 18.97 on 1 and 7 DF,  p-value: 0.003334 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">通过对上述直线方程模型的分析，可初步得出以下结论：</span><br><span class="line"></span><br><span class="line">·直线方程即线性方程，可写成y=ax+b的方式，a即系数（Coefficients项中的x）为0.42117，b即截距（Coefficients项中的Intercept）为-8.28830，线性拟合模型为y=0.42117x-8.28830。</span><br><span class="line"></span><br><span class="line">·Coefficients栏的x行尾的星号为2个。星号的含义表示线性关系是否显著：*的数量是0~3，*的数量越多则线性关系越显著。在本例中，自变量身高与因变量体重的线性关系并不是非常显著，否则星号应为3个。</span><br><span class="line"></span><br><span class="line">下面绘制回归线，图9-17所示。观察各数据点在回归线周围的分布情况，目测拟合效果。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(x,y)
    > abline( lm(y~x)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从图9-17来看，数据分布在回归线周围，但某些数据点的残差较大（比如155到160身高段）。总体来说，数据拟合效果较好，没有出现数据点分布趋势严重偏离回归线。</span><br><span class="line"></span><br><span class="line">通过R语言的residuals函数分析残差。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > residuals(xy)->xy_res
    > xy_res
             1          2          3          4          5          6          7 
    -1.0988557  1.7952956 -1.2565162  0.8471074  3.3223140  0.1624285 -1.0988557 
             8          9 
    -0.9411952 -1.7317228  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">残差计算的方式为：通过上一步计算得到的线性模型，将9个女大学生的自变量身高带入线性模型中的x，计算出观测的y值后，计算实际值与预测y值的差额，这个差额就是残差。如果拟合模型正确，可以将残差看作误差的观测值，它应符合模型的假设条件，且具有误差的一些性质。</span><br><span class="line"></span><br><span class="line">上述代码根据线性模型计算得出残差对象xy_res，9个元素分别为9个女大学生样本数据的残差，其中残差最大的数据为第5个女大学生，即3.3223140，最小为0.1624285，是第6个女大学生。</span><br><span class="line"></span><br><span class="line">然后，计算残差平方和。残差平方和是指每个残差的平方后的累计，它表示随机误差的效应。残差平方和是衡量拟合优度的重要标准，它的值越小，说明拟合效果越好。通过下面代码计算，线性模型拟合后的残差平方和为22.88334。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > sum(xy_res*xy_res)
    [1] 22.88334 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后，分析残差分布、标准残差及标准残差图。</span><br><span class="line"></span><br><span class="line">残差为测定值与按回归方程预测的值之差，可用δ表示，如果数据拟合模型效果较好，那么残差δ应遵从正态分布N(0，σ2 )，通过绘制QQ图观察残差数据是否符合正态分布。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > qqnorm(xy_res)
    > qqline(xy_res) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察残差分布QQ图，如图9-18所示。可看出：残差δ分布接近正态分布，数据点基本在直线附近，回归效果较理想，但仍不是非常理想。</span><br><span class="line"></span><br><span class="line">![](Image00384.jpg)</span><br><span class="line"></span><br><span class="line">图9-17 女大学生身高体重数据的回归线</span><br><span class="line"></span><br><span class="line">![](Image00385.jpg)</span><br><span class="line"></span><br><span class="line">图9-18 残差分布QQ图</span><br><span class="line"></span><br><span class="line">标准残差就是（残差δ-残差的均值）/残差的标准差，用δ*表示。下面通过R语言的rstandard函数计算身高体重拟合模型的标准残差，同时绘制标准残差图，图9-19所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > rstandard(xy)->std_xy_res
    > std_xy_res         1          2          3          4          5          6          7 -0.6696927  1.0532610 -0.7984996  0.5447647  2.0629420  0.1235619 -0.6696927          8          9 
    -0.5591209 -1.0857787 
    > plot(x,std_xy_res)
    > abline(h=0) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">标准残差图是以拟合模型的自变量为横坐标，以标准残差为纵坐标，将每一个自变量的标准残差描述在该平面坐标上，形成图形，实验点的标准残差落在残差图的（-2，2）区间以外的概率≤0.05，若某一实验点的标准化残差落在（-2，2）区间以外，可在95%置信度将其判为异常实验点。置信度也称置信水平，抽样不可能抽取全部总体进行分析，由于样本的随机性，通过这些样本对总体参数作出估计时，结论总是不确定的，因此引入置信度，用概率来陈述总体参数值落在样本统计值某一区内的可能性。</span><br><span class="line"></span><br><span class="line">当描绘标准残差的点围绕标准残差等于0的直线上下完全随机地分布，绝大多数点落在（-2，+2）的水平带状区间之中，且不带有任何系统趋势时，则说明拟合模型对原观测值（即样本）的拟合情况良好，如图9-20所示。</span><br><span class="line"></span><br><span class="line">![](Image00386.jpg)</span><br><span class="line"></span><br><span class="line">图9-19 身高体重标准残差图</span><br><span class="line"></span><br><span class="line">![](Image00387.jpg)</span><br><span class="line"></span><br><span class="line">图9-20 拟合良好的标准残差图</span><br><span class="line"></span><br><span class="line">如果拟合方程原本是非线性模型（曲线），但拟合时却采用了线性模型（直线），标准化残差图就会表现出曲线形状，产生系统性偏差，说明拟合模型不适合，如图9-21、图9-22所示。</span><br><span class="line"></span><br><span class="line">针对当前的拟合模型，样本数据中如果出现了异常点，它们会远离大多数数据点，如图9-23所示。</span><br><span class="line"></span><br><span class="line">![](Image00388.jpg)</span><br><span class="line"></span><br><span class="line">图9-21 出现系统性偏差的标准残差图①</span><br><span class="line"></span><br><span class="line">![](Image00389.jpg)</span><br><span class="line"></span><br><span class="line">图9-22 出现系统性偏差的标准残差图②</span><br><span class="line"></span><br><span class="line">此外，如果拟合不充分，很多点会落在（-2，+2）的水平带状区间之外，如图9-24所示。</span><br><span class="line"></span><br><span class="line">![](Image00390.jpg)</span><br><span class="line"></span><br><span class="line">图9-23 异常点</span><br><span class="line"></span><br><span class="line">![](Image00391.jpg)</span><br><span class="line"></span><br><span class="line">图9-24 拟合不充分</span><br><span class="line"></span><br><span class="line">根据标准残差图的相关知识，观察图9-19所示的身高体重标准残差图，可得出以下结论：</span><br><span class="line"></span><br><span class="line">·绝大部分数据在（-2，+2）的水平带状区间内，因此模型拟合较充分。</span><br><span class="line"></span><br><span class="line">·数据点分布稍均匀，但没有达到随机均匀分布的状态。此外，部分数据点还是呈现某种曲线波动形状，有少许系统性偏差，因此可能采用非线性拟合效果会更好。</span><br><span class="line"></span><br><span class="line">3）大学生身高与体重非线性拟合。继续以女大学生身高与体重的例子为例，再次仔细观察图9-16所示的散点图，数据点呈现上凸的递增曲线分布，可对身高与体重的关系应用非线性模型，也许效果会比直线好，因为曲线更贴近它的分布趋势。那么选用哪个非线性数学函数比较适合呢？观察前面列举的常见函数图像，可发现幂函数比较适合，尤其是y=x1/2 的函数图像，也呈现上凸且递增趋势，但是幂函数y=xa 仅有一个参数a，需要进行变形，在函数尾部加上截距b，使函数图像能在Y轴整体上下移动，这样，就拥有了两个可调节参数，形成的拟合方程更灵活和适用。</span><br><span class="line"></span><br><span class="line">细心的读者肯定发现了，加上截距后，幂函数y=xa 变成了多项式函数y=xa +b，因此将非线性拟合模型假设为y=xa +b的多项式方程。</span><br><span class="line"></span><br><span class="line">首先，显示自变量和因变量数据。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > x[1] 160 165 158 172 159 176 160 162 171
    > y
    [1] 58 63 57 65 62 66 58 59 62 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着，通过nls函数建立非线性拟合模型，并通过summary函数分析该模型。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > nls(y ~  Const + x^A)->nlmod
    > summary(nlmod)
    Formula: y ~ Const + x^A
    Parameters:
           Estimate Std. Error t value Pr(>|t|)    
    Const -19.66594   15.09467  -1.303    0.234    
    A       0.86036    0.03657  23.523 6.37e-08 ***
    ---
    Signif. codes:  0 ‘

    ***’

     0.001 ‘

    **’

     0.01 ‘

    *’

     0.05 ‘

    .’

     0.1 ‘

     ’

     1
    Residual standard error: 1.808 on 7 degrees of freedom
    Number of iterations to convergence: 4 
    Achieved convergence tolerance: 5.78e-06 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，计算残差，分析残差平方和。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > residuals(nlmod)->nlxy_res
    > nlxy_res
    [1] -1.0986204  1.7882691 -1.2508068  0.8448399  3.3251002  0.1704208 -1.0986204 -0.9449555 -1.7357098
    attr(,"label")
    [1] "Residuals"
    > sum(nlxy_res*nlxy_res)
    [1] 22.88108 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述代码计算得出的残差平方和为22.88108，比刚才应用线性拟合的残差平方和22.88334稍小些，可见非线性模型更适合拟合本例中的身高体重数据。</span><br><span class="line"></span><br><span class="line">下面，绘制残差的QQ图，如图9-25所示。从QQ图中，可看出：残差δ分布接近正态分布，数据点基本在直线附近。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > qqnorm(nlxy_res)
    > qqline(nlxy_res) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着，计算标准残差，将计算结果存入std_nlxy_res。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > (nlxy_res-mean(nlxy_res))/sd(nlxy_res)->std_nlxy_res
    > std_nlxy_res[1] -0.6496072  1.0574063 -0.7395947  0.4995580  1.9661322  0.1007751[7] -0.6496072 -0.5587453 -1.0263171attr(,"label")[1] "Residuals" <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">绘制标准残差图，如图9-26所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(x,std_nlxy_res)
    > abline(h=0) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">通过绘制图9-26所示的标准残差图，应用summary函数对非线性模型进行分析，以及计算残差平方和与标准残差，可得出以下结论：</span><br><span class="line"></span><br><span class="line">![](Image00392.jpg)</span><br><span class="line"></span><br><span class="line">图9-25 残差的QQ图</span><br><span class="line"></span><br><span class="line">![](Image00393.jpg)</span><br><span class="line"></span><br><span class="line">图9-26 身高体重非线性模型标准残差图</span><br><span class="line"></span><br><span class="line">·图9-26中没有任何异常点，计算的标准残差全在（-2，+2）的水平带状区间内，模型拟合充分。</span><br><span class="line"></span><br><span class="line">·图9-26中数据点分布较均匀，拟合效果良好。</span><br><span class="line"></span><br><span class="line">·残差平方和比线性模型小，非线性模型更适于描述女大学生身高与体重的关系。</span><br><span class="line"></span><br><span class="line">·非线性拟合模型为y=x0.86036 -19.66594。</span><br><span class="line"></span><br><span class="line">最后，观察一下拟合预测数据以及拟合效果图，如图9-27所示。</span><br><span class="line"></span><br><span class="line">![](Image00394.jpg)</span><br><span class="line"></span><br><span class="line">图9-27 拟合效果图</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > predict(nlmod)
    [1] 59.09862 61.21173 58.25081 64.15516 58.67490 65.82958 59.09862 59.94496
    [9] 63.73571
    > plot(x,y)
    > lines(x, predict(nlmod), col = 2) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">不要把图9-27中的拟合线误看成直线，通过分析predict(nlmod)的执行结果及得到的非线性拟合方程可看出，拟合预测点的位置在一条曲线上，但位置相差不大。</span><br><span class="line"></span><br><span class="line">仔细观察图9-27（非线性拟合）与图9-17（线性拟合）的拟合线，可以看出，图9-27所示的确实是一条曲线。</span><br><span class="line"></span><br><span class="line">#### 9.1.2 神经网络拟合法</span><br><span class="line"></span><br><span class="line">数据分布如果近似一条直线，可以使用线性神经网络来完成数据拟合，比如上一章介绍的Rosenblatt感知器；如果呈曲线，可使用多层感知器的神经网络进行拟合。上一节讲述了通过观察数据分布图像，估计非线性回归对应的数学方程。本节将要介绍的神经网络方法与之不同，它具有学习未知数据规律的能力。</span><br><span class="line"></span><br><span class="line">通过样本对神经网络进行训练的过程就是在输入与输出数据之间建立映射的过程。训练完成后，神经网络就已定型，网络内部的权值矩阵和神经元的激活函数共同组成了映射组件，这些组件代替了数学方程。</span><br><span class="line"></span><br><span class="line">1.常见数学函数拟合</span><br><span class="line"></span><br><span class="line">理论上来说，有了神经元作为映射组件，神经网络可以对数据之间的任何规律进行学习和模仿。下面是神经网络对上一节介绍的几个数学函数进行拟合的效果。</span><br><span class="line"></span><br><span class="line">1）sin函数拟合。顾名思义，sin函数拟合就是使用一组数据x作为输入，通过神经网络建立模型，其输出值为sin(x)。可通过使用Python编写神经网络，实现sin函数拟合。</span><br><span class="line"></span><br><span class="line">在华章网站下载本书的资源包，打开里面的文档“多层感知器神经网络源代码.doc”。下面将在该文档中源代码的基础上进行修改，实现非线性拟合。</span><br><span class="line"></span><br><span class="line">首先，随机生成500个x值，同时计算这些样本对应的目标值。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-1.py
    import numpy as np
    import matplotlib.pyplot as plt
    import random
    import copy
    isdebug=False
    #x和

    d样本初始化


    train_x =[]
    d=[]
    for yb_i in xrange(0,500):
    train_x.append([np.random.rand()*4*np.pi-2*np.pi])
    for yb_i in xrange(0,500):
    d.append(np.sin(train_x[yb_i])) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后设置相关参数。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    warray_txn=len(train_x[0])
    warray_n=warray_txn*4*2
    #基本参数初始化


    oldmse=10**100
    err=[]
    maxtrycount=800
    mycount=0.0
    if maxtrycount>=20:
    r=maxtrycount/10
    else:
    r=maxtrycount/2
    #sigmoid函数


    ann_sigfun=None
    ann_delta_sigfun=None
    #总层数初始化


    alllevel_count=int(warray_txn*4*1.5+1)
    # 非线性层数初始化


    hidelevel_count=alllevel_count-1
    #学习率参数


    learn_r0=0.002
    learn_r=learn_r0 *1.5
    #动量参数


    train_a0=learn_r0*1.2
    train_a0*=0.001
    train_a=train_a0
    expect_e=0.02 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着，对数据进行预处理，并生成初始权值矩阵。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #对输入数据进行预处理


    ann_max=[]
    for m_ani in xrange(0,warray_txn):
        temp_x=np.array(train_x)
        ann_max.append(np.max(temp_x[:,m_ani]))
    ann_max=np.array(ann_max)
    def getnowsx(mysx,in_w):
            '''生成本次的扩维输入数据

      '''
            global warray_n
            mysx=np.array(mysx)
            x_end=[]   
            for i in xrange(0,warray_n):
                    x_end.append(np.dot(mysx,in_w[:,i]))
            return x_end
    def get_inlw(my_train_max,w_count,myin_x):
            '''计算对输入数据预处理的权值

    '''
            #对随机生成的多个权值进行优化选择，选择最优的权值


            global warray_txn
            global warray_n
            mylw=[]
            y_in=[]
            #生成测试权值


            mylw=np.random.rand(w_count,warray_txn,warray_n)
            for ii in xrange (0,warray_txn):
                mylw[:,ii,:]=mylw[:,ii,:]*1/float(my_train_max[ii])-1/float(my_
                train_max[ii])*0.5
            #计算输出


            for i in xrange(0,w_count):
                    y_in.append([])
                    for  xj in xrange(0,len(myin_x)):
                            y_in[i].append(getnowsx(myin_x[xj],mylw[i]))
            #计算均方差


            mymin=10**5
            mychoice=0
            for i in xrange(0,w_count):
                    myvar=np.var(y_in[i])
                    if abs(myvar-1)<mymin: mymin="abs(myvar-1)" mychoice="i" #返回数据整理的权值矩阵 return mylw[mychoice] mylnww="get_inlw(ann_max,300,train_x)" def get_inputx(mytrain_x,myin_w): '''将训练数据通过输入权数，扩维后形成输入数据 ''' end_trainx="[]" for i in xrange(0,len(mytrain_x)): end_trainx.append(getnowsx(mytrain_x[i],myin_w)) x="get_inputx(train_x,mylnww)" get_siminx(sim_x): global myxx="np.array(sim_x)" get_inputx(myxx,mylnww) getlevelw(myin_x,wo_n,wi_n,w_count): '''计算一层的初始化权值矩阵 mylw="[]" y_in="[]" #生成测试权值 #计算输出 xrange(0,w_count): y_in.append([]) xj xrange(0,len(myin_x)): x_end="[]" myii xrange(0,wo_n): x_end.append(np.dot(myin_x[xj],mylw[i,:,myii])) y_in[i].append(x_end) #计算均方差 myvar="np.var(y_in[i])" if abs(myvar-1)<mymin: csmylw="mylw[mychoice]" csmylw,y_in[mychoice] ann_w="[]" init_annw(): hidelevel_count warray_n d lwyii="np.array(x)" myn xrange(0,hidelevel_count): #层数 ann_w.append([]) iii xrange(0,warray_n): ann_w[myn].append([]) jjj ann_w[myn][iii].append(0.0) elif templw,lwyii="getlevelw(lwyii,len(d[0]),warray_n,10)" xii xjj xrange(0,len(d[0])): ann_w[myn][xii].append(templw[xii,xjj]) xrange(len(d[0]),warray_n): ann_w[myn][xii].append(0.0) else: generate_lw(trycount): print u"产生权值初始矩阵 ", meanmin="1" myann_w="ann_w" alltry="30" tryc="0" while tryc<alltry: i_i range(trycount): ".", init_annw() abs(np.mean(np.array(ann_w)))<meanmin: tryc+="1" abs(np.mean(np.array(myann_w)))<0.01:break u"权值矩阵平均 :%f"%(np.mean(np.array(ann_w))) u"权值矩阵方差 :%f"%(np.var(np.array(ann_w))) generate_lw(15) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面，对所有样本数据进行反复训练，直到误差降到期望值为止。单个样本的训练过程如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

         def sample_train(myx,myd,n,sigmoid_func,delta_sigfun):
            '''一个样本的前向和后向计算

    '''
            global ann_yi
            global ann_delta
            global ann_w
            global ann_wj0
            global ann_y0
            global hidelevel_count
            global alllevel_count
            global learn_r
            global train_a
            global ann_oldw
            level=hidelevel_count
            #清空

    yi输出信号数组


            hidelevel=hidelevel_count
            alllevel=alllevel_count
            for i in xrange(0,alllevel):
                    #第一维是层数，从

    0开始


                    for j in xrange(0,n):
                            #第二维是神经元


                            ann_yi[i][j]=0.0
            ann_yi=np.array(ann_yi)
            yi=ann_yi
            #清空

    delta矩阵


            for i in xrange(0,hidelevel-1):    
                    for j in xrange(0,n):
                            ann_delta[i][j]=0.0
            delta=ann_delta
            #保留

    W的拷贝，以便下一次迭代


            ann_oldw=copy.deepcopy(ann_w)
            oldw=ann_oldw
            #前向计算


            if isdebug:print u"前向计算中

    ..."
            #对输入变量进行预处理


            myo=np.array([])
            for nowlevel in xrange(0,alllevel):
                    #一层层向前计算


                    #计算诱导局部域


                    my_y=[]
                    myy=yi[nowlevel-1] 
                    myw=ann_w[nowlevel-1]                
                    if nowlevel==0:
                            #第一层隐藏层


                            my_y=myx
                            yi[nowlevel]=my_y                        
                    elif nowlevel==(alllevel-1):
                            #输出层


                            my_y=o_func(yi[nowlevel-1,:len(myd)])
                            yi[nowlevel,:len(myd)]=my_y
                    elif nowlevel==(hidelevel-1):
                            #最后一层输出层


                            for i in xrange(0,len(myd)):
                                    temp_y=sigmoid_func(np.dot(myw[:,i],myy))
                                    my_y.append(temp_y)                        
                            yi[nowlevel,:len(myd)]=my_y 
                    else:
                            #中间隐藏层


                            for i in xrange(0,len(myy)):
                                    temp_y=sigmoid_func(np.dot(myw[:,i],myy))
                                    my_y.append(temp_y)
                            yi[nowlevel]=my_y
            if isdebug:
                print u"******本样本训练的输出矩阵

    **********"  
                print yi
                print u"**********************************"          
            #计算误差与均方误差


            #因为线性输出层为直接复制，所以取非线性隐藏输出层的结果


            myo=yi[hidelevel-1][:len(myd)]
            myo_end=yi[alllevel-1][:len(myd)]
            mymse=get_e(myd,myo_end)
            #反向计算


            #输入层不需要计算

    delta,输出层不需要计算

    W
            if isdebug:print u"反向计算中

    ..."
            #计算

    delta
            for nowlevel in xrange(level-1,0,-1):
                    if nowlevel==level-1:
                            mydelta=delta[nowlevel]
                            my_n=len(myd)
                    else:
                            mydelta=delta[nowlevel+1]
                            my_n=n
                    myw=ann_w[nowlevel]                
                    if nowlevel==level-1:
                            #输出层


                            mydelta=delta_sigfun(myo,myd,None,None,None,None,None)
    ##                        mydelta=mymse*myo
                    elif nowlevel==level-2:
                            #输出隐藏层的前一层，因为输出结果和前一层隐藏层的神经元数目可能存在不一致的情况，所以单独处理，传输相当于输出隐藏层的神经元数目的数据


                             mydelta=delta_sigfun(yi[nowlevel],myd,nowlevel,level-
                             1,my_n,mydelta[:len(myd)],myw[:,:len(myd)])
                    else:
                             mydelta=delta_sigfun(yi[nowlevel],myd,nowlevel,level-
                             1,my_n,mydelta,myw)
                    delta[nowlevel][:my_n]=mydelta
            #计算与更新权值

    W 
            for nowlevel in xrange(level-1,0,-1):
                    #每个层的权值不一样


                    if nowlevel==level-1:
                            #输出层


                            my_n=len(myd)
                            mylearn_r=learn_r*0.8
                            mytrain_a=train_a*1.8
                    elif nowlevel==1:
                            #输入层


                            my_n=len(myd)
                            mylearn_r=learn_r*0.9
                            mytrain_a=train_a*0.8                       
                    else:
                            #其他层


                            my_n=n
                            mylearn_r=learn_r
                            mytrain_a=train_a
                    pre_level_myy=yi[nowlevel-1]
                    pretrain_myww=oldw[nowlevel-1]
                    pretrain_myw=pretrain_myww[:,:my_n]
                    #第二个调整参数


                    temp_i=[]                
                    for i in xrange(0,n):
                            temp_i.append([])
                            for jj in xrange(0,my_n):
                                 temp_i[i].append(mylearn_r*delta[nowlevel,jj]*pre_
                                 level_myy[i])
                    temp_rs2=np.array(temp_i)
                    temp_rs1=mytrain_a*pretrain_myw
                    #总调整参数


                    temp_change=temp_rs1+temp_rs2               
                    my_ww=ann_w[nowlevel-1]                
                    my_ww[:,:my_n]+=temp_change
            if isdebug:
                print "============="
                print u"***权值矩阵

    ***"  
                print ann_w
                print u"***梯度矩阵

    ***" 
                print delta
                print "============="
            return mymse <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">经过43次训练，误差率降到了0.02以下，训练过程停止，如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ......
    ......
    -------开始第

    41次训练

    ---------误差为：

    0.026790
    -------开始第

    42次训练

    ---------误差为：

    0.021292
    -------开始第

    43次训练

    ---------误差为：

    0.019350训练成功，正在进行检验

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后，进行仿真测试。下面是一个样本值的仿真计算过程。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     def simulate(myx,sigmoid_func,delta_sigfun):
            '''一个样本的仿真计算

    '''
            print u"仿真计算中

    "        
            global ann_yi
            global ann_w
            global ann_wj0
            global ann_y0
            global hidelevel_count
            global alllevel_count
            global d
            global mylnww
            myd=d[0]
            myx=np.array(myx)
            n=len(myx)
            #清空

    yi输出信号数组


            hidelevel=hidelevel_count
            alllevel=alllevel_count
            for i in xrange(0,alllevel):
                    #第一维是层数，从

    0开始


                    for j in xrange(0,n):
                            #第二维是神经元


                            ann_yi[i][j]=0.0
            ann_yi=np.array(ann_yi)
            yi=ann_yi
            #前向计算


            myy=np.array([])           
            for nowlevel in xrange(0,alllevel):
                    #一层层向前计算


                    #计算诱导局部域


                    my_y=[]
                    myy=yi[nowlevel-1]
                    myw=ann_w[nowlevel-1]                
                    if nowlevel==0:
                            #第一层隐藏层


                            my_y=myx
                            yi[nowlevel]=my_y                        
                    elif nowlevel==(alllevel-1):
                            #线性输出层


                            my_y=o_func(yi[nowlevel-1,:len(myd)])
                            yi[nowlevel,:len(myd)]=my_y                       
                    elif nowlevel==(hidelevel-1):
                            #最后一层隐藏输出层


                            for i in xrange(0,len(myd)):
                                    temp_y=sigmoid_func(np.dot(myw[:,i],myy))
                                    my_y.append(temp_y)                        
                            yi[nowlevel,:len(myd)]=my_y 
                    else:
                            #中间隐藏层


                            #中间隐藏层需要加上偏置


                            for i in xrange(0,len(myy)):
                                    temp_y=sigmoid_func(np.dot(myw[:,i],myy))
                                    my_y.append(temp_y)
                            yi[nowlevel]=my_y
            if isdebug:
                print "============="
                print u"***权值矩阵

    ***"  
                print ann_w
                print u"***输出矩阵

    ***" 
                print yi
                print "============="
            return yi[alllevel-1,:len(myd)] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">为了验证效果，绘制数据拟合效果和误差曲线，如图9-28所示。图9-28的上部是拟合效果图，目标值和预测值很接近，下部是误差曲线，下降平滑。</span><br><span class="line"></span><br><span class="line">2）0.6sin(x)函数神经网络拟合。下面尝试实现稍复杂数学函数的拟合，比如y=0.6sin(x)。这里的Python实现代码与前面相同，因此，只是在样本数据初始化代码段进行了修改。示例如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-2.py
    import numpy as np
    import matplotlib.pyplot as plt
    import random
    import copy
    isdebug=False
    #x和

    d样本初始化


    train_x =[]
    d=[]
    for yb_i in xrange(0,500):
        train_x.append([np.random.rand()*4*np.pi-2*np.pi])
    for yb_i in xrange(0,500):
        d.append(np.sin(train_x[yb_i])*0.6) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">经过71次训练，神经网络的收敛目标达到，也就是说误差率达到了期望值。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ....................
    ....................
    -------开始第

    69次训练

    ---------误差为：

    0.020464
    -------开始第

    70次训练

    ---------误差为：

    0.020673
    -------开始第

    71次训练

    ---------误差为：

    0.019350训练成功，正在进行检验

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">图9-29为程序绘制的拟合效果和误差曲线图。</span><br><span class="line"></span><br><span class="line">![](Image00395.jpg)</span><br><span class="line"></span><br><span class="line">图9-28 sin函数神经网络拟合</span><br><span class="line"></span><br><span class="line">![](Image00396.jpg)</span><br><span class="line"></span><br><span class="line">图9-29 0.6sin(x)函数神经网络拟合（附彩图）</span><br><span class="line"></span><br><span class="line">3）0.5sin(x)+0.5cos(x)函数拟合。前两个例子使用了本书资源包所示的Python代码。下面使用Neurolab库实现对0.5sin(x)+0.5cos(x)的拟合。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #9-3.py
    #拟合

    sin*0.5+cos*0.5
    import neurolab as nl
    import numpy as np
    import matplotlib.pyplot as plt
    isdebug=False
    #x和

    d样本初始化


    train_x =[]
    d=[]
    samplescount=1000
    myrndsmp=np.random.rand(samplescount)
    for yb_i in xrange(0,samplescount):
        train_x.append([myrndsmp[yb_i]*4*np.pi-2*np.pi])
    for yb_i in xrange(0,samplescount):
        d.append(np.sin(train_x[yb_i])*0.5+np.cos(train_x[yb_i])*0.5)
    myinput=np.array(train_x)   
    mytarget=np.array(d)
    bpnet = nl.net.newff([[-2*np.pi, 2*np.pi]], [5, 1])
    err = bpnet.train(myinput, mytarget, epochs=800, show=100, goal=0.02)
    simd=[]
    for xn in xrange(0,len(train_x)):
            simd.append(bpnet.sim([train_x[xn]])[0][0])
    temp_x=[]
    temp_y=simd
    temp_d=[]
    i=0
    for mysamp in train_x:
         temp_x.append(mysamp[0])
         temp_d.append(d[i][0])
         i+=1                
    x_max=max(temp_x)
    x_min=min(temp_x)
    y_max=max(max(temp_y),max(d))+0.2
    y_min=min(min(temp_y),min(d))-0.2
    plt.xlabel(u"x")
    plt.xlim(x_min, x_max)
    plt.ylabel(u"y")
    plt.ylim(y_min, y_max)
    lp_x1 = temp_x
    lp_x2 = temp_y
    lp_d = temp_d
    plt.plot(lp_x1, lp_x2, 'r*')
    plt.plot(lp_x1,lp_d,'bo')
    plt.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">800次训练后，拟合效果较好，如图9-30所示。</span><br><span class="line"></span><br><span class="line">![](Image00397.jpg)</span><br><span class="line"></span><br><span class="line">图9-30 0.5sin(x)+0.5cos(x)的拟合</span><br><span class="line"></span><br><span class="line">2.钢包使用次数与容积模型拟合</span><br><span class="line"></span><br><span class="line">表9-3是钢包使用次数与容积实测数据，以x为输入，y为输出，在输入与输出数据之间可建立非线性关系。这里用神经网络建立数据拟合模型。</span><br><span class="line"></span><br><span class="line">表9-3 钢包使用次数与容积实测数据</span><br><span class="line"></span><br><span class="line">![](Image00398.jpg)</span><br><span class="line"></span><br><span class="line">下面尝试应用神经网络完成以上数据拟合任务，这里调用Neurolab库，用Python实现。</span><br><span class="line"></span><br><span class="line">首先读取数据文件。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-4.py
    import numpy as np
    import pylab as pl
    import neurolab as nl
    print u'正在处理中

    '
    #x和

    d样本初始化


    train_x =[]
    d=[]
    f = open("cubage.csv")  
    try:  
        f_text = f.read( ) 
    finally:  
        f.close( ) 
    x_text=f_text.split('\n')
    for line_i in xrange(0,len(x_text)):
        line=x_text[line_i]
        if line_i>1 and len(line)>0:
            train_x.append([])
            hdata=line.split(',')
            train_x[line_i-2].append(float(hdata[0]))
            d.append([float(hdata[1])]) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着，生成样本数据，一般情况下，使用tanh的神经网络输出值不会超过1，因此，设置调整系数，把输出值处理成1以内的小数。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    myinput=np.array(train_x)  
    mytarget=np.array(d)
    mymax=np.max(d)
    tz=(0.1**(len(str(int(mymax)))))*5
    myinput=myinput
    mytarget=tz*mytarget <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后进行训练，训练时可加入未知样本进行测试。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #对未知样本进行测试


    myinputtest=[[6],[9],[17],[20]]
    testsimd= bpnet.sim(myinputtest)
    end_x=np.array(myinputtest)
    testsimd/=tz
    end_y=testsimd <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">经过9次训练，达到了训练目标，误差为1.9713682268777952e-05。对神经网络输出值应用调整系数，将其输出值恢复到原有的数值范围。</span><br><span class="line"></span><br><span class="line">程序生成了拟合效果图（如图9-31上部所示）及误差曲线图（如图9-31下部所示）。同时使用在样本空间中没有出现的部分测试数据6、9、17、20作为神经网络的输入，验证神经网络的训练效果和拟合效果。图中实心圆圈为未知测试数据，即：使用次数为6、9、17、20时容积的预测值，星号为样本数据。</span><br><span class="line"></span><br><span class="line">![](Image00399.jpg)</span><br><span class="line"></span><br><span class="line">图9-31 钢包使用次数与容积的神经网络拟合</span><br><span class="line"></span><br><span class="line">从图9-31的拟合效果来看，样本数据非常接近神经网络拟合的曲线，说明曲线较好地反映了随着使用次数的增加，容积的增长趋势。此外，对在样本中没出现的钢包使用次数6、9、17、20，与之相关的容积预测效果不错。</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-4.py
    import numpy as np
    import pylab as pl
    import neurolab as nl
    print u'正在处理中

    '
    #x和

    d样本初始化


    train_x =[]
    d=[]
    f = open("cubage.csv")  
    try:  
        f_text = f.read( ) 
    finally:  
        f.close( ) 
    x_text=f_text.split('\n')
    for line_i in xrange(0,len(x_text)):
        line=x_text[line_i]
        if line_i>1 and len(line)>0:
            train_x.append([])
            hdata=line.split(',')
            train_x[line_i-2].append(float(hdata[0]))
            d.append([float(hdata[1])])
    myinput=np.array(train_x)  
    mytarget=np.array(d)
    mymax=np.max(d)
    tz=(0.1**(len(str(int(mymax)))))*5
    myinput=myinput
    mytarget=tz*mytarget
    netminmax=[0,np.max(myinput)]
    print u'\n正在建立神经网络

    '
    bpnet = nl.net.newff([netminmax], [5, 1])
    print u'\n训练神经网络中

    ...'
    err = bpnet.train(myinput, mytarget, epochs=800, show=5, goal=0.0001)
    if err[len(err)-1]>0.0001:
        print u'\n训练神经网络失败

    ...\n'
    else:
        print u'\n训练神经网络完毕

    '    
        pl.subplot(211)
        pl.plot(err)  
        pl.xlabel('Epoch number')
        pl.ylabel('error (default SSE)')
        #对样本进行测试


        simd= bpnet.sim(myinput)
        temp_x=myinput
        temp_d=mytarget
        simd/=tz
        temp_y=simd
        temp_d/=tz  
        #对未知样本进行测试


        myinputtest=[[6],[9],[17],[20]]
        testsimd= bpnet.sim(myinputtest)
        end_x=np.array(myinputtest)
        testsimd/=tz
        end_y=testsimd
        x_max=np.max(temp_x)
        x_min=np.min(temp_x)-5
        y_max=np.max(temp_y)+2  
        y_min=np.min(temp_y)
        pl.subplot(212)
        pl.xlabel(u"x")
        pl.xlim(x_min, x_max)
        pl.ylabel(u"y")
        pl.ylim(y_min, y_max)
        lp_x1 = temp_x
        lp_x2=temp_y
        lp_d = temp_d
        pl.plot(lp_x1, lp_x2, 'g-')
        pl.plot(end_x, end_y, 'ro')
        pl.plot(lp_x1,lp_d,'b*') <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 9.2 线性滤波</span><br><span class="line"></span><br><span class="line">#### 9.2.1 WAV声音文件</span><br><span class="line"></span><br><span class="line">声音是由物体的机械振动而形成的。用鼓棒敲击鼓皮，于是鼓皮发生振动而发声；吹笛时笛腔内的空气柱发生振动而发声；把音频电流送入扬声器，扬声器的纸盆发生振动而发声。发生声音的振动源叫作“声源”，由声源发出的声音，必须通过媒质才能传送到我们的耳朵中。空气是最常见的媒质，如水、金属、木材等媒质都能传播声音。</span><br><span class="line"></span><br><span class="line">WAV声音文件为Microsoft公司开发的一种记录声音的文件格式，它符合RIFF（Resource Interchange File Format）文件规范，音频格式未经过压缩，在音质方面不会出现失真的情况。它以指定频率采样，比如每秒采样44100次。在采集声音的振动状态时，它会使用模/数转换器（A/D）以每秒上万次的速率对声波进行采样，每一次采样都记录下了原始模拟声波在某一时刻的状态，采样的结果即为样本。将一串样本连接起来，就可以描述一段声波了。</span><br><span class="line"></span><br><span class="line">#### 9.2.2 线性滤波算法过程</span><br><span class="line"></span><br><span class="line">神经网络既可以进行函数拟合，也能对波形数据进行拟合。下面将输入x作为函数的自变量，将神经网络输出的数据y作为函数f(x)的输出，然后应用该拟合功能进行一个线性滤波，以实现去除周围环境的噪音，使说话声音更清楚。</span><br><span class="line"></span><br><span class="line">下面以从含有音乐的语音中去除背景音乐为例进行讲解。具体算法过程如下：</span><br><span class="line"></span><br><span class="line">1）读取该机器学习算法必需的两个素材文件：含有背景音乐的语音和部分背景音乐。细心的读者一定会问，既然已经有背景音乐这个文件，那么直接从语音的波形数据减去背景音乐，这样就完成了背景音乐的过滤。没错，但是不能直接减去源背景音乐。原因如下：</span><br><span class="line"></span><br><span class="line">在对声波进行采样时，虽然同时对背景音乐和语音进行了采样，但采样过程很可能会被周边的音源、采样音量等很多因素干扰，导致采样形成的背景音乐波形并不是源背景音乐的波形。如果直接使用源背景音乐进行减，将会导致滤波后的语音文件有杂音且部分失真。我们要做的是干净地将背景音乐剔除。</span><br><span class="line"></span><br><span class="line">2）采样器先采样一小段背景音乐，然后再采集语音文件。其好处在于：生成了经过采样后的背景音乐样本，这些样本就是神经网络拟合训练样本中的目标输出值。</span><br><span class="line"></span><br><span class="line">3）用神经网络进行训练，输入样本为源背景音乐中相当于采样背景音乐长度的波形数据，输出目标为采样器开始采集的小段背景音乐波形数据。</span><br><span class="line"></span><br><span class="line">4）训练达到期望误差率或达到最大训练次数后，将源背景音乐作为未知样本数据送入神经网络，其预测输出就是拟合后的采样背景音乐。</span><br><span class="line"></span><br><span class="line">5）将混杂有背景音乐的语音文件波形数据直接减去拟合后的采样背景音乐，得到去除背景音乐的纯净语音。</span><br><span class="line"></span><br><span class="line">自适应线性滤波器的工作原理也是如此：先采集一段背景噪声；然后用噪声数据进行拟合，之后在噪声数据和背景噪声之间建立了一种映射关系；最后，人可以通过该系统传送语音，说话周围环境产生的背景噪声将被过滤。</span><br><span class="line"></span><br><span class="line">#### 9.2.3 滤波Python实现</span><br><span class="line"></span><br><span class="line">下面用Python实现上述步骤。</span><br><span class="line"></span><br><span class="line">1）读取声音素材，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-5.py
    import numpy as np
    import wave
    import pylab as pl
    import copy
    print 'working...' 
    print "read wav data...."
    err=[]
    # 打开

    WAV文档


    f = wave.open(r"speak.wav", "rb")
    fo = wave.open(r"wait_jg.wav", "wb")
    fi=wave.open(r"back.wav", "rb")
    fend=wave.open(r"end_jg.wav", "wb")
    # 读取波形数据


    # (nchannels, sampwidth, framerate, nframes, comptype, compname)
    params = f.getparams()
    nchannels, sampwidth, framerate, nframes = params[:4]
    str_data = f.readframes(nframes)
    fi_params=fi.getparams()
    fi_nframes = fi_params[3]
    fi_str_data=fi.readframes(fi_nframes)
    #将波形数据转换为数组，并更改


    print "update wav data...."
    wave_data = np.fromstring(str_data, dtype=np.short)
    fi_wave_data= np.fromstring(fi_str_data, dtype=np.short) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）复制波形，在一个随机的基数基础上，将背景音乐的振幅（音量）稍微变动一下，并与语音合并。前面预留一段经过波形调整后的背景音乐，以供线性神经网络拟合用。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    emptywdata=np.zeros(framerate, dtype=np.short)
    new_wave_data=np.hstack((emptywdata,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data))
    wave_data =copy.deepcopy(new_wave_data)
    nframes*=8
    nframes+=framerate/2
    temp_wavedata=np.hstack((fi_wave_data,fi_wave_data))[:len(new_wave_data)]
    backrnd=np.random.rand(len(new_wave_data))*10-5
    backbase=np.random.rand()*2+1
    temp_wavedata=temp_wavedata*backbase+backrnd
    new_wave_data=temp_wavedata+new_wave_data
    new_wave_data=np.array(new_wave_data)
    new_wave_data =new_wave_data.astype(wave_data.dtype)
    new_str_data=new_wave_data.tostring() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）拟合数据，去除背景音乐。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    jg_wave_data=copy.deepcopy(new_wave_data)
    jg_temp_wavedata=np.hstack((fi_wave_data,fi_wave_data))[:len(new_wave_data)]
    jg_temp_wavedata=jg_temp_wavedata[:len(new_wave_data)]*w[1]+w[0]
    jg_wave_data=jg_wave_data-jg_temp_wavedata
    for jg_i in xrange(0,len(jg_wave_data)):
        if abs(jg_wave_data[jg_i])<500: jg_wave_data[jg_i]="0" jg_wave_data[:framerate]="0" jg_wave_data="jg_wave_data.astype(wave_data.dtype)" jg_str_data="jg_wave_data.tostring()" print "save output wav...." fend.setnchannels(nchannels) fend.setframerate(framerate) fend.setsampwidth(sampwidth) fend.writeframes(jg_str_data) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #9-5.py
    import numpy as np
    import wave
    import pylab as pl
    import copy
    print 'working...' 
    print "read wav data...."
    err=[]
    # 打开

    WAV文档


    f = wave.open(r"speak.wav", "rb")
    fo = wave.open(r"wait_jg.wav", "wb")
    fi=wave.open(r"back.wav", "rb")
    fend=wave.open(r"end_jg.wav", "wb")
    # 读取波形数据


    # (nchannels, sampwidth, framerate, nframes, comptype, compname)
    params = f.getparams()
    nchannels, sampwidth, framerate, nframes = params[:4]
    str_data = f.readframes(nframes)
    fi_params=fi.getparams()
    fi_nframes = fi_params[3]
    fi_str_data=fi.readframes(fi_nframes)
    #将波形数据转换为数组，并更改


    print "update wav data...."
    wave_data = np.fromstring(str_data, dtype=np.short)
    fi_wave_data= np.fromstring(fi_str_data, dtype=np.short)
    #复制并将背景音乐的振幅

    (音量

    )在一个随机的基数基础上稍微变动后，与语音合并


    #前面预留一段经过波形调整后的背景音乐，以供线性神经网络拟合用


    emptywdata=np.zeros(framerate, dtype=np.short)
    new_wave_data=np.hstack((emptywdata,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data,wave_data))
    wave_data =copy.deepcopy(new_wave_data)
    nframes*=8
    nframes+=framerate/2
    temp_wavedata=np.hstack((fi_wave_data,fi_wave_data))[:len(new_wave_data)]
    backrnd=np.random.rand(len(new_wave_data))*10-5
    backbase=np.random.rand()*2+1
    temp_wavedata=temp_wavedata*backbase+backrnd
    new_wave_data=temp_wavedata+new_wave_data
    new_wave_data=np.array(new_wave_data)
    new_wave_data =new_wave_data.astype(wave_data.dtype)
    new_str_data=new_wave_data.tostring()
    #写波形数据参数


    print "save mix wav files...."
    fo.setnchannels(nchannels)
    fo.setframerate(framerate)
    fo.setsampwidth(sampwidth)
    fo.writeframes(new_str_data)
    #线性逼近前段噪声


    b=1
    a0=5e-1
    a=0.0
    r=1.5
    x=[]
    d=[]
    ii=0
    for audio_i in xrange(0,framerate/2):
        if fi_wave_data[audio_i]!=0.:
            x.append([])
            x[ii].append(1)
            x[ii].append(fi_wave_data[audio_i])
            d.append(new_wave_data[audio_i])
            ii+=1
        if ii>100:
            break
    x=np.array(x)
    d=np.array(d)
    w=np.random.rand(2)*np.mean(x)#np.array([b,0])
    expect_e=15
    maxtrycount=10000
    mycount=0
    def sgn(v):
        return  v
    def get_v(myw,myx):
            return sgn(np.dot(myw.T,myx))
    def neww(oldw,myd,myx,a):
            mye=get_e(oldw,myx,myd)
            a=a0/(1+float(mycount)/r)
            return (oldw+a*mye*myx,mye)
    def get_e(myw,myx,myd):
            return myd-get_v(myw,myx)
    while True:
            mye=0.
            i=0          
            for xn in x:
                    w,e=neww(w,d[i],xn,a)
                    i+=1
                    mye+=pow(e,2)
            mye=np.sqrt(mye)
            mycount+=1
            err.append(mye)
            print u"第

     %d 次调整后的权值：

    "%mycount
            print w
            print u"误差：

    %f"%mye        
            if abs(mye)<expect_e or mycount>maxtrycount:break 
    print "w:[%f,%f]"%(w[0],w[1])
    #复制并除去背景声音


    jg_wave_data=copy.deepcopy(new_wave_data)
    jg_temp_wavedata=np.hstack((fi_wave_data,fi_wave_data))[:len(new_wave_data)]
    jg_temp_wavedata=jg_temp_wavedata[:len(new_wave_data)]*w[1]+w[0]
    jg_wave_data=jg_wave_data-jg_temp_wavedata
    for jg_i in xrange(0,len(jg_wave_data)):
        if abs(jg_wave_data[jg_i])<500: 2 jg_wave_data[jg_i]="0" jg_wave_data[:framerate]="0" jg_wave_data="jg_wave_data.astype(wave_data.dtype)" jg_str_data="jg_wave_data.tostring()" print "save output wav...." fend.setnchannels(nchannels) fend.setframerate(framerate) fend.setsampwidth(sampwidth) fend.writeframes(jg_str_data) # 绘制波形 time="np.arange(0," nframes) * (1.0 framerate) wave_data.shape="-1," wave_data="wave_data.T" pl.subplot(321) pl.plot(time, wave_data[0]) pl.subplot(322) wave_data[1], c="g" ) pl.xlabel("time (seconds)") new_wave_data.shape="-1," new_wave_data="new_wave_data.T" pl.subplot(323) pl.plot(time,new_wave_data[0]) pl.subplot(324) new_wave_data[1], pl.show() jg_wave_data.shape="-1," pl.subplot(325) pl.plot(time,jg_wave_data[0]) pl.subplot(326) jg_wave_data[1], <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图9-32所示是程序运行完毕后生成的效果图。最上面的两张图是无背景音乐语音文件的两个声道的波形图，中间是混杂了背景音乐的语音文件，下面是经过线性滤波后生成的纯净语音文件。</span><br><span class="line"></span><br><span class="line">观察图9-32可看出，线性滤波的效果是不错的。读者可以从本书的资源包中下载相关程序，执行后，用音箱播放滤波后的语音，听听效果，是否还能听出背景音乐。</span><br><span class="line"></span><br><span class="line">![](Image00400.jpg)</span><br><span class="line"></span><br><span class="line">图9-32 线性滤波效果</span><br><span class="line"></span><br><span class="line">### 9.3 数据或曲线平滑</span><br><span class="line"></span><br><span class="line">#### 9.3.1 平滑概述</span><br><span class="line"></span><br><span class="line">在介绍平滑的概念之前，先来看一组数据，表9-4是某虚拟商品X连续21天的销量。</span><br><span class="line"></span><br><span class="line">表9-4 虚拟商品X连续21天的销量</span><br><span class="line"></span><br><span class="line">![](Image00401.jpg)</span><br><span class="line"></span><br><span class="line">现绘制该虚拟商品X的销量图（如图9-33所示），R代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> plot(x,type="o",col="blue",xlab="天

    ",ylab="销量

    ") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">初步观察图9-33，曲线波折较多，销量不稳定，仔细观察才能发现销量在整体走高。再观察图9-34，它是将图9-33平滑处理后生成的销量走势图。</span><br><span class="line"></span><br><span class="line">观察图9-34，曲线波动较小，整体增长趋势一目了然，销量连续经过了两次攀升，虽然每次攀升后有少量回落，但销量仍在增长中。</span><br><span class="line"></span><br><span class="line">现在正式介绍平滑的概念，数据或曲线平滑是通过建立近似函数来发现数据中的主要模式的，去除噪音、结构细节或瞬时现象，减少不必要的数据波动，从而实现数据集的平滑。平滑过程中会修改数据点，降低由噪音数据点产生的影响，而低于毗邻数据点的点则被提升，从而得到一个更平滑的数据序列。</span><br><span class="line"></span><br><span class="line">![](Image00402.jpg)</span><br><span class="line"></span><br><span class="line">图9-33 虚拟商品的销量图</span><br><span class="line"></span><br><span class="line">![](Image00403.jpg)</span><br><span class="line"></span><br><span class="line">图9-34 经过平滑处理后的销量走势图</span><br><span class="line"></span><br><span class="line">#### 9.3.2 移动平均</span><br><span class="line"></span><br><span class="line">移动平均（Moving Average，MA），又称“移动平均线”，简称均线，是数据分析中一种分析时间序列数据的工具。最常见的是利用股价、交易量等变量计算出移动平均。移动平均可抚平短期波动，反映出长期趋势或周期，在数学上，移动平均可视为一种卷积。</span><br><span class="line"></span><br><span class="line">1.简单移动平均</span><br><span class="line"></span><br><span class="line">简单移动平均是某变量之前n个数值的未作加权的算术平均。比如，设某股票的预测收市价为SMA，该股票前n日的收市价为p1 至pn ，则预测收市价的计算方式如下：</span><br><span class="line"></span><br><span class="line">![](Image00404.jpg)</span><br><span class="line"></span><br><span class="line">上述公式的计算效率较高，原因在于：计算连续的数值时，若有一个新的数值加入，可将一个旧的数值剔出，无须每次都重新将数值逐个加起来，如下面的公式所示：</span><br><span class="line"></span><br><span class="line">![](Image00405.jpg)</span><br><span class="line"></span><br><span class="line">在R语言中，可调用filter函数进行线性过滤，实现简单移动平均算法，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">1）filter参数（该参数指定了参加平均计算的前期数据的权重）设定为1/n，n为前n期。</span><br><span class="line"></span><br><span class="line">2）method参数指定为convolution，表示使用移动平均法，并将sides参数设置为1，表示使用单边卷积。</span><br><span class="line"></span><br><span class="line">3）filter函数对数据进行预测时，参与计算的前期数据不但包括前n-1期的数据，还包括当前数据，预测值的计算公式如下：</span><br><span class="line"></span><br><span class="line">y[t]=f[1]*x[t]+f[2]*x[t-1]+f[3]*x[t-2]+…+f[n-1]*x[t-(n-1)]</span><br><span class="line"></span><br><span class="line">以上公式中，t为时间，f为该时间点数据的权重值。</span><br><span class="line"></span><br><span class="line">以表9-4所示的X商品的销量为例，设当前时间点t为3，期数n为2，权重为1/2（即0.5），x为商品销量数组，提取前n期的数据，预测当前时间点的平滑值，其计算方式如下：</span><br><span class="line"></span><br><span class="line">y[3]=x[2]×0.5+x[3]×0.5=123×0.5+54×0.5=88.5</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-4所示的销量数据进行平滑，效果如图9-35所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> plot(x,type="o",col="blue",xlab="天

    ",ylab="销量

    ")
    > y= filter(x, filter=rep(1/3,3),method = "convolution",sides=1) 
    > lines(y,col="red")
    > points(y,pch=8,col="red") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-35，平滑效果不错，红色曲线及星号表示平滑后的数据，蓝色曲线及空心圆点表示原数据。上述R程序通过将fliter参数设为rep(1/3，3)，使每个时间点的权值均为1/3，且前期数据取前3天的数据，从而生成当天的平滑数据值。</span><br><span class="line"></span><br><span class="line">2.加权移动平均</span><br><span class="line"></span><br><span class="line">加权移动平均给固定跨越期限内的每个变量值以不相等的权重，其原理是：历史各期产品需求的数据信息对预测未来期内的需求量的作用是不一样的，除了以n为周期的周期性变化外，远离目标期的变量值的影响力相对较低，故应给予较低的权重。简单的移动平均法实质上也是加权移动平均，只不过它是各元素的权重都相等。</span><br><span class="line"></span><br><span class="line">加权移动平均的计算公式如下：</span><br><span class="line"></span><br><span class="line">y[t-1]=a1 ×x[t-1]+a2 ×x[t-2]+a3 ×x[t-3]+…+an ×x[t-n]</span><br><span class="line"></span><br><span class="line">上式中，a为权值，x为数据，y为预测值，n为参与计算的数据期数，且权值之和为1。</span><br><span class="line"></span><br><span class="line">在R语言中，可调用filter函数进行线性过滤，实现加权移动平均算法，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">·filter参数（该参数指定了参加平均计算的前期数据的权重）设定为参与计算时间点的各自权重。</span><br><span class="line"></span><br><span class="line">·method参数指定为convolution，表示使用移动平均法，并将sides参数设置为1，表示使用单边卷积。</span><br><span class="line"></span><br><span class="line">·filter函数对数据进行预测时，参与计算的前期数据不但包括前n-1期的数据，还包括当前数据，预测值的计算公式如下：</span><br><span class="line"></span><br><span class="line">y[t]=f[1]×x[t]+f[2]×x[t-1]+f[3]×x[t-2]+…+f[n-1]×x[t-(n-1)]</span><br><span class="line"></span><br><span class="line">以上公式中，t为时间，f为该时间点数据的权重值。</span><br><span class="line"></span><br><span class="line">以表9-4所示的X商品的销量为例，设当前时间点t为5，期数n为3，当前时间点权重为0.65，前1个时间点的权重为0.25，前2个时间点的权重为0.1，x为商品销量数组，提取前n期的数据，预测当前时间点的平滑值，其计算方式如下：</span><br><span class="line"></span><br><span class="line">y[5]=x[5]×0.65+x[4]×0.25+x[3]×0.1=121×0.65+176×0.25+54×0.1=128.05</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-4所示的销量数据进行平滑，效果如图9-36所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> plot(x,type="o",col="blue",xlab="天

    ",ylab="销量

    ")
     > y= filter(x, filter=c(0.65,0.25,0.1),method = "convolution",sides=1) 
     > lines(y,col="red")
     > points(y,pch=8,col="red") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-36，平滑效果不错，红色曲线及星号表示平滑后的数据，蓝色曲线以及空心圆点表示原数据。上述R程序通过将filter参数设为c(0.65，0.25，0.1)，将从预测时间点开始依次向前的3个时间点的权值分别设置为0.65、0.25、0.1，从而生成当天的平滑数据值。</span><br><span class="line"></span><br><span class="line">![](Image00406.jpg)</span><br><span class="line"></span><br><span class="line">图9-35 简单移动平均</span><br><span class="line"></span><br><span class="line">![](Image00407.jpg)</span><br><span class="line"></span><br><span class="line">图9-36 加权移动平均</span><br><span class="line"></span><br><span class="line">此外，还可输出y值，从以下输出结果可以看出，第5个时间点的平滑值是128.05，与前面手工计算的一致。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > y
    Time Series:
    Start = 1 
    End = 21 
    Frequency = 1 
     [1]     NA     NA  67.05 140.20 128.05 134.95 174.30 163.65 137.85 118.15
    [11] 126.40 202.95 255.00 244.70 259.35 234.25 203.75 194.40 226.20 152.05
    [21] 137.80 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.双边卷积</span><br><span class="line"></span><br><span class="line">双边卷积算法与简单移动平均法、加权移动平均法相似，不同之处在于其计算平均值的依据不仅包括以前时间点的数据，而且还包括以后时间点的数据。</span><br><span class="line"></span><br><span class="line">在R语言中，可调用filter函数进行线性过滤，实现双边卷积算法，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">·filter参数（该参数指定了参加平均计算的前期数据的权重）设定为参与计算时间点各自的权重。</span><br><span class="line"></span><br><span class="line">·method参数指定为convolution，表示使用移动平均法，并将sides参数设置为2，表示使用双边卷积。</span><br><span class="line"></span><br><span class="line">·filter函数对数据进行预测时，参与计算的数据不但包括前n-1期的数据和当前数据，还包括以后时间点的数据。以期数是5为例，计算当前时间点t的预测值y[t]，公式如下：</span><br><span class="line"></span><br><span class="line">y[t]=f[1]×x[t+2]+f[2]×x[t+1]+f[3]×x[t]+f[4]×x[t-1]+f[5]×x[t-2]</span><br><span class="line"></span><br><span class="line">以上公式中，t为时间，f为该时间点数据的权重值。</span><br><span class="line"></span><br><span class="line">以表9-4所示的X商品的销量为例，设当前时间点t为5，期数n为5，当前时间点权重为0.5，前1个时间点的权重为0.15，前2个时间点的权重为0.1，后1个时间点的权重为0.15，后2个时间点的权重为0.1，x为商品销量数组，提取前n-2期、后n-2期及第n期的数据，预测当前时间点的平滑值，计算方式如下：</span><br><span class="line"></span><br><span class="line">y[5]=x[7]×0.1+x[6]×0.15+x[5]×0.5+x[4]×0.15+x[3]×0.1</span><br><span class="line"></span><br><span class="line">=198×0.1+134×0.15+121×0.5+176×0.15+54×0.1</span><br><span class="line"></span><br><span class="line">=132.2</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-4所示的销量数据进行平滑，效果如图9-37所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> plot(x,type="o",col="blue",xlab="天

    ",ylab="销量

    ")
     > y= filter(x, filter=c(0.1,0.15,0.5,0.15,0.1),method = "convolution",sides=2) 
     > lines(y,col="red")
     > points(y,pch=8,col="red") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-37，平滑效果不错，红色曲线及星号表示平滑后的数据，蓝色曲线及空心圆点表示原数据。上述R程序通过将filter参数设为c(0.1，0.15，0.5，0.15，0.1)，将从预测时间点后2个时间点、当前时间点及之前2个时间点的权值分别设置为0.1、0.15、0.5、0.15、0.1，从而生成当天的平滑数据值。</span><br><span class="line"></span><br><span class="line">此外，还可输出y值，从以下输出结果可以看出，第5个时间点的平滑值是132.20，与前面手工计算的一致。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > c(y)
     [1]     NA     NA  85.15 139.95 132.20 147.95 166.65 150.00 134.00 133.65 159.75 217.95 250.40 244.35 248.10 221.60 206.95
    [18] 194.50 199.85     NA     NA <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 9.3.3 递归线性过滤</span><br><span class="line"></span><br><span class="line">递归线性过滤相当于自回归法，在R语言中，可调用filter函数进行递归线性过滤，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">·filter参数（该参数指定了参加平均计算的前期数据的权重）设定为参与计算时间点各自的权重。</span><br><span class="line"></span><br><span class="line">·method参数指定为recursive，表示使用递归线性过滤。</span><br><span class="line"></span><br><span class="line">·filter函数对数据进行预测时，参与计算的数据包括当前时间点的数据和以前n-1个时间点的预测值。当前时间点t的预测值y[t]的计算公式如下：</span><br><span class="line"></span><br><span class="line">y[t]=x[t]+f[1]×y[t-1]+…+f[n-1]×y[t-(n-1)]</span><br><span class="line"></span><br><span class="line">以上公式中，t为时间，f为该时间点数据的权重值。</span><br><span class="line"></span><br><span class="line">以表9-4所示的X商品的销量为例，设当前时间点t为3，期数n为2，前1个时间点的权重为0.1，前2个时间点的权重为0.05，x为商品销量数组，提取前n-2期预测值y及第n期值x，预测当前时间点的平滑值，计算方式如下：</span><br><span class="line"></span><br><span class="line">y[1]=x[1]=12</span><br><span class="line"></span><br><span class="line">y[2]=x[2]+x[1]*0.1=124.2y[3]=x[3]+y[2]*0.1+y[1]*0.05</span><br><span class="line"></span><br><span class="line">=54+124.2*0.1+12*0.05</span><br><span class="line"></span><br><span class="line">=67.02</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-4所示的销量数据进行平滑，效果如图9-38所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> plot(x,type="o",col="blue",xlab="天

    ",ylab="销量

    ",ylim=c(1,400))
     > y<-filter(x, filter="c(0.1,0.05),method" = "recursive")> lines(y,col="red")
     > points(y,pch=8,col="red") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-38，红色曲线及星号表示平滑后的数据，蓝色曲线及空心圆点表示原数据。上述R程序通过将filter参数设为c(0.1，0.05)，将以前2个时间点的权值分别设置为0.1和0.05，从而生成当天的平滑数据值。</span><br><span class="line"></span><br><span class="line">![](Image00408.jpg)</span><br><span class="line"></span><br><span class="line">图9-37 双边卷积</span><br><span class="line"></span><br><span class="line">![](Image00409.jpg)</span><br><span class="line"></span><br><span class="line">图9-38 递归线性过滤</span><br><span class="line"></span><br><span class="line">此外，还可输出y值，从以下输出结果可以看出，第3个时间点的平滑值是67.02，与前面手工计算的一致。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >  c(y)
     [1]  12.0000 124.2000  67.0200 188.9120 143.2422 157.7698 220.9391 184.9824
     [9] 151.5452 135.4036 154.1176 266.1819 312.3241 276.5415 310.2704 266.8541
    [17] 229.1989 229.2626 279.3862 149.4018 160.9095 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 9.3.4 指数平滑</span><br><span class="line"></span><br><span class="line">指数平滑（Exponential Smoothing，ES）法是布朗（Robert G.Brown）所提出的，布朗认为时间序列的态势具有稳定性或规则性，所以时间序列可被合理地顺势推延，最近的过去数据趋势，在某种程度上会持续到未来，因此将较大的权重放在最近的资料上。指数平滑法是在移动平均法的基础上发展起来的一种时间序列分析预测法，它是通过计算指数平滑值，配合一定的时间序列预测模型对现象的未来进行预测，其原理是任一期的指数平滑值都是本期实际观察值与前一期指数平滑值的加权平均。</span><br><span class="line"></span><br><span class="line">根据平滑次数不同，指数平滑法分为：一次指数平滑法、二次指数平滑法和三次指数平滑法等。一次指数平滑法是根据前期的实测数和预测数，以一次平滑系数为权重，进行加权平均，从而预测未来时间趋势的方法；二次指数平滑法是对一次指数平滑的再平滑，它保留并更新了平滑后的信号及平滑后的趋势，它增加了二次趋势平滑系数；三次指数平滑法是在二次平滑的基础上再添加第三个量，用来描述周期性，它是二次平滑的再平滑，增加了三次周期平滑系数。</span><br><span class="line"></span><br><span class="line">1.二次指数平滑</span><br><span class="line"></span><br><span class="line">在R语言中，可调用HoltWinters函数进行二次指数平滑，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">·alpha参数指定一次平滑系数，beta参数指定二次平滑系数，gamma参数设置为FALSE表示不进行三次平滑，如果不指定平滑系数，HoltWinters函数将自动计算最优系数。</span><br><span class="line"></span><br><span class="line">·在调用HoltWinters函数前，需要使用ts函数将数据转化为时间序列向量。ts函数主要有以下参数：</span><br><span class="line"></span><br><span class="line">·Frequency：周期频率</span><br><span class="line"></span><br><span class="line">·Start：开始时间点</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-5所示的虚拟商品Y的销量数据进行平滑。</span><br><span class="line"></span><br><span class="line">表9-5 虚拟商品Y连续21天的销量</span><br><span class="line"></span><br><span class="line">![](Image00410.jpg)</span><br><span class="line"></span><br><span class="line">首先，载入数据，然后转成时间序列。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     > 
    x<-c(42,153,54,176,61,134,98,155,82,111,63,244,178,232,167,222,107,193,115,190,132)> ts(x,frequency=7,start=c(1,1))->sales.x
      > sales.x
      Time Series:
      Start = c(1, 1) 
      End = c(3, 7) 
      Frequency = 7 
       [1]  42 153  54 176  61 134  98 155  82 111  63 244 178 232 167 222 107 193
      [19] 115 190 132 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察sales.x的输出结果，表9-5所示为21天的销售数据，指定周期为7天后，即形成以周为周期的时间序列，Start表示数据的周期起始为c(1，1)，即：第1周的第1天，End表示数据的周期终止为c(3，7)，即：第3周的第7天。</span><br><span class="line"></span><br><span class="line">然后，进行二次平滑。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > HoltWinters(sales.x, gamma=FALSE)->mysol
    > mysol
    Holt-Winters exponential smoothing with trend and without seasonal component.
    Call:
    HoltWinters(x = sales.x, gamma = FALSE)
    Smoothing parameters:
     alpha: 0.4649865
     beta : 0.8894224
     gamma: FALSE
    Coefficients:
            [,1]
    a 143.102068
    b   2.827244
    > <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察mysol输出，HoltWinters函数计算出最佳平滑系数，其中，一次指数平滑系数为0.4649865，二次指数平滑系数为0.8894224。</span><br><span class="line"></span><br><span class="line">最后，绘制效果图（如图9-39所示）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(sales.x,col="blue",ylim=c(1,500),xlim=c(1,5),xlab="周

    ",ylab="销量

    ")
    > lines(mysol$fitted[,1],col="red",type="b") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-39，蓝色实线是原数据，红色虚线是平滑拟合值。</span><br><span class="line"></span><br><span class="line">2.三次指数平滑</span><br><span class="line"></span><br><span class="line">在R语言中，可调用HoltWinters函数进行三次指数平滑，使用时需要注意以下事项：</span><br><span class="line"></span><br><span class="line">·alpha参数指定一次平滑系数，beta参数指定二次平滑系数，gamma参数指定三次平滑系数。</span><br><span class="line"></span><br><span class="line">·HoltWinters函数计算预测值的方式有如下两种。</span><br><span class="line"></span><br><span class="line">第一种是累乘法，计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00411.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00412.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00413.jpg)</span><br><span class="line"></span><br><span class="line">图9-39 二次指数平滑</span><br><span class="line"></span><br><span class="line">其中，α、β、γ分别为一次、二次、三次平滑系数，Yhat为预测值。</span><br><span class="line"></span><br><span class="line">第二种是累加法，计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00414.jpg)</span><br><span class="line"></span><br><span class="line">由seasonal参数指定三次平滑的方式，分别为additive（累加方式）、multiplicative（累乘方式），默认为additvie。</span><br><span class="line"></span><br><span class="line">·调用HoltWinters函数前，需要使用ts函数将数据转化为时间序列向量。ts函数主要有以下参数：</span><br><span class="line"></span><br><span class="line">·Frequency：周期频率</span><br><span class="line"></span><br><span class="line">·Start：开始时间点</span><br><span class="line"></span><br><span class="line">下面编写R代码，对表9-4所示的虚拟商品X的销量数据进行平滑。</span><br><span class="line"></span><br><span class="line">首先，载入数据，然后转成时间序列。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

      > 
    x<-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)> ts(x,frequency=7,start=c(1,1))->sales.x
      > sales.x
      Time Series:
      Start = c(1, 1) 
      End = c(3, 7) 
      Frequency = 7 
       [1]  12 123  54 176 121 134 198 155 122 111 133 244 278 232 267 222
      [17] 187 193 245 110 132 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察sales.x的输出结果，表9-4所示为21天的销售数据，指定周期为7天后，即形成以周为周期的时间序列，Start表示数据的周期起始为c(1，1)，即：第1周的第1天，End表示数据的周期终止为c(3，7)，即：第3周的第7天。</span><br><span class="line"></span><br><span class="line">然后，进行三次平滑。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > HoltWinters(sales.x)->mysol
    > mysol
    Holt-Winters exponential smoothing with trend and additive seasonal component.
    Call:
    HoltWinters(x = sales.x)
    Smoothing parameters:
     alpha: 0.6264084
     beta : 0
     gamma: 1
    Coefficients:
             [,1]
    a  122.270966
    b    8.447279
    s1  36.581455
    s2 -20.578516
    s3 -57.187646
    s4 -26.947654
    s5  24.695147
    s6 -30.083230
    s7   9.729034 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察mysol输出，HoltWinters函数计算出最佳平滑系数，其中，一次指数平滑系数为0.6264084，二次指数平滑系数为0，三次指数平滑系数为1。此外，商品X的销量周期系数为s1到s7。</span><br><span class="line"></span><br><span class="line">再绘制效果图，如图9-40所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    > plot(sales.x,col="blue",ylim=c(1,500),xlim=c(1,5),xlab="周

    ",ylab="销量

    ")
    > lines(mysol$fitted[,1],col="red",type="b") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-40，蓝色实线是原数据，红色虚线是平滑拟合值。</span><br><span class="line"></span><br><span class="line">最后，对以后的趋势进行预测。表9-4所示的数据是虚拟商品X21天的销量，现在对以后14天的销量进行预测，预测效果如图9-41所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >  predict(mysol, 14, prediction.interval = TRUE)->p
    > plot(mysol,p,xlab="周

    ",ylab="销量

    ",xlim=c(1,7),main="销量预测

    ") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图9-41，黑色线为原数据，红色线为平滑拟合值。虚线右侧的部分是以后14天的虚拟商品X的预测销量部分，该部分的中间红线为预测走势曲线，上方和下方曲线分别为预测置信区间的上限和下限。</span><br><span class="line"></span><br><span class="line">![](Image00415.jpg)</span><br><span class="line"></span><br><span class="line">图9-40 三次指数平滑</span><br><span class="line"></span><br><span class="line">![](Image00416.jpg)</span><br><span class="line"></span><br><span class="line">图9-41 三次指数平滑预测</span><br><span class="line"></span><br><span class="line">### 9.4 小结</span><br><span class="line"></span><br><span class="line">本章首先介绍了数据拟合的技术。数据拟合是通过理想的假设方程来拟合数据的，得到这个假设方程主要有两种方式：第一，通过观察样本数据点的分布来估计所属函数的图像，在拟合后计算相关统计指标，评估拟合的效果；第二，以假设方程的自变量为输入样本，以变量为样本的目标输出，通过神经网络进行训练，以权值矩阵和众多神经元的激活函数等神经网络组件完成输入到输出的映射，其实质是建立一个更复杂的拟合模型来实现数据拟合。</span><br><span class="line"></span><br><span class="line">然后讲解了移动平均法、递归线性过滤法、指数平滑法等平滑方法。数据或曲线平滑通过建立近似函数发现数据中的主要模式，去除噪声、结构细节或瞬时现象，减少不必要的数据波动，从而实现数据集的平滑。</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">（1）假设有两类数据，下面是这两类数据的分布散点图，从图像上分析拟合这些数据的函数方程。</span><br><span class="line"></span><br><span class="line">（2）编写Python代码实现多层感知器，拟合y=0.7sin(x)+0.3cos(x)函数。</span><br><span class="line"></span><br><span class="line">（3）本章讲解了通过线性滤波去除背景音乐的方法。请尝试用非线性滤波解决这个问题，即：使用多层感知器对背景音乐进行拟合，然后将它从语音文件中去除。</span><br><span class="line"></span><br><span class="line">![](Image00417.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00418.jpg)</span><br><span class="line"></span><br><span class="line">## 第10章 图像算法案例</span><br><span class="line"></span><br><span class="line">机器学习算法可对数字图像进行加工和处理，以便进一步进行特征提取的工作，主要目标为从图像中挖掘所需要的知识和信息，主要解决图像锐化、图像除噪、图像增强、图像分类、图像识别等问题，其算法过程主要包括：图像获取、预处理、特征提取、加工分析、提取知识等。</span><br><span class="line"></span><br><span class="line">### 10.1 图像边缘算法</span><br><span class="line"></span><br><span class="line">#### 10.1.1 数字图像基础</span><br><span class="line"></span><br><span class="line">再次复习一下数字图像的知识。数字图像在计算机中保存为二维整数数组，数组中元素是二维图像中的像素，每个像素都用有限数值表示，对应于二维空间中一个特定的位置。图像是由二维像素点组成的矩阵，通常每个像素点由3个元素组成——红、绿、蓝，这3个基本分量可以组成高清的图像。也可以把图像上的每个像素点理解为（x，y，z）这样的一个点，这个点定义在三维空间，每一维分别代表红、绿、蓝分量。</span><br><span class="line"></span><br><span class="line">假设将像素的顺序定义为：蓝、绿、红，那么就可以定义一个像素点为（blue，green，red）。每个图像由大量的像素点组成，如果将这个像素点组成的矩阵定义为H×W大小（H为高，W为宽），那么就得到了一个H×W×3的矩阵（“3”表示像素点的数值由3个基本分量组成）。OpenCV作为图像算法库，对图像矩阵也是这么定义的。请提前安装好OpenCV，本章大部分例子都需要它的Python绑定库。</span><br><span class="line"></span><br><span class="line">假设图像矩阵的变量名为img，现在要用Python实现一个蓝色分量为200、绿色为100、红色为50的像素点的定义，这个像素点位于图像的300×150处。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    img[300,150,0]=200
    img[300,150,1]=100
    img[300,150,2]=50 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 10.1.2 算法描述</span><br><span class="line"></span><br><span class="line">算法的基本原理是：将当前像素与邻接的下部和右部的像素进行比较，如果相似，则将当前像素设置为白色，否则设置为黑色。如何判定像素相似呢？应用欧氏距离算法，将一个像素的3个色彩分量映射在三维空间中，如果2个像素点的欧氏距离小于某个常数的阈值，就认为它们相似。算法的最终效果如图10-1所示。图10-1中左图是原图像，右图是计算图像边缘的结果。</span><br><span class="line"></span><br><span class="line">![](Image00419.jpg)</span><br><span class="line"></span><br><span class="line">图10-1 图像边缘</span><br><span class="line"></span><br><span class="line">上面涉及的算法其关键是欧氏距离计算。下面用Python编写计算欧氏距离的函数。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy))) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的代码为：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-1.py
    import cv2
    import numpy as np
    fn="test1.jpg"
    def get_EuclideanDistance(x,y):
        myx=np.array(x)
        myy=np.array(y)
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))
    if __name__ == '__main__':
        print 'loading %s ...' % fn
        print 'working',
        myimg1 = cv2.imread(fn)
        w=myimg1.shape[1]
        h=myimg1.shape[0]
        sz1=w
        sz0=h
        #创建空白图像


        myimg2=np.zeros((sz0,sz1,3), np.uint8)   
        #对比产生线条


        black=np.array([0,0,0])
        white=np.array([255,255,255])
        centercolor=np.array([125,125,125])
        for y in xrange(0,sz0-1):
            for x in xrange(0,sz1-1):
                mydown=myimg1[y+1,x,:]
                myright=myimg1[y,x+1,:]
                myhere=myimg1[y,x,:]
                lmyhere=myhere
                lmyright=myright
                lmydown=mydown
                if get_EuclideanDistance(lmyhere,lmydown)>16 and get_EuclideanDistan\
                ce(lmyhere,lmyright)>16:
                    myimg2[y,x,:]=black
                elif get_EuclideanDistance(lmyhere,lmydown)<=16 and get_euclideandis\ tance(lmyhere,lmyright)<="16:" myimg2[y,x,:]="white" else: print '.', cv2.namedwindow('img2') cv2.imshow('img2', myimg2) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 10.2 图像匹配</span><br><span class="line"></span><br><span class="line">图像匹配算法是基于像素的比较和计算来实现的方法。如图10-2所示是美国的X-47B，它是人类历史上第一架无需人工干预、完全由计算机智能操纵的无人驾驶飞机。现在以其在航母起飞的图像为例讲解本节内容。</span><br><span class="line"></span><br><span class="line">![](Image00420.jpg)</span><br><span class="line"></span><br><span class="line">图10-2 X-47B航母起飞</span><br><span class="line"></span><br><span class="line">如图10-3所示为图10-2的两张局部切片图。我们的任务是找到两张切片图在图10-2中的位置，并将它们标注出来。</span><br><span class="line"></span><br><span class="line">![](Image00421.jpg)</span><br><span class="line"></span><br><span class="line">图10-3 两张X-47B起飞画面切片图</span><br><span class="line"></span><br><span class="line">#### 10.2.1 差分矩阵求和</span><br><span class="line"></span><br><span class="line">差分算法的核心在于差分矩阵，实质为差异矩阵，计算公式很简单：</span><br><span class="line"></span><br><span class="line">差分矩阵=图像A矩阵数据-图像B矩阵数据</span><br><span class="line"></span><br><span class="line">算法过程是：首先，计算两个图像的矩阵数据之间差异分析图像的相似性；然后，设置一个阈值进行比较，如果差分矩阵的所有元素之和在阈值以内，则表示这两张图像是相似的，且描述了同一物体。另外，它要求两个图像的大小相同，大小处理对于计算机来说不成问题，改变图像尺寸的算法已非常成熟，实现起来很方便。</span><br><span class="line"></span><br><span class="line">编写程序实现这个算法的基本思路为：将图10-3所示的切片图在图10-2中进行移动，并计算两个图像的差分矩阵，如果差分矩阵的所有元素之和小于1，则认为找到了切片图在图像中的位置。实现该算法的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    def showpiclocation(img,findimg):
        #定位图像


        w=img.shape[1]  
        h=img.shape[0]  
        fw=findimg.shape[1]
        fh=findimg.shape[0]
        findpt=None
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                comp_tz=img[now_h:now_h+fh,now_w:now_w+fw,:]-findimg       
                if np.sum(comp_tz)<1: findpt="now_w,now_h" print ".", if findpt!="None:" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(255,0,0)) return img <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">如图10-4所示为算法效果图，看上去识别效果不错。</span><br><span class="line"></span><br><span class="line">![](Image00422.jpg)</span><br><span class="line"></span><br><span class="line">图10-4 切片识别效果图</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-2.py
    #简单定位图像


    import cv2
    import numpy as np
    print 'loading  ...'
    def showpiclocation(img,findimg):
        #定位图像


        w=img.shape[1]  
        h=img.shape[0]  
        fw=findimg.shape[1]
        fh=findimg.shape[0]
        findpt=None
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                comp_tz=img[now_h:now_h+fh,now_w:now_w+fw,:]-findimg       
                if np.sum(comp_tz)<1: findpt="now_w,now_h" print ".", if findpt!="None:" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(255,0,0)) return img fn="pictest.png" fn1="pictestt1.png" fn2="pictestt2.png" myimg="cv2.imread(fn)" myimg1="cv2.imread(fn1)" myimg2="cv2.imread(fn2)" cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 10.2.2 差分矩阵均值</span><br><span class="line"></span><br><span class="line">刚才小试牛刀，通过对差分矩阵中所有元素求和完成了匹配，效果不错。当数字图像质量较差时，则需要计算差分矩阵的均值，并为均值设一个适当的阈值。</span><br><span class="line"></span><br><span class="line">下面仍用Python编写算法，在目标图中加上少量（50000个）不同颜色的噪声点，从而测试算法在弱噪声环境下的有效性。因为图像质量不高，存在很多噪声点，所以要将差分矩阵均值的阈值设置得稍大一点，这里设为20。通常来说，阈值为10~200，阈值越大，能容忍的噪声点越多。但如果阈值超过200，最好使用下一节介绍的欧氏距离算法。如图10-5所示是算法应用效果。</span><br><span class="line"></span><br><span class="line">![](Image00423.jpg)</span><br><span class="line"></span><br><span class="line">图10-5 弱噪声切片识别效果图（附彩图）</span><br><span class="line"></span><br><span class="line">Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-3.py
    #少量噪声定位图像


    import cv2
    import numpy as np
    print 'loading  ...'
    def showpiclocation(img,findimg):
        #定位图像


        w=img.shape[1]  
        h=img.shape[0]  
        fw=findimg.shape[1]
        fh=findimg.shape[0]
        findpt=None
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                comp_tz=img[now_h:now_h+fh,now_w:now_w+fw,:]-findimg       
                if abs(np.mean(comp_tz))<20: findpt="now_w,now_h" print "ok" ".", if findpt!="None:" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(0,0,255)) return img def addnoise(img): coutn="50000" for k in xrange(0,coutn): xi="int(np.random.uniform(0,img.shape[1]))" xj="int(np.random.uniform(0,img.shape[0]))" img[xj,xi,0]="255" *np.random.rand() img[xj,xi,1]="255" img[xj,xi,2]="255" fn="pictest.png" fn1="pictestt1.png" fn2="pictestt2.png" myimg="cv2.imread(fn)" myimg1="cv2.imread(fn1)" myimg2="cv2.imread(fn2)" addnoise(myimg) cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">可见，在弱噪声的情况下，差分算法仍然具有很好的匹配效果。</span><br><span class="line"></span><br><span class="line">#### 10.2.3 欧氏距离匹配</span><br><span class="line"></span><br><span class="line">1.强噪声图像匹配</span><br><span class="line"></span><br><span class="line">对强噪声环境下的图像进行匹配时，欧氏距离匹配方法相对于以上两种方法会有更好的效果。</span><br><span class="line"></span><br><span class="line">仍以上面的图像为目标进行讲解。首先，在目标图像中加上更多的（500000个）不同颜色的噪声点。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

     def addnoise(img):
        coutn=500000
        for k in xrange(0,coutn):  
            xi = int(np.random.uniform(0,img.shape[1]))  
            xj = int(np.random.uniform(0,img.shape[0]))  
            img[xj,xi,0]= 255 *np.random.rand() 
            img[xj,xi,1]= 255 *np.random.rand()   
            img[xj,xi,2]= 255 *np.random.rand() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">生成强噪声环境下的图像，如图10-6所示。</span><br><span class="line"></span><br><span class="line">![](Image00424.jpg)</span><br><span class="line"></span><br><span class="line">图10-6 强噪声图像（附彩图）</span><br><span class="line"></span><br><span class="line">现在要应用欧氏距离对如图10-6所示的目标图完成匹配。其核心算法为：设图像矩阵有n个元素，用n个元素值（x1 ，x2 ，…，xn</span><br><span class="line">）组成该图像的特征组，特征组形成了n维空间，特征组中的特征码构成每一维的数值。在n维空间下，两个图像矩阵各形成了一个点，然后计算这两个点之间的距离，距离最小者为最匹配的图像。</span><br><span class="line"></span><br><span class="line">如图10-7所示是算法应用的效果图，欧氏距离算法成功地找到了匹配位置。在图像如此模糊的情况下，人用肉眼都很难进行图像匹配。由此可见，机器学习算法在某些方面胜过人类的“智能”。</span><br><span class="line"></span><br><span class="line">![](Image00425.jpg)</span><br><span class="line"></span><br><span class="line">图10-7 强噪声切片识别效果图（附彩图）</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-4.py
    #大量噪声定位图像


    import cv2
    import numpy as np
    print 'http://blog.csdn.net/myhaspl'  
    print 'myhaspl@qq.com'  
    print  
    print 'loading  ...'
    def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))  
    def findpic(img,findimg,h,fh,w,fw):
        minds=1e8
        mincb_h=0
        mincb_w=0
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                my_img=img[now_h:now_h+fh,now_w:now_w+fw,:]
                my_findimg=findimg  
                dis=get_EuclideanDistance(my_img,my_findimg)
                if dis<minds: mincb_h="now_h" mincb_w="now_w" minds="dis" print ".", findpt="mincb_w,mincb_h" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(0,0,255)) return img def showpiclocation(img,findimg): #定位图像 w="img.shape[1]" h="img.shape[0]" fw="findimg.shape[1]" fh="findimg.shape[0]" findpic(img,findimg,h,fh,w,fw) addnoise(img): coutn="500000" for k in xrange(0,coutn): xi="int(np.random.uniform(0,img.shape[1]))" xj="int(np.random.uniform(0,img.shape[0]))" img[xj,xi,0]="255" *np.random.rand() img[xj,xi,1]="255" img[xj,xi,2]="255" fn="pictest.png" fn1="pictestt1.png" fn2="pictestt2.png" myimg="cv2.imread(fn)" myimg1="cv2.imread(fn1)" myimg2="cv2.imread(fn2)" addnoise(myimg) cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.变形图像匹配</span><br><span class="line"></span><br><span class="line">欧氏距离方法不仅对强噪声图像匹配有效，而且对变形后的图像匹配效果也不错。如图10-8所示就是应用欧氏距离方法对有倾斜角度的图像进行匹配的效果。</span><br><span class="line"></span><br><span class="line">![](Image00426.jpg)</span><br><span class="line"></span><br><span class="line">图10-8 倾斜图像匹配效果图</span><br><span class="line"></span><br><span class="line">算法原理前面已经解说过，在此不重复。相关的Python代码实现如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-5.py
    #图像倾斜后定位图像


    import cv2
    import numpy as np
    print 'loading  ...'
    def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))  
    def findpic(img,findimg,h,fh,w,fw):
        minds=1e8
        mincb_h=0
        mincb_w=0
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                my_img=img[now_h:now_h+fh,now_w:now_w+fw,:]
                my_findimg=findimg  
                dis=get_EuclideanDistance(my_img,my_findimg)
                if dis<minds: mincb_h="now_h" mincb_w="now_w" minds="dis" print ".", findpt="mincb_w,mincb_h" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(0,0,255)) return img def showpiclocation(img,findimg): #定位图像 w="img.shape[1]" h="img.shape[0]" fw="findimg.shape[1]" fh="findimg.shape[0]" findpic(img,findimg,h,fh,w,fw) fn="pictestxz.png" fn1="pictestt1.png" fn2="pictestt2.png" myimg="cv2.imread(fn)" myimg1="cv2.imread(fn1)" myimg2="cv2.imread(fn2)" cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">欧氏距离对弱噪声环境下的变形图像仍有不错的效果，如图10-9所示。</span><br><span class="line"></span><br><span class="line">![](Image00427.jpg)</span><br><span class="line"></span><br><span class="line">图10-9 弱噪声变形图像匹配</span><br><span class="line"></span><br><span class="line">该算法的Python实现代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-6.py
    #图像倾斜后加噪声点，定位图像


    import cv2
    import numpy as np
    print 'loading  ...'
    def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))  
    def findpic(img,findimg,h,fh,w,fw):
        minds=1e8
        mincb_h=0
        mincb_w=0
        for now_h in xrange(0,h-fh):
            for now_w in xrange(0,w-fw):
                my_img=img[now_h:now_h+fh,now_w:now_w+fw,:]
                my_findimg=findimg  
                dis=get_EuclideanDistance(my_img,my_findimg)
                if dis<minds: mincb_h="now_h" mincb_w="now_w" minds="dis" print ".", findpt="mincb_w,mincb_h" cv2.rectangle(img, findpt, (findpt[0]+fw,findpt[1]+fh),(0,0,255)) return img def showpiclocation(img,findimg): #定位图像 w="img.shape[1]" h="img.shape[0]" fw="findimg.shape[1]" fh="findimg.shape[0]" findpic(img,findimg,h,fh,w,fw) addnoise(img): coutn="50000" for k in xrange(0,coutn): xi="int(np.random.uniform(0,img.shape[1]))" xj="int(np.random.uniform(0,img.shape[0]))" img[xj,xi,0]="255" *np.random.rand() img[xj,xi,1]="255" img[xj,xi,2]="255" fn="pictestxz.png" fn1="pictestt1.png" fn2="pictestt2.png" myimg="cv2.imread(fn)" myimg1="cv2.imread(fn1)" myimg2="cv2.imread(fn2)" addnoise(myimg) cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 10.3 图像分类</span><br><span class="line"></span><br><span class="line">近年来随着多媒体技术的发展，图像分类技术受到了普遍的关注，目前采用的方法以机器学习算法为主。图像分类利用计算机对图像进行分析，根据图像信息的不同特征，将不同类别的图像区分开来。</span><br><span class="line"></span><br><span class="line">图像分类的算法过程如下：</span><br><span class="line"></span><br><span class="line">1）准备样本图像。样本图像的要求是：能代表所属类别中尽可能多的图像。</span><br><span class="line"></span><br><span class="line">2）提取每个样本的特征后，形成类别特征码。</span><br><span class="line"></span><br><span class="line">3）应用机器学习算法对类别特征码进行学习，提取特征码包含的图像知识。</span><br><span class="line"></span><br><span class="line">4）判断未知图像所属类别。</span><br><span class="line"></span><br><span class="line">#### 10.3.1 余弦相似度</span><br><span class="line"></span><br><span class="line">余弦相似度通过测量两个向量内积空间的夹角的余弦值来度量它们之间的相似性，尤其适用于任何维度的向量比较中，因此属于高维空间应用较多的机器学习算法。通常来说，数字图像包含的特征码较多，而这些特征组就属于高维空间，这正是余弦相似度算法应用的范围，算法将每个图像的特征组转化为高维空间的向量，两个向量之间的角度之余弦值可用于确定两个向量是否大致指向相同的方向。</span><br><span class="line"></span><br><span class="line">在图像分类中应用余弦相似度算法的关键在于：计算这些代表每个图像特征的向量的内积空间的夹角余弦值，从而度量图像之间的相似性。对于相似性的衡量标准有以下两种：</span><br><span class="line"></span><br><span class="line">·为相似性设置一个阈值。在这个阈值以内的都属于同一类别图像。这种标准可以将图像划分为多种类型，例如：高楼不但属于城市美景，而且属于写字楼景观。</span><br><span class="line"></span><br><span class="line">·选择与样本向量的余弦相似度最接近1的图像为该类别图像。这种标准只能将图像划分为一种类别。</span><br><span class="line"></span><br><span class="line">1.算法描述</span><br><span class="line"></span><br><span class="line">下面针对第二种衡量标准讲解余弦相似度算法。</span><br><span class="line"></span><br><span class="line">特征提取一直是图像处理和计算机视觉研究领域中一个值得探讨的问题，在计算机科学、医疗辅助诊断、军事、工业测量等众多领域都广泛采用这一技术，尤其是在计算机视觉和模式识别的研究中。如何准确定位和提取关键特征往往是首先需要解决的问题之一，是提高识别率等问题的重要前期准备和关键因素。目前图像特征提取算法较多，不同的算法适应于不同的图像分析任务。</span><br><span class="line"></span><br><span class="line">本节讲述的算法基本原理是：把图像上的点分为不同的子集，这些子集往往属于孤立的点、连续的曲线或者连续的区域。将这些点按区域组成子集，提取子集的特征后，将每个子集的特征作为图像的一个特征项来进行计算。</span><br><span class="line"></span><br><span class="line">1）样本特征。设图像分为m个区域，每个区域有n个像素，每个像素在图像矩阵中以红、绿、蓝三色来表示，且区域特征计算方式为：</span><br><span class="line"></span><br><span class="line">![](Image00428.jpg)</span><br><span class="line"></span><br><span class="line">那么，样本特征码矩阵为3×m，即共3行m列，这3行分别代表红、绿、蓝三个分量，每列为各分量的区域特征码。</span><br><span class="line"></span><br><span class="line">2）类别特征。这里为每个类别准备了3个样本，类别特征的计算方式为：</span><br><span class="line"></span><br><span class="line">![](Image00429.jpg)</span><br><span class="line"></span><br><span class="line">其中，样本i是属于该类别的样本。</span><br><span class="line"></span><br><span class="line">在计算出类别特征后，算法对样本学习完毕。当有未知图像需要分类时，首先计算其图像的样本特征，然后将样本特征和类别特征映射为高维空间的向量，最后计算这两个向量的余弦相似度，选择余弦相似度最大的类别为未知图像对应的类别。</span><br><span class="line"></span><br><span class="line">2.算法应用</span><br><span class="line"></span><br><span class="line">下面以风景图像分类为例说明余弦相似度的应用。为每个类别各准备3个样本图像，提取类别特征码，然后将如图10-10~图10-12所示的3个待分类图像划分到蓝天风景、树林风景、瀑布风景这3个分类中。</span><br><span class="line"></span><br><span class="line">![](Image00430.jpg)</span><br><span class="line"></span><br><span class="line">图10-10 蓝天风景</span><br><span class="line"></span><br><span class="line">3.Python实现</span><br><span class="line"></span><br><span class="line">1）将图10-10~图10-12分别从上到下、从左到右分割成若干块状区域，对每块区域的图像像素特征进行提取后，形成这3个待分类图像的特征码。下面的代码所示的函数readpic定义了分割并提取特征码的操作，以待分类图像为参数调用该函数，完成特征码计算。</span><br><span class="line"></span><br><span class="line">![](Image00431.jpg)</span><br><span class="line"></span><br><span class="line">图10-11 树林风景</span><br><span class="line"></span><br><span class="line">![](Image00432.jpg)</span><br><span class="line"></span><br><span class="line">图10-12 瀑布风景</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(800,600))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/w_fg
        h_interval=h/h_fg 
        alltz=[]
        alltz.append([])
        alltz.append([])
        alltz.append([])
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz[0].append(btz)
                alltz[1].append(gtz)
                alltz[2].append(rtz)
        return alltz <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）计算类别特征码。通过每个类别所有样本的区域特征的平均值，提取类别特征。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #读取图像，提取每类图像的特征


    for ii in xrange(1,picflag+1):
        smp_x=[]
        b_tz=np.array([0,0,0])
        g_tz=np.array([0,0,0])
        r_tz=np.array([0,0,0])
        mytz=np.zeros((3,w_fg*h_fg))
        for jj in xrange(1,3):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            tmptz=readpic(fn)
            mytz+=np.array(tmptz)
        mytz/=3
        train_x.append(mytz[0].tolist()+mytz[1].tolist()+mytz[2].tolist()) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）计算待分类图像的特征码与每个类别特征码之间的余弦距离，距离最大者为图像所属分类。下面的代码计算了ptest3.png图像与每个类别特征码的余弦相似度。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    fn='ptest3.png'
    testtz=np.array(readpic(fn))
    simtz=testtz[0].tolist()+testtz[1].tolist()+testtz[2].tolist()
    maxtz=0
    nowi=0
    for i in xrange(0,picflag):
        nowsim=get_cossimi(train_x[i],simtz)
        if nowsim>maxtz:
            maxtz=nowsim
            nowi=i        
    print u'%s属于第

    %d类

    '%(fn,nowi+1) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-7.py
    #余弦距离识别图像类型


    import numpy as np
    import cv2
    print u'正在处理中

    '
    w_fg=20
    h_fg=15
    picflag=3
    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(800,600))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/w_fg
        h_interval=h/h_fg 
        alltz=[]
        alltz.append([])
        alltz.append([])
        alltz.append([])
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz[0].append(btz)
                alltz[1].append(gtz)
                alltz[2].append(rtz)
        return alltz
    def get_cossimi(x,y):
        myx=np.array(x)
        myy=np.array(y)
        cos1=np.sum(myx*myy)
        cos21=np.sqrt(sum(myx*myx))
        cos22=np.sqrt(sum(myy*myy))
        return cos1/float(cos21*cos22)
    #x和

    d样本初始化


    train_x =[]
    d=[]
    #读取图像，提取每类图像的特征


    for ii in xrange(1,picflag+1):
        smp_x=[]
        b_tz=np.array([0,0,0])
        g_tz=np.array([0,0,0])
        r_tz=np.array([0,0,0])
        mytz=np.zeros((3,w_fg*h_fg))
        for jj in xrange(1,3):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            tmptz=readpic(fn)
            mytz+=np.array(tmptz)
        mytz/=3
        train_x.append(mytz[0].tolist()+mytz[1].tolist()+mytz[2].tolist())
    fn='ptest3.png'
    testtz=np.array(readpic(fn))
    simtz=testtz[0].tolist()+testtz[1].tolist()+testtz[2].tolist()
    maxtz=0
    nowi=0
    for i in xrange(0,picflag):
        nowsim=get_cossimi(train_x[i],simtz)
        if nowsim>maxtz:
            maxtz=nowsim
            nowi=i        
    print u'%s属于第

    %d类

    '%(fn,nowi+1)
    fn='ptest1.png'
    testtz=np.array(readpic(fn))
    simtz=testtz[0].tolist()+testtz[1].tolist()+testtz[2].tolist()
    maxtz=0
    nowi=0
    for i in xrange(0,picflag):
        nowsim=get_cossimi(train_x[i],simtz)
        if nowsim>maxtz:
            maxtz=nowsim
            nowi=i        
    print u'%s属于第

    %d类

    '%(fn,nowi+1)
    fn='ptest2.png'
    testtz=np.array(readpic(fn))
    simtz=testtz[0].tolist()+testtz[1].tolist()+testtz[2].tolist()
    maxtz=0
    nowi=0
    for i in xrange(0,picflag):
        nowsim=get_cossimi(train_x[i],simtz)
        if nowsim>maxtz:
            maxtz=nowsim
            nowi=i        
    print u'%s属于第

    %d类

    '%(fn,nowi+1) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行上述代码，观察下面的运行结果，可见对算法任务中列举的图像识别效果不错。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    正在处理中


    ptest3.png属于第

    3类


    ptest1.png属于第

    1类


    ptest2.png属于第

    2类

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">本节中每个类别仅使用了3个样本，基于余弦相似度的算法在样本量较小的情况下，效果其实不是最佳的。例如：在测试图像中加入另一张测试图，要用基于余弦相似度算法将它分类，那会怎样？修改10-7.py，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-8.py
    #余弦距离识别图像类型，有一张图像不能正确识别


    import numpy as np
    import cv2
    print u'正在处理中

    '
    .......
    .......
    fn='ptest22.png'
    testtz=np.array(readpic(fn))
    simtz=testtz[0].tolist()+testtz[1].tolist()+testtz[2].tolist()
    maxtz=0
    nowi=0
    for i in xrange(0,picflag):
        nowsim=get_cossimi(train_x[i],simtz)
        if nowsim>maxtz:
            maxtz=nowsim
            nowi=i        
    print u'%s属于第

    %d类

    '%(fn,nowi+1) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    正在处理中


    ptest3.png属于第

    3类


    ptest1.png属于第

    1类


    ptest2.png属于第

    2类


    ptest22.png属于第

    3类

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从上述结果看，图像ptest22.png（如图10-13所示）被错误地分到了第三类，实际它属于第二类树林风景图像。</span><br><span class="line"></span><br><span class="line">![](Image00433.jpg)</span><br><span class="line"></span><br><span class="line">图10-13 待分类图像</span><br><span class="line"></span><br><span class="line">#### 10.3.2 PCA图像特征提取算法</span><br><span class="line"></span><br><span class="line">PCA算法基于变量协方差矩阵对信息进行压缩和处理，通常用于数据降维，可将它用于图像矩阵降维，以降维后的矩阵为基础提取图像特征。当提取的图像特征维度比较高时，为了简化计算量以及存储空间，需要对这些高维数据进行一定程度上的降维，并尽量保证数据不失真。此外，PCA算法还可应用于图像矩阵，它能找到变化大的维，去除掉那些变化不大的维，这样能更有效地提取图像明显特征，便于后期识别算法并进一步加工，因为图像特征组含有的不明显的特征值将会影响识别的精度。</span><br><span class="line"></span><br><span class="line">应用PCA降维技术，对上节讲述的图像特征码算法进行改进，返回图像特征码。下面是用Python实现的基于PCA的图像特征码算法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(500,400))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/20
        h_interval=h/10    
        alltz=[]
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):            
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz.append([btz,gtz,rtz])
        result_alltz=np.array(alltz).T
        pca = mlpy.PCA() 
        pca.learn(result_alltz) 
        result_alltz = pca.transform(result_alltz, k=len(result_alltz)/2)   
        result_alltz =result_alltz.reshape(len(result_alltz))
        return result_alltz   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下一节的神经网络与SVM图像分类算法将基于本节描述的PCA技术提取图像特征码，然后进一步分析和计算，得到图像所属类别。</span><br><span class="line"></span><br><span class="line">#### 10.3.3 基于神经网络的图像分类</span><br><span class="line"></span><br><span class="line">基于神经网络的图像分类算法比余弦相似度分类算法的普适性更好，准确率更高。</span><br><span class="line"></span><br><span class="line">1.算法描述</span><br><span class="line"></span><br><span class="line">神经网络图像分类算法首先通过PCA技术提取样本图像特征码与待分类图像特征码，然后将特征码送入神经网络进行训练，让神经网络学习每个类别图像的特征，最后将未知类别图像送入神经网络，自动识别它的类型。其步骤如下：</span><br><span class="line"></span><br><span class="line">1）基于PCA技术提取每个样本的图像特征码。</span><br><span class="line"></span><br><span class="line">2）根据样本特征码生成输入项，根据样本所属类别生成对应的输出项。</span><br><span class="line"></span><br><span class="line">3）将输入与输出项送入非线性神经网络训练。</span><br><span class="line"></span><br><span class="line">4）基于PCA技术生成待分类图像的特征码。</span><br><span class="line"></span><br><span class="line">5）将待分类图像的特征码送入神经网络仿真测试，根据神经网络输出项判断其所属类别。</span><br><span class="line"></span><br><span class="line">2.输出目标设计</span><br><span class="line"></span><br><span class="line">神经网络的输出目标以及输出函数的设计应本着灵活实用的原则。在本例中，神经网络的输出值为3个图像类别，用数字1~3来表示，但不能直接将数字作为目标输出值。常用的表示方式有以下几种。</span><br><span class="line"></span><br><span class="line">·将数字转换为1以内的小数。比如：乘以输出值的最大数的倒数进行调整等。</span><br><span class="line"></span><br><span class="line">·按照二进制编码的思路，将其设计为如下形式：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    1:[0,0,1]
    2:[0,1,0]
    3:[0,1,1] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">或者，设计为以下格式（本例采用这种格式）：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    1:[0,0,1]
    2:[0,1,0]
    3:[1,0,0] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">输出函数的设计原则是：将输出目标值转化为实际样本的输出值格式。本例中将其定义为：</span><br><span class="line"></span><br><span class="line">神经网络输出值=输出目标值的最大值所在的数组索引</span><br><span class="line"></span><br><span class="line">3.Python实现</span><br><span class="line"></span><br><span class="line">下面来看看图像特征码计算，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(500,400))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/20
        h_interval=h/10    
        alltz=[]
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):            
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz.append([btz,gtz,rtz])
        result_alltz=np.array(alltz).T
        pca = mlpy.PCA() 
        pca.learn(result_alltz) 
        result_alltz = pca.transform(result_alltz, k=len(result_alltz)/2)   
        result_alltz =result_alltz.reshape(len(result_alltz))
        return result_alltz <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">接着是输入与输出项初始化。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #x和

    d样本初始化


    train_x =[]
    d=[]
    sp_d=[]
    sp_d.append([0,0,1])
    sp_d.append([0,1,0])
    sp_d.append([1,0,0])
    #读取图片


    for ii in xrange(1,4):
        for jj in xrange(1,4):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            pictz=readpic(fn)
            train_x.append(pictz)
            d.append(sp_d[ii-1])
    myinput=np.array(train_x) 
    mytarget=np.array(d) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">下面来看看训练效果。误差曲线如图10-14所示。</span><br><span class="line"></span><br><span class="line">![](Image00434.jpg)</span><br><span class="line"></span><br><span class="line">图10-14 误差曲线</span><br><span class="line"></span><br><span class="line">程序运行后，识别效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    训练神经网络完毕

    对样本进行测试


    [1, 1, 1, 2, 2, 2, 3, 3, 3]进行仿真


    ===ptest3.png===
    [[ 0.96680714  0.00471284 -0.04523491]]
    [3]
    ===ptest1.png===
    [[ 0.10858063 -0.00820875  0.95785349]]
    [1]
    ===ptest2.png===
    [[ 0.01738297  0.99945777 -0.01017012]]
    [2]
    ===ptest21.png===
    [[ 0.95422417  0.00308943  0.12213834]]
    [3]
    ===ptest22.png===
    [[-0.26776152  0.99953727 -0.12122857]]
    [2] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后几行表明，无法被余弦相似度正确分类的ptest22.png被神经网络分类成功，但ptest21.png（如图10-15所示）被错误分类。因为神经网络与SVM的不同之处在于，神经网络训练需要更多的样本进行训练（本例仅使用3个样本），否则不一定能取得更好的识别效果。</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">![](Image00435.jpg)</span><br><span class="line"></span><br><span class="line">图10-15 错误分类的图像</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-9.py
    #PCA加上人工神经网络识别图像类型


    import numpy as np
    import pylab as pl
    import neurolab as nl
    import cv2
    import mlpy
    print u'正在处理中

    '
    def getresult(simjg):
        jg=[]
        for j in xrange(0,len(simjg)):
            maxjg=-2
            nowii=0
            for i in xrange(0,len(simjg[0])):
                if simjg[j][i]>maxjg:
                    maxjg=simjg[j][i]
                    nowii=i
            jg.append(len(simjg[0])-nowii)
        return jg
    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(500,400))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/20
        h_interval=h/10    
        alltz=[]
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):            
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz.append([btz,gtz,rtz])
        result_alltz=np.array(alltz).T
        pca = mlpy.PCA() 
        pca.learn(result_alltz) 
        result_alltz = pca.transform(result_alltz, k=len(result_alltz)/2)   
        result_alltz =result_alltz.reshape(len(result_alltz))
        return result_alltz   
    #x和

    d样本初始化


    train_x =[]
    d=[]
    sp_d=[]
    sp_d.append([0,0,1])
    sp_d.append([0,1,0])
    sp_d.append([1,0,0])
    #读取图像


    for ii in xrange(1,4):
        for jj in xrange(1,4):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            pictz=readpic(fn)
            train_x.append(pictz)
            d.append(sp_d[ii-1])
    myinput=np.array(train_x) 
    mytarget=np.array(d)
    mymax=np.max(myinput)
    netminmax=[]
    for i in xrange(0,len(myinput[0])):
        netminmax.append([0,mymax])
    print u'\n正在建立神经网络

    '
    bpnet = nl.net.newff(netminmax, [5, 3])
    print u'\n训练神经网络中

    ...'
    err = bpnet.train(myinput, mytarget, epochs=800, show=5, goal=0.2)
    if err[len(err)-1]>0.4:
        print u'\n训练神经网络失败

    ...\n'
    else:
        print u'\n训练神经网络完毕

    '        
        pl.subplot(111)
        pl.plot(err)  
        pl.xlabel('Epoch number')
        pl.ylabel('error (default SSE)')
        print u"对样本进行测试

    "
        simd= bpnet.sim(myinput)
        mysimd=getresult(simd)
        print mysimd
        print u"进行仿真

    "
        testpictz=np.array([readpic('ptest3.png')])
        simtest=bpnet.sim(testpictz) 
        mysimtest=getresult(simtest)
        print "===ptest3.png==="
        print simtest
        print mysimtest
        testpictz=np.array([readpic('ptest1.png')])
        simtest=bpnet.sim(testpictz)
        mysimtest=getresult(simtest)
        print "===ptest1.png==="
        print simtest
        print mysimtest   
        testpictz=np.array([readpic('ptest2.png')])
        simtest=bpnet.sim(testpictz)
        mysimtest=getresult(simtest)
        print "===ptest2.png==="
        print simtest
        print mysimtest     
        testpictz=np.array([readpic('ptest21.png')])
        simtest=bpnet.sim(testpictz)
        mysimtest=getresult(simtest)
        print "===ptest21.png==="
        print simtest
        print mysimtest      
        testpictz=np.array([readpic('ptest22.png')])
        simtest=bpnet.sim(testpictz)
        mysimtest=getresult(simtest)
        print "===ptest22.png==="
        print simtest
        print mysimtest
        pl.show() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 10.3.4 基于SVM的图像分类</span><br><span class="line"></span><br><span class="line">在样本量少的情况下，SVM分类的效果是最佳的。SVM算法相比神经网络的优势在于：只需要少量样本，就能达到较高的识别精度。</span><br><span class="line"></span><br><span class="line">1.算法描述</span><br><span class="line"></span><br><span class="line">SVM图像分类算法首先通过PCA技术提取样本图像特征码与待分类图像特征码，然后将特征码送入SVM进行训练，学习每个类别图像的特征，最后将未知类别图像送入SVM仿真测试，自动识别它的类型。步骤如下：</span><br><span class="line"></span><br><span class="line">1）基于PCA技术提取每个样本的图像特征码。</span><br><span class="line"></span><br><span class="line">2）根据样本特征码生成输入项，根据样本所属类别生成对应的输出项。</span><br><span class="line"></span><br><span class="line">3）将输入与输出项送入SVM训练。</span><br><span class="line"></span><br><span class="line">4）基于PCA技术生成待分类图像的特征码。</span><br><span class="line"></span><br><span class="line">5）将待分类图像的特征码送入SVM仿真测试，根据SVM输出项判断其所属类别。</span><br><span class="line"></span><br><span class="line">其中，SVM的输出目标可以直接使用类别序号（在本例中为数字1~3）。</span><br><span class="line"></span><br><span class="line">2.Python实现</span><br><span class="line"></span><br><span class="line">1）输入与输出项的初始化。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #x和

    d样本初始化


    train_x =[]
    d=[]
    #读取图像，提取每类图像的特征


    for ii in xrange(1,picflag+1):
        smp_x=[]
        mytz=np.zeros((3,w_fg*h_fg))
        for jj in xrange(1,4):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            tmptz=readpic(fn)
            train_x.append(tmptz.tolist())
            d.append(ii) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）SVM训练与仿真训练。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x=np.array(train_x)
    y=np.array(d)
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly',gamma=50)
    svm.learn(x, y)
    print svm.pred(x) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）识别效果。如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     正在处理中


    [ 1.  1.  1.  2.  2.  2.  3.  3.  3.]
    ptest3.png属于第

    3类


    ptest1.png属于第

    1类


    ptest2.png属于第

    2类


    ptest21.png属于第

    2类


    ptest22.png属于第

    2类

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">相对神经网络而言，在每个类别仅有3个样本的情况下，所有的测试图像得到了正确的分类。</span><br><span class="line"></span><br><span class="line">以下是完整的代码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #10-10.py
    #PCA加上

    SVM识别图像类型


    import numpy as np
    import cv2
    import mlpy
    print u'正在处理中

    '
    w_fg=10
    h_fg=5
    picflag=3
    def readpic(fn):
        #返回图像特征码


        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(400,200))
        w=img.shape[1]  
        h=img.shape[0]  
        w_interval=w/w_fg
        h_interval=h/h_fg 
        alltz=[]
        for now_h in xrange(0,h,h_interval):
            for now_w in xrange(0,w,w_interval):            
                b = img[now_h:now_h+h_interval,now_w:now_w+w_interval,0]
                g = img[now_h:now_h+h_interval,now_w:now_w+w_interval,1]
                r = img[now_h:now_h+h_interval,now_w:now_w+w_interval,2]
                btz=np.mean(b)
                gtz=np.mean(g)
                rtz=np.mean(r)
                alltz.append([btz,gtz,rtz])
        result_alltz=np.array(alltz).T
        pca = mlpy.PCA() 
        pca.learn(result_alltz) 
        result_alltz = pca.transform(result_alltz, k=len(result_alltz)/2)   
        result_alltz =result_alltz.reshape(len(result_alltz))
        return result_alltz  
    #x和

    d样本初始化


    train_x =[]
    d=[]
    #读取图像，提取每类图像的特征


    for ii in xrange(1,picflag+1):
        smp_x=[]   
        mytz=np.zeros((3,w_fg*h_fg))
        for jj in xrange(1,4):
            fn='p'+str(ii)+'-'+str(jj)+'.png'
            tmptz=readpic(fn)
            train_x.append(tmptz.tolist())
            d.append(ii)
    x=np.array(train_x)
    y=np.array(d)
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly',gamma=50)
    svm.learn(x, y)
    print svm.pred(x)
    fn='ptest3.png'
    testtz=np.array(readpic(fn))
    nowi=svm.pred(testtz)     
    print u'%s属于第

    %d类

    '%(fn,nowi)
    fn='ptest1.png'
    testtz=np.array(readpic(fn))
    nowi=svm.pred(testtz)       
    print u'%s属于第

    %d类

    '%(fn,nowi)      
    fn='ptest2.png'
    testtz=np.array(readpic(fn))
    nowi=svm.pred(testtz)      
    print u'%s属于第

    %d类

    '%(fn,nowi)
    fn='ptest21.png'
    testtz=np.array(readpic(fn))
    nowi=svm.pred(testtz)      
    print u'%s属于第

    %d类

    '%(fn,nowi)
    fn='ptest22.png'
    testtz=np.array(readpic(fn))
    nowi=svm.pred(testtz)      
    print u'%s属于第

    %d类

    '%(fn,nowi) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 10.4 高斯噪声生成</span><br><span class="line"></span><br><span class="line">噪声可理解为妨碍人们的感觉器官去正确理解所接收的信源信息的因素，图像中各种会妨碍人们接受其信息的因素都可称为图像噪声，噪声在理论上可以定义为“不可预测，只能用概率统计的方法来认识的随机误差”。图像噪声在数字图像处理技术中的重要性越来越明显。图像噪声按其产生的原因可以分为：</span><br><span class="line"></span><br><span class="line">1）外部噪声。指系统外部的干扰以电磁波或经电源串进系统内部而引起的噪声。如电气设备、天体放电现象等引起的噪声。</span><br><span class="line"></span><br><span class="line">2）内部噪声。一般可分为以下四种：</span><br><span class="line"></span><br><span class="line">·由光和电的基本性质所引起的噪声。如电流的产生是由电子或空穴粒子的集合，定向运动所形成的。</span><br><span class="line"></span><br><span class="line">·电器的机械运动产生的噪声。如各种接头因抖动引起电流的变化所产生的噪声；磁头、磁带等抖动或仪器的抖动等。</span><br><span class="line"></span><br><span class="line">·器材材料本身引起的噪声。如正片和负片的表面颗粒性和磁带磁盘表面的缺陷所产生的噪声。</span><br><span class="line"></span><br><span class="line">·系统内部设备电路所引起的噪声。如电源引入的交流噪声；偏转系统和箝位电路所引起的噪声等。</span><br><span class="line"></span><br><span class="line">既然噪声是不可避免，那么在图像处理的过程中，为检验图像算法的有效性，需要人为地生成一些噪声来模拟现实的环境。</span><br><span class="line"></span><br><span class="line">下面以加性零均值高斯噪声为例，通过在灰度图上加上这类高斯噪声进行噪声仿真。具体方法是：在每个点的灰度值上加上一个噪声值，噪声值的产生方式为Box-Muller算法生成高斯噪声。Box-Muller方法是产生随机数的一种方法，算法隐含的原理非常深奥，但是结果却相当简单。它一般是要得到服从正态分布的随机数，基本思想是先得到服从均匀分布的随机数，再将服从均匀分布的随机数转变为服从正态分布。Box-Muller算法的具体过程如下：</span><br><span class="line"></span><br><span class="line">1）假设图像的灰阶范围是［0，G-1］。取σ&gt;0：它的值越小时，相应的噪声也越小。</span><br><span class="line"></span><br><span class="line">2）针对每对水平相邻的像素（x，y），（x，y+1）产生一对位于［0，1］的独立随机数r和Φ。</span><br><span class="line"></span><br><span class="line">3）计算以下值：</span><br><span class="line"></span><br><span class="line">![](Image00436.jpg)</span><br><span class="line"></span><br><span class="line">上式中，Z1 是Z2 独立的有0均值和σ方差的正态分布。</span><br><span class="line"></span><br><span class="line">4）设g为输入图像，计算以下值：</span><br><span class="line"></span><br><span class="line">![](Image00437.jpg)</span><br><span class="line"></span><br><span class="line">5）计算f(x，y)和f(x，y+1)的值：</span><br><span class="line"></span><br><span class="line">![](Image00438.jpg)</span><br><span class="line"></span><br><span class="line">![](Image00439.jpg)</span><br><span class="line"></span><br><span class="line">6）反复执行第3至第5步，直到像素点处理完毕为止。</span><br><span class="line"></span><br><span class="line">下面以Python代码来实现对某图像的加高斯噪声的操作，如程序10-11.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #加性零均值高斯噪声


    #code:myhaspl@myhaspl.com  
    #10-11.py
    import cv2  
    import numpy as np  
    fn="test112.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
        param=30  
        #灰阶范围


        grayscale=256  
        w=img.shape[1]  
        h=img.shape[0]  
        newimg=np.zeros((h,w),np.uint8)  
        for x in xrange(0,h):  
            for y in xrange(0,w,2):  
                r1=np.random.random_sample()  
                r2=np.random.random_sample()  
                z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))  
                z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))  
                fxy=int(img[x,y]+z1)  
                fxy1=int(img[x,y+1]+z2)         
                #f(x,y)  
                if fxy<0: fxy_val="0" elif fxy>grayscale-1:  
                    fxy_val=grayscale-1  
                else:  
                    fxy_val=fxy  
                #f(x,y+1)  
                if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:  
                    fxy1_val=grayscale-1  
                else:  
                    fxy1_val=fxy1  
                newimg[x,y]=fxy_val  
                newimg[x,y+1]=fxy1_val  
        cv2.imshow('preview',newimg)  
        cv2.waitKey()  
        cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序10-11.py，结果如图10-16所示。</span><br><span class="line"></span><br><span class="line">![](Image00440.jpg)</span><br><span class="line"></span><br><span class="line">图10-16 灰度图像高斯噪声</span><br><span class="line"></span><br><span class="line">程序10-12.py实现了对彩色图像增加高斯噪声，代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #加性零均值高斯噪声


    #code:myhaspl@myhaspl.com
    #10-12.py
    import cv2
    import numpy as np
    fn="test112.jpg"
    myimg=cv2.imread(fn)
    img=myimg
    param=30
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w,3),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))        
            fxy_0=int(img[x,y,0]+z1)
            fxy1_0=int(img[x,y+1,0]+z2)  
            fxy_1=int(img[x,y,1]+z1)
            fxy1_1=int(img[x,y+1,1]+z2)  
            fxy_2=int(img[x,y,2]+z1)
            fxy1_2=int(img[x,y+1,2]+z2)          
            #f(x,y)
            if fxy_0<0: fxy_val_0="0" elif fxy_0>grayscale-1:
                fxy_val_0=grayscale-1
            else:
                fxy_val_0=fxy_0
            if fxy_1<0: fxy_val_1="0" elif fxy_1>grayscale-1:
                fxy_val_1=grayscale-1
            else:
                fxy_val_1=fxy_1
            if fxy_2<0: fxy_val_2="0" elif fxy_2>grayscale-1:
                fxy_val_2=grayscale-1
            else:
                fxy_val_2=fxy_2
            #f(x,y+1)
            if fxy1_0<0: fxy1_val_0="0" elif fxy1_0>grayscale-1:
                fxy1_val_0=grayscale-1
            else:
                fxy1_val_0=fxy1_0
            if fxy1_1<0: fxy1_val_1="0" elif fxy1_1>grayscale-1:
                fxy1_val_1=grayscale-1
            else:
                fxy1_val_1=fxy1_1
            if fxy1_2<0: fxy1_val_2="0" elif fxy1_2>grayscale-1:
                fxy1_val_2=grayscale-1
            else:
                fxy1_val_2=fxy1_2 
            newimg[x,y,0]=fxy_val_0
            newimg[x,y,1]=fxy_val_1
            newimg[x,y,2]=fxy_val_2
            newimg[x,y+1,0]=fxy1_val_0
            newimg[x,y+1,1]=fxy1_val_1
            newimg[x,y+1,2]=fxy1_val_2
    cv2.imshow('preview',newimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序10-12.py在彩色图像中人为地增加了若干高斯噪声，运行程序，效果如图10-17所示。</span><br><span class="line"></span><br><span class="line">![](Image00441.jpg)</span><br><span class="line"></span><br><span class="line">图10-17 彩色图像加高斯噪声</span><br><span class="line"></span><br><span class="line">### 10.5 二值化</span><br><span class="line"></span><br><span class="line">图像的二值化，就是将图像上像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的只有黑和白的视觉效果，最常用的方法就是设定一个阈值T，用T将图像的数据分成两部分：大于T的像素群和小于T的像素群。</span><br><span class="line"></span><br><span class="line">#### 10.5.1 threshold</span><br><span class="line"></span><br><span class="line">可调用OpenCV的threshold实现二值化，Python调用此方法的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.threshold(src, thresh, maxval, type[, dst]) →

     retval, dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该方法主要有以下核心参数：</span><br><span class="line"></span><br><span class="line">·src：输入数组（单通道、8位或32位）。</span><br><span class="line"></span><br><span class="line">·dst：二值化输出结果的矩阵。</span><br><span class="line"></span><br><span class="line">·thresh：阈值。</span><br><span class="line"></span><br><span class="line">·maxval：二值化中除0以外的其他值。</span><br><span class="line"></span><br><span class="line">·type：二值化类别。主要有以下几种：</span><br><span class="line"></span><br><span class="line">·THRESH_BINARY</span><br><span class="line"></span><br><span class="line">![](Image00442.jpg)</span><br><span class="line"></span><br><span class="line">·THRESH_BINARY_INV</span><br><span class="line"></span><br><span class="line">![](Image00443.jpg)</span><br><span class="line"></span><br><span class="line">·THRESH_TRUNC</span><br><span class="line"></span><br><span class="line">![](Image00444.jpg)</span><br><span class="line"></span><br><span class="line">·THRESH_TOZERO</span><br><span class="line"></span><br><span class="line">![](Image00445.jpg)</span><br><span class="line"></span><br><span class="line">·THRESH_TOZERO_INV</span><br><span class="line"></span><br><span class="line">![](Image00446.jpg)</span><br><span class="line"></span><br><span class="line">编写程序10-13.py，对某图像进行二值化，效果如图10-18所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #10-13.py
    import cv2  
    fn="test3.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    retval, newimg=cv2.threshold(img,40,255,cv2.THRESH_BINARY)  
    cv2.imshow('preview',newimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 10.5.2 adaptiveThreshold</span><br><span class="line"></span><br><span class="line">OpenCV的adaptiveThreshold函数可完成自适应二值化，也可以提取边缘。Python调用此方法的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数的核心参数如下：</span><br><span class="line"></span><br><span class="line">·block_size：决定局部阈值的block的大小，block很小时，如block_size=3、5、7时，表现为边缘提取函数。当把block_size设为比较大的值时，如block_size=21、51等，就是二值化。</span><br><span class="line"></span><br><span class="line">·src：输入数组（单通道、8位或32位）。</span><br><span class="line"></span><br><span class="line">·dst：二值化输出结果的矩阵。</span><br><span class="line"></span><br><span class="line">·thresholdType：二值化类型，为THRESH_BINARY或THRESH_BINARY_INV，见10.5.1节对该参数的说明。</span><br><span class="line"></span><br><span class="line">编写程序10-14.py，进行二值化，效果如图10-19所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #10-14.py
    import cv2 
    fn="test3.jpg" 
    myimg=cv2.imread(fn) 
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY) 
    newimg=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,5,2) 
    cv2.imshow('preview',newimg) 
    cv2.waitKey() 
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00447.jpg)</span><br><span class="line"></span><br><span class="line">图10-18 二值化</span><br><span class="line"></span><br><span class="line">![](Image00448.jpg)</span><br><span class="line"></span><br><span class="line">图10-19 adaptiveThreshold二值化</span><br><span class="line"></span><br><span class="line">程序10-15.py演示了通过二值化提取边缘，效果如图10-20所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #10-15.py
    import cv2
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    newimg=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,2)
    cv2.imshow('preview',newimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00449.jpg)</span><br><span class="line"></span><br><span class="line">图10-20 二值化提取边缘</span><br><span class="line"></span><br><span class="line">### 10.6 插值与缩放</span><br><span class="line"></span><br><span class="line">通过OpenCV的resize函数可实现插值与缩放。Python调用该函数的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数的interpolation参数可分别设为INTER_NEAREST（最近邻插值）、INTER_LINEAR（双线性插值）、INTER_AREA（像素关系重采样）、INTER_CUBIC（双立方插值）、INTER_LANCZOS4（8×8像素邻域内Lanczos插值）。</span><br><span class="line"></span><br><span class="line">程序10-16.py演示了插值与缩放的操作，效果如图10-21所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #10-16.py
    import cv2  
    fn="test112.jpg"  
    img=cv2.imread(fn)  
    w=img.shape[1]    
    h=img.shape[0]    
    #放大

    ,双立方插值


    newimg1=cv2.resize(img,(w*2,h*2),interpolation=cv2.INTER_CUBIC)  
    #放大

    , 最近邻插值


    newimg2=cv2.resize(img,(w*2,h*2),interpolation=cv2.INTER_NEAREST)  
    #放大

    , 像素关系重采样


    newimg3=cv2.resize(img,(w*2,h*2),interpolation=cv2.INTER_AREA)  
    #缩小

    , 像素关系重采样


    newimg4=cv2.resize(img,(300,200),interpolation=cv2.INTER_AREA)  
    cv2.imshow('preview1',newimg1)  
    cv2.imshow('preview2',newimg2)  
    cv2.imshow('preview3',newimg3)  
    cv2.imshow('preview4',newimg4)  
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00450.jpg)</span><br><span class="line"></span><br><span class="line">图10-21 插值与缩放</span><br><span class="line"></span><br><span class="line">### 10.7 仿射</span><br><span class="line"></span><br><span class="line">#### 10.7.1 仿射原理</span><br><span class="line"></span><br><span class="line">仿射变换，又称仿射映射，是指在几何中，一个向量空间进行一次线性变换并接上一个平移，变换为另一个向量空间，它可对图像进行缩放、旋转、平衡等操作。</span><br><span class="line"></span><br><span class="line">一个对向量![](Image00451.jpg) 平移![](Image00452.jpg) ，与旋转放大缩小A的仿射映射为：</span><br><span class="line"></span><br><span class="line">![](Image00453.jpg)</span><br><span class="line"></span><br><span class="line">上式在齐次坐标上，等价于下面的式子：</span><br><span class="line"></span><br><span class="line">![](Image00454.jpg)</span><br><span class="line"></span><br><span class="line">为了表示仿射变换，需要使用齐次坐标，即用三维向量（x，y，1）表示二维向量，对于高维来说也是如此。按照这种方法，就可以用矩阵乘法表示变换。x′=x+tx</span><br><span class="line">；y′=y+ty 变为</span><br><span class="line"></span><br><span class="line">![](Image00455.jpg)</span><br><span class="line"></span><br><span class="line">在矩阵中增加一列与一行，除右下角的元素为1外其他部分均填充为0，通过这种方法，所有的线性变换都可以转换为仿射变换。例如，上面的旋转矩阵可变为</span><br><span class="line"></span><br><span class="line">![](Image00456.jpg)</span><br><span class="line"></span><br><span class="line">通过这种方法，使用与前面一样的矩阵乘积可以将各种变换无缝地集成到一起。</span><br><span class="line"></span><br><span class="line">#### 10.7.2 仿射变换实例</span><br><span class="line"></span><br><span class="line">1.warpAffine</span><br><span class="line"></span><br><span class="line">OpenCV的warpAffine函数可实现仿射变换，Python调用此方法的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.warpAffine(src, M, dsize[, dst[, f?lags[, borderMode[, borderValue]]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数中的参数M表示变换矩阵。函数使用以下变换公式：</span><br><span class="line"></span><br><span class="line">dst(x，y)=src(M11 x+M12 y+M13 ，M21 x+M22 y+M23 )</span><br><span class="line"></span><br><span class="line">2.getRotationMatrix2D</span><br><span class="line"></span><br><span class="line">OpenCV的getRotationMatrix2D函数计算二维旋转变换矩阵，Python调用此函数的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.getRotationMatrix2D(center, angle, scale) →

     retval <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00457.jpg)</span><br><span class="line"></span><br><span class="line">其中，α与β的计算公式如下：</span><br><span class="line"></span><br><span class="line">α=scale·cos angle</span><br><span class="line"></span><br><span class="line">β=scale·sin angle</span><br><span class="line"></span><br><span class="line">程序10-17.py演示了仿射变换完成缩小并旋转的操作，效果如图10-22所示。</span><br><span class="line"></span><br><span class="line">![](Image00458.jpg)</span><br><span class="line"></span><br><span class="line">图10-22 仿射变换</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #10-17.py
    import cv2  
    fn="test3.jpg"  
    img=cv2.imread(fn)  
    w=img.shape[1]    
    h=img.shape[0]    
    #得到仿射变换矩阵，完成旋转


    #中心


    mycenter=(h/2,w/2)  
    #旋转角度


    myangle=90  
    #缩放尺度


    myscale=0.5  
    #仿射变换完成缩小并旋转


    transform_matrix=cv2.getRotationMatrix2D(mycenter,myangle,myscale)  
    newimg=cv2.warpAffine(img,transform_matrix,(w,h))  
    cv2.imshow('preview',newimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows()  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 10.8 透视投影与透视变换</span><br><span class="line"></span><br><span class="line">#### 10.8.1 透视投影原理</span><br><span class="line"></span><br><span class="line">三维计算机图形学中另外一种重要的变换是透视投影。与平行投影沿着平行线将物体投影到图像平面上不同，透视投影是指从投影中心这一点发出的直线将物体投影到图像平面上。这就意味着距离投影中心越远的投影越小，距离越近的投影越大。</span><br><span class="line"></span><br><span class="line">最简单的透视投影是将投影中心作为坐标原点，z=1作为图像平面，这样投影变换为；![](Image00459.jpg) ，用齐次坐标表示如下：</span><br><span class="line"></span><br><span class="line">![](Image00460.jpg)</span><br><span class="line"></span><br><span class="line">上述乘法的计算结果是（xc ，yc ，zc ，wc ）=（x，y，z，z）。乘法计算完毕之后，通常齐次元素wc 并不为1，所以为了映射回真实平面需要进行齐次除法，即每个元素都除以wc ：</span><br><span class="line"></span><br><span class="line">![](Image00461.jpg)</span><br><span class="line"></span><br><span class="line">更加复杂的透视投影可以与旋转、缩放、平移、切变等组合在一起对图像进行变换。</span><br><span class="line"></span><br><span class="line">#### 10.8.2 透视投影实例</span><br><span class="line"></span><br><span class="line">1.WarpPerspective</span><br><span class="line"></span><br><span class="line">OpenCV提供了WarpPerspective函数，可对图像进行透视变换。Python调用此函数的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数的主要参数如下：</span><br><span class="line"></span><br><span class="line">·map_matrix：3×3变换矩阵。</span><br><span class="line"></span><br><span class="line">·flags：插值方法和以下开关选项的组合，有以下两种：</span><br><span class="line"></span><br><span class="line">·CV_WARP_FILL_OUTLIERS：填充所有缩小图像的像素。如果部分像素落在输入图像的边界外，那么它们的值设定为fillval。</span><br><span class="line"></span><br><span class="line">·CV_WARP_INVERSE_MAP：指定matrix是输出图像到输入图像的反变换，因此可以直接用来做像素插值。否则，函数从map_matrix得到反变换。</span><br><span class="line"></span><br><span class="line">·fillval：用来填充边界外面的值。</span><br><span class="line"></span><br><span class="line">该函数对源图像进行转换的计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00462.jpg)</span><br><span class="line"></span><br><span class="line">2.GetPerspectiveTransform</span><br><span class="line"></span><br><span class="line">OpenCV提供了GetPerspectiveTransform函数，以四边形的4个点计算透射变换。Python调用该函数的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.getPerspectiveTransform(src, dst) →

     retval <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数的主要参数如下：</span><br><span class="line"></span><br><span class="line">·src：输入IDR的四边形顶点坐标。</span><br><span class="line"></span><br><span class="line">·dst：输出的相应的四边形顶点坐标。</span><br><span class="line"></span><br><span class="line">该函数对3×3的透射变换矩阵的计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00463.jpg)</span><br><span class="line"></span><br><span class="line">3.透射变换矩阵计算实例</span><br><span class="line"></span><br><span class="line">程序10-18.py演示了如何计算透射变换矩阵。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #10-18.py
    import cv2
    import numpy as np
    fn="test112.jpg"
    img=cv2.imread(fn)
    w=img.shape[1]  
    h=img.shape[0]  
    #得到透射变换矩阵


    src=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype = np.float32)
    dst=np.array([[w*0.08,h*0.01],[w*0.8,h*0.25],[w*0.8,h*0.9],[w*0.05,h*0.8]],dtype = np.float32)
    transform_matrix=cv2.getPerspectiveTransform(src,dst)  
    #输出透射变换矩阵


    print transform_matrix  
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序10-18.py，输出透射变换矩阵，结果如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    [[  8.98634886e-01  -5.70473560e-02   5.12000008e+01]
     [  1.66413868e-01   7.60111420e-01   3.59999990e+00]
     [  3.46695559e-04  -1.11420617e-04   1.00000000e+00]] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4.透射变换实例</span><br><span class="line"></span><br><span class="line">程序10-19.py演示了透射变换，效果如图10-23所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #10-19.py
    import cv2
    import numpy as np
    fn="test112.jpg"
    img=cv2.imread(fn)
    w=img.shape[1]  
    h=img.shape[0]  
    #得到透射变换矩阵


    src=np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype = np.float32)
    dst=np.array([[w*0.08,h*0.01],[w*0.8,h*0.25],[w*0.8,h*0.9],[w*0.05,h*0.8]],dtype = np.float32)
    transform_matrix=cv2.getPerspectiveTransform(src,dst)
    print transform_matrix
    #透射变换完成变形


    newimg=cv2.warpPerspective(img,transform_matrix,(w,h))
    cv2.imshow('preview',newimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00464.jpg)</span><br><span class="line"></span><br><span class="line">图10-23 透射变换</span><br><span class="line"></span><br><span class="line">### 10.9 灰度变换与图像增强</span><br><span class="line"></span><br><span class="line">#### 10.9.1 灰度变换概述</span><br><span class="line"></span><br><span class="line">在计算机领域中，灰度（Gray Scale）数字图像是每个像素只有一个采样颜色的图像。这类图像通常显示为从最暗黑色到最亮的白色的灰度，尽管理论上这个采样可以是不同深浅的任何颜色，甚至可以是不同亮度上的不同颜色。灰度图像与黑白图像不同，在计算机图像领域中黑白图像只有黑白两种颜色，灰度图像在黑色与白色之间还有很多级的颜色深度。用于显示的灰度图像通常用每个采样像素8位的非线性尺度来保存，这样就可以有256种灰度（即2的8次方=256）了。这种精度刚刚能够避免可见的条带失真，并且非常易于编程。灰度图像是一种具有从黑到白256级灰度色阶或等级的单色图像。该图像中的每个像素均用8位数据表示，因此像素点值介于黑白间的256种灰度中的一种。该图像只有灰度等级，没有颜色的变化。</span><br><span class="line"></span><br><span class="line">灰度变换是基于点操作的增强方法，它将每一个像素的灰度值按照一定的数学变换公式转换为一个新的灰度值，它能增强图像，扩展图像的对比度，使图像变清晰，使其特征更加突出，灰度非线性变换是指将灰度数据按照经验数据或某种算术非线性关系进行变换后再显示。灰度变换是基于点操作的增强方法，它将每一个像素的灰度值按照一定的数学变换公式转换为一个新的灰度值，如增强处理中的对比度增强。</span><br><span class="line"></span><br><span class="line">#### 10.9.2 对数变换</span><br><span class="line"></span><br><span class="line">对数变换对图像的低亮度区有较大的扩展而对高亮度区进行压缩，简言之就是增强了低值灰度的图像细节，灰度非线性变换公式如下：</span><br><span class="line"></span><br><span class="line">dst=Clog(1+src)</span><br><span class="line"></span><br><span class="line">程序10-20.py演示了对数变换，效果如图10-24所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #10-20.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    jg_img=np.array(40*np.log(img+1),np.uint8)
    cv2.imshow('src',img)
    cv2.imshow('dst',jg_img)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00465.jpg)</span><br><span class="line"></span><br><span class="line">图10-24 对数变换</span><br><span class="line"></span><br><span class="line">观察图10-24，左边的是经过非线性变换操作的图，右边的是原图，左边的低亮度区更清晰。</span><br><span class="line"></span><br><span class="line">#### 10.9.3 分段线性变换</span><br><span class="line"></span><br><span class="line">分段线性变换将图像的值域分成多个值域并进行不同的线性变换计算，可以压缩某部分灰度区，扩展另一部分灰度区间，下面以两个区间为例，编写程序进行变换，如程序10-21.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #分段线性变换


    #code:myhaspl@myhaspl.com
    #10-21.py
    import cv2
    import numpy as np
    fn="test4.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    #源


    Ds_min=0
    Ds_internal=80#中间


    Ds_max=255
    #目标


    Dd_min=0
    Dd_internal=160#中间


    Dd_max=255
    for m in xrange(h):
        for n in xrange(w):
            if img[m,n]>Ds_min and img[m,n]<=ds_internal: newimg[m,n]="int((Dd_internal-Dd_min)/(Ds_internal-Ds_min)*(img[m,n]-Ds_min)+Dd_min)" else: print ".", cv2.imshow('src',img) cv2.imshow('dst',newimg) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-25，左边是经过分段线性变换的图像，右边是原图像，通过压缩高亮度区，扩展低亮度区，使图像的比对度变得更强。</span><br><span class="line"></span><br><span class="line">![](Image00466.jpg)</span><br><span class="line"></span><br><span class="line">图10-25 分段线性变换</span><br><span class="line"></span><br><span class="line">程序10-21.py的代码中，各变量的含义如下：</span><br><span class="line"></span><br><span class="line">·Ds_min为源区段的最小值域。</span><br><span class="line"></span><br><span class="line">·Ds_internal为源区段的中间分界值。</span><br><span class="line"></span><br><span class="line">·Ds_max为源区段的最大值域。</span><br><span class="line"></span><br><span class="line">·Dd_min为目标区段的最小值域。</span><br><span class="line"></span><br><span class="line">·Dd_internal为目标区段的中间分界值。</span><br><span class="line"></span><br><span class="line">·Dd_max为目标区段的最大值域。</span><br><span class="line"></span><br><span class="line">#### 10.9.4 指数变换</span><br><span class="line"></span><br><span class="line">指数变换的作用是扩展图像的高灰度级、压缩低灰度级，可用于亮度过高的图像。指数变换的基本表达式如下：</span><br><span class="line"></span><br><span class="line">y=bc(x-a) -1</span><br><span class="line"></span><br><span class="line">其中，参数b、c控制曲线的变换形状，参数a控制曲线的位置。指数变换与对数变换的关系如图10-26所示。</span><br><span class="line"></span><br><span class="line">程序10-22.py演示了对太阳图像进行指数变换，使低亮度区（温度较低的区域）不再显示，突出亮度区（温度较高的区域），效果如图10-27所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    # -*-coding: utf-8 -*-  
    #指数非线性变换


    #code:myhaspl@myhaspl.com
    #10-22.py
    import cv2
    import numpy as np
    fn="test5.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    b=1.2
    c=0.2
    a=0.2
    newimg=np.array(np.power(b,c*(img-a))-1,np.uint8)
    cv2.imshow('src',img)
    cv2.imshow('dst',newimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00467.jpg)</span><br><span class="line"></span><br><span class="line">图10-26 指数变换与对数变换</span><br><span class="line"></span><br><span class="line">![](Image00468.jpg)</span><br><span class="line"></span><br><span class="line">图10-27 指数变换</span><br><span class="line"></span><br><span class="line">观察图10-27，左边是指数变换后生成的图，右边是原图，左图的高亮度区显示得到突出，达到了预期的效果。</span><br><span class="line"></span><br><span class="line">#### 10.9.5 直方图均衡化</span><br><span class="line"></span><br><span class="line">直方图均衡化通常用来增加许多图像的全局对比度，尤其是当图像的有用数据的对比度相当接近的时候。通过这种方法，亮度可以更好地在直方图上分布。这样就可以用于增强局部的对比度而不影响整体的对比度。在灰度图像上使用直方图均衡化的方法如下：</span><br><span class="line"></span><br><span class="line">设有一灰度图像，让ni 表示灰度i出现的次数，这样图像中灰度为i的像素出现的概率如下：</span><br><span class="line"></span><br><span class="line">![](Image00469.jpg)</span><br><span class="line"></span><br><span class="line">其中，L是图像中所有的灰度数，n是图像中所有的像素数，p实际上是图像的直方图，归一化到0..1。把c作为对应于p的累计概率函数，定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00470.jpg)</span><br><span class="line"></span><br><span class="line">其中，c是图像的累计归一化直方图。</span><br><span class="line"></span><br><span class="line">然后，创建一个形式为y=T(x)的变化，对于原始图像中的每个值它都产生一个y，这样y的累计概率函数就可以在所有值范围内进行线性化，转换公式定义如下：</span><br><span class="line"></span><br><span class="line">![](Image00471.jpg)</span><br><span class="line"></span><br><span class="line">上式中，T将不同的等级映射到0..1域，为了将这些值映射回它们最初的域，需要在结果上应用下面的简单变换：</span><br><span class="line"></span><br><span class="line">![](Image00472.jpg)</span><br><span class="line"></span><br><span class="line">此外，可将上述方法分别用于图像RGB颜色值的红色、绿色和蓝色分量，实现对彩色图像的直方图均衡化。</span><br><span class="line"></span><br><span class="line">Python可调用OpenCV的equalizeHist函数实现直方图均衡化，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.equalizeHist(src[, dst]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序10-23.py演示了直方图均衡化，效果如图10-28所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #10-23.py
    import cv2  
    fn="test1.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    newimg=cv2.equalizeHist(img)  
    cv2.imshow('src',img)  
    cv2.imshow('dst',newimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows()   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00473.jpg)</span><br><span class="line"></span><br><span class="line">图10-28 直方图均衡化</span><br><span class="line"></span><br><span class="line">观察图10-28，右边是原图，左边是经过增强化的图。</span><br><span class="line"></span><br><span class="line">再看程序10-24.py，该程序实现了直方图均衡化的具体算法，效果如图10-29所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #直方图均衡化


    #10-24.py
    import cv2
    import numpy as np
    fn="test5.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    h=img.shape[0]
    w=img.shape[1]
    newimg=np.zeros((h,w),np.uint8)
    scount=0.0
    #原始图像灰度级


    scol={}
    #目标图像灰度级


    dcol={}
    #原始图像频度


    Ps={}
    #累计概率


    Cs={}
    #统计原始图像灰度级


    for m in xrange(h):
        for n in xrange(w):
            scol[img[m,n]]=scol.setdefault(img[m,n],0)+1
            scount+=1
    #计算原始图像频度


    for key in scol:
        Ps[key]=scol[key]/scount
    #计算图像灰度的离散随机变量累计概率


    keys=Ps.keys()
    keys.sort()
    for skey in scol:
        Cs.setdefault(skey,0)
        for key in keys:
            if key>skey :
                break            
            Cs[skey]+=Ps[key]
     #建立输入与输出之间的映射


    d_max=np.max(keys)
    d_min=np.min(keys)
    for skey in keys:
        dcol[skey]=int((d_max-d_min)*Cs[skey]+d_min)
    for m in xrange(h):
        for n in xrange(w):
            newimg[m,n]=dcol[img[m,n]]
    cv2.imshow('src',img)
    cv2.imshow('dst',newimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00474.jpg)</span><br><span class="line"></span><br><span class="line">图10-29 直方图均衡化</span><br><span class="line"></span><br><span class="line">观察图10-29，左图为均衡化后的图，右边为原图，左图的全局对比度增强了。</span><br><span class="line"></span><br><span class="line">### 10.10 图像滤波与除噪</span><br><span class="line"></span><br><span class="line">#### 10.10.1 均一化块滤波</span><br><span class="line"></span><br><span class="line">H(x，y)根据作用域（3×3、5×5、7×7等）的不同而不同。假设为3×3，则有9个像素参加运算。可以有以下几种：</span><br><span class="line"></span><br><span class="line">![](Image00475.jpg)</span><br><span class="line"></span><br><span class="line">OpenCV提供的blur函数可进行归一化块滤波操作，Python调用该函数的格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.blur(src, ksize[, dst[, anchor[, borderType]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，该函数使用了如下脉冲响应函数（也称为核函数）：</span><br><span class="line"></span><br><span class="line">![](Image00476.jpg)</span><br><span class="line"></span><br><span class="line">1.高斯噪声滤波</span><br><span class="line"></span><br><span class="line">程序10-25.py演示了归一化块滤波对高斯噪声的处理，效果如图10-30所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #归一化块滤波


    #10-25.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
    #滤波去噪


    lbimg=cv2.blur(newimg,(3,3))
    cv2.imshow('src',newimg)
    cv2.imshow('dst',lbimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00477.jpg)</span><br><span class="line"></span><br><span class="line">图10-30 归一化块滤波</span><br><span class="line"></span><br><span class="line">观察图10-30，左边为经过归一化块滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">当然，也可以使用第3个脉冲响应函数，如下：</span><br><span class="line"></span><br><span class="line">![](Image00478.jpg)</span><br><span class="line"></span><br><span class="line">程序10-26.py演示了使用第3个脉冲响应函数，应用归一化块滤波对高斯噪声进行处理，效果如图10-31所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #归一化块滤波


    #10-26.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
        print "-",
    #滤波去噪


    #图像四个边的像素处理


    lbimg=np.zeros((h+2,w+2),np.float32)
    tmpimg=np.zeros((h+2,w+2))
    myh=h+2
    myw=w+2
    tmpimg[1:myh-1,1:myw-1]=newimg[0:myh,0:myw]
    #用第

    3个脉冲响应函数


    a=1/16.0
    kernel=a*np.array([[1,2,1],[2,4,2],[1,2,1]])
    for y in xrange(1,myh-1):
        for x in xrange(1,myw-1):
            lbimg[y,x]=np.sum(kernel*tmpimg[y-1:y+2,x-1:x+2])
        print ".",
    resultimg=np.array(lbimg[1:myh-1,1:myw-1],np.uint8)        
    cv2.imshow('src',newimg)
    cv2.imshow('dst',resultimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-31，左图为归一化块滤波后的效果，右图为原图，左图去除噪声的效果较好。</span><br><span class="line"></span><br><span class="line">2.椒盐噪声滤波</span><br><span class="line"></span><br><span class="line">归一化块滤波对椒盐噪声仍有一定的滤波效果，但需要将作用域扩大（比如：设成5×5），图像会更模糊，效果较好。</span><br><span class="line"></span><br><span class="line">程序10-27.py演示了应用归一化块滤波对椒盐噪声进行处理，效果如图10-32所示。</span><br><span class="line"></span><br><span class="line">![](Image00479.jpg)</span><br><span class="line"></span><br><span class="line">图10-31 用第3个脉冲响应函数归一化块滤波</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #归一化块滤波


    #10-27.py
    import cv2  
    import numpy as np  
    fn="test3.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    #加上椒盐噪声


    #灰阶范围


    w=img.shape[1]  
    h=img.shape[0]  
    newimg=np.array(img)  
    #噪声点数量


    noisecount=100000  
    for k in xrange(0,noisecount):  
        xi=int(np.random.uniform(0,newimg.shape[1]))  
        xj=int(np.random.uniform(0,newimg.shape[0]))  
        newimg[xj,xi]=255  
    #滤波去噪


    lbimg=cv2.blur(newimg,(5,5))  
    cv2.imshow('src',newimg)  
    cv2.imshow('dst',lbimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-32，左边为经过滤波后的图，右边为原图，去噪效果较好。</span><br><span class="line"></span><br><span class="line">![](Image00480.jpg)</span><br><span class="line"></span><br><span class="line">图10-32 归一化块滤波对椒盐噪声进行处理</span><br><span class="line"></span><br><span class="line">#### 10.10.2 邻域平均法</span><br><span class="line"></span><br><span class="line">邻域平均法可有效消除高斯噪声，其数学公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00481.jpg)</span><br><span class="line"></span><br><span class="line">S为邻域，不包括（x，y）本身的像素点，核h(x，y)可为：</span><br><span class="line"></span><br><span class="line">半径为1：</span><br><span class="line"></span><br><span class="line">![](Image00482.jpg)</span><br><span class="line"></span><br><span class="line">半径为2：</span><br><span class="line"></span><br><span class="line">![](Image00483.jpg)</span><br><span class="line"></span><br><span class="line">程序10-28.py演示了邻域平均法对椒盐噪声滤波进行处理的操作，效果如图10-33所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #领域平均法滤波

    3*3
    #10-28.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上椒盐噪声


    param=20
    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #噪声点数量


    noisecount=100000
    for k in xrange(0,noisecount):
        xi=int(np.random.uniform(0,newimg.shape[1]))
        xj=int(np.random.uniform(0,newimg.shape[0]))
        newimg[xj,xi]=255
    #领域平均法去噪


    #脉冲响应函数，核函数


    #图像四个边的像素处理


    lbimg=np.zeros((h+2,w+2),np.float32)
    tmpimg=np.zeros((h+2,w+2))
    myh=h+2
    myw=w+2
    tmpimg[1:myh-1,1:myw-1]=newimg[0:myh,0:myw]
    #用领域平均法的（设半径为

    2）脉冲响应函数


    a=1/8.0
    kernel=a*np.array([[1,1,1],[1,0,1],[1,1,1]])
    for y in xrange(1,myh-1):
        for x in xrange(1,myw-1):
            lbimg[y,x]=np.sum(kernel*tmpimg[y-1:y+2,x-1:x+2])
        print ".",
    resultimg=np.array(lbimg[1:myh-1,1:myw-1],np.uint8)        
    cv2.imshow('src',newimg)
    cv2.imshow('dst',resultimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00484.jpg)</span><br><span class="line"></span><br><span class="line">图10-33 邻域平均法对椒盐噪声滤波</span><br><span class="line"></span><br><span class="line">观察图10-33，左边为经过滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">程序10-29.py演示了邻域平均法对高斯噪声进行滤波的操作，效果如图10-34所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #领域平均法滤波


    #10-29.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
        print "-",
    #领域平均法去噪


    #脉冲响应函数，核函数


    #图像四个边的像素处理


    lbimg=np.zeros((h+2,w+2),np.float32)
    tmpimg=np.zeros((h+2,w+2))
    myh=h+2
    myw=w+2
    tmpimg[1:myh-1,1:myw-1]=newimg[0:myh,0:myw]
    #用领域平均法的（设半径为

    2）脉冲响应函数


    a=1/8.0
    kernel=a*np.array([[1,1,1],[1,0,1],[1,1,1]])
    for y in xrange(1,myh-1):
        for x in xrange(1,myw-1):
            lbimg[y,x]=np.sum(kernel*tmpimg[y-1:y+2,x-1:x+2])
        print ".",
    resultimg=np.array(lbimg[1:myh-1,1:myw-1],np.uint8)        
    cv2.imshow('src',newimg)
    cv2.imshow('dst',resultimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00485.jpg)</span><br><span class="line"></span><br><span class="line">图10-34 邻域平均法对高斯噪声滤波</span><br><span class="line"></span><br><span class="line">观察图10-34，左边为经过滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">#### 10.10.3 中值滤波</span><br><span class="line"></span><br><span class="line">中值滤波与邻域平均法类似，但计算的是中值，而不是平均值。具体算法是：将图像的每个像素用邻域（以当前像素为中心的正方形区域）像素的中值来代替。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #中值滤波


    #10-30.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上椒盐噪声


    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #噪声点数量


    noisecount=50000
    for k in xrange(0,noisecount):
        xi=int(np.random.uniform(0,newimg.shape[1]))
        xj=int(np.random.uniform(0,newimg.shape[0]))
        newimg[xj,xi]=255
    #滤波去噪


    #脉冲响应函数，核函数


    #图像四个边的像素处理


    lbimg=np.zeros((h+2,w+2),np.float32)
    tmpimg=np.zeros((h+2,w+2))
    myh=h+2
    myw=w+2
    tmpimg[1:myh-1,1:myw-1]=newimg[0:myh,0:myw]
    #用中值法


    for y in xrange(1,myh-1):
        for x in xrange(1,myw-1):
            lbimg[y,x]=np.median(tmpimg[y-1:y+2,x-1:x+2])
        print ".",
    resultimg=np.array(lbimg[1:myh-1,1:myw-1],np.uint8)        
    cv2.imshow('src',newimg)
    cv2.imshow('dst',resultimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-35可发现，中值滤波忽略了较高阶灰度和较低阶灰度，直接取中值，可以有效地过滤椒盐噪声。</span><br><span class="line"></span><br><span class="line">![](Image00486.jpg)</span><br><span class="line"></span><br><span class="line">图10-35 中值滤波</span><br><span class="line"></span><br><span class="line">此外，也可以在Python中调用OpenCV的medianBlur函数实现中值滤波，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.medianBlur(src, ksize[, dst]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序10-31.py演示了medianBlur函数实现中值滤波的操作过程，效果如图10-36所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #中值滤波


    #10-31.py
    import cv2  
    import numpy as np  
    fn="test3.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    #加上椒盐噪声


    #灰阶范围


    w=img.shape[1]  
    h=img.shape[0]  
    newimg=np.array(img)  
    #噪声点数量


    noisecount=50000  
    for k in xrange(0,noisecount):  
        xi=int(np.random.uniform(0,newimg.shape[1]))  
        xj=int(np.random.uniform(0,newimg.shape[0]))  
        newimg[xj,xi]=255  
    #滤波去噪


    lbimg=cv2.medianBlur(newimg,3)  
    cv2.imshow('src',newimg)  
    cv2.imshow('dst',lbimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows()   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00487.jpg)</span><br><span class="line"></span><br><span class="line">图10-36 medianBlur函数实现的中值滤波</span><br><span class="line"></span><br><span class="line">观察图10-36，左边为经过中值滤波后的图，右边为原图，滤波效果很好。</span><br><span class="line"></span><br><span class="line">当然，也可以使用中值滤波方法对高斯噪声进行滤波，程序10-32.py演示了该操作，效果如图10-37所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #中值滤波


    #10-32.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
    #滤波去噪


    lbimg=cv2.medianBlur(newimg,3)
    cv2.imshow('src',newimg)
    cv2.imshow('dst',lbimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00488.jpg)</span><br><span class="line"></span><br><span class="line">图10-37 对高斯噪声进行中值滤波</span><br><span class="line"></span><br><span class="line">观察图10-37，左边为经过中值滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">#### 10.10.4 高斯滤波</span><br><span class="line"></span><br><span class="line">高斯滤波是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到的。高斯滤波的具体操作是：用一个模板（或称卷积、掩模）扫描图像中的每一个像素，用模板确定的邻域内像素的加权平均灰度值去替代模板中心像素点的值。</span><br><span class="line"></span><br><span class="line">Python可调用OpenCV的GaussianBlur函数进行高斯滤波，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序10-33.py演示了高斯滤波，效果如图10-38所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #高斯滤波


    #10-33.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
    #滤波去噪


    lbimg=cv2.GaussianBlur(newimg,(3,3),1.8)
    cv2.imshow('src',newimg)
    cv2.imshow('dst',lbimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-38，左边为经过滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">![](Image00489.jpg)</span><br><span class="line"></span><br><span class="line">图10-38 高斯滤波</span><br><span class="line"></span><br><span class="line">#### 10.10.5 双边滤波</span><br><span class="line"></span><br><span class="line">双边滤波（Bilateral Filter）是一种非线性的滤波方法，是结合图像的空间邻近度和像素值相似度的一种折衷处理方法，同时考虑空域信息和灰度相似性，达到保边去噪的目的。具有简单、非迭代、局部的特点。</span><br><span class="line"></span><br><span class="line">Python可调用OpenCV的bilateralFilter函数来实现，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">该函数的核心参数如下：</span><br><span class="line"></span><br><span class="line">·d：滤波时像素邻域的直径，d为负时由sigaColor计算得到；d&gt;5时不能实时处理。</span><br><span class="line"></span><br><span class="line">·sigmaColor、sigmaSpace表示颜色空间和坐标空间的滤波系数sigma，可简单的赋值为相同的值，其值小于10时几乎没有效果；其值大于150时为油画效果。</span><br><span class="line"></span><br><span class="line">程序10-34.py演示了双边滤波对椒盐噪声的滤波，效果如图10-39所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #双边滤波


    #10-34.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #加上椒盐噪声


    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #噪声点数量


    noisecount=50000
    for k in xrange(0,noisecount):
        xi=int(np.random.uniform(0,newimg.shape[1]))
        xj=int(np.random.uniform(0,newimg.shape[0]))
        newimg[xj,xi]=255
    #滤波去噪


    lbimg=cv2.bilateralFilter(newimg,5,140,140)
    cv2.imshow('src',newimg)
    cv2.imshow('dst',lbimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00490.jpg)</span><br><span class="line"></span><br><span class="line">图10-39 双边滤波对椒盐噪声的滤波</span><br><span class="line"></span><br><span class="line">观察图10-39，左边为经过滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">程序10-35.py演示了双边滤波对高斯噪声的滤波，效果如图10-40所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-  
    #code:myhaspl@myhaspl.com
    #双边滤波


    #11-35.py
    import cv2
    import numpy as np
    fn="test3.jpg"
    myimg=cv2.imread(fn)
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)
    #灰阶范围


    w=img.shape[1]
    h=img.shape[0]
    newimg=np.array(img)
    #加上高斯噪声


    param=20
    #灰阶范围


    grayscale=256
    w=img.shape[1]
    h=img.shape[0]
    newimg=np.zeros((h,w),np.uint8)
    for x in xrange(0,h):
        for y in xrange(0,w,2):
            r1=np.random.random_sample()
            r2=np.random.random_sample()
            z1=param*np.cos(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            z2=param*np.sin(2*np.pi*r2)*np.sqrt((-2)*np.log(r1))
            fxy=int(img[x,y]+z1)
            fxy1=int(img[x,y+1]+z2)       
            #f(x,y)
            if fxy<0: fxy_val="0" elif fxy>grayscale-1:
                fxy_val=grayscale-1
            else:
                fxy_val=fxy
            #f(x,y+1)
            if fxy1<0: fxy1_val="0" elif fxy1>grayscale-1:
                fxy1_val=grayscale-1
            else:
                fxy1_val=fxy1
            newimg[x,y]=fxy_val
            newimg[x,y+1]=fxy1_val
    #滤波去噪


    lbimg=cv2.bilateralFilter(newimg,3,140,140)
    cv2.imshow('src',newimg)
    cv2.imshow('dst',lbimg)
    cv2.waitKey()
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-40，左边为经过滤波后的图，右边为原图，滤波效果较好。</span><br><span class="line"></span><br><span class="line">#### 10.10.6 卷积滤波</span><br><span class="line"></span><br><span class="line">卷积滤波的基本思想是：将卷积核矩阵的中心依次放在图像矩阵的每一个像素的位置上，将卷积核的每一个元素分别和图像矩阵对应位置的元素相乘，最终将乘积累加起来，作为卷积结果。如图10-41所示。</span><br><span class="line"></span><br><span class="line">![](Image00491.jpg)</span><br><span class="line"></span><br><span class="line">图10-40 双边滤波对高斯噪声的滤波</span><br><span class="line"></span><br><span class="line">![](Image00492.jpg)</span><br><span class="line"></span><br><span class="line">图10-41 卷积滤波</span><br><span class="line"></span><br><span class="line">可在Python中使用OpenCV的filter2D函数进行卷积滤波，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序10-36.py演示了卷积滤波对图像的锐化处理，效果如图10-42所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #卷积滤波


    #code:myhaspl@myhaspl.com 
    #10-36.py
    import cv2 
    import numpy as np 
    fn="test112.jpg" 
    myimg=cv2.imread(fn) 
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY) 
    myh=np.array([[0,1,0],[1,-4,1],[0,1,0]]) 
    jgimg=cv2.filter2D(img,-1,myh) 
    cv2.imshow('src',img) 
    cv2.imshow('dst',jgimg) 
    cv2.waitKey() 
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察图10-42，左边是经过滤波处理的图，右边是原图，锐化效果不错。</span><br><span class="line"></span><br><span class="line">程序10-37.py演示了拉普拉斯算子进行二维卷积计算，对图像进行锐化处理，效果如图10-43所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #10-37.py
    import cv2 
    import numpy as np 
    from scipy import signal 
    fn="test6.jpg" 
    myimg=cv2.imread(fn) 
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY) 
    srcimg=np.array(img,np.double) 
    myh=np.array([[0,1,0],[1,-4,1],[0,1,0]]) 
    myj=signal.convolve2d(srcimg,myh,mode="same") 
    jgimg=img-myj 
    cv2.imshow('src',img) 
    cv2.imshow('dst',jgimg) 
    cv2.waitKey() 
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00493.jpg)</span><br><span class="line"></span><br><span class="line">图10-42 卷积滤波对图像的锐化处理</span><br><span class="line"></span><br><span class="line">![](Image00494.jpg)</span><br><span class="line"></span><br><span class="line">图10-43 拉普拉斯算子进行二维卷积</span><br><span class="line"></span><br><span class="line">观察图10-43，左边是原图，右边是经过锐化后的图像，锐化效果较好。</span><br><span class="line"></span><br><span class="line">#### 10.10.7 边缘检测</span><br><span class="line"></span><br><span class="line">1.Laplacian</span><br><span class="line"></span><br><span class="line">可在Python中调用OpenCV的Laplacian函数进行边缘检测，调用格式如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) →

     dst <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">当该函数的ksize参数大于1时，Sobel算子计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00495.jpg)</span><br><span class="line"></span><br><span class="line">此外，当ksize=1时，对图像采用如下内核做卷积：</span><br><span class="line"></span><br><span class="line">![](Image00496.jpg)</span><br><span class="line"></span><br><span class="line">程序10-38.py演示了拉普拉斯边缘检测，效果如图10-44所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #线性锐化滤波，拉普拉斯图像变换


    #code:myhaspl@myhaspl.com  
    #10-38.py
    import cv2  
    fn="test6.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    jgimg=cv2.Laplacian(img,-1)  
    cv2.imshow('src',img)  
    cv2.imshow('dst',jgimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows()   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00497.jpg)</span><br><span class="line"></span><br><span class="line">图10-44 拉普拉斯边缘检测</span><br><span class="line"></span><br><span class="line">观察图10-44，左边是原图，右边是经过滤波后的图像，边缘被成功提取，将右图进行反转（黑色变白色，白色变黑色，用255减去图像矩阵）后，可得到更好的效果。</span><br><span class="line"></span><br><span class="line">2.sobel非线性滤波</span><br><span class="line"></span><br><span class="line">sobel非线性滤波采用梯度模的近似方式提取边缘，锐化图像。</span><br><span class="line"></span><br><span class="line">程序10-39.py演示了sobel非线性滤波，效果如图10-45所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #非线性锐化滤波，

    sobel算子变换


    #code:myhaspl@myhaspl.com  
    #10-39.py
    import cv2  
    fn="test6.jpg"  
    myimg=cv2.imread(fn)  
    img=cv2.cvtColor(myimg,cv2.COLOR_BGR2GRAY)  
    jgimg=cv2.Sobel(img,0,1,1)  
    cv2.imshow('src',img)  
    cv2.imshow('dst',jgimg)  
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00498.jpg)</span><br><span class="line"></span><br><span class="line">图10-45 sobel非线性滤波</span><br><span class="line"></span><br><span class="line">观察图10-45，左边是原图，右边是经过滤波后的图像，边缘被成功提取，将右图进行反转（黑色变白色，白色变黑色，用255减去图像矩阵）后，可得到更好的效果。</span><br><span class="line"></span><br><span class="line">### 10.11 小结</span><br><span class="line"></span><br><span class="line">机器学习算法可对数字图像进行加工和处理，以便进一步进行特征提取。本章首先介绍了数字图像的基础知识，数字图像用二维矩阵表示有限像素点，每个像素点对应于矩阵对应位置的元素；然后以实例说明了图像边缘、图像匹配、图像分类算法；最后讲解了噪声生成、图像二值化、插值与缩放、仿射、透视投影与透视变换、灰度变换与图像增强、图像滤波与除噪等算法。此外，在讲解这些算法的过程中，注重实践的效果，每个实例均用Python进行实现，以验证算法的有效性。</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">（1）首先应用欧氏距离算法计算图像边缘，并对多个不同的图像进行实验，观察效果；然后将欧氏距离算法改为像素差分算法（计算像素数值的差分绝对值）进行实验，观察其效果。</span><br><span class="line"></span><br><span class="line">（2）以多个图像为实验对象，对其进行加噪声点、变形、放大、缩小等操作，应用图像匹配技术进行图像匹配算法实验，尝试在图像匹配算法中应用PCA降维技术。</span><br><span class="line"></span><br><span class="line">（3）首先任意选取一个彩色图像，分别加上高斯噪声和椒盐噪声，然后应用本章介绍的各种滤波方法，进行滤波除噪，并观察效果。</span><br><span class="line"></span><br><span class="line">（4）首先任意选取一个彩色图像，将其灰度化，然后应用本章介绍的图像增强方法对灰度图像进行处理，最后应用本章介绍的二值化、仿射、透视化变换等方法对彩色图像进行处理。</span><br><span class="line"></span><br><span class="line">## 第11章 机器视觉案例</span><br><span class="line"></span><br><span class="line">计算机视觉是一门研究如何使机器“看懂”图像的科学，即用摄像机和计算机代替人眼对目标进行识别、跟踪和测量等。首先，使用摄像机等设备采集画面，生成数字图像；然后，用计算机对图像进行分析，相当于人的大脑对眼睛采集的信息进行加工，得到所需的信息。</span><br><span class="line"></span><br><span class="line">计算机视觉、图像处理、图像分析、机器人视觉、机器视觉等都是彼此紧密关联的学科，这些学科都属于人工智能的范畴，它们的研究目的都是使机器人（计算机）和人一样，能看到图像，理解图像，学习图像中包含的知识。机器学习是人工智能的核心技术，基于机器学习的图像算法应用于图像处理与分析领域，其作用相当于人类大脑加工和处理视觉神经反馈的图像。</span><br><span class="line"></span><br><span class="line">### 11.1 人脸辨识</span><br><span class="line"></span><br><span class="line">生物特征识别技术，是指通过生物体（一般特指人）本身的生物特征来区分生物体个体。生物特征识别技术所研究的相关特征包括脸、指纹、手掌纹、虹膜、视网膜、声音、体形、个人习惯等。相应的识别技术有人脸识别、指纹识别、掌纹识别、虹膜识别、视网膜识别、语音识别、体形识别、键盘敲击识别、签字识别等。</span><br><span class="line"></span><br><span class="line">人脸识别属于生物特征识别技术中的一种，指利用分析比较人脸视觉特征信息进行身份鉴别的计算机技术。</span><br><span class="line"></span><br><span class="line">#### 11.1.1 人脸定位</span><br><span class="line"></span><br><span class="line">在一张图像或一段视频中定位人脸的技术目前已比较成熟，可调用OpenCV提供的接口来完成。相应的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     def findface(image):
        #人脸识别，获取脸在图像中的坐标


        grayscale = cv.CreateImage((image.width, image.height), 8, 1)
        cv.CvtColor(image, grayscale, cv.CV_BGR2GRAY)
        cascade = 
    cv.Load(OPCV_PATH+"/data/haarcascades/haarcascade_frontalface_alt_tree.xml")
        rect = cv.HaarDetectObjects(grayscale, cascade, cv.CreateMemStorage(), 1.015, 2,cv.CV_HAAR_DO_CANNY_PRUNING, (10,10))
        result = []
        for r in rect:
            result.append([(r[0][0], r[0][1]), (r[0][0]+r[0][2], r[0][1]+r[0][3])])
        return result <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面算法的原理是：首先将图像转换为灰度图，然后加载OpenCV提供的面部特征库，接着调用HaarDetectObjects找到人脸的位置，最后将定位的结果赋值给result数据并返回。</span><br><span class="line"></span><br><span class="line">下面以如图11-1所示的《机械公敌》的电影海报为例来应用算法。</span><br><span class="line"></span><br><span class="line">实现该算法的完整Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #11-1.py
    #人脸定位


    import cv2
    import cv2.cv as cv 
    print 'loading  ...'
    #请在本程序运行前检查

    opencv的目录是否为下面的

    OPCV_PATH值


    OPCV_PATH=r"F:/soft/c++/opencv"
    def findface(image):
        #人脸识别，获取脸在图像中的坐标


        grayscale = cv.CreateImage((image.width, image.height), 8, 1)
        cv.CvtColor(image, grayscale, cv.CV_BGR2GRAY)
        cascade = cv.Load(OPCV_PATH+"/data/haarcascades/haarcascade_frontalface_alt_tree.xml")
        rect = cv.HaarDetectObjects(grayscale, cascade, cv.CreateMemStorage(), 1.015, 2,cv.CV_HAAR_DO_CANNY_PRUNING, (10,10))
        result = []
        for r in rect:
            result.append([(r[0][0], r[0][1]), (r[0][0]+r[0][2], r[0][1]+r[0][3])])
        return result
    fn='facesb.png'
    my_img=cv.LoadImage(fn)
    #获取脸在图像中的坐标


    faceresult=findface(my_img)    
    myimg=cv2.imread(fn)
    for  ii in xrange(0,len(faceresult)):
        cv2.rectangle(myimg, faceresult [ii][0], faceresult[ii][1],(0,0,250))    
    cv2.namedWindow('img')       
    cv2.imshow('img', myimg)   
    cv2.waitKey()  
    cv2.destroyAllWindows()  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序运行效果如图11-2所示。不但所有人类的脸被定位，而且机器人的脸也被成功找到。程序的OPCV_PATH为OpenCV源码包中data所在的目录，运行10-10.py前请自行更改。</span><br><span class="line"></span><br><span class="line">![](Image00499.jpg)</span><br><span class="line"></span><br><span class="line">图11-1 《机械公敌》的电影海报</span><br><span class="line"></span><br><span class="line">![](Image00500.jpg)</span><br><span class="line"></span><br><span class="line">图11-2 人脸定位</span><br><span class="line"></span><br><span class="line">#### 11.1.2 人脸辨识</span><br><span class="line"></span><br><span class="line">在讲述本节内容之前，先明确一下本节讲述的算法需要完成的任务：通过某人的一张照片，在他与别人的合影中找到他。</span><br><span class="line"></span><br><span class="line">1.算法描述</span><br><span class="line"></span><br><span class="line">完成该任务的人脸辨识算法主要过程是：</span><br><span class="line"></span><br><span class="line">1）读取两张图像，生成图像矩阵。</span><br><span class="line"></span><br><span class="line">2）以两个图像矩阵为基础，调用OpenCV的相关函数完成人脸定位。</span><br><span class="line"></span><br><span class="line">3）读取两张图像的人脸区域，生成人脸图像矩阵，并将人脸矩阵转换为灰度图。</span><br><span class="line"></span><br><span class="line">4）比较分析人脸图像矩阵，找到最相近的人脸。</span><br><span class="line"></span><br><span class="line">2.欧氏距离算法</span><br><span class="line"></span><br><span class="line">在进行人脸识别时，可使用标准欧氏距离算法，该算法不仅简单，而且实用。下面以一张Microsoft公司员工与比尔·盖茨的合影和在比尔·盖茨办公室中他与某人的合影为例讲解该算法。</span><br><span class="line"></span><br><span class="line">算法基本原理是：将标准欧氏距离算法作为比较分析人脸图像矩阵方法。首先，将两个人脸图像调整为指定大小；接着，用所包含像素的三元色数值组成特征组，然后将特征组映射为高维空间的某个点（在此称之为特征点）；最后，计算两个人脸图像的特征点映射到高维空间后的距离，以欧氏距离最小者为最匹配的人脸。具体步骤如下。</span><br><span class="line"></span><br><span class="line">1）调用OpenCV相关函数定位人脸。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cv2.imshow('img', myimg)   
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）计算欧氏距离。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def get_distance(img,findimg):
        newsize=(img.shape[1],img.shape[0])   
        fimg=cv2.resize(findimg,newsize)
        my_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        my_fimg=cv2.cvtColor(fimg,cv2.COLOR_BGR2GRAY)
        return get_EuclideanDistance(my_img,my_fimg) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）找到最匹配的人脸。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    myimg=cv2.imread(fn)
    myimgt=cv2.imread(fnt)
    #IT精英比尔

    ·盖茨


    isface1=get_distance(myimg[faceresult[0][0][0]:faceresult[0][1][0],faceresult[0][0][1]:faceresult[0][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    isface2=get_distance(myimg[faceresult[1][0][0]:faceresult[1][1][0],faceresult[1][0][1]:faceresult[1][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    if isface1<isface2: cv2.rectangle(myimg, faceresult[0][0], faceresult[0][1],(255,0,255)) cv2.rectangle(myimgt, facet_result[0][0], facet_result[0][1],(255,0,255)) else: faceresult[1][0], faceresult[1][1],(255,0,255)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #11-2.py
    #标准欧氏距离实现的人脸识别


    import cv2
    import numpy as np
    import cv2.cv as cv 
    print 'loading  ...'
    #请在本程序运行前检查

    opencv的目录是否为下面的

    OPCV_PATH值


    OPCV_PATH=r"F:/soft/c++/opencv"
    def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))*np.var(myx-myy)
    def get_distance(img,findimg):
        newsize=(img.shape[1],img.shape[0])   
        fimg=cv2.resize(findimg,newsize)
        my_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        my_fimg=cv2.cvtColor(fimg,cv2.COLOR_BGR2GRAY)
        return get_EuclideanDistance(my_img,my_fimg)
    def findface(image):
        #人脸识别，获取脸在图像中的坐标


        grayscale = cv.CreateImage((image.width, image.height), 8, 1)
        cv.CvtColor(image, grayscale, cv.CV_BGR2GRAY)
        cascade = cv.Load(OPCV_PATH+"/data/haarcascades/haarcascade_frontalface_alt_tree.xml")
        rect = cv.HaarDetectObjects(grayscale, cascade, cv.CreateMemStorage(), 1.1, 2,cv.CV_HAAR_DO_CANNY_PRUNING, (10,10))
        result = []
        for r in rect:
            result.append([(r[0][0], r[0][1]), (r[0][0]+r[0][2], r[0][1]+r[0][3])])
        return result
    fn='billall1.png'
    fnt= 'billtest.png'
    my_img=cv.LoadImage(fn)
    face_test=cv.LoadImage(fnt)
    #获取人脸在图像中的坐标


    faceresult=findface(my_img)
    facet_result=findface(face_test)
    myimg=cv2.imread(fn)
    myimgt=cv2.imread(fnt)
    #IT精英比尔

    ·盖茨


    isface1=get_distance(myimg[faceresult[0][0][0]:faceresult[0][1][0],faceresult[0][0][1]:faceresult[0][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    isface2=get_distance(myimg[faceresult[1][0][0]:faceresult[1][1][0],faceresult[1][0][1]:faceresult[1][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    if isface1<isface2: cv2.rectangle(myimg, faceresult[0][0], faceresult[0][1],(255,0,255)) cv2.rectangle(myimgt, facet_result[0][0], facet_result[0][1],(255,0,255)) else: faceresult[1][0], faceresult[1][1],(255,0,255)) cv2.namedwindow('img') cv2.imshow('img', myimg) cv2.namedwindow('imgt') cv2.imshow('imgt', myimgt) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行算法程序后，成功地在员工合影中找到比尔·盖茨。运行本书资源包中的上述代码，可验证人脸识别效果。</span><br><span class="line"></span><br><span class="line">3.改进的欧氏距离算法</span><br><span class="line"></span><br><span class="line">前面描述的图像特征码提取算法仅仅是基于像素点的三元色数值的，有时候，图像少量的像素点差异可能干扰识别结果。人脸是一个整体，可能因为人脸的某个部位（如文身、饰品等）、人脸的不同动作和不同角度（如正面人脸、斜侧面人脸以及抬头或低头等）造成少数像素点之间的差异过大，使欧式距离失真（被放大或缩小）。如果从以下两个方面改进上述人脸辨识算法，可以使其识别效果更好。</span><br><span class="line"></span><br><span class="line">·将人脸图像大小设置为适当的数值（通常来说比较小），这样更能突出人脸的特征，而略去很多干扰项。此外，提取原始特征组后，使用PCA降维技术对原始特征组进行进一步加工，生成最终的特征组，从而更好地表征人脸。</span><br><span class="line"></span><br><span class="line">·在标准欧氏距离的基础上乘以权重。有两种计算方式：第一，每区域像素设置不同的权重，因为人脸的不同区域表征人脸的能力不同；第二，设置整体权重，使人脸图像矩阵的差分值均匀化。</span><br><span class="line"></span><br><span class="line">本节使用第二种方式，加工后的欧氏距离不但能更好地表征人脸整体差异，而且不会因为人脸中某些部分过大或过小的差异影响整体识别效果。</span><br><span class="line"></span><br><span class="line">在讲解上述算法之前，先讲解一下统计学的变异系数。标准差和方差均可反映数据离散程度，但反映的是离散绝对值。在衡量数据分布离散程度时，不仅要考虑变量值离散程度，还要考虑变量值平均水平。变异系数同时考虑了这两个因素。</span><br><span class="line"></span><br><span class="line">变异系数，又称离散系数，是概率分布离散程度的一个归一化量度。它定义为标准差σ与平均值μ之比：</span><br><span class="line"></span><br><span class="line">![](Image00501.jpg)</span><br><span class="line"></span><br><span class="line">注意，变异系数只在平均值不为零时有定义，人脸差分矩阵正好满足这个条件。</span><br><span class="line"></span><br><span class="line">变异系数可以消除因为平均数不同在变异程度比较中产生的干扰。变异系数越小，数据离平均值的偏离程度越小；反之，变异系数越大，数据离平均值的偏离程度越大。</span><br><span class="line"></span><br><span class="line">这里首先将变异系数改进，将标准差用方差代替；然后将改进的变异系数的倒数作为计算欧氏距离的调节系数（这样做的效果是：将偏离程度较大的数据赋予较小的权重，将偏离程度较小的数据赋予较大的权重中）；最后将标准欧氏距离乘以调节权重，从而实现差异平均化，让改进后的欧氏矩阵更好地表征人脸整体差异。通过对多个样本的实验来看，这种方式的效果比较理想。</span><br><span class="line"></span><br><span class="line">下面以找到威尔·史密斯为例来讲解改进的欧氏距离算法。在《机械公敌》中，威尔·史密斯饰演警探戴尔史普纳，布丽姬穆娜饰演苏珊卡尔文博士。以威尔·史密斯出演的《我是传奇》的电影海报（如图11-3所示）中的图像为蓝本，在他与布丽姬穆娜合影的《机械公敌》海报（如图11-4和图11-2所示）中找到他。</span><br><span class="line"></span><br><span class="line">![](Image00502.jpg)</span><br><span class="line"></span><br><span class="line">图11-3 《我是传奇》海报</span><br><span class="line"></span><br><span class="line">![](Image00503.jpg)</span><br><span class="line"></span><br><span class="line">图11-4 《机械公敌》海报</span><br><span class="line"></span><br><span class="line">经过实验，发现标准的欧氏距算法无法完成这个任务，需要使用刚刚描述的改进后的欧氏距离算法。</span><br><span class="line"></span><br><span class="line">1）在PCA降维后，计算基于整体权重的欧氏距离。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    def get_distance(img,findimg):
        newsize=(21,21)   
        fimg=cv2.resize(findimg,newsize)
        img=cv2.resize(img,newsize)
        my_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        my_fimg=cv2.cvtColor(fimg,cv2.COLOR_BGR2GRAY)
        pcaimg = mlpy.PCA() 
        pcaimg.learn(my_img) 
        pca_img = pcaimg.transform(my_img, k=1)  
        pca_img=pcaimg.transform_inv(pca_img)   
        pcafimg = mlpy.PCA() 
        pcafimg.learn(my_fimg) 
        pca_fimg = pcaimg.transform(my_fimg, k=1)
        pca_fimg= pcafimg.transform_inv(pca_fimg)    
        return get_EuclideanDistance(pca_img,pca_fimg) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）根据欧氏距离决定哪个人脸更匹配。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    my_img=cv.LoadImage(fn2)
    myimg=cv2.imread(fn2)
    #获取脸在图像中的坐标


    faceresult=findface(my_img)
    #找到威尔

    ·史密斯


    isface1=get_distance(myimg[faceresult[0][0][0]:faceresult[0][1][0],faceresult[0][0][1]:faceresult[0][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    isface2=get_distance(myimg[faceresult[1][0][0]:faceresult[1][1][0],faceresult[1][0][1]:faceresult[1][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    if isface1<isface2: cv2.rectangle(myimg, faceresult[0][0], faceresult[0][1],(255,0,255)) cv2.rectangle(myimgt, facet_result[0][0], facet_result[0][1],(255,0,255)) else: faceresult[1][0], faceresult[1][1],(255,0,255)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #11-3.py
    #pcb+改进变异系数人脸识别


    import cv2
    import numpy as np
    import cv2.cv as cv
    import mlpy 
    print 'loading  ...'
    #请在本程序运行前检查

    opencv的目录是否为下面的

    OPCV_PATH值


    OPCV_PATH=r"F:/soft/c++/opencv"
    def get_EuclideanDistance(x,y):  
        myx=np.array(x)  
        myy=np.array(y)  
        return np.sqrt(np.sum((myx-myy)*(myx-myy)))/(np.var(myx-myy)/abs(np.mean(myx-myy)))
    def get_distance(img,findimg):
        newsize=(21,21)   
        fimg=cv2.resize(findimg,newsize)
        img=cv2.resize(img,newsize)
        my_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        my_fimg=cv2.cvtColor(fimg,cv2.COLOR_BGR2GRAY)
        pcaimg = mlpy.PCA() 
        pcaimg.learn(my_img) 
        pca_img = pcaimg.transform(my_img, k=1)  
        pca_img=pcaimg.transform_inv(pca_img)
        pcafimg = mlpy.PCA() 
        pcafimg.learn(my_fimg) 
        pca_fimg = pcaimg.transform(my_fimg, k=1)
        pca_fimg= pcafimg.transform_inv(pca_fimg)    
        return get_EuclideanDistance(pca_img,pca_fimg)
    def findface(image):
        #人脸识别，获取脸在图像中的坐标


        grayscale = cv.CreateImage((image.width, image.height), 8, 1)
        cv.CvtColor(image, grayscale, cv.CV_BGR2GRAY)
        cascade = cv.Load(OPCV_PATH+"/data/haarcascades/haarcascade_frontalface_alt_tree.xml")
        rect = cv.HaarDetectObjects(grayscale, cascade, cv.CreateMemStorage(), 1.1, 2,cv.CV_HAAR_DO_CANNY_PRUNING, (10,10))
        result = []
        for r in rect:
            result.append([(r[0][0], r[0][1]), (r[0][0]+r[0][2], r[0][1]+r[0][3])])
        return result 
    fn1='jjgdall.png' 
    fn2='facesb.png'
    fnt='jjgdtest.png'
    face_test=cv.LoadImage(fnt)
    #获取人脸在图像中的坐标


    facet_result=findface(face_test)
    myimgt=cv2.imread(fnt)
    my_img=cv.LoadImage(fn1)
    myimg=cv2.imread(fn1)
    #获取人脸在图像中的坐标


    faceresult=findface(my_img)
    #找到威尔

    ·史密斯


    isface1=get_distance(myimg[faceresult[0][0][0]:faceresult[0][1][0],faceresult[0][0][1]:faceresult[0][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    isface2=get_distance(myimg[faceresult[1][0][0]:faceresult[1][1][0],faceresult[1][0][1]:faceresult[1][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])
    if isface1<isface2: cv2.rectangle(myimg, faceresult[0][0], faceresult[0][1],(255,0,255)) cv2.rectangle(myimgt, facet_result[0][0], facet_result[0][1],(255,0,255)) else: faceresult[1][0], faceresult[1][1],(255,0,255)) cv2.namedwindow('img1') cv2.imshow('img1', myimg) my_img="cv.LoadImage(fn2)" myimg="cv2.imread(fn2)" #获取人脸在图像中的坐标 faceresult="findface(my_img)" #找到威尔 ·史密斯 isface1="get_distance(myimg[faceresult[0][0][0]:faceresult[0][1][0],faceresult[0][0][1]:faceresult[0][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])" isface2="get_distance(myimg[faceresult[1][0][0]:faceresult[1][1][0],faceresult[1][0][1]:faceresult[1][1][1],:],myimgt[facet_result[0][0][0]:facet_result[0][1][0],facet_result[0][0][1]:facet_result[0][1][1],:])" if isface1<isface2: cv2.namedwindow('img2') cv2.imshow('img2', cv2.namedwindow('imgt') cv2.imshow('imgt', myimgt) cv2.waitkey() cv2.destroyallwindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行上述程序后，效果良好，在图11-5中，以左图中的史密斯的脸为依据，成功地在右边两个图像中找到史密斯（方框中标示了人脸）。</span><br><span class="line"></span><br><span class="line">![](Image00504.jpg)</span><br><span class="line"></span><br><span class="line">图11-5 人脸匹配</span><br><span class="line"></span><br><span class="line">### 11.2 手写数字识别</span><br><span class="line"></span><br><span class="line">手写数字识别就是指用计算机读取含有手写数字的图像，然后将图像转换为用计算机文字表示的对应数字。SVM在文本分类、手写文字识别、图像分类、生物序列分析等实际应用中表现出了非常好的性能。下面应用SVM算法对1~9的手写数字图像进行识别。</span><br><span class="line"></span><br><span class="line">#### 11.2.1 手写数字识别算法</span><br><span class="line"></span><br><span class="line">1）为每个数字各准备4个样本图像，如图11-6所示。</span><br><span class="line"></span><br><span class="line">![](Image00505.jpg)</span><br><span class="line"></span><br><span class="line">图11-6 数字样本图像</span><br><span class="line"></span><br><span class="line">2）将图像大小调整为8×8的尺寸，读取样本图像。</span><br><span class="line"></span><br><span class="line">虽然较大的图像比较小的图像尺寸更清晰，但并不意味着它能更好地表现图像的主要特征。不过，由于手写字体不规范，因此较大的尺寸会更清楚地表征字体的不规范细节。当图像尺寸调整得更小时，图像矩阵规模变小，能表现图像细节的能力减弱，大部分字体的不规范细节会消失，但这样一来，数字的主要特征就更加突出了，可尽可能消除手写字体不规范带来的影响。比如，如图11-7所示的数字3，从左边起第一张是40×40的尺寸，第二张是20×20的尺寸，而第三张则是8×8的尺寸。我们在用肉眼观察时，可以看到，随着尺寸越来越小，图像越来越模糊，不规范的细节也慢慢消失。当计算机使用8×8的尺寸来分析数字3的图像时，提取的特征就能更好地表达图像。</span><br><span class="line"></span><br><span class="line">![](Image00506.jpg)</span><br><span class="line"></span><br><span class="line">图11-7 不同尺寸的数字3图像</span><br><span class="line"></span><br><span class="line">在8×8（实际是8×8×3，因为调用OpenCV库读取图像后，会多出一维空间，多出的这维空间分别放置了红、绿、蓝三元色数值）的图像矩阵中，当色彩为黑色（数字字体的颜色）时，表示该像素的特征码为1，否则为0，形成的像素特征码组成了样本图像特征组。</span><br><span class="line"></span><br><span class="line">现在将每个数字类别的样本图像特征组作为输入，样本对应的数字值作为输出，用SVM进行训练。</span><br><span class="line"></span><br><span class="line">3）读取未知样本图像，将未知图像调整为8×8的尺寸，提取图像特征码，生成图像特征组。</span><br><span class="line"></span><br><span class="line">4）将未知样本图像特征组送入SVM仿真测试，仿真输出值为根据图像识别出的数字。</span><br><span class="line"></span><br><span class="line">#### 11.2.2 算法的Python实现</span><br><span class="line"></span><br><span class="line">现在根据上述步骤一步步来实现。首先，提取图像特征，代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    def getnumc(fn):
        '''返回数字特征

    '''
        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(8,8))
        alltz=[]
        for now_h in xrange(0,8):
            xtz=[]        
            for now_w in xrange(0,8):
                b = img[now_h,now_w,0]
                g = img[now_h,now_w,1]
                r = img[now_h,now_w,2]
                btz=255-b
                gtz=255-g
                rtz=255-r
                if btz>0 or gtz>0 or rtz>0:
                    nowtz=1
                else:
                    nowtz=0
                xtz.append(nowtz)  
            alltz+=xtz
        return alltz <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后训练SVM并仿真输出。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    x=np.array(x)
    y=np.array(y)
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly',gamma=10)
    svm.learn(x, y)
    print svm.pred(x) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">完整的Python代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #11-4.py
    import numpy as np
    import mlpy
    import cv2
    print 'loading  ...'
    def getnumc(fn):
        '''返回数字特征

    '''
        fnimg = cv2.imread(fn)
        img=cv2.resize(fnimg,(8,8))
        alltz=[]
        for now_h in xrange(0,8):
            xtz=[]        
            for now_w in xrange(0,8):
                b = img[now_h,now_w,0]
                g = img[now_h,now_w,1]
                r = img[now_h,now_w,2]
                btz=255-b
                gtz=255-g
                rtz=255-r
                if btz>0 or gtz>0 or rtz>0:
                    nowtz=1
                else:
                    nowtz=0
                xtz.append(nowtz)  
            alltz+=xtz   
        return alltz
    #读取样本数字


    x=[]
    y=[]
    for numi in xrange(1,10):
        for numij in xrange(1,5):
            fn='nums/'+str(numi)+'-'+str(numij)+'.png'
            x.append(getnumc(fn))
            y.append(numi)
    x=np.array(x)
    y=np.array(y)
    svm = mlpy.LibSvm(svm_type='c_svc', kernel_type='poly',gamma=10)
    svm.learn(x, y)
    print svm.pred(x)
    for iii in xrange (1,10):
        testfn= 'nums/test/'+str(iii)+'-test.png'
        testx=[]
        testx.append(getnumc(testfn))
        print svm.pred(testx) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后，进行仿真测试。</span><br><span class="line"></span><br><span class="line">通过对如图11-8所示的未知样本的仿真测试得知，运行效果不错。</span><br><span class="line"></span><br><span class="line">![](Image00507.jpg)</span><br><span class="line"></span><br><span class="line">图11-8 未知数字样本</span><br><span class="line"></span><br><span class="line">运行效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    loading  ...训练样本测试


    [ 1.  1.  1.  1.  2.  2.  2.  2.  3.  3.  3.  3.  4.  4.  4.  4.  5.  5.
      5.  5.  6.  6.  6.  6.  7.  7.  7.  7.  8.  8.  8.  8.  9.  9.  9.  9.]未知图像测试


    nums/test/1-test.png: [ 1.]
    nums/test/2-test.png: [ 2.]
    nums/test/3-test.png: [ 3.]
    nums/test/4-test.png: [ 4.]
    nums/test/5-test.png: [ 5.]
    nums/test/6-test.png: [ 6.]
    nums/test/7-test.png: [ 7.]
    nums/test/8-test.png: [ 8.]
    nums/test/9-test.png: [ 9.] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 11.3 运动侦测</span><br><span class="line"></span><br><span class="line">运动侦测，英文翻译为“Motion Detection Technology”，一般也叫移动检测，是指通过摄像头按照不同的帧率采集得到的图像，电脑按照一定的算法对这些图像进行计算和比较，当画面有变化时，指示系统能自动做出相应的处理。比如：有人走过，镜头被移动，电脑计算比较得出的移动数值，检测是否会超过阈值，如果超过阈值，则进行下一步处理（发出警报等）。</span><br><span class="line"></span><br><span class="line">移动侦测技术是运动检测录像技术的基础，最早用于于无人值守监控录像和自动报警，现在已经被广泛应用于网络摄像机、汽车监控锁、数字宝护神、婴儿监视器、自动取样仪、自识别门禁等众多安防仪器和设施上。</span><br><span class="line"></span><br><span class="line">#### 11.3.1 视频采集</span><br><span class="line"></span><br><span class="line">1.视频采集</span><br><span class="line"></span><br><span class="line">程序11-5.py演示了视频采集，程序每隔15毫秒检测一次是否采集图像。程序的具体实现方式如下：</span><br><span class="line"></span><br><span class="line">首先设置捕获设备，然后建立循环，每15毫秒更新一次画面显示，并检测是否退出，或采集图像，按空格键则退出，按c键则捕获当前视频的图像。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #coding:myhaspl@myhaspl.com
    #11-5.py
    import cv2
    #设置需要采集视频的设备

    ID为

    0,从第

    0个摄像头采集


    mycap=cv2.VideoCapture(0)
    id=0
    while True:
        ret,im=mycap.read()
        cv2.imshow('myvideo',im)
        #每

    15毫秒采集

    1次


        key=cv2.waitKey(15)
        #空格键退出


        if key==32:
            break
        #c键采集


        elif key==ord('c'):
            cv2.imwrite('vd_'+str(id)+'.png',im)
            id+=1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序11-5.py运行后，将出现从摄像头实时采集的图像，如图11-9所示。</span><br><span class="line"></span><br><span class="line">![](Image00508.jpg)</span><br><span class="line"></span><br><span class="line">图11-9 摄像头实时采集的图像1</span><br><span class="line"></span><br><span class="line">每次按c键后，采集连接图像，如图11-10至图11-13所示的图像序列。</span><br><span class="line"></span><br><span class="line">![](Image00509.jpg)</span><br><span class="line"></span><br><span class="line">图11-10 图像序列2</span><br><span class="line"></span><br><span class="line">![](Image00510.jpg)</span><br><span class="line"></span><br><span class="line">图11-11 图像序列3</span><br><span class="line"></span><br><span class="line">![](Image00511.jpg)</span><br><span class="line"></span><br><span class="line">图11-12 图像序列4</span><br><span class="line"></span><br><span class="line">![](Image00512.jpg)</span><br><span class="line"></span><br><span class="line">图11-13 图像序列5</span><br><span class="line"></span><br><span class="line">2.图像序列数组</span><br><span class="line"></span><br><span class="line">可按帧生成视频图像序列数组，程序11-6.py演示了对视频图像的抓图保存。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #coding:myhaspl@myhaspl.com
    #采集视频生成视频帧数组


    #11-6.py
    import cv2
    #设置需要采集视频的设备

    ID为

    0,从第

    0个摄像头采集


    mycap=cv2.VideoCapture(0)
    myframes=[]
    while True:
        ret,im=mycap.read()
        cv2.imshow('myvideo',im)
        #采集


        myframes.append(im)
        #每

    15毫秒采集

    1次


        key=cv2.waitKey(15)
        #空格键退出


        if key==32:
            break
    #生成视频帧数组


    myframes=np.array(myframes) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.读取视频文件</span><br><span class="line"></span><br><span class="line">除了从摄像头采集数据外，还可从视频文件获取视频，用如下格式的Python代码来实现：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    mycapture=cv2.VideoCapture("文件名

    ") <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 11.3.2 差分算法</span><br><span class="line"></span><br><span class="line">1.差分检测</span><br><span class="line"></span><br><span class="line">差分检测根据当前图像与参考图像的差别分析来判断序列图像中是否有运动的物体，在环境亮度变化不大的情况下，如果对应像素灰度值的差异小于某个阈值，则认为画面静止无运动变化，如果图像区域某处的灰度变化大于某个阈值，则认为这是由于图像中运动的物体所引起的，然后求出运动目标在图像中的位置。</span><br><span class="line"></span><br><span class="line">根据差分的参考图像不同，可以分为基于相邻帧差的算法和基于背景图像与当前帧差的算法：基于相邻帧差的算法是将前后两帧图像对应像素点的灰度值相减，基于背景图像与当前帧差的算法则是将当前帧和背景帧对应像素的灰度值相减。</span><br><span class="line"></span><br><span class="line">下面将以实例来说明该算法。图11-14~图11-19是某视频的6个截图，根据这6个运动图像序列，判断画面在何时出现了运动的物体，输出警告信息，并生成运动效果组合图。</span><br><span class="line"></span><br><span class="line">![](Image00513.jpg)</span><br><span class="line"></span><br><span class="line">图11-14 视频的截图1</span><br><span class="line"></span><br><span class="line">![](Image00514.jpg)</span><br><span class="line"></span><br><span class="line">图11-15 视频的截图2</span><br><span class="line"></span><br><span class="line">![](Image00515.jpg)</span><br><span class="line"></span><br><span class="line">图11-16 视频的截图3</span><br><span class="line"></span><br><span class="line">![](Image00516.jpg)</span><br><span class="line"></span><br><span class="line">图11-17 视频的截图4</span><br><span class="line"></span><br><span class="line">![](Image00517.jpg)</span><br><span class="line"></span><br><span class="line">图11-18 视频的截图5</span><br><span class="line"></span><br><span class="line">![](Image00518.jpg)</span><br><span class="line"></span><br><span class="line">图11-19 视频的截图6</span><br><span class="line"></span><br><span class="line">2.基于相邻帧差的算法</span><br><span class="line"></span><br><span class="line">基于相邻帧差的算法过程如下：</span><br><span class="line"></span><br><span class="line">1）将当前帧的灰度图像与前一帧的灰度图像相减，得到差分值，当差分值大于某个阈值时，将差分矩阵的相应位置设置为1，否则设置为0，差分矩阵的计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00519.jpg)</span><br><span class="line"></span><br><span class="line">其中，fk （i，j）表示第k个图像矩阵（i，j）处的灰度值，D（i，j）表示差分矩阵（i，j）处的值。</span><br><span class="line"></span><br><span class="line">2）如果差分矩阵不全为0，则表示检测到运动。如果有必要，可按一定的运动检测次数对运动画面进行分组，并融合叠加形成多组运动轨迹图。</span><br><span class="line"></span><br><span class="line">3）取下一帧图像，转到（1），直到所有帧图像全部处理完毕后退出。</span><br><span class="line"></span><br><span class="line">用Python代码实现该算法，如程序11-7.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #差分运动检测，相邻帧差检测画面中是否有运动的物体


    #11-7.py
    import cv2  
    import numpy as np  
    #读取运动序列图像


    fn=[]
    for i in xrange(6):
        fn.append(str(i+1)+".png")
    img=[]
    colorimg=[]
    myimg=[]
    for i in xrange(6):
        tmpimg=(cv2.imread(fn[i]))
        colorimg.append(tmpimg)
        myimg=cv2.cvtColor(tmpimg,cv2.COLOR_BGR2GRAY)  
        img.append(myimg)
    #差分计算


    myimg1=colorimg[0].copy()
    myimg2=myimg1.copy()
    w=myimg1.shape[1]  
    h=myimg1.shape[0] 
    moveimg1=np.zeros((h,w),np.uint8 )
    moveimg2=np.zeros((h,w,3),np.uint8 )
    for ii in xrange(5):
        print u"开始分析第

    "+str(ii+2)+u"个运动图像

    ..."
        myd=img[ii+1]-img[ii]
        #生成差分矩阵


        THRESHOLD=int(np.median(abs(myd)))#取中位数做为阈值


        mymove=np.ones([h,w],np.uint8)
        for i in xrange(h):
            for j in xrange(w):
                if abs(myd[i,j])<threshold or myd[i,j]="=0:" mymove[i,j]="0" #如果有物体运动则输出报警，并生成运动效果叠加图 if np.sum(mymove)>0 :
            print u"第

    "+str(ii+2)+u"个运动图像发生了变化

    !"
            moveimg1=img[ii+1]*(1-mymove)*0.16+img[ii]*(1-mymove)*0.16+moveimg1
            moveimg2=colorimg[ii+1]*0.16+colorimg[ii]*0.16+moveimg2
            moveimg1=np.array(moveimg1,np.uint8)
            moveimg2=np.array(moveimg2,np.uint8)
    #显示运动画面


    #计算运动部分


    moveimg1=moveimg1-img[0]
    #灰度图二值化以更好地显示运动的效果。


    retval, showimg1=cv2.threshold(moveimg1,140,255,cv2.THRESH_BINARY) 
    showimg1=showimg1
    showimg2=moveimg2
    cv2.imshow("move1",showimg1)
    cv2.imshow("move2",showimg2)
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序11-7.py，程序检测到第2、3、4、6帧时，图像发生了变化，运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    开始分析第

    2个运动图像

    ...第

    2个运动图像发生了变化

    !开始分析第

    3个运动图像

    ...第

    3个运动图像发生了变化

    !开始分析第

    4个运动图像

    ...第

    4个运动图像发生了变化

    !开始分析第

    5个运动图像

    ...开始分析第

    6个运动图像

    ...第

    6个运动图像发生了变化

    ! <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序11-7.py绘制了使用相邻帧差分法检测的运动效果，如图11-20所示。</span><br><span class="line"></span><br><span class="line">观察图11-20，左边的图像为运动图像的融合，右边的图像为程序提取运动部分的灰度图，可较直观地看出手拿着笔摆动时的运动路径和运动速度。</span><br><span class="line"></span><br><span class="line">![](Image00520.jpg)</span><br><span class="line"></span><br><span class="line">图11-20 运动效果</span><br><span class="line"></span><br><span class="line">3.基于背景图像与当前帧差的算法</span><br><span class="line"></span><br><span class="line">该算法的具体过程如下：</span><br><span class="line"></span><br><span class="line">1）将当前帧的灰度图像与背景灰度图像相减，得到差分值，当差分值大于某个阈值时，将差分矩阵的相应位置设置为1，否则设置为0，差分矩阵计算公式如下：</span><br><span class="line"></span><br><span class="line">![](Image00521.jpg)</span><br><span class="line"></span><br><span class="line">上式中，fk （i，j）表示第k个图像矩阵（i，j）处的灰度值，D（i，j）表示差分矩阵（i，j）处的值。</span><br><span class="line"></span><br><span class="line">2）如果差分矩阵不全为0，则表示检测到运动。如果有必要，可按一定的运动检测次数对运动画面进行分组，并融合叠加形成多组运动轨迹图。</span><br><span class="line"></span><br><span class="line">3）取下一帧图像，转到（1），直到n个帧的图像全部处理完毕后退出。</span><br><span class="line"></span><br><span class="line">用Python代码实现该算法，如程序11-8.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #差分运动检测，基于背景图像与当前帧差来检测画面中是否有运动的物体


    #11-8.py
    import cv2  
    import numpy as np  
    #读取运动序列图像


    fn=[]
    for i in xrange(6):
        fn.append("mv"+str(i+1)+".png")
    img=[]
    colorimg=[]
    myimg=[]
    for i in xrange(6):
        tmpimg=(cv2.imread(fn[i]))
        colorimg.append(tmpimg)
        myimg=cv2.cvtColor(tmpimg,cv2.COLOR_BGR2GRAY)  
        img.append(myimg)
    #差分计算


    myimg=colorimg[0].copy()
    w=myimg.shape[1]  
    h=myimg.shape[0] 
    moveimg=np.zeros((h,w,3),np.uint8 )
    for ii in xrange(5):
        print u"开始分析第

    "+str(ii+2)+u"个运动图像

    ..."
        myd=img[ii+1]-img[0]
        #生成差分矩阵


        THRESHOLD=int(np.median(abs(myd)))#取中位数做为阈值


        mymove=np.ones([h,w],np.uint8)
        for i in xrange(h):
            for j in xrange(w):
                if abs(myd[i,j])<threshold or myd[i,j]="=0:" mymove[i,j]="0" #如果有物体运动则输出报警 if np.sum(mymove)>0 :
            print u"第

    "+str(ii+2)+u"个运动图像发生了变化

    !"
            moveimg=colorimg[ii+1]*0.16+colorimg[ii]*0.16+moveimg
            moveimg=np.array(moveimg,np.uint8)
    #显示移动部分


    showimg=moveimg
    cv2.imshow("move",showimg)
    cv2.waitKey()  
    cv2.destroyAllWindows() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序11-8.py绘制了检测到的运动效果（如图11-21所示），并输出结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    开始分析第

    2个运动图像

    ...第

    2个运动图像发生了变化

    !开始分析第

    3个运动图像

    ...第

    3个运动图像发生了变化

    !开始分析第

    4个运动图像

    ...第

    4个运动图像发生了变化

    !开始分析第

    5个运动图像

    ...第

    5个运动图像发生了变化

    !开始分析第

    6个运动图像

    ... <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从图11-21中可较直观地看出手拿着笔摆动时的运动路径和运动速度。</span><br><span class="line"></span><br><span class="line">![](Image00522.jpg)</span><br><span class="line"></span><br><span class="line">图11-21 检测到的运动</span><br><span class="line"></span><br><span class="line">#### 11.3.3 光流法</span><br><span class="line"></span><br><span class="line">1.光流法概述</span><br><span class="line"></span><br><span class="line">光流（Optical Flow/Optic Flow）是关于视域中的物体运动检测的概念。用来描述相对于观察者的运动所造成的观测目标、表面或边缘的运动。光流法在模式识别、计算机视觉及其他图像处理中非常有用，可用于运动检测、物件切割、碰撞时间与物体膨胀的计算、运动补偿编码，或者通过物体的表面与边缘进行立体的测量等。</span><br><span class="line"></span><br><span class="line">光流法的基本原理为：光流是空间运动物体在观测成像面上的像素运动的瞬时速度。光流的研究是利用图像序列中的像素强度数据的时域变化和相关性来确定各自像素位置的“运动”，即研究图像灰度在时间上的变化与景象中的物体结构及其运动的关系。一般情况下，光流是由相机运动、场景中的目标运动或两者的共同运动产生的。光流的计算方法大致可分为三类：基于匹配的、频域的和梯度的方法。</span><br><span class="line"></span><br><span class="line">光流法的前提假设如下：</span><br><span class="line"></span><br><span class="line">·相邻帧之间的亮度恒定。</span><br><span class="line"></span><br><span class="line">·相邻视频帧的取帧时间是连续的，或者说，相邻帧之间物体的运动比较“微小”。</span><br><span class="line"></span><br><span class="line">·保持空间的一致性，即同一子图像的像素点具有相同的运动。</span><br><span class="line"></span><br><span class="line">2.Python实现</span><br><span class="line"></span><br><span class="line">程序11-9.py从摄像头采集图像，然后对每个连续的图像进行光流估计，并绘制流矢量，效果如图11-22所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-
    #coding:myhaspl@myhaspl.com
    #光流法


    #11-9.py
    import cv2
    import numpy as np
    def flowdraw(im,flow,step=14):
        #绘制光流


        h,w=im.shape[:2]
        y,x=np.mgrid[step/2:h:step,step/2:w:step].reshape(2,-1)
        fx,fy=flow[y,x].T
        #线终点


        lines=np.vstack([x,y,x+fx,y+fy]).T.reshape(-1,2,2)
        lines=np.int32(lines)
        #创建图像


        myvis=cv2.cvtColor(im,cv2.COLOR_GRAY2BGR)
        for (x1,y1),(x2,y2) in lines:
            cv2.line(myvis,(x1,y1),(x2,y2),(0,255,0),1)
            cv2.circle(myvis,(x1,y1),1,(0,255,0),-1)
        return myvis
    #设置需要采集视频的设备

    ID为

    0,从第

    0个摄像头采集


    mycap=cv2.VideoCapture(0)
    #前一个图像


    ret,im=mycap.read()
    prev_pic=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
    while True:
        ret,im=mycap.read()
        #采集


        pic=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)    
        #计算流


        myflow=cv2.calcOpticalFlowFarneback(prev_pic,pic,0.5,3,15,3,5,1,0)
        #上帧图像赋值


        prev_pic=pic
        #绘制流矢量


        cv2.imshow('myvideo flow ',flowdraw(pic,myflow))    
        #每

    15毫秒采集

    1次


        key=cv2.waitKey(15)    
        #空格键退出


        if key==32:
            break <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00523.jpg)</span><br><span class="line"></span><br><span class="line">图11-22 光流法</span><br><span class="line"></span><br><span class="line">观察图11-22，从流矢量线条及箭头的方向中可以发现手电筒正在从左到右移动。</span><br><span class="line"></span><br><span class="line">### 11.4 形状检测</span><br><span class="line"></span><br><span class="line">#### 11.4.1 KNN算法概述</span><br><span class="line"></span><br><span class="line">K最近邻（KNN，k-NearestNeighbor）分类算法可以说是整个数据分类技术中最简单的方法了。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最靠近的k个邻居来代表。KNN算法的核心思想是：如果一个样本在特征空间中的k个最相邻的样本中的大多数都属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性，算法在确定分类决策上只需要依据最邻近的一个或几个样本的类别即可决定待分样本所属的类别，因此，在做类别决策时，只与极少量的相邻样本有关。</span><br><span class="line"></span><br><span class="line">由于KNN方法主要靠周围有限的邻近样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他的方法更为合适。</span><br><span class="line"></span><br><span class="line">以二维样本为例，利用KNN方法将样本分成两类。图11-23中三角形和方形是已知类别的样本点，这里假设三角形为正类，方形为负类，圆形点是未知类别的数据，现在需要利用这些已知类别的样本对圆形点进行分类。</span><br><span class="line"></span><br><span class="line">![](Image00524.jpg)</span><br><span class="line"></span><br><span class="line">图11-23 K近邻算法示意图</span><br><span class="line"></span><br><span class="line">对图11-23的圆形点进行KNN分类的具体过程如下：</span><br><span class="line"></span><br><span class="line">1）事先定下k值（就是指K近邻方法中k的大小，代表对于一个待分类的数据点，要寻找它的几个邻居）。为讲解方便，取两个k值，分别为3和5。</span><br><span class="line"></span><br><span class="line">2）根据事先确定的距离度量公式（如：欧氏距离），得出待分类数据点和所有已知类别的样本点中，距离最近的k个样本。</span><br><span class="line"></span><br><span class="line">3）统计这k个样本点中各个类别的数量。如图12-15，如果选定k值为3，则正类样本（三角形）有2个，负类样本（方形）有1个，那么就把这个圆形数据点定为正类；而如果选择k值为5，则正类样本（三角形）有2个，负类样本（方形）有3个，那么将这个数据点定为负类。即，根据k个样本中，数量最多的样本是什么类别，就把这个数据点定为什么类别。</span><br><span class="line"></span><br><span class="line">#### 11.4.2 形状特征提取</span><br><span class="line"></span><br><span class="line">图11-24是三个典型的形状，分别是方形、圆形和三角形。</span><br><span class="line"></span><br><span class="line">![](Image00525.jpg)</span><br><span class="line"></span><br><span class="line">图11-24 典型的形状</span><br><span class="line"></span><br><span class="line">那么如何提取图11-24所示的三个形状的特征呢，可使用距中心距离法，具体过程如下：</span><br><span class="line"></span><br><span class="line">1）确定图像的中心点center，通常是图片的中间位置。</span><br><span class="line"></span><br><span class="line">2）计算图像线条上的每个点x与中心点center之间的距离（两点间的距离公式），形成距离向量d。</span><br><span class="line"></span><br><span class="line">3）计算距离向量d的标准差。以标准差为最终特征值。</span><br><span class="line"></span><br><span class="line">#### 11.4.3 形状分类</span><br><span class="line"></span><br><span class="line">本算法为KNN算法的变体，本案例每种形状只提供了一个样本，因此，将KNN算法中的k值取1，以最近的那个邻近点的类别判断未知形状的分类。</span><br><span class="line"></span><br><span class="line">算法具体过程为：首先采集样本图像（图11-24所示的样本图像文件名从左到右分别是shape0.png、shape1.png、shape2.png）的特征值，然后以未知形状图像的特征值为分类数据，进行KNN分类，最后将未知图像归为上图所示的3类之中，从左边数起，类别分别为0（方形）、1（圆形）、2（三角形），Python代码如程序11-10.py所示。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    # -*-coding: utf-8 -*-    
    #code:myhaspl@myhaspl.com  
    #形状检测


    #11-10.py
    import cv2  
    import numpy as np  
    def mydist(point1,point2):
        #两点间的距离


        return 
    np.sqrt(np.power((point1[0]-point2[0]),2)+np.power((point1[1]-point2[1]),2))
    #离中心点距离的标准差


    def getstd(tmpimg,centerpoint):
        w=tmpimg.shape[1]  
        h=tmpimg.shape[0] 
        dst=[]
        for i in xrange(h):
            for j in xrange(w):
                if tmpimg[i,j]<255: #该像素不是空白 ,是线条中的点 dst.append(mydist((i,j),centerpoint)) mysd="np.std(dst)" return #读取样本形状图像，计算标准差 imgsd="[]" testimgsd="[]" mysdratio="[]" centerpoint="(26,26)" for i in xrange(3): tmpimg="(cv2.imread(" shape"+str(i)+".png"))" myimg="cv2.cvtColor(tmpimg,cv2.COLOR_BGR2GRAY)" retval, newimg="cv2.threshold(myimg,40,255,cv2.THRESH_BINARY)" imgsd.append(getstd(myimg,centerpoint)) print "--------------" xrange(4): #测试样本 fn="shapetest_" +str(i)+".png" #得到距离标准差 testimgsd.append(getstd(myimg,centerpoint)) mysdratio.append([]) ii #与样本进行比较 mysdratio[i].append(abs(testimgsd[i]-imgsd[ii])) u"knn距离矩阵如下 " #knn算法，找到最近邻 myindex="0" mymin="np.min(mysdratio[i])" #测试样本最终分类 if (mysdratio[i][ii])="=mymin:" break fn+u"分类为： "+str(myindex) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">执行程序11-10.py后，输出KNN距离矩阵及分类结果，类别0表示方形，类别1表示圆形，类别2表示三角形。结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    --------------
    KNN距离矩阵如下


    [[0.71030223330565079, 0.75471514364899916, 3.9533561391620591], [1.2922713309313281, 0.17274604602332189, 4.5353252367877364], [2.0123227209027084, 3.4773400978573585, 1.2307311849536999], [0.49271253133816462, 0.97230484561648534, 3.7357664371945729]]
    --------------
    shapetest_0.png分类为：

    0
    shapetest_1.png分类为：

    1
    shapetest_2.png分类为：

    2
    shapetest_3.png分类为：

    0 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序11-10.py使用的测试图像如图11-25所示。</span><br><span class="line"></span><br><span class="line">![](Image00526.jpg)</span><br><span class="line"></span><br><span class="line">图11-25 测试图像</span><br><span class="line"></span><br><span class="line">观察图11-25及程序11-10.py的输出结果，可发现测试图像的分类结果是正确的，效果还不错。</span><br><span class="line"></span><br><span class="line">为提高分类准确率，实践中可采用标准的KNN算法，为每种形状提供更多的样本，分类的方法为：如果与未知形状的k个最相似的大多数样本属于某一个类别，那么该未知形状也属于这个类别。</span><br><span class="line"></span><br><span class="line">### 11.5 小结</span><br><span class="line"></span><br><span class="line">计算机视觉研究使机器能看懂图像，属于人工智能和机器学习的范畴。目前机器视觉实现的主要方式是：首先，使用摄像机等设备采集画面，生成数字图像；然后，对图像进行预处理和加工，提取特征；最后，分析图像特征，挖掘图像包含的知识和信息。本章讲述了运用机器学习算法对视频和图像进行加工、分析、提取特征、总结知识等技术，首先介绍了人脸辨识的算法，然后讲解了手写数字识别的算法，最后讲述了运动侦测技术和形状检测的方法，在讲解这些算法的过程中，注重实践效果，每个实例均用Python进行实现，以验证算法的有效性。</span><br><span class="line"></span><br><span class="line">### 思考题</span><br><span class="line"></span><br><span class="line">（1）以多个图像进行更多的人脸辨识实验，尝试应用更多的机器学习算法，比如应用SVM和神经网络，或者对欧氏距离算法进行进一步改进，对人脸的不同部位赋予不同的权重，总结各算法的实际应用效果。</span><br><span class="line"></span><br><span class="line">（2）实现从a到z的24个字母图像的识别算法，要求识别未知样本图像表征的字母。</span><br><span class="line"></span><br><span class="line">（3）运用本章介绍的运动侦测方法，分析自己的计算机摄像头所采集的视频。</span><br><span class="line"></span><br><span class="line">（4）运用本章介绍的形状检测方法或其他方法，对某类复杂的鼠标（或触摸屏输入）手势进行识别，比如以下手势：</span><br><span class="line"></span><br><span class="line">![](Image00527.jpg)</span><br><span class="line"></span><br><span class="line">## 第12章 文本分类案例</span><br><span class="line"></span><br><span class="line">在网络信息时代，全球正面临着前所未有的信息爆炸式增长的挑战，中文信息处理也迎来了高速发展。如果拥有着海量的中文文字数据对数据知识的提取依旧停留在过去简单查询、检索的水平上，那么就会导致所谓的“数据爆炸但知识贫乏”的现象。从中文信息中获取知识，快速有效地组织和管理用户所要的信息是当前信息科学和技术所面临的重要挑战。</span><br><span class="line"></span><br><span class="line">数据挖掘技术致力于从海量数据中提取有用的信息，文本分类等文本挖掘技术则属于数据挖掘领域中被研究的热点。文本挖掘是人工智能、机器学习、自然语言处理、数据挖掘及相关自动文本处理（如信息抽取、信息检索）等领域中理论和技术结合的产物。文本分类是文本挖掘领域的一个重要分支，而且逐渐成为一个日益重要的研究领域。自动文本分类则会依据文本内容，由计算机根据某种自动分类算法把文本划分为预先定义好的类别，它是对复杂类型的数据进行挖掘的技术。</span><br><span class="line"></span><br><span class="line">### 12.1 文本分类概述</span><br><span class="line"></span><br><span class="line">近年来，随着互联网的高速发展和大数据时代的到来，文本分类等文本挖掘技术应用于越来越多的领域。互联网和大数据是信息技术发展催生的一对孪生子。互联网能够方便、准确地记录用户数据，产生了大量的半结构化、非结构化的文本数据，这也使互联网成为大数据分析应用最广泛的领域之一。例如：搜索引擎技术的基础就是基于文本分析算法的，而面向互联网用户的精准营销则是以广告数据分析（现在已经催生了一门科学“计算广告学”）为依据的。海量文档数据库需要高效的文本挖掘算法作为数据索引、查询分析的核心算法，智能输入法需要分析用户输入习惯及输入的词句，自动客服系统由原始的词语匹配技术转变为基于文本挖掘的自然语言理解算法。</span><br><span class="line"></span><br><span class="line">分类技术是数据挖掘中非常重要的分支。分类就是根据数据集的特点找出类别的概念描述，这个概念描述代表了这类数据的整体信息，也就是该类的内涵描述，使用这种类的描述可对未来的测试数据进行分类。</span><br><span class="line"></span><br><span class="line">文本挖掘算法在搜索引擎中一直扮演着重要的角色，搜索引擎每个阶段的发展都伴随着文本挖掘技术的进步。1990年，作为可搜索FTP文件名列表的Archie，通过文件名匹配技术完成了文本检索。1993年，世界上第一个Spider程序——World Wide Web Wanderer开始在网络间爬取资料，统计互联网上的服务器数量。同年，Stanford大学的学生创造了Excite，它通过分析字词关系进行更有效的检索，文本挖掘技术再次进步。1994年，杨致远和David Filo共创办了Yahoo，Yahoo网站的分类目录由人工整理维护，他们会精选互联网上的优秀网站，进行简要描述后，分类放置到不同目录下。用户查询时，通过一层层的点击来查找自己想找的网站，人工分类精准度高，但工作量很大。同年Lycos正式发布，Lycos使用了更先进的文本挖掘技术，包括：相关性排序、前缀匹配和字符相近限制、网页自动摘要等。1995年，更多的文本挖掘技术陆续产生，AltaVista在搜索引擎中引入了自然语言搜索技术，实现高级搜索语法（如AND、OR、NOT等）。1997年，文本自动分类技术首次应用于Northernlight搜索引擎，该搜索引擎支持对搜索结果进行简单的自动分类。同年，google.com的域名被Larry Page注册，Google横空出世，之后发展成为今天的搜索业巨头。2013年全球在线广告营收中，Google预计占有超过33%的市场份额，在全球移动广告营收中，Google的市场份额约56%。Google研究和应用了大量文本挖掘算法，例如：Pagerank、动态摘要、网页快照、DailyRefresh、多文档格式支持等。有人评论说Google永远改变了搜索引擎的定义。2001年，百度搜索引擎发布，和Google一样，百度也研发和使用了很多文本挖掘算法：网页快照、相关搜索词、错别字纠正、Flash搜索、信息快递搜索、图像搜索、新闻搜索等。</span><br><span class="line"></span><br><span class="line">近年来，借助模式识别算法，文本分类技术飞速发展。文本分类大致分为几个要素：文本向量模型表示、文本特征选择和文本训练分类器。目前比较流行的分类方法主要有SVM、改进余弦相似度、贝叶斯方法、神经网络、k2最近邻方法、遗传算法、粗糙集等。文本分类算法通常包括文本预处理（中文分词、去除停用词）、文本特征提取、样本特征学习及算法对未知样本的预测等过程。</span><br><span class="line"></span><br><span class="line">本章将以余弦相似度、朴素贝叶斯分类算法为主，阐述文本分类技术。</span><br><span class="line"></span><br><span class="line">### 12.2 余弦相似度分类</span><br><span class="line"></span><br><span class="line">基于余弦相似度的文本分类算法实现的基本过程为：首先对样本文本进行分词，接着将垃圾词剔除，然后根据剔除后的词条把样本文本中的所有词映射到n维空间的一个向量上，并计算未知文本特征组形成的向量与各类别特征组向量之间夹角的余弦值，最后通过比较余弦值的大小判断最接近的分类。</span><br><span class="line"></span><br><span class="line">#### 12.2.1 中文分词</span><br><span class="line"></span><br><span class="line">中文分词指的是将一个汉字序列切分成一个个单独的词。中文分词是文本挖掘的基础，对于一段中文文本，中文分词是文本自动识别的前提。目前常用的中文分词软件主要有以下几种：</span><br><span class="line"></span><br><span class="line">·SCWS。基于词频词典的机械中文分词引擎，它能将一整段的汉字基本正确地切分成词。采用的是采集的词频词典（词频TF指某一个给定的词语在一份给定的文件里出现的次数，近年来，利用计算机进行词频统计，以词频统计的结果来验证词典收词的得失，决定哪些词需要收录，中文词频词典按词频排序存储词语和词组），并辅以一定的专有名称、人名、地名、数字、年代等识别规则，从而达到基本分词的目的。</span><br><span class="line"></span><br><span class="line">·ICTCLAS。这是最早的中文开源分词项目，在国内973专家组组织的评测活动中获得了第一名，在第一届国际中文处理研究机构SigHan组织的评测中获得了多项第一名。ICTCLAS全部采用C/C++编写，支持Linux、FreeBSD及Windows系列操作系统，支持C/C++、C#、Delphi、Java等主流的开发语言。</span><br><span class="line"></span><br><span class="line">·HTTPCWS。基于HTTP协议的开源中文分词系统，将取代之前的PHPCWS中文分词扩展。</span><br><span class="line"></span><br><span class="line">·庖丁解牛分词。仅支持Java语言，且提供lucence（一款流行的Java全文搜索引擎）接口。</span><br><span class="line"></span><br><span class="line">·CC-CEDICT。提供一份以汉语拼音为中文辅助的汉英辞典，其词典可以用于中文分词，Chrome中文版就是使用这个词典进行中文分词的。</span><br><span class="line"></span><br><span class="line">·“结巴”（Jieba）中文分词。Python中文分词组件Jieba支持3种分词模式：精确模式，试图将句子最精确地切开，适合文本分析；全模式，把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义；搜索引擎模式，在精确模式的基础上，对长词再次切分，提高招回率，适合用于搜索引擎分词。</span><br><span class="line"></span><br><span class="line">本章基于Python实现算法，因此选择“结巴”中文分词作为分词组件库。可在&lt;http://pypi.python.org/pypi/jieba&gt; 处下载，解压后运行pythonsetup.py install进行安装。下面的代码演示了分词组件Jieba的基本使用方法。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-1.py
    import sys
    sys.path.append("../")
    import jieba
    seg_list = jieba.cut("我来到北京清华大学

    ", cut_all=True)
    print "Full Mode:", "/ ".join(seg_list) # 全模式


    seg_list = jieba.cut("我来到北京清华大学

    ", cut_all=False)
    print "Default Mode:", "/ ".join(seg_list) # 默认模式


    seg_list = jieba.cut("他来到了网易杭研大厦

    ")
    print ", ".join(seg_list)
    seg_list = jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在日本京都大学深造

    ") # 搜索引擎模式


    print ", ".join(seg_list) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">演示程序的分词效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    / 我

    / 来到

    / 北京

    / 清华

    / 清华大学

    / 华大

    / 大学

    / 
    Default Mode: 我

    / 来到

    / 北京

    / 清华大学

    他

    , 来到

    , 了

    , 网易

    , 杭研

    , 大厦

    小明

    , 硕士

    , 毕业

    , 于

    , 中国

    , 科学

    , 学院

    , 科学院

    , 中国科学院

    , 计算

    , 计算所

    , ，

    , 后

    , 在

    , 日本

    , 京都

    , 大学

    , 日本京都大学

    , 深造

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">中文分词有一个困难，就是会遇到歧义。同样的一句话，可能有两种或者更多的切分方法。主要的歧义有两种：交集型歧义和组合型歧义。例如：语句中出现了“漂亮的”，因为“漂亮”和“亮的”都是词，那么这个短语就可以分成“漂亮/的”和“漂/亮的”，这种称为交集型歧义。组合型歧义情况更复杂，要根据整个句型来判断，比如：句子“2010年底部队友谊篮球赛结束”，“底部”是一个词，“年底”是一个词，“部队”是一个词，“队友”是一个词，“友谊”是一个词，而分词不能曲解句子含义，这样就产生了分词困难。</span><br><span class="line"></span><br><span class="line">目前大部分分词软件能较好地解决歧义问题。下面试着应用“结巴”分词对“2010年底部队友谊篮球赛结束”分词。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-2.py
    import jieba
    seg_list = jieba.cut("2010年底部队友谊篮球赛结束

    ", cut_all=False)
    print "Default Mode:", "/ ".join(seg_list) # 默认模式

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从下面的执行结果来看，分词效果很理想。“结巴”分词技术比较成熟，能应用于实际工程中。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    Default Mode:Building Trie..., from E:\WinPython-32bit-2.7.5.1\python-2.7.5\lib\site-packages\jieba\dict.txt
    loading model from cache c:\users\admini~1\appdata\local\temp\jieba.cache
     2010/ 年底

    / 部队

    / 友谊

    / 篮球赛

    / 结束


    loading model cost  1.26200008392 seconds.
    Trie has been built succesfully. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面执行结果的第一行中的Trie是一种数据结构，“结巴”分词使用它构造词条字典。Trie称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中的，而是由节点在树中的位置决定的。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。</span><br><span class="line"></span><br><span class="line">#### 12.2.2 停用词清理</span><br><span class="line"></span><br><span class="line">停用词又称垃圾词。完成自然语言理解与文本分类等任务时，都需要预处理文本，自动过滤掉某些不能表征意义的字、词或符号，这些字或词被称为停用词（Stop Words）。进行文本分词后形成的词条组中会存在很多停用词，这些词基本不具备表示文本特征的能力，其存在会影响其他词对文本特征的表征能力，因此，需要过滤后才能形成“干净”的文本特征码。</span><br><span class="line"></span><br><span class="line">例如：对下面这句话进行分词：“春秋时期有一个农夫，他总是嫌田里的庄稼长得太慢，今天去瞧瞧，明天去看看，觉得禾苗好像总没有长高。他心想：有什么办法能使它们长得高些快些呢？”代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-3.py
    import jieba
    seg_list = jieba.cut("春秋时期有一个农夫，他总是嫌田里的庄稼长得太慢，今天去瞧瞧，明天去看看，觉得禾苗好像总没有长高。他心想：有什么办法能使它们长得高些快些呢？

     ", cut_all=False)
    print "Default Mode:", "/ ".join(seg_list)##默认模式


    .......
    ....... <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">分词效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    春秋时期

    / 有

    / 一个

    / 农夫

    / ，

    / 他

    / 总是

    / 嫌

    / 田里

    / 的

    / 庄稼

    / 长得

    / 太慢

    / ，

    / 今天

    / 去

    / 瞧瞧

    / ，

    / 明天

    / 去

    / 看看

    / ，

    / 觉得

    / 禾苗

    / 好像

    / 总

    / 没有

    / 长高

    / 。

    / 他

    / 心想

    / ：

    / 有

    / 什么

    / 办法

    / 能

    / 使

    / 它们

    / 长得

    / 高些

    / 快些

    / 呢

    / ？

    / <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述分词结果中，“有”“能”“呢”“什么”等词以及标点符号都属于停用词的范围，应对其进行清理。清理的方式是建立停用词表，扫描分词结果，从中剔除停用词表中的词条。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-3.py
    import jieba
    seg_list = jieba.cut("春秋时期有一个农夫，他总是嫌田里的庄稼长得太慢，今天去瞧瞧，明天去看看，觉得禾苗好像总没有长高。他心想：有什么办法能使它们长得高些快些呢？

     ", cut_all=False)
    liststr="/ ".join(seg_list)
    print u"------清理前的词条

    ---------"
    print "Default Mode:", liststr##默认模式


    print u"------清理后的词条

    ---------"
    #停用词清理


    f_stop = open('stopwords.txt')  
    try:  
        f_stop_text = f_stop.read( )
        f_stop_text=unicode(f_stop_text,'utf-8')
    finally:  
        f_stop.close( ) 
    f_stop_seg_list=f_stop_text.split('\n')
    for myword in liststr.split('/'):
        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
            print myword,',', <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从直观上看，清理停用词后留下的文本词条表征文本的能力都比较强。来比较一下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ------清理前的词条

    ---------
    Default Mode: 春秋时期

    / 有

    / 一个

    / 农夫

    / ，

    / 他

    / 总是

    / 嫌

    / 田里

    / 的

    / 庄稼

    / 长得

    / 太慢

    / ，

    / 今天

    / 去

    / 瞧瞧

    / ，

    / 明天

    / 去

    / 看看

    / ，

    / 觉得

    / 禾苗

    / 好像

    / 总

    / 没有

    / 长高

    / 。

    / 他

    / 心想

    / ：

    / 有

    / 什么

    / 办法

    / 能

    / 使

    / 它们

    / 长得

    / 高些

    / 快些

    / 呢

    / ？

    /  
    ------清理后的词条

    ---------春秋时期

     ,  一个

     ,  农夫

     ,  总是

     ,  田里

     ,  庄稼

     ,  长得

     ,  太慢

     ,  今天

     ,  瞧瞧

     ,  明天

     ,  看看

     ,  觉得

     ,  禾苗

     ,  好像

     ,  长高

     ,  心想

     ,  办法

     ,  长得

     ,  高些

     ,  快些

     , <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 12.2.3 算法实战</span><br><span class="line"></span><br><span class="line">1.任务描述</span><br><span class="line"></span><br><span class="line">假设提供了一个描述战争的样本数据，如图12-1所示。现在需要对两个未知类型文本进行分析，它们的内容如图12-2和图12-3所示，判断哪个文本是描述战争类的。</span><br><span class="line"></span><br><span class="line">![](Image00528.jpg)</span><br><span class="line"></span><br><span class="line">图12-1 描述战争的样本文本</span><br><span class="line"></span><br><span class="line">![](Image00529.jpg)</span><br><span class="line"></span><br><span class="line">图12-2 描述战争的未知类型文本</span><br><span class="line"></span><br><span class="line">2.算法过程</span><br><span class="line"></span><br><span class="line">用余弦相似度算法完成上述文本分类任务的过程如下：</span><br><span class="line"></span><br><span class="line">1）读取样本文本。</span><br><span class="line"></span><br><span class="line">2）对文本进行utf-8编码转换。</span><br><span class="line"></span><br><span class="line">3）对文本进行预处理，完成中文分词，形成词条库，并去除停用词。</span><br><span class="line"></span><br><span class="line">4）读取文本词条库，统计每个词条的词频。词频代表了每个词对一段文本的的重要程度，字词的重要性随着它在文件中出现的次数成正比增加。</span><br><span class="line"></span><br><span class="line">5）将上一步整理形成的每个词的词频组成文本的词条词频特征码。</span><br><span class="line"></span><br><span class="line">![](Image00530.jpg)</span><br><span class="line"></span><br><span class="line">图12-3 描述手机的未知类型文本</span><br><span class="line"></span><br><span class="line">6）使用前面第1步到第5步的方法分析待分类文本，生成待分类文本的词条词频特征码。</span><br><span class="line"></span><br><span class="line">7）将待分类文本的词条词频特征码与样本的词条词频特征码进行比较，应用余弦相似度算法判断待分类文本与样本的相似度，取最相似的类型为最终分类的类型。</span><br><span class="line"></span><br><span class="line">下面用Python实现上述算法过程。</span><br><span class="line"></span><br><span class="line">1）读取样本文本，完成utf-8编码转换，然后进行中文分词。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

        print
        print 'loading  ...'
        print 'working',   
        f1 = open(sampfn)  
        try:  
            f1_text = f1.read( ) 
            f1_text=unicode(f1_text,'utf-8')
        finally:  
            f1.close( ) 
        f1_seg_list = jieba.cut(f1_text) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）对文本词条进行预处理，去除停用词，计算每个词条的词频。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     #去除停用词，同时构造样本词的字典


        f_stop = open('stopwords.txt')  
        try:  
            f_stop_text = f_stop.read( )
            f_stop_text=unicode(f_stop_text,'utf-8')
        finally:  
            f_stop.close( ) 
        f_stop_seg_list=f_stop_text.split('\n')
        test_words={}
        all_words={}
        for  myword in f1_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
                test_words.setdefault(myword,0)
                all_words.setdefault(myword,0)
                all_words[myword]+=1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）读取待分类文本，进行中文分词。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

        #第一个待测试数据


        ftest1 = open(ftest1fn)  
        try:  
            ftest1_text = ftest1.read( ) 
            ftest1_text=unicode(ftest1_text,'utf-8')
        finally:  
            ftest1.close( ) 
        ftest1_seg_list = jieba.cut(ftest1_text)
        #第二个待测试数据


        ftest2 = open(ftest2fn)  
        try:  
               ftest2_text = ftest2.read( ) 
       ftest2_text=unicode(ftest2_text,'utf-8')
       finally:  
            ftest2.close( ) 
       ftest2_seg_list = jieba.cut(ftest2_text) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4）继续预处理待分类文本，去除停用词，并生成词频特征码。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

       #读取待测试文本


        mytest1_words=copy.deepcopy(test_words)
        for  myword in ftest1_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
               if mytest1_words.has_key(myword):
                  mytest1_words[myword]+=1
        mytest2_words=copy.deepcopy(test_words)
        for  myword in ftest2_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
                if mytest2_words.has_key(myword):
                   mytest2_words[myword]+=1 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">5）计算并输出样本与待测试文本的余弦相似度。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     #计算样本与待测试文本的余弦相似度


        sampdata=[]
        test1data=[]
        test2data=[]
        for key in all_words.keys():
            sampdata.append(all_words[key])
            test1data.append(mytest1_words[key])
            test2data.append(mytest2_words[key])
        test1simi=get_cossimi(sampdata,test1data)
        test2simi=get_cossimi(sampdata,test2data)
    print u"%s与样本

    [%s]的余弦相似度

    :%f"%(ftest1fn,sampfn,test1simi)
    print u"%s与样本

    [%s]的余弦相似度

    :%f"%(ftest2fn,sampfn,test2simi) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面这段代码调用了get_cossimi函数，这是余弦相似度计算函数。该函数的定义如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def get_cossimi(x,y):
        myx=np.array(x)
        myy=np.array(y)
        cos1=np.sum(myx*myy)
        cos21=np.sqrt(sum(myx*myx))
        cos22=np.sqrt(sum(myy*myy))
        return cos1/float(cos21*cos22) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6）根据屏幕输出的相似度，预测分类。</span><br><span class="line"></span><br><span class="line">两个向量之间的角度余弦值确定两个向量是否大致指向相同的方向。如果两个向量有相同的指向，余弦相似度的值为1；如果两个向量夹角为90，余弦相似度的值则为0。可见，余弦相似度越接近1，两个文本就越相似。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    .............
    mobile2.txt与样本

    [war2.txt]的余弦相似度

    :0.160806
    war1.txt与样本

    [war2.txt]的余弦相似度

    :0.264215 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上面是代码的执行结果，分析这个结果可得出结论：mobile2.txt与war2.txt的余弦相似度较小，war1.txt与war2.txt的余弦相似度为0.264215，更接近1。因此，应将war1.txt文本文件划分为战争类。</span><br><span class="line"></span><br><span class="line">以下是全部源代码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-4.py
    import numpy as np
    import jieba
    import copy
    ftest1fn='mobile2.txt'
    ftest2fn='war1.txt'
    sampfn='war2.txt'
    def get_cossimi(x,y):
        myx=np.array(x)
        myy=np.array(y)
        cos1=np.sum(myx*myy)
        cos21=np.sqrt(sum(myx*myx))
        cos22=np.sqrt(sum(myy*myy))
        return cos1/float(cos21*cos22)   
    if __name__ == '__main__':
        print
        print 'loading  ...'
        print 'working',   
        f1 = open(sampfn)  
        try:  
            f1_text = f1.read( ) 
            f1_text=unicode(f1_text,'utf-8')
        finally:  
            f1.close( ) 
        f1_seg_list = jieba.cut(f1_text)
        #第一个待测试数据


        ftest1 = open(ftest1fn)  
        try:  
            ftest1_text = ftest1.read( ) 
            ftest1_text=unicode(ftest1_text,'utf-8')
        finally:  
            ftest1.close( ) 
        ftest1_seg_list = jieba.cut(ftest1_text)
        #第二个待测试数据


        ftest2 = open(ftest2fn)  
        try:  
            ftest2_text = ftest2.read( ) 
            ftest2_text=unicode(ftest2_text,'utf-8')
        finally:  
            ftest2.close( ) 
        ftest2_seg_list = jieba.cut(ftest2_text)
        #读取样本文本


        #去除停用词，同时构造样本词的字典


        f_stop = open('stopwords.txt')  
        try:  
            f_stop_text = f_stop.read( )
            f_stop_text=unicode(f_stop_text,'utf-8')
        finally:  
            f_stop.close( ) 
        f_stop_seg_list=f_stop_text.split('\n')
        test_words={}
        all_words={}
        for  myword in f1_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
                test_words.setdefault(myword,0)
                all_words.setdefault(myword,0)
                all_words[myword]+=1
        #读取待测试文本


        mytest1_words=copy.deepcopy(test_words)
        for  myword in ftest1_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
                if mytest1_words.has_key(myword):
                    mytest1_words[myword]+=1
        mytest2_words=copy.deepcopy(test_words)
        for  myword in ftest2_seg_list:
            print ".",
            if not(myword.strip() in f_stop_seg_list):
                if mytest2_words.has_key(myword):
                    mytest2_words[myword]+=1                
        #计算样本与待测试文本的余弦相似度


        sampdata=[]
        test1data=[]
        test2data=[]
        for key in all_words.keys():
            sampdata.append(all_words[key])
            test1data.append(mytest1_words[key])
            test2data.append(mytest2_words[key])
        test1simi=get_cossimi(sampdata,test1data)
        test2simi=get_cossimi(sampdata,test2data)
        print u"%s与样本

    [%s]的余弦相似度

    :%f"%(ftest1fn,sampfn,test1simi)
        print u"%s与样本

    [%s]的余弦相似度

    :%f"%(ftest2fn,sampfn,test2simi) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 12.3 朴素贝叶斯分类</span><br><span class="line"></span><br><span class="line">贝叶斯是一种基于概率的学习算法，其性能可与决策树、神经网络等算法相媲美，是文本分类挖掘技术的典型代表。它以贝叶斯定理为基础，预测成员关系的可能性，由于其具有坚实的数学理论基础，并且能综合先验信息和数据样本信息，因此成为当前机器学习和数据挖掘的研究热点之一。朴素贝叶斯分类器是目前公认的一种简单有效的概率分类方法，这种分类方法具有非常高的计算效率，在某些应用问题上表现出较好的分类精度，因而被广泛地应用于文本挖掘领域。</span><br><span class="line"></span><br><span class="line">#### 12.3.1 算法描述</span><br><span class="line"></span><br><span class="line">标准的朴素贝叶斯分类算法的执行过程如下：</span><br><span class="line"></span><br><span class="line">1）获取样本文本，将样本人工分类整理，并进行标记。</span><br><span class="line"></span><br><span class="line">2）对每个类别的样本文本进行中文分词。</span><br><span class="line"></span><br><span class="line">3）去除样本文本中垃圾词条。</span><br><span class="line"></span><br><span class="line">4）将整理后词条合成样本文本的特征组，分析并计算词条频率信息。例如：假设共有3个类别的文本，词条i在类别A、B、C中出现的次数分别为COUNTi</span><br><span class="line">(A)、COUNTi (B)、COUNTi</span><br><span class="line">(C)，每个类别的词条总数为WORDCOUNT(A)、WORDCOUNT(B)、WORDCOUNT(C)，那么根据词每个类别的词条总数与词条在每个类别出现的次数就能计算词条频率，计算方式是：词语在每个类别出现的次数除以该类别的总词语数。</span><br><span class="line"></span><br><span class="line">比如，某类别的词条总数是100个，而词条“冬天”出现了5次，那么“冬天”一词在该文件中的词频就是0.05（5/100）。</span><br><span class="line"></span><br><span class="line">5）根据词条频率信息，计算词条在各类别文本的先验概率。词条i的各类别先验概率计算公式为：</span><br><span class="line"></span><br><span class="line">Pi (A)=COUNTi (A)/WORDCOUNT(A)</span><br><span class="line"></span><br><span class="line">Pi (B)=COUNTi (B)/WORDCOUNT(B)</span><br><span class="line"></span><br><span class="line">Pi (C)=COUNTi (C)/WORDCOUNT(C)</span><br><span class="line"></span><br><span class="line">6）读取未知样本，进行中文分词，并去除垃圾词，然后形成样本特征组。</span><br><span class="line"></span><br><span class="line">7）将未知样本特征词条的先验概率代入朴素贝叶斯公式计算后验算概率，计算得到的最大概率的所属类别即为文本所属类别。</span><br><span class="line"></span><br><span class="line">#### 12.3.2 先验概率计算</span><br><span class="line"></span><br><span class="line">同一条词条在不同类型的文本中出现的频率通常是不一样的，很多词条只会在某些类别的文本中出现，比如说“微软”、“谷歌”、“医保”、“乔布斯”等词条极少出现在战争类题材的文本中，而“黑莓”、“3G”、“手机”、“电信”等词极少出现在健康类题材的文本中。词条先验概率计算通过提取不同类别中样本的词条，分析其在所有类别中出现的概率，它会以词条为键值，生成词条先验概率哈希数组（在Python中称为字典结构），以供后期分类算法使用。</span><br><span class="line"></span><br><span class="line">根据朴素贝叶斯的先验概率计算公式来看，在后期计算中，需要计算词条先验概率累乘。如果某词在某类型的样本中从来没有出现，其概率为0，这样将会使累乘结果变为0，算法变得毫无意义。在计算先验概率后，在每个词条的先验概率基础上加上一个适当的较小的概率值，防止累乘出现0。此外，某词在某类型的所有样本中未出现，不代表该词不会出现在该类型的所有文本中，因此，这个较小概率值非常有必要加入先验概率的计算中。</span><br><span class="line"></span><br><span class="line">#### 12.3.3 最大后验概率</span><br><span class="line"></span><br><span class="line">对未知文本分类时，需要计算后验概率，对于在未知文本中出现的词条，提取其在先验概率哈希数组中的概率值。然后分别计算不同类型哈希数组中出现的词条的先验概率累乘，从而得到未知文本属于不同类型的后验概率，其中，最大概率所属类别即为未知文本所属类别。</span><br><span class="line"></span><br><span class="line">#### 12.3.4 算法实现</span><br><span class="line"></span><br><span class="line">这里分别提取数量几乎相同的新闻文本作为样本，这些样本属于汽车、财经、健康、教育、军事类新闻，对样本进行分析。为了验证效果，最后使用未在样本中出现的新闻正文链接进行测试，分析该链接指向的新闻所属类别。</span><br><span class="line"></span><br><span class="line">1.新闻爬取</span><br><span class="line"></span><br><span class="line">提取新闻文本的原理与搜索引擎相同。首先，通过类似爬虫的程序对新闻进行爬取，分析新闻主页的新闻正文链接；接着爬取新闻正文网页，清理HTML标记；然后形成文本样本，为提高效率，仅在内存中形成文本样本，不在本地硬盘保存；最后，以内存数据为基础，进行下一步分析。相关代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #读取网上新闻搜索目录


    txt_class=[]
    myclassfl = open('ClassList.txt')  
    try:  
        myclass_str = myclassfl.read() 
        myclass_str=unicode(myclass_str,'gbk')
        myclass_text=myclass_str.split()
        for ii in xrange(0,len(myclass_text),2):
            print ".",
            txt_class.append((myclass_text[ii],myclass_text[ii+1]))            
    finally:  
        myclassfl.close()
    links=[]
    #分类别爬取网页，生成词条数据


    for ci in xrange(0,len(txt_class)):
        print u"\n爬取

    %s类网页

    :%s" % (txt_class[ci][0],txt_class[ci][1])
        links.append([])    
        pattern = re.compile(r'(.*?)/\d+\.shtml')
        purl=txt_class[ci][1]
        page=urllib2.urlopen(purl)
        soup = BeautifulSoup(page)
        for link in soup.find_all('a'): 
            mylink=link.get('href')
            match = pattern.match(mylink)
            if match and mylink.find("hd")<0: basestr="http://www.chinanews.com" if mylink.find("chinanews.com")<0: mylink="basestr+mylink" print links[ci].append(mylink) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.先验概率计算</span><br><span class="line"></span><br><span class="line">提取不同类别中样本的词条，分析其在所有类别中出现的概率，生成以词条为键值的先验概率字典变量。此外，根据朴素贝叶斯的先验概率计算公式，在后期计算中，需要计算词条先验概率累乘，所以在每个词条的先验概率基础上加上一个适当的较小的概率值，防止累乘出现0。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table>

    #词条在每个样本中出现的次数


    basegl=1e-8
    wordybcount={}
    lbcount=np.zeros(len(yb_txt))
    #整理计算词条出现次数


    for i in xrange(0,len(yb_txt)):
        for j in xrange(0,len(yb_txt[i])):       
            for k in xrange(0,len(yb_txt[i][j])):
                my_word=yb_txt[i][j][k].encode('gbk')
                wordybcount.setdefault(my_word,np.repeat(0,len(yb_txt)).tolist())           
                wordybcount[my_word][i]+=1
                lbcount[i]+=1
    #计算词条先验概率


    print u"\n计算词条概率

    "
    ybgl={}
    for my_word in wordybcount.keys():
        ybgl.setdefault(my_word,np.repeat(0.,len(yb_txt)).tolist())
        for ybii in xrange(0,len(yb_txt)):
            ybgl[my_word][ybii]=basegl+wordybcount[my_word][ybii]/float(lbcount[ybii])
            print '.', <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.后验概率计算</span><br><span class="line"></span><br><span class="line">读取待分类文本的先验概率字典变量，提取每个词条的先验概率值，然后计算不同类型中出现的词条的先验概率累乘，最后得到待分类文本属于不同类型的后验概率。代码如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #计算待分类文本后验概率


    print u"计算待分类文本后验概率

    "
    testgl=None
    wordgl=None     
    testgl=np.repeat(1.,len(yb_txt))
    for  myword in ftest_seg_list:
        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
            myword=myword.encode('gbk')
            for i in xrange(0,len(yb_txt)):
                wordgl=ybgl.get(myword)
                if wordgl:
                   if wordgl[i]<>0:
                      testgl[i]*=wordgl[i]
                      if np.min(testgl)<1e-50: testgl*="1e20" if np.max(testgl)>1e100:
                            testgl/=float(1e30) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">运行程序，读取网页&lt;http://www.chinanews.com/edu/2013/09-17/5296319.shtml&gt; 和&lt;http://finance.chinanews.com/auto/2013/09-16/5290491.shtml&gt; ，以这两个网页为测试对象进行分类。执行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    .............
    .............读取待分类文本


    <http: 2013 www.chinanews.com edu 09-17 5296319.shtml>

    读取成功

    .计算待分类文本后验概率


    <http: 2013 www.chinanews.com edu 09-17 5296319.shtml>


    :教育

    计算待分类文本后验概率


    <http: 2013 finance.chinanews.com auto 09-16 5290491.shtml>


    :汽车

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">从以上执行结果看，两个新闻链接被成功地划分到教育类新闻和汽车类新闻，分类效果良好。</span><br><span class="line"></span><br><span class="line">本例中，样本数量较小，在实际应用中，每个类别应准备更多的样本文本。通常来说，一个分类效果较好的朴素贝叶斯算法，其每个类别的样本数量大致有2000~10000个。近年来，基于朴素贝叶斯分类的改进算法越来越多，最普遍的是在算法中加入权重的影响，针对某些关键词或中心词加上权重，这种方法法被称为加权朴素贝叶斯算法。</span><br><span class="line"></span><br><span class="line">关于加权朴素贝叶斯算法的更多细节，可以查看在《厦门大学学报：自然科学版》2012年第4期上刊登的饶丽丽等的文章《基于特征相关的改进加权朴素贝叶斯分类算法》，也可以在Google学术搜索（&lt;http://scholar.google.com.hk/schhphl=zh-CN&gt; ）中以“加权朴素贝叶斯分类算法”为关键字进行搜索。</span><br><span class="line"></span><br><span class="line">以下是完整的Python代码：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #!/usr/bin/env python
    #-*-coding: utf-8 -*-
    #code:myhaspl@qq.com
    #12-5.py
    #bayes文本分类


    #本程序仅做机器学习研究


    #本程序对新闻爬取的工作原理与搜索引擎相同，通过分析链接


    #直接搜索新闻

    ,计算词条概率


    import numpy as np
    import jieba
    import urllib2
    from bs4 import BeautifulSoup
    import re
    #读取网上新闻搜索目录


    txt_class=[]
    myclassfl = open('ClassList.txt')  
    try:  
        myclass_str = myclassfl.read() 
        myclass_str=unicode(myclass_str,'gbk')
        myclass_text=myclass_str.split()
        for ii in xrange(0,len(myclass_text),2):
            print ".",
            txt_class.append((myclass_text[ii],myclass_text[ii+1]))            
    finally:  
        myclassfl.close()
    links=[]
    #分类别爬取网页，生成词条数据


    for ci in xrange(0,len(txt_class)):
        print u"\n爬取

    %s类网页

    :%s" % (txt_class[ci][0],txt_class[ci][1])
        links.append([])    
        pattern = re.compile(r'(.*?)/\d+\.shtml')
        purl=txt_class[ci][1]
        page=urllib2.urlopen(purl)
        soup = BeautifulSoup(page)
        for link in soup.find_all('a'): 
            mylink=link.get('href')
            match = pattern.match(mylink)
            if match and mylink.find("hd")<0: basestr="<http://www.chinanews.com>

    " if mylink.find("chinanews.com")<0: mylink="basestr+mylink" print links[ci].append(mylink) #提取正文内容 ybtxt="[]" u"\n提取正文内容 " for ci in xrange(0,len(txt_class)): ybtxt.append([]) ".", mypage links[ci]: try: my_page="urllib2.urlopen(mypage)" except: continue my_soup="BeautifulSoup(my_page,from_encoding=" gb2312")" my_tt="my_soup.get_text(" |"," strip="True)" my_txt="my_tt" my_fs="u'正文" |' my_fe1="u'【编辑" ' my_fe2="u'标签" zw_start="my_txt.find(my_fs)+8" last_txt="my_txt[zw_start:len(my_txt)]" zw_end="last_txt.find(my_fe1)" zw_end<0: page_content="my_txt[zw_start:zw_start+zw_end]" 大画 ','').replace(u'标签： ','').replace(u'评论 ','').replace(u'正文 start编辑姓名 start','') len(page_content.strip())>0:
               try:
                    print my_soup.title.string.encode('gb2312')
                    page_content=my_soup.title.string+page_content
                except:
                    print "...."
                finally:
                    print "-done."
                    ybtxt[ci].append(page_content)
    #分析正文内容


    print u"\n分析正文内容

    ..."
    #停用词字典


    f_stop = open('stopwords.txt')  
    try:  
        f_stop_text = f_stop.read( )
        f_stop_text=unicode(f_stop_text,'utf-8')
    finally:  
        f_stop.close( ) 
    f_stop_seg_list=f_stop_text.split('\n')
    #分类提取正文词条


    print u"\n提取正文词条

    ..."
    yb_txt=[]
    for ci in xrange(0,len(ybtxt)):
        yb_txt.append([])
        for cj in xrange(0,len(ybtxt[ci])):
            yb_txt[ci].append([])
            my_str = ybtxt[ci][cj]
            my_txt=jieba.cut(my_str)            
            for myword in my_txt:
                if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
                    yb_txt[ci][cj].append(myword) 
            print ".",    
    #词条在每个样本中出现的次数


    basegl=1e-10
    wordybcount={}
    lbcount=np.zeros(len(yb_txt))
    #整理计算词条出现次数


    for i in xrange(0,len(yb_txt)):
        for j in xrange(0,len(yb_txt[i])):       
            for k in xrange(0,len(yb_txt[i][j])):
                my_word=yb_txt[i][j][k].encode('gbk')
                wordybcount.setdefault(my_word,np.repeat(0,len(yb_txt)).tolist())           
                wordybcount[my_word][i]+=1
                lbcount[i]+=1
    #计算词条先验概率


    print u"\n计算词条概率

    "
    ybgl={}
    for my_word in wordybcount.keys():
        ybgl.setdefault(my_word,np.repeat(0.,len(yb_txt)).tolist())
        for ybii in xrange(0,len(yb_txt)):
            ybgl[my_word][ybii]=basegl+wordybcount[my_word][ybii]/float(lbcount[ybii])
            print '.',
    #读取待分类文本


    print u"\n读取待分类文本

    "
    ftestlinks=[]
    ftestlinks.append(r'<http: 2013 www.chinanews.com edu 09-17 5296319.shtml>

    ')          
    ftestlinks.append(r'<http: 2013 finance.chinanews.com auto 09-16 5290491.shtml>

    ') 
    for mypage in ftestlinks:
        my_page=urllib2.urlopen(mypage)
        my_soup = BeautifulSoup(my_page,from_encoding="gb2312")
        my_tt=my_soup.get_text("|", strip=True)
        my_txt=my_tt
        my_fs=u'正文

    |'
        my_fe1=u'【编辑

    '
        my_fe2=u'标签

    '
        zw_start=my_txt.find(my_fs)+8
        last_txt=my_txt[zw_start:len(my_txt)]
        zw_end=last_txt.find(my_fe1)
        if zw_end<0: zw_end="last_txt.find(my_fe2)" page_content="my_txt[zw_start:zw_start+zw_end]" 大画 ','').replace(u'标签： ',''). replace(u'评论 ','').replace(u'正文 start编辑姓名 start','') print u"%s读取成功 ."%mypage #计算待分类文本后验概率 u"计算待分类文本后验概率 " testgl="None" wordgl="None" if len(page_content.strip())>0:
            ftest_seg_list = jieba.cut(page_content)
            for  myword in ftest_seg_list:
                myword=myword.encode('gbk')
                if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>2:
                    for i in xrange(0,len(yb_txt)):                    
                        wordgl=ybgl.get(myword)
                        if wordgl:
                            if wordgl[i]<>0:
                                testgl[i]*=wordgl[i]
                                if np.min(testgl)<1e-100: testgl*="1e30" if np.max(testgl)>1e100:
                                    testgl/=float(1e30)
            #计算最大归属概率


            maxgl=0.
            mychoice=0
            for ti in xrange(0,len(yb_txt)):
                if testgl[ti]>maxgl:
                    maxgl=testgl[ti]
                    mychoice=ti
            print "\n\n%s\n:%s"%(mypage,txt_class[mychoice][0]) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">### 12.4 自然语言处理</span><br><span class="line"></span><br><span class="line">自然语言处理（NLP）是计算机科学领域与人工智能领域中的一个重要方向，是一门融语言学、计算机科学、数学于一体的学科，是计算机科学、人工智能、语言学研究计算机和人类（自然）语言之间的相互作用的工具。达到人类水平的自然语言处理，是一个人工智能的完全问题，NLP研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法，相当于解决中央的人工智能问题，使计算机成为和人一样聪明或强大的人工智能。因此NLP的未来也会密切结合人工智能的发展而发展。</span><br><span class="line"></span><br><span class="line">#### 12.4.1 NLTK简介</span><br><span class="line"></span><br><span class="line">NLTK是一个用来完成NLP的Python处理包。NLTK致力于打造使用Python程序的人类语言工作平台，它提供了易于使用的接口、大量的英文语料库和词汇资源，连同一套文本处理库的分类、标记、堵塞、标注、句法分析、语义推理、工业强度的NLP库包装及活跃的论坛，可用于Windows、Mac OS X、Linux等操作系统。</span><br><span class="line"></span><br><span class="line">更为重要的是：NLTK是一个免费的、开源的、社区驱动的项目。</span><br><span class="line"></span><br><span class="line">此外，NLTK虽然支持unicode编码的文本（中文可采用unicode编码，通常为utf-8），但它是为处理英文文本而生的，因此NLTK对英文的支持比中文更好。鉴于上述原因，在实践中，可结合jieba中文分词组件来完成NLP的相关工作。</span><br><span class="line"></span><br><span class="line">#### 12.4.2 NLTK与jieba的配置</span><br><span class="line"></span><br><span class="line">1.NLTK的安装与配置</span><br><span class="line"></span><br><span class="line">首先打开NLTK的官网&lt;http://www.nltk.org/&gt; ，下载相关平台的安装包并安装好，然后在Python交互解释器下执行下面的语句：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> import nltk
    >>> nltk.download() <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">最后，将出现NLTK包的下载界面，选择下载目录后，按Download键（如图12-4所示）。下载完毕后，在Python的安装目录下新建nltk_data文件夹，将下载的文件拷入其中。以WinPython为例，笔者的WinPython安装目录如下：</span><br><span class="line"></span><br><span class="line">![](Image00531.jpg)</span><br><span class="line"></span><br><span class="line">图12-4 NLTK包下载</span><br><span class="line"></span><br><span class="line">E:\\\WinPython-32bit-2.7.10.3\\\python-2.7.10\\\nltk_data</span><br><span class="line"></span><br><span class="line">将nltk_data拷入其中后，效果如图12-5所示。</span><br><span class="line"></span><br><span class="line">上述步骤全部完成后，可在Python交互解释器下输入如下代码，进行测试：</span><br><span class="line"></span><br><span class="line">![](Image00532.jpg)</span><br><span class="line"></span><br><span class="line">图12-5 nltk_data拷贝</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    >>> import nltk
    >>> sentence = """At eight o'clock on Thursday morning
    ... ... Arthur didn't feel very good."""
    >>> tokens = nltk.word_tokenize(sentence)
    >>> tokens
    ['At', 'eight', "o'clock", 'on', 'Thursday', 'morning', '...', 'Arthur', 'did', "n't", 'feel', 'very', 'good', '.']
    >>>以空格分隔的中文


    >>> mystr="您好

     世界

    "
    >>> tokens = nltk.word_tokenize(mystr)
    >>> tokens
    ['\xc4\xfa\xba\xc3', '\xca\xc0\xbd\xe7']
    >>> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2.jieba中文分词组件的安装与配置</span><br><span class="line"></span><br><span class="line">首先，下载jieba组件并解压缩。接着，打开控制台，输入以下命令来查看目录的结构：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    E:\WinPython-32bit-2.7.10.3\python-2.7.10>cd E:\jieba-0.38
    E:\jieba-0.38>dir
    ...
    2016/01/27  08:27                <dir>                .
    2016/01/27  08:27                <dir>                ..
    2016/01/27  08:27                <dir>                jieba
    2015/12/16  16:28                                     2617 PKG-INFO
    2015/12/16  16:09                                     2571 setup.py
    2016/01/27  08:27                <dir>                test
                    2 个文件

                            5188 字节


                    4 个目录

                            69 317 844 992 可用字节

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">然后，观察上述目录结构，可看到目录下有setup.py文件，执行这个文件进行安装。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    E:\jieba-0.38>python setup.py install
    ...
    ...
    byte-compiling E:\WinPython-32bit-2.7.10.3\python-2.7.10\Lib\site-packages\jieba\__main__.py to __main__.pyc
    running install_egg_info
    Writing E:\WinPython-32bit-2.7.10.3\python-2.7.10\Lib\site-packages\jieba-0.38-py2.7.egg-info <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">#### 12.4.3 中文分词并标注词性</span><br><span class="line"></span><br><span class="line">NLTK和jieba安装配置完毕后，可测试一个中文分词和词性标注的程序（如12-6.py所示）。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #encoding=utf-8
    #--coding:utf-8--
    #code by myhaspl 
    #分词，词性


    #12-6.py
    from __future__ import unicode_literals
    import nltk
    import sys
    sys.path.append("../")
    import jieba
    from jieba import posseg
    def cutstrpos(txt):
        #分词

    +词性


        cutstr = posseg.cut(txt)
        result=""
        for word, flag in cutstr:
            result+=word+"/"+flag+' '
        return result
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('nltest1.txt')
    textstr=""
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    #中文分词并标注词性


    posstr=cutstrpos(filestr)
    strtag=[nltk.tag.str2tuple(word) for word in posstr.split()]
    for word,tag in strtag:
        print word,"/",tag,"|",
    #进入语料库


    cutstr=cutstring(filestr)
    mytext=nltk.text.Text(cutstr)
    #在该语料库中查找包括

    "人

    "的语句


    print(mytext.concordance(u"人

    ")) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察程序12-6.py可发现，它演示了以下两种分词方式。</span><br><span class="line"></span><br><span class="line">（1）纯中文分词</span><br><span class="line"></span><br><span class="line">cutstring函数负责文本的中文分词，通过直接调用jieba模块的cut函数来完成，分割的词使用空格分离的方式进行标注，代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）中文分词并标注词性</span><br><span class="line"></span><br><span class="line">cutstrpos函数负责文本的中文分词，并标注词性，通过直接调用posseg模块的cut函数来完成，该cut函数将返回一个列表，列表中是由形如“（词，词性）”格式的元组组成，因此，分割的词使用空格分离的方式进行标注的同时，还需要使用“/”分割符（也可使用其他非空格的分割字符）将词与词性进行分离。cutstrpos函数代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def cutstrpos(txt):
        #分词

    +词性


        cutstr = posseg.cut(txt)
        result=""
        for word, flag in cutstr:
            result+=word+"/"+flag+' '
        return result <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，Concordance函数可显示指定的词在某语料库中的出现情况，并显示一些上下文。</span><br><span class="line"></span><br><span class="line">程序12-6.py的运行效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    据

     / P | 国外

     / S | 媒体报道

     / N | ，

     / X | 美国

     / NS | 科学家

     / N | 近日

     / T | 获得

     / V | 了

     / UL | 2800 / M | 万美元

     / M | （

     / X | 约合

     / VN | 1.84 / M | 亿

     / M | 人民币

     / N | ）

     / X | 的

     / UJ | 研究

     / VN | 经费

     / VN | ，

    ......，

     / X | 我们

     / R | 迟早会

     / NR | 设计

     / VN | 出

     / V | 一款

     / M | 能够

     / V | 媲美

     / V | 、

     / X | 甚至

     / D | 超越

     / V | 人类

     / N | 的

     / UJ | 计算机系统

     / N | 。

     / X |Displaying 11 of 11 matches:
     0 0   万

     美

     元

       （

       约

     合

       1 . 8 4   亿

       人

     民

     币

       ）

       的

       研

     究

       经

     费

       ，

       用

     于

    .....它

       的

       规

     模

       类

     似

       于

       人

     类

       基

     因

     组

       计

     划

       。

       该

     项

       目

     的

       领

      出

       一

     款

       能

     够

       媲

     美

       、

       甚

     至

       超

     越

       人

     类

       的

       计

     算

     机

     系

     统

       。

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述运行效果，第一段是中文分词与词性标注的结果，第二段是将文本加入NLTK语料库，并在语料库中查找含有“人”的语句的结果。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 NLTK的语料库对英文的支持非常好，但对中文的支持有限，因此，如果使用NLTK语料库对中文进行处理，请慎重使用，反复调试。</span><br><span class="line"></span><br><span class="line">#### 12.4.4 词特征指标分析</span><br><span class="line"></span><br><span class="line">1.词频统计</span><br><span class="line"></span><br><span class="line">程序12-7.py演示了如何调用NLTK模块的函数进行词频统计。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #词频分析


    #12-7.py
    from __future__ import unicode_literals
    from __future__ import division
    import nltk
    import sys
    sys.path.append("../")
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('nltest1.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr)
    #全文总词数


    print u"词总数

    :",
    print len(tokenstr)
    #共出现多少词


    print u"共出现词数

    :",
    print len(set(tokenstr))
    #词汇条目排序表


    print u"词汇条目排序表

    "
    for word in sorted(set(tokenstr)):
        print word,
    print 
    #每个词的平均使用次数


    print u"每个词的平均使用次数

    :",
    print len(tokenstr)/len(set(tokenstr))
    #统计词频


    fdist1=nltk.FreqDist(tokenstr)
    for key,val in sorted(fdist1.iteritems()):
        print key,val,
    print
    print u".........计算机系统出现的次数

    ..............."
    print fdist1[u'计算机系统

    ']
    #统计出现最多的前

    5个词


    print
    print u".........统计出现最多的前

    5个词

    ..............."
    fdist1=nltk.FreqDist(tokenstr)
    for key,val in sorted(fdist1.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:5]:
        print key,val <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察程序12-8.py，该程序依次执行了以下操作：</span><br><span class="line"></span><br><span class="line">（1）读取文件</span><br><span class="line"></span><br><span class="line">通过调用Python的open函数来打开文件，read函数来读取文件，无论读取文件成功与否都关闭文件对象，代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    txtfileobject = open('nltest1.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( ) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）中文分词</span><br><span class="line"></span><br><span class="line">首先，调用cutstring函数，从而使用jiaba的cut函数完成中文分词，其中，每个词都用空格进行分割；然后，针对空格分割的分词结果，调用NLTK模块的word_tokenize函数进行NLTK方式的二次分词，最终生成NLTK模块要求的中文分词格式，即：以中文词为元素，组成词语列表。代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 NLTK模块的分词是针对英文分词而设计的，而英文分词相对比较简单，通常句子中的英语单词是用空格来分隔的，因此，使用NLTK完成中文分词，需要模拟英文分词的方式来进行，即：先使用空格将中文词组分割形成字符串后，再送往NLTK分词函数做进一步处理。</span><br><span class="line"></span><br><span class="line">（3）统计词出现的次数</span><br><span class="line"></span><br><span class="line">首先，通过调用len函数，对NLTK分词形成的词列表中的元素总数（即词的总数量）进行统计；然后，调用set函数将NLTK分词结果转换成集合，统计集合中出现的词数。代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #全文总词数


    print u"词总数

    :",
    print len(tokenstr)
    #共出现多少词


    print u"共出现词数

    :",
    print len(set(tokenstr)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（4）统计词频</span><br><span class="line"></span><br><span class="line">首先，调用NLTK模块的FreqDist函数，生成NLTK词频字典对象，该字典的键为词，值为该词出现的次数；然后，调用该词频对象的iteritems()返回迭代对象，遍历所有的词。代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #统计词频


    fdist1=nltk.FreqDist(tokenstr)
    for key,val in sorted(fdist1.iteritems()):
        print key,val,print u"共出现词数

    :", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（5）按词频大小分析中文词</span><br><span class="line"></span><br><span class="line">首先，生成NLTK词频字典；然后，依据字典的值（即词频）对字典的键（即中文词语）进行从大到小的排序。下面的代码片断演示的是分析出现最多的前5个词：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    fdist1=nltk.FreqDist(tokenstr)
    for key,val in sorted(fdist1.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:5]:
        print key,val <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-7.py的运行效果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    词总数

    : 386共出现词数

    : 216词汇条目排序表


    1.84 2800 CBS Cox David IARPA SEAS · 、

     。

     一个

     一半

     一款

     一点

     一项

     万美元

     上

     不然

     与

     东西

     中

     中心

     为了

     为何

     之后

     之间

     也

     了

     ......每个词的平均使用次数为

     1.78703703704
    1.84 1 2800 1 CBS 1 Cox 1 David 1 IARPA 1 SEAS 2 · 1 、

     7 。

     13 一个

     2 一半

     1 一款

     2 一点

     1 一项

     1 万美元

     1 上

     1 不然

     1 与

     5 东西

     1 中

     1 中心

     1 为了

     1 为何

     1 之后

     1 之间

     2 也

     1 了

     6 于

     1 人员

     1 .......
    .........计算机系统出现的次数

    ...............
    3
    .........统计出现最多的前

    5个词

    ...............的

     25，

     23。

     13人类

     8、

     7 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述12-7.py的运行结果，程序依次输出了词总数、共出现词数、词汇条目排序表、每个词的平均使用次数、“计算机系统”这个词出现的次数、出现最多的前5个词。</span><br><span class="line"></span><br><span class="line">2.词频与长词分析</span><br><span class="line"></span><br><span class="line">程序12-8.py演示了如何调用NLTK模块的函数进行词频统计：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-8.py
    from __future__ import unicode_literals
    from __future__ import division
    import nltk
    import sys
    sys.path.append("../")
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('nltest2.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr)
    fdist1=nltk.FreqDist(tokenstr)
    #只出现了

    1次的低频词


    print "----只出现了

    1次的低频词

    -----"
    for word in fdist1.hapaxes():
        print word,
    #找出文本中的长词


    print
    print "----文本中的长词

    -----"
    for word in [w for w in set(tokenstr) if len(w)>3]:
        print word,
    #找出文本中出现了

    2次以上的长词


    print
    print "----文本中出现了

    2次以上的长词

    -----"
    for word in [w for w in set(tokenstr) if len(w)>3 and fdist1[w]>2]:
            print word, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-8.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">（1）低频词</span><br><span class="line"></span><br><span class="line">NLTK将只出现过1次的词作为低频词，可通过调用hapaxes函数分析低频词。如下面的代码片断所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     #只出现了

    1次的低频词


    print "----只出现了

    1次的低频词

    -----"
    for word in fdist1.hapaxes():
        print word, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）长词</span><br><span class="line"></span><br><span class="line">可将长度超过3的中文词视为长词，如下面的代码片断所示，首先通过len函数找到文本中的长词，然后结合词频字典的值来寻找出现了2次以上的长词。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #找出文本中的长词


    print
    print "----文本中的长词

    -----"
    for word in [w for w in set(tokenstr) if len(w)>3]:
        print word,
    #找出文本中出现了

    2次以上的长词


    print
    print "----文本中出现了

    2次以上的长词

    -----"
    for word in [w for w in set(tokenstr) if len(w)>3 and fdist1[w]>2]:
            print word, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-8.py的输出结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ----只出现了

    1次的低频词

    -----无意识

     加快

     一方面

     特性

     电视观众

     窗

     圣哲

     神经科学

     尽可能

     团队

     置于

     繁重

     经

     干预

     显然

     下丘脑

     关系

     中带

     正确

     ......
    ----文本中的长词

    -----大脑皮层

     电视观众

     神经科学

     另一方面

     与此同时

     ......
    ----文本中出现了

    2次以上的长词

    -----持续时间

     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3.搭配词分析</span><br><span class="line"></span><br><span class="line">程序12-9.py演示了如何调用NLTK模块的函数进行搭配词分析：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-9.py
    from __future__ import unicode_literals
    from __future__ import division
    import nltk
    import sys
    sys.path.append("../")
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('nltest2.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr)
    fdist1=nltk.FreqDist(tokenstr)
    bigramcolloc=nltk.collocations.BigramCollocationFinder.from_words(tokenstr)
    print "----出现最频繁的前

    10个词

    -----"
    fdist1=bigramcolloc.word_fd
    for key,val in sorted(fdist1.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:10]:
        print key,":",val
    print "----只出现了

    1次的低频词

    -----"
    fdist1=bigramcolloc.word_fd
    for w  in fdist1.hapaxes():
        print w.encode("utf-8"),"|",  
    #找出文本中的搭配词


    print
    print "----找出双连搭配词

    -----"
    bigramwords=nltk.bigrams(tokenstr)
    for fw,sw in set(bigramwords):
        print fw," ",sw,"|",
    print       
    print "----双连搭配词及词频

    -----"
    for w,c  in sorted(bigramcolloc.ngram_fd.iteritems(),key=lambda x:(x[1],x[0]),reverse=True):
        fw,sw=w
        print fw," ",sw,"=>",c,"||",
    print
    trigramcolloc=nltk.collocations.TrigramCollocationFinder.from_words(tokenstr)    
    print "----三连搭配词

    -----"
    for fw,sw,tw  in trigramcolloc.ngram_fd:
        print fw.encode("utf-8")," ",sw.encode("utf-8")," ",tw.encode("utf-8"),"|", 
    print <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-9.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">（1）双连搭配词</span><br><span class="line"></span><br><span class="line">将两个经常在一起使用的词语合并为一个词组，并称为双连搭配词，比如：“通过”、“扫描”这两个词经常在一起使用，可合并为“通过扫描”的词组。可通过调用bigrams函数来寻找所有的双连搭配词。代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    bigramwords=nltk.bigrams(tokenstr)
    for fw,sw in set(bigramwords):
        print fw," ",sw,"|",  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（2）三连搭配词</span><br><span class="line"></span><br><span class="line">将三个经常在一起使用的词语合并为一个词组，并称为三连搭配词，比如：“发现”、“任何”、“异样”这三个词经常在一起使用，可合并为“发现任何异样”的词组。可通过调用模块nltk.collocations.TrigramCollocationFinder的from_words函数来寻找所有的三连搭配词，并统计词频。代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    trigramcolloc=nltk.collocations.TrigramCollocationFinder.from_words(tokenstr)  
    for fw,sw,tw  in  trigramcolloc.ngram_fd:
        print fw.encode("utf-8")," ",sw.encode("utf-8")," ",tw.encode("utf-8"),"|", 
    print <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">（3）词频</span><br><span class="line"></span><br><span class="line">可通过调用模块nltk.collocations.BigramCollocationFinder的from_words函数来寻找所有的双连搭配词，并统计词频。</span><br><span class="line"></span><br><span class="line">其中，可通过word_fd方法返回单个词的词频，代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    bigramcolloc=nltk.collocations.BigramCollocationFinder.from_words(tokenstr)
    print "----出现最频繁的前

    10个词

    -----"
    fdist1=bigramcolloc.word_fd
    for key,val in sorted(fdist1.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:10]:
        print key,":",val <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">也可以通过iteritems方法返回双连搭配词的词频，代码片断如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    bigramcolloc=nltk.collocations.BigramCollocationFinder.from_words(tokenstr)
    for w,c  in sorted(bigramcolloc.ngram_fd.iteritems(),key=lambda x:(x[1],x[0]),
    reverse=True):
        fw,sw=w
        print fw," ",sw,"=>",c,"||",
    print <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-9.py的运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ----出现最频繁的前

    10个词

    -----的

     : 131，

     : 99。

     : 64在

     : 30大脑

     : 28
    ...
    ...
    ----只出现了

    1次的低频词

    -----无意识

     | 加快

     | 一方面

     | 特性

     | 电视观众

     | 窗

     | 圣哲

     | 神经科学

     | 尽可能

     | 团队

     | 置于

     | 繁重

     | 经

     | 干预

     | 显然

     ......神经学家

     | 前

     |
    ----找出双连搭配词

    -----
    .......声音

       的

     | 例如

       在

     | 振荡

       活动

     | 的

       区别

     | 就

       像

     | 控制

       着

     | 和

       从来

     | 如果

       两件事

     | 这

       就

     | 随机

       组合

    ......
    ----双连搭配词及词频

    -----
    ......不同

       速度

     => 2 || 不

       超过

     => 2 || 下

       一个

     => 2 || 一项

       试验

     => 2 || 一个

       等级

     => 2......
    ----三连搭配词

    -----
    ...... 大脑

       中

       发生

     | 生活

       在

       太

     | 他们

       观察

       一个

     | 不

       清楚

       这些

     | 建立

       在

       过去

     | 维特曼

       设计

       出

    ...... <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">观察上述运行结果，程序12-9.py依次输出了出现最频繁的前10个词、只出现了1次的低频词、双连搭配词、双连搭配词及词频、三连搭配词。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 12.4节中有些代码并没有对标点符号做任何处理，比如12-9.py没有对标点进行过滤，读者可参考本章前面的部分，将标点符号作为停用词进行删除处理。但有一点必须要注意：标点符号并非完全没有意义，在NLP过程的初期并不一定要过滤标点符号，例如，标点符号可以作为词组、句子甚至口语文本分割的标志等。</span><br><span class="line"></span><br><span class="line">4.词详细指标分析</span><br><span class="line"></span><br><span class="line">程序12-10.py演示了如何调用NLTK模块的函数进行不同指标的词频分析、某词汇指标分析、样本特征分析、频率分析等。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-10.py
    from __future__ import unicode_literals
    from __future__ import division
    import pylab 
    import nltk
    import sys
    sys.path.append("../")
    pylab.mpl.rcParams['font.sans-serif']=['SimHei']
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('test2.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr)
    fdist=nltk.FreqDist(tokenstr)
    #以词长为元素，计算不同词长的频率


    print "----词频

    -----"
    fdist1=nltk.FreqDist([len(w) for w in tokenstr])
    for w,c  in fdist1.items():
        print w,"=>",c,"||",
    #词长


    print
    print "----词长

    -----"
    print fdist1.keys()
    #词


    print 
    print u"---词频

    ---"
    fdist2=nltk.FreqDist(tokenstr)
    for w,c  in fdist2.items():
        print w,"=>",c,"||",
    print
    print  u"---无意识出现的次数

    ---"
    print fdist2[u"无意识

    "]
    print  u"---神经学家出现的次数

    ---"
    print fdist2[u"神经学家

    "]
    #其他基本指标


    sample=cutstring(u"据悉，这辆汽车绰号野兽，野兽很可能于

    2017年

    1月份美国第

    45任总统就职时使用。目前，野兽的详细规格都属于绝密信息，但谍照显示野兽采用了凯迪拉克的最新护栅和前灯设计。

    ")
    tokenstr=nltk.word_tokenize(sample)
    fdist3=nltk.FreqDist(tokenstr)
    print u"---美国出现的次数

    ---"
    print fdist3[u"美国

    "]
    print u"---样本总数

    ---"
    print fdist3.N()
    print u"---数值最大的样本

    ---"
    print fdist3.max()
    #频率分布表


    fdist3.tabulate()
    #频率分布图


    fdist3.plot()
    #前

    10个高频词的累积频率分布图


    fdist3.plot(10,cumulative=True) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-10.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">1）以词长作为指标进行词频分析。通过len函数取出词长，以词长为元素形成列表，将列表作为FreqDist函数的参数，返回以词长为指标的词频字典，代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    fdist1=nltk.FreqDist([len(w) for w in tokenstr])
    for w,c  in fdist1.items():
        print w,"=>",c,"||", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）频率分布。调用tabulate函数输出词频的分布情况，调用plot函数绘制词频分布图和累积频率分布图。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #频率分布表


    fdist3.tabulate()
    #频率分布图


    fdist3.plot()
    #前

    10个高频词的累积频率分布图


    fdist3.plot(10,cumulative=True) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）pylab绘图的中文乱码处理。通过指定pylab字体的方式可避免绘图出现中文乱码。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    pylab.mpl.rcParams['font.sans-serif']=['SimHei'] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-10.py执行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ----词频

    -----
    1 => 750 || 2 => 864 || 3 => 80 || 4 => 28 || 5 => 2 || 6 => 1 ||
    ----词长

    -----
    [1, 2, 3, 4, 5, 6]
    ---词频

    ---要

     => 2 || 大脑皮层

     => 2 || 一切

     => 3 || 无意识

     => 1 || 加快

     => 1 || 一方面

     => 1 || 通过

     => 2 || 特性

     => 1 || ......|| 情绪

     => 1 || 是否

     => 1 || 蜂鸣

     => 1 || 他们

     => 2 || 近距离

     => 1 || 起

     => 1 || 神经学家

     => 1 || 前

     => 1 || 能够

     => 7 ||
    ---无意识出现的次数

    ---
    1
    ---神经学家出现的次数

    ---
    1
    ---美国出现的次数

    ---
    1
    ---样本总数

    ---
    49
    ---数值最大的样本

    ---
    ......  可能

        年

       详细

        时

        任

     凯迪拉克

        都


    ......   1    1    1    1    1    1    1  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，程序12-10.py绘制了如图12-6所示的词频率分布图。</span><br><span class="line"></span><br><span class="line">观察图12-6，上面的曲线为累积频率分布曲线，观察该曲线，“，”、“野兽”这两个词共使用了8次，“，”、“野兽、“。”这3个词共使用了10次。下面的曲线是频率分布曲线，观察该曲线可以看出，“显示”一词出现了1次，“的”一词出现了2次，“野兽”一词出现了4次。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 累积频率（Cumulative Percentage）是指，按某种标志对数据进行分组后，分布在各组内的数据个数称为频数或次数，各组频数与全部频数之和的比值称为频率或比重。为了统计分析的需要，有时需要观察某一数值以下或某一数值以上的频率之和，叫作累积频率，或称为对频率的累计。从变量值小的一方向变量值大的一方累加，称为向上累积，反之为向下累积。频率的最终累积值为100%。设x1 &lt;x2 &lt;…&lt;xm 是不重复的样本值，m&lt;n，把样本值小于等于某个样本数据xi 的频率累加起来，就可得到小于等于xi 的累积频率。</span><br><span class="line"></span><br><span class="line">![](Image00533.jpg)</span><br><span class="line"></span><br><span class="line">图12-6 词频率分布图</span><br><span class="line"></span><br><span class="line">程序12-11.py演示了如何调用NLTK模块的函数对词缀、包含词等情况进行分析：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl
    #12-11.py 
    from __future__ import unicode_literals
    from __future__ import division
    import pylab 
    import nltk
    import sys
    sys.path.append("../")
    pylab.mpl.rcParams['font.sans-serif']=['SimHei']
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    #读取文件


    txtfileobject = open('nltest2.txt','r')
    try:
        filestr = txtfileobject.read( )
    finally:
        txtfileobject.close( )
    cutstr=cutstring(filestr)
    tokenstr=nltk.word_tokenize(cutstr)
    fdist=nltk.FreqDist(tokenstr)
    #以词频递减的顺序访问所有以

    "神

    "开头的词


    print "以词频递减的顺序访问所有以

    "神

    "开头的词

    "
    mywords=[w for w in fdist.keys() if w.startswith(u"神

    ")]
    for word in mywords:
        print word,"||",
    #以词频递减的顺序访问所有以

    "学

    "结尾的词


    print
    print "以词频递减的顺序访问所有以

    "学

    "结尾的词

    "
    mywords=[w for w in fdist.keys() if w.endswith(u"学

    ")]
    for word in mywords:
        print word,"||",
    #以词频递减的顺序访问所有包含

    "美国

    "的搭配词


    print
    print "以词频递减的顺序访问所有包含

    "美国

    "的搭配词

    "
    bigramwords=nltk.bigrams(tokenstr)
    mywords=[w for w in set(bigramwords) if u"美国

    " in w]
    for fw,sw in mywords:
        print fw," ",sw,"|", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-11.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">1）词缀。通过endswith函数对词后缀进行分析。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    print "以词频递减的顺序访问所有以

    "学

    "结尾的词

    "
    mywords=[w for w in fdist.keys() if w.endswith(u"学

    ")]
    for word in mywords:
        print word,"||", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">通过startswith函数对词的前缀进行分析。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    print "以词频递减的顺序访问所有以

    "神

    "开头的词

    "
    mywords=[w for w in fdist.keys() if w.startswith(u"神

    ")]
    for word in mywords:
        print word,"||", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）包含词。通过in对包含词进行分析。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    bigramwords=nltk.bigrams(tokenstr)
    mywords=[w for w in set(bigramwords) if u"美国

    " in w]
    for fw,sw in mywords:
        print fw," ",sw,"|", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-11.py的运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    以词频递减的顺序访问所有以

    "神

    "开头的词

    神经科学

     || 神经节

     || 神经学家

     ||以词频递减的顺序访问所有以

    "学

    "结尾的词

    神经科学

     || 大学

     || 光学

     || 社会心理学

     || 心理学

     || 美国杜克大学

     ||以词频递减的顺序访问所有包含

    "美国

    "的搭配词

    美国

       得克萨斯州

     | 根据

       美国

     | <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-12.py演示了如何调用NLTK模块的函数进行条件频率分析：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-12.py
    from __future__ import unicode_literals
    from __future__ import division
    import pylab 
    import nltk
    import sys
    sys.path.append("../")
    pylab.mpl.rcParams['font.sans-serif']=['SimHei']
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    samples=[('nltest1.txt',u'科技

    '),('nltest2.txt',u'科技

    '),('nltest3.txt',u'财经

    '),('nltest4.txt',u'财经

    ')]
    samplewords=[]
    for (filename,categories) in samples:
        #读取文件


        txtfileobject = open(filename,'r')    
        try:
            filestr = txtfileobject.read( )
        finally:
            txtfileobject.close( )
        cutstr=cutstring(filestr)
        tokenstr=nltk.word_tokenize(cutstr)
        mywords=[w for w in tokenstr]
        for word in mywords:
            samplewords.append((categories,word))
    #条件频率，每个词汇在不同分类中出现的频率


    print "------------------"
    cfd=nltk.ConditionalFreqDist(samplewords)   
    fdist=cfd[u'财经

    ']
    for word in fdist:
        print word
    print "---------流动性出现次数

    -----------"
    print cfd[u'财经

    '][u'流动性

    ']
    print "----------条件

    :分类

    ----------"
    for cnd in cfd.conditions():
        print cnd
    print "---------------------------"
    #频数最大的样本


    print cfd[u'财经

    '].max()
    #条件频率分布


    print "----------条件频率分布表

    ----------"
    cfd.tabulate(title=u'条件频率分布表

    ',conditions=[u'科技

    ',u'财经

    '])
    cfd.plot(title=u'条件频率分布图

    ',conditions=[u'科技

    ',u'财经

    ']) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-12.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">1）条件频率字典构造。可使用NLTK模块的ConditionalFreqDist函数构造条件频率字典，条件频率字典与FreqDist函数构造的频率字典不同（如12-11.py所示），它在频率的基础上增加了文本类别，这样就可以实现分类的频率分析了。</span><br><span class="line"></span><br><span class="line">此外，ConditionalFreqDist函数的参数是一个列表，列表中的每个元素均为带类别标志的元组，格式为：（类别，词汇）。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    for word in mywords:
        samplewords.append((categories,word)) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）条件频率字典访问。生成的条件频率字典属于二维结构，第一维是类别，第二维是词汇，下面的代码演示了分析访问财经类文本中的“流动性”一词的频率。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    print "---------流动性出现的次数

    -----------"
    print cfd[u'财经

    '][u'流动性

    '] <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）条件频率分布。使用tabulate函数绘制条件频率分布表，使用plot函数绘制条件频率分布图。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    cfd.tabulate(title=u'条件频率分布表

    ',conditions=[u'科技

    ',u'财经

    '])
    cfd. plot (title=u'条件频率分布图

    ',conditions=[u'科技

    ',u'财经

    ']) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-12.py首先输出财经类的所有词汇及财经类中“流动性”的数量；然后输出该字典内包含的类别（条件），最后输出频数最大的样本及频率分布的情况。运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    ...
    ...体量

    起

    超额完成

    过硬

    三大


    ---------流动性出现的次数

    -----------
    8
    ----------条件

    :分类

    ----------科技

    财经


    ---------------------------，


    ----------条件频率分布表

    ----------高级

     高达

     高速

     鸡尾酒

     鸣声

     黑暗

     鼓励（

      ）

     ，

     ：

      ；

     ？

     科技

        .......  1    1    0    1    1    1    0    6    6  122    2    2    2 财经

        ......  0    1    2    0    0    0    2    3    3  169    4    1    0 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">图12-7为程序12-12.py输出的条件频率分布图，横轴为词汇，纵轴为词汇数量。</span><br><span class="line"></span><br><span class="line">![](Image00534.jpg)</span><br><span class="line"></span><br><span class="line">图12-7 条件频率分布图</span><br><span class="line"></span><br><span class="line">#### 12.4.5 Web文档分析</span><br><span class="line"></span><br><span class="line">Web文档即网页，它是构成网站的基本元素，是承载各种网站应用的平台，Web文档是一个包含HTML标签的纯文本文件，它可以存放在世界某个角落的某一台计算机中，是万维网中的一“页”，其格式为超文本标记语言（标准通用标记语言的一个应用），通常Web文档的文件扩展名为.html或.htm）。</span><br><span class="line"></span><br><span class="line">![](Image00050.jpg) 提示 HTML是用来描述网页的一种语言，是超文本标记语言（Hyper Text Markup Language），但它不是一种编程语言，而是一种标记语言（markup language），标记语言是一套标记标签（markup tag）。</span><br><span class="line"></span><br><span class="line">HTML使用标记标签来描述网页，HTML标记标签通常被称为HTML标签（HTML tag）。HTML标签是由尖括号包围的关键词组成的，比如“&lt;html&gt;”。HTML标签通常是成对出现的，比如“&lt;b&gt;”和“&lt;/b&gt;”，标签对中的第一个标签是开始标签，第二个标签是结束标签，开始和结束标签也称为开放标签和闭合标签。比如下面这段网页：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    <html>
    <body>
    <h1>My First Heading</h1>
    <p>My first paragraph.</p>
    <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false,"scale":0.5},"react":{"opacity":0.7},"log":false,"tagMode":false});</script></body>
    </html>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">上述网页的HTML标签意义为：&lt;html&gt;与&lt;/html&gt;之间的文本是描述网页；&lt;body&gt;与&lt;/body&gt;之间的文本是可见的页面内容；&lt;h1&gt;与&lt;/h1&gt;之间的文本在网页上被显示为标题；&lt;p&gt;与&lt;/p&gt;之间的文本在网页上被显示为段落。</span><br><span class="line"></span><br><span class="line">程序12-13.py演示了如何调用NLTK模块的函数对Web文档进行条件频率分析：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-13.py
    from __future__ import unicode_literals
    from __future__ import division
    import pylab 
    import nltk
    import urllib
    from bs4 import BeautifulSoup
    import sys
    sys.path.append("../")
    pylab.mpl.rcParams['font.sans-serif']=['SimHei']
    import jieba
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    urls=[(u"科技

    ","http://tech.163.com/16/0203/06/BESLRF5O000915BD.html"),(u"科技

    ","http://tech.163.com/16/0202/01/BEPHEI1200094O5H.html"),(u"科技

    ","http://tech.163.com/16/0203/03/BESBB73B000915BD.html"),(u"科技

    ","http://tech.163.com/16/0203/03/BESAGOPB000915BD.html"),(u"教育

    ","http://edu.163.com/16/0203/05/BESI2S7500294NE9.html"),(u"教育

    ","http://kids.163.com/16/0118/06/BDJEMJ3H00294MO6.html"),(u"教育

    ","http://edu.163.com/16/0128/05/BED4NHBB00294NE9.html"),(u"教育

    ","http://edu.163.com/16/0202/01/BEPHFQ1800294IIH.html")]
    samplewords=[]
    print "|=",
    for (category,myurl) in urls: 
        htmlsrc=urllib.urlopen(myurl).read()
        htmlsrc=htmlsrc.decode('gbk')
        soup = BeautifulSoup(htmlsrc, 'html.parser')
        txtsrc=soup.find_all(id="endText" )
        txtsoup=BeautifulSoup(repr(txtsrc[0]))
        txtstr=txtsoup.get_text()
        txtstr=txtstr.decode('gbk').decode("unicode-escape").encode('utf-8')
        cutstr=cutstring(txtstr)
        tokenstr=nltk.word_tokenize(cutstr)
        for word in tokenstr:
            samplewords.append((category,word))
        print "=",
    print "=>|"
    cfdist=nltk.ConditionalFreqDist(samplewords)   
    #知识一词的频率


    print cfdist[u'科技

    '].freq(u'知识

    ')
    samplews=[]
    #在教育分类中出现最多的

    20个词


    fd=cfdist[u'教育

    ']
    edufd20=sorted(fd.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:20]
    for w,c in edufd20:
        print w,"=>",c,"||",
        samplews.append(w)    
    print
    #在科技分类中出现最多的

    20个词


    fd=cfdist[u'科技

    ']
    techfd20=sorted(fd.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:20]
    for w,c in techfd20:
        print w,"=>",c,"||",
        samplews.append(w)    
    print 
    samplews=set(samplews)
    #条件频率分布图


    cfdist.tabulate(title=u'条件频率分布表

    ',samples=samplews,conditions=[u'科技

    ',u'教育

    '])
    cfdist.plot(title=u'条件频率分布图

    ',samples=samplews,conditions=[u'科技

    ',u'教育

    ']) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-13.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">（1）解析网页</span><br><span class="line"></span><br><span class="line">Web文档通常是HTML格式的网页，处理此类文档的关键在于提取标签中的内容，下面的代码片段演示了如何解析网页文本。首先，通过urllib模块的urlopen打开Web链接，并通过read函数读取链接指向的HTML内容。然后，通过BeautifulSoup模块对HTML文本做进一步处理，本例中需要提取新闻的正文，观察新闻的网页文本可发现，其正文通常处于id为endText的标签内。具体过程为：通过调用BeautifulSoup模块的find_all函数找到标签，提取标签中的内容，通过BeautifulSoup模块的get_text函数去掉提取内容中残余的HTML标记，得到纯净的新闻正文字符串。最后，将新闻正文字符串进行jieba分词和NLTK分词，以便进行下一步处理。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    htmlsrc=urllib.urlopen(myurl).read()
    htmlsrc=htmlsrc.decode('gbk')
    soup = BeautifulSoup(htmlsrc, 'html.parser')
    txtsrc=soup.find_all(id="endText" )
    txtsoup=BeautifulSoup(repr(txtsrc[0]))
    txtstr=txtsoup.get_text()
    txtstr=txtstr.decode('gbk').decode("unicode-escape").encode('utf-8')
    cutstr=cutstring(txtstr)
    tokenstr=nltk.word_tokenize(cutstr) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">在解析网页时需要特别注意字符编码的问题，中文网页文本的字符编码格式不止UTF-8一种，很多中文网页是GB2312格式的编码，通过HTML的charset属性可指定HTML文档的字符编码。对于不同字符编码的文本需要调用decode()和encode()来进行解码和编码。</span><br><span class="line"></span><br><span class="line">（2）某条件下出现最多的高频词汇</span><br><span class="line"></span><br><span class="line">可通过分析某条件下出现频率最多的词汇，近似得到该条件的常用关键词。下面的代码片段对条件频率字典cfdist中的教育条件（对于本例而言，此处的条件部分实质上是类别，“某条件下”意味着“某类别下”）进行排序，排序的依据是值（即词汇频数），排序的函数是Python的sorted函数，返回词频从大到小的词汇列表，列表的前20个元素就是出现得最多的高频词汇。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #在教育类

    web文档中出现最多的

    20个词


    fd=cfdist[u'教育

    ']
    edufd20=sorted(fd.iteritems(),key=lambda x:(x[1],x[0]),reverse=True)[:20]
    for w,c in edufd20:
        print w,"=>",c,"||",
        samplews.append(w) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-13.py的运行结果如下：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    0.00117233294256
    , => 541 || 的

     => 356 || 。

     => 238 || 在

     => 102 || 、

     => 86 || 了

     => 85 || 是

     => 77 || 学生

     => 75 || " => 67 || " => 67 || 学校

     => 53 || 毕业生

     => 51 || 就业

     => 49 || % => 48 || 她

     => 45 || 也

     => 44 || 都

     => 43 || 美国

     => 40 || 和

     => 40 || 有

     => 34 ||
    , => 126 || 的

     => 121 || 。

     => 59 || 是

     => 38 || 在

     => 19 || 了

     => 18 || iPhone => 17 || 量子

     => 15 || 人类

     => 15 || " => 14 || " => 14 || 份额

     => 13 || ：

     => 12 || 世界

     => 12 || 上

     => 12 || 一个

     => 12 || Windows => 12 || 机器人

     => 11 || 、

     => 11 || % => 11 ||
          、

        。

        的

        了

        有

        上

       世界

        和

       学校

        ：

        "    "    %   份额

        在

        是

       学生

      毕业生

     Windows   就业

     iPhone    ，

       美国

       人类

        也

      机器人

       一个

        她

        都

       量子

     科技

       11   59  121   18    5   12   12    9    0   12   14   14   11   13   19   38    0    0   12    0   17  126    0   15    4   11   12    0    8   15 教育

       86  238  356   85   34   21    1   40   53   33   67   67   48    0  102   77   75   51    0   49    0  541   40    0   44    0   17   45   43    0 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-13.py首先输出“知识”一词在科技分类中的频率（此处的频率不是频数，可理解为“知识”在科技类别的文档中出现的概率）为0.00117233294256；然后输出在科技、教育类别中出现最多的20个高频词。最后，输出高频词的条件频率分布表，并绘制条件频率分布图（如图12-8所示），观察图12-8，较高的曲线为教育，较低的曲线为科技，可见这20个高频词属于教育的频数比属于科技的要多。</span><br><span class="line"></span><br><span class="line">![](Image00535.jpg)</span><br><span class="line"></span><br><span class="line">图12-8 条件频率分布图</span><br><span class="line"></span><br><span class="line">#### 12.4.6 Web文档的朴素贝叶斯分类</span><br><span class="line"></span><br><span class="line">朴素贝叶斯分类器（Naive Bayes Classifier，NBC）发源于古典数学理论，有着坚实的数学基础和稳定的分类效率；同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。</span><br><span class="line"></span><br><span class="line">NBC模型假设属性之间相互独立，通过建立一个属性模型，将相互不独立的属性单独处理。例如对中文文本进行分类的时候，可以建立一个字典来处理一些词组，把一个词组看作一个单独的模式（如果发现特定的问题中存在特殊的模式属性，那么就单独进行处理），这是自然语言与其他分类识别问题的不同点。</span><br><span class="line"></span><br><span class="line">1.词汇特征项分析</span><br><span class="line"></span><br><span class="line">假设某样本中的若干文本共分为两类，“中国”这一词汇在两类样本中存在的频率不一样，存在的可能性也不相同。程序12-14.py演示了使用NLTK分析词条归属类别的可能性：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    #--coding:utf-8--
    #code by myhaspl 
    #12-14.py
    from __future__ import unicode_literals
    from __future__ import division
    import pylab 
    import nltk
    import urllib
    from bs4 import BeautifulSoup
    import sys
    sys.path.append("../")
    pylab.mpl.rcParams['font.sans-serif']=['SimHei']
    import jieba
    #停用词字典


    f_stop = open('stopwords.txt')  
    try:  
        f_stop_text = f_stop.read( )
        f_stop_text=unicode(f_stop_text,'utf-8')
    finally:  
        f_stop.close( ) 
    f_stop_seg_list=f_stop_text.split('\n')
    def cutstring(txt):
        #分词


        cutstr = jieba.cut(txt)
        result=" ".join(cutstr)
        return result
    def wordfeatures(word):
        return {"cnword":word}
    urls=[(u"科技

    ","http://tech.163.com/16/0203/06/BESLRF5O000915BD.html"),(u"科技

    ","http://tech.163.com/16/0202/01/BEPHEI1200094O5H.html"),(u"科技

    ","http://tech.163.com/16/0203/03/BESBB73B000915BD.html"),(u"科技

    ","http://tech.163.com/16/0203/03/BESAGOPB000915BD.html"),(u"教育

    ","http://edu.163.com/16/0203/05/BESI2S7500294NE9.html"),(u"教育

    ","http://kids.163.com/16/0118/06/BDJEMJ3H00294MO6.html"),(u"教育

    ","http://edu.163.com/16/0128/05/BED4NHBB00294NE9.html"),(u"教育

    ","http://edu.163.com/16/0202/01/BEPHFQ1800294IIH.html")]
    samplewords=[]
    print "|=",
    for (category,myurl) in urls: 
        htmlsrc=urllib.urlopen(myurl).read()
        htmlsrc=htmlsrc.decode('gbk')
        soup = BeautifulSoup(htmlsrc, 'html.parser')
        txtsrc=soup.find_all(id="endText" )
        txtsoup=BeautifulSoup(repr(txtsrc[0]))
        txtstr=txtsoup.get_text()
        txtstr=txtstr.decode('gbk').decode("unicode-escape").encode('utf-8')
        cutstr=cutstring(txtstr)
        tokenstr=nltk.word_tokenize(cutstr)
        for myword in tokenstr:
            if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
                samplewords.append((wordfeatures(myword),category))
                print "=",
    #测试数据


    testurl="http://edu.163.com/16/0204/05/BEV40UHF00294NE9.html"
    testwords=[]        
    htmlsrc=urllib.urlopen(testurl).read()
    htmlsrc=htmlsrc.decode('gbk')
    soup = BeautifulSoup(htmlsrc, 'html.parser')
    txtsrc=soup.find_all(id="endText" )
    txtsoup=BeautifulSoup(repr(txtsrc[0]))
    txtstr=txtsoup.get_text()
    txtstr=txtstr.decode('gbk').decode("unicode-escape").encode('utf-8')
    cutstr=cutstring(txtstr)
    tokenstr=nltk.word_tokenize(cutstr)
    for myword in tokenstr:
        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
            testwords.append((wordfeatures(myword),"教育

    "))
            print "=",
    print "=>|"
    classifier=nltk.NaiveBayesClassifier.train(samplewords)
    #大学所属的类别


    print u"----大学所属的类别

    -----"
    print classifier.classify({"cnword":u"大学

    "})
    #大脑所属的类别


    print u"----大脑所属的类别

    -----"
    print classifier.classify({"cnword":u"大脑

    "})
    #测试数据分类的准确率


    print nltk.classify.accuracy(classifier,testwords)
    #特征分类最有效的

    10个词


    for wf,mostword in classifier.most_informative_features(10):
        print mostword,
    print
    #为显示

    utf-8，将

    show_most_informative_features代码进行修改


    #classifier.show_most_informative_features(10) 也可直接调用这句，但是

    utf-8显示有问题


    cpdist = classifier._feature_probdist
    print('Most Informative Features')
    for (fname, fval) in classifier.most_informative_features(10):
        def labelprob(l):
            return cpdist[l, fname].prob(fval)
        labels = sorted([l for l in classifier._labels
                                if fval in cpdist[l, fname].samples()],
                            key=labelprob)
        if len(labels) == 1:
            continue
        l0 = labels[0]
        l1 = labels[-1]
        if cpdist[l0, fname].prob(fval) == 0:
            ratio = 'INF'
        else:
            ratio = '%8.1f' % (cpdist[l1, fname].prob(fval) /
                                    cpdist[l0, fname].prob(fval))
        print fname+"="+fval, 
        print(('%6s : %-6s = %s : 1.0' % (("%s" % l1)[:6], ("%s" % l0)[:6], ratio))) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">程序12-14.py中有以下几个关键知识点。</span><br><span class="line"></span><br><span class="line">1）去除Web文档中的停用词。在处理自然语言数据（或文本）之前或之后有时需要自动过滤掉某些字或词，这些字或词称为Stop Words（停用词），停用词主要包括英文字符、数字、数学字符、标点符号及使用频率特高的单汉字等。</span><br><span class="line"></span><br><span class="line">下面的代码片段通过word_tokenize完成NLTK分词后，遍历分词结果，如果含有停用词或是单汉字的，则作为停用词，不将其加入最终分词特征列表（该列表是进一步分析文本特征的依据）中。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    tokenstr=nltk. word_tokenize (cutstr)
    for myword in tokenstr:
        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())>1:
            samplewords.append((wordfeatures(myword),category))
            print "=", <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">2）构造朴素贝叶斯分类器。通过nltk.NaiveBayesClassifier的train方法，将文本特征作为参数，构造朴素贝叶斯分类器。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    classifier=nltk.NaiveBayesClassifier.train(samplewords) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">3）某词汇属于某类别的可能性。下面的代码演示了如何计算“大脑”一词最可能归属的文本类别：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    print u"----大脑所属的类别

    -----"
    print classifier.classify({"cnword":u"大脑

    "}) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">4）对分类最有贡献的词汇。most_informative_features函数将返回对分类最有效的词汇，参数是词汇数量。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    for wf,mostword in classifier.most_informative_features(10):
        print mostword, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">此外，还可调用show_most_informative_features函数输出对分类有明显作用的词汇具体信息。</span><br><span class="line"></span><br><span class="line">5）测试分类的准确率。</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

     #测试数据分类的准确率


    print nltk.classify.accuracy(classifier,testwords) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;/details&gt;</span><br><span class="line"></span><br><span class="line">6）词汇特征分析。NLTK的朴素贝叶斯分类器对特征项的要求是：每个特征项（在本例中为每个词汇）为一个字典，字典元素的键是特征名称，字典元素的值是特征值，某特征项（在本例中为某词汇）的所有特征组成了该特征项（在本例中为该词汇）的特征4字典。代码如下所示：</span><br><span class="line"></span><br><span class="line">&lt;details&gt;</span><br><span class="line">  &lt;summary&gt;代码详情&lt;/summary&gt;</span><br></pre></td></tr></table></figure>

    def wordfeatures(word):
        return {"cnword":word}

* * *

程序12-14.py的运行结果如下：

<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">|= = = = = = = ......= = =&gt;|</span><br><span class="line">----大学所属的类别</span><br><span class="line"></span><br><span class="line">-----教育</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----大脑所属的类别</span><br><span class="line"></span><br><span class="line">-----科技</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0.977346278317世界</span><br><span class="line"></span><br><span class="line"> 公司</span><br><span class="line"></span><br><span class="line"> 事先</span><br><span class="line"></span><br><span class="line"> 游戏</span><br><span class="line"></span><br><span class="line"> 之后</span><br><span class="line"></span><br><span class="line"> 领域</span><br><span class="line"></span><br><span class="line"> 采用</span><br><span class="line"></span><br><span class="line"> 学科</span><br><span class="line"></span><br><span class="line"> 里面</span><br><span class="line"></span><br><span class="line"> 技术</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Most Informative Features</span><br><span class="line">cnword=世界</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =     20.6 : 1.0</span><br><span class="line">cnword=公司</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =     12.4 : 1.0</span><br><span class="line">cnword=事先</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      5.8 : 1.0</span><br><span class="line">cnword=游戏</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      5.8 : 1.0</span><br><span class="line">cnword=之后</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.5 : 1.0</span><br><span class="line">cnword=领域</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.5 : 1.0</span><br><span class="line">cnword=采用</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.5 : 1.0</span><br><span class="line">cnword=学科</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.1 : 1.0</span><br><span class="line">cnword=里面</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.1 : 1.0</span><br><span class="line">cnword=技术</span><br><span class="line"></span><br><span class="line">     科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.1 : 1.0</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述的运行结果，程序12-14.py首先分析“大学”最有可能属于教育类别，而“大脑”最有可能属于科技类别；然后输出数据分类的准确率为0.977346278317，并输出分类最有效的10个词汇；最后反映词汇在不同类别中出现的比例，比如，观察输出结果的最后一行，“技术”一词在科技中出现的频率是在教育中出现频率的4.1倍。</p>
<p>程序12-15.py演示了如何使用NLTK对不同词及词长归属类别可能性的分析：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-15.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import urllib</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import random</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">import jieba</span><br><span class="line">#停用词字典</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f_stop = open(&apos;stopwords.txt&apos;)  </span><br><span class="line">try:  </span><br><span class="line">    f_stop_text = f_stop.read( )</span><br><span class="line">    f_stop_text=unicode(f_stop_text,&apos;utf-8&apos;)</span><br><span class="line">finally:  </span><br><span class="line">    f_stop.close( ) </span><br><span class="line">f_stop_seg_list=f_stop_text.split(&apos;\n&apos;)</span><br><span class="line">def cutstring(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = jieba.cut(txt)</span><br><span class="line">    result=&quot; &quot;.join(cutstr)</span><br><span class="line">    return result</span><br><span class="line">def wordfeatures(word):</span><br><span class="line">    return &#123;&quot;cnword&quot;:word,&quot;wcnlen&quot;:len(word) &#125;</span><br><span class="line">urls=[(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/06/BESLRF5O000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0202/01/BEPHEI1200094O5H.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESBB73B000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESAGOPB000915BD.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0203/05/BESI2S7500294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://kids.163.com/16/0118/06/BDJEMJ3H00294MO6.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0128/05/BED4NHBB00294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0202/01/BEPHFQ1800294IIH.html&quot;)]</span><br><span class="line">samplewords=[]</span><br><span class="line">print &quot;|=&quot;,</span><br><span class="line">for (category,myurl) in urls: </span><br><span class="line">    htmlsrc=urllib.urlopen(myurl).read()</span><br><span class="line">    htmlsrc=htmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">    soup = BeautifulSoup(htmlsrc, &apos;html.parser&apos;)</span><br><span class="line">    txtsrc=soup.find_all(id=&quot;endText&quot; )</span><br><span class="line">    txtsoup=BeautifulSoup(repr(txtsrc[0]))</span><br><span class="line">    txtstr=txtsoup.get_text()</span><br><span class="line">    txtstr=txtstr.decode(&apos;gbk&apos;).decode(&quot;unicode-escape&quot;).encode(&apos;utf-8&apos;)</span><br><span class="line">    cutstr=cutstring(txtstr)</span><br><span class="line">    tokenstr=nltk.word_tokenize(cutstr)</span><br><span class="line">    for myword in tokenstr:</span><br><span class="line">        if not(myword.strip() in f_stop_seg_list) and len(myword.strip())&gt;1:</span><br><span class="line">            samplewords.append((myword,category))</span><br><span class="line">            print &quot;=&quot;,</span><br><span class="line">#通过</span><br><span class="line"></span><br><span class="line">apply_features方法返回链表，不在内存中存储所有的特征集，以节约内存</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">samplelen=len(samplewords)</span><br><span class="line">trlen=int(samplelen*2/3) #训练样本的长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">random.shuffle(samplewords)</span><br><span class="line">traintxt=nltk.classify.apply_features(wordfeatures,samplewords[:trlen])</span><br><span class="line">testtxt=nltk.classify.apply_features(wordfeatures,samplewords[trlen:])</span><br><span class="line">print &quot;=&gt;|&quot;</span><br><span class="line">classifier=nltk.NaiveBayesClassifier.train(traintxt)</span><br><span class="line">#大学所属的类别</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;----大学所属的类别</span><br><span class="line"></span><br><span class="line">-----&quot;</span><br><span class="line">print classifier.classify(&#123;&quot;cnword&quot;:u&quot;大学</span><br><span class="line"></span><br><span class="line">&quot;,&quot;wcnlen&quot;:len(u&quot;大学</span><br><span class="line"></span><br><span class="line">&quot;)&#125;)</span><br><span class="line">#大脑所属的类别</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;----大脑所属的类别</span><br><span class="line"></span><br><span class="line">-----&quot;</span><br><span class="line">print classifier.classify(&#123;&quot;cnword&quot;:u&quot;大脑</span><br><span class="line"></span><br><span class="line">&quot;,&quot;wcnlen&quot;:len(u&quot;大脑</span><br><span class="line"></span><br><span class="line">&quot;)&#125;)</span><br><span class="line">#测试数据分类的准确率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print nltk.classify.accuracy(classifier,testtxt)</span><br><span class="line">#特征分类最有效的</span><br><span class="line"></span><br><span class="line">10个特征</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for wf,mostword in classifier.most_informative_features(10):</span><br><span class="line">    print mostword,</span><br><span class="line">print</span><br><span class="line">#为显示</span><br><span class="line"></span><br><span class="line">utf-8，将</span><br><span class="line"></span><br><span class="line">show_most_informative_features代码进行修改</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#classifier.show_most_informative_features(10)        #也可直接调用这句，但是</span><br><span class="line"></span><br><span class="line">utf-8显示有问题</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cpdist = classifier._feature_probdist</span><br><span class="line">print(&apos;Most Informative Features&apos;)</span><br><span class="line">for (fname, fval) in classifier.most_informative_features(10):</span><br><span class="line">    def labelprob(l):</span><br><span class="line">        return cpdist[l, fname].prob(fval)</span><br><span class="line">    labels = sorted([l for l in classifier._labels</span><br><span class="line">                            if fval in cpdist[l, fname].samples()],</span><br><span class="line">                        key=labelprob)</span><br><span class="line">    if len(labels) == 1:</span><br><span class="line">        continue</span><br><span class="line">    l0 = labels[0]</span><br><span class="line">    l1 = labels[-1]</span><br><span class="line">    if cpdist[l0, fname].prob(fval) == 0:</span><br><span class="line">        ratio = &apos;INF&apos;</span><br><span class="line">    else:</span><br><span class="line">        ratio = &apos;%8.1f&apos; % (cpdist[l1, fname].prob(fval)/</span><br><span class="line">                                cpdist[l0, fname].prob(fval))</span><br><span class="line">    print fname,</span><br><span class="line">    print &quot;=&quot;,</span><br><span class="line">    print fval, </span><br><span class="line">    print((&apos;%6s : %-6s = %s : 1.0&apos; % ((&quot;%s&quot; % l1)[:6], (&quot;%s&quot; % l0)[:6], ratio)))</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-15.py中有以下几个关键知识点。</p>
<p>1）词汇特征分析。以某词汇的内容和长度作为该词汇的特征项，代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def wordfeatures(word):</span><br><span class="line">    return &#123;&quot;cnword&quot;:word,&quot;wcnlen&quot;:len(word) &#125;</span><br></pre></td></tr></table></figure>

</details>

<p>2）不在内存中存储文本的所有特征项集，以节约内存。通过apply_features方法，创建文本特征项集的列表，可不在内存中存储所有特征项集，当特征项数量特别大时，这种方法能节约内存。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">traintxt=nltk.classify.apply_features(wordfeatures,samplewords[:trlen])</span><br><span class="line">testtxt=nltk.classify.apply_features(wordfeatures,samplewords[trlen:])</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-15.py的运行结果如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">|= = = = = = =...... = = = = = = =&gt;|</span><br><span class="line">----大学所属的类别</span><br><span class="line"></span><br><span class="line">-----教育</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----大脑所属的类别</span><br><span class="line"></span><br><span class="line">-----科技</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">0.863354037267</span><br><span class="line">8 世界</span><br><span class="line"></span><br><span class="line"> 公司</span><br><span class="line"></span><br><span class="line"> 7 信息</span><br><span class="line"></span><br><span class="line"> 领域</span><br><span class="line"></span><br><span class="line"> 6 学科</span><br><span class="line"></span><br><span class="line"> 里面</span><br><span class="line"></span><br><span class="line"> 事先</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Most Informative Features</span><br><span class="line">wcnlen = 8           科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =     15.1 : 1.0</span><br><span class="line">cnword = 世界</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =     11.8 : 1.0</span><br><span class="line">cnword = 公司</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =     10.2 : 1.0</span><br><span class="line">wcnlen = 7           科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      5.6 : 1.0</span><br><span class="line">cnword = 信息</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      5.5 : 1.0</span><br><span class="line">cnword = 领域</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      5.5 : 1.0</span><br><span class="line">wcnlen = 6           科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      4.8 : 1.0</span><br><span class="line">cnword = 学科</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      3.9 : 1.0</span><br><span class="line">cnword = 里面</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      3.9 : 1.0</span><br><span class="line">cnword = 事先</span><br><span class="line"></span><br><span class="line">        科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      3.9 : 1.0</span><br></pre></td></tr></table></figure>

</details>

<p>观察上述运行结果，程序12-15.py首先分析“大学”最有可能属于教育类别，而“大脑”最有可能属于科技类别；然后输出数据分类准确率为0.863354037267，并输出分类最有效的10个特征，用前3个特征8、“世界”、“公司”为例进行剖析可以看出，长度为8、“世界”、“公司”是对分类最有效的前3个特征；最后反映特征在不同类别中出现的比例，比如，观察输出结果的最后一行，“事先”在科技类别中出现的频率是教育类中出现频率的3.9倍。</p>
<p>程序12-16.py演示了如何使用NLTK的不同词归属类别可能性的分析，与12-14.py的不同之处在于：特征字典的值为该词汇是否出现。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-16.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import urllib</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import random</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">import jieba</span><br><span class="line">def cutstring(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = jieba.cut(txt)</span><br><span class="line">    result=&quot; &quot;.join(cutstr)</span><br><span class="line">    return result</span><br><span class="line">def txtfeatures(allwords,tokenw,stopseg):</span><br><span class="line">    features=&#123;&#125;</span><br><span class="line">    for myword in set(allwords):</span><br><span class="line">        if not(myword.strip() in stopseg) and len(myword.strip())&gt;1:</span><br><span class="line">            features[&quot;cnword-&quot;+myword]=(myword in set(tokenw))</span><br><span class="line">            print &quot;=&quot;,    </span><br><span class="line">    return features</span><br><span class="line">#停用词字典</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f_stop = open(&apos;stopwords.txt&apos;)  </span><br><span class="line">try:  </span><br><span class="line">    f_stop_text = f_stop.read( )</span><br><span class="line">    f_stop_text=unicode(f_stop_text,&apos;utf-8&apos;)</span><br><span class="line">finally:  </span><br><span class="line">    f_stop.close( ) </span><br><span class="line">f_stop_seg_list=f_stop_text.split(&apos;\n&apos;)</span><br><span class="line">urls=[(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/06/BESLRF5O000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0202/01/BEPHEI1200094O5H.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESBB73B000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESAGOPB000915BD.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0203/05/BESI2S7500294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://kids.163.com/16/0118/06/BDJEMJ3H00294MO6.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0128/05/BED4NHBB00294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0202/01/BEPHFQ1800294IIH.html&quot;)]</span><br><span class="line">samplewords=[]</span><br><span class="line">allw=[]</span><br><span class="line">tokendocstr=[]</span><br><span class="line">print &quot;|=&quot;,</span><br><span class="line">for (category,myurl) in urls: </span><br><span class="line">    htmlsrc=urllib.urlopen(myurl).read()</span><br><span class="line">    htmlsrc=htmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">    soup = BeautifulSoup(htmlsrc, &apos;html.parser&apos;)</span><br><span class="line">    txtsrc=soup.find_all(id=&quot;endText&quot; )</span><br><span class="line">    txtsoup=BeautifulSoup(repr(txtsrc[0]))</span><br><span class="line">    txtstr=txtsoup.get_text()</span><br><span class="line">    txtstr=txtstr.decode(&apos;gbk&apos;).decode(&quot;unicode-escape&quot;).encode(&apos;utf-8&apos;)</span><br><span class="line">    cutstr=cutstring(txtstr)</span><br><span class="line">    tokendocstr.append(nltk.word_tokenize(cutstr))</span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    for w in docstr:</span><br><span class="line">        allw.append(w)</span><br><span class="line">allw=set(allw)</span><br><span class="line">samplefeatures=[]   </span><br><span class="line">i=0   </span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    docfeature=txtfeatures(allw,docstr,f_stop_seg_list)</span><br><span class="line">    samplefeatures.append((docfeature,urls[i][0]))</span><br><span class="line">    i=i+1</span><br><span class="line">samplelen=len(samplefeatures)</span><br><span class="line">trlen=int(samplelen*2/3)#训练样本长度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">random.shuffle(samplefeatures)</span><br><span class="line">traintxt=samplefeatures[:trlen]</span><br><span class="line">testtxt=samplefeatures[trlen:]</span><br><span class="line">print &quot;=&gt;|&quot;</span><br><span class="line">classifier=nltk.NaiveBayesClassifier.train(traintxt)</span><br><span class="line">#测试数据分类准确率</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print nltk.classify.accuracy(classifier,testtxt)</span><br><span class="line">classifier.show_most_informative_features(15)</span><br></pre></td></tr></table></figure>

</details>

<p>观察程序12-16.py，对文本进行特征分析时，其文本特征项由非停用词特征组成，每个非停用词的特征计算方式为：特征名称为非停用词内容，特征值为True（该非停用词在该文本中出现）或False（该非停用词未在该文本中出现）。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def txtfeatures(allwords,tokenw,stopseg):</span><br><span class="line">    features=&#123;&#125;</span><br><span class="line">    for myword in set(allwords):</span><br><span class="line">        if not(myword.strip() in stopseg) and len(myword.strip())&gt;1:</span><br><span class="line">            features[&quot;cnword-&quot;+myword]=(myword in set(tokenw))</span><br><span class="line">            print &quot;=&quot;,    </span><br><span class="line">    return features</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-16.py首先输出分类准确率为0.666666666667；然后输出对分类最有效的前15个特征。程序12-16.py的运行结果如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">......= = =&gt;|</span><br><span class="line">0.666666666667</span><br><span class="line">Most Informative Features</span><br><span class="line">               cnword-国外</span><br><span class="line"></span><br><span class="line"> = False              科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      2.2 : 1.0</span><br><span class="line">               cnword-一年</span><br><span class="line"></span><br><span class="line"> = False              科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      2.2 : 1.0</span><br><span class="line">                ......</span><br><span class="line">               cnword-厕所</span><br><span class="line"></span><br><span class="line"> = False              科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      2.2 : 1.0</span><br><span class="line">               cnword-确实</span><br><span class="line"></span><br><span class="line"> = False              科技</span><br><span class="line"></span><br><span class="line"> : 教育</span><br><span class="line"></span><br><span class="line">     =      2.2 : 1.0</span><br></pre></td></tr></table></figure>

</details>

<p>2.网页分类</p>
<p>程序12-17.py演示了如何使用NLTK对未知网页进行朴素贝叶斯分类：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-17.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import urllib</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">import jieba</span><br><span class="line">def cutstring(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = jieba.cut(txt)</span><br><span class="line">    result=&quot; &quot;.join(cutstr)</span><br><span class="line">    return result</span><br><span class="line">def txtfeatures(allwords,tokenw,stopseg):</span><br><span class="line">    features=&#123;&#125;</span><br><span class="line">    for myword in set(allwords):</span><br><span class="line">        if not(myword.strip() in stopseg) and len(myword.strip())&gt;1:</span><br><span class="line">            features[&quot;cnword-&quot;+myword]=(myword in set(tokenw))  </span><br><span class="line">    return features</span><br><span class="line">#停用词字典</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f_stop = open(&apos;stopwords.txt&apos;)  </span><br><span class="line">try:  </span><br><span class="line">    f_stop_text = f_stop.read( )</span><br><span class="line">    f_stop_text=unicode(f_stop_text,&apos;utf-8&apos;)</span><br><span class="line">finally:  </span><br><span class="line">    f_stop.close( ) </span><br><span class="line">f_stop_seg_list=f_stop_text.split(&apos;\n&apos;)</span><br><span class="line">urls=[(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/06/BESLRF5O000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0202/01/BEPHEI1200094O5H.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESBB73B000915BD.html&quot;),(u&quot;科技</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://tech.163.com/16/0203/03/BESAGOPB000915BD.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0203/05/BESI2S7500294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://kids.163.com/16/0118/06/BDJEMJ3H00294MO6.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0128/05/BED4NHBB00294NE9.html&quot;),(u&quot;教育</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://edu.163.com/16/0202/01/BEPHFQ1800294IIH.html&quot;)]</span><br><span class="line">samplewords=[]</span><br><span class="line">allw=[]</span><br><span class="line">tokendocstr=[]</span><br><span class="line">print &quot;|=&quot;,</span><br><span class="line">for (category,myurl) in urls: </span><br><span class="line">    htmlsrc=urllib.urlopen(myurl).read()</span><br><span class="line">    htmlsrc=htmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">    soup = BeautifulSoup(htmlsrc, &apos;html.parser&apos;)</span><br><span class="line">    txtsrc=soup.find_all(id=&quot;endText&quot; )</span><br><span class="line">    txtsoup=BeautifulSoup(repr(txtsrc[0]))</span><br><span class="line">    txtstr=txtsoup.get_text()</span><br><span class="line">    txtstr=txtstr.decode(&apos;gbk&apos;).decode(&quot;unicode-escape&quot;).encode(&apos;utf-8&apos;)</span><br><span class="line">    cutstr=cutstring(txtstr)</span><br><span class="line">    tokendocstr.append(nltk.word_tokenize(cutstr))</span><br><span class="line">    print &quot;=&quot;,</span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    for w in docstr:</span><br><span class="line">        allw.append(w)</span><br><span class="line">allw=set(allw)</span><br><span class="line">samplefeatures=[]   </span><br><span class="line">i=0   </span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    docfeature=txtfeatures(allw,docstr,f_stop_seg_list)</span><br><span class="line">    samplefeatures.append((docfeature,urls[i][0]))</span><br><span class="line">    i=i+1</span><br><span class="line">traintxt=samplefeatures</span><br><span class="line">print &quot;=&gt;|&quot;</span><br><span class="line">classifier=nltk.NaiveBayesClassifier.train(traintxt)</span><br><span class="line">#新的网页</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testmyurl=&quot;http://tech.163.com/16/0207/09/BF7AR5D4000915BD.html&quot;</span><br><span class="line">testhtmlsrc=urllib.urlopen(testmyurl).read()</span><br><span class="line">testhtmlsrc=testhtmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">soup = BeautifulSoup(testhtmlsrc, &apos;html.parser&apos;)</span><br><span class="line">testtxtsrc=soup.find_all(id=&quot;endText&quot; )</span><br><span class="line">testtxtsoup=BeautifulSoup(repr(testtxtsrc[0]))</span><br><span class="line">testtxtstr=testtxtsoup.get_text()</span><br><span class="line">testtxtstr=testtxtstr.decode(&apos;gbk&apos;).decode(&quot;unicode-escape&quot;).encode(&apos;utf-8&apos;)</span><br><span class="line">testcutstr=cutstring(testtxtstr)</span><br><span class="line">testtokendocstr=nltk.word_tokenize(testcutstr)</span><br><span class="line">testdocfeature=txtfeatures(allw,testtokendocstr,f_stop_seg_list)</span><br><span class="line">#测试数据分类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print classifier.classify(testdocfeature)</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-17.py中有以下关键知识点。</p>
<p>1）文本特征分析。对文本特征的分析首先从词汇特征入手，在去除非停用词后，余下的词汇对文本特征的提取均有意义，每个非停用词的特征名称均为非停用词的内容，特征值为True（该非停用词在该文本中出现）或False（该非停用词未在该文本中出现）。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def txtfeatures(allwords,tokenw,stopseg):</span><br><span class="line">    features=&#123;&#125;</span><br><span class="line">    for myword in set(allwords):</span><br><span class="line">        if not(myword.strip() in stopseg) and len(myword.strip())&gt;1:</span><br><span class="line">            features[&quot;cnword-&quot;+myword]=(myword in set(tokenw))  </span><br><span class="line">    return features</span><br></pre></td></tr></table></figure>

</details>

<p>2）分类结果。调用分类器对象classifier的classify方法对未知样本数据进行分类：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print classifier.classify(testdocfeature)</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-17.py的运行结果如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">...... = = = =&gt;|科技</span><br></pre></td></tr></table></figure>

</details>

<p>观察12-17.py的运行结果可以得知，链接<a href="http://tech.163.com/16/0207/09/BF7AR5D400091" target="_blank" rel="noopener">http://tech.163.com/16/0207/09/BF7AR5D400091</a></p>
<p>5BD.html指向的Web文档为科技类别，在浏览器中打开该页面，标题为“伦敦希望谷歌能将无人驾驶汽车测试带进英国”，该文档确实属于科技类别，分类准确无误。</p>
<h4 id="12-4-7-语法结构分析"><a href="#12-4-7-语法结构分析" class="headerlink" title="12.4.7 语法结构分析"></a>12.4.7 语法结构分析</h4><p>语法是语言学的一个分支，研究按确定用法来运用的词类、词的曲折变化或表示相互关系的其他手段及词在句子中的功能和关系。包含词的构词、构形的规则和组词成句的规则。</p>
<p>程序12-18.py演示了如何使用NLTK识别名词短语及语法树分析：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-18.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">from jieba import posseg</span><br><span class="line">def cutstrpos(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line">+词性</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = posseg.cut(txt)</span><br><span class="line">    result=&quot;&quot;</span><br><span class="line">    for word, flag in cutstr:</span><br><span class="line">        result+=word+&quot;/&quot;+flag+&apos;  &apos;</span><br><span class="line">    return result</span><br><span class="line">sentencestr=[]</span><br><span class="line">txtstr=&quot;&quot;&quot;据美国华盛顿自由灯塔网站</span><br><span class="line"></span><br><span class="line">2月</span><br><span class="line"></span><br><span class="line">17日报道，政府问责局</span><br><span class="line"></span><br><span class="line">16日发布的这份报告称，美国导弹防御局继续将大笔资金用于未被证明能够应对来自伊朗或朝鲜的弹道导弹袭击的技术。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">#生成</span><br><span class="line"></span><br><span class="line">nltk格式的词性单词集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">posstr=cutstrpos(txtstr)</span><br><span class="line">strtag=[nltk.tag.str2tuple(word) for word in posstr.split()]</span><br><span class="line">#句子分割</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sentstr=[]</span><br><span class="line">for wtag in strtag:    </span><br><span class="line">    if wtag[0].strip() in [&quot;，</span><br><span class="line"></span><br><span class="line">&quot;,&quot;。</span><br><span class="line"></span><br><span class="line">&quot;,&quot;！</span><br><span class="line"></span><br><span class="line">&quot;,&quot;？</span><br><span class="line"></span><br><span class="line">&quot;,&quot;：</span><br><span class="line"></span><br><span class="line">&quot;]:</span><br><span class="line">        sentencestr.append(sentstr)</span><br><span class="line">        sentstr=[]</span><br><span class="line">    else :</span><br><span class="line">        if wtag[1]!=&quot;X&quot;:</span><br><span class="line">            sentstr.append((wtag[0].strip(),wtag[1]))</span><br><span class="line">#输出分割后的句子</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for wordstr in sentencestr:</span><br><span class="line">    print</span><br><span class="line">    for word in wordstr:</span><br><span class="line">        print word[0],&quot;/&quot;,word[1],</span><br><span class="line">#名词短语识别</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grammar=r&quot;&quot;&quot;</span><br><span class="line">NP:&#123;(&lt;A&gt;|&lt;R&gt;|&lt;MQ&gt;)*&lt;N&gt;+&lt;K&gt;*&#125;</span><br><span class="line">NP:&#123;(&lt;A&gt;|&lt;R&gt;|&lt;MQ&gt;)*&lt;NS&gt;+&lt;K&gt;*&#125;</span><br><span class="line">NP:&#123;&lt;M&gt;+&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">cp=nltk.RegexpParser(grammar)</span><br><span class="line">result1=cp.parse(sentencestr[0])</span><br><span class="line">result1.draw()</span><br><span class="line">result2=cp.parse(sentencestr[1])</span><br><span class="line">result2.draw()</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-18.py中有以下关键知识点。</p>
<p>（1）生成NLTK格式的词性单词集</p>
<p>首先，通过jieba中文分词组件分词并标注词性，分词结果为形如“词汇1/词性1词汇2/词性2…/…词汇n/词性n”的字符串，每个词汇之间用空格进行分隔；然后，调用nltk.tag的str2tuple函数生成NLTK格式的词性单词集。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">posstr=cutstrpos(txtstr)</span><br><span class="line">strtag=[nltk.tag.str2tuple(word) for word in posstr.split()]</span><br></pre></td></tr></table></figure>

</details>

<p>（2）句子分割并去除标点</p>
<p>在文本字符串中查找“，”、“。”等常用的中文标点符号，将文本分割成句子；此外，将词性是“X”类别（这个词性类别通常为标点）的词删除。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">for wtag in strtag:    </span><br><span class="line">    if wtag[0].strip() in [&quot;，</span><br><span class="line"></span><br><span class="line">&quot;,&quot;。</span><br><span class="line"></span><br><span class="line">&quot;,&quot;！</span><br><span class="line"></span><br><span class="line">&quot;,&quot;？</span><br><span class="line"></span><br><span class="line">&quot;,&quot;：</span><br><span class="line"></span><br><span class="line">&quot;]:</span><br><span class="line">        sentencestr.append(sentstr)</span><br><span class="line">        sentstr=[]</span><br><span class="line">    else :</span><br><span class="line">        if wtag[1]!=&quot;X&quot;:</span><br><span class="line">            sentstr.append((wtag[0].strip(),wtag[1]))</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00050.jpg" alt> 提示 jieba中文分词采用的是和ictclas兼容的标记法。某词的词性“X”表示它是非语素字，非语素字只是一个符号和未知数。</p>
<p>（3）名词短语识别</p>
<p>使用NLTK识别语法结构，最好的方式是指定某语法结构的正则表达式。为简单起见，12-18.py根据本例的实际情况，将常用的名词短语格式定义为“形容词/代词/数量词+名词（包括地名）若干+后缀”或“日期”的格式。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">grammar=r&quot;&quot;&quot;</span><br><span class="line">NP:&#123;(&lt;A&gt;|&lt;R&gt;|&lt;MQ&gt;)*&lt;N&gt;+&lt;K&gt;*&#125;</span><br><span class="line">NP:&#123;(&lt;A&gt;|&lt;R&gt;|&lt;MQ&gt;)*&lt;NS&gt;+&lt;K&gt;*&#125;</span><br><span class="line">NP:&#123;&lt;M&gt;+&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00050.jpg" alt> 提示 A表示形容词，R表示代词，MQ表示数量词，M表示日期词，K表示后缀。具体请参见ICTCLAS汉语词性标注集。</p>
<p>（4）解析语法结构，并绘制语法结构图</p>
<p>首先通过RegexpParser来构造语法结构解析器，然后，通过解析器对象的parse方法解析语法结构，并通过draw方法绘图。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp=nltk.RegexpParser(grammar)</span><br><span class="line">result1=cp.parse(sentencestr[0])</span><br><span class="line">result1.draw()&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-18.py运行后，首先输出句子分割结果，如下所示。然后输出语法结构图，如图12-9所示。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">据</span><br><span class="line"></span><br><span class="line"> / P 美国</span><br><span class="line"></span><br><span class="line"> / NS 华盛顿</span><br><span class="line"></span><br><span class="line"> / NS 自由</span><br><span class="line"></span><br><span class="line"> / A 灯塔</span><br><span class="line"></span><br><span class="line"> / N 网站</span><br><span class="line"></span><br><span class="line"> / N 2 / M 月</span><br><span class="line"></span><br><span class="line"> / M 17 / M 日</span><br><span class="line"></span><br><span class="line"> / M 报道</span><br><span class="line"></span><br><span class="line"> / V政府</span><br><span class="line"></span><br><span class="line"> / N 问责局</span><br><span class="line"></span><br><span class="line"> / N 16 / M 日</span><br><span class="line"></span><br><span class="line"> / M 发布</span><br><span class="line"></span><br><span class="line"> / V 的</span><br><span class="line"></span><br><span class="line"> / UJ 这份</span><br><span class="line"></span><br><span class="line"> / MQ 报告</span><br><span class="line"></span><br><span class="line"> / N 称</span><br><span class="line"></span><br><span class="line"> / V</span><br><span class="line">......因为</span><br><span class="line"></span><br><span class="line"> / C 还</span><br><span class="line"></span><br><span class="line"> / D 需要</span><br><span class="line"></span><br><span class="line"> / V 进行</span><br><span class="line"></span><br><span class="line"> / V 大规模</span><br><span class="line"></span><br><span class="line"> / B 的</span><br><span class="line"></span><br><span class="line"> / UJ 更新</span><br><span class="line"></span><br><span class="line"> / D</span><br></pre></td></tr></table></figure>

</details>

<p><img src="Image00536.jpg" alt></p>
<p>图12-9 语法结构图</p>
<p>观察图12-9所示的语法结构图，可看出程序12-18.py识别出名词短语NP（比如：“美国华盛顿”），并将它们单独绘制在树的第三层。此外，树的第一层是S，表示句子，第二层是该句的语法结构：P表示介词，NP表示名词短语，V表示动词。</p>
<h4 id="12-4-8-Web文档聚类"><a href="#12-4-8-Web文档聚类" class="headerlink" title="12.4.8 Web文档聚类"></a>12.4.8 Web文档聚类</h4><p>文档聚类（Text Clustering）主要是依据著名的聚类假设：同类文档的相似度较大，而不同类文档的相似度较小。作为一种无监督的机器学习方法，聚类由于不需要训练过程，以及不需要预先对文档进行手工标注类别，因此具有一定的灵活性和较高的自动化处理能力，已经成为对文本信息进行有效地组织、摘要和导航的一种重要手段。</p>
<p>1.重点词聚类</p>
<p>程序12-19.py演示了如何使用NLTK通过电影评论对电影进行聚类。对于评论而言，重点词一般是情感类及相关词汇，本例将重点词汇定义为名词、形容词、语气词及叹词。</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-19.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import urllib</span><br><span class="line">import numpy </span><br><span class="line">import re</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">from jieba import posseg</span><br><span class="line">def cutstrpos(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line">+词性</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = posseg.cut(txt)</span><br><span class="line">    result=&quot;&quot;</span><br><span class="line">    for word, flag in cutstr:</span><br><span class="line">        result+=word+&quot;/&quot;+flag+&apos; &apos;</span><br><span class="line">    return result</span><br><span class="line">def inittxtw(allwords):</span><br><span class="line">    txtwords=&#123;&#125;</span><br><span class="line">    for w in allwords:</span><br><span class="line">        txtwords[w]=0</span><br><span class="line">    return txtwords</span><br><span class="line">def txtfeatures(allwdt,tokenw):</span><br><span class="line">    #词频特征提取</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    txtfd=nltk.FreqDist(tokenw)  </span><br><span class="line">    for key,val in sorted(txtfd.iteritems()):</span><br><span class="line">        allwdt[key]=val</span><br><span class="line">    return allwdt.values()</span><br><span class="line">#根据电影评论将电影聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">urls=[(u&quot;功夫熊猫</span><br><span class="line"></span><br><span class="line">3&quot;,&quot;http://ent.163.com/16/0129/00/BEF5L97P00034R77.html&quot;),(u&quot;唐人街探案</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1230/15/BC3GSVQ700034R77.html&quot;),(u&quot;恶棍天使</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1224/07/BBJ60V1H00034R77.html&quot;),(u&quot;老炮儿</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1224/00/BBIED1QL00034R77.html&quot;),(u&quot;寻龙诀</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1218/03/BB3A3I2B00034R77.html&quot;),(u&quot;万万没想到</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1218/03/BB3ACSP700034R77.html&quot;),(u&quot;星球大战</span><br><span class="line"></span><br><span class="line">7&quot;,&quot;http://ent.163.com/15/1217/15/BB21INTG00034R77.html&quot;),(u&quot;饥饿游戏</span><br><span class="line"></span><br><span class="line">3（下）</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1120/07/B8RKKR9C00034R77.html&quot;),(u&quot;九层妖塔</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0930/01/B4NN919N00034R77.html&quot;),(u&quot;超能查派</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0508/06/AP2T6CP400034R77.html&quot;),(u&quot;我是路人甲</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0702/17/ATHL56DT00034R77.html&quot;),(u&quot;港囧</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0925/05/B4BA6IJ600034R77.html&quot;),(u&quot;007：幽灵党</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1113/08/B89PJSGE00034R77.html&quot;),(u&quot;小黄人大眼萌</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0913/07/B3CI689C00034R77.html&quot;)]</span><br><span class="line">allw=[]</span><br><span class="line">tokendocstr=[]</span><br><span class="line">i=0</span><br><span class="line">errorfilm=[]</span><br><span class="line">for (film,myurl) in urls: </span><br><span class="line">    print &quot;\n***************《</span><br><span class="line"></span><br><span class="line">&quot;+film+&quot;》核心词</span><br><span class="line"></span><br><span class="line">**********************&quot; </span><br><span class="line">    htmlsrc=urllib.urlopen(myurl).read()</span><br><span class="line">    htmlsrc=htmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">    pattern=re.compile(r&apos;((class=&quot;end-text&quot;&gt;)|(&lt;br  /&gt;&lt;/p&gt;&lt;p&gt;))(.*&lt;style&gt;.*--&gt;&lt;/p&gt;)*(.+?)(&lt;/p&gt;&lt;/div&gt;|&lt;div id=)&apos;)    </span><br><span class="line">    match = pattern.findall(repr(htmlsrc))</span><br><span class="line">    matchstr=&quot;&quot;</span><br><span class="line">    if match:</span><br><span class="line">        mstr=match[0][4].encode(&apos;utf-8&apos;).decode(&quot;unicode-escape&quot;)</span><br><span class="line">        matchstr+=mstr</span><br><span class="line">    else:</span><br><span class="line">        print film,&quot;无法取得评论</span><br><span class="line"></span><br><span class="line">!&quot;</span><br><span class="line">        errorfilm.append(i)</span><br><span class="line">    i+=1</span><br><span class="line">    txtstr=matchstr.replace(&quot;&lt;/p&gt;&quot;,&quot;&quot;).replace(&quot;&lt;p&gt;&quot;,&quot;&quot;).replace(&quot;&lt;span&gt;&quot;,&quot;&quot;).replace(&quot;&lt;/span&gt;&quot;,&quot;&quot;).replace(r&apos;&lt;b&gt;&apos;,&apos;&apos;).replace(r&apos;&lt;/b&gt;&apos;,&apos;&apos;)</span><br><span class="line">    #生成</span><br><span class="line"></span><br><span class="line">nltk格式的词性单词集</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    posstr=cutstrpos(txtstr)</span><br><span class="line">    strtag=[nltk.tag.str2tuple(word) for word in posstr.split()]</span><br><span class="line">    cutstr=&quot;&quot;    </span><br><span class="line">    for word,tag in strtag:</span><br><span class="line">        #只处理名词、形容词、语气词、叹词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        if  tag[0]==&quot;N&quot; or tag[0]==&quot;A&quot; or tag[0]==&quot;Y&quot; or tag[0]==&quot;E&quot;:</span><br><span class="line">            cutstr+=word+&quot; &quot;</span><br><span class="line">    print  cutstr</span><br><span class="line">    tokendocstr.append(nltk.word_tokenize(cutstr))</span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    for w in docstr:</span><br><span class="line">        allw.append(w)</span><br><span class="line">allw=set(allw)</span><br><span class="line">samplefeatures=[]   </span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    allwdt=inittxtw(allw)</span><br><span class="line">    docfeature=numpy.array(txtfeatures(allwdt,docstr))</span><br><span class="line">    samplefeatures.append(docfeature)</span><br><span class="line">#GAAC聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;----------------GAAC聚类</span><br><span class="line"></span><br><span class="line">------------&quot;</span><br><span class="line">txtclassfier=nltk.cluster.gaac.GAAClusterer(num_clusters=5,normalise=True)</span><br><span class="line">txtclassfier.cluster(vectors=samplefeatures)</span><br><span class="line">i=0</span><br><span class="line">for data in samplefeatures:</span><br><span class="line">    print urls[i][0],&quot;聚类编号</span><br><span class="line"></span><br><span class="line">:&quot;</span><br><span class="line">    print txtclassfier.classify(data)</span><br><span class="line">    i+=1</span><br><span class="line">#kmeans聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;-------------kmeans聚类</span><br><span class="line"></span><br><span class="line">--------------&quot;</span><br><span class="line">txtclassfier=nltk.cluster.kmeans.KMeansClusterer(num_means=5,distance=nltk.cluster.util.euclidean_distance)</span><br><span class="line">txtclassfier.cluster(samplefeatures)</span><br><span class="line">i=0</span><br><span class="line">for data in samplefeatures:</span><br><span class="line">    print urls[i][0],&quot;聚类编号</span><br><span class="line"></span><br><span class="line">:&quot;</span><br><span class="line">    print txtclassfier.classify(data)</span><br><span class="line">    i+=1</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-19.py中有以下关键知识点。</p>
<p>（1）文本特征提取</p>
<p>通过提取重点词在文本中出现的数量作为该文本的特征，代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def txtfeatures(allwdt,tokenw):</span><br><span class="line">    #词频特征提取</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    txtfd=nltk.FreqDist(tokenw)  </span><br><span class="line">    for key,val in sorted(txtfd.iteritems()):</span><br><span class="line">        allwdt[key]=val</span><br><span class="line">    return allwdt.values()</span><br></pre></td></tr></table></figure>

</details>

<p>（2）重点词筛选</p>
<p>N表示名词，A表示形容词，Y表示语气词，E表示叹词，将这4类词筛选出来作为评论的重点词，参与文本特征提取计算。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for word,tag in strtag:</span><br><span class="line">    #只处理名词、形容词、语气词、叹词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    if  tag[0]==&quot;N&quot; or tag[0]==&quot;A&quot; or tag[0]==&quot;Y&quot; or tag[0]==&quot;E&quot;:</span><br><span class="line">        cutstr+=word+&quot; &quot;</span><br></pre></td></tr></table></figure>

</details>

<p>（3）GAA算法</p>
<p>群平均聚类，简称GAA（The Group Average Agglomerative），核心思想是：开始以每一个向量作为单个群，然后迭代，将有最近的质心的集全部成群，这一过程持续到仅有一个群，这种合并产生了树状图。纵观这一过程可以看出，GAA属于层次式聚类方法，它的基本步骤如下：</p>
<p>1）将每个对象归为一类，共得到N类，每类仅包含一个对象。类与类之间的距离就是它们所包含的对象之间的距离。</p>
<p>2）找到最接近的两个类并合并成一个类，于是类的总数少了一个。</p>
<p>3）重新计算新的类与所有旧类之间的距离。</p>
<p>4）重复第2步和第3步，直到最后合并成一个类为止（此类包含了N个对象）。</p>
<p>整个聚类过程其实是建立了GAA树（如图12-10所示）。关键是如何判断两个类之间的相似度，对于文本而言，一般使用余弦距离来判断相似性。</p>
<p><img src="Image00537.jpg" alt></p>
<p>图12-10 GAA树</p>
<p>使用NLTK进行GAA的过程一般如下：</p>
<p>1）通过nltk.cluster.gaac的GAAClusterer函数构造GAA对象，其中normalise参数为True时表示使用余弦相似度。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txtclassfier=nltk.cluster.gaac.GAAClusterer(num_clusters=5,normalise=True)</span><br></pre></td></tr></table></figure>

</details>

<p>2）以聚类样本为参数调用cluster函数进行聚类。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txtclassfier.cluster(vectors=samplefeatures)</span><br></pre></td></tr></table></figure>

</details>

<p>3）通过classify函数返回聚类结果。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print txtclassfier.classify(data)</span><br></pre></td></tr></table></figure>

</details>

<p>（4）K均值算法</p>
<p>K均值算法以欧式距离作为相似度来测度，它是求对应某一初始聚类中心向量V的最优分类，使得评价指标J最小。算法采用误差平方和准则函数作为聚类准则函数，即认为两个对象的距离越近，其相似度就越大，因此算法把产生紧凑且独立的簇作为最终目标。</p>
<p>该算法在每次迭代中对数据集中剩余的每个对象，根据其与各个簇中心的距离将每个对象重新赋给最近的簇。当考察完所有的数据对象后，一次迭代运算完成，新的聚类中心被计算出来。如果在一次迭代前后，评价指标J的值没有发生变化，就说明算法已经收敛。</p>
<p>算法的具体过程如下：</p>
<p>1）从N个文档随机选取K个文档作为质心。</p>
<p>2）对剩余的每个文档测量其到每个质心的距离，并把它归到最近的质心的类。</p>
<p>3）重新计算已经得到的各个类的质心。</p>
<p>4）迭代第2步和第3步直至新的质心与原质心相等或小于指定阈值，算法结束。</p>
<p>使用NLTK进行K均值算法的过程一般如下：</p>
<p>1）通过nltk.cluster.kmeans的KMeansClusterer函数构造K均值聚类器对象。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txtclassfier=nltk.cluster.kmeans.KMeansClusterer(num_means=5,distance=nltk.cluster.util.euclidean_distance)</span><br></pre></td></tr></table></figure>

</details>

<p>2）以聚类样本为参数调用cluster函数进行聚类。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txtclassfier.cluster(vectors=samplefeatures)</span><br></pre></td></tr></table></figure>

</details>

<p>3）通过classify函数返回聚类结果。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print txtclassfier.classify(data)</span><br></pre></td></tr></table></figure>

</details>

<p>2.关键词聚类</p>
<p>程序12-20.py演示了如何使用NLTK，通过电影评论对电影进行聚类。与12-19.py不同的是，本例聚类的依据是关键词，计算关键词的算法为TF/IDF权重算法，取权重最大的前30个词作为关键词。代码如下所示：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line">#--coding:utf-8--</span><br><span class="line">#code by myhaspl </span><br><span class="line">#12-20.py</span><br><span class="line">from __future__ import unicode_literals</span><br><span class="line">from __future__ import division</span><br><span class="line">import pylab </span><br><span class="line">import nltk</span><br><span class="line">import urllib</span><br><span class="line">import numpy </span><br><span class="line">import re</span><br><span class="line">import sys</span><br><span class="line">import jieba.analyse</span><br><span class="line">sys.path.append(&quot;../&quot;)</span><br><span class="line">pylab.mpl.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]</span><br><span class="line">from jieba import posseg</span><br><span class="line">def cutstrpos(txt):</span><br><span class="line">    #分词</span><br><span class="line"></span><br><span class="line">+词性</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    cutstr = posseg.cut(txt)</span><br><span class="line">    result=&quot;&quot;</span><br><span class="line">    for word, flag in cutstr:</span><br><span class="line">        result+=word+&quot;/&quot;+flag+&apos; &apos;</span><br><span class="line">    return result</span><br><span class="line">def inittxtw(allwords):</span><br><span class="line">    txtwords=&#123;&#125;</span><br><span class="line">    for w in allwords:</span><br><span class="line">        txtwords[w]=0</span><br><span class="line">    return txtwords</span><br><span class="line">def txtfeatures(allwdt,tokenw):</span><br><span class="line">    #统计词频数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    txtfd=nltk.FreqDist(tokenw)  </span><br><span class="line">    for key,val in sorted(txtfd.iteritems()):</span><br><span class="line">        allwdt[key]=val</span><br><span class="line">    return allwdt.values()</span><br><span class="line">#根据电影评论将电影聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">urls=[(u&quot;功夫熊猫</span><br><span class="line"></span><br><span class="line">3&quot;,&quot;http://ent.163.com/16/0129/00/BEF5L97P00034R77.html&quot;),(u&quot;唐人街探案</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1230/15/BC3GSVQ700034R77.html&quot;),(u&quot;恶棍天使</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1224/07/BBJ60V1H00034R77.html&quot;),(u&quot;老炮儿</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1224/00/BBIED1QL00034R77.html&quot;),(u&quot;寻龙诀</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1218/03/BB3A3I2B00034R77.html&quot;),(u&quot;万万没想到</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1218/03/BB3ACSP700034R77.html&quot;),(u&quot;星球大战</span><br><span class="line"></span><br><span class="line">7&quot;,&quot;http://ent.163.com/15/1217/15/BB21INTG00034R77.html&quot;),(u&quot;饥饿游戏</span><br><span class="line"></span><br><span class="line">3（下）</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1120/07/B8RKKR9C00034R77.html&quot;),(u&quot;九层妖塔</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0930/01/B4NN919N00034R77.html&quot;),(u&quot;超能查派</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0508/06/AP2T6CP400034R77.html&quot;),(u&quot;我是路人甲</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0702/17/ATHL56DT00034R77.html&quot;),(u&quot;港囧</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0925/05/B4BA6IJ600034R77.html&quot;),(u&quot;007：幽灵党</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/1113/08/B89PJSGE00034R77.html&quot;),(u&quot;小黄人大眼萌</span><br><span class="line"></span><br><span class="line">&quot;,&quot;http://ent.163.com/15/0913/07/B3CI689C00034R77.html&quot;)]</span><br><span class="line">allw=[]</span><br><span class="line">tokendocstr=[]</span><br><span class="line">i=0</span><br><span class="line">errorfilm=[]</span><br><span class="line">for (film,myurl) in urls: </span><br><span class="line">    print &quot;\n***************《</span><br><span class="line"></span><br><span class="line">&quot;+film+&quot;》关键词</span><br><span class="line"></span><br><span class="line">**********************&quot; </span><br><span class="line">    htmlsrc=urllib.urlopen(myurl).read()</span><br><span class="line">    htmlsrc=htmlsrc.decode(&apos;gbk&apos;)</span><br><span class="line">    pattern=re.compile(r&apos;((class=&quot;end-text&quot;&gt;)|(&lt;br  /&gt;&lt;/p&gt;&lt;p&gt;))(.*&lt;style&gt;.*--&gt;&lt;/p&gt;)*(.+?)(&lt;/p&gt;&lt;/div&gt;|&lt;div id=)&apos;)    </span><br><span class="line">    match = pattern.findall(repr(htmlsrc))</span><br><span class="line">    matchstr=&quot;&quot;</span><br><span class="line">    if match:</span><br><span class="line">        mstr=match[0][4].encode(&apos;utf-8&apos;).decode(&quot;unicode-escape&quot;)</span><br><span class="line">        matchstr+=mstr</span><br><span class="line">    else:</span><br><span class="line">        print film,&quot;无法取得评论</span><br><span class="line"></span><br><span class="line">!&quot;</span><br><span class="line">        errorfilm.append(i)</span><br><span class="line">    i+=1</span><br><span class="line">    txtstr=matchstr.replace(&quot;&lt;/p&gt;&quot;,&quot;&quot;).replace(&quot;&lt;p&gt;&quot;,&quot;&quot;).replace(&quot;&lt;span&gt;&quot;,&quot;&quot;).replace(&quot;&lt;/span&gt;&quot;,&quot;&quot;).replace(r&apos;&lt;b&gt;&apos;,&apos;&apos;).replace(r&apos;&lt;/b&gt;&apos;,&apos;&apos;)</span><br><span class="line">    #提取前</span><br><span class="line"></span><br><span class="line">30位</span><br><span class="line"></span><br><span class="line">TF/IDF权重最大的关键词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    topK = 30</span><br><span class="line">    tags = jieba.analyse.extract_tags(txtstr, topK=topK)</span><br><span class="line">    cutstr=&quot;  &quot;.join(tags)</span><br><span class="line">    print cutstr</span><br><span class="line">    tokendocstr.append(nltk.word_tokenize(cutstr))</span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    for w in docstr:</span><br><span class="line">        allw.append(w)</span><br><span class="line">allw=set(allw)</span><br><span class="line">samplefeatures=[]   </span><br><span class="line">for docstr in tokendocstr:</span><br><span class="line">    allwdt=inittxtw(allw)</span><br><span class="line">    docfeature=numpy.array(txtfeatures(allwdt,docstr))</span><br><span class="line">    samplefeatures.append(docfeature)</span><br><span class="line">#GAAC聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;----------------GAAC聚类</span><br><span class="line"></span><br><span class="line">------------&quot;</span><br><span class="line">txtclassfier=nltk.cluster.gaac.GAAClusterer(num_clusters=5,normalise=True)</span><br><span class="line">txtclassfier.cluster(vectors=samplefeatures)</span><br><span class="line">i=0</span><br><span class="line">for data in samplefeatures:</span><br><span class="line">    print urls[i][0],&quot;聚类编号</span><br><span class="line"></span><br><span class="line">:&quot;</span><br><span class="line">    print txtclassfier.classify(data)</span><br><span class="line">    i+=1</span><br><span class="line">#kmeans聚类</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print u&quot;-------------kmeans聚类</span><br><span class="line"></span><br><span class="line">--------------&quot;</span><br><span class="line">txtclassfier=nltk.cluster.kmeans.KMeansClusterer(num_means=5,distance=nltk.cluster.util.euclidean_distance)</span><br><span class="line">txtclassfier.cluster(samplefeatures)</span><br><span class="line">i=0</span><br><span class="line">for data in samplefeatures:</span><br><span class="line">    print urls[i][0],&quot;聚类编号</span><br><span class="line"></span><br><span class="line">:&quot;</span><br><span class="line">    print txtclassfier.classify(data)</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-20.py的核心在于提取关键词，本例基于TF/IDF权重，即：取TF/IDF权重最高的前30个词作为关键词。</p>
<p>TF-IDF是一种统计方法，用以评估某一字词对于一个文件集或一个语料库中的某一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF指词频（Term Frequency），IDF指逆向文件频率（Inverse Document Frequency）。TF的意义在于可表示词条t在文档d中出现的频率，IDF的意义在于如果包含词条t的文档越少，也就是n越小，IDF越大，则说明词条t具有很好的类别区分能力。</p>
<p>下面的代码片断通过调用jieba分词组件的analyse.extract_tags方法来分析TF/IDF权重：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#提取前</span><br><span class="line"></span><br><span class="line">30位</span><br><span class="line"></span><br><span class="line">TF/IDF权重最大的关键词</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> topK = 30</span><br><span class="line"> tags = jieba.analyse.extract_tags(txtstr, topK=topK)</span><br><span class="line"> cutstr=&quot;  &quot;.join(tags)-</span><br><span class="line"> print cutstr</span><br><span class="line"> tokendocstr.append(nltk.word_tokenize(cutstr))</span><br></pre></td></tr></table></figure>

</details>

<p>程序12-20.py首先输出各部电影评论的关键词，然后输出电影的聚类结果，聚类编号相同者为观众心目中的同一类型电影。运行结果如下：</p>
<details>
  <summary>代码详情</summary>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">***************《功夫熊猫</span><br><span class="line"></span><br><span class="line">3》关键词</span><br><span class="line"></span><br><span class="line">***************熊猫</span><br><span class="line"></span><br><span class="line">  功夫</span><br><span class="line"></span><br><span class="line">  阿宝</span><br><span class="line"></span><br><span class="line">  天煞</span><br><span class="line"></span><br><span class="line">  梦工厂</span><br><span class="line"></span><br><span class="line">  影片</span><br><span class="line"></span><br><span class="line">  反派</span><br><span class="line"></span><br><span class="line">  动画电影</span><br><span class="line"></span><br><span class="line">  修炼</span><br><span class="line"></span><br><span class="line">  师父</span><br><span class="line"></span><br><span class="line">  电影</span><br><span class="line"></span><br><span class="line">  搞笑</span><br><span class="line"></span><br><span class="line">  动画</span><br><span class="line"></span><br><span class="line">  角色</span><br><span class="line"></span><br><span class="line">  残豹</span><br><span class="line"></span><br><span class="line">  前作</span><br><span class="line"></span><br><span class="line">  浣熊</span><br><span class="line"></span><br><span class="line">  无厘头</span><br><span class="line"></span><br><span class="line">  一集</span><br><span class="line"></span><br><span class="line">  顿悟</span><br><span class="line"></span><br><span class="line">  气功</span><br><span class="line"></span><br><span class="line">  一部</span><br><span class="line"></span><br><span class="line">  没有</span><br><span class="line"></span><br><span class="line">  包子</span><br><span class="line"></span><br><span class="line">  剧情</span><br><span class="line"></span><br><span class="line">  显得</span><br><span class="line"></span><br><span class="line">  武功</span><br><span class="line"></span><br><span class="line">  孔雀</span><br><span class="line"></span><br><span class="line">  觉醒</span><br><span class="line"></span><br><span class="line">  以及</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">----------------GAAC聚类</span><br><span class="line"></span><br><span class="line">------------功夫熊猫</span><br><span class="line"></span><br><span class="line">3 聚类编号：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1唐人街探案</span><br><span class="line"></span><br><span class="line"> 聚类编号：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2</span><br><span class="line">......</span><br><span class="line">-------------kmeans聚类</span><br><span class="line"></span><br><span class="line">--------------功夫熊猫</span><br><span class="line"></span><br><span class="line">3 聚类编号：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">4唐人街探案</span><br><span class="line"></span><br><span class="line"> 聚类编号：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

</details>

<h3 id="12-5-小结"><a href="#12-5-小结" class="headerlink" title="12.5 小结"></a>12.5 小结</h3><p>现在已经是数字时代了，可获得的和需要处理的文本数量越来越多，而文本数据与其他数据不同，它具有非结构化的特点，这对文本数据的分类与自然语言的处理提出了更高的要求。</p>
<p>本章首先介绍了基于余弦相似度、朴素贝叶斯算法的文本分类及Web文档分类技术，并详细讲解了文本预处理技术（中文分词、停用词处理等）、文本特征提取技术等内容。然后阐述了使用NLTK工具对中文进行自然语言处理的技术，包括分词与词性标注、词汇特征指标、Web文档分析、Web文档分类及聚类、文本语法结构分析等内容。</p>
<h3 id="思考题-2"><a href="#思考题-2" class="headerlink" title="思考题"></a>思考题</h3><p>（1）基于余弦相似度算法对新闻网页进行分类，观察其效果。</p>
<p>（2）基于SVM算法对新闻网页进行分类，观察其效果。</p>
<p><img src="Image00050.jpg" alt> 提示 文本样本的特征组可以定义为其包含的词条在某类别中出现的先验概率。</p>
<p>（3）基于加权朴素贝叶斯算法对新闻网页进行分类，观察其效果。</p>
<p><img src="Image00050.jpg" alt> 提示 可以以新闻的标题为关键句，将标题中包含的词赋予较大的权重，将权重直接乘以先验概率作为标题词条的先验概率。</p>
</dir></dir></dir></dir></1e-100:></0:></http:></http:></0:></http:></http:></http:></1e-50:></0:></255:></threshold></threshold></isface2:></isface2:></isface2:></isface2:></0:></0:></0:></0:></0:></0:></0:></0:></0:></0:></0:></0:></=ds_internal:></0:></0:></0:></0:></0:></0:></0:></0:></minds:></minds:></minds:></20:></1:></1:></=16></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></-c(42,153,54,176,61,134,98,155,82,111,63,244,178,232,167,222,107,193,115,190,132)></-filter(x,></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></-c(12,123,54,176,121,134,198,155,122,111,133,244,278,232,267,222,187,193,245,110,132)></500:></expect_e></500:></mymin:></-data.frame(></-dist(buy)></-c(13,1)></-c(500,600,200,12,38,59,482,295,260,279,410,552,677)></5:></3:></3:></3:></matplotlib.lines.line2d></matplotlib.lines.line2d></matplotlib.lines.line2d></matplotlib.lines.line2d></matplotlib.lines.line2d></details></-jyhy></-jyhy></-c(1.6,0.9,2.1,2.2,2.3,1.7,1.3,1.6,4.7,1.2,0.9,4.7,0.6,5.3,1.1,4.8,4,4.2,></-nls(y></-100></-seq(1,10,0.1)></-nls(y></-100></-seq(1,10,0.1)></-100></-nls(y></-100></-c(1,2,3,4,7,8,9)></2e-16></-c(6,8,10,12,16,20)></-c(1,2,3,4,7,9)></-c(5,7,9,11,16,20)></-c(5,7,9,11,16,20)></-c(1,2,3,4,7,9)></-c(1,2,3,4,7,9)></-c(5,7,9,11,16,20)></=65535:></str_len:></str_len):></str_len):></10000000):></https:></https:></http:></http:></student.txt></18"></student.txt></student.txt></http:></-function(...){></-function(x1，></-function(参数></-function(x){></-function(x1，></-function(参数></-seq(min(y)，></-c(11，></-c(1，></-c(5，></-c(1，></-c(2，></-array(c(1:4)，></-array(c(1:16)，></-array(c(1:3)，></-array(c(4:6)，></-c(1:3)></-c(4:6)></-c(1:3)></-array(c(5:8))></-array(c(1:4))></-array(c(5:6))></-array(c(1:4))></-matrix(c(101:105)，></-matrix(c(1:10)，></-c(1:10)></-c(101:105)></-array(c(1:16)，></-array(c(1:10)，></-array(1，></-array(h，></-c(2，></-array(h，></-111></-c(10)></-c(2，></-function(x)></-c(3.5，></-c("苹果></-(11:20)></-(1:10)></-c()></10)></-c(1:10)></-(11:20)></-(1:10)></-c()></-c(></-c(25，></-c(11，></-c(11，></-"test"></-5:12></100]<-x[x<100]+20></-32></-age[c("张三></100]-></30)-></30-></30-></details><link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      <div>    
       
       
      <ul class="post-copyright">
        <li class="post-copyright-author">
            <strong>本文作者：</strong>hac_lang
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="/2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/" title="book_《机器学习实践指南：案例应用解析（第2版）》">2016/11/07/book-《机器学习实践指南：案例应用解析（第2版）》/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          许可协议，请勿用于商业，转载注明出处！
        </li>
      </ul>
      
      </div>
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/自评/" rel="tag"># 自评</a>
          
            <a href="/tags/books/" rel="tag"># books</a>
          
            <a href="/tags/算法/" rel="tag"># 算法</a>
          
            <a href="/tags/更毕/" rel="tag"># 更毕</a>
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
            <a href="/tags/豆瓣/" rel="tag"># 豆瓣-</a>
          
            <a href="/tags/IBOM/" rel="tag"># IBOM</a>
          
            <a href="/tags/FK/" rel="tag"># FK</a>
          
            <a href="/tags/BUPE/" rel="tag"># BUPE</a>
          
            <a href="/tags/Citrix/" rel="tag"># Citrix</a>
          
            <a href="/tags/统计分析/" rel="tag"># 统计分析</a>
          
            <a href="/tags/SVM/" rel="tag"># SVM</a>
          
            <a href="/tags/机器视觉/" rel="tag"># 机器视觉</a>
          
            <a href="/tags/文本分类/" rel="tag"># 文本分类</a>
          
            <a href="/tags/NLTK/" rel="tag"># NLTK</a>
          
            <a href="/tags/虚拟化/" rel="tag"># 虚拟化</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/09/30/book-《机器学习系统设计：Python语言实现》/" rel="next" title="book_《机器学习系统设计：Python语言实现》">
                <i class="fa fa-chevron-left"></i> book_《机器学习系统设计：Python语言实现》
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/11/11/book-《机器学习实战》-Peter-Harrington-李锐等译/" rel="prev" title="book_《机器学习实战》_Peter Harrington_李锐等译">
                book_《机器学习实战》_Peter Harrington_李锐等译 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="hac_lang">
  
  <p class="site-author-name" itemprop="name">hac_lang</p>
  <div class="site-description motion-element" itemprop="description">小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">82</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>







  <div class="links-of-author motion-element">
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/HACLANG" title="GitHub &rarr; https://github.com/HACLANG" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://stackoverflow.com/yourname" title="StackOverflow &rarr; https://stackoverflow.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://gitter.im" title="Gitter &rarr; https://gitter.im" rel="noopener" target="_blank"><i class="fa fa-fw fa-github-alt"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.jianshu.com/u/442ddccf3f32" title="简书 &rarr; https://www.jianshu.com/u/442ddccf3f32" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="Quora &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://plus.google.com/yourname" title="Google &rarr; https://plus.google.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:haclang.org@gmail.com" title="E-Mail &rarr; mailto:haclang.org@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="skype:haclang?call|chat" title="Skype &rarr; skype:haclang?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://twitter.com/haclang2" title="Twitter &rarr; https://twitter.com/haclang2" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="FaceBook &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a>
      </span>
    
  </div>








          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#推荐序"><span class="nav-text">推荐序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么要写这本书"><span class="nav-text">为什么要写这本书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#读者对象"><span class="nav-text">读者对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何阅读本书"><span class="nav-text">如何阅读本书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#勘误和支持"><span class="nav-text">勘误和支持</span></a></li></ol></li></ol><li class="nav-item nav-level-2"><a class="nav-link" href="#第1章-机器学习发展及应用前景"><span class="nav-text">第1章 机器学习发展及应用前景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-机器学习概述"><span class="nav-text">1.1 机器学习概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-1-什么是机器学习"><span class="nav-text">1.1.1 什么是机器学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-2-机器学习的发展"><span class="nav-text">1.1.2 机器学习的发展</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-3-机器学习的未来"><span class="nav-text">1.1.3 机器学习的未来</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-机器学习应用前景"><span class="nav-text">1.2 机器学习应用前景</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-1-数据分析与挖掘"><span class="nav-text">1.2.1 数据分析与挖掘</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-模式识别"><span class="nav-text">1.2.2 模式识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-3-更广阔的领域"><span class="nav-text">1.2.3 更广阔的领域</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-小结"><span class="nav-text">1.3 小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第2章-科学计算平台"><span class="nav-text">第2章 科学计算平台</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-科学计算软件平台概述"><span class="nav-text">2.1 科学计算软件平台概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-常用的科学计算软件"><span class="nav-text">2.1.1 常用的科学计算软件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-本书使用的工程计算平台"><span class="nav-text">2.1.2 本书使用的工程计算平台</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-计算平台的配置"><span class="nav-text">2.2 计算平台的配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-Numpy等Python科学计算包的安装与配置"><span class="nav-text">2.2.1 Numpy等Python科学计算包的安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-OpenCV安装与配置"><span class="nav-text">2.2.2 OpenCV安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-mlpy安装与配置"><span class="nav-text">2.2.3 mlpy安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-4-BeautifulSoup安装与配置"><span class="nav-text">2.2.4 BeautifulSoup安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-5-Neurolab安装与配置"><span class="nav-text">2.2.5 Neurolab安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-6-R安装与配置"><span class="nav-text">2.2.6 R安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-小结"><span class="nav-text">2.3 小结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第二部分-基础篇"><span class="nav-text">第二部分 基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第3章-计算平台应用实例"><span class="nav-text">第3章 计算平台应用实例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Python计算平台简介及应用实例"><span class="nav-text">3.1 Python计算平台简介及应用实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-Python语言基础"><span class="nav-text">3.1.1 Python语言基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-Numpy库"><span class="nav-text">3.1.2 Numpy库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-pylab、matplotlib绘图"><span class="nav-text">3.1.3 pylab、matplotlib绘图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-4-图像基础"><span class="nav-text">3.1.4 图像基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-5-图像融合与图像镜像"><span class="nav-text">3.1.5 图像融合与图像镜像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-6-图像灰度化与图像加噪"><span class="nav-text">3.1.6 图像灰度化与图像加噪</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-7-声音基础"><span class="nav-text">3.1.7 声音基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-8-声音音量调节"><span class="nav-text">3.1.8 声音音量调节</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-9-图像信息隐藏"><span class="nav-text">3.1.9 图像信息隐藏</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-10-声音信息隐藏"><span class="nav-text">3.1.10 声音信息隐藏</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-R语言基础"><span class="nav-text">3.2 R语言基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-基本操作"><span class="nav-text">3.2.1 基本操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-4-中位数"><span class="nav-text">6.2.4 中位数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-5-极差、半极差"><span class="nav-text">6.2.5 极差、半极差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-6-方差"><span class="nav-text">6.2.6 方差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-7-标准差"><span class="nav-text">6.2.7 标准差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-8-变异系数、样本平方和"><span class="nav-text">6.2.8 变异系数、样本平方和</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-9-偏度系数、峰度系数"><span class="nav-text">6.2.9 偏度系数、峰度系数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-正态分布案例解析"><span class="nav-text">6.3 正态分布案例解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-1-正态分布函数"><span class="nav-text">6.3.1 正态分布函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-2-峰度系数分析"><span class="nav-text">6.3.2 峰度系数分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-3-累积分布概率"><span class="nav-text">6.3.3 累积分布概率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-4-概率密度函数"><span class="nav-text">6.3.4 概率密度函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-5-分位点"><span class="nav-text">6.3.5 分位点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-6-频率直方图"><span class="nav-text">6.3.6 频率直方图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-7-核概率密度与正态概率分布图"><span class="nav-text">6.3.7 核概率密度与正态概率分布图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-8-正态检验与分布拟合"><span class="nav-text">6.3.8 正态检验与分布拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-9-其他分布及其拟合"><span class="nav-text">6.3.9 其他分布及其拟合</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-多变量分析"><span class="nav-text">6.4 多变量分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-1-多变量数据分析"><span class="nav-text">6.4.1 多变量数据分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4-2-多元数据相关性分析"><span class="nav-text">6.4.2 多元数据相关性分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-小结"><span class="nav-text">6.5 小结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#思考题"><span class="nav-text">思考题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第7章-假设检验与回归模型案例"><span class="nav-text">第7章 假设检验与回归模型案例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-假设检验"><span class="nav-text">7.1 假设检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-1-二项分布假设检验"><span class="nav-text">7.1.1 二项分布假设检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-2-数据分布检验"><span class="nav-text">7.1.2 数据分布检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-3-正态总体均值检验"><span class="nav-text">7.1.3 正态总体均值检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-4-列联表"><span class="nav-text">7.1.4 列联表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-5-符号检测"><span class="nav-text">7.1.5 符号检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-6-秩相关检验"><span class="nav-text">7.1.6 秩相关检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-7-Kendall相关检验"><span class="nav-text">7.1.7 Kendall相关检验</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-回归模型"><span class="nav-text">7.2 回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-1-回归预测与显著性检验"><span class="nav-text">7.2.1 回归预测与显著性检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-2-回归诊断"><span class="nav-text">7.2.2 回归诊断</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-3-回归优化"><span class="nav-text">7.2.3 回归优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-4-主成分回归"><span class="nav-text">7.2.4 主成分回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-5-广义线性模型"><span class="nav-text">7.2.5 广义线性模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-小结"><span class="nav-text">7.3 小结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#思考题-1"><span class="nav-text">思考题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第四部分-机器学习实战篇"><span class="nav-text">第四部分 机器学习实战篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#第8章-机器学习算法"><span class="nav-text">第8章 机器学习算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-神经网络"><span class="nav-text">8.1 神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-1-1-Rosenblatt感知器"><span class="nav-text">8.1.1 Rosenblatt感知器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-1-2-梯度下降"><span class="nav-text">8.1.2 梯度下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-1-3-反向传播与多层感知器"><span class="nav-text">8.1.3 反向传播与多层感知器</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#null"><span class="nav-text">My First Heading</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-4-7-语法结构分析"><span class="nav-text">12.4.7 语法结构分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-4-8-Web文档聚类"><span class="nav-text">12.4.8 Web文档聚类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-5-小结"><span class="nav-text">12.5 小结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#思考题-2"><span class="nav-text">思考题</span></a></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hac_lang</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  





  
    
    
      
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="true"></script>









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  
  

  
  

  


  

  

  

  

  


  


  




  




  




  



<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>


  

  

  


  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false,"scale":0.5},"react":{"opacity":0.7},"log":false,"tagMode":false});</script></body>
</html>
