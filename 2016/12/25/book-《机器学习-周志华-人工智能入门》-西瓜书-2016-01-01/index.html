<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="主要符号表    符号 意义     $x$ 标量   $\boldsymbol x$ 向量   x 变量集   $A$ 矩阵   $I$ 单位阵   $\chi$ 样本空间或状态空间   $D$ 概率分布   D 数据样本（数据集）   $H$ 假设空间   H 假设集   $\xi$ 学习算法   $(·,·,·)$ 行向量   $(·;·;·)$ 列向量   $(·)^T$ 向量或矩阵的转置">
<meta name="keywords" content="机器学习,计算机科学,计算机,人工智能,自评,books,更毕,AI,数据挖掘,数据分析,MachineLearning,豆瓣8">
<meta property="og:type" content="article">
<meta property="og:title" content="book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01">
<meta property="og:url" content="https://haclang.github.io/2016/12/25/book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01/index.html">
<meta property="og:site_name" content="Hac_lang">
<meta property="og:description" content="主要符号表    符号 意义     $x$ 标量   $\boldsymbol x$ 向量   x 变量集   $A$ 矩阵   $I$ 单位阵   $\chi$ 样本空间或状态空间   $D$ 概率分布   D 数据样本（数据集）   $H$ 假设空间   H 假设集   $\xi$ 学习算法   $(·,·,·)$ 行向量   $(·;·;·)$ 列向量   $(·)^T$ 向量或矩阵的转置">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2020-08-16T12:30:05.968Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01">
<meta name="twitter:description" content="主要符号表    符号 意义     $x$ 标量   $\boldsymbol x$ 向量   x 变量集   $A$ 矩阵   $I$ 单位阵   $\chi$ 样本空间或状态空间   $D$ 概率分布   D 数据样本（数据集）   $H$ 假设空间   H 假设集   $\xi$ 学习算法   $(·,·,·)$ 行向量   $(·;·;·)$ 列向量   $(·)^T$ 向量或矩阵的转置">





  
  
  <link rel="canonical" href="https://haclang.github.io/2016/12/25/book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01 | Hac_lang</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hac_lang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">小白hac_lang的笔记，涉及内容包含但不限于：人工智能   基因工程    信息安全   软件工程   嵌入式   天文物理</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-news">

    
    
      
    

    

    <a href="/news/" rel="section"><i class="menu-item-icon fa fa-fw fa-rss"></i> <br>news</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    
  
  

  

  <a href="https://github.com/HACLANG" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://haclang.github.io/2016/12/25/book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="hac_lang">
      <meta itemprop="description" content="小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hac_lang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-12-25 16:06:40" itemprop="dateCreated datePublished" datetime="2016-12-25T16:06:40+08:00">2016-12-25</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="主要符号表"><a href="#主要符号表" class="headerlink" title="主要符号表"></a>主要符号表</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$x$</td>
<td style="text-align:center">标量</td>
</tr>
<tr>
<td style="text-align:center">$\boldsymbol x$</td>
<td style="text-align:center">向量</td>
</tr>
<tr>
<td style="text-align:center">x</td>
<td style="text-align:center">变量集</td>
</tr>
<tr>
<td style="text-align:center">$A$</td>
<td style="text-align:center">矩阵</td>
</tr>
<tr>
<td style="text-align:center">$I$</td>
<td style="text-align:center">单位阵</td>
</tr>
<tr>
<td style="text-align:center">$\chi$</td>
<td style="text-align:center">样本空间或状态空间</td>
</tr>
<tr>
<td style="text-align:center">$D$</td>
<td style="text-align:center">概率分布</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">数据样本（数据集）</td>
</tr>
<tr>
<td style="text-align:center">$H$</td>
<td style="text-align:center">假设空间</td>
</tr>
<tr>
<td style="text-align:center">H</td>
<td style="text-align:center">假设集</td>
</tr>
<tr>
<td style="text-align:center">$\xi$</td>
<td style="text-align:center">学习算法</td>
</tr>
<tr>
<td style="text-align:center">$(·,·,·)$</td>
<td style="text-align:center">行向量</td>
</tr>
<tr>
<td style="text-align:center">$(·;·;·)$</td>
<td style="text-align:center">列向量</td>
</tr>
<tr>
<td style="text-align:center">$(·)^T$</td>
<td style="text-align:center">向量或矩阵的转置</td>
</tr>
<tr>
<td style="text-align:center">$\{···\}$</td>
<td style="text-align:center">集合</td>
</tr>
<tr>
<td style="text-align:center">$P(·),P(·&#124;·)$</td>
<td style="text-align:center">概率质量函数，条件概率质量函数</td>
</tr>
<tr>
<td style="text-align:center">$p(·),p(·&#124;·)$</td>
<td style="text-align:center">概率密度函数，条件概率密度函数</td>
</tr>
<tr>
<td style="text-align:center">$\mathbb{E}_{·\sim D}[f(·)]$</td>
<td style="text-align:center">函数f(⋅)对·在分布D下的数学期望;意义明确时将省略D和(或).</td>
</tr>
<tr>
<td style="text-align:center">sup(⋅)</td>
<td style="text-align:center">上确界</td>
</tr>
<tr>
<td style="text-align:center">Ⅱ(⋅)</td>
<td style="text-align:center">指示函数，在⋅为真和假时分别取值为1,0</td>
</tr>
<tr>
<td style="text-align:center">sign(⋅)</td>
<td style="text-align:center">符号函数，在⋅<0, =0,>0时分别取值为-1,0,1</0,></td>
</tr>
</tbody>
</table>
</div>
<h1 id="第1章"><a href="#第1章" class="headerlink" title="第1章"></a>第1章</h1><h2 id><a href="#" class="headerlink" title></a><br></h2><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>傍晚小街路面上沁出微雨后的湿润，和照的细风吹来，抬头看看天边的晚霞，嗯，明天又是一个好天气。走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学期狠下了工夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一定差不了！</p>
<p>希望各位在学期结束时有这样的感觉。作为开场，我们先大致了解一下什么是“机器学习”(machine learning)。</p>
<p>回头看第一段话，我们会发现这里涉及很多基于经验做出的预判例如，为什么看到微湿路面、感到和风、看到晚霞就认为明天是好天呢？这是因为在我们的生活经验中已经遇见过很多类似情况，头一天观察到上述特征后，第二天天气通常会很好。为什么色泽青绿、根蒂蜷缩、敲声浊响，就能判断出是正熟的好瓜？因为我们吃过、看过很多西瓜，所以基于色泽、根蒂、敲声这几个特征我们就可以做出相当好的判断。类似的，我们从以往的学习经验知道，下足了工夫、弄清了概念、做好了作业，自然会取得好成绩。可以看出，我们能做出有效的预判，是因为我们已经积累了许多经验，而通过对经验的利用，就能对新情况做出有效的决策。</p>
<p>上面对经验的利用是靠我们人类自身完成的计算机能帮忙吗？</p>
<p>机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”(model)的算法，即“学习算法”(learning a lgorithm)。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时(例如看到一个没剖开的西瓜，模型会给我们提供相应的判断(例如好瓜)。如果说计算机科学是研究关于“算法”的学问，那么类似的，可以说机器学习是研究关于“学习算法”的学问。</p>
<p>本书用“模型”泛指从数据中学得的结果。有文献用“模型”指全局性结果(例如一棵决策树)，而用“模式”指局部性结果(例如一条规则)。</p>
<h2 id="-1"><a href="#-1" class="headerlink" title></a><br></h2><h2 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h2><p>要进行机器学习，先要有数据.假定我们收集了一批关于西瓜的数据，例如(色泽=青绿；根蒂==赌缩；敲声=池响)，(色泽=乌黑；根蒂=稍滕；敲声=沉闷)，(色泽=浅白； 根蒂=硬挺；敲声=清脆)，.……，每对括号内是一条记录，“=”意思是“取值为” 。</p>
<p>这组记录的集合称为一个“数据集”(data set)，其中每条记录是关于一个事件或对象(这里是一个西瓜的描述，称为一个“示例”(instance)或“样本”(sample).反映事件或对象在某方面的表现或性质的事项，例如“色泽”“根蒂”“敲声”，称为“属性”(attribute或“特征”(feature)；属性上的取值，例如“青绿”、“乌黑”称为“属性值”(attribute value).属性张成的空间称为“属性空间”(attribute space)、“样本空间”(sample space)或“输入空间”例如我们把“色泽”“根蒂”“敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自已的坐标位置。由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个“特征向量”(feature vector)。</p>
<p>《《有时整个数据集亦称一个“样本”因为它可看作对样本空间的一个采样，通过上下文可判断出“样本”是指羊个示例还是数据集》》</p>
<p>一般地，令））表示包含m个示例的数据集，每个示例由d个属性描述(例如上面的西瓜数据使用了3个属性，则每个示例））是d 维样本空间X 中的一个向量）），其中Xij 是Xi 在第3个属性上的取值(例如上述第3个西瓜在第2个属性上的值是“硬挺”，d 称为样本x的“维数”(dimensionality)。</p>
<p>从数据中学得模型的过程称为“学习”(learning)或“训练”(training),这个过程通过执行某个学习算法来完成。训练过程中使用的数据称为“训练数据”(training data)，其中每个样本称为一个“训练样本”(training sample),训练样本组成的集合称为“训练集”(training set).学得模型对应了关于数据的某种潜在的规律，因此亦称“假设”(hypothesis)；这种潜在规律自身，则称为“真相”或“真实”(ground-truth)，学习过程就是为了找出或逼近真相。本书有时将模型称为“学习器”(learner)，可看作学习算法在给定数据和参数空间上的实例化。</p>
<p>《《训练样本亦称“训练示例”(training instance或“训练例”》》</p>
<p>《《学习算法通常有参数需设置，使用不同的参数值和(或)训练数据，将产生不同的结果》》</p>
<p>如果希望学得一个能帮助我们判断没剖开的是不是“好瓜”的模型，仅有前面的示例数据显然是不够的要建立这样的关于“预测”(prediction)的模型，我们需获得训练样本的“结果”信息，例如“((色泽=青绿，根蒂=蜷缩；敲声=浊响)，好瓜)”。这里关于示例结果的信息’例如“好瓜”，称为“标记”(label)；拥有了标记信息的示例，则称为“样例”(example).一般地，用(Xi,Yi)表示第i个样例，其中））是示例x的标记，Y是所有标记的集合，亦称“标记空间” (label space)或“输出空间”。</p>
<p>《《将“label”译为“标记”而非“标签”是考虑到英文中“label”既可用作名词、也可用作动词》》</p>
<p>《《若将标记看作对象本身的一部分，则“样例”有一时也称为“样本”》》</p>
<p>若我们欲预测的是离散值，例如“好瓜” “坏瓜”此类学习任务称为“分类”(classification)；若欲预测的是连续值，例如西瓜成熟度0.95 、0.37,此类学习任务称为“回归”(regression).对只涉及两个类别的“ 二分类”(binary classification)任务，通常称其中一个类为“正类”(positive class),另一个类为“反类”(negative class)；涉及多个类别时，则称为“ 多分类”(multi-class classification任务。一般地，预测任务是希望通过对训练集）） 进行学习，建立一个从输入空间X到输出空间y 的映射f: x ←→ Y，对二分类任务，通常令））或））；对多分类任务，））；对回归任务）） 为实数集。</p>
<p>学得模型后，使用其进行预测的过程称为“测试”(testing)，被预测的样本称为“测试样本”(testing sample).例如在学得f 后，对测试例x，可得到其预测标记y=f(x)。</p>
<p>我们还可以对西瓜做“聚类”(clustering，即将训练集中的西瓜分成若干组，每组称为一个“簇”(cluster);这些自动形成的簇可能对应一些潜在的概念划分，例如“浅色瓜” “深色瓜”，甚至“本地瓜” “外地瓜”。这样的学习过程有助于我们了解数据内在的规律’能为更深入地分析数据建立基础需说明的是，在聚类学习中，“浅色瓜”“本地瓜”这样的概念我们事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。</p>
<p>根据训练数据是否拥有标记信息，学习任务可大致划分为两大类： “监督学习”，(supervised learning)和“无监督学习”(unsupervised learning)，分类和回归是前者的代表，而聚类则是后者的代表。</p>
<p>需注意的是，机器学习的目标是使学得的模型能很好地适用于“新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为“泛化”(generalization)能力。具有强泛化能力的模型能很好地适用于整个样本空间。于是，尽管训练集通常只是样本空间的一个很小的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作得很好。通常假设样本空间中全体样本服从一个未知“分布”(distribution)，我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”(independent and identically distributed)，简称i.i.d.)，－般而言，训练样本越多，我们得到的关于D的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。</p>
<h2 id="-2"><a href="#-2" class="headerlink" title></a><br></h2><h2 id="假设空间"><a href="#假设空间" class="headerlink" title="假设空间"></a>假设空间</h2><p>归纳(induction)与演绎(deduction)是科学推理的两大基本手段。前者是从特殊到一般的“泛化”(generalization)过程，即从具体的事实归结出一般性规律；后者则是从一般到特殊的“特化”(specialization过程，即从基础原理推演出具体状况。例如，在数学公理系统中，基于一组公理和推理规则推导出与之相洽的定理，这是演绎；而“从样例中学习”显然是一个归纳的过程，因此亦称“归纳学习”(inductive learning)。</p>
<p>归纳学习有狭义与广义之分，广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习则要求从训练数据中学得概念(concept)，因此亦称为“概念学习”或“概念形成”。概念学习技术目前研究、应用都比较少，因为要学得泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生“黑箱”模型。然而，对概念学习有所了解，有助于理解机器学习的一些基础思想。</p>
<p>概念学习中最基本的是布尔概念学习，即对“是”“不是”这样的可表示为0/1布尔值的目标概念的学习。举一个简单的例子，假定我们获得了这样一个训练数据集：</p>
<p>这里要学习的目标是“好瓜”。暂且假设“好瓜”可由“色泽”“根蒂”“敲声”这三个因素完全确定，换言之，只要某个瓜的这三个属性取值明确了，我们就能判断出它是不是好瓜。于是，我们学得的将是“好瓜是某种色泽、某种根蒂、某种敲声的瓜”这样的概念，用布尔表达式写出来则是“好瓜件(色泽=？〈(根蒂=？〈(敲声=？”，这里“？”表示尚未确定的取值，而我们的任务就是通过对表1.1的训练集进行学习，把“？”确定下来。</p>
<p>《《灵一般的情况是考虑形如））的析合范式》》</p>
<p>读者可能马上发现，表1.1第一行：<br>“(色泽=青绿)∧(根蒂=蜷缩)∧(敲声=浊响)”<br>不就是好瓜吗？是的，但这是一个已见过的瓜，别忘了我们学习的目的是“泛化”，即通过对训练集中瓜的学习以获得对没见过的瓜进行判断的能力如果仅仅把训练集中的瓜“记住”今后再见到一模一样的瓜当然可判断，但是，对没见过的瓜，例如<br>“(色泽=浅白)∧(根蒂=蜷缩)∧(敲声=浊响)”<br>怎么办呢？</p>
<p>“记住”训练样本，就是所谓的“机械学习”［C。hen and Feigenbaum ,1983］，或称“死记硬背式学习”，参几1.5节</p>
<p>我们可以把学习过程看作一个在所有假设(hypothesis)组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”(fit)的假设，即能够将训练集中的瓜判断正确的假设。假设的表示一旦确定，假设空间及其规模大小就确定了这里我们的假设空间由形如“(色泽=？〈(根蒂=？八(敲声=？”的可能取值所形成的假设组成。例如色泽有“青绿”“乌黑”“浅白”这三种可能取值；还需考虑到，也许“色泽”无论取什么值都合适，我们用通配符“＊”来表示，例如“好瓜件(色泽=＊〈(根蒂=蜷缩八(敲声=浊响”，即“好瓜是根蒂蜷缩、敲声浊响的瓜，什么色泽都行”。此外，还需考虑极端情况·有可能“好瓜”这个概念根本就不成立，世界上没有“好瓜”这种东西；我们用∅表示这个假设。这样，若“色泽”“根蒂”“敲声”分别有3 、3 、3 种可能取值，则我们面临的假设空间规模大小为4×4×4+1=65.图1.1 直观地显示出了这个西瓜问题假设空间。</p>
<p>这里我们假定训练样本不含噪声，并且不考忘“非青绿” 这样的 ┐A 操作由于训练集包含正例，因此∅假设自然不出现》》</p>
<p>可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假设、和(或)与反例一致的假设。最终将会获得与训练集一致(即对所有训练样本能够进行正确判断)的假设，这就是我们学得的结果。</p>
<p>有许多可能的选择，如在路径上自顶向下与自底向上同时进行，在操作上只删除与正例不一致的假设等》》</p>
<p>需注意的是，现实问题中我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”我们称之为“版本空间”(version space).例如，在西瓜问题中，与表1.1训练集所对应的版本空间如图1.2 所示。</p>
<h2 id="-3"><a href="#-3" class="headerlink" title></a><br></h2><h2 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h2><p>通过学习得到的模型对应了假设空间中的一个假设。于是，图1.2 的西瓜版本空间给我们带来一个麻烦。现在有三个与训练集一致的假设？但与它们对应的模型在面临新样本的时候，却会产生不同的输出例如，对(色泽=青绿；根蒂=蜷缩；敲声=沉闷这个新收来的瓜，如果我们采用的是“好瓜↔(色泽=<em>)∧(根蒂=蜷缩)∧(敲声=</em>)”，那么将会把新瓜判断为好瓜，而如果采用了另外两个假设，则判断的结果将不是好瓜。那么，应该采用哪一个模型(或)假设呢？</p>
<p>若仅有表1.1中的训练样本，则无法断定上述三个假设中哪一个“更好”，然而，对于一个具体的学习算法而言，它必须要产生一个模型。这时，学习算法本身的“偏好”就会起到关键的作用。例如，若我们的算法喜欢“尽可能特殊”的模型，则它会选择“好瓜↔(色泽=＊)∧(根蒂=蜷缩)∧(敲声=浊响)”；但若我们的算法喜欢“尽可能一般”的模型，并且由于某种原因它更“相信”根蒂，则它会选择“好瓜↔(色泽=<em>)∧(根蒂=蜷缩)∧(敲声=</em>)”。机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”(inductive bias), 或简称为“偏好”。</p>
<p>《《对“根蒂”还是对“敲声”更重视看起来和属性选择。亦称“特征选择”(feature selection)有关，但需注意的是，机器学习中的特征选择仍是基于对训练样本的分析进行的，而在此处我们并非基于特征选择做出对“根蒂”的重视，这里对“根蒂”的信赖可视为基于某种领域知识而产生的归纳偏好关于特征选择方面的内容参见第11章》》</p>
<p>任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。可以想象，如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时随机抽选训练集上的等效假设，那么对这个新瓜“(色泽=青绿；根蒂=蜷缩；敲声=沉闷”，学得模型时而告诉我们它是好的、时而告诉我们它是不好的，这样的学习结果显然没有意义。</p>
<p>归纳偏好的作用在图1.3这个回归学习图示中可能更直观。这里的每个训练样本是图中的一个点(x,y)，要学得一个与训练集一致的模型，相当于找到一条穿过所有训练样本点的曲线。显然，对有限个样本点组成的训练集，存在着很多条曲线与其一致。我们的学习算法必须有某种偏好，才能产出它认为“正确”的模型。例如？若认为相似的样本应有相似的输出(例如，在各种属性上都很相像的西瓜，成熟程度应该比较接近，则对应的学习算法可能偏好图1.3 中比较“平滑”的曲线A 而不是比较“崎岖”的曲线B。</p>
<p>归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”。那么有没有一般性的原则来引导算法确立“正确的”偏好呢？“奥卡姆剃刀”(Occam ’s razor) 是一种常用的、自然科学研究中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个”。如果采用这个原则，并且假设我们认为“更平滑”意味着“更简单”(例如曲线A 更易于描述，其方程式是）），而曲线B 则要复杂得多，则在图1.3中我们会自然地偏好“平滑”的曲线A。</p>
<p>然而，奥卡姆剃刀并非唯一可行的原则。退一步说，即便假定我们是奥卡姆剃刀的铁杆拥趸，也需注意到，奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃刀原则并不平凡例如对我们已经很熟悉的西瓜问题来说，<br>假设1 ：“好瓜↔(色泽=＊)∧(根蒂=蜷缩)∧(敲声=浊响)”<br>和<br>假设2 ：“好瓜↔(色泽=＊)∧(根蒂=蜷缩)∧(敲声=＊)”<br>这两个假设，｜哪一个更“简单”呢？这个问题并不简单，需借助其他机制才能解决。</p>
<p>事实上，归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。</p>
<p>让我们再回头看看图1.3.假设学习算法ξa基于某种归纳偏好产生了对应于曲线A的模型，学习算法ξa基于另一种归纳偏好产生了对应于曲线B 的模型。基于前面讨论的平滑曲线的某种“描述简单性法ξα 比ξb 更好。确实，图l.4(a)显示出，与B相比，A与训练集外的样本更一致；换言之，A 的泛化能力比B 强。</p>
<p>但是，且慢！虽然我们希望并相信ξα 比ξb 更好，但会不会出现图l.4(b)的情况。与A 相比，B 与训练集外的样本更一致，</p>
<p>很遗憾，这种情况完全可能出现。换言之，对于一个学习算法ξα，若它在某些问题上比学习算法ξb，则必然存在另一些问题，在那里ξb比ξα好。有趣的是，这个结论对任何算法均成立，哪怕是把本书后面将要介绍的一些聪明算法作为ξα而将“随机胡猜”这样的笨拙算法作为ξb。惊讶吗？让我们看看下面这个简短的讨论。</p>
<p>为简单起见，假设样本空间X 和假设空间切都是离散的，令））代表算法ξα基于训练数据X 产生假设H 的概率，再令f 代表我们希望学习的<br>真实目标函数ξα 的“ 训练集外误差”，即ξα 在训练集之外的所有样本上的误差为</p>
<p>这里只用到一些非常基础的数学知识，只准备读第1章且有“数学恐惧”的读者可以跳过这个部分而不会影响理解，只需相信，上面这个看起来“匪夷所思”的结论确实是成立的，</p>
<p>其中））是指示函数，若·为真则取值1，否则取值0。</p>
<p>考虑二分类问题，且真实目标函数可以是任何函数）），函数空间为））,对所有可能的f 按均匀分布对误差求和，有</p>
<p>若f 均匀分布，则有一半的f 对x 的预测与h(x)不一致</p>
<p>式(1.2)显示出，总误差竟然与学习算法无关！对于任意两个学习算法ξa和ξb ，我们都有</p>
<p>也就是说，无论学习算法ξα 多聪明、学习算法ξa多笨拙，它们的期望性能竟然相同！这就是“没有免费的午餐”定理(No Free Lunch Theorem)，简称NFL定理 ［Wolpert, 1996; Wolpert and Macready, 1995］。</p>
<p>《《严格的NFL 定理证明比这里的简化论述繁难得多》》</p>
<p>这下子，读者对机器学习的热情可能被一盆冷水浇透了：既然所有学习算法的期望性能都跟随机胡猜差不多，那还有什么好学的？</p>
<p>我们需注意到，NFL定理有一个重要前提。所有“问题”出现的机会相同、或所有问题同等重要。但实际情形并不是这样。很多时候，我们只关注自已正在试图解决的问题(例如某个具体应用任务，希望为它找到一个解决方案，至于这个解决方案在别的问题、甚至在相似的问题上是否为好方案，我们并不关心。例如，为了快速从A地到达B地，如果我们正在考虑的A地是南京鼓楼、B地是南京新街口，那么“骑自行车”是很好的解决方案；这个方案对A地是南京鼓楼、B地是北京新街口的情形显然很糟糕，但我们对此并不关心。</p>
<p>事实上，上面 NFL定理的简短论述过程中假设了f 的均匀分布，而实际情形并非如此。例如，回到我们熟悉的西瓜问题，考虑{假设1: 好瓜↔(色泽=＊)∧(根蒂=蜷缩)∧(敲声=浊响)} 和 {假设2 好瓜↔(色泽=＊)∧(根蒂=硬挺)∧(敲声=清脆)} 。从 NFL定理可知，这两个假设同样好。我们立即会想到符合条件的例子，对好瓜(色泽=青绿；根蒂=蜷缩；敲声=浊响)是假设1更好，而对好瓜(色泽=乌黑；根蒂=硬挺，敲声=清脆)则是假设2更好。看上去的确是这样。然而需注意到，“(根蒂=蜷缩，敲声=浊响”的好瓜很常见，而“(根蒂=硬挺；敲声=清脆)”的好瓜罕见，甚至不存在。</p>
<p>所以，NFL定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论“什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好。要谈论算法的相对优劣，必须要针对具体的学习问题；在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。</p>
<h2 id="-4"><a href="#-4" class="headerlink" title></a><br></h2><h2 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a>发展历程</h2><p>机器学习是人工智能(artificial intelligence)研究发展到一定阶段的必然产物。二十世纪五十年代到七十年代初，人工智能研究处于“推理期”，那时人们以为只要能赋予机器逻辑推理能力，机器就能具有智能。这一阶段的代表性工作主要有A.Newell 和H.Simon 的“逻辑理论家”(Logic Theorist程序以及此后的“通用问题求解”(General Problem Solving程序等，这些工作在当时取得了令人振奋的结果。例如，“逻辑理论家”程序在1952年证明了著名数学家罗素和怀特海的名著《数学原理》中的38 条定理，在1963年证明了全部52条定理，特别值得一提的是，定理2.85 甚至比罗素和怀特海证明得更巧妙.A。Newell 和H.Simon 因为这方面的工作获得了1975年图灵奖。然而，随着研究向前发展，人们逐渐认识到，仅具有逻辑推理能力是远远实现不了人工智能的E.A.Feigenbaum 等人认为，要使机器具有智能？就必须设法使机器拥有知识。在他们的倡导下，从二十世纪七十年代中期开始，人工智能研究进入了“知识期”。在这一时期，大量专家系统问世，在很多应用领域取得了大量成果.E.A。Feigenbaum 作为“知识工程”之父在1994年获得图灵奖。但是，人们逐渐认识到，专家系统面临“知识工程瓶颈”，简单地说，就是由人来把知识总结出来再教给计算机是相当困难的于是，一些学者想到，如果机器自已能够学习知识该多好！</p>
<p>事实上，图灵在1950年关于图灵测试的文章中，就曾提到了机器学习的可能； 二十世纪五十年代初已有机器学习的相关研究，例如A.Samuel 著名的跳棋程序五十年代中后期，基于神经网络的“连接主义”(connectionism)学习开始出现，代表性工作有F.Rosenblatt 的感知机(Perceptron)、B.Widrow 的Adaline 等。在六七十年代，基于逻辑表示的“符号主义”(symbolism)学习技术蓬勃发展，代表性工作有P.Winston的“结构学习系统”、R.S.Michalski 等人的“基于逻辑的归纳学习系统”、E.B.Hunt 等人的“概念学习系统”等；以决策理论为基础的学习技术以及强化学习技术等也得到发展，代表性工作有N.J.Nilson 的“学习机器”，等。二十多年后红极一时的统计学习理论的一些奠基性结果也是在这个时期取得的。</p>
<p>1980年夏，在美国卡耐基梅隆大学举行了第一届机器学习研讨会(IWML);同年，《策略分析与信息系统》连出三期机器学习专辑； 1983年，Tioga出版社出版了R S.Michalski 、J.G.Carbonell 和T.Mitchell 主编的《机器学习： 一种人工智能途径》［Michalski et al., 1983］，对当时的机器学习研究工作进行了总结； 1986年，第一本机器学习专业期刊 Machine Learning 创刊； 1989年，人工智能领域的权威期刊Artificial Intelligence出版机器学习专辑，刊发了当时一些比较活跃的研究工作，其内容后来出现在J.G.Carbonell 主编、MIT 出版社1990年的《机器学习：范型与方法》［Carbonell,1990］一书中总的来看，二十世纪八十年代是机器学习成为一个独立的学科领域、各种机器学习技术百花初绽的时期。</p>
<p>IWML后来发展为国际机器学习会议ICML。</p>
<p>R.S.Michalski 等人［Michaiski et al., 1983］把机器学习研究划分为“从样例中学习”“在问题求解和规划中学习”“通过观察和发现学习”“从指令中学习”等种类； E A.Feigenbaum 等人在著名的《人工智能手册》(第三卷［Cohen and Feigenbaum, 1983］中，则把机器学习划分为“机械学习” “示教学习” “类比学习”和“归纳学习”。机械学习亦称“死记硬背式学习”，即把外界输入的信息全部记录下来，在需要时原封不动地取出来使用，这实际上没有进行真正的学习，仅是在进行信息存储与检索；示教学习和类比学习类似于R.S.Michalski 等人所说的“从指令中学习”和“通过观察和发现学习”;归纳学习相当于“从样例中学习”即从训练样例中归纳出学习结果。二十世纪八十年代以来，被研究最多、应用最广的是“从样例中学习”(也就是广义的归纳学习，它涵盖了监督学习、无监督学习等，本书大部分内容均属此范畴。下面我们对这方面主流技术的演进做一个简单回顾。</p>
<p>在二十世纪八十年代，“从样例中学习”的一大主流是符号主义学习，其代表包括决策树(decision tree)和基于逻辑的学习。典型的决策树学习以信息论为基础，以信息嫡的最小化为目标，直接模拟了人类对概念进行判定的树形流程。基于逻辑的学习的著名代表是归纳逻辑程序设计(Inductive Logic Programming)，简称ILP，可看作机器学习与逻辑程序设计的交叉，它使用一阶逻辑(即谓词逻辑来进行知识表示，通过修改和扩充逻辑表达式(例如Prolog表达式来完成对数据的归纳符号主义学习占据主流地位与整个人工智能领域的发展历程是分不开的前面说过，人工智能在二十世纪五十到八十年代经历了“推理期”和“知识期”，在“推理期”人们基于符号知识表示、通过演绎推理技术取得了很大成就，而在“知识期”人们基于符号知识表示、通过获取和利用领域知识来建立专家系统取得了大量成果，因此，在“学习期”的开始，符号知识表示很自然地受到青睐。事实上，机器学习在二十世纪八十年代正是被视为“解决知识工程瓶颈问题的关键”而走上人工智能主舞台的，决策树学习技术由于简单易用，到今天仍是最常用的机器学习技术之一，ILP具有很强的知识表示能力，可以较容易地表达出复杂数据关系，而且领域知识通常可方便地通过逻辑表达式进行描述，因此，ILP不仅可利用领域知识辅助学习，还可通过学习对领域知识进行精化和增强；然而，成也萧何、败也萧何，由于表示能力太强，直接导致学习过程面临的假设空间太大、复杂度极高，因此，问题规模稍大就难以有效进行学习，九十年代中期后这方面的研究相对陷入低潮。</p>
<p>这时实际是ILP 的前身。</p>
<p>二十世纪九十年代中期之前“从样例中学习”的另一主流技术是基于神经网络的连接主义学习连接主义学习在二十世纪五十年代取得了大发展，但因为早期的很多人工智能研究者对符号表示有特别偏爱，例如图灵奖得主H.Simon 曾断言人工智能是研究“对智能行为的符号化建模”所以当时连接主义的研究未被纳入主流人工智能研究范畴。尤其是连接主义自身也遇到了很大的障碍，正如图灵奖得主M.Minsky 和S.Papert 在1969年指出，(当时的神经网络只能处理线性分类，甚至对“异或”这么简单的问题都处理不了.1983年，J.J.Hop field 利用神经网络求解“流动推销员问题”这个著名的NP 难题取得重大进展，使得连接主义重新受到人们关注.1986年，D.E.Rumelhart 等人重新发明了著名的BP算法，产生了深远影响。与符号主义学习能产生明确的概念表示不同，连接主义学习产生的是“黑箱”模型，因此从知识获取的角度来看，连接主义学习技术有明显弱点； 然而，由于有BP这样有效的算法，使得它可以在很多现实问题上发挥作用事实上，BP一直是被应用得最广泛的机器学习算法之一连接主义学习的最大局限是其“试错性”；简单地说，其学习过程涉及大量参数，而参数的设置缺乏理论指导，主要靠手工“调参”；夸张一点说，参数调节上失之毫厘，学习结果可能谬以千里。</p>
<p>二十世纪九十年代中期，“统计学习”(statistical learning)闪亮登场并迅速占据主流舞台，代表性技术是支持向量机(Support Vector Machine)，简称SVM以及更一般的“核方法”(kernel methods).这方面的研究早在二十世纪六七十年代就已开始，统计学习理论［Vapnik, 1998］在那个时期也已打下了基础，例如V.N.Vapnik 在1963年提出了“支持向量”概念，他和A.J.Chervonenkis 在1968年提出vc维，在1974年提出了结构风险最小化原则等。但直到九十年代中期统计学习才开始成为机器学习的主流，一方面是由于有效的支持向量机算法在九十年代初才被提出，其优越性能到九十年代中期在文本分类应用中才得以显现；另一方面，正是在连接主义学习技术的局限性凸显之后，人们才把目光转向了以统计学习理论为直接支撑的统计学习技术。事实上，统计学习与连接主义学习有密切的联系在支持向量机破普遍接受后，核技巧(kernel trick)被人们用到了机器学习的几乎每一个角落，核方法也逐渐成为机器学习的基本内容之一。</p>
<p>有趣的是，二十一世纪初，连接主义学习又卷土重来，掀起了以“深度学习”为名的热潮所谓深度学习，狭义地说就是“很多层”的神经网络。在若干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术取得了优越性能。以往机器学习技术在应用中要取得好性能，对使用者的要求较高；而深度学习技术涉及的模型复杂度非常高，以至于只要下工夫“调参”，把参数调节好，性能往往就好。因此，深度学习虽缺乏严格的理论基础，但它显著降低了机器学习应用者的门槛，为机器学习技术走向工程实践带来了便利。那么，它为什么此时才热起来呢？有两个基本原因：数据大了、计算能力强了深度学习模型拥有大量参数，若数据样本少，则很容易“过拟合”；如此复杂的模型、如此大的数据样本，若缺乏强力计算设备，根本无法求解。恰由于人类进入了“大数据时代”，数据储量与计算设备都有了大发展，才使得连接主义学习技术焕发又一春。有趣的是，神经网络在二十世纪八十年代中期走红，与当时Intel x86系列微处理器与内存条技术的广泛应用所造成的计算能力、数据访存效率比七十年代有显著提高不无关联。深度学习此时的状况，与彼时的神经网络何其相似。</p>
<p>需说明的是，机器学习现在已经发展成为一个相当大的学科领域，本节仅是管中窥豹，很多重要技术都没有谈及，耐心的读者在读完本书后会有更全面的了解。</p>
<h2 id="-5"><a href="#-5" class="headerlink" title></a><br></h2><h2 id="应用现状"><a href="#应用现状" class="headerlink" title="应用现状"></a>应用现状</h2><p>在过去二十年中，人类收集、存储、传输、处理数据的能力取得了飞速提升，人类社会的各个角落都积累了大量数据，亟需能有效地对数据进行分析利用的计算机算法，而机器学习恰顺应了大时代的这个迫切需求，因此该学科领域很自然地取得巨大发展、受到广泛关注。</p>
<p>今天，在计算机科学的诸多分支学科领域中，无论是多媒体、图形学，还是网络通信、软件工程，乃至体系结构、芯片设计，都能找到机器学习技术的身影，尤其是在计算机视觉、自然语言处理等“计算机应用技术”领域，机器学习已成为最重要的技术进步源泉之一。</p>
<p>机器学习还为许多交叉学科提供了重要的技术支撑例如：“生物信息学”试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药物的美好愿景让人们为之心潮澎湃。生物信息学研究涉及从“生命现象”到“规律发现”的整个过程，其间必然包括数据获取、数据管理、数据分析、仿真实验等环节，而“数据分析”恰是机器学习技术的舞台，各种机器学习技术已经在这个舞台上大放异彩。</p>
<p>事实上，随着科学研究的基本手段从传统的“理论＋实验”走向现在的“理论＋实验＋计算”，乃至出现“数据科学”这样的提法，机器学习的重要性日趋显著，因为“计算”的目的往往是数据分析，而数据科学的核心也恰是通过分析数据来获得价值。若要列出目前计算机科学技术中最活跃、最受瞩目的研究分支，那么机器学习必居其中.2001年，美国NASA-JPL 的科学家在Science 杂志上专门撰文［Mjolsness and DeCoste, 2001］指出，机器学习对科学研究的整个过程正起到越来越大的支撑作用，其进展对科技发展意义重大2003年，DARPA 启动PAL 计划，将机器学习的重要性上升到美国国家安全的高度来考虑。众所周知，美国最尖端科技的研究通常是由NASA 和DARPA 推进的，而这两大机构不约而同地强调机器学习的重要性，其意义不言而喻。</p>
<p>2006年，卡耐基梅隆大学宣告成立世界上第一个“机器学习系”，机器学习领域奠基人之一T.Mitchell 教授出任首任系主任.2012年3月，美国奥巴马政府启动“大数据研究与发展计划克利分校启动加强计划’强调要深入研究和整合大数据时代的三大关键技术：机器学习、云计算、众包(crowdsourci蚓显然，机器学习在大数据时代是必不可少的核心技术，道理很简单：收集、存储、传输、管理大数据的目的，是为了“利用”大数据，而如果没有机器学习技术分析数据，则“利用”无从谈起。</p>
<p>《《NASA-JPL 的全称是美国航空航天局喷气格进实’验室，著名的“勇气”号》》</p>
<p>《《DARPA 的全称是美国国防部先进研究计划局，互联网、全珠卫星定位系统等都源于DARPA 启动的研究项目》》</p>
<p>谈到对数据进行分析利用，很多人会想到“数据挖掘”(data mining)，这里简单探讨一下数据挖掘与机器学习的联系数据挖掘领域在二十世纪丸十年代形成，它受到很多学科领域的影响，其中数据库、机器学习、统计学无疑影响最大［Zhou,2003］.数据挖掘是从海量数据中发掘知识，这就必然涉及对“海量数据”的管理和分析。大体来说。数据库领域的研究为数据挖掘提供数据管理技术，而机器学习和统计学的研究为数据挖掘提供数据分析技术。由于统计学界的研究成果通常需要经由机器学习研究来形成有效的学习算法，之后再进入数据挖掘领域，因此从这个意义上说，统计学主要是通过机器学习对数据挖掘发挥影响，而机器学习领域和数据库领域则是数据挖掘的两大支撑。</p>
<p>《《“数据挖掘”这个词很早就在统计学界出现并略带贬义，这是由于传统统计学研究往往醉心于理论的优美而忽视实际效用但最近情况发生变化，越来越多的统计学家开始关注现实问题，进入机器学习和数据挖掘领域》》</p>
<p>今天，机器学习已经与普通人的生活密切相关例如在天气预报、能源勘探、环境监测等方面，有效地利用机器学习技术对卫星和传感器发回的数据进行分析，是提高预报和检测准确性的重要途径；在商业营销中，有效地利用机器学习技术对销售数据、客户信息进行分析，不仅可帮助商家优化库存降低成本，还有助于针对用户群设计特殊营销策略；……下面再举几例</p>
<p>众所周知，谷歌、百度等互联网搜索引擎已开始改变人类的生活方式，例如很多人已习惯于在出行前通过互联网搜索来了解目的地信息、寻找合适的酒店、餐馆等。美国《新闻周刊》曾对谷歌有一句话评论。“它使任何人离任何问题的答案间的距离变得只有点击一下鼠标这么远。” 显然，互联网搜索是通过分析网络上的数据来找到用户所需的信息，在这个过程中，用户查询是输入、搜索结果是输出，而要建立输入与输出之间的联系，内核必然需要机器学习技术。事实上，互联网搜索发展至今，机器学习技术的支撑厥功至伟。到了今天，搜索的对象、内容日趋复杂，机器学习技术的影响更为明显，例如在进行“图片搜索”时，无论谷歌还是百度都在使用最新潮的机器学习技术。谷歌、百度、脸书、雅虎等公司纷纷成立专攻机器学习技术的研究团队，甚至直接以机器学习技术命名的研究院，充分体现出机器学习技术的发展和应用，甚至在一定程度上影响了互联网产业的走向。</p>
<p>再举一例。车祸是人类最凶险的杀手之一，全世界每年有上百万人丧生车轮，仅我国每年就有约十万人死于车祸。由计算机来实现自动汽车驾驶是一个理想的方案，因为机器上路时可以确保不是新手驾驶、不会疲劳驾驶，更不会酒后驾驶，而且还有重要的军事用途。美国在二十世纪八十年代就开始进行这方面研究。这里最大的困难是无法在汽车厂里事先把汽车上路后所会遇到的所有情况都考虑到、设计出处理规则并加以编程实现而只能根据上路时遇到的情况即时处理。若把车载传感器接收到的信息作为输入，把方向、刹车、油门的控制行为作为输出，则这里的关键问题恰可抽象为一个机器学习任务.2004年3月2在美国DARPA组织的自动驾驶车比赛中，斯坦福大学机器学习专家S.Thrun的小组研制的参赛车用6小时53分钟成功走完了132英里赛程获得冠军。比赛路段是在内华达州西南部的山区和沙漠中，路况相当复杂，在这样的路段上行车即使对经验丰富的人类司机来说也是一个挑战S.Thrun 后来到谷歌领导自动驾驶车项目团队。值得一提的是，自动驾驶车在近几年取得了飞跃式发展，除谷歌外，通用、奥迪、大众、宝马等传统汽车公司均投入巨资进行研发，目前已开始有产品进入市场2011年6月，美国内华达州议会通过法案，成为美国第一个认可自动驾驶车的州，此后，夏威夷州和佛罗里达州也先后通过类似法案。自动驾驶汽车可望在不久的将来出现在普通人的生活中，而机器学习技术则起到了“ 司机”作用。</p>
<p>《《例如著名机器学习教科书［Mitchell, 1997］4.2节介绍了二十世纪九十年代早期利用神经网络学习来控制自动驾驶车的ALVINN系统》》</p>
<p>机器学习技术甚至已影响到人类社会政治生活.2012年美国大选期间，奥巴马磨下有一支机器学习团队，他们对各类选情数据进行分析，为奥巴马提示下一步竞选行动。例如他们使用机器学习技术分析社交网络数据，判断出在总统候选人第一次辩论之后哪些选民会倒戈，并根据分析的结果开发出个性化宣传策略，能为每位选民找出一个最有说服力的挽留理由；他们基于机器学习模型的分析结果提示奥巴马应去何处开展拉票活动，有些建议甚至让专业竞选顾问大吃一惊，而结果表明去这些地方大有收获。总统选举需要大量金钱，机器学习技术在这方面发挥了奇效。例如，机器学习模型分析出，某电影明星对某地区某年龄段的特定人群很有吸引力，而这个群体很愿意出高价与该明星及奥巴马共进晚餐……果然，这样一次筹资晚宴成功募集到1500万美元；最终，借助机器学习模型，奥巴马筹到了创纪录的10亿美元竞选经费机器学习技术不仅有助于竞选经费“开源”，还可帮助“节流”例如机器学习模型通过对不同群体选民进行分析，建议购买了一些冷门节目的广告时段，而没有采用在昂贵的黄金时段购买广告的传统做法，使得广告资金效率相比2008年竞选提高了14% ；… …胜选后，《时代》周刊专门报道了这个被奥巴马称为“竞选核武器”、由半监督学习研究专家R.Ghani 领导的团队</p>
<p>值得一提的是，机器学习备受瞩目当然是由于它已成为智能数据分析技术的创新源泉，但机器学习研究还有另一个不可忽视的意义，即通过建立一些关于学习的计算模型来促进我们理解“人类如何学习” 例如，P.Kanerva 在二十世纪八十年代中期提出SDM (Sparse Distributed Memory模型［Kanerva,1988］时并没有刻意模仿脑生理结构，但后来神经科学的研究发现，SDM 的稀疏编码机制在视觉、昕觉、嗅觉功能的脑皮层中广泛存在，从而为理解脑的某些功能提供了一定的启发。自然科学研究的驱动力归结起来无外是人类对宇宙本源、万物本质、生命本性、自我本识的好奇，而“人类如何学习”无疑是一个有关自我本识的重大问题从这个意义上说，机器学习不仅在信息科学中占有重要地位，还具有一定的自然科学探索色彩。</p>
<h2 id="阅读材料"><a href="#阅读材料" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>［Mitchell, 1997］是第一本机器学习专门性教材，［Duda et al., 2001; Al- paydin, 2004; Flach, 2012］都是出色的入门读物［Hastie et al., 2009］是很好的进阶读物，［Bishop, 2006］也很有参考价值，尤其适合于贝叶斯学习偏好者［Shalev-Shwartz and Ben-David, 2014］则适合于理论偏好者.［Witten et al.,2011］是基于WEKA 撰写的入门读物，有助于初学者通过WEKA 实践快速掌握常用机器学习算法。</p>
<p>《《WEKA 是著名的免费机器学习算法程序库，由新西兰Waikat。大学研究人员基于JAVA 开发：》》</p>
<p>本书1.5 和1.6 节主要取材于［周志华，2007］.《机器学习一种人工智能途径》［Michalski et al., 1983］ 汇集了20 位学者撰写的16 篇文章，是机器学习早期最重要的文献。该书出版后产生了很大反响，Morgan Kaufmann 出版社后来分别于1986年和1990年出版了该书的续篇，编为第二卷和第三卷。《人工智能手册》系列是图灵奖得主E.A.Feigenbaum 与不同学者合作编写而成，该书第三卷［Cohen and Feigenbaum, 1983］对机器学习进行了讨论，是机器学习早期的重要文献.［Dietterich, 1997］对机器学习领域的发展进行了评述和展望早期的很多文献在今天仍值得重视，一些闪光的思想在相关技术进步后可能焕发新的活力，例如近来流行的“迁移学习”(transfer learning) ［Pan and Yang,2010］，恰似“类比学习”(learning by analogy)在统计学习技术大发展后的升级版i 红极一时的“深度学习”(deep learning)在思想上并未显著超越二十世纪八十年代中后期神经网络学习的研究。</p>
<p>机器学习中关于概念学习的研究开始很早，从中产生的不少思想对整个领域都有深远影响。例如作为主流学习技术之一的决策树学习，就起源于关于概念形成的树结构研究［Hunt and Hoviand, 1963］. ［Winston, 1970］在著名的“积木世界”研究中，将概念学习与基于泛化和特化的搜索过程联系起来.［Simon and Lea, 1974］较早提出了“学习”是在假设空间中搜索的观点［Mitchell, 1977］稍后提出了版本空间的概念。概念学习中有很多关于规则学习的内容。</p>
<p>奥卡姆剃刀原则主张选择与经验观察一致的最简单假设，它在自然科学如物理学、天文学等领域中是一个广为沿用的基础性原则，例如哥自尼坚持“日心说”的理由之一就是它比托勒密的“地心说”更简单且符合天文观测。奥卡姆剃刀在机器学习领域也有很多追随者［Blumer et al., 1996］.但机器学习中什么是“更简单的”这个问题一直困扰着研究者们，因此，对奥卡姆剃刀在机器学习领域的作用一直存在着争议［Webb, 1996; Domingos, 1999］.需注意的是，奥卡姆剃刀并非科学研究中唯一可行的假设选择原则，例如古希腊哲学家伊壁坞鲁(公元前341年一前270年提出的“多释原则”(principle of multipleexplanations)，主张保留与经验观察一致的所有假设［Asmis, 1984］，这与集成学习(ensemble learning)方面的研究更加吻合。</p>
<p>机器学习领域最重要的国际学术会议是国际机器学习会议(ICML)、国际神经信息处理系统会议(NIPS)和国际学习理论会议(COLT)，重要的区域性会议主要有欧洲机器学习会议(ECML和亚洲机器学习会议(ACML)；，最重要的国际学术期刊是Journal of Machine Learning Research 和Machine Learning。人工智能领域的重要会议如IJCAI, AAAI 以及重要期刊如Artificial  Intelligence、Journal of Artificial Intelligence Research，数据挖掘领域的重要会议如KDD 、ICDM 以及重要期刊如ACM Transactions on Knowledge Discoveryfrom Data、Data Mining and Knowledge Discovery，计算机视觉与模式识别领域的重要会议如CVPR 以及重要期刊如IEEE Transactions on PatternAnalysis αηd Machine Intelligence)，神经网络领域的重要期刊如Neural Computαtioη、IEEE Trans αctions on Neural Networks αnd Learning Systems 等也经常发表机器学习方面的论文。此外，统计学领域的重要期刊如Annals ofStatistics 等也常有关于统计学习方面的理论文章发表。</p>
<p>国内不少书籍包含机器学习方面的内容，例如［陆汝铃，1996］.［李航，2012］是以统计学习为主题的读物。国内机器学习领域最主要的活动是两年一次的中国机器学习大会(CCML以及每年举行的“机器学习及其应用”研讨会(MLA)；很多学术刊物都经常刊登有关机器学习的论文。</p>
<h3 id="休息一会儿"><a href="#休息一会儿" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事： “机器学习”名字的由来</p>
<p>1952年，阿瑟·萨缪尔(Arthur Samuel, 1901-1990)在IBM公司研制了一个西洋跳棋程序，这个程序具有自学习能力，可通过对大量棋局的分析逐渐辨识出当前局面下的“好棋”和“坏棋”，从而不断提高弈棋水平，并很快就下赢了萨缪尔自已1956年，萨缪尔应约翰·麦卡锡(John McCarthy)，“人工智能之父”，1971年图灵奖得主之邀，在标志着人工智能学科诞生的达特茅斯会议上介绍这项工作萨缪尔发明了“机器学习”这个词，将其定义为“不显式编程地赋予计算机能力的研究领域” 。他的文章“ Some studies in machine learning using the game of checkers” 1959年在IBM Journal 正式发表后，爱德华·费根鲍姆(Edward Feigenbaurn,“知识工程之父”，1994年图灵奖得主为编写其巨著Computers and Thought，在1961年邀请萨缪尔提供一个该程序最好的对弈实例。于是，萨缪尔借机向康涅狄格州的跳棋冠军、当时全美排名第四的棋手发起了挑战，结果萨缪尔程序获胜，在当时引起轰动。</p>
<p>《《这个跳棋手呈序实质上使用了强化学习技术》》</p>
<p>事实上，萨缪尔跳棋程序不仅在人工智能领域产生了重大影响，还影响到整个计算机科学的发展。早期计算机科学研究认为，计算机不可能完成事先没有显式编程好的任务，而萨缪尔跳棋程序否证了这个假设。另外，这个程序是最早在计算机上执行非数值计算任务的程序之一其逻辑指令设计思想极大地影响了IBM 计算机的指令集，并很快被其他计算机的设计者采用。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第2章-模型评估与选择"><a href="#第2章-模型评估与选择" class="headerlink" title="第2章 模型评估与选择"></a>第2章 模型评估与选择</h1><h2 id="-6"><a href="#-6" class="headerlink" title></a><br></h2><h2 id="经验误差与过拟合"><a href="#经验误差与过拟合" class="headerlink" title="经验误差与过拟合"></a>经验误差与过拟合</h2><p>通常我们把分类错误的样本数占样本总数的比例称为“错误率”(error rate)，即如果在m个样本中有a个样本分类错误，则错误率E=a/m；相应的，1-a/m 称为“精度”(accuracy)，即“精度=1-错误率” 更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”(error),学习器在训练集上的误差称为“训练误差”(training error)或“经验误差”(empirical error)，在新样本上的误差称为“泛化误差”(generalization error).显然，我们希望得到泛化误差小的学习器。然而，我们事先并不知道新样本是什么样，实际能做的是努力使经验误差最小化。在很多情况下，我们可以学得一个经验误差很小、在训练集上表现很好的学习器，例如甚至对所有训练样本都分类正确，即分类错误率为零，分类精度为100%，但这是不是我们想要的学习器呢？遗憾的是，这样的学习器在多数情况下都不好。</p>
<p>《《精度常写为百分比形式》》</p>
<p>《《这里所说的“误差”均指误差期望》》</p>
<p>《《在后面的章节中将介绍不同的学习算法如何最小化经验误差》》</p>
<p>我们实际希望的1 是在新样本上能表现得很好的学习器。为了达到这个目的’应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为“过拟合”(overfitting).与“过拟合”相对的是“欠拟合”(underfitting)，这是指对训练样本的一般性质尚未学好。图2.1 给出了关于过拟合与欠拟合的一个便于直观理解的类比。</p>
<p>《《过拟合亦称“过自已”欠拟合亦称“欠配”》》</p>
<p>有多种因素可能导致过拟合，其中最常见的情况是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由于学习能力低下而造成的欠拟合比较容易克服，例如在决策树学习中扩展分支、在神经网络学习中增加训练轮数等，而过拟合则很麻烦。在后面的学习中我们将看到，过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施，然而必须认识到，过拟合是无法彻底避免的，我们所能做的只是“缓解”或者说减小其风险关于这一点，可大致这样理解：机器学习面临的问题通常是NP难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了“P=NP”，因此，只要相信“P=NP”，过拟合就不可避免。</p>
<p>《《学习能力是否“过于强大”，是由学习算法和数据内涵共同决定的》》</p>
<p>在现实任务中，我们往往有多种学习算法可供选择，甚至对同一个学习算法，当使用不同的参数配置时，也会产生不同的模型。那么，我们该选用哪一个学习算法、使用哪一种参数配置呢？这就是机器学习中的“模型选择” (model selection）问题。理想的解决方案当然是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。然而如上面所讨论的，我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，那么，在现实中如何进行模型评估与选择呢？</p>
<h2 id="-7"><a href="#-7" class="headerlink" title></a><br></h2><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><p>通常，我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选择。为此，需使用一个“测试集”(testing set来测试学习器对新样本的判别能力，然后以测试集上的“测试误差” (testing error)作为泛化误差的近似通常我们假设测试样本也是从样本真实分布中独立同分布采样而得。但需注意的是，测试集应该尽可能与训练集互斥，即测试样本尽量不在训练集中出现、未在训练过程中使用过。</p>
<p>《《在现实任务中往往还会考虑时间开稍、存储开销、可解释性等方面的因素。这里暂且只考虑泛化误差》》</p>
<p>测试样本为什么要尽可能不出现在训练集中呢？为理解这一点，不妨考虑这样一个场景： 老师出了10道习题供同学们练习，考试时老师又用同样的这10道题作为试题，这个考试成绩能否有效反映出同学们学得好不好呢？答案是否定的，可能有的同学只会做这10道题却能得高分。回到我们的问题上来，我们希望得到泛化性能强的模型，好比是希望同学们对课程学得很好、获得了对所学知识“举一反三”的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试显然，若测试样本被用作训练了，则得到的将是过于“乐观”的估计结果</p>
<p>可是，我们只有一个包含m个样例的数据集）），既要训练，又要测试，怎样才能做到呢？答案是：通过对D进行适当的处理，从中产生出训练集S 和测试集T.下面介绍几种常见的做法。</p>
<h3 id="留出法"><a href="#留出法" class="headerlink" title="留出法"></a>留出法</h3><p>“留出法”(hold-out)直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即D=S∪T，S∩T=∅在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。</p>
<p>以二分类任务为例，假定D包含1000个样本，将其划分为S包含700个样本，T包含300个样本，用S进行训练后，如果模型在T 上有90个样本分类错误，那么其错误率为(90/300)×100%=30%，相应的，精度为1-30%=70%。</p>
<p>需注意的是，训练／测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中至少要保持样本的类别比例相似。如果从采样(sampling)的角度来看待数据集的划分过程，则保留类别比例的采样方式通常称为“分层采样”(stratifiedsampling).例如通过对D 进行分层采样而获得含70% 样本的训练集S 和含30% 样本的测试集T，若D 包含500个正例、500个反例，则分层采样得到的S 应包含350个正例、350个反例，而T 则包含150个正例和150个反例；若S、T中样本类别比例差别很大，则误差估计将由于训练／测试数据分布的差异而产生偏差。</p>
<p>另一个需注意的问题是，即便在给定训练／测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割。例如在上面的例子中，可以把D中的样本排序，然后把前350个正例放到训练集中，也可以把最后350个正例放到训练集中，……这些不同的划分将导致不同的训练／测试集，相应的，模型评估的结果也会有差别。因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。例如进行100次随机划分，每次产生一个训练／测试集用于实验评估，100次后就得到100个结果，而留出法返回的则是这100个结果的平均。</p>
<p>《《同时可得估计结采的标准差》》</p>
<p>此外，我们希望评估的是用D 训练出的模型的性能，但留出法需划分训练／测试集，这就会导致一个窘境。若令训练、集S 包含绝大多数样本，则训练出的模型可能更接近于用D 训练出的模型，但由于T 比较小，评估结果可能不够稳定准确；若令测试集T 多包含一些样本，则训练集S 与D 差别更大了，被评估的模型与用D 训练出的模型相比可能有较大差别，从而降低了评估结果的保真性(fidelity).这个问题没有完美的解决方案，常见做法是将大约2/3 ～ 4/5 的样本用于训练，剩余样本用于测试。</p>
<p>《《可从“偏差－方差”(参见2.5 节的角度来理解测试集小时，评估结果的方差较大，训练集小时，评估结采的偏差较大》》</p>
<p>《《一般而言，测试集至少应含30个样》》</p>
<h3 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h3><p>“交叉验证法”(cross validation先将数据集D 划分为k个大小相似的互斥子集，即））.每个子集Di 都尽可能保持数据分布的一致性，即从D中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练／测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为强调这一点，通常把交叉验证法称为“k折交叉验证”(k-fold crossvalidation). k最常用的取值是10，此时称为10 折交叉验证，其他常用的k 值有5 、20等。图2.2给出了10折交叉验证的示意图。</p>
<p>亦称“ k 倍交叉验证”</p>
<p>图2.2 10 折交又验证示意图</p>
<p>与留出法相似，将数据集D划分为k个子集同样存在多种划分方式。为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，例如常见的有“10次10折交叉验证”。</p>
<p>《《“10次10折交叉验证”与“100次留出法”都是进行了100 次训练/测试》》</p>
<p>假定数据集D中包含m个样本，若令k=m，则得到了交叉验证法的一个特例。留一法(Leave-One-Out)，简称LOO).显然，留一法不受随机样本划分方式的影响，因为m个样本只有唯一的方式划分为m个子集—-每个子集包含一个样本；留一法使用的训练、集与初始数据集相比只少了一个样本，这就使得，在绝大多数情况下，留一法中被实际评估的模型与期望评估的用D训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。然而，留一法也有其缺陷在数据集比较大时，训练m个模型的计算开销可能是难以忍受的(例如数据集包含1百万个样本，则需训练l百万个模型，而这还是在未考虑算法调参的情况下。另外，留一法的估计结果也未必永远比其他评估方法准确，“没有免费的午餐”定理对实验评估方法同样适用。</p>
<h3 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h3><p>我们希望评估的是用D训练出的模型。但在国出法和交叉验证法中，由于保留了一部分样本用于测试因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差留一法受训练样本规模变化的影响较小，但计算复杂度又太高了有没有什么办法可以减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计呢？</p>
<p>《《关于样本复杂度与泛化性能之间的关系，参见12章》》</p>
<p>“自助法”(bootstrapping)是一个比较好的解决方案，它直接以自助采样法(bootstrap sampling)为基础［Efron and Tibshirani, 1993］.给定包含m个样本的数据集D，我们对它进行采样产生数据集D＇： 每次随机从D中挑选一个样本，将其拷贝放入D＇’然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行m次后，我们就得到了包含m个样本的数据集D＇，这就是自助采样的结果显然，D中有一部分样本会在D＇中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在m 次采样中始终不被来到的概率是）），取极限得到</p>
<p>e 是自然常数。</p>
<p>即通过自助采样，初始数据集D 中约有36.8，的样本未出现在采样数据集D’中于是我们可将D＇ 用作训练集，D  D ＇ 用作测试集； 这样，实际评估的模型与期望评估的模型都使用m个训练样本，而我们仍有数据总量约1/3 的、没在训练集中出现的样本用于测试这样的测试结果，亦称“包外估计”(out-of-bag estimate)。</p>
<p>《《Bootstrap本意是“解靴带”；这里是在使用德国18世纪文学作品《吹牛大王历险记》中解靴带自助的典故，因此本书译为“自助法” 自助采样亦称“可重复采样”或“有放回采样”。》》</p>
<p>《《“＼”表示集合减法。》》</p>
<p>自助法在数据集较小、难以有效划分训练／测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练、集这对集成学习等方法有很大的好处。然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。</p>
<h3 id="调参与最终模型"><a href="#调参与最终模型" class="headerlink" title="调参与最终模型"></a>调参与最终模型</h3><p>大多数学习算法都有些参数(parameter)需要设定，参数配置不同，学得模型的性能往往有显著差别。因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需对算法参数进行设定，这就是通常所说的“参数调节”或简称“调参”(parameter tuning)。</p>
<p>读者可能马上想到，调参和算法选择没什么本质区别：对每种参数配置都训练出模型，然后把对应最好模型的参数作为结果。这样的考虑基本是正确的，但有一点需注意：学习算法的很多参数是在实数范围内取值，因此，对每种参数配置都训练出模型来是不可行的现实中常用的做法，是对每个参数选定一个范围和变化步长，例如在［0,0.2］范围内以0.05 为步长，则实际要评估的候选参数值有5个，最终是从这5个候选值中产生选定值。显然，这样选定的参数值往往不是“最佳”值，但这是在计算开销和性能估计之间进行折中的结果，通过这个折中，学习过程才变得可行。事实上，即便在进行这样的折中后，调参往往仍很困难。可以简单估算一下：假定算法有3个参数，每个参数仅考虑5个候选值，这样对每一组训练／测试集就有5的3次方=125个模型需考察；很多强大的学习算法有不少参数需设定：这将导致极大的调参工程量，以至于在不少应用任务中，参数调得好不好往往对最终模型性能有关键性影响。</p>
<p>《《机器学习常涉及两类参数一类是算法的参数，亦称“超参数”，数目常在10以内；另一类是模型的参数，数目可能很多，例如大型“深度学习”模型甚至有上百亿个参数两者调参方式相似，均是产生多个模型之后基于某种评估方法来进行选择；不同之处在于前者通常是由人工设定多个参数候选值后产生模型，后者则是通过学习来产生多个候选模型(例如神经网络在不同轮数停止训练) 》》</p>
<p>给定包含m个样本的数据集D，在模型评估与选择过程中由于需要留出一部分数据进行评估测试，事实上我们只使用了一部分数据训练模型。因此，在模型选择完成后，学习算法和参数配置已选定，此时应该用数据集D重新训练模型。这个模型在训练过程中使用了所有m个样本，这才是我们最终提交给用户的模型。</p>
<p>另外，需注意的是，我们通常把学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验证集”(validation set).例如，在研究对比不同算法的泛化性能时，我们用测试集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参。</p>
<h2 id="-8"><a href="#-8" class="headerlink" title></a><br></h2><h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><p>对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量(performance measure)。性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果；这意味着模型的“好坏”是相对的，什么样的模型是好的，不仅取决于算法和数据，还决定于任务需求。</p>
<p>《《聚类的性能度量参见第9 章。》》</p>
<p>在预测任务中，给定样例集）），其中Yi是示例x的真实标记。要评估学习器f 的性能，就要把学习器预测结果f(x)与真实标记y 进行比较。</p>
<p>回归任务最常用的性能度量是“均方误差”(mean squared error)</p>
<p>更一般的，对于数据分布D 和概率密度函数p(⋅)，均方误差可描述为</p>
<p>本节下面主要介绍分类任务中常用的性能度量。</p>
<h3 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h3><p>本章开头提到了错误率和精度，这是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。对样例集D，分类错误率定义为</p>
<p>精度则定义为</p>
<p>更一般的，对于数据分布D和概率密度函数p(⋅)，错误率与精度可分别描述为</p>
<h3 id="查准率、查全率与F1"><a href="#查准率、查全率与F1" class="headerlink" title="查准率、查全率与F1"></a>查准率、查全率与F1</h3><p>错误率和精度虽常用，但并不能满足所有任务需求。以西瓜问题为例，假定瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡量了有多少比例的瓜被判别错误。但是若我们关心的是“挑出的西瓜中有多少比例是好瓜”，或者“所有好瓜中有多少比例被挑了出来”，那么错误率显然就不够用了，这时需要使用其他的性能度量。</p>
<p>类似的需求在信息检索、Web搜索等应用中经常出现，例如在信息检索中，我们经常会关心“检索出的信息中有多少比例是用户感兴趣的” “用户感兴趣的信息中有多少被检索出来了”，“查准率”(precision与“查全率”(recall是更为适用于此类需求的性能度量。</p>
<p>《《查准率亦称“准确率” 查全率亦称“召回率”》》</p>
<p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种情形，令TP 、FP 、TN 、FN分别表示其对应的样例数，则显然有TP+FP+TN+FN=样例总数。分类结果的“混淆矩阵”(confusion matrix)如表2.1所示。</p>
<p>查准率P 与查全率R 分别定义为</p>
<p>查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。例如，若希望将好瓜尽可能多地选出来，则可通过增加选瓜的数量来实现，如果将所有西瓜都选上，那么所有的好瓜也必然都被选上了，但这样查准率就会较低，若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较低。通常只有在一些简单任务中，才可能使查全率和查准率都很高。</p>
<p>在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率”查全率曲线，简称“P-R曲线”，显示该曲线的图称为“P-R图”．图2.3给出了一个示意图。</p>
<p>《《以信息检索应用为例，逐条向用户反馈其可能感兴趣的信息，即可计算出查全率、查准率》》</p>
<p>P-R图直观地显示出学习器在样本总体上的查全率、查准率。在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，例如图2.3中学习器A的性能优于学习器C；如果两个学习器的P-R曲线发生了交叉，例如图2.3中的A与B，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率、查全率的性能度量。</p>
<p>“平衡点”(Break-Even Point)，简称BEP就是这样一个度量，它是“查准率=查全率”时的取值，例如图2.3中学习器C的BEP是0.64，而基于BEP的比较，可认为学习器A优于B。</p>
<p>但BEP 还是过于简化了些，更常用的是Fl 度量：</p>
<p>《《Fl 是基于查准率与查全率的调和平均(harmonic mean)定义的</p>
<p>Fβ则是加权调和平均</p>
<p>与算术平均(P+R)和几何平均(PxR)相比，调和平均更重视较小值》》</p>
<p>在一些应用中，对查准率和查全率的重视程度有所不同。例如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要.Fl度量的一般形式——Fβ，能让我们表达出对查准率／查全率的不同偏好，它定义为</p>
<p>其中β＞0 度量了查全率对查准率的相对重要性，β=1时退化为标准的Fl ; β＞1时查全率有更大影响，β＜1时查准率有更大影响。</p>
<p>很多时候我们有多个二分类混淆矩阵，例如进行多次训练／测试，每次得到一个混淆矩阵; 或是在多个数据集上进行训练／测试，希望估计算法的“全局”性能；甚或是执行多分类任务，每两两类别的组合都对应一个混淆矩阵，……总之，我们希望在η个二分类混淆矩阵上综合考察查准率和查全率。</p>
<p>一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，记为）），再计算平均值，这样就得到“宏查准 率”(macro-P)、“宏查全率”(macro-R)，以及相应的“宏Fl” (macro-Fl):</p>
<p>还可先将各混淆矩阵的对应元素进行平均，得到TP 、FP 、TN 、FN 的平均值，分别记为TP、 FP、 TN、 FN，再基于这些平均值计算出“微查准 率”(micro-P)..“微查全率”(micro-R和“微Fl” (micro-Fl):</p>
<h3 id="ROC与AUC"><a href="#ROC与AUC" class="headerlink" title="ROC与AUC"></a>ROC与AUC</h3><p>很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与－个分类阈值(threshold进行比较，若大于阈值则分为正类，否则为反类。例如，神经网络在一般情形下是对每个测试样本预测出一个［0,0,1,0］之间的实值，然后将这个值与0.5进行比较，大于0.5则判为正例，否则为反例。这个实值或概率预测结果的好坏，直接决定了学习器的泛化能力。实际上，根据这个实值或概率预测结果，我们可将测试样本进行排序，“最可能”是正例的排在最前面，“最不可能”是正例的排在最后面这样分类过程就相当于在这个排序中以某个“截断点”(cut point)将样本分为两部分，前一部分判作正例，后一部分则判作反例。</p>
<p>在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若我们更重视“查准率”，则可选择排序中靠前的位置进行截断；若更重视“查全率”，则可选择靠后的位置进行截断。因此，排序本身的质量好坏。体现了综合考虑学习器在不同任务下的“期望泛化性能”的好坏，或者说，“一般情况下”泛化性能的好坏。ROC曲线则是从这个角度出发来研究学习器泛化性能的有力工具。</p>
<p>ROC全称是“受试者工作特征”(Receiver Operating Characteristic)曲线，它源于“二战”中用于敌机检测的雷达信号分析技术，二十世纪六七十年代开始被用于一些心理学、医学检测应用中，此后被引入机器学习领域［Spackman, 1989］。与2.3.2节中介绍的P-R曲线相似，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了“ROC曲线”.与P-R曲线使用查准率、查全率为纵、横轴不同，ROC曲线的纵轴是“真正例率”(True Positive Rate，简称TPR)，横轴是“假正例率”(False PositiveRate，简称FPR)，基于表2.1中的符号，两者分别定义为</p>
<p>显示ROC曲线的图称为“ROC图”。图2.4(a)给出了一个示意图，显然，<br>对角线对应于“随机猜测”模型，而点(0, 1)则对应于将所有正例排在所有反例之前的“理想模型”。</p>
<p>现实任务中通常是利用有限个测试样例来绘制ROC图，此时仅能获得有限个(真正例率，假正例率坐标对，无法产生图2.4(a)中的光滑ROC曲线，只能绘制出如图2.4(b)所示的近似ROC曲线。绘图过程很简单：给定m+个正例和m-个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为。，在坐标(0,0)处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为(x,y)，当前若为真正例，则对应标记点的坐标为））；当前若为假正例，则对应标记点的坐标为）），然后用线段连接相邻点即得。</p>
<p>进行学习器的比较时，与P-R图相似，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据是比较ROC曲线下的面积，即AUC (Area Under ROC Curve)，如图2.4所示。</p>
<p>从定义可知，AUC可通过对ROC曲线下各部分的面积求和而得。假定ROC曲线是由坐标为））的点按序连接而形成）），参见图2.4(b)，则AUC可估算为</p>
<p>形式化地看，AUC 考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定m+个正例和m-个反例，令 D+ 和 D- 分别表示正、反例集合，则排序“损失”(loss)定义为</p>
<p>即考虑每一对正、反例，若正例的预测值小于反例，则记一个“罚分”，若相等，则记0.5个“罚分”。容易看出，蓉rank对应的是RUG曲线之上的面积：若一个正例在RUG曲线上对应标记点的坐标为(x,y)，则二恰是排序在其之前的反例所占的比例，即假正例率。因此有</p>
<h3 id="代价敏感错误率与代价曲线"><a href="#代价敏感错误率与代价曲线" class="headerlink" title="代价敏感错误率与代价曲线"></a>代价敏感错误率与代价曲线</h3><p>在现实任务中常会遇到这样的情况：不同类型的错误所造成的后果不同。例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者，看起来都是犯了“一次错误”，但后者的影响是增加了进一步检查的麻烦，前者的后果却可能是丧失了拯救生命的最佳时机；再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故。为权衡不同类型错误所造成的不同损失，可为错误赋予“非 均等代价”(unequal cost)。</p>
<p>以二分类任务为例，我们可根据任务的领域知识设定一个“代价矩 阵”(cost matrix)，如表2.2所示，其中cost ij表示将第i类样本预测为第j类样本的代价。一般来说，cost=0;若将第0类判别为第1类所造成的损失更大，则。ost01＞cost10；损失程度相差越大，cost01与cost10值的差别越大。</p>
<p>一般情况下，重要的是代价比值而非绝对值例如cost01:cost10=5:1与50: 10所起效果相当</p>
<p>回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价，例如式(2.4所定义的错误率是直接计算“错误次数，并没有考虑不同错误会造成不同的后果。在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”(total cost).若将表2.2 中的第0 类作为正类、第1类作为反类，令 D+ 与 D- 分别代表样例集D的正例子集和反例子集，则“代价敏感”(cost-sensitive)错误率为</p>
<p>类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量如精度的代价敏感版本。若令costij 中的i、j 取值不限于0、1，则可定义出多分类任务的代价敏感性能度量。</p>
<p>在非均等代价下，ROC 曲线不能直接反映出学习器的期望总体代价，而“代价曲线”(cost curve)则可达到该目的。代价曲线图的横轴是取值为[0,1]的正例概率代价</p>
<p>其中p 是样例为正例的概率；纵轴是取值为[0,1]的归一化代价</p>
<p> 《《“规范化”(normaliza-tion)是将不同变化范围的值映射到相同的固定范围中常见的是[0,1]，此时亦称“归一化”》》</p>
<p>其中FPR是式(2.19)定义的假正例率，FNR=1-TPR是假反例率。代价曲线的绘制很简单：ROC曲线上每一点对应了代价平面上的一条线段，设ROC曲线上点的坐标为(FPR, TPR)，则可相应计算出FNR，然后在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如图2.5所示。</p>
<h2 id="-9"><a href="#-9" class="headerlink" title></a><br></h2><h2 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h2><p>有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较了。先使用某种实验评估方法测得学习器的某个性能度量结果，然后对这些结果进行比较。但怎么来做这个“比较”呢？是直接取得性能度量的值然后“比大小”吗？实际上，机器学习中性能比较这件事要比大家想象的复杂得多这里面涉及几个重要因素。首先，我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试集上的性能，两者的对比结果可能未必相同，第二，测试集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会得到不同的结果，即便用相同大小的测试集，若包含的测试样例不同，测试结果也会有不同，第三，很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会有不同。那么，有没有适当的方法对学习器的性能进行比较呢？</p>
<p>统计假设检验(hypothesis test)为我们进行学习器性能比较提供了重要依据。基于假设检验结果我们可推断出，若在测试集上观察到学习器A 比B 好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。下面我们先介绍两种最基本的假设检验，然后介绍几种常用的机器学习性能比较方法。为便于时论，本节默认以错误率为性能度量，用E 表示。</p>
<h3 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h3><p>假设检验中的“假设”是对学习器泛化错误率分布的某种判断或猜想，例如“E=E0”。现实任务中我们并不知道学习器的泛化错误率，只能获知其测试错误率E，泛化错误率与测试错误率未必相同，但直观上，二者接近的可能性应比较大，相差很远的可能性比较小。因此，可根据测试错误率估推出泛化错误率的分布。</p>
<p>泛化错误率为E 的学习器在一个样本上犯错的概率是E，测试错误率t意味着在m个测试样本中恰有 E× m个被误分类假定测试样本是从样本总体分布中独立采样而得，那么泛化错误率为E 的学习器将其中m＇个样本误分类、其余样本全都分类正确的概率是β）） 由此可估算出其恰将 E× m 个样本误分类的概率如下式所示，这也表达了在包含m个样本的测试集上，泛化错误率为 E 的学习器被测得测试错误率为 E 的概率：</p>
<p>给定测试错误率，则解））可知，））在））时最大，））增大时P( 减小。这符合二项(binomial) 分布，如图2.6 所示，若E=0.3，则10个样本中测得3个被误分类的概率最大。</p>
<p>《《a的常用取值有05.0.1,图2.6中。较大是为了绘图方便》》</p>
<p>我们可使用“二项检验”(binomial test)来对“E ≤ 0.3”(即“泛化错误率是否不大于0.3”这样的假设进行检验。更一般的，考虑假设“ E ≤ E0则在1-a 的概率内所能观测到的最大错误率如下式计算。这里1-a 反映了结论的“置信度”(confidence)，直观地来看，相应于图2.6中非阴影部分的范围。</p>
<p>《《s.t 是“subject to”的简写，使左边式子在右边条件满足时成立。》》</p>
<p>此时若测试错误率王小子临界值E，则根据二项检验可得出结论：在a 的显著度下，假设“ E ＜ E0”不能被拒绝，即能以1-a 的置信度认为，学习器的泛化错误率不大于E0 ；否则该假设可被拒绝，即在a 的显著度下可认为学习器的泛化错误率大于E0。</p>
<p>在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是交叉验证法等进行多次训练／测试，这样会得到多个测试错误率，此时可使用“t检验”(t-test).假定我们得到了k个测试错误率，….，则平均测试错误率μ 和方差σ2 为</p>
<p>考虑到这k个测试错误率可看作泛化错误率tQ 的独立采样，则变量</p>
<p>服从自由度为k-1 的t 分布，如图2.7 所示。</p>
<p>图2.7 t分布示意图(k=10)</p>
<p>对假设“μ=E0”和显著度a，我们可计算出当测试错误率均值为E0 时，在1-a 概率内能观测到的最大错误率，即临界值。这里考虑双边(two-tailed)假设，如图2.7 所示，两边阴影部分各有a／2 的面积；假定阴影部分范围分别为））和））.若平均错误率μ 与 E0 之差位于临界值范围［］））内，则不能拒绝假设“））”，即可认为泛化错误率为E0，置信度为1-a；否则可拒绝该假设，即在该显著度下可认为泛化错误率与E0有显著不同。a常用取值有0.05和0.1表2.3给出了一些常用临界值。</p>
<p>《《临界值2 在R 语言中可通过））计算，在Matlab 中是。》》</p>
<p>上面介绍的两种方法都是对关于单个学习器泛化性能的假设进行检验，而在现实任务中，更多时候我们需对不同学习器的性能进行比较，下面将介绍适用于此类情况的假设检验方法</p>
<h3 id="交叉验证t检验"><a href="#交叉验证t检验" class="headerlink" title="交叉验证t检验"></a>交叉验证t检验</h3><p>对两个学习器A和B，若我们使用k折交叉验证法得到的测试错误率分别为））和）），其中A和B是在相同的第i 折训练／测试集上得到的结果，则可用k 折交叉验证“成对t 检验”(paired t-tests)来进行比较检验。这里的基本思想是若两个学习器的性能相同，则它们使用相同的训练／测试集得到的测试错误率应相同，即））。</p>
<p>具体来说，对k折交叉验证产生的k对测试错误率：先对每对结果求差，））；若两个学习器性能相同，则差值均值应为零。因此，可根据差值））来对“学习器A 与B 性能相同”这个假设做t 检验，计算出差值的均值μ 和l 方差σ2，在显著度a 下，若变量</p>
<p>小于临界值）），则假设不能被拒绝，即认为两个学习器的性能没有显著差别；否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习器性能较优这里）） 是自由度为k-l 的t分布上尾部累积分布为a／2的临界值。</p>
<p>欲进行有效的假设检验一个重要前提是测试错误率均为泛化错误率的独立采样。然而，通常情况下由于样本有限，在使用交叉验证等实验估计方法时，不同轮次的训练集会有一定程度的重叠，这就使得测试错误率实际上并不独立，会导致过高估计假设成立的概率。为缓解这一问题，可采用“5×2交叉验证”法。</p>
<p>5×2交叉验证是做5次2折交叉验证，在每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复。对两个学习器A和B，第4次2折交叉验证将产生两对测试错误率，我们对它们分别求差，得到第1折上的差值））和第2折上的差值））.为缓解测试错误率的非独立性，我们仅计算第1次2折交叉验证的两个结果的平均值μ）），但对每次2折实验的结果都计算出其方差σ））,变量</p>
<p>《《服从自由度为5的t分布，其双边检验的临界值ta/2.5 当a=0.05 时为2.5706 ,a=0.1 时为2.0150。》》</p>
<h3 id="McNemar检验"><a href="#McNemar检验" class="headerlink" title="McNemar检验"></a>McNemar检验</h3><p>对二分类问题，使用留出法不仅可估计出学习器A和B的测试错误率，还可获得两学习器分类结果的差别，即两者都正确、都错误、一个正确另一个错  误的样本数，如“列联表”(contingency table) 2.4所示。<br>                     表2.4 两学习器分类差别列联表</p>
<p>若我们做的假设是两学习器性能相同，则应有e01=e10，那么变量））应当服从正态分布.McNemar 检验考虑变量</p>
<p>服从自由度为1 的χ2 分布，即标准正态分布变量的平方。给定显著度a，当以上变量值小于临界值χ2 时，不能拒绝假设，即认为两学习器的性能没有显著差别；否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习器性能较优。自由度为1 的χ2 检验的临界值当a=0.05 时为3.8415，a=0.1时为2.7055。</p>
<h3 id="Friedma检验与Nemenyi后续检验"><a href="#Friedma检验与Nemenyi后续检验" class="headerlink" title="Friedma检验与Nemenyi后续检验"></a>Friedma检验与Nemenyi后续检验</h3><p>交叉验证t检验和McNemar检验都是在一个数据集上比较两个算法的性能，而在很多时候，我们会在一组数据集上对多个算法进行比较。当有多个算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，而在两两比较时可使用前述方法，另一种方法更为直接，即使用基于算法排序的Friedman检验</p>
<p>假定我们用D1, D2 、D3 和D4 四个数据集对算法A 、B 、C 进行比较。首先，使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏排序，并赋予序值1, 2，…i 若算法的测试性能相同，则平分序值。例如，在D1 和D3 上，A 最好、B 其次、C 最差，而在D2 上，A 最好、B 与C 性能相同，……，则可列出表2.5，其中最后一行通过对每一列的序值求平均，得到平均序值</p>
<p>表2.5 算法比较序值表</p>
<p>然后，使用Friedman 检验来判断这些算法是否性能都相同若相同，则它们的平均序值应当相同假定我们在N个数据集上比较k个算法，令ri表示第t个算法的平均序值，为简化讨论，暂不考虑平分序值的情况，则ri的均值和方差分别为(k+1)/2 和(k2-1)/12.变量</p>
<p>《《在k 和N 都较大时，服从自由度为k 1 的χ2 分布。》》</p>
<p>然而，上述这样的“原始Friedman检验”过于保守，现在通常使用变量其中TX2由式(2.34)得到.TF服从自由度为k-l 和(k-l)(N-1)的F 分布，表2.6 给出了一些常用临界值。</p>
<p>原始检验妥求k 较大(例如＞ 30)，若k 较小则倾向于认为无显著区别</p>
<p>若“所有算法的性能相同”这个假设被拒绝则说明算法的性能显著不同这时需进行“后续检验”(post-hoc test)来进一步区分各算法。常用的有Nemenyi 后续检验.</p>
<p>Nemenyi 检验计算出平均序值差别的临界值域</p>
<p>表2.7 给出了a=0.05和0.1时常用的也值。若两个算法的平均序值之差超出了临界值域CD，则以相应的置信度拒绝“两个算法性能相同”这一假设。</p>
<p>《《qa 是Tukey 分布的临界值，在R 语言中可通过qtukey(l-a, k, Inf) /sqrt(2)计算.》》</p>
<p>以表2.5 中的数据为例，先根据式(2.34)和(2.35)计算出rp=24.429，由表2.6 可知，它大于a=0.05 时的F 检验临界值5.143，因此拒绝“所有算法性能相同”这个假设。然后使用Nemenyi 后续检验，在表2.7 中找到k=3 时qo.os=2.344，根据式(2.36)计算出临界值域CD=1.657，由表2.5 中的平均序值可知，算法A 与B 的差距，以及算法B 与C 的差距均未超过临界值域，而算法A 与C 的差距超过临界值域，因此检验结果认为算法A 与C 的性能显著不同，而算法A 与B 、以及算法B 与C 的性能没有显著差别</p>
<p>上述检验比较可以直观地用Friedman 检验图显示。例如根据表2.5 的序值结果可绘制出图2.8，图中纵轴显示各个算法，横轴是平均序值。对每个算法，用一个圆点显示其平均值，以圆点为中心的横线段表示临界值域的大小。然后就可从图中观察，若两个算法的横线段有交叠，则说明这两个算法没有显著差别，否则即说明有显著差别。从图2.8 中可容易地看出，算法A 与B 没有显著差别，因为它们的横线段有交叠区域，而算法A 显著优于算法C，因为它们的横线段没有交叠区域。</p>
<h2 id="-10"><a href="#-10" class="headerlink" title></a><br></h2><h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><p>对学习算法除了通过实验估计其泛化性能，人们往往还希望了解它“为什么”具有这样的性能“偏差一方差分解”(bias-variance decomposition)是解释学习算法泛化性能的一种重要工具。</p>
<p>偏差一方差分解试图对学习算法的期望泛化错误率进行拆解我们知道，算法在不同训练集上学得的结果很可能不同，即便这些训练集是来自同一个分布。对测试样本x，令YD 为z 在数据集中的标记，U 为2 的真实标记，f(x; D)为训练集D 上学得模型f 在X 上的预测输出。以回归任务为例，学习算法的期望预测为</p>
<p>《《有可能出现噪声使得YD不等于≠3》》</p>
<p>使用样本数相同的不同训练集产生的方差为</p>
<p>噪声为</p>
<p>期望输出与真实标记的差别称为偏差(bias)，即</p>
<p>为便于讨论，假定噪声期望为零, 即））.通过简单的多项式展开合<br>并，可对算法的期望泛化误差进行分解：</p>
<p>于是，</p>
<p>《《考点到噪声不依赖于f，由式(2.37)，最后项为0》》</p>
<p>《《噪声期望为0，因此最后项为0》》</p>
<p>也就是说，泛化误差可分解为偏差、方差与噪声之和。</p>
<p>回顾偏差、方差、噪声的含义：偏差(2.40)度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力，方差(2.38)度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；噪声(2.39)则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度偏差方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。</p>
<p>一般来说，偏差与方差是有冲突的，这称为偏差方差窘境(bias-variancedilemma).图2.9 给出了一个示意图。给定学习任务，假定我们能控制学习算法的训练、程度，则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率；在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。</p>
<p>《《很多学习算法都可控制训练程度，例如决策树可控制层数，神经网络可控制训练轮数，集成学习方法可控制基学习器个数。》》</p>
<p>图2.9 泛化误差与偏差、方差的关系示意图</p>
<h2 id="阅读材料-1"><a href="#阅读材料-1" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>自助采样法在机器学习中有重要用途，［Efron and Tibshirani, 1993］对此进行了详细的讨论。</p>
<p>ROC 曲线在二卡世纪八十年代后期被引入机器学习［Spackman, 1989］,AUC 则是从九十年代中期起在机器学习领域广为使用［Bradley, 1997］，但利用ROC 曲线下面积来评价模型期望性能的做法在医疗检测中早已有之［Hanleyand McNeil, 1983］.［Hand and Till, 2001］将ROC 曲线从二分类任务推广到多分类任务.［Fawcett, 2006］综述了ROC 曲线的用途。</p>
<p>［Drummond and Holte, 2006］发明了代价曲线。需说明的是，机器学习过程涉及许多类型的代价，除了误分类代价，还有测试代价、标记代价、属性代价等，即便仅考虑、误分类代价，仍可进一步划分为基于类别的误分类代价以及基于样本的误分类代价。代价敏感学习(cost-sensitive learning) ［Elkan, 2001;Zhou and Liu, 2006］专门研究非均等代价下的学习。</p>
<p>［Dietterich, 1998］指出了常规k 折交叉验证法存在的风险，并提出了5×2交叉验证法［Demsar, 2006］讨论了对多个算法进行比较检验的方法。［Geman et al., 1992］针对回归任务给出了偏差一方差一协方差分解(biasvariance-covariance decomposition)，后来被简称为偏差一方差分解。虽然偏差和方差确实反映了各类学习任务内在的误差决定因素，但式(2.42)这样优美的形式仅在基于均方误差的回归任务中得以推导出对分类任务，由于0/1 损失函数的跳变性，理论上推导出偏差一方差分解很困难已有多种方法可通过实验对偏差和方差进行估计［Kong and Dietterich, 1995; Kohavi and Wolpert,1996; Breiman, 1996; Friedman, 1997; Domingos,  2000］。</p>
<p>《《2.3.4 节仅讨论了基于类别的误分类代价》》</p>
<h3 id="休息一会儿-1"><a href="#休息一会儿-1" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事： t检验、啤酒、“学生”与威廉·戈瑟特</p>
<p>1899年，由于爱尔兰都柏林的吉尼斯啤酒厂热衷于聘用剑桥、牛津的优秀毕业生，学化学的牛津毕业生威廉·戈瑟特(William Gosset, 1876-1937)到该厂就职，希望将他的生物化学知识用于啤酒生产过程。为降低啤酒质量监控的戚本，戈瑟特发明了t 检验法，1908年在Biometrika 发表。为防止泄漏商业机密，戈瑟特发表文章时用了笔名“学生”，于是该方法被称为“学生氏t检验”(Student ’s t-test)。</p>
<p>《《1954年该厂开始出版《吉尼斯世界纪录大全》 》》</p>
<p>吉尼斯啤酒厂是一家很有远见的企业，为保持技术人员的高水准，该厂像高校一样给予技术人员“学术假”，1906-1907年戈瑟特得以到“统计学之父”卡尔·皮尔逊(Karl Pearson, 1857-1936)教授在伦敦大学学院(University College London，简称UCL的实验室访问学习。因此，很难说t检验法是戈瑟特在啤酒厂还是在UCL 访学期间提出的，但“学生”与戈瑟特之间的联系是被UCL 的统计学家们发现的，尤其因为皮尔逊教授恰是Biometri阳的主编。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第3章-线性模型"><a href="#第3章-线性模型" class="headerlink" title="第3章 线性模型"></a>第3章 线性模型</h1><h2 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h2><p>给定由d个属性描述的示例x=(x1;x2;…;xd)，其中均是z 在第4个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即</p>
<p>一般用向量形式写成</p>
<p>其中w=(w1;w2;..;wd)· w 和b 学得之后，模型就得以确定。</p>
<p>线性模型形式简单、易于建模，但却蕴涵着机器学习中一些重要的基本思想许多功能更为强大的非线性模型(nonlinear model)可在线性模型的基础上通过引入层级结构或高维映射而得。此外，由于w 直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性(comprehensibility.例如若在西瓜问题中学得“ f好瓜(x)=0.2·x色泽十0.5 x根蒂＋ 0.3.x敲声＋ 1 ”，则意味着可通过综合考虑色泽、根蒂和敲声来判断瓜好不好，其中根蒂最要紧，而敲声比色泽更重要。</p>
<p>本章介绍几种经典的线性模型。我们先从回归任务开始，然后讨论二分类和多分类任务。</p>
<h2 id="-11"><a href="#-11" class="headerlink" title></a><br></h2><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>给定数据集D={(x1 ,Y1) ,…, (xm,Ym)}，其中Xi=(), Yi∈R “线性回归” (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。</p>
<p>我们先考虑一种最简单的情形。输入属性的数目只有一个。为便于讨论，此时我们忽略关于属性的下标，即D=(其中Xi∈R 对离散属性，若属性值间存在“序”(order)关系，可通过连续化将其转化为连续值，例如二值属性“身高”的取值“高”“矮”可转化为{1.0, 0.0}，三值属性“ 高度”的取值“高”“中”“低”可转化为{1.0, 0.5, 0.0}；若属性值间不存在序关系，假定有k个属性值，则通常转化为k 维向量，例如属性“瓜类”的取值“西瓜”“南瓜”“黄瓜”可转化为））。</p>
<p>线性回归试图学得</p>
<p>////////////////开始取消注释54页//////////</p>
<p>如何确定w 和b 呢？显然，关键在于如何衡量f(x)与y之间的差别。2.3节介绍过，均方误差(2.2)是回归任务中最常用的性能度量，因此我们可试图让均方误差最小化，即</p>
<p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”(Euclidean distance).基于均方误差最小化来进行模型求解的方法称为“最小二乘法”(least square method).在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。</p>
<p>求解w 和b 使）） 最小化的过程，称为线性回归模型的最小二乘“参数估计”(parameter estimation).我们可将E(w，b) 分别对w 和b 求导，得到</p>
<p>然后令式(3.5)和(3.6)为零可得到w 和b 最优解的闭式(closed-form)解</p>
<p>其中））为X 的均值</p>
<p>更一般的情形是如本节开头的数据集D，样本由d个属性描述。此时我们试图学得：</p>
<p>这称为“多元线性回归”(multivariate linear regression).</p>
<p>类似的，可利用最小二乘法来对w和b进行估计为便于讨论，我们把w和b吸收入向量形式w=(w;b)，相应的，把数据集D表示为一个m×(d+1)大小的矩阵X，其中每行对应于一个示例，该行前d个元素对应于示例的d个属性值，最后一个元素恒置为1，即</p>
<p>再把标记也写成向量形式ν=(y1; y2 ；… ； ym)，则类似于式(3.4)，有</p>
<p>令）），对w 求导得到</p>
<p>令上式为零可得w最优解的闭式解，但由于涉及矩阵逆的计算，比单变量情形要复杂一些。下面我们做一个简单的讨论。</p>
<p>当xTx 为满秩矩阵(full-rank matrix)或正定矩阵(positive definite matrix)时，令式(3.10)为零可得</p>
<p>其中(xTx) -1 是矩阵(xTx的逆矩阵令xi=）），则最终学得的多元线性回归模型为</p>
<p>然而，现实任务中xTx 往往不是满秩矩阵。例如在许多任务中我们会遇到大量的变量，其数目甚至超过样例数，导致X 的列数多于行数，xTx显然不满秩。此时可解出多个w，它们都能使均方误差最小化选择哪一个解作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化(regularization)项.</p>
<p>线性模型虽简单，却有丰富的变化。例如对于样例(x,y)，y∈R，当我们希望线性模型(3.2)的预测值逼近真实标记y 时，就得到了线性回归模型为便于观察，我们把线性回归模型简写为</p>
<p>可否令模型预测值逼近y的衍生物呢？譬如说，假设我们认为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标.</p>
<p>这就是“对数线性回归” (log-linear regression)，它实际上是在试图让））逼近y.式(3.14)在形式上仍是线性回归，但实质上已是在求取输入空间到输出空间的非线性函数映射如图3.1 所示。这里的对数函数起到了将线性回归模型的预测值与真实标记联系起来的作用。</p>
<p>更一般地，考虑单调可做函数g(•)，令</p>
<p>这样得到的模型称为“广义线性模型”(generalized linear model)，其中函数g(•)  称为“联系函数”(link function)。显然，对数线性回归是广义线性模型在进行g(•)=ln(•)时的特例。</p>
<h2 id="-12"><a href="#-12" class="headerlink" title></a><br></h2><h2 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h2><p>上一节讨论了如何使用线性模型进行回归学习，但若要做的是分类任务该怎么办？答案蕴涵在式(3.15)的广义线性模型中:只需找一个单调可微函数将分类任务的真实标记y 与线性回归模型的预测值联系起来。</p>
<p>考虑二分类任务，其输出标记 y∈{0,1}，而线性回归模型产生的预测值z=wTx+b 是实值，于是，我们需将实值z 转换为0/1 值。最理想的是“单位阶跃函数”(unit - step function)</p>
<p>即若预测值z 大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别，如图3.2 所示</p>
<p>但从图3.2 可看出，单位阶跃函数不连续，因此不能直接用作式(3.15)中的g-(•)。于是我们希望找到能在一定程度上近似单位阶跃函数的“替代函数”(surrogate function)，并希望它单调可微对数几率函数(logisticfunction)正是这样一个常用的替代函数：</p>
<p>从图3.2 可看出，对数几率函数是一种“Sigmoid函数”它将z 值转化为一个接近0 或1 的y值，并且其输出值在z=0 附近变化很陡将对数几率函数作为g-(•) 代入式(3.15)，得到</p>
<p>类似于式(3.14)，式(3.18)可变化为</p>
<p>若将y 视为样本x 作为正例的可能性，则1-y 是其反例可能性，两者的比值</p>
<p>称为“几率”(odds)，反映了x 作为正例的相对可能性。对几率取对数则得到“对数几率”(log odds，亦称logit)</p>
<p>由此可看出，式(3.18)实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为“对数几率回归” (logisticregression，亦称logit regression).特别需注意到，虽然它的名字是“回归”，但实际却是一种分类学习方法这种方法有很多优点，例如它是直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题，它不是仅预测出“类别” 而是可得到近似概率预测，这对许多需利用概率辅助决策的任务很有用；此外，对率函数是任意阶可导的凸函数，有很好的数学性质，现有的许多数值优化算法都可直接用于求取最优解.</p>
<p>下面我们来看看如何确定式(3.18)中的w 和b.若将式(3.18)中的y 视为类后验概率估计p(y=1|x)，则式(3.19)可重写为</p>
<p>显然有</p>
<p>于是，我们可通过“极大似然法”(maximum likelihood method)来估计w 和b.给定数据集）），对率回归模型最大化“对数似然” (log-likelihood)</p>
<p>即令每个样本属于其真实标记的概率越大越好，为便于讨论，令β）），则WTX + b 可简写为βT。再令 β）），则式(3.25)中的似然项可重写为</p>
<p>将式(3.26)代入(3.25)，并根据式(3.23)和(3.24)可知，最大化式(3.25)等价于最小化</p>
<p>式(3.27)是关于β 的高阶可导连续凸函数，根据凸优化理论［Boyd and Vandenberghe, 2004］，经典的数值优化算法如梯度下降法(gradient descentmethod)、牛顿法(Newton method)等都可求得其最优解，于是就得到.</p>
<p>以牛顿法为例，其第t+1 轮迭代解的更新公式为</p>
<p>其中关于β的一阶、二阶导数分别为</p>
<h2 id="-13"><a href="#-13" class="headerlink" title></a><br></h2><h2 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h2><p>线性判别分析(Linear Discriminant Analysis，简称LDA)是－种经典的线性学习方法，在二分类问题上因为最早由［Fisher, 1936］提出，亦称“Fisher判 别分析”。</p>
<p>LDA的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上，</p>
<p>使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。图3.3给出了一个二维示意图。</p>
<p>图3.3 LDA 的二维示意图，“+”、“-”分别代表正例和反例，椭圆表示数据簇的外轮廓，虚线表示投影，红色实心园和实心三角形分别表示两类样本投影后的中心点。</p>
<p>给定数据集D=）），令））分别表示第））类示例的集合、均值向量、协方差矩阵。若将数据投影到直线w上，<br>则两类样本的中心在直线上的投影分别为wTμ0 和wTμl ；若将所有样本点都投影到直线上，则两类样本的协方差分别为wT∑0w 和WT∑1W .由于直线是一维空间，因此wTμ0、wTμl 、wT∑0w 和WT∑1W 均为实数。</p>
<p>欲便同类样例的投影点尽可能接近，可以让同类样例投影点的协方差尽可能小，即wT∑0w + WT∑1W 尽可能小；而欲使异类样例的投影点尽可能远离，可以让类中心之间的距离尽可能大，即））尽可能大。同时考虑二者，则可得到欲最大化的目标</p>
<p>定义“类内散度矩阵”(within-class scatter matrix)</p>
<p>以及“类间散度矩阵”(between-class scatter matrix)</p>
<p>则式(3.32)可重写为</p>
<p>这就是LDA欲最大化的目标，即Sb 与Sw 的“广义瑞利商”(generalized Rayleigh quotient)。</p>
<p>如何确定w 呢？注意到式(3.35)的分子和分母都是关于w 的二次项，因此式(3.35)的解与w 的长度无关，只与其方向有关。不失一般性，令wTSww=1,则式(3.35)等价于</p>
<p>由拉格朗日乘子法，上式等价于</p>
<p>其中λ 是拉格朗日乘子注意到Sb切的方向恒为μ0-μ1，不妨令</p>
<p>代入式(3.37)即得</p>
<p>考虑到数值解的稳定性，在实践中通常是对Sw 进行奇异值分解，即Sw=U∑VT，这里∑ 是一个实对角矩阵，其对角线上的元素是Sw 的奇异值，然后再由）） 得到Sw。</p>
<p>值得一提的是，LDA 可从贝叶斯决策理论的角度来阐释，并可证明，当两类数据同先验、满足高斯分布且协方差相等时，LDA 可达到最优分类。</p>
<p>可以将LDA 推广到多分类任务中假定存在N个类，且第z 类示例数为mi，我们先定义“ 全局散度矩阵”</p>
<p>其中μ 是所有示例的均值向量。将类内散度矩阵Sw 重定义为每个类别的散度矩阵之和，即</p>
<p>显然，多分类LDA 可以有多种实现方法：使用Sb，Sw, St 三者中的任何两个即可。常见的一种实现是采用优化目标</p>
<p>其中W））表示矩阵的迹(trace)，式(3.44)可通过如下广义特征值问题求解:</p>
<p>w 的闭式解则是sw 的d＇个最大非零广义特征值所对应的特征向量组成的矩阵，d＇≤ N-1。</p>
<p>若将W 视为一个投影矩阵，则多分类LDA 将样本投影到d＇维空间，d＇ 通常远小子数据原有的属性数d.于是，可通过这个投影来减小样本点的维数，且投影过程中使用了类别信息，因此LDA 也常被视为一种经典的监督降维技术。</p>
<h2 id="-14"><a href="#-14" class="headerlink" title></a><br></h2><h2 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h2><p>现实中常遇到多分类学习任务有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。</p>
<p>不失一般性，考虑N个类别C1, C2 ,..,CN，多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器；在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。这里的关键是如何对多分类任务进行拆分？以及如何对多个分类器进行集成。本节主要介绍拆分策略。</p>
<p>最经典的拆分策略有三种“一对一”(One vs.One，简称OvO)、 “一对其余”(One vs.Rest，简称OvR)和 “多对多”(Many vs.Many，简称MvM)。</p>
<p>给定数据集D={））}。OvO将这N个类别两两配对，从而产生N(N-1)/2个二分类任务，例如OvO将为区分类别Ci 和Cj 训练一个分类器，该分类器把D 中的Ci 类样例作为正例，Cj 类样例作为反例。在测试阶段，新样本将同时提交给所有分类器，于是我们将得到N(N-1)/2个分类结果，最终结果可通过投票产生： 即把被预测得最多的类别作为最终分类结果。图3.4 给出了一个示意图。</p>
<p>OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器。在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果？如图3.4所示。若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。</p>
<p>容易看出，OvR 只需训练N个分类器，而OvO需训练N(N-1 )/2个分类器，因此，OvO 的存储开销和测试时间开销通常比OvR 更大但在训练时，OvR 的每个分类器均使用全部训练样例，而OvO 的每个分类器仅用到两个类的样例，因此，在类别很多时，OvO 的训练时间开销通常比OvR 更小至于预测性能，则取决于具体的数据分布，在多数情形下两者差不多。</p>
<p>MvM 是每次将若干个类作为正类，若干个其他类作为反类。显然，OvO 和OvR 是MvM 的特例.MvM 的正、反类构造必须有特殊的设计，不能随意选取。这里我们介绍一种最常用的MvM 技术·“纠错输出码”(Error CorrectingOutput Codes，简称ECOC)。</p>
<p>ECOC ［Dietterich and Bakiri, 1995］是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性.ECOC 工作过程主要分为两步：</p>
<p>•编码。对N个类别做M 次划分，每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集i 这样一共产生M个训练集，可训练出M个分类器。</p>
<p>•解码： M个分类器分别对测试样本进行预测，这些预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果。</p>
<p>类别划分通过“ 编码矩阵”(coding matrix)指定。编码矩阵有多种形式，常见的主要有二元码和三元码。前者将每个类别分别指定为正类和反类，后者在正、反类之外，还可指定“ 停用类”，图3.5 给出了一个示意图，在图3.5(a)中，分类器h 将C1 类和C3 类的样例作为正例，C2 类和C4 类的样例作为反例；在图3.5(b)中，分类器f4 将C1 类和C4 类的样例作为正例，C3 类的样例作为反例。在解码阶段，各分类器的预测结果联合起来形成了测试示例的编码，该编码与各类所对应的编码进行比较，将距离最小的编码所对应的类别作为预测结果。例如在图3.5(a)中，若基于欧氏距离，预测结果将是C3。</p>
<p>图3.5 ECOC 编码示意图。“＋”、“-1 ”分别表示学习器fi 将该类样本作为正、反例；三元码中“0”表示fi 不使用该类样本</p>
<p>为什么称为“纠错输出码”呢？这是因为在测试阶段，ECOC编码对分类器的错误有一定的容忍和修正能力例如图3.5(a)中对测试示例的正确预测编码是）），假设在预测时某个分类器出错了，例如f2出错从而导致了错误编码）），但基于这个编码仍能产生正确的最终分类结果C3.一般来说，对同一个学习任务，ECOC编码越长，纠错能力越强。然而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大； 另一方面，对有限类别数，可能的组合数目是有限的，码长超过一定范围后就失去了意义。</p>
<p>对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强。因此，在码长较小时可根据这个原则计算出理论最优编码然而，码长稍大一些就难以有效地确定最优编码，事实上这是NP难问题不过，通常我们并不需获得理论最优编码因为非最优编码在实践中往往已能产生足够好的分类器。另一方面，并不是编码的理论性质越好，分类性能就越好，因为机器学习问题涉及很多因素，例如将多个类拆解为两个“类别子集”不同拆解方式所形成的两个类别子集的区分难度往往不同，即其导致的二分类问题的难度不同；于是，一个理论纠错性质很好、但导致的二分类问题较难的编码，与另一个理论纠错性质差一些、但导致的二分类问题较简单的编码，最终产生的模型性能孰强孰弱很难说。</p>
<h2 id="-15"><a href="#-15" class="headerlink" title></a><br></h2><h2 id="类别不平衡问题"><a href="#类别不平衡问题" class="headerlink" title="类别不平衡问题"></a>类别不平衡问题</h2><p>前面介绍的分类学习方法都有一个共同的基本假设，即不同类别的训练、样例数目相当。如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰。例如有998个反例，但正例只有2个，那么学习方法只需返回一个永远将新样本预测为反例的学习器，就能达到99.8% 的精度，然而这样的学习器往往没有价值，因为它不能预测出任何正例。</p>
<p>类别不平衡(class-imbalance)就是指分类任务中不同类别的训练样例数目差别很大的情况。不失一般性，本节假定正类样例较少，反类样例较多在现实的分类学习任务中，我们经常会遇到类别不平衡，例如在通过拆分法解决多分类问题时，即使原始问题中不同类别的训练样例数目相当，在使用OvR、MvM策略后产生的二分类任务仍可能出现类别不平衡现象，因此有必要了解类别不平衡性处理的基本方法。</p>
<p>从线性分类器的角度讨论容易理解，在我们用y=wTx+b 对新样本x进行分类时，事实上是在用预测出的y值与一个阈值进行比较，例如通常在y＞0.5时判别为正例，否则为反例，y实际上表达了正例的可能性，几率击则反映了正例可能性与反例可能性之比值，阈值设置为0.5 恰表明分类器认为真实正、反例可能性相同，既分类器决策规则为</p>
<p>若y＞1 则预测为正例。</p>
<p>然而，当训练集中正、反例的数目不同时，令m+ 表示正例数目，m-表示反例数目，则观测几率是）），由于我们通常假设训练集是真实样本总体的无偏采样，因此观测儿率就代表了真实几率于是，只要分类器的预测几率高于观测几率就应判定为正例，既</p>
<p>若 则 预测为正例，</p>
<p>但是，我们的分类器是基于式(3.46)进行决策，因此，需对其预测值进行调整，使其在基于式(3.46)决策时，实际是在执行式(3.47).要做到这一点很容易，只需令</p>
<p>这就是类别不平衡学习的一个基本策略——“再缩放”(rescaling)。</p>
<p>再缩放的思想虽简单，但实际操作却并不平凡，主要因为“训练集是真实样本总体的无偏采样”这个假设往往并不成立，也就是说，我们未必能有效地基于训练集观测儿率来推断出真实几率。现有技术大体上有三类做法· 第一类是直接对训练集里的反类样例进行“欠采样”(undersampling)，即去除一些反例使得正、反例数目接近，然后再进行学习；第二类是对训练集里的正类样例进行“过采样”(oversampling)，即增加一些正例使得正、反例数目接近，然后再进行学习，第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式(3.48)嵌入到其决策过程中，称为“阈值移动”(threshold-moving)。</p>
<p>欠采样法的时间开悄通常远小于过采样法，因为前者丢弃了很多反例，使得分类器训练集远小于初始训练集，而过采样法增加了很多正例，其训练集大于初始训练集需注意的是，过采样法不能简单地对初始正例样本进行重复采样，否则会招致严重的过拟合；过采样法的代表性算法SMOTE ［Chawlaet al., 2002］是通过对训练集里的正例进行插值来产生额外的正例。另一方面，欠采样法若随机丢弃反例，可能丢失一些重要信息； 欠采样法的代表性算法EasyEnscmble ［Liu et al., 2009］则是利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息。</p>
<p>值得一提的是，“再缩放”也是“代价敏感学习”(cost-sensitive learning)的基础。在代价敏感学习中将式(3.48)中的m-/m+用cost+ /cost-代替即 可，其中cost+ 是将正例误分为反例的代价，cost-是将反例误分为正例的代价。</p>
<h2 id="阅读材料-2"><a href="#阅读材料-2" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>“稀疏表示”(sparse representation)近年来很受关注，但即便对多元线性回归这样简单的模型，获得具有最优“稀疏性”(sparsity)的解也并不容易。稀疏性问题本质上对应了L0范数的优化，这在通常条件下是NP难问题。LASSO通过L1 范数来近似L0 范数，是求取稀疏解的重要技术。</p>
<p>可以证明，OvO 和OvR 都是ECOC 的特例［Allwein et al，2000］.人们以往希望设计通用的编码法，［Crammer and Singer, 2002］提出要考虑问题本身的特点，设计“问题依赖”的编码法，并证明寻找最优的离散编码矩阵是一个NP 完全问题。此后，有多种问题依赖的ECOC 编码法被提出，通常是通过找出具有代表性的二分类问题来进行编码［Pujol et al., 2006, 2008］.［Escalera etal., 2010］开发了一个开源ECOC 库。</p>
<p>MvM 除了ECOC 还可有其他实现方式，例如DAG (Directed AcyclicGraph)拆分法［Platt et al., 2000］将类别划分表达成树形结构，每个结点对应于一个二类分类器还有一些工作是致力于直接求解多分类问题，例如多类支持向量机方面的一些研究。</p>
<p>代价敏感学习中研究得最多的是基于类别的“误分类代价”(misclassification cost)，代价矩阵如表2.2 所示，本书在提及代价敏感学习时，默认指此类情形。已经证明，对二分类任务可通过“再缩放”获得理论最优解。但对多分类任务，仅在某些特殊情形下存在闭式解［Zhouand Liu, 2006a］.非均等代价和类别不平衡性虽然都可借助“再缩放”技术，但两者本质不同。需注意的是，类别不平衡学习中通常是较小类的代价更高，否则无需进行特殊处理。</p>
<p>多分类学习中虽然有多个类别，但每个样本仅属于一个类别。如果希望为一个样本同时预测出多个类别标记，例如一幅图像可同时标注为“蓝天”、 “白云”、 “羊群”、 “自然场景”，这样的任务就不再是多分类学习，而是“多标记学习”(multi-label learning)，这是机器学习中近年来相当活跃的一个研究领域。对多标记学习感兴趣的读者可参阅。</p>
<h3 id="休息一会儿-2"><a href="#休息一会儿-2" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事： 关于“最小二乘法”</p>
<p>1801年，意大利天文学家皮亚齐发现了1号小行星“谷神星”，但在跟踪观测了40天后，因谷神星转至太阳的背后，皮亚齐失去了谷神星的位置。许多天文学家试图重新找到谷神星，但都徒劳无获。这引起了伟大的德国数学家高斯的注意，他发明了一种方法，根据皮亚齐的观测数据计算出了谷神星的轨道，后来德国天文学家奥伯斯在高斯预言的时间和星空领域重新找到了谷神星.1809年，高斯在他的著作《天体运动论》中发表了这种方法，即最小二乘法。</p>
<p>1805年，在椭圆积分、数论和几何方面都有重大贡献的法国大数学家勒让德发表了《计算彗星轨道的新方法》，其附录中描述了最小二乘法。勒让德是法国18-19世纪数学界的三驾马车之一，早已是法国科学院院士但勒让德的书中没有涉及最小二乘法的误差分析，高斯1809年的著作中包括了这方面的内容，这对最小二乘法用于数理统计、乃至今天的机器学习有极为重要的意义。由于高斯的这一重大贡献，以及他声称自已1799年就已开始使用这个方法，因此很多人将最小二乘法的发明优先权归之为高斯。当时这两位大数学家发生了著名的优先权之争，此后有许多数学史家专门进行研究，但至今也没弄清到底是谁最先发明了最小二乘法。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第4章-决策树"><a href="#第4章-决策树" class="headerlink" title="第4章 决策树"></a>第4章 决策树</h1><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>决策树(decision tree是一类常见的机器学习方法。以二分类任务为例，我们希望从给定训练数据集学得一个模型用以对新示例进行分类，这个把样本分类的任务，可看作对“当前样本属于正类吗，”这个问题的“决策”或“判定”过程。顾名思义，决策树是基于树结构来进行决策的，这恰是人类在面临决策问题时一种很自然的处理机制。例如，我们要对“这是好瓜吗？”这样的问题进行决策时，通常会进行一系列的判断或“子决策”：我们先看“它是什么颜色？”，如果是“青绿色”，则我们再看“它的根蒂是什么形态？”，如果是“蜷缩”，我们再判断“它敲起来是什么声音？”，最后，我们得出最终决策：这是个好瓜。这个决策过程如图4.1所示。</p>
<p>显然，决策过程的最终结论对应了我们所希望的判定结果，例如“是”或“不是”好瓜；决策过程中提出的每个判定问题都是对某个属性的“测试”,例如“色泽=?”“根蒂=?”；每个测试的结果或是导出最终结论，或是导出进一步的判定问题，其考虑范围是在上次决策结果的限定范围之内，例如若在“色泽一青绿”之后再判断“根蒂=?”，则仅在考虑青绿色瓜的根蒂。</p>
<p>一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点；</p>
<p>叶结点对应于决策结果，其他每个结点则对应于一个属性测试；每个结点包含的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的“分而治之”(divide-and-conquer)策略，如图4.2所示。</p>
<p>显然，决策树的生成是一个递归过程。在决策树基本算法中，有三种情形会导致递归返回：(1)当前结点包含的样本全属于同一类别，无需划分；(2)当前属性集为空，或是所有样本在所有属性上取值相同，无法划分；(3)当前结点包含的样本集合为空，不能划分。</p>
<p>在第(2)种情形下，我们把当前结点标记为叶结点，并将其类别设定为该结点所含样本最多的类别；在第(3)种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别。注意这两种情形的处理实质不同：情形(2)是在利用当前结点的后验分布，而情形(3)则是把父结点的样本分布作为当前结点的先验分布。</p>
<h2 id="-16"><a href="#-16" class="headerlink" title></a><br></h2><h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><p>由算法4.2可看出，决策树学习的关键是第8行，即如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”(purity)越来越高。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>“信息熵”(information entropy)是度量样本集合纯度最常用的一种指标。假定当前样本集合D中第k类样本所占的比例为）），则D的信息熵定义为</p>
<p>Ent(D)的值越小，则D的纯度越高。</p>
<p>假定离散属性a 有V个可能的取值{a1，a2，av}，若使用a来对样本集D进行划分，则会产生V个分支结点，其中第v个分支结点包含了D中所有在属性a上取值为U的样本，记为DV我们可根据式(4.1)计算出DV的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重））,即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集D进行划分所获得的“信息增益”(informationgain)。</p>
<p>一般而言，信息增益越大，则意味着使用属性a来进行划分所获得的“纯度提升”越大。因此，我们可用信息增益来进行决策树的划分属性选择，即在图4.2 算法第8 行选择属性 a=argmaxGain(D，a)著名的ID3 决策树学习算aEA法就是以信息增益为准则来选择划分属性。</p>
<p>以表4.1 中的西瓜数据集2.0 为例，该数据集包含17个训练样例，用以学习一棵能预测没剖开的是不是好瓜的决策树。显然，|Y|=2.在决策树学习开始时，根结点包含D 中的所有样例，其中正例占）），反例占））是，根据式(4.1)计算出根结点的信息熵为</p>
<p>然后，我们要计算出当前属性集合{色泽，根蒂，敲声，纹理，脐部，触感}中每个属性的信息增益。以属性“色泽”为例，它有3个可能的取值：{青绿，乌黑，浅白}。若使用该属性对D进行划分，则可得到3个子集，分别记为：D1(色泽=青绿),D2(色泽=乌黑),D3(色泽=浅白)。</p>
<p>子集D1包含编号为{1, 4, 6, 10, 13, 17}的6个样例，其中正例占；）），反例占））；D2包含编号为{2, 3, 7, 8, 9, 15}的6个样例，其中正、反例分别占）），D3包含编号为{5, 11, 12, 14, 16}的5个样例，其中正、反例分别占P1=）），P2=））。根据式(4.1)可计算出用“色泽”划分之后所获得的3 个分支结点的信息熵为</p>
<p>于是，根据式(4.2)可计算出属性“色泽”的信息增益为</p>
<p>类似的，我们可计算出其他属性的信息增益。</p>
<p>显然，属性“纹理”的信息增益最大，于是它被选为划分属性。图4.3给出了基于“纹理”对根结点进行划分的结果，各分支结点所包含的样例子集显示在结点中。</p>
<p>然后，决策树学习算法将对每个分支结点做进一步划分。以图4.3中第一个分支结点(“纹理一清晰”为例，该结点包含的样例集合D1中有编号为{1, 2, 3, 4, 5, 6, 8, 10, 15}的9个样例，可用属性集合为{色泽，根蒂，敲声，脐部，<br>触感}。基于D1计算出各属性的信息增益：</p>
<p>《《“纹理”不再作为候选划分属性》》</p>
<p>“根蒂”、“脐部”、“触感”3个属性均取得了最大的信息增益，可任选其中之一作为划分属性。类似的，对每个分支结点进行上述操作，最终得到的决策树如图4.4所示。</p>
<h3 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h3><p>在上面的介绍中，我们有意忽略了表4.1中的“编号”这一列。若把“编号”也作为一个候选划分属性，则根据式(4.2)可计算出它的信息增益为0.998 ,远大于其他候选划分属性这很容易理解： “编号”将产生17个分支，每个分支结点仅包含一个样本，这些分支结点的纯度已达最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测。</p>
<p>实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5 决策树算法［Quinlan, 1993］ 不直接使用信息增益，而是使用“增益率”(gain ratio)来选择最优划分属性采用与式(4.2)相同的符号表示，增益率定义为</p>
<p>称为属性a 的“固有值”(intrinsic value) ［Quinla民1993］.属性a 的可能取值数目越多(即V 越大)，则IV(a)的值通常会越大。例如，对表4.1 的西瓜数据集2.0，有IV(触感)=0.874 (V=2), IV(色泽)=1.580 (V=3) ,IV(编号)=4.088 (V=17)。</p>
<p>需注意的是，增益率准则对可取值数目较少的属性有所偏好，因此，C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式［Quinlan, 1993］：先从候选划分属性中找出信息增益高于平均水平的属’性，再从中选择增益率最高的。</p>
<h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><p>CART 决策树［Breiman et al., 1984］使用“基尼指数”(Gini index)来选择划分属性。采用与式(4.1)相同的符号，数据集D 的纯度可用基尼值来度量：</p>
<p>直观来说，Gini(D) 反映了从数据集D 中随机抽取两个样本，其类别标记不一致的概率。因此，Gini(D)越小，则数据集D 的纯度越高。</p>
<p>采用与式(4.2)相同的符号表示，属性a 的基尼指数定义为</p>
<p>于是，我们在候选属性集合A 中，选择那个使得划分后基尼指数最小的属性作为最优划分属性，即  a=argmin Gini_index(D，a)。</p>
<h2 id="-17"><a href="#-17" class="headerlink" title></a><br></h2><h2 id="剪枝处理"><a href="#剪枝处理" class="headerlink" title="剪枝处理"></a>剪枝处理</h2><p>剪枝(pruning)是决策树学习算法对付“过拟合”的主要手段。在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得“太好”了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险。</p>
<p>决策树剪枝的基本策略有“预剪枝”(prepruning和“后剪枝”(postpruning)［Quinlan, 1993］.预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点</p>
<p>如何判断决策树泛化性能是否提升呢？这可使用2.2节介绍的性能评估方法。本节假定采用留出法即预留一部分数据用作“验证集”以进行性能评估例如对表4.1的西瓜数据集2.0，我们将其随机划分为两部分，如表4.2所示，编号为{1,2,3,6,7,10,14,15,16,17}的样例组成训练集，编号为{4,5,8,9,11,12,13}的样例组成验证集。</p>
<p>表4.2 西瓜数据集2.0划分出的训练集（双线上部）与验证集（双线下部）</p>
<p>假定我们采用4.2.1节的信息增益准则来进行划分属性选择，则从表4.2的训练集将会生成一棵如图4.5所示的决策树。为便于讨论，我们对图中的部分结点做了编号。</p>
<h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>我们先讨论预剪枝基于信息增益准则我们会选取属性“脐部”来对训练、集进行划分，并产生，个分支，如图4.6 所示然而，是否应该进行这个划分呢？预剪枝要对划分前后的泛化性能进行估计。</p>
<p>在划分之前，所有样例集中在根结点若不进行划分，则根据图4.2算法第6行，该结点将被标记为叶结点，其类别标记为训练样例数最多的类别，假设我们将这个叶结点标记为“好瓜”。用表4.2的验证集对这个单结点决策树进行评估，则编号为{4,5,8}的样例被分类正确，另外4个样例分类错误，于是，验证集精度为））42.9%。</p>
<p>在用属性“脐部”划分之后，图4.6 中的结点②、③、④分别包含编号为{1,2,3,14}、 {6,7,15.17}、{10,16}的训练样例，因此这，个结点分别被标记为叶结点“好瓜”、“好瓜”、“坏瓜”。此时，验证集中编号为{4,5,8,11,12}的样例被分类正确，验证集精度为）×100%=71.4%＞42.9%。于是，用“脐部”进行划分得以确定。</p>
<p>然后，决策树算法应该对结点②进行划分，基于信息增益准则将挑选出划分属性“色泽”。然而，在使用“色泽”划分后，编号为{5}的验证集样本分类结果会由正确转为错误，使得验证集精度下降为57.1%。于是，预剪枝策略将禁止结点②被划分。</p>
<p>对结点③，最优划分属性为“根蒂”，划分后验证集精度仍为71.4%。这个划分不能提升验证集精度，于是，预剪枝策略禁止结点③被划分。</p>
<p>对结点④，其所含训练样例已属于同一类，不再进行划分。</p>
<p>于是，基于预剪枝策略从表4.2数据所生成的决策树如图4.6所示，其验证集精度为71.4%。这是一棵仅有一层划分的决策树，亦称“决策树桩”(decision stump).</p>
<p>对比图4.6和图4.5可看出，预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。</p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>后剪枝先从训练集生成一棵完整决策树，例如基于表4.2的数据我们得到如图4.5所示的决策树。易知，该决策树的验证集精度为42.9%。</p>
<p>后剪枝首先考察图4.5中的结点⑥。若将其领衔的分支剪除，则相当于把⑥替换为叶结点。替换后的叶结点包含编号为{7,15}的训练样本，于是，该叶结点的类别标记为“好瓜”，此时决策树的验证集精度提高至57.1%。于是，后剪枝策略决定剪枝，如图4.7所示。</p>
<p>然后考察结点⑤，若将其领衔的子树替换为叶结点，则替换后的叶结点包含编号为{6,7,15}的训练样例，叶结点类别标记为“好瓜”，此时决策树验证集精度仍为57.1%。于是，可以不进行剪枝。</p>
<p>对结点②，若将其领衔的子树替换为叶结点，则替换后的叶结点包含编号为{1, 2, 3, 14}的训练样例，叶结点标记为“好瓜”。此时决策树的验证集精度提高至71.4%。于是，后剪枝策略决定剪枝。</p>
<p>对结点③和①，若将其领衔的子树替换为叶结点，则所得决策树的验证集精度分别为71.4%与42.9%，均未得到提高。于是它们被保留。</p>
<p>最终，基于后剪枝策略从表4.2数据所生成的决策树如图4.7所示，其验证集精度为71.4%。</p>
<p>对比图4.7和图4.6可看出，后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。</p>
<h2 id="-18"><a href="#-18" class="headerlink" title></a><br></h2><h2 id="连续与缺失值"><a href="#连续与缺失值" class="headerlink" title="连续与缺失值"></a>连续与缺失值</h2><h3 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h3><p>到目前为止我们仅讨论了基于离散属性来生成决策树。现实学习任务中常会遇到连续属性，有必要讨论如何在决策树学习中使用连续属性。</p>
<p>由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可取值来对结点进行划分。此时，连续属性离散化技术可派上用场。最简单的策略是采用二分法(bi-partition)对连续属性进行处理，这正是C4.5 决策树算法中采用的机制。</p>
<p>给定样本集D和连续属性矶假定a在D上出现了n个不同的取值，将这些值从小到大进行排序，记为{a1，a2,…, an}.基于划分点t 可将D 分为子集Dt- 和Dt+，其中Dt- 包含那些在属性a 上取值不大于t 的样本，而Dt+ 则包含那些在属性a上取值大于t的样本，显然，对相邻的属性取值ai与ai+1来说，t在区间［a,l)中取任意值所产生的划分结果相同。因此，对连续属性a, 我们可考察包含n-1个元素的候选划分点集合</p>
<p>即把区间［ai,ai+l)的中位点业产作为候选划分点然后，我们就可像离散属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分例如，可对式(4.2)稍加改造：</p>
<p>其中Gain(D，a，t)是样本集D基于划分点t三分后的信息增益。于是，我们就可选择使Gain(D，a，t)最大化的划分点。</p>
<p>作为一个例子，我们在表4.1的西瓜数据集2.0上增加两个连续属性“密度”和“含糖率”，得到表4.3所示的西瓜数据集3.0。 下面我们用这个数据集来生成一棵决策树。</p>
<p>对属性“密度”，在决策树学习开始时，根结点包含的17个训练样本在该属性上取值均不同。根据式(4.7)，该属性的候选划分点集合包含16个候选值：T密度={}.由式(4.8)可计算出属性“密度”的信息增益为0.262，对应于划分点0.381。</p>
<p>对属性“含糖率”，其候选划分点集合也包含16个候选值：T含糖率={}.类似的，根据式(.8)可计算出其信息增益为0.349,对应于划分点0.126。</p>
<p>再由4.2.l 节可知，表4.3 的数据上各属性的信息增益为</p>
<p>于是，“纹理”被选作根结点划分属性，此后结点划分过程递归进行，最终生成如图4.8 所示的决策树。</p>
<p>需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。</p>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>现实任务中常会遇到不完整样本即样本的某些属性值缺失。例如由于诊测成本、隐私保护等因素，患者的医疗数据在某些属性上的取值(如HIV测试结果)未知；尤其是在属性数目较多的情况下，往往会有大量样本出现缺失值如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，显然是对数据信息极大的浪费。例如，表4.4 是表4.1 中的西瓜数据集2.0 出现缺失值的版本，如果放弃不完整样本，则仅有编号{4, 7, 14, 16}的4个样本能被使用。显然，有必要考虑利用有缺失属性值的训练样例来进行学习。</p>
<p>我们需解决两个问题： (1)如何在属性值缺失的情况下进行划分属性选择？(2)给定划分属性？ 若样本在该属性上的值缺失，如何对样本进行划分？</p>
<p>给定训练集D 和属性a，令D 表示D 中在属性a 上没有缺失值的样本子集。对问题(1)，显然我们仅可根据D 来判断属性a 的优劣。假定属性a 有V个可取值{a1，a2，…，av}，令Dv 表示D 中在属性a 上取值为av 的样本子集，Dk表示D 中属于第k 类））的样本子集，则显然有D，假定我们为每个样本 x 赋予一个权重 wx，并定义</p>
<p>直观地看，对属性a，ρ 表示无缺失值样本所占的比例，Pk 表示无缺失值样本中第k 类所占的比例，rv 则表示无缺失值样本中在属性a 上取值d 的样本所占的比例，显然，</p>
<p>基于上述定义，我们可将信息增益的计算式(4.2)推广为</p>
<p>对问题(2)若样本x在划分属性a上的取值已知，则将x划入与其取值对应的子结点，且样本权值在子结点中保持为Wx· 若样本x 在划分属性a 上的取值未知，则将x 同时划入所有子结点，且样本权值在与属性值av 对应的子结点中调整为rv·Wx ；直观地看，这就是让同一个样本以不同的概率划入到不同的子结点中去。</p>
<p>C4.5 算法使用了上述解决方案［Quinlan, 1993］.下面我们以表4.4 的数据集为例来生成一棵决策树。</p>
<p>在学习开始时，根结点包含样本集D中全部17个样例：各样例的权值均为1，以属性“色泽”为例，该属性上无缺失值的样例子集D 包含编号为））的14个样例。显然，D的信息熵为</p>
<p>令D1, D2 与D3 分别表示在属性“色泽”上取值为“ 青绿”“乌黑”以及“浅白”的样本子集，有</p>
<p>因此，样本子集D 上属性“色泽”的信息增益为</p>
<p>于是，样本集D 上属性“色泽”的信息增益为</p>
<p>类似地可计算出所有属性在D 上的信息增益</p>
<p>“纹理”在所有属性中取得了最大的信息增益，被用于对根结点进行划分划分结果是使编号为{}））的样本进入“纹理=清晰”分支，编号为{}））的样本进入“ 纹理=稍糊”分支，而编号为{}）） 的样本进入“纹理=模糊”分支，且样本在各子结点中的权重保持为1.需注意的是，编号为{8}的样本在属性“纹理”上出现了缺失值，因此它将同时进入三个分支中，但权重在三个子结点中分别调整为主、击和去编号为{10}的样本有类似划分结果。</p>
<p>上述结点划分过程递归执行，最终生成的决策树如图4.9 所示。</p>
<h2 id="-19"><a href="#-19" class="headerlink" title></a><br></h2><h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><p>若我们把每个属性视为坐标空间中的一个坐标轴则d个属性描述的样本就对应了d维空间中的一个数据点，对样本分类则意味着在这个坐标空间中寻找不同类样本之间的分类边界。决策树所形成的分类边界有一个明显的特点：轴平行(axis-parallel)，即它的分类边界由若干个与坐标轴平行的分段组成。</p>
<p>在西瓜数据集2.0a 上基于信息增益生成的决策树</p>
<p>以表4.5中的西瓜数据3.0a为例将它作为训练集可学得图4.10所示的决策树，这棵树所对应的分类边界如图4.11所示。</p>
<p>显然，分类边界的每一段都是与坐标轴平行的这样的分类边界使得学习结果有较好的可解释性，因为每一段划分都直接对应了某个属性取值。但在学习任务的真实分类边界比较复杂时，必须使用很多段划分才能获得较好的近似，如图4.12 所示；此时的决策树会相当复杂，由于要进行大量的属性测试，预测时间开销会很大。</p>
<p>若能使用斜的划分边界，如图4.12中红色线段所示，则决策树模型将大为简化“多变量决策树”(multivariate decision tree)就是能实现这样的“斜划分”甚至更复杂划分的决策树以实现斜划分的多变量决策树为例，在此类决策树中，非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试，换言之，每个非叶结点是一个形如））的线性分类器，其中Wi是属性ai的权重，Wi和t可在该结点所含的样本集和属性集上学得于是，与传统的“单变量决策树”(univariate decision tree)不同，在多变量决策树的学习过程中，不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。例如对西瓜数据3.0a，我们可学得图4.13 这样的多变量决策树，其分类边界如图4.14 所示。</p>
<p>图4.13 在西瓜数据集3.0a 上生成的多变量决策树</p>
<p>图4.14 图4.13 多变量决策树对应的分类边界</p>
<h2 id="阅读材料-3"><a href="#阅读材料-3" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>决策树学习算法最著名的代表是ID3 ［Quinlan, 1979, 1986］、C4.5［Quinlan,1993］和I CART ［Breiman et al., 1984］.［Murthy, 1998］提供了一个关于决策树文献的阅读指南.C4.5Rule 是一个将C4.5 决策树转化为符号规则的算法［Quinlan, 1993］，决策树的每个分支可以容易地重写为一条规则，但C4.5Rule算法在转化过程中会进行规则前件合并、删减等操作，因此最终规则集的泛化性能甚至可能优于原决策树。</p>
<p>在信息增益、增益率、基尼指数之外，人们还设计了许多其他的准则用于决策树划分选择，然而有实验研究表明［Mingers, 1989］，这些准则虽然对决策树的尺寸有较大影响，但对泛化性能的影响很有限.［Raileanu and Stoffel,2004］对信息增益和基尼指数进行的理论分析也显示出，它们仅在2% 的情况下会有所不同.4.3 节介绍了决策树剪枝的基本策略； 剪枝方法和程度对决策树泛化性能的影响相当显著，有实验研究表明［Mingers, 1989］，在数据带有噪声时通过剪枝甚至可将决策树的泛化性能提高25%。</p>
<p>多变量决策树算法主要有OCl ［Murthy et al., 1994］和［Bradley and Utgoff,1995］提出的一系列算法OCl先贪心地寻找每个属性的最优权值，在局部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界；［Bradleyand Utgoff, 1995］则直接引入了线性分类器学习的最小二乘法。还有一些算法试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如“感知机树”(Perceptron tree) ［Utgoff, 1989b］在决策树的每个叶结点上训练一个感知机，而［Guo and Gelfand, 1992］则直接在叶结点上嵌入多层神经网络。</p>
<p>有一些决策树学习算法可进行“增量学习”(incremental learning)，即在接收到新样本后可对已学得的模型进行调整，而不用完全重新学习。主要机制是通过调整分支路径上的划分属性次序来对树进行部分重构，代表性算法有ID4［Schlimmer and Fisher, 1986］、ID5R［Utgoff, 1989a］、ITI［Utgoff et al.,1997］ 等。增量学习可有效地降低每次接收到新样本后的训练、时间开销，但多步增量学习后的模型会与基于全部数据训练而得的模型有较大差别。</p>
<h3 id="休息一会儿-3"><a href="#休息一会儿-3" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：决策树与罗斯·昆兰</p>
<p>说起决策树学习，就必然要谈到澳大利亚计算机科学家罗斯·昆兰(J.Ross Quinlan, 1943-)。</p>
<p>最初的决策树算法是心理学家兼计算机科学家E.B。Hunt 1962年在研究人类的概念学习过程时提出的CLS(Concept Learning System)，这个算法确立了决策树“分而治之”的学习策略。罗斯。昆兰在Hunt 的指导下于1968年在美国华盛顿大学获得计算机博士学位，然后到悉尼大学任教.1978年他在学术假时到斯坦福大学访问，选修了图灵的助手D.Michie 开设的一门研究生课程课上有一个大作业，要求写程序来学习出完备正确的规则，以判断国际象棋残局中一方是否会在两步棋后被将死。昆兰写了一个类似于CLS 的程序来完成作业，其中最重要的改进是引入了信息增益准则。后来他把这个工作整理出来在1979年发表，这就是ID3 算法。</p>
<p>1986年Machine Leaming 杂志创刊，昆兰应邀在创刊号上重新发表了ID3算法，掀起了决策树研究的热潮。短短几年间众多决策树算法问世，ID4 、ID5等名字迅速被其他研究者提出的算法占用，昆兰只好将自已的ID3 后继算法命名为C4.0，在此基础上进一步提出了著名的C4.5。有趣的是，昆兰自称C4.5 仅是对C4.0 做了些小改进，因此将它命名为“第4.5 代分类器”，而将后续的商业化版本称为C5.0。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第5章-神经网络"><a href="#第5章-神经网络" class="headerlink" title="第5章 神经网络"></a>第5章 神经网络</h1><h2 id="-20"><a href="#-20" class="headerlink" title></a><br></h2><h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><p>神经网络(neural networks)方面的研究很早就已出现，今天“神经网络”已是一个相当大的、多学科交叉的学科领域。各相关学科对神经网络的定义多种多样，本书采用目前使用得最广泛的一种，即“神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应”［Kohonen, 1988］.我们在机器学习中谈论神经网络时指的是“神经网络学习”，或者说，是机器学习与神经网络这两个学科领域的交叉部分。</p>
<p>神经网络中最基本的成分是神经元(neuron)模型，即上述定义中的“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值”(threshold)，那么它就会被激活，即“兴奋”起来，向其他神经元发送化学物质。</p>
<p>1943年，［McCulloch and Pitts, 1943］将上述情形抽象为图5.1所示的简单模型，这就是一直沿用至今的“M-P神经元模型”。在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数”(activation function)处理以产生神经元的输出。</p>
<p>理想中的激活函数是图5.2(a)所示的阶跃函数，它将输入值映射为输出值“0”或“1”，显然“1”对应于神经元兴奋，“0”对应于神经元抑制，然而，阶跃函数具有不连续、不光滑等不太好的性质，因此实际常用Sigmoid函数作为激活函数。典型的Sigmoid 函数如图5.2(b)所示，它把可能在较大范围内变化的输入值挤压到(0,1)输出值范围内，因此有时也称为“挤压函数”(squashing function)。</p>
<p>把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。</p>
<p>事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模拟了生物神经网络，只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，例如）） 相互(嵌套)代入而得。有效的神经网络学习算法大多以数学证明为支撑。</p>
<h2 id="-21"><a href="#-21" class="headerlink" title></a><br></h2><h2 id="感知机与多层网络"><a href="#感知机与多层网络" class="headerlink" title="感知机与多层网络"></a>感知机与多层网络</h2><p>感知机(Perceptron)由两层神经元组成，如图5.3所示，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，亦称“阈值逻辑单元”(threshold logic unit)。</p>
<p>感知机能容易地实现逻辑与、或、非运算。注意到）），假定f 是图5.2 中的阶跃函数，有</p>
<p>更一般地，给定训练数据集，权重））以及阈值θ可通过学习得到。阈值。可看作一个固定输入为-1.0 的“哑结点”(dummy node)所对应的连接权重Wn+l，这样，权重和阈值的学习就可统一为权重的学习。感知机学习规则非常简单，对训练样例(x,y)，若当前感知机的输出为y，则感知机权重将这样调整：</p>
<p>其中称为学习率(learning rate).从式(5.1)可看出，若感知机对训练样例(x,y)预测正确，即y=y，则感知机不发生变化，否则将根据错误的程度进行权重调整。</p>
<p>需注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元(functional neuron)，其学习能力非常有限。事实上，上述与、或、非问题都是线性可分(linearly separable)的问题。可以证明［Minsky and Papert,1969］，若两类模式是线性可分的，即存在一个线性超平面能将它们分开，如图5.4(a)-(c)所示，则感知机的学习过程一定会收敛(converge)而求得适当的权向量w=(w1;wz;…;Wn+1)；否则感知机学习过程将会发生振荡(fluctuation),w难以稳定下来，不能求得合适解，例如感知机甚至不能解决如图5.4(d)所示的异或这样简单的非线性可分问题。</p>
<p>图5.4 线性可分的“与” “或” “非”问题与非线性可分的“异或”问题</p>
<p>要解决非线性可分问题，需考虑使用多层功能神经元。例如图5.5中这个简单的两层感知机就能解决异或问题。在图5.5(a)中，输出层与输入层之间的一层神经元，被称为隐层或隐含层(hidden layer)，隐含层和输出层神经元都是拥有激活函数的功能神经元。</p>
<p>更一般的，常见的神经网络是形如图5.6所示的层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为“多层前馈神经网络”(multi-layer feedforward neuralnetworks)，其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出，换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。因此，图5.6(a)通常被称为“两层网络”。为避免歧义，本书称其为“单隐层网络”。只需包含隐层，即可称为多层网络。神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”(connection weight)以及每个功能神经元的阈值；换言之，神经网络“学”到的东西，蕴涵在连接权与阈值中。</p>
<h2 id="-22"><a href="#-22" class="headerlink" title></a><br></h2><h2 id="误差逆传播算法"><a href="#误差逆传播算法" class="headerlink" title="误差逆传播算法"></a>误差逆传播算法</h2><p>多层网络的学习能力比单层感知机强得多。欲训练多层网络，式(5.1)的简单感知机学习规则显然不够了，需要更强大的学习算法。误差逆传播(errorBackPropagation，简称BP)算法就是其中最杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中使用神经网络时，大多是在使用BP算法进行训练。值得指出的是，BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，例如训练递归神经网络［Pineda, 1987］.但通常说“BP网络”时3一般是指用BP算法训练的多层前馈神经网络。</p>
<p>下面我们来看看BP算法究竟是什么样给定训练集D=）），即输入示例由d个属性描述，输出𝒍维实值向量。为便于讨论，图5.7给出了一个拥有d个输入神经元、𝒍个输出神经元、q个隐层神经元的多层前馈网络结构，其中输出层第j个神经元的阈值用θj表示，隐层第h个神经元的阙值用旧表示。输入层第i个神经元与隐层第h个神经元之间的连接权为𝓥hj，隐层第h个神经元与输出层第h个神经元之间的连接权为𝓦hj，记隐层第h个神经元接收到的输入为）），输出层第3个神经元接收到的输入为）），其中bh为隐层第h个神经元的输出假设隐层和输出层神经元都使用图5.2(b)中的Sigmoid 函数。</p>
<p>对训练例(Xk, Yk)，假定神经网络的输出为）），即</p>
<p>则网络在(Xk, Yk)，如上的均方误差为</p>
<p>图5.7 的网络中有））个参数需确定：输入层到隐层的d × q个权值、隐层到输出层的q × 𝒍个权值、q个隐层神经元的阈值、𝒍个输出层神经元的阈值。BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计，即与式(5.1)类似，任意参数𝒗的更新估计式为</p>
<p>下面我们以图5.7 中隐层到输出层的连接权w均为例来进行推导。</p>
<p>BP算法基于梯度下降(gradient descent)策略，以目标的负梯度方向对参数进行调整。对式(5.4)的误差Ek，给定学习率η，有</p>
<p>注意到𝓦hj先影响到第j个输出层神经元的输入值βj，再影响到其输出值件，然后影响到Ek，有</p>
<p>根据岛的定义，显然有</p>
<p>图5.2 中的Sigmoid 函数有一个很好的性质：</p>
<p>于是根据式(5.4)和(5.3)，有</p>
<p>将式(5.10)和(5.8)代入式(5.7)，再代入式(5.6)，就得到了BP算法中关于𝓦hj的更新公式</p>
<p>学习率η∈(0,1)控制着算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。有时为了做精细调节，可令式(5.11)与(5.12)使用η1，式(5.13)与(5.14)使用η2，两者未必相等。</p>
<p>图5.8给出了BP算法的工作流程。对每个训练样例，BP算法执行以下操作。先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果；然后计算输出层的误差(第4-5行)，再将误差逆向传播至隐层神经元(第6行)，最后根据隐层神经元的误差来对连接权和阈值进行调整(第7行)。该迭代过程循环进行，直到达到某些停止条件为止，例如训练误差已达到一个很小的值。图5.9给出了在2个属性、5个样本的西瓜数据上，随着训练轮数的增加，网络参数和分类边界的变化情况。</p>
<p>需注意的是，BP算法的目标是要最小化训练集D上的累积误差</p>
<p>但我们上面介绍的“标准BP算法”每次仅针对一个训练样例更新连接权和阈值，也就是说，图5.8 中算法的更新规则是基于单个的Ek 推导而得。如果类似地推导出基于累积误差最小化的更新规则，就得到了累积误差逆传播(accumulated error backpropagation)算法。累积BP算法与标准BP算法都很常用。一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现“抵消”现象因此，为了达到同样的累积误差极小点，标准BP算法往往需进行更多次数的迭代累积BP算法直接针对累积误差最小化它在读取整个训练集D一遍后才对参数进行更新，其参数更新的频率低得多。但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显。</p>
<p>［Hornik et al., 1989］证明，只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数然而如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠“试错法” (trial-by-error)调整。</p>
<p>正是由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两种策略常用来缓解BP 网络的过拟合第一种策略是“早停” (early stopping)：将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。第二种策略是“正则化”(regularization) ［Barron, 1991; Girosi et al., 1995］，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。仍令Ek 表示第k个训练样例上的误差，叫表示连接权和阈值，则误差目标函数(5.16）改变为</p>
<p>其中λ∈(0,1)用于对经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。</p>
<h2 id="-23"><a href="#-23" class="headerlink" title></a><br></h2><h2 id="全局最小与局部极小"><a href="#全局最小与局部极小" class="headerlink" title="全局最小与局部极小"></a>全局最小与局部极小</h2><p>若用E 表示神经网络在训练集上的误差，则它显然是关于连接权w 和阈值。的函数。此时，神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得E 最小。</p>
<p>我们常会谈到两种“最优”：“局部极小”(local minimum)和“全局最小”(global minimum).对w＊和θ＊若存在E＞0 使得</p>
<p>都有））成立，则））为局部极小解；若对参数空间中的任意））都有）），则））为全局最小解。直观地看，局部极小解是参数空间中的某个点其邻域点的误差函数值均不小于该点的函数值；全局最小解则是指参数空间中所有点的误差函数值均不小于该点的误差函数值。两者对应的E））分别称为误差函数的局部极小值和全局最小值。</p>
<p>显然，参数空间内梯度为零的点，只要其误差函数值小子邻点的误差函数值，就是局部极小点；可能存在多个局部极小值，但却只会有一个全局最小值。也就是说，“全局最小”一定是“局部极小”，反之则不成立。例如.图5.10中有两个局部极小，但只有其中之一是全局最小。显然，我们在参数寻优过程中是希望找到全局最小。</p>
<p>基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值每次迭代中，我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。若误差函数在当前点的梯度为零，则已达到局部极小，更新量将为零，这意味着参数的迭代更新将在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小；然而，如果误差函数具有多个局部极小，则不能保证找到的解是全局最小。对后一种情形，我们称参数寻优陷入了局部极小，这显然不是我们所希望的</p>
<p>在现实任务中，人们常采用以下策略来试图“跳出”局部极小，从而进一步接近全局最小。</p>
<p>•以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。</p>
<p>•使用“模拟退火”(simulated annealing)技术［Aarts and Korst, 1989］。模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。在每步i是代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。</p>
<p>•使用随机梯度下降与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索。</p>
<p>此外，遗传算法(genetic algorithms) ［Goldberg, 1989］也常用来训练神经网络以更好地逼近全局最小。需注意的是，上述用于跳出局部极小的技术大多是启发式，理论上尚缺乏保障。</p>
<h2 id="-24"><a href="#-24" class="headerlink" title></a><br></h2><h2 id="其他常见神经网络"><a href="#其他常见神经网络" class="headerlink" title="其他常见神经网络"></a>其他常见神经网络</h2><p>神经网络模型、算法繁多本节不能详尽描述只对特别常见的几种网络稍作简介。</p>
<h3 id="RBF网络"><a href="#RBF网络" class="headerlink" title="RBF网络"></a>RBF网络</h3><p>RBF(Radial Basis Function，径向基函数网络［Broomhead and Lowe,1988］是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。假定输入为d 维向量z，输出为实值，则RBF 网络可表示为</p>
<p>其中q为隐层神经元个数，Ci和𝓦i分别是第i个隐层神经元所对应的中心和权重，p(x,ci)是径向基函数，这是某种沿径向对称的标量函数，通常定义为样本x到数据中心Ci之间欧氏距离的单调函数。常用的高斯径向基函数形如</p>
<p>［Park and Sandberg, 1991］ 证明，具有足够多隐层神经元的RBF 网络能以任意精度逼近任意连续函数。</p>
<p>通常采用两步过程来训练RBF 网络：第一步，确定神经元中心Ci，常用的方式包括随机采样、聚类等; 第二步，利用BP算法等来确定参数𝓦和𝝱。</p>
<h3 id="ART网络"><a href="#ART网络" class="headerlink" title="ART网络"></a>ART网络</h3><p>竞争型学习(competitive learning)是神经网络中一种常用的无监督学习策略，在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制这种机制亦称“胜者通吃”(winner-take-all)原则。</p>
<p>ART(Adaptive Resonance Theory)，自适应谐振理论网络［Carpenter and Grossberg, 1987］是竞争型学习的重要代表。该网络由比较层、识别层、识别阈值和重置模块构成。其中，比较层负责接收输入样本，并将其传递给识别层神经元识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类。</p>
<p>在接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元竞争的最简单方式是计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离距离最小者胜获胜神经元将向其他识别层神经元发送信号，抑制其激活若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本将被归为该代表向量所属类别，同时，网络连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的相似度，从而使该获胜神经元有更大可能获胜；若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量就设置为当前输入向量。</p>
<p>显然，识别阈值对ART网络的性能有重要影响。当识别阈值较高时，输入样本将会被分成比较多、比较精细的模式类，而如果识别阈值较低，则会产生比较少、比较粗略的模式类。</p>
<p>ART 比较好地缓解了竞争型学习中的“可塑性－稳定性窘境”(stability-plasticity dilemma)，可塑性是指神经网络要有学习新知识的能力，而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆这就使得ART 网络具有一个很重要的优点：可进行增量学习(incremental learning)或在线学习(online learning)。</p>
<p>早期的ART网络只能处理布尔型输入数据，此后ART发展成了一个算法族，包括能处理实值输入的ART2网络、结合模糊处理的Fuzzy ART网络，以及可进行监督学习的ARTMAP网络等。</p>
<h3 id="SOM网络"><a href="#SOM网络" class="headerlink" title="SOM网络"></a>SOM网络</h3><p>SOM(Self-Organizing Map，自组织映射)网络［Kohonen, 1982］是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间(通常为二维)，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。</p>
<p>如图5.11 所示，SOM 网络中的输出层神经元以矩阵方式排列在三维空间中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置.SOM 的训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。</p>
<p>SOM 的训练过程很简单：在接收到一个训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离距离最近的神经元成为竞争获胜者，称为最佳匹配单元(best matching unit).然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小。这个过程不断迭代，直至收敛。</p>
<h3 id="级联相关网络"><a href="#级联相关网络" class="headerlink" title="级联相关网络"></a>级联相关网络</h3><p>一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阈值等参数。与此不同，结构自适应网络则将网络结构也当作学习的目标之一并希望能在训练过程中找到最符合数据特点的网络结构。级联相关(Cascade-Correlation)网络［Fahlman and Lebiere, 1990］是结构自适应网络的重要代表。</p>
<p>图5.12 级联相关网络的训练过程。新的隐结点加入时，红色连接权通过最大化新结点的输出与网络误差之间的相关性来进行训练</p>
<p>级联相关网络有两个主要成分：“级联”和“相关”。级联是指建立层次连接的层级结构。在开始训练时，网络只有输入层和输出层，处于最小拓扑结构；随着训练的进行，如图5.12所示，新的隐层神经元逐渐加入，从而创建起层级结构。当新的隐层神经元加入时，其输入端连接权值是冻结固定的相关是指通过最大化新神经元的输出与网络误差之间的相关性(correlation)来训练相关的参数。</p>
<p>与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。</p>
<h3 id="Elman网络"><a href="#Elman网络" class="headerlink" title="Elman网络"></a>Elman网络</h3><p>与前馈神经网络不同，“递归经网络”(recurrent neural networks)允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号。这样的结构与信息反馈过程，使得网络在t 时刻的输出状态不仅与t 时刻的输入有关，还与t-1 时刻的网络状态有关，从而能处理与时间有关的动态变化。</p>
<p>Elman 网络［Elman, 1990］是最常用的递归神经网络之一，其结构如图5.13所示，它的结构与多层前馈网络很相似，但隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入。隐层神经元通常采用Sigmoid 激活函数，而网络的训练则常通过推广的BP算法进行［Pineda，1987］。</p>
<h3 id="Boltzmann机"><a href="#Boltzmann机" class="headerlink" title="Boltzmann机"></a>Boltzmann机</h3><p>神经网络中有一类模型是为网络状态定义一个“能量”(energy)，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。Boltzmann 机［Ackley et al., 1985］就是一种“基于能量的模型”(energy-based model)，常见结构如图5.14(a)所示，其神经元分为两层：显层与隐层。显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达.Boltzmann 机中的神经元都是布尔型的，即只能取0、1 两种状态，状态1表示激活，状态0表示抑制。令向量s∈{0,1}n 表示n个神经元的状态，Wij 表示神经元i与j 之间的连接权，θi表示神经元i的阈值，则状态向量s 所对应的Boltzmann 机能量定义为</p>
<p>若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到Boltzmann 分布，此时状态向量s 出现的概率将仅由其能量与所有可能状态向量的能量确定：</p>
<p>Boltzmann 机的训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大标准的Boltzmann 机是一个全连接图，训练网络的复杂度很高，这使其难以用于解决现实任务。现实中常采用受限Boltzmann机(Restricted Boltzmann Machine，简称RBM).如图5.14(b)所示，受限Boltzmann机仅保留显层与隐层之间的连接从而将Boltzmann 机结构由完全图简化为二部图。</p>
<p>受限Boltzmann 机常用“对比散度” (Contrastive Divergence，简称CD)算法来进行训练。假定网络中有d个显层神经元和q个隐层神经元，令v 和h 分别表示显层与隐层的状态向量，则由于同一层内不存在连接，有</p>
<p>CD 算法对每个训练样本v，先根据式(5.23)计算出隐层神经元状态的概率分布，然后根据这个概率分布采样得到h； 此后，类似地根据式(5.22)从h 产生v’，再从v＇产生h＇； 连接权的更新公式为</p>
<h2 id="-25"><a href="#-25" class="headerlink" title></a><br></h2><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>理论上来说，参数越多的模型复杂度越高、“容量”(capacity)越大，这意味着它能完成更复杂的学习任务。但一般情形下，复杂模型的训练效率低，易陷入过拟合，因此难以受到人们青睐。而随着云计算、大数据时代的到来，计算能力的大幅提高可缓解训练低效性，训练数据的大幅增加则可降低过拟合风险，因此，以“深度学习”(deep learning)为代表的复杂模型开始受到人们的关注。</p>
<p>典型的深度学习模型就是很深层的神经网络。显然，对神经网络模型，提高容量的一个简单办法是增加隐层的数目。隐层多了，相应的神经元连接权、阐值等参数就会更多。模型复杂度也可通过单纯增加隐层神经元的数目来实现3前面我们谈到过，单隐层的多层前馈网络已具有很强大的学习能力；但从增加模型复杂度的角度来看：增加隐层的数目显然比增加隐层神经元的数目更有效3因为增加隐层数不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌套的层数。然而，多隐层神经网络难以直接用经典算法(例如标准BP算法进行训练，因为误差在多隐层内逆传播时，往往会“发散”(diverge)而不能收敛到稳定状态。</p>
<p>无监督逐层训练(unsupervised layer-wise training)是多隐层网络训练的有效手段，其基本思想是每次训练一层隐结点： 训练时将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这称为“预训练”(pre-training)；在预训练全部完成后，再对整个网络进行“微调”(fine-tuning)训练例如，在深度信念网络(deep belief network，简称DBN) ［Hintonet al., 2006］ 中，每层都是一个受限Boltzmann 机，即整个网络可视为若干个RBM堆叠而得在使用无监督逐层训练时，首先训练第一层，这是关于训练样本的RBM模型，可按标准的RBM 训练；然后，将第一层预训练好的隐结点视为第二层的输入结点，对第二层进行预训练； …… 各层预训练完成后，再利用B P算法等对整个网络进行训练。</p>
<p>事实上，“预训练+微调”的做法可视为将大量参数分组，对每组先找到局部看来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优。这样就在利用了模型大量参数所提供的自由度的同时，有效地节省了训练开销。</p>
<p>另一种节省训练开销的策略是“权共享”(weight sharing)，即让一组神经元使用相同的连接权－ 这个策略在卷积神经网络(Convolutional NeuralNetwork，简称CNN) ［LeCun and Bengio］中发挥了重要作用。以CNN 进行手写数字识别任务为例［LeCun et al., 1998］，如图5.15所示，网络输入是一个32 × 32 的手写数字图像，输出是其识别结果，CNN 复合多个“卷积层”和“采样层”对输入信号进行加工，然后在连接层实现与输出目标之间的映射。每个卷积层都包含多个特征映射(feature map)，每个特征映射是一个由多个神经元构成的“平面”，通过一种卷积滤波器提取输入的一种特征。例如，图5.15 中第一个卷积层由6个特征映射构成，每个特征映射是一个28 × 28 的神经元阵列，其中每个神经元负责从5 × 5 的区域通过卷积晦波器提取局部特征。采样层亦称为“汇合”(pooling)层，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息。例如图5.15 中第一个采样层有6个14 × 14 的特征映射，其中每个神经元与上一层中对应特征映射的2 × 2 邻域相连，并据此计算输出通过复合卷积层和采样层，图5.15 中的CNN 将原始图像映射成120 维特征向量，最后通过一个由84个神经元构成的连接层和输出层连接完成识别任务.CNN 可用BP算法进行训练，但在训练中，无论是卷积层还是采样层，其每一组神经元(即图5.15中的每个“平面”)都是用相同的连接权，从而大幅减少了需要训练的参数数目。</p>
<p>我们可以从另一个角度来理解深度学习。无论是DBN还是CNN，其多隐层堆叠、每层对上一层的输出进行处理的机制，可看作是在对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化成与输出目标联系更密切的表示使得原来仅基于最后一层输出映射难以完成的任务成为可能－换言之，通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示后，用“简单模型”即可完成复杂的分类等学习任务。由此可将深度学习理解为进行“特征学习”(feature learning)或“表示学习”(representation learning)。</p>
<p>以往在机器学习用于现实任务时，描述样本的特征通常需由人类专家来设计，这称为“特征工程”(feature engineering).众所周知，特征的好坏对泛化性能有至关重要的影响，人类专家设计出好特征也并非易事，特征学习则通过机器学习技术自身来产生好特征，这使机器学习向“全自动数据分析”又前进了一步。</p>
<h2 id="阅读材料-4"><a href="#阅读材料-4" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>［Haykin, 1998］是很好的神经网络教科书，［Bishop, 1995］则偏重于机器学习和模式识别。神经网络领域的主流学术期刊有Neural Computation 、NeuralNetworks 、IEEE Trans actions on Neural Networks aηd Learning Systems;主要国际学术会议有国际神经信息处理系统会议(NIPS)和国际神经网络联合会议(IJCNN)，区域性国际会议主要有欧洲神经网络会议(ICANN)和亚太神经网络会议(ICONIP)。</p>
<p>M-P神经元模型使用最为广泛，但还有一些神经元模型也受到关注，如考虑了电位脉冲发放时间而不仅是累积电位的脉冲神经元(spiking neuron)模型［Gerstner and Kistler, 2002］。</p>
<p>BP算法由［Werbos, 1974］首先提出，此后［Rumelhart et al., 1986a,b］重新发明.BP算法实质是LMS (Least Mean Square)算法的推广.LMS试图使网络的输出均方误差最小化，可用于神经元激活函数可微的感知机学习；将LMS推广到由非线性可微神经元组成的多层前馈网络，就得到BP算法，因此BP算法亦称广义𝞭规则［Chauvin and Rumelhart, 1995］。</p>
<p>［MacKay，1992］在贝叶斯框架下提出了自动确定神经网络正则化参数的方法.［Gori and Tesi, 1992］ 对BP网络的局部极小问题进行了详细讨论.［Yao,1999］综述了利用以遗传算法为代表的演化计算(evolutionary computation)技术来生成神经网络的研究工作。对BP算法的改进有大量研究，例如为了提速，可在训练过程中自适应缩小学习率，即先使用较大的学习率然后逐步缩小，更多“窍门”(trick可参阅［Reed and Marks, 1998; Orr and Muller, 1998］。</p>
<p>关于RBF 网络训练过程可参阅［Schwenker et al，2001］.［Carpenter and Grossberg, 1991］介绍了ART 族算法.SOM 网络在聚类、高维数据可视化、图像分割等方面有广泛应用，可参阅［Kohonen, 2001］.［Bengio et al., 2013］综述了深度学习方面的研究进展。</p>
<p>神经网络是一种难解释的“黑箱模型”，但已有一些工作尝试改善神经网络的可解释性，主要途径是从神经网络中抽取易于理解的符号规则，可参阅［Tickle et al., 1998; Zhou, 2004］。</p>
<h3 id="休息一会儿-4"><a href="#休息一会儿-4" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：神经网络的几起几落</p>
<p>二十世纪四十年代M-P 神经元模型、Hebb 学习律出现后，五十年代出现了以感知机、Adaline 为代表的一系列成果，这是神经网络发展的第一个高潮期。不幸的是，MIT 计算机科学研究的奠基人马文·闵斯基(MarvinMinsky, 1927-2016)与Seymour Papert 在1969年出版了《感知机》一书，书中指出，单层神经网络无法解决非线性问题，而多层网络的训练算法尚看不到希望。这个论断直接使神经网络研究进入了“冰河期”，美国和苏联均停止了对神经网络研究的资助，全球该领域研究人员纷纷转行，仅剩极少数人坚持下来。哈佛大学的Paul Werbos 在1974年发明BP算法时，正值神经网络冰河期，因此未受到应有的重视。</p>
<p>1983年，加州理工学院的物理学家John Hopfield 利用神经网络，在旅行商问题这个NP完全问题的求解上获得当时最好结果，引起了轰动。稍后，UCSD的D avid Rumelhart 与James McClelland领导的PDP小组出版了《并行分布处理·认知微结构的探索》一书，Rumelhart等人重新发明了BP算法，由于当时正处于Hopfield带来的兴奋之中，BP算法迅速走红。这掀起了神经网络的第二次高潮。二十世纪九十年代中期，随着统计学习理论和支持向量机的兴起，神经网络学习的理论性质不够清楚、试错性强、在使用中充斥大量“窍门”(trick)的弱点更为明显，于是神经网络研究又进入低谷，NIPS 会议甚至多年不接受以神经网络为主题的论文。</p>
<p>2010年前后，随着计算能力的迅猛提升和大数据的涌现，神经网络研究在“深度学习”的名义下又重新崛起，先是在ImageNet等若干竞赛上以大优势夺冠，此后谷歌、百度、脸书等公司纷纷投入巨资进行研发，神经网络迎来了第三次高潮。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第6章-支持向量机"><a href="#第6章-支持向量机" class="headerlink" title="第6章 支持向量机"></a>第6章 支持向量机</h1><h2 id="间隔与支持向量"><a href="#间隔与支持向量" class="headerlink" title="间隔与支持向量"></a>间隔与支持向量</h2><p>给定训练样本集D=}，分类学习最基本的想法就是基于训练集D 在样本空间中找到一个划分超平面，将不同类别的样本分开但能将训练样本分开的划分超平面可能有很多，如图6.1所示，我们应该努力去找到哪一个呢？</p>
<p>直观上看，应该去找位于两类训练样本“正中间”的划分超平面，即图6.1中红色的那个，因为该划分超平面对训练样本局部扰动的“容忍”性最好。例如，由于训练集的局限性或噪声的因素，训练集外的样本可能比图6.1 中的训练样本更接近两个类的分隔界，这将使许多划分超平面出现错误，而红色的超平面受影响最小。换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见示例的泛化能力最强。</p>
<p>在样本空间中，划分超平面可通过如下线性方程来描述：</p>
<p>其中w为法向量，决定了超平面的方向；b为位移项，决定了超平面与原点之间的距离。显然，划分超平面可被法向量w 和位移b 确定，下面我们将其记为(w,b)。样本空间中任意点二到超平面(w,b)的距离可写为</p>
<p>假设超平面(w, b)能将训练样本正确分类，</p>
<p>如图6.2所示，距离超平面最近的这几个训练样本点使式(6.3)的等号成立，它们被称为“支持向量”(support vector)，两个异类支持向量到超平面的距离之和为</p>
<p>它被称为“间隔”(margin)。</p>
<p>欲找到具有“最大间隔”(maximum margin)的划分超平面，也就是要找到能满足式(6.3)中约束的参数w和b，使得γ最大，即</p>
<p>显然，为了最大化间隔，仅需最大化|w|, 这等价于最小化|w|，于是，式(6.5)可重写为</p>
<p>这就是支持向量HL(Support Vector Machine，简称SVM)的基本型</p>
<h2 id="-26"><a href="#-26" class="headerlink" title></a><br></h2><h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>我们希望求解式(6.6)来得到大间隔划分超平面所对应的模型</p>
<p>其中w 和b 是模型参数。注意到式(6.6)本身是一个凸二次规划(convex quadratic programming)问题，能直接用现成的优化计算包求解，但我们可以有更高效的办法。</p>
<p>对式(6.6)使用拉格朗日乘子法可得到其“对偶问题”(dual problem).具体来说，对式(6.6)的每条约束添加拉格朗日乘子 ai≥0，则该问题的拉格朗日函数可写为</p>
<p>其中））.令L(w,b,a)对w和b的偏导为零可得</p>
<p>将式(6.9)代入(6.8)，即可将L(w,b,a)中的w 和b 消去，再考虑式(6.10)的约束，就得到式(6.6)的对偶问题</p>
<p>解出a 后，求出w 与b 即可得到模型</p>
<p>从对偶问题(6.11)解出的句是式(6.8)中的拉格朗日乘子，它恰对应着训练样本(xi,Yi)注意到式(6.6)中有不等式约束，因此上述过程需满足KKT(Karush-Kuhn-Tucker)条件，即要求</p>
<p>于是，对任意训练样本(xi,Yi)，总有ai=0或f(xi)=l.若ai=0，则该样本将不会在式(6.12)的求和中出现，也就不会对f(x)有任何影响；若a＞0,则必有）），所对应的样本点位于最大间隔边界上，是一个支持向量。这显示出支持向量机的一个重要性质。训练完成后，大部分的训练样本都不需保留，最终模型仅与支持向量有关。</p>
<p>那么，如何求解式(6.11)呢？不难发现，这是一个二次规划问题，可使用通用的二次规划算法来求解；然而，该问题的规模正比于训练样本数，这会在实际任务中造成很大的开销。为了避开这个障碍，人们通过利用问题本身的特性，提出了很多高效算法，SMO(Sequential Minimal Optimization)是其中一个著名的代表［Platt, 1998］。</p>
<p>SMO 的基本思路是先固定ai之外的所有参数，然后求向上的极值。由于存在约束，若固定向之外的其他变量，则ai 可由其他变量导出于是，SMO 每次选择两个变量岛和句，并固定其他参数。这样，在参数初始化后，SMO 不断执行如下两个步骤直至收敛：</p>
<p>•选取一对需更新的变量ai和aj;</p>
<p>•固定向和a3 以外的参数，求解式(6.11)获得更新后的问和aj;</p>
<p>注意到只需选取的az 和a3 中有一个不满足KKT 条件(6.13)，目标函数就会在迭代后增大［Osuna et al., 1997］.直观来看，KKT 条件违背的程度越大，则变量更新后可能导致的目标函数值增幅越大于是SMO 先选取违背KKT条件程度最大的变量第二个变量应选择一个使目标函数值增长最快的变量，但由于比较各变量所对应的目标函数值增幅的复杂度过高，因此SMO采用了一个启发式。使选取的两变量所对应样本之间的间隔最大。一种直观的解释是，这样的两个变量有很大的差别，与对两个相似的变量进行更新相比，对它们进行更新会带给目标函数值更大的变化。</p>
<p>SMO 算法之所以高效，恰由于在固定其他参数后，仅优化两个参数的过程能做到非常高效。具体来说，仅考虑ai和aj 时，式(6.11)中的约束可重写为</p>
<p>消去式(6.11)中的变量句，则得到一个关于向的单变量二次规划问题，仅有的约束是ai≥0.不难发现，这样的二次规划问题具有闭式解，于是不必调用数值优化算法即可高效地计算出更新后的ai和aj。</p>
<p>如何确定偏移项b 呢？注意到对任意支持向量）），如都有））即</p>
<p>其中s=））为所有支持向量的下标集。理论上，可选取任意支持向量并通过求解式(6.17)获得b，但现实任务中常采用一种更鲁棒的做法：使用所有支持向量求解的平均值</p>
<h2 id="-27"><a href="#-27" class="headerlink" title></a><br></h2><h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>在本章前面的讨论中，我们假设训练样本是线性可分的，即存在一个划分超平面能将训练样本正确分类。然而在现实任务中原始样本空间内也许并不存在一个能正确划分两类样本的超平面例如图6.3 中的“异或”问题就不是线性可分的。</p>
<p>对这样的问题，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。例如在图6.3中若将原始的三维空间映射到一个合适的三维空间，就能找到一个合适的划分超平面。幸运的是，如果原始空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分。</p>
<p>令𝜱(x) 表示将𝙭映射后的特征向量，于是，在特征空间中划分超平面所对应的模型可表示为</p>
<p>其中w 和b 是模型参数。类似式(6.6)，有</p>
<p>其对偶问题是</p>
<p>求解式(6.21)涉及到计算𝜱(xi)T𝜱(xj)，这是样本Xi与Xj的映射到特征空间之后的内积由于特征空间维数可能很高，甚至可能是无穷维，因此直接计算𝜱(𝒙i)T𝜱(𝒙j)通常是困难的为了避开这个障碍，可以设想这样一个函数；</p>
<p>即𝒙i与𝒙j 在特征空间的内积等于它们在原始样本空间中通过函数κ））计算的结果。有了这样的函数，我们就不必直接去计算高维甚至无穷维特征空间中的内积，于是式(6.21)可重写为</p>
<p>求解后即可得到</p>
<p>这里的函数κ））就是“核函数”(kernel function).式(6.24)显示出模型最优解可通过训练样本的核函数展开，这一展式亦称“支持向量展式”(supportvector expansion</p>
<p>显然，若已知合适映射𝜱的具体形式，则可写出核函数κ）），但在现实任务中我们通常不知道𝜱是什么形式，那么，合适的核函数是否一定存在呢？什么样的函数能做核函数呢？我们有下面的定理：</p>
<p>定理6.1 (核函数)令𝛘为输入空间，κ））是定义在𝛘×𝛘上的对称函数，则κ是核函数当且仅当对于任意数据D=）），“核矩阵”(kernel matrix) K 总是半正定的：</p>
<p>定理6.1 表明，只要一个对称函数所对应的核矩阵半正定，它就能作为核函数使用。事实上，对于－个半正定核矩阵，总能找到一个与之对应的映射𝜱换言之，任何一个核函数都隐式地定义了一个称为“再生核希尔伯特空间”(Reproducing Kernel Hilbert Space，简称RKHS)的特征空间。</p>
<p>通过前面的时论可知，我们希望样本在特征空间内线性可分，因此特征空间的好坏对支持向量机的性能至关重要。需注意的是，在不知道特征映射的形式时，我们并不知道什么样的核函数是合适的，而核函数也仅是隐式地定义了这个特征空间。于是，“核函数选择”成为支持向量机的最大变数。若核函数选择不合适，则意味着将样本映射到了一个不合适的特征空间，很可能导致性能不佳。</p>
<p>表6.1 列出了几种常用的核函数</p>
<p>此外，还可通过函数组合得到，例如：</p>
<p>•若κ1 和κ2 为核函数，则对于任意正数γ1 、γ2，其线性组合<br>也是核函数；</p>
<p>•若κ1 和κ2 为核函数，则核函数的直积</p>
<p>也是核函数；</p>
<p>•若κ1 为核函数，则对于任意函数g(x)，</p>
<p>也是核函数。</p>
<h2 id="-28"><a href="#-28" class="headerlink" title></a><br></h2><h2 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h2><p>在前面的讨论中，我们一直假定训练样本在样本空间或特征空间中是线性可分的，即存在一个超平面能将不同类的样本完全划分开然而，在现实任务中往往很难确定合适的核函数使得训练样本在特征空间中线性可分；退一步说，即便恰好找到了某个核函数使训练集在特征空间中线性可分，也很难断定这个貌似线性可分的结果不是由于过拟合所造成的。</p>
<p>缓解该问题的一个办法是允许支持向量机在一些样本上出错。为此，要引入“软间隔”(soft margin)的概念，如图6.4 所示。</p>
<p>图6.4 软问隔示意图。红色图出了一些不满足约束的样本</p>
<p>具体来说，前面介绍的支持向量机形式是要求所有样本均满足约束(6.3),即所有样本都必须划分正确，这称为“ 硬间隔”(hard margin)，而软间隔则是允许某些样本不满足约束</p>
<p>当然，在最大化间隔的同时，不满足约束的样本应尽可能少。于是，优化目标可写为</p>
<p>其中C＞0 是一个常数，f0/1 是 “0/1 损失函数”</p>
<p>显然，当C 为无穷大时，式(6.29)迫使所有样本均满足约束(6.28)，于是式(6.29)等价于(6.6)；当C 取有限值时，式(6.29)允许一些样本不满足约束。</p>
<p>然而，f0/1 非凸、非连续，数学性质不太好，使得式(6.29)不易直接求解。于是，人们通常用其他一些函数来代替f0/1，称为“替代损失”(surrogate loss)。替代损失函数一般具有较好的数学性质，如它们通常是凸的连续函数且是f0/1的上界图6.5 给出了三种常用的替代损失函数：</p>
<p>hinge 损失：<br>指数损失(exponential loss):<br>对率损失(logistic loss):</p>
<p>若采用hinge 损失，则式(6.29)变成</p>
<p>引入“松弛变量”(slack variables)≥0，可将式(6.34)重写为</p>
<p>图6.5 三种常见的替代损失函数： hinge损失、指数损失、对率损失</p>
<p>这就是常用的“软间隔支持向量机”。</p>
<p>显然，式(6.35)中每个样本都有一个对应的松弛变量，用以表征该样本不满足约束(6.28)的程度但是，与式(6.6)相似，这仍是一个二次规划问题。于是，类似式(6.8)，通过拉格朗日乘子法可得到式(6.35)的拉格朗日函数</p>
<p>其中a 是拉格朗日乘子。</p>
<p>令L的偏导为零可得</p>
<p>将式(6.37)-(6.39)代入式(6.36)即可得到式(6.35)的对偶问题</p>
<p>将式(6.40)与硬间隔下的对偶问题(6.11)对比可看出，两者唯一的差别就在于对偶变量的约束不同。前者是，后者是a,于是，可采用6.2节中同样的算法求解式(6.40)；，在引入核函数后能得到与式(6.24)同样的支持向<br>量展式。</p>
<p>类似式(6.13)，对软间隔支持向量机，KKT 条件要求</p>
<p>于是，对任意训练样本(xi,yi)；，总有））或）），若ai=0，则该样本不会对f(x)有任何影响；若ai＞0，则必有）），即该样本是支持向量：由式(6.39)可知，若ai＜C，则μi＞0，进而有𝝴i=0，即该样本恰在最大间隔边界上；若ai=C，则有μi=0，此时若））则该样本落在最大间隔内部，若 𝝴i＞1 则该样本被错误分类。由此可看出，软间隔支持向量机的最终模型仅与支持向量有关，即通过采用hinge 损失函数仍保持了稀疏性。</p>
<p>那么，能否对式(6.29)使用其他的替代损失函数呢？</p>
<p>可以发现，如果使用对率损失函数ℯ log 来替代式(6.29)中的0/1损失函数，则几乎就得到了对率回归模型(3.27.实际上，支持向量机与对率回归的优化目标相近，通常情形下它们的性能也相当。对率回归的优势主要在于其输出具有自然的概率意义，即在给出预测标记的同时也给出了概率，而支持向量机的输出不具有概率意义，欲得到概率输出需进行特殊处理［Platt, 2000］；，此外，对率回归能直接用于多分类任务，支持向量机为此则需进行推广［Hsu and Lin,2002］.另一方面，从图6.5 可看出，hinge 损失有一块“平坦”的零区域，这使得支持向量机的解具有稀疏性，而对率损失是光滑的单调递减函数，不能导出类似支持向量的概念，因此对率回归的解依赖于更多的训练样本，其预测开销更大。</p>
<p>我们还可以把式(6.29)中的0/1损失函数换成别的替代损失函数以得到其他学习模型，这些模型的性质与所用的替代函数直接相关，但它们具有一个共性;优化目标中的第一项用来描述划分超平面的“间隔”大小，另一项用来表述训练集上的误差，可写为更一般的形式</p>
<p>其中w(f)称为“结构风险”(structural risk)，用于描述模型f的某些性质；第二项））称为“经验风险”(empirical risk)，用于描述模型与训练数据的契合程度；C用于对二者进行折中。从经验风险最小化的角度来看，w(f)表述了我们希望获得具有何种性质的模型(例如希望获得复杂度较小的模型)，这为引入领域知识和用户意图提供了途径，另一方面，该信息有助于削减假设空间，从而降低了最小化训练误差的过拟合风险从这个角度来说，式(6.42)称为“正则化”(regul arization)问题，w(f)称为正则化项，C则称为正则化常数。Lp范数(norm)是常用的正则化项，其中L2 范数W2 倾向于W 的分量取值尽量均衡，即非零分量个数尽量稠密，而L0范数 w0 和 L1 范数 w1 则倾向于w的分量尽量稀疏，即非零分量个数尽量少。</p>
<h2 id="-29"><a href="#-29" class="headerlink" title></a><br></h2><h2 id="支持向量回归"><a href="#支持向量回归" class="headerlink" title="支持向量回归"></a>支持向量回归</h2><p>现在我们来考虑回归问题给定训练样本D=）），希望学得一个形如式(6.7)的回归模型，使得f(x)与y尽可<br>能接近，w 和b 是待确定的模型参数。</p>
<p>对样本(x,y)，传统回归模型通常直接基于模型输出f(x)与真实输出y之间的差别来计算损失，当且仅当f(x)与y 完全相同时，损失才为零。与此不同，支持向量回归(Support Vector Regression)，简称SVR假设我们能容忍f(x)与y 之间最多有E 的偏差，即仅当f(x)与y 之间的差别绝对值大于E 时才计算损失。如图6.6 所示，这相当于以f(x)为中心，构建了一个宽度为2E 的间隔带，若训练样本落入此间隔带，则认为是被预测正确的。</p>
<p>图 6.6 支持向量回归示意图红色显示出←间隔带，落入其中的样本不计算损失。</p>
<p>于是，SVR 问题可形式化为</p>
<p>其中C为正则化常数，𝓁E 是图6.7 所示的E-不敏感损失(E-insensitive loss)函数</p>
<p>引入松弛变量Ei和Ei可将式(6.43)重写为</p>
<p>类似式(6.36)，通过引入拉格朗日乘子μ）），由拉格朗日乘子法可得到式(6.45)的拉格朗日函数</p>
<p>将式(6.7)代入，再令L对w和e的偏导为零可得</p>
<p>将式(6.47)-(6.50)代入式(6.46)，即可得到SVR 的对偶问题</p>
<p>上述过程中需满足KKT 条件，即要求</p>
<p>可以看出，当且仅当））时ai 能取非零值，当且仅当。时句能取非零值换言之，仅当样本））不落入E-间<br>隔带中，相应的ai和ai与才能取非零值。此外，约束））和））不能同时成立，因此问和向中至少有一个为零，</p>
<p>将式(6.47)代入(6.7)，则SVR 的解形如</p>
<p>能使式(6.53)中的））的样本即为SVR 的支持向量，它们必落在E-间隔带之外。显然，SVR 的支持向量仅是训练样本的一部分、即其解仍具有稀疏性</p>
<p>由KKT 条件(6.52)可看出，对每个样本(xi, yi)都有 且。于是，在得到向后，若0＜ai＜C，则必有））,<br>进而有</p>
<p>因此，在求解式(6.51)得到问后，理论上来说，可任意选取满足0＜ai＜C的样本通过式(6.54)求得b.实践中常采用一种更鲁棒的办法:选取多个(或所有)满足条件0＜ai＜C的样本求解b 后取平均值。</p>
<p>若考虑特征映射形式(6.19)，则相应的，式(6.47)将形如</p>
<p>将式(6.55)代入(6.19)，则SVR 可表示为</p>
<p>其中κ））为核函数</p>
<h2 id="-30"><a href="#-30" class="headerlink" title></a><br></h2><h2 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h2><p>回顾式(6.24)和(6.56)可发现，给定训练样本）），若不考虑偏移项b，则无论SVM 还是SVR，学得的模型总能表<br>示成核函数κ(x,x)；的线性组合不仅如此，事实上我们有下面这个称为“表<br>示定理”(representer theorem)的更一般的结论：</p>
<p>定理6.2 (表示定理)<br>令H为核函数κ 对应的再生核希尔伯特空间，））表示H空间中关于h 的范数，对于任意单调递增函数 w:[0,∞]→R 和任意非负损失函数）），优化问题</p>
<p>的解总可写为</p>
<p>表示定理对损失函数没有限制，对正则化项口仅要求单调递增，甚至不要<br>求。是凸函数，意味着对于一般的损失函数和正则化项，优化问题(6.57)的最优<br>解））都可表示为核函数κ））的线性组合，这显示出核函数的巨大威力。</p>
<p>人们发展出一系列基于核函数的学习方法，统称为“核方法”(kernel methods)。最常见的，是通过“核化”(即引入核函数)来将线性学习器拓展为非线性学习器。下面我们以线性判别分析为例来演示如何通过核化来对其进行非线性拓展，从而得到“核线性判别分析”(Kernelized Linear Discriminant Analysis，简称KLDA)。</p>
<p>我们先假设可通过某种映射））将样本映射到一个特征空间F，然后在F 中执行线性判别分析，以求得</p>
<p>类似于式(3.35), KLDA 的学习目标是</p>
<p>其中sb 和sw 分别为训练样本在特征空间F 中的类间散度矩阵和类内散度矩阵令xi 表示第 i∈{0,1} 类样本的集合，其样本数为mi；总样本数））。第i类样本在特征空间F 中的均值为</p>
<p>两个散度矩阵分别为</p>
<p>通常我们难以知道映射∅的具体形式，因此使用核函数））来隐式地表达这个映射和特征空间F把J(w)作为式(6.57)中的损失函数，再令，由表示定理，函数h(x)可写为</p>
<p>于是由式(6.59)可得</p>
<p>令））为核函数κ 所对应的核矩阵，））。令））为第i类样本的指示向量，即𝒍i的第j个分量为1当且仅当问））,否则𝒍i 的第j个分量为0.再令</p>
<p>于是，式(6.60)等价为</p>
<p>显然，使用线性判别分析求解方法即可得到a，进而可由式(6.64)得到投影函数h(x)。</p>
<h2 id="阅读材料-5"><a href="#阅读材料-5" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>支持向量机于1995年正式发表［Cortes and Vapnik, 1995］，由于在文本分类任务中显示出卓越性能［Joachims, 1998］，很快成为机器学习的主流技术，并直接掀起了“统计学习”(statistical learning在2000年前后的高潮。但实际上，支持向量的概念早在二十世纪六十年代就已出现，统计学习理论在七十年代就已成型。对核函数的研究更早，Mercer 定理［Cristianini and Shawe-Taylor,2000］可追溯到1909年，RKHS 则在四十年代就已被研究，但在统计学习兴起后，核技巧才真正成为机器学习的通用基本技术。关于支持向量机和核方法有很多专门书籍和介绍性文章［Cristianini and Shawe-Taylor, 2000; Burges, 1998;邓乃扬与田英杰，2009; Scholkopf et al., 1999; Scholkopf and Smola, 2002］，统计学习理论则可参阅［Vapnik, 1995, 1998, 1999］。</p>
<p>支持向量机的求解通常是借助于凸优化技术［Boyd and Vandenberghe,2004］.如何提高效率，使SVM 能适用于大规模数据一直是研究重点。对线性核SVM 已有很多成果，例如基于割平面法(cutting plane algorithm)的SVMperf具有线性复杂度［Joachims, 2006］，基于随机梯度下降的Pegasos 速度甚至更快［Shalev-Shwartz et al，20 11］，而坐标下降法则在稀疏数据上有很高的效率［Hsieh et al., 2008］.非线性核SVM的时间复杂度在理论上不可能低于O(m2),因此研究重点是设计快速近似算法，如基于采样的CVM ［Tsang et al., 2006］、基于低秩逼近的Nystrom 方法［Williams and Seeger, 2001］、基于随机傅里叶特征的方法［Rahimi and Recht, 2007］ 等。最近有研究显示，当核矩阵特征值有很大差别时，Nystrom 方法往往优于随机傅里叶特征方法［Yang et al., 2012］。支持向量机是针对二分类任务设计的，对多分类任务要进行专门的推广［Hsu and Lin, 2002］，对带结构输出的任务也已有相应的算法［Tsochantaridiset al., 2005］.支持向量回归的研究始于［Drucker et al., 1997］, ［Smola andScholkopf, 2004］给出了一个较为全面的介绍。</p>
<p>核函数直接决定了支持向量机与核方法的最终性能，但遗憾的是，核函数的选择是一个未决问题多核学习(multiple kernel learning)使用多个核函数并通过学习获得其最优凸组合作为最终的核函数［Lanckriet et 此，2004; Bach et al., 2004］，这实际上是在借助集成学习机制。</p>
<p>替代损失函数在机器学习中被广泛使用，但是，通过求解替代损失函数得到的是否仍是原问题的解？这在理论上称为替代损失的“ 一致性”(consistency)问题.［Vapnik and Chervonenkis, 1991］给出了基于替代损失进行经验风险最小化的一致性充要条件，［Zhang, 2004］证明了几种常见凸替代损失函数的一致性。</p>
<p>SVM 已有很多软件包，比较著名的有LIBSVM ［Chang and Lin, 2011］和LIBLINEAR ［Fan et al., 2008］等。</p>
<h3 id="休息一会儿-5"><a href="#休息一会儿-5" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：统计学习理论之父弗拉基米尔·瓦普尼克</p>
<p>弗拉基米尔·瓦普尼克(Vladimir N.Vapnik, 1936-)是杰出的数学家、统计学家、计算机科学家。他出生于苏联，1958年在乌兹别克国立大学获数学硕士学位，1964年在莫斯科控制科学学院获统计学博士学位，此后一直在该校工作并担任计算机系主任.1990年(苏联解体的前一年他离开苏联来到新泽西州的美国电话电报公司贝尔实验室工作，1995年发表了最初的SVM 文章当时神经网络正当红，因此这篇文章被权威期刊Machine Learning 要求以“支持向量网络”的名义发表。</p>
<p>实际上，瓦普尼克在1963年就已提出了支持向量的概念，1968年他与另一位苏联数学家A Chervon enkis 提出了以他们两人的姓氏命名的“VC维”，1974年又提出了结构风险最小化原则使得统计学习理论在二十世纪七十年代就已成型但这些工作主要是以俄文发表的，直到瓦普尼克随着东欧剧变和苏联解体导致的苏联科学家移民潮来到美国，这方面的研究才在西方学术界引起重视，统计学习理论、支持向量机、核方法在二十世纪末大红大紫。</p>
<p>瓦普尼克2002年离开美国电话电报公司加入普林斯顿的NEC 实验室，2014年加盟脸书(Facebook)公司人工智能实验室.1995年之后他还在伦敦大学、哥伦比亚大学等校任教授。据说瓦普尼克在苏联根据一本字典自学了英语及其发音。他有一句名言被广为传诵。“ Nothing is more practical than a goodtheory.”</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第7章-贝叶斯分类器"><a href="#第7章-贝叶斯分类器" class="headerlink" title="第7章 贝叶斯分类器"></a>第7章 贝叶斯分类器</h1><h2 id="-31"><a href="#-31" class="headerlink" title></a><br></h2><h2 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h2><p>贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方法。对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。下面我们以多分类任务为例来解释其基本原理。</p>
<p>假设有N种可能的类别标记，即Y=）），λij是将一个真实标记为Cj的样本误分类为Ci所产生的损失基于后验概率P(ci|x)可获得将样本x 分类为ai 所产生的期望损失(expected loss)，即在样本x上的“条件风险”(conditional risk)</p>
<p>我们的任务是寻找一个判定准则））以最小化总体风险</p>
<p>显然，对每个样本x，若h能最小化条件风险，则总体风险））也将被最小化。这就产生了贝叶斯判定准则(Bayes decision rule)： 为最小化总体风险，只需在每个样本上选择那个能使条件风险））最小的类别标记，即</p>
<p>此时，h＊称为贝叶斯最优分类器(Bayes optimal classifier)，与之对应的总体风险R(h＊) 称为贝叶斯风险(Bayes risk)反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。</p>
<p>具体来说，若目标是最小化分类错误率，则误判损失λij可写为</p>
<p>此时条件风险</p>
<p>于是，最小化分类错误率的贝叶斯最优分类器为</p>
<p>即对每个样本z，选择能使后验概率P(c|x)最大的类别标记</p>
<p>不难看出，欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概率P(c|x).然而，在现实任务中这通常难以直接获得。从这个角度来看，机器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率P(c|x).大体来说，主要有两种策略。给定x，可通过直接建模P(c|x)来预测c，这样得到的是“判别式模型”(discriminative models)；，也可先对联合概率分布P(x|c)建模，然后再由此获得P(c|x)，这样得到的是“生成式模型”(generative models).显然，前面介绍的决策树、BP神经网络、支持向量机等，都可归入判别式模型的范畴对生成式模型来说，必然考虑</p>
<p>基于贝叶斯定理，P(c|x)可写为</p>
<p>其中，P(c)是类“先验”(prior)概率； P(x|c)是样本x 相对于类标记c的类条件概率(class-conditional probability)，或称为“似然”(likelihood);P(x)是用于归一化的“证据”(evidence因子。对给定样本z，证据因子P(x)与类标记无关，因此估计P(c|x)的问题就转化为如何基于训练数据D 来估计先验P(c)和似然P(x|c)。</p>
<p>类先验概率P(c)表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，P(c)可通过各类样本出现的频率来进行估计。</p>
<p>对类条件概率P(x|c)来说，由于它涉及关于x所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。例如，假设样本的d个属性都是二值的，则样本空间将有2d种可能的取值，在现实应用中，这个值往往远大于训练样本数m，也就是说，很多样本取值在训练集中根本没有出现，直接使用频率来估计P(x|c)显然不可行，因为“未被观测到”与“出现概率为零”通常是不同的。</p>
<h2 id="-32"><a href="#-32" class="headerlink" title></a><br></h2><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。具体地，记关于类别c 的类条件概率为P(x|c)，假设P(x|c)具有确定的形式并且被参数向量θc 唯一确定，则我们的任务就是利用训练集D 估计参数θc，为明确起见，我们将P(x|c)记为P(x|θc)。</p>
<p>事实上，概率模型的训练过程就是参数估计(parameter estimation)过程。对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学派 (Ftequentist)认为参数虽然未知，但却是客观存在的固定值，因此，可通过优化似然函数等准则来确定参数值，贝叶斯学派(Bayesian)则认为参数是未观察到的随机变量，其本身也可有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。本节介绍源自频率主义学派的极大似然估计(Maximum Likelihood Estimation，简称MLE)，这是根据数据采样来估计概率分布参数的经典方法。</p>
<p>令Dc 表示训练集D 中第c 类样本组成的集合，假设这些样本是独立同分布的，则参数θc 对于数据集Dc 的似然是</p>
<p>对θc 进行极大似然估计，就是去寻找能最大化似然P(Dc|θc)的参数值θc，直观上看，极大似然估计是试图在θc 所有可能的取值中，找到一个能使数据出现的“可能性”最大的值。</p>
<p>式(7.9)中的连乘操作易造成下溢，通常使用对数似然(log-likelihood)</p>
<p>此时参数 θc 的极大似然估计 θc 为</p>
<p>例如，在连续属性情形下，假设概率密度函数P(x|c)～N(μc,𝞼c2)，则参数μc 和𝞼c2 的极大似然估计为</p>
<p>也就是说，通过极大似然法得到的正态分布均值就是样本均值，方差就是(x-βc)(x-βc)T的均值，这显然是一个符合直觉的结果。在离散属性情形下，也可通过类似的方式估计类条件概率。</p>
<p>需注意的是，这种参数化的方法虽能使类条件概率估计变得相对简单，但估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布。在现实应用中，欲做出能较好地接近潜在真实分布的假设，往往需在一定程度上利用关于应用任务本身的经验知识，否则若仅凭“猜测”来假设概率分布形式，很可能产生误导性的结果。</p>
<h2 id="-33"><a href="#-33" class="headerlink" title></a><br></h2><h2 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h2><p>不难发现，基于贝叶斯公式(7.8)来估计后验概率P(c|x)的主要困难在于：类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计而得。为避开这个障碍，朴素贝叶斯分类器(naive Bayes classifier)采用了“属性条件独立性假设”(attribute conditional independence assumption)：对已知类别，假设所有属性相互独立。换言之，假设每个属性独立地对分类结果发生影响。</p>
<p>基于属性条件独立性假设，式(7.8)可重写为</p>
<p>其中d 为属性数目，Xi为x 在第i个属性上的取值。</p>
<p>由于对所有类别来说P(x)相同，因此基于式(7.6)的贝叶斯判定准则有</p>
<p>这就是朴素贝叶斯分类器的表达式。</p>
<p>显然，朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率P(c)，并为每个属性估计条件概率P(xi|c)。</p>
<p>令Dc 表示训练集D 中第c 类样本组成的集合，若有充足的独立同分布样本，则可容易地估计出类先验概率</p>
<p>对离散属性而言，令Dcx； 表示De 中在第i个属性上取值为Xi 的样本组成的集合，则条件概率P(xi|c)可估计为</p>
<p>对连续属性可考虑概率密度函数，假定）），其中））分别是第c类样本在第i个属性上取值的均值和方差，则有</p>
<p>下面我们用西瓜数据集3.0训练一个朴素贝叶斯分类器，对测试例“测1”进行分类：</p>
<p>首先估计类先验概率P(c)，显然有</p>
<p>然后，为每个属性估计条件概率P(xi|c):</p>
<p>于是，有</p>
<p>由于0.063＞6.80 × 10的负5次方，因此，朴素贝叶斯分类器将测试样本“测1”判别为“好瓜”。</p>
<p>需注意，若某个属性值在训练、集中没有与某个类同时出现过，则直接基于式(7.17)进行概率估计，再根据式(7.15)进行判别将出现问题。例如，在使用西瓜数据集3.0训练朴素贝叶斯分类器时，对一个“敲声=清脆”的测试例，有</p>
<p>由于式(7.15)的连乘式计算出的概率值为零，因此，无论该样本的其他属性是什么，哪怕在其他属性上明显像好瓜，分类的结果都将是“好瓜=否”，这显然不太合理。</p>
<p>为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常要进行“平滑”(smoothing)，常用“拉普拉斯修正”(Laplacian correction)具体来说，令N 表示训练集D 中可能的类别数，Ni 表示第i个属性可能的取值数，则式(7.16)和(7.17)分别修正为</p>
<p>例如，在本节的例子中，类先验概率可估计为</p>
<p>类似地，P青绿｜是 和 P青绿｜否 可估计为</p>
<p>同时，上文提到的概率 P清脆｜是 可估计为</p>
<p>显然，拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题，并且在训练集变大时，修正过程所引入的先验(prior)的影响也会逐渐变得可忽略，使得估值渐趋向于实际概率值。</p>
<p>在现实任务中朴素贝叶斯分类器有多种使用方式。例如，若任务对预测速度要求较高，则对给定训练集，可将朴素贝叶斯分类器涉及的所有概率估值事先计算好存储起来，这样在进行预测时只需“查表”即可进行判别；若任务数据更替频繁，则可采用“懒惰学习”(lazy learning)方式，先不进行任何训练，待收到预测请求时再根据当前数据集进行概率估值；若数据不断增加，则可在现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习。</p>
<h2 id="-34"><a href="#-34" class="headerlink" title></a><br></h2><h2 id="半朴素贝叶斯分类器"><a href="#半朴素贝叶斯分类器" class="headerlink" title="半朴素贝叶斯分类器"></a>半朴素贝叶斯分类器</h2><p>为了降低贝叶斯公式(7.8)中估计后验概率P(c|x)的困难，朴素贝叶斯分类器采用了属性条件独立性假设但在现实任务中这个假设往往很难成立。于是，人们尝试对属性条件独立性假设进行一定程度的放松，由此产生了一类称为“半朴素贝叶斯分类器”(semi-naive Bayes classifiers)的学习方法。</p>
<p>半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。“独依赖估计’＇ (One-Dependent Estimator，简称ODE)是半朴素贝叶斯分类器最常用的一种策略。顾名思议所谓“独依赖”就是假设每个属性在类别之外最多仅依赖于一个其他属性，即</p>
<p>其中pa i为属性Xi 所依赖的属性，称为xi的父属性此时，对每个属性xi，若其父属性pa i 已知，则可采用类似式(7.20)的办法来估计概率值））。于是，问题的关键就转化为如何确定每个属性的父属性，不同的做法产生不同的独依赖分类器。</p>
<p>最直接的做法是假设所有属性都依赖于同一个属性，称为“超父”(super-parent)，然后通过交叉验证等模型选择方法来确定超父属性，由此形成了SPODE (Super-Parent ODE)方法。例如，在图7.l(b)中，x1是超父属性。</p>
<p>图7.1 朴素贝叶斯与两种半朴素贝叶斯分类器所考虑的属性依赖关系</p>
<p>TAN (Tree Augmented naive Bayes) ［Friedman et al，1997］则是在最大带<br>权生成树(maximum weighted spanning tree)算法［Chow and Liu, 1968］的基<br>础上，通过以下步骤将属性间依赖关系约简为如图7.l(c) 所示的树形结构：</p>
<p>(1)计算任意两个属性之间的条件互信息(conditional mutual information)</p>
<p>(2)以属性为结点构建完全图，任意两个结点之间边的权重设为</p>
<p>(3)构建此完全图的最大带权生成树，挑选根变量，将边置为有向；</p>
<p>(4)加入类别结点y，增加从y 到每个属性的有向边。</p>
<p>容易看出，条件互信息））刻画了属性和在已知类别情况下的相关性，因此，通过最大生成树算法，TAN 实际上仅保留了强相关属性之间的依赖性。</p>
<p>AODE (Averaged One-Dependent Estimator) ［Webb et al., 2005］是一种基于集成学习机制、更为强大的独依赖分类器与SPODE 通过模型选择确定超父属性不同，AODE尝试将每个属性作为超父来构建SPODE，然后将那些具有足够训练数据支撑的SPODE 集成起来作为最终结果，即</p>
<p>其中Dxi是在第i个属性上取值为Xi的样本的集合，m＇为阈值常数。显然，AODE需估计P(c,xi)和P(xj|c,xi)，类似式(7.20)，有</p>
<p>其中N 是D 中可能的类别数，Ni 是第i个属性可能的取值数，）） 是类别为c且在第i个属性上取值为Xi 的样本集合，））是类别为c 且在第i 和第j个属性上取值分别为Xi和Xj的样本集合。例如，对西瓜数据集3.0有</p>
<p>不难看出，与朴素贝叶斯分类器类似，AODE 的训练过程也是“计数”，即在训练数据集上对符合条件的样本进行计数的过程与朴素贝叶斯分类器相似，AODE 无需模型选择，既能通过预计算节省预测时间，也能采取懒惰学习方式在预测时再进行计数，并且易于实现增量学习。</p>
<p>既然将属性条件独立性假设放松为独依赖假设可能获得泛化性能的提升，那么，能否通过考虑属性间的高阶依赖来进一步提升泛化性能呢？ 也就是说，将式(7.21)中的属性归pai 替换为包含k个属性的集合pai，从而将ODE 拓展为kDE.需注意的是，随着k的增加，准确估计概率））所需的训练样本数量将以指数级增加。因此，若训练数据非常充分，泛化性能有可能提升；但在有限样本条件下，则又陷入估计高阶联合概率的泥沼。</p>
<h2 id="-35"><a href="#-35" class="headerlink" title></a><br></h2><h2 id="贝叶斯网"><a href="#贝叶斯网" class="headerlink" title="贝叶斯网"></a>贝叶斯网</h2><p>贝叶斯网(Bayesian network)亦称“信念网”(belief network)，它借助有向无环图(Directed Acyclic Graph，简称DAG)来刻画属性之间的依赖关系，并使用条件概率表(Conditional Probability Table，简称CPT)来描述属性的联合概率分布。</p>
<p>具体来说，一个贝叶斯网B由结构G和参数θ两部分构成，即））网络结构G是一个有向无环图，其每个结点对应于一个属性，若两个属性有直接依赖关系，则它们由一条边连接起来；参数θ定量描述这种依赖关系，假设属性均在G 中的父结点集为Πi，则θ包含了每个属性的条件概率表））。</p>
<p>作为一个例子，图7.2给出了西瓜问题的一种贝叶斯网结构和属性“根蒂”的条件概率表从图中网络结构可看出“色泽”直接依赖于“好瓜”和“甜度”，而“根蒂”则直接依赖于“甜度”，进一步从条件概率表能得到“根蒂”对“甜度” 量化依赖关系，如P(根蒂=硬挺｜甜度=高)=0.1 等</p>
<p>图7.2 西瓜问题的一种贝叶斯网结构以及属性“根蒂”的条件概率表</p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>贝叶斯网结构有效地表达了属性间的条件独立性。给定父结点集，贝叶斯网假设每个属性与它的非后裔属性独立，于是B将属性））的联合概率分布定义为</p>
<p>以图7.2为例，联合概率分布定义为</p>
<p>显然，X3 和X4 在给定X1 的取值时独立，X4 和X5 在给定X2 的取值时独立，分别简记为））。</p>
<p>图7.3 显示出贝叶斯网中三个变量之间的典型依赖关系，其中前两种在式(7.26)中已有所体现。</p>
<p>在“同父”(common parent)结构中，给定父结点X1的取值，则X3 与X4 条件独立。在“顺序”结构中，给定x 的值，则y 与z 条件独立。V型结构(V-structure)亦称“冲撞”结构，给定子结点X4 的取值，X1 与X2 必不独立；奇妙的是，若X4 的取值完全未知，则V型结构下X1 与X2 却是相互独立的我们做一个简单的验证：</p>
<p>这样的独立性称为“边际独立性”(marginal indep endence)，记为））。</p>
<p>事实上，一个变量取值的确定与否，能对另两个变量间的独立性发生影响，这个现象并非V型结构所特有。例如在同父结构中，条件独立性））成立，但若x1的取值未知，则X3 和X4 就不独立，即））不成立；在顺序结构中，））不成立。</p>
<p>为了分析有向图中变量间的条件独立性，可使用“有向分离”(D-separation)。我们先把有向图转变为一个无向图：</p>
<p>•找出有向图中的所有V 型结构在V 型结构的两个父结点之间加上一条无向边；</p>
<p>•将所有有向边改为无向边。</p>
<p>由此产生的无向图称为“道德图”(moral graph)，令父结点相连的过程称为“道德化”(moralizat ion) ［Cowell et al., 1999］。</p>
<p>基于道德图能直观、迅速地找到变量间的条件独立性。假定道德图中有变量x，y 和变量集合z={zi}，若变量x 和y 能在图上被z 分开，即从道德图中将变量集合z 去除后，x 和y 分属两个连通分支，则称变量x 和y 被z 有向分离，成立例如，图7.2 所对应的道德图如图7.4 所示，从图中能容易地找出所有的条件独立关系：</p>
<h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><p>若网络结构已知，即属性间的依赖关系已知，则贝叶斯网的学习过程相对简单，只需通过对训练样本“计数”，估计出每个结点的条件概率表即可。但在现实应用中我们往往并不知晓网络结构，于是，贝叶斯网学习的首要任务就是根据训练数据集来找出结构最“恰当”的贝叶斯网。“评分搜索”是求解这一问题的常用办法。具体来说，我们先定义一个评分函数(score function)，以此来评估贝叶斯网与训练数据的契合程度然后基于这个评分函数来寻找结构最优的贝叶斯网。显然，评分函数引入了关于我们希望获得什么样的贝叶斯网的归纳偏好。</p>
<p>常用评分函数通常基于信息论准则，此类准则将学习问题看作一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时编码的长度包括了描述模型自身所需的字节长度和使用该模型描述数据所需的字节长度。对贝叶斯网学习而言，模型就是一个贝叶斯网，同时，每个贝叶斯网描述了一个在训练数据上的概率分布，自有一套编码机制能使那些经常出现的样本有更短的编码。于是，我们应选择那个综合编码长度(包括描述网络和编码数据最短的贝叶斯网，这就是“最小描述长度”(Minimal DescriptionLength，简称MDL)准则。</p>
<p>给定训练集D={x1 ,x2 γ.，xm}，贝叶斯网））在D 上的评分函数可写为<br>））</p>
<p>其中，|B| 是贝叶斯网的参数个数； f(B)表示描述每个参数θ所需的字节数；而</p>
<p>是贝叶斯网B 的对数似然。显然，式(7.28)的第一项是计算编码贝叶斯网B 所需的字节数，第二项是计算B 所对应的概率分布PB 对D 描述得有多好。于是3学习任务就转化为一个优化任务，即寻找一个贝叶斯网B 使评分函数s(B|D)最小。</p>
<p>若f(θ)=1，即每个参数用1字节描述，则得到AIC (Akaike Information Criterion)评分函数</p>
<p>若f(θ)=logm，即每个参数用log m字节描述，则得到BIC (Bayesian Information Criterion)评分函数</p>
<p>显然，若f(θ)=0，即不计算对网络进行编码的长度，则评分函数退化为负对数似然，相应的，学习任务退化为极大似然估计。</p>
<p>不难发现，若贝叶斯网））的网络结构G固定，则评分函数））的第一项为常数此时，最小化s(B|D)等价于对参数θ的极大似然估计，由式(7.29)和(7.26)可知，参数；能直接在训练数据D上通过经验估计获得，即</p>
<p>其中））是D上的经验分布因此，为了最小化评分函数s(B|D)，只需对网络结构进行搜索，而候选结构的最优参数可直接在训练集上计算得到。</p>
<p>不幸的是，从所有可能的网络结构空间搜索最优贝叶斯网结构是一个NP难问题，难以快速求解。有两种常用的策略能在有限时间内求得近似解。第一种是贪心法，例如从某个网络结构出发，每次调整一条边(增加、删除或调整方向，直到评分函数值不再降低为止；第二种是通过给网络结构施加约束来削减搜索空间，例如将网络结构限定为树形结构等。</p>
<h3 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h3><p>贝叶斯网训练好之后就能用来回答“查询”(query)，即通过一些属性变量的观测值来推测其他属性变量的取值例如在西瓜问题中，若我们观测到西瓜色泽青绿、敲声浊响、根蒂蜷缩想知道它是否成熟、甜度如何。这样通过已知变量观测值来推测待查询变量的过程称为“推断”(inference)，已知变量观测值称为“证据” (evidence)。</p>
<p>最理想的是直接根据贝叶斯网定义的联合概率分布来精确计算后验概率，不幸的是，这样的“精确推断”已被证明是NP难的［Cooper, 1990］；换言之，当网络结点较多、连接稠密时，难以进行精确推断，此时需借助“近似推断”，通过降低精度要求，在有限时间内求得近似解在现实应用中，贝叶斯网的近似推断常使用吉布斯采样(Gibbs sampling)来完成，这是一种随机采样方法，我们来看看它是如何工作的。</p>
<p>令））表示待查询变量，）） 为证据变量，已知其取值为）），目标是计算后验概率）） ,其中））是待查询变量的一组取值以西瓜问题为例，待查询变量为Q={好瓜，甜度}，证据变量为E ={色浑，敲声，根蒂}且已知其取值为e ={青绿，浊响，蜷缩}，查询的目标值是q ={是, 高}，即这是好瓜且甜度高的概率有多大。</p>
<p>如图7.5 所示，吉布斯采样算法先随机产生一个与证据 E=e 一致的样本q0作为初始点，然后每步从当前样本出发产生下一个样本。具体来说，在第t次采样中，算法先假设qt=qt-1，然后对非证据变量逐个进行采样改变其取值，采样概率根据贝叶斯网B和其他变量的当前取值(即Z=z计算获得。假定经过T 次采样得到的与q 一致的样本共有问个，则可近似估算出后验概率</p>
<p>实质上，吉布斯采样是在贝叶斯网所有变量的联合状态空间与证据E=e一致的子空间中进行“随机漫步”(random walk).每一步仅依赖于前一步的状态，这是一个“马尔可夫链”(Markov chain).在一定条件下，无论从什么初始状态开始，马尔可夫链第t步的状态分布在t→∞时必收敛于一个平稳分布(stationary distribution)；对于吉布斯采样来说，这个分布恰好是））.因此，在T很大时，吉布斯采样相当于根据））采样，从而保证了式(7.33)收敛于））。</p>
<p>需注意的是，由于马尔可夫链通常需很长时间才能趋于平稳分布，因此吉布斯采样算法的收敛速度较慢此外若贝叶斯网中存在极端概率“0”或“1”，则不能保证马尔可夫链存在平稳分布，此时吉布斯采样会给出错误的估计结果。</p>
<h2 id="-36"><a href="#-36" class="headerlink" title></a><br></h2><h2 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h2><p>在前面的讨论中，我们一直假设训练样本所有属性变量的值都已被观测到，即训练样本是“完整”的。但在现实应用中往往会遇到“不完整”的训练样本，例如由于西瓜的根蒂已脱落，无法看出是“蜷缩”还是“硬挺”本的“根蒂”属性变量值未知。在这种存在“未观测” 变量的情形下，是否仍能对模型参数进行估计呢？</p>
<p>未观测变量的学名是“隐变量”(latent variable).令X 表示已观测变量集，Z表示隐变量集，θ表示模型参数。若欲对θ 做极大似然估计，则应最大化对数似然</p>
<p>然而由于Z是隐变量，上式无法直接求解。此时我们可通过对Z计算期望，来最大化已观测数据的对数“边际似然”(marginal likelihood)</p>
<p>EM (Expectation-Maximi zation)算法［Dempster et al，1977］是常用的估计参数隐变量的利器，它是一种迭代式的方法，其基本想法是·若参数θ已知3则可根据训练数据推断出最优隐变量Z 的值(E步)，反之，若Z的值已知，则可方便地对参数θ做极大似然估计(M步)。</p>
<p>于是，以初始值。。为起点，对式(7.35)，可迭代执行以下步骤直至收敛：</p>
<p>· 基于θt 推断隐变量Z 的期望，记为Zt;<br>· 基于已观测变量X 和Zt 对参数θ做极大似然估计，记为θ;</p>
<p>这就是EM算法的原型。</p>
<p>进一步，若我们不是取Z的期望，而是基于θt计算隐变量Z的概率分布）），则EM算法的两个步骤是：</p>
<p>• E 步(Expectation)：以当前参数伊推断隐变量分布）），并计算对数似然））关于Z 的期望</p>
<p>• M 步(Maximization)： 寻找参数最大化期望似然，即</p>
<p>简要来说，EM算法使用两个步骤交替计算：第一步是期望(E)步，利用当前估计的参数值来计算对数似然的期望值；第二步是最大化(M)步，寻找能使E步产生的似然期望最大化的参数值然后，新得到的参数值重新被用于E步，……直至收敛到局部最优解。</p>
<p>事实上，隐变量估计问题也可通过梯度下降等优化算法求解，但由于求和的项数将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦，而EM算法则可看作一种非梯度优化方法。</p>
<h2 id="阅读材料-6"><a href="#阅读材料-6" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>贝叶斯决策论在机器学习、模式识别等诸多关注数据分析的领域都有极为重要的地位。对贝叶斯定理进行近似求解，为机器学习算法的设计提供了一种有效途径为避免贝叶斯定理求解时面临的组合爆炸、样本稀疏问题，朴素贝叶斯分类器引入了属性条件独立性假设这个假设在现实应用中往往很难成立，但有趣的是，朴素贝叶斯分类器在很多情形下都能获得相当好的性能［Domingos and Pazzani, 1997; Ng and Jordan, 2002］.一种解释是对分类任务来说，只需各类别的条件概率排序正确、无须精准概率值即可导致正确分类结果；另一种解释是，若属性间依赖对所有类别影响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响［Zhang, 2004］.朴素贝叶斯分类器在信息检索领域尤为常用［Lewis, 1998］, ［McCallum and Nigam, 1998］对其在文本分类中的两种常见用法进行了比较。</p>
<p>根据对属性问依赖的涉及程度，贝叶斯分类器形成了一个“谱”：朴素贝叶斯分类器不考虑属性间依赖性，贝叶斯网能表示任意属性间的依赖性，二者分别位于“谱”的两端；介于两者之间的则是一系列半朴素贝叶斯分类器，它们基于各种假设和约束来对属性间的部分依赖性进行建模一般认为，半朴素贝叶斯分类器的研究始于［Kononenko, 1991］.ODE 仅考虑依赖一个父属性，由此形成了独依赖分类器如TAN ［Friedman et al., 1997］、AODE ［Webb et 址，2005］、LBR (lazy Bayesian Rule) ［Zheng and Webb, 2000］等； KDE 则考虑最多依赖k个父属性，由此形成了k 依赖分类器如KDB ［Sahami, 1996］、NBtree［Kohavi, 1996］等。</p>
<p>贝叶斯分类器(Bayes Classifier)与一般意义上的“贝叶斯学习”(Bayesian Learning有显著区别，前者是通过最大后验概率进行单点估计，后者则是进行分布估计。关于贝叶斯学习的内容可参阅［Bishop, 2006］。贝叶斯网为不确定学习和推断提供了基本框架，因其强大的表示能力、良好的可解释性而广受关注［Pearl, 1988］.贝叶斯网学习可分为结构学习和参数学习两部分。参数学习通常较为简单，而结构学习则被证明是NP 难问题［Cooper, 1990; Chickering et al., 2004］，人们为此提出了多种评分搜索方法［Friedman and Goldszmidt，1996］.贝叶斯网通常被看作生成式模型，但近年来也有不少关于贝叶斯网判别式学习的研究［Grossman and Domingos, 2004］.关于贝叶斯网的更多介绍可参阅［Jensen, 1997; Heckerman, 1998］。</p>
<p>EM算法是最常见的隐变量估计方法，在机器学习中有极为广泛的用途，例如常被用来学习高斯混合模型(Gaussian mixture model，简称GMM)的参数；9.4节将介绍的k均值聚类算法就是一个典型的EM算法。更多关于EM算法的分析、拓展和应用可参阅［McLachlan and Krishnan, 2008］。本章介绍的朴素贝叶斯算法和EM算法均曾入选“数据挖掘十大算法”［Wu et al., 2007］。</p>
<h3 id="休息一会儿-6"><a href="#休息一会儿-6" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：贝叶斯之谜</p>
<p>1763年12月23日，托马斯·贝叶斯(Thomas Bayes,1701?-1761)的遗产受赠者R.Price牧师在英国皇家学会宣读了贝叶斯的遗作《论机会学说中一个问题的求解》，其中给出了贝叶斯定理，这一天现在被当作贝叶斯定理的诞生日。虽然贝叶斯定理在今天已成为概率统计最经典的内容之一，但贝叶斯本人却笼罩在谜团中。</p>
<p>现有资料表明，贝叶斯是一位神职人员，长期担任英国坦布里奇韦尔斯地方教堂的牧师，他从事数学研究的目的是为了证明上帝的存在。他在1742年当选英国皇家学会会士，但没有记录表明他此前发表过任何科学或数学论文。他的提名是由皇家学会的重量级人物签署的，但为什么提名以及他为何能当选，至今仍是个谜贝叶斯的研究工作和他本人在他生活的时代很少有人关注，贝叶斯定理出现后很快就被遗忘了，后来大数学家拉普拉斯使它重新被科学界所熟悉，但直到二十世纪随着统计学的广泛应用才备受瞩目。贝叶斯的出生年份至今也没有清楚确定，甚至关于如今广泛流传的他的画像是不是贝叶斯本人，也仍存在争议。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第8章-集成学习"><a href="#第8章-集成学习" class="headerlink" title="第8章 集成学习"></a>第8章 集成学习</h1><h2 id="个体与集成"><a href="#个体与集成" class="headerlink" title="个体与集成"></a>个体与集成</h2><p>集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统(multi-classifier System)、基于委员会的学习(committee-based learning)等。</p>
<p>图8.1显示出集成学习的一般结构：先产生一组“个体学习器”(individual learner)，再用某种策略将它们结合起来个体学习器通常由一个现有的学习算法从训练数据产生例如C4.5 决策树算法、BP神经网络算法等，此时集成中只包含同种类型的个体学习器，例如“决策树集成”中全是决策树，“神经网络集成”中全是神经网络，这样的集成是“同质”的(homogeneous).同质集成中的个体学习器亦粉“基学习器”(base learner),相应的学习算法称为“基学习算法”(base learning algorithm).集成也可包含不同类型的个体学习器，例如同时包含决策树和神经网络，这样的集成是“异质”的(heterogenous).异质集成中的个体学习器由不同的学习算法生成，这时就不再有基学习算法；相应的，个体学习器一般不称为基学习器，常称为“组件学习器”(component learner)或直接称为个体学习器。</p>
<p>集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。这对“弱学习器”(weak learner)尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器但需注意的是，虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实践中出于种种考虑，例如希望使用较少的个体学习器，或是重用关于常见学习器的一些经验等，人们往往会使用比较强的学习器。</p>
<p>在一般经验中，如果把好坏不等的东西掺到一起，那么通常结果会是比最坏的要好一些，比最好的要坏一些集成学习把多个学习器结合起来，如何能获得比最好的单一学习器更好的性能呢？</p>
<p>考虑一个简单的例子:在二分类任务中，假定三个分类器在三个测试样本上的表现如图8.2 所示，其中 √ 表示分类正确，×表示分类错误，集成学习的结果通过投票法(voting)产生，即“少数服从多数”。在图8.2(a)中，每个分类器都只有66.63%的精度，但集成学习却达到了100%；在图8.2(b)中，三个分类器没有差别，集成之后性能没有提高；在图8.2(c)中，每个分类器的精度都只有33.33%，集成学习的结果变得更糟。这个简单的例子显示出：要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”即学习器不能太坏，并且要有“多样性”(diversity)，即学习器间具有差异。</p>
<p>图8.2 集成个体应“好而不同” (hi表示第i个分类器)</p>
<p>我们来做个简单的分析。考虑二分类问题））和真实函数f，假定基分类器的错误率为𝞮，即对每个基分类器h i有</p>
<p>假设集成通过简单投票法结合T个基分类器，若有超过半数的基分类器正确，则集成分类就正确。</p>
<p>假设基分类器的错误率相互独立，则由Hoeffding 不等式可知，集成的错误率为</p>
<p>上式显示出，随着集成中个体分类器数目T的增大，集成的错误率将指数级下降，最终趋向于零。</p>
<p>然而我们必须注意到，上面的分析有一个关键假设。基学习器的误差相互独立。在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立！事实上，个体学习器的“准确性”和“多样性”本身就存在冲突一般的，准确性很高之后，要增加多样性就需牺牲准确性。事实上，如何产生并结合“好而不同”的个体学习器，恰是集成学习研究的核心。</p>
<p>根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging 和“随机森林”(Random Forest)。</p>
<h2 id="-37"><a href="#-37" class="headerlink" title></a><br></h2><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似。先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。</p>
<p>Boosting 族算法最著名的代表是AdaBoost ［Freund and Schapire, 1997］,<br>其描述如图8.3 所示，其中））, f 是真实函数。</p>
<p>AdaBoost 算法有多种推导方式，比较容易理解的是基于“加性模型”(additive model，即基学习器的线性组合。</p>
<p>来最小化指数损失函数(exp onential loss function) ［Friedman et al., 2000］</p>
<p>若H(x)能令指数损失函数最小化，则考虑式(8.5)对H(x)的偏导</p>
<p>令式(8.6)为零可解得</p>
<p>这意味着sign(H(x)) 达到了贝叶斯最优错误率换言之，若指数损失函数最小化，则分类错误率也将最小化；这说明指数损失函数是分类任务原本0/1损失函数的一致的(consistent)替代损失函数。由于这个替代函数有更好的数学性质，例如它是连续可微函数，因此我们用它替代0/1损失函数作为优化目标。</p>
<p>在AdaBoost算法中，第一个基分类器h1是通过直接将基学习算法用于初始数据分布而得，此后i在代地生成h_t 和a_t，当基分类器h_t 基于分布Dt 产生后，该基分类器的权重at 应使得atht 最小化指数损失函数</p>
<p>其中））.考虑指数损失函数的导数</p>
<p>令式(8.10)为零可解得</p>
<p>这恰是图8.3中算法第6行的分类器权重更新公式。</p>
<p>AdaBoost 算法在获得 Ht-1 之后样本分布将进行调整，使下一轮的基学习<br>器问能纠正 Ht-1 的一些错误理想的ht 能纠正 Ht-1 的全部错误，即最小化</p>
<p>注意到 ）），式(8.12)可使用）） 的泰勒展式近似为</p>
<p>于是，理想的基学习器</p>
<p>注意到））是一个常数。令Dt 表示一个分布</p>
<p>则根据数学期望的定义，这等价于令</p>
<p>由）），有</p>
<p>则理想的基学习器</p>
<p>由此可见，理想的ht 将在分布Dt 下最小化分类误差。因此，弱分类器将基于分布Dt 来训练，且针对Dt 的分类误差应小于0.5。这在一定程度上类似“ 残差逼近”的思想考虑到 Dt和Dt+l 的关系，有</p>
<p>这恰是图8.3 中算法第7 行的样本分布更新公式。</p>
<p>于是，由式(8.11)和(8.19)可见，我们从基于加性模型迭代式优化指数损失函数的角度推导出了图8.3的AdaBoost 算法。</p>
<p>Boosting 算法要求基学习器能对特定的数据分布进行学习，这可通过“重赋权法”(re-weighting)实施，即在训练过程的每一轮中，根据样本分布为每个训练样本重新赋予一个权重。对无法接受带权样本的基学习算法，则可通过“重采样法”(re-sampling)来处理即在每一轮学习中，根据样本分布对训练集重新进行采样，再用重采样而得的样本集对基学习器进行训练。一般而言，这两种做法没有显著的优劣差别。需注意的是，Boosting算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件(例如图8.3的第5行，检查当前基分类器是否是比随机猜测好)，一旦条件不满足，则当前基学习器即被抛弃，且学习过程停止在此种情形下，初始设置的学习轮数T 也许还远未达到，可能导致最终集成中只包含很少的基学习器而性能不佳。若采用“重采样法”，则可获得“重启动”机会以避免训练过程过早停止［Kohavi and Wolpert, 1996］,即在抛弃不满足条件的当前基学习器之后，可根据当前分布重新对训练样本进行采样，再基于新的采样结果重新训练出基学习器，从而使得学习过程可以持续到预设的T 轮完成。</p>
<p>从偏差一方差分解的角度看，Boosting 主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成。我们以决策树桩为基学习器，在表4.5 的西瓜数据集3.0a 上运行AdaBoost 算法，不同规模(size的集成及其基学习器所对应的分类边界如图8.4 所示。</p>
<p>图8.4 西瓜数据集3.0a 上AdaBoost 集成规模为3 、5 、11 时，集成(红色)与基学习器(黑色)的分类边界</p>
<h2 id="-38"><a href="#-38" class="headerlink" title></a><br></h2><h2 id="Bagging与随机森林"><a href="#Bagging与随机森林" class="headerlink" title="Bagging与随机森林"></a>Bagging与随机森林</h2><p>由8.1节可知，欲得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立;虽然“独立”在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异给定一个训练数据集，一种可能的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器这样，由于训练数据不同，我们获得的基学习器可望具有比较大的差异然而，为获得好的集成，我们同时还希望个体学习器不能太差如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。为解决这个问题，我们可考虑使用相互有交叠的采样子集。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>Bagging［Breiman, 1996a］是并行式集成学习方法最著名的代表。从名字即可看出，它直接基于我们在2.2.3 节介绍过的自助采样法(bootstrap sampling)。给定包含m个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现。由式(2.1)可知，初始训练、集中约有63.2%的样本出现在采样集中。</p>
<p>照这样，我们可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这就是Bagging 的基本流程。在对预测输出进行结合时，Bagging 通常对分类任务使用简单投票法，对回归任务使用简单平均法。若分类预测时出现两个类收到同样票数的情形，则最简单的做法是随机选择一个，也可进一步考察学习器投票的置信度来确定最终胜者Bagging 的算法描述如图8.5 所示。</p>
<p>假定基学习器的计算复杂度为O(m)，则Bagging 的复杂度大致为T(O(m)+O(s))，考虑到采样与投票／平均过程的复杂度。(s)很小，而T通常是一个不太大的常数，因此，训练一个Bagging 集成与直接使用基学习算法训练一个学习器的复杂度同阶，这说明Bagging 是一个很高效的集成学习算法另外，与标准AdaBoost 只适用于二分类任务不同，Bagging 能不经修改地用于多分类、回归等任务。</p>
<p>值得一提的是，自助采样过程还给Bagging 带来了另一个优点:由于每个基学习器只使用了初始训练集中约63.2% 的样本，剩下约36.8% 的样本可用作验证集来对泛化性能进行“包外估计”(out-of-bag estimate) ［Breiman, 1996a;Wolpert and Macready, 1999］.为此需记录每个基学习器所使用的训练、样本不妨令Dt 表示ht 实际使用的训练样本集，令Hoob (x) 表示对样本x 的包外预测，即仅考虑那些未使用x 训练的基学习器在x 上的预测，有</p>
<p>事实上，包外样本还有许多其他用途例如当基学习器是决策树时，可使用包外样本来辅助剪枝，或用于估计决策树中各结点的后验概率以辅助对零训练样本结点的处理；当基学习器是神经网络时，可使用包外样本来辅助早期停止以减小过拟合风险。</p>
<p>从偏差一方差分僻的角度看，Bagging 主要关注降低方差，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显。我们以基于信息增益划分的决策树为基学习器，在表4.5 的西瓜数据集3.0a 上运行Bagging 算法，不同规模的集成及其基学习器所对应的分类边界如图8.6 所示。</p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林(Random Forest，简称RF) ［Breiman, 2001a］是Bagging 的一个扩展变体.RF 在以决策树为基学习器构建Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机属性选择具体来说，传统决策树在选择划分属性时是在当前结点的属性集合(假定有d个属性)中选择一个最优属性，而在RF 中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数k 控制了随机性的引入程度若令k=d，则基决策树的构建与传统决策树相同i若令k=1，则是随机选择一个属性用于划分; 一般情况下，推荐值k=log2 d［Breiman, 2001a］</p>
<p>图8.6 西瓜数据集3.0a 上Bagging 集成规模为3 、5 、11 时，集成(红色)与基学习器(黑色)的分类边界。</p>
<p>随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现出强大的性能，被誉为“代表集成学习技术水平的方法” 可以看出，随机森林对Bagging 只做了小改动，但是与Bagging 中基学习器的“多样性”仅通过样本扰动(通过对初始训练集采样)而来不同，随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间差异度的增加而进一步提升。</p>
<p>随机森林的收敛性与Bagging 相似。 如图8.7所示，随机森林的起始性能往往相对较差，特别是在集成中只包含一个基学习器时。这很容易理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低。然而，随着个体学习器数目的增加，随机森林通常会收敛到更低的泛化误差。值得一提的是，随机森林的训练效率常优于Bagging，因为在个体决策树的构建过程中，Bagging使用的是“确定型”决策树，在选择划分属性时要对结点的所有属性进行考察，而随机森林使用的“随机型”决策树则只需考察一个属性子集。</p>
<p>图 8.7 在两个 UCI 数据上，集成规模对随机森林与 Bagging 的影响</p>
<h2 id="-39"><a href="#-39" class="headerlink" title></a><br></h2><h2 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h2><p>学习器结合可能会从三个方面带来好处［Dietterich, 2000］：首先，从统计的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器则会减小这一风险－ 第二。从计算的方面来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入糟糕局部极小点的风险；第三，从表示的方面来看，某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器则肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学得更好的近似。图8.8 给出了一个直观示意图。</p>
<p>图8.8 学习器结合可能从三个方面带来好处［Dietterich, 2000］</p>
<p>假定集成包含T个基学习器{h1，h2，…, hr}，其中hi 在示例x上的输出为hi(x).本节介绍几种对hi进行结合的常见策略。</p>
<h3 id="平均法"><a href="#平均法" class="headerlink" title="平均法"></a>平均法</h3><p>对数值型输出）），最常见的结合策略是使用平均法(averaging)。</p>
<p>•简单平均法(simple averaging)<br>•加权平均法(weighted averaging)</p>
<p>其中问是个体学习器hi的权重，通常要求））。</p>
<p>显然，简单平均法是加权平均法令））。加权平均法在二十世纪五十年代已被广泛使用［Markowitz, 1952］, ［Perrone and Cooper, 1993］正式将其用于集成学习。它在集成学习中具有特别的意义，集成学习中的各种结合方法都可视为其特例或变体事实上，加权平均法可认为是集成学习研究的基本出发点，对给定的基学习器，不同的集成学习方法可视为通过不同的方式来确定加权平均法中的基学习器权重。</p>
<p>力日权平均法的权重一般是从训练数据中学习而得，现实任务中的训练样本<br>通常不充分或存在噪声，这将使得学出的权重不完全可靠尤其是对规模比较<br>大的集成来说，要学习的权重比较多，较容易导致过拟合因此，实验和应用均<br>显示出，加权平均法未必一定优于简单平均法））.一般而言，在个体学习器性能相差较大时直使用加权平均<br>法，而在个体学习器性能相近时直使用简单平均法。</p>
<h3 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h3><p>对分类任务来说，学习器hi 将从类别标记集合{c1 ,c2,..,cN}中预测出一<br>个标记，最常见的结合策略是使用投票法(voting).为便于时论，我们将hi 在样<br>本z 上的预测输出表示为一个N 维向量）），其中））是hi在类别标记Cj 上的输出。</p>
<p>• 绝对多数投票法(majority voting)</p>
<p>即若某标记得票过半数，则预测为该标记;否则拒绝预测。</p>
<p>• 相对多数投票法(plurality voting)</p>
<p>即预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取一个</p>
<p>• 加权投票法(weighted voting)</p>
<p>与加权平均法类似，w是h的权重，通常））。</p>
<p>标准的绝对多数投票法(8.24)提供了“拒绝预测”选项：这在可靠性要求较高的学习任务中是一个很好的机制但若学习任务要求必须提供预测结果，则绝对多数投票法将退化为相对多数投票法。因此，在不允许拒绝预测的任务中，绝对多数、相对多数投票法统称为“多数投票法”。</p>
<p>式(8.24)～(8.26)没有限制个体学习器输出值的类型。在现实任务中，不同类型个体学习器可能产生不同类型的时(x)值，常见的有：</p>
<ul>
<li><p>类标记：）） ，若hi 将样本z 预测为类别Cj 则取值为1，否则为0.使用类标记的投票亦称“硬投票” (hard voting)。</p>
</li>
<li><p>类概率：）），相当于对后验概率P 的一个估计。使用类概率的投票亦称“软投票”(soft voting)。</p>
</li>
</ul>
<p>不同类型的））值不能混用。对一些能在预测出类别标记的同时产生分类置信度的学习器，其分类置信度可转化为类概率使用。若此类值未进行规范化，例如支持向量机的分类间隔值，则必须使用一些技术如Platt 缩放(Platt scaling) ［Platt, 2000］、等分回归(isotonic regression) ［Zadrozny andElkan, 2001］等进行“校准”(calibration后才能作为类概率使用有趣的是，虽然分类器估计出的类概率值一般都不太准确，但基于类概率进行结合却往往比直接基于类标记进行结合性能更好。市注意的是，若基学习器的类型不同，则其类概率值不能直接进行比较，在此种情形下，通常可将类概率输出转化为类标记输出(例如将类概率输出最大的时(x)设为1，其他设为0)然后再投票。</p>
<h3 id="学习法"><a href="#学习法" class="headerlink" title="学习法"></a>学习法</h3><h2 id="-40"><a href="#-40" class="headerlink" title></a><br></h2><h2 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h2><p>当训练数据很多时，一种更为强大的结合策略是使用“学习法”，即通过另一个学习器来进行结合.Stacking ［Wolper 1992; Breiman, 1996b］是学习法的典型代表这里我们把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器(meta-learner)。</p>
<p>Stacking先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作样例标记.Stacking的算法描述如图8.9所示，这里我们假定初级学习器使用不同学习算法产生，即初级集成是异质的。</p>
<p>在训练阶段，次级训练集是利用初级学习器产生的，若直接用初级学习器的训练集来产生次级训练集，则过拟合风险会比较大；因此，一般是通过使用交叉验证或留一法这样的方式，用训练初级学习器未使用的样本来产生次级学习器的训练样本。以k折交叉验证为例，初始训练集D被随机划分为k个大小相似的集合））.令））和））分别表示第j折的测试集和训练集给定T个初级学习算法，初级学习器））通过在Dj上使用第t个学习算法而得对Dj 中每个样本）），令）），则由X i所产生的次级训练样例的示例部分为）），标记部分为于是，在整个交叉验证过程结束后，从这T个初级学习器产生的次级训练集是然后D＇将用于训练次级学习器。</p>
<p>次级学习器的输入属性表示和次级学习算法对Stacking集成的泛化性能有很大影响。有研究表明，将初级学习器的输出类概率作为次级学习器的输入属性，用多响应线性回归(Multi-response Linear Regression，简称MLR)作为次级学习算法效果较好［Ting and Witten, 1999］，在MLR 中使用不同的属性集更佳［Seewald, 2002］。</p>
<p>贝叶斯模型平均(Bayes Model Averaging，简称BMA)基于后验概率来为不同模型赋予权重，可视为加权平均法的一种特殊实现.［Clarke, 2003］对Stacking 和BMA 进行了比较理论上来说，若数据生成模型恰在当前考虑的模型中，且数据噪声很少，则BMA 不差于Stacking；然而，在现实应用中无法确保数据生成模型一定在当前考虑的模型中，甚至可能难以用当前考虑的模型来进行近似，因此，Stacking 通常优于BMA，因为其鲁棒性比BMA 更好，而且BMA 对模型近似误差非常敏感。</p>
<h3 id="误差———分歧分解"><a href="#误差———分歧分解" class="headerlink" title="误差———分歧分解"></a>误差———分歧分解</h3><p>8.1 节提到，欲构建泛化能力强的集成，个体学习器应“好而不同” 现在我们来做一个简单的理论分析。</p>
<p>假定我们用个体学习器h1, h2，…，ht 通过加权平均法(8.23)结合产生的<br>集成来完成回归学习任务）），对示例x，定义学习器hi 的“分歧”(ambiguity)为</p>
<p>则集成的“分歧”是</p>
<p>显然，这里的“分歧”项表征了个体学习器在样本x上的不一致性，即在一定程度上反映了个体学习器的多样性个体学习器hi 和集成H 的平方误差分别为</p>
<p>令））表示个体学习器误差的加权均值，有</p>
<p>式(8.31)对所有样本x 均成立，令p(x)表示样本的概率密度，则在全样本上有</p>
<p>类似的，个体学习器hi 在全样本上的泛化误差和分歧项分别为</p>
<p>集成的泛化误差为</p>
<p>将式(8.33)～(8.35)代入式(8.32)，再令））表示个体学习器泛化误差的加权均值，； 表示个体学习器的加权分歧值，有</p>
<p>式(8.36)这个漂亮的式子明确提示出：个体学习器准确性越高、多样性越大，则集成越好上面这个分析首先由［Krogh and Vedelsby, 1995］给出，称为“误差分歧分解”(error-ambiguity decomposition)。</p>
<p>至此，读者可能很高兴：我们直接把））互作为优化目标来求解，不就能得到最优的集成了，遗憾的是，在现实任务中很难直接对））进行优化，不仅由于它们是定义在整个样本空间上，还由于互不是一个可直接操作的多样性度量，它仅在集成构造好之后才能进行估计。此外需注意的是，上面的推导过程只适用于回归学习，难以直接推广到分类学习任务上去。</p>
<h3 id="多样性度量"><a href="#多样性度量" class="headerlink" title="多样性度量"></a>多样性度量</h3><p>顾名思义，多样性度量(diversity measure) 是用于度量集成中个体分类器的多样性，即估算个体学习器的多样化程度回典型做法是考虑个体分类器的两两相似／不相似性。</p>
<p>给定数据集D=）），对二分类任务）），分类器h i 与h j 的预测结果列联表(contingency table)为</p>
<p>其中，a 表示hi 与hj 均预测为正类的样本数目； b 、c 、d 含义由此类推，））.基于这个列联表，下面给出一些常见的多样性度量。</p>
<p>• 不合度量(disagreement measure)</p>
<p>dij 的值域为[0,1].值越大则多样性越大。</p>
<p>• 相关系数(correlation coefficient)</p>
<p>ρij 的值域为［-1, 1］.若hi与hj无关，则值为0，若hi与hj 正相关则值为正，否则为负。</p>
<p>• Q-统计量(Q-statistic)</p>
<p>Qij 与相关系数pij 的符号相同，且））</p>
<p>• κ-统计量(κ-statistic)</p>
<p>其中，P1 是两个分类器取得一致的概率；归是两个分类器偶然达成一致的概率，它们可由数据集D 估算。</p>
<p>若分类器hi 与hj 在D 上完全一致，则κ=1；若它们仅是偶然达成一致，</p>
<p>则κ=0.κ 通常为非负值，仅在hi 与hj 达成一致的概率甚至低于偶然性的情况下取负值。</p>
<p>以上介绍的都是“成对型”(pairwise)多样性度量，它们可以容易地通过2维图绘制出来。例如著名的“κ-误差图”，就是将每一对分类器作为图上的一个点，横坐标是这对分类器的κ值，纵坐标是它们的平均误差，图8.10给出了一个例子显然，数据点云的位置越高，则个体分类器准确性越低；点云的位置越靠右，则个体学习器的多样性越小。</p>
<p>图8.10 在UCI数据集tic-tac-toe上的κ-误差图每个集成含50棵C4.5 决策树</p>
<h3 id="多样性增强"><a href="#多样性增强" class="headerlink" title="多样性增强"></a>多样性增强</h3><p>在集成学习中需有效地生成多样性大的个体学习器与简单地直接用初始数据训练出个体学习器相比如何增强多样性呢？一般思路是在学习过程中引入随机性，常见做法主要是对数据样本、输入属性、输出表示、算法参数进行扰动</p>
<p>• 数据样本扰动</p>
<p>给定初始数据集，可从中产生出不同的数据子集，再利用不同的数据子集训练出不同的个体学习器。数据样本扰动通常是基于采样法，例如在Bagging中使用自助采样，在AdaBoost中使用序列采样。此类做法简单高效，使用最广。对很多常见的基学习器，例如决策树、神经网络等，训练样本稍加变化就会导致学习器有显著变动，数据样本扰动法对这样的“不稳定基学习器”很有效；然而，有一些基学习器对数据样本的扰动不敏感例如线性学习器、支持向量机、朴素贝叶斯、k近邻学习器等，这样的基学习器称为稳定基学习器(stable base learner)，对此类基学习器进行集成往往需使用输入属性扰动等其他机制。</p>
<p>• 输入属性扰动</p>
<p>训练样本通常由一组属性描述，不同的“子空间”(subspace，即属性子集)提供了观察数据的不同视角。显然，从不同子空间训练出的个体学习器必然有所不同。著名的随机子空间(random subspace)算法［Ho, 1998］就依赖于输入属性扰动，该算法从初始属性集中抽取出若干个属性子集，再基于每个属性子集训练一个基学习器，算法描述如图8.11所示，对包含大量元余属性的数据，在子空间中训练、个体学习器不仅能产生多样性大的个体，还会因属性数的减少而大幅节省时间开销，同时，由于冗余属性多，减少一些属性后训练出的个体学习器也不至于太差。若数据只包含少量属性，或者冗余属性很少，则不宜使用输入属性扰动法。</p>
<p>• 输出表示扰动</p>
<p>此类做法的基本思路是对输出表示进行操纵以增强多样性。可对训练样本的类标记稍作变动，如“翻转法”(Flipping Output) ［Breiman, 2000］随机改变一些训练样本的标记；也可对输出表示进行转化，如“输出调制法”(Output Smearing) ［Breiman, 2000］将分类输出转化为回归输出后构建个体学习器；还可将原任务拆解为多个可同时求解的子任务，如ECOC 法［Dietterich and Bakiri, 1995］利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基学习器。</p>
<p>• 算法参数扰动</p>
<p>基学习算法一般都有参数需进行设置，例如神经网络的隐层神经元数、初始连接权值等，通过随机设置不同的参数，往往可产生差别较大的个体学习器。例如“负相关法”(Negative Correlation) ［Liu and Yao, 1999］ 显式地通过正则化项来强制个体神经网络使用不同的参数。对参数较少的算法，可通过将其学习过程中某些环节用其他类似方式代替，从而达到扰动的目的，例如可将决策树使用的属性选择机制替换成其他的属性选择机制。值得指出的是，使用单一学习器时通常需使用交叉验证等方法来确定参数值，这事实上已使用了不同参数训练出多个学习器，只不过最终仅选择其中一个学习器进行使用，而集成学习则相当于把这些学习器都利用起来； 由此也可看出，集成学习技术的实际计算开销并不比使用单一学习器大很多。</p>
<p>不同的多样性增强机制可同时使用，例如8.3.2节介绍的随机森林中同时使用了数据样本扰动和输入属性扰动，有些方法甚至同时使用了更多机制［Zhou,2012 ］。</p>
<h2 id="阅读材料-7"><a href="#阅读材料-7" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>集成学习方面的主要推荐读物是［Zhou,2012］，本章提及的所有内容在该书中都有更深入详细的介绍.［Kuncheva, 2004; Rokach, 2010b］可供参考［Schapire and Freund，2012］则是专门关于Boosting 的著作。</p>
<p>Boosting 源于［Schapire, 1990］对［Kearns and Valiant, 1989］提出的“弱学习是否等价于强学习”这个重要理论问题的构造性证明最初的Boosting算法仅有理论意义，经数年努力后［Freund and Schapire, 1997］ 提出AdaBoost,并因此获得理论计算机科学方面的重要奖项——哥德尔奖。不同集成学习方法的工作机理和理论性质往往有显著不同，例如从偏差一方差分解的角度看，Boosting 主要关注降低偏差，而Bagging 主要关注降低方差.MultiBoosting［Webb, 2000］ 等方法尝试将二者的优点加以结合。关于Boosting 和Bagging已有很多理论研究结果，可参阅［Zhou, 2012］；第2～3 章。</p>
<p>8.2 节给出的AdaBoost 推导源于“统计视角”(statistical view) ［Fried-man et al., 2000］，此派理论认为AdaBoost 实质上是基于加性模型(additive model)以类似牛顿迭代法来优化指数损失函数。受此启发，通过将迭代优化过程替换为其他优化方法，产生了GradientBoosting ［Friedman, 2001］、LPBoost［Demiriz et al., 2008］等变体算法然而，这派理论产生的推论与AdaBoost 实际行为有相当大的差别［Mease and Wyner, 2008］，尤其是它不能解释AdaBoost为什么没有过拟合这个重要现象，因此不少人认为’统计视角本身虽很有意义，但其阐释的是一个与AdaBoost 相似的学习过程而并非AdaBoost 本身。“间隔理论＂ (margin theory) ［Schapire et al., 1998］能直观地解释这个重要现象，但过去15年中一直存有争论，直到最近的研究结果使它最终得以确立，并对新型学习方法的设计给出了启示；相关内容可参阅［Zhou, 2014］。</p>
<p>本章仅介绍了最基本的几种结合方法，常见的还有基于D-S证据理论的方法、动态分类器选择、混合专家(mixture of experts)等。本章仅介绍了成对型多样性度量［Kuncheva and Whitaker, 2003; Tang et al., 2006］显示出，现有多样性度量都存在显著缺陷如何理解多样性，被认为是集成学习中的圣杯问题。关于结合方法和多样性方面的内容，可参阅［Zhou, 2012］第4～5 章。</p>
<p>在集成产生之后再试图通过去除一些个体学习器来获得较小的集成，称为集成修剪(ensemble pruning).这有助于减小模型的存储开销和预测时间开销早期研究主要针对序列化集成进行，减小集成规模后常导致泛化性能下降［Rokach, 2010a］; ［Zhou et al., 2002］ 揭示出对并行化集成进行修剪能在减小规模的同时提升泛化性能，并催生了基于优化的集成修剪技术。这方面的内容可参阅［Zhou, 2012］ 第6章。</p>
<p>关于聚类、半监督学习、代价敏感学习等任务中集成学习的内容，可参阅［Zhou, 2012］ 第7～8 章事实上，集成学习已被广泛用于几乎所有的学习任务。著名数据挖掘竞赛KDDCup历年的冠军几乎都使用了集成学习。</p>
<p>由于集成包含多个学习器，即便个体学习器有较好的可解释性，集成仍是黑箱模型。已有一些工作试图改善集成的可解释性，例如将集成转化为单模型、从集成中抽取符号规则等，这方面的研究衍生出了能产生性能超越集成的单学习器的“二次学习” (twice-learning)技术，例如NeC4.5 算法［Zhou and Jiang, 2004］.可视化技术也对改善可解释性有一定帮助可参阅［Zhou, 2012］第8章。</p>
<h3 id="休息－会儿"><a href="#休息－会儿" class="headerlink" title="休息－会儿"></a>休息－会儿</h3><p>小故事：老当益壮的李奥·布瑞曼</p>
<p>李奥·布瑞曼(Leo Breiman, 1928-2005)是二十世纪伟大的统计学家。他在二十世纪末公开宣称，统计学界把统计搞成了抽象数学，这偏离了初衷，统计学本该是关于预测、解释和处理数据的学问。他自称与机器学习走得更近，因为这一行是在处理有挑战的数据问题。事实上，布瑞曼是一位卓越的机器学习学家，他不仅是CART 决策树的作者，还对集成学习有三大贡献：Bagging 、随机森林以及关于Boosting 的理论探讨有趣的是，这些都是在他1993年从加州大学伯克利分校统计系退休后完成的。</p>
<p>布瑞曼早年在加州理工学院获物理学士学位然后打算到哥伦比亚大学念哲学，但哲学系主任告诉他，自已最优秀的两个博士生没找到工作，于是布瑞曼改学数学，先后在哥伦比亚大学和加州大学伯克利分校获得数学硕士、博士学位。他先是研究概率论，但在加州大学洛杉矶分校(UCLA)做了7 年教授后他厌倦了概率论，于是主动辞职。为了向概率论告别，辞职后他把自已关在家里半年写了本关于概率论的书，然后他到工业界做了13年咨询，再回到加州大学伯克利分校统计系做教授。布瑞曼的经历极为丰富，他曾在UCLA 学术假期间主动到联合国教科文组织工作，被安排到非洲利比里亚统计失学儿童数。他是一位业余雕塑家，甚至还与人合伙在墨西哥开过制冰厂。他自认为一生最重要的研究成果————随机森林，是70 多岁时做出来的。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第9章-聚类"><a href="#第9章-聚类" class="headerlink" title="第9章 聚类"></a>第9章 聚类</h1><h2 id="聚类任务"><a href="#聚类任务" class="headerlink" title="聚类任务"></a>聚类任务</h2><p>在“无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。此类学习任务中研究最多、应用最广的是“聚类”(clustering)。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster.通过这样的划分，每个簇可能对应于一些潜在的概念(类别，如“浅色瓜”，“深色瓜”，“有籽瓜”“无籽瓜”，甚至“本地瓜”“外地瓜”等；需说明的是，这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构，簇所对应的概念语义需由使用者来把握和命名。</p>
<p>形式化地说，假定样本集D={x1, x2，…，Xm}包含m个无标记样本，每个样本））是一个n维特征向量，则聚类算法将样本集D 划分为k个不相交的簇）），其中））且））.相应地，我们用））表示样本町的“簇标记”(cluster label)，即））于是，聚类的结果可用包含m个元素的簇标记向量λ =(λ1； λ2;…; λm)表示</p>
<p>聚类既能作为一个单独过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程例如，在一些商业应用中需对新用户的类型进行判别，但定义“用户类型”对商家来说却可能不太容易，此时往往可先对用户数据进行聚类，根据聚类结果将每个簇定义为一个类，然后再基于这些类训练分类模型，用于判别新用户的类型。</p>
<p>基于不同的学习策略，人们设计出多种类型的聚类算法。本章后半部分将对不同类型的代表性算法进行介绍但在此之前我们先讨论聚类算法涉及的两个基本问题———性能度量和距离计算。</p>
<h2 id="-41"><a href="#-41" class="headerlink" title></a><br></h2><h2 id="性能度量-1"><a href="#性能度量-1" class="headerlink" title="性能度量"></a>性能度量</h2><p>聚类性能度量亦称聚类“有效性指标”(validity index).与监督学习中的性能度量作用相似，对聚类结果，我们需通过某种性能度量来评估其好坏；另一方面，若明确了最终将要使用的性能度量，则可直接将其作为聚类过程的优化目标，从而更好地得到符合要求的聚类结果。</p>
<p>聚类是将样本集D划分为若干互不相交的子集，即样本簇那么，什么样的聚类结果比较好呢？直观上看，我们希望“物以类聚”，即同一簇的样本尽可能彼此相似，不同簇的样本尽可能不同。换言之，聚类结果的“簇内相似度”(intra-cluster similarity)高且“簇间相似度”(inter-cluster similarity)低。</p>
<p>聚类性能度量大致有两类。一类是将聚类结果与某个“参考模型”(reference model)进行比较，称为“外部指标”(external index)；另一类是直接考察聚类结果而不利用任何参考模型，称为“内部指标”(internalindex)。</p>
<p>对数据集）），假定通过聚类给出的簇划分为）），参考模型给出的簇划分为））相应地，令λ 与λ<em> 分别表示与C 和C</em> 对应的簇标记向量。我们将样本两两配对考虑，定义</p>
<p>其中集合SS 包含了在C 中隶属于相同簇且在P 中也隶属于相同簇的样本对，集合SD 包含了在C 中隶属于相同簇但在P 中隶属于不同簇的样本对，……由于每个样本对）） 仅能出现在一个集合中，因此有））成立。</p>
<p>基于式(9.1)～(9.4)可导出下面这些常用的聚类性能度量外部指标。</p>
<p>• Jaccard系数(Jaccard Coefficient，简称JC)<br>））</p>
<p>• FM 指数(Fowlkes and Mallows Index，简称FMI)</p>
<p>• Rand指数(Rand Index，简称RI)<br>））</p>
<p>显然，上述性能度量的结果值均在[0,1]区间，值越大越好，</p>
<p>考虑聚类结果的簇划分）），定义<br>））</p>
<p>其中，dist(.,.)用于计算两个样本之间的距离；μ代表簇C的中心点μ=））显然，对应于簇C内样本间的平均距离，））对应于簇C内样本间的最远距离，对应于簇Ci与簇Cj最近样本间的距离，））对应于簇Ci与簇Cj中心点间的距离。</p>
<p>基于式(9.8)～(9.11)可导出下面这些常用的聚类性能度量内部指标：</p>
<p>• DB指数(Davies-Bouldin Index，简称DBI)<br>））</p>
<p>显然，DBI 的值越小越好，而DI 则相反，值越大越好。</p>
<h2 id="-42"><a href="#-42" class="headerlink" title></a><br></h2><h2 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h2><p>对函数dist(.,.)，若它是一个“距离度量” (distance measure)，则需满足一些基本性质：</p>
<p>非负性：<br>同一性：<br>对称性：<br>直递性：</p>
<p>给定样本）） 与）），最常用的是“闵可夫斯基距离”(Minkowskid istance)</p>
<p>对p≥l时，式(9.1 8显然满足式(9.14)～(9.17)的距离度量基本性质。</p>
<p>p=2 时，闵可夫斯基距离即欧氏距离(Euclid ean d istance)</p>
<p>p=1 时，闵可夫斯基距离即曼哈顿距离(Manhattand istance)</p>
<p>我们常将属性划分为“连续属性”(continuous attribute)和“离散属性”(categorical attribute)，前者在定义域上有无穷多个可能的取值，后者在定义域上是有限个取值。然而，在讨论距离计算时，属性上是否定义了“序”关系更为重要。例如定义域为{1,2,3}的离散属性与连续属性的性质更接近一些，能直接在属性值上计算距离：“1”与“2”比较接近、与“3”比较远，这样的属性称为“有序属性”(ordinal attribute)；而定义域为{飞机，火车，轮船}这样的离散属性则不能直接在属性值上计算距离，称为“无序属性”(non-ordinal attribute)。显然，闵可夫斯基距离可用于有序属性。</p>
<p>对无序属性可采用VDM (Value Difference Metric) ［Stanfill and Waltz,1986］.令mu,a 表示在属性u 上取值为a 的样本数，mu,a,i 表示在第i个样本簇中在属性u 上取值为a 的样本数，k 为样本簇数，则属性u 上两个离散值a 与b之间的VDM距离为</p>
<p>于是，将闵可夫斯基距离和VDM 结合即可处理混合属性假定有nc个有序属性、））个无序属性，不失一般性，令有序属性排列在无序属性之前，则</p>
<p>当样本空间中不同属性的重要性不同时，可使用“加权距离”(weighted distance).以加权闵可夫斯基距离为例：</p>
<p>其中权重））表征不同属性的重要性，通常））。</p>
<p>需注意的是，通常我们是基于某种形式的距离来定义“相似度度量”(similarity measure)，距离越大，相似度越小。然而，用于相似度度量的距离未必一定要满足距离度量的所有基本性质，尤其是直递性(9.17).例如在某些任务中我们可能希望有这样的相似度度量。“人”“马”分别与“人马”相似，但“人”与“马”恨不相似；要达到这个目的，可以令“人”“马”与“人马”之间的距离都比较小，但“人”与“马”之间的距离很大，如图9.1所示，此时该距离不再满足直递性，这样的距离称为“非度量距离”(non-metricdistance.此外，本节介绍的距离计算式都是事先定义好的，但在不少现实任务中，有必要基于数据样本来确定合适的距离计算式，这可通过“距离度量学习”(distance metric learning)来实现。</p>
<h2 id="-43"><a href="#-43" class="headerlink" title></a><br></h2><h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><p>原型聚类亦称“基于原型的聚类”(prototype-based clustering)，此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用。通常情形下，算法先对原型进行初始化，然后对原型进行迭代更新求解。采用不同的原型表示、不同的求解方式，将产生不同的算法。下面介绍几种著名的原型聚类算法。</p>
<h3 id="k均值算法"><a href="#k均值算法" class="headerlink" title="k均值算法"></a>k均值算法</h3><p>给定样本集）），“k均值”(k-means)算法针对聚类所得簇划分）） 最小化平方误差</p>
<p>其中））是簇Ci的均值向量，直观来看，式(9.24)在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度，E 值越小则簇内样本相似度越高。</p>
<p>最小化式(9.24)并不容易，找到它的最优解需考察样本集D 所有可能的簇划分，这是一个NP 难问题［Aloise et al., 2009］.因此，k均值算法采用了贪心策略，通过迭代优化来近似求解式(9.24).算法流程如图9.2 所示，其中第1行对均值向量进行初始化，在第4-8行与第9-16行依次对当前簇划分及均值向量迭代更新，若迭代更新后聚类结果保持不变，则在第18 行将当前簇划分结果返回。</p>
<p>下面以表9.1的西瓜数据集4.0为例来演示k均值算法的学习过程为方便叙述，我们将编号为i的样本称为Xi，这是一个包含“密度”与“含糖率”两个属性值的二维向量。</p>
<p>假定聚类簇数k=3，算法开始时随机选取三个样本X5, X12, X24 作为初始均值向量，即<br>））</p>
<p>考察样本）），它与当前均值向量μ1, μ2，μ3 的的距离分别为）），因此X1 将被划入簇C3中类似的，对数据集中的所有样本考察一遍后，可得当前簇划分为</p>
<p>于是，可从C1 、C2 、C3 分别求出新的均值向量</p>
<p>更新当前均值向量后，不断重复上述过程，如图9.3所示，第五轮迭代产生的结果与第四轮迭代相同，于是算法停止，得到最终的簇划分。</p>
<p>图9.3 西瓜数据集4.0上k 均值算法(k=3)在各轮迭代后的结果。样本点与均值向量分别用“•” 与“＋”表示，红色虚线显示出簇划分。</p>
<h3 id="学习向量量化"><a href="#学习向量量化" class="headerlink" title="学习向量量化"></a>学习向量量化</h3><p>与k 均值算法类似，“学习向量量化”(Learning Vector Quantization)，简称LVQ也是试图找到一组原型向量来刻画聚类结构，但与一般聚类算法不同的是，LVQ 假设数据样本带有类别标记，学习过程利用样本的这些监督信息来辅助聚类。</p>
<p>给定样本集）），每个样本Xj 是由n个属性描述的特征向量）），是样本町的类别标记LVQ 的目标是学得一组η 维原型向量）），每个原型向量代表一个聚类簇，簇标记））,</p>
<p>LVQ 算法描述如图9.4 所示。算法第1 行先对原型向量进行初始化，例如对第q个簇可从类别标记为tq 的样本中随机选取一个作为原型向量。算法第2～12行对原型向量进行迭代优化。在每一轮迭代中，算法随机选取一个有标记训练样本，找出与其距离最近的原型向量，并根据两者的类别标记是否一致来对原型向量进行相应的更新。在第12行中，若算法的停止条件已满足(例如已达到最大迭代轮数，或原型向量更新很小甚至不再更新)，则将当前原型向量作为最终结果返回。</p>
<p>显然，LVQ 的关键是第6-10 行，即如何更新原型向量。直观上看，对样本<br>Xj，若最近的原型向量））与））的类别标记相同，则令））向）） 的方向靠拢，<br>如第7行所示，此时新原型向量为</p>
<p>令学习率η∈(0,1)，则原型向量））在更新为））之后将更接近Xj。</p>
<p>类似的，若））与））的类别标记不同，则更新后的原型向量与町之间的<br>距离将增大为）），从而更远离Xj。</p>
<p>在学得一组原型向量））后，即可实现对样本空间X的簇划分对任意样本队它将被划入与其距离最近的原型向量所代表的族中，换言之，每个原型向量Pi定义了与之相关的一个区域Ri，该区域中每个样本与Pi的距离不大于它与其他原型向量））的距离，即</p>
<p>由此形成了对样本空间X 的簇划分）），该划分通常称为“Voronoi剖分”(Voronoi tessellation)。</p>
<p>下面我们以表9.1 的西瓜数据集4.0 为例来演示LVQ 的学习过程令9-21号样本的类别标记为C2，其他样本的类别标记为q.假定q=5，即学习目标是找到5个原型向量）），并假定其对应的类别标记分别为））。</p>
<p>算法开始时，根据样本的类别标记和簇的预设类别标记对原型向量进行随机初始化，假定初始化为样本））.在第一轮迭代中，假定随机选取的样本为X1，该样本与当前原型向量））的距离分别为）） 由于p5与X1 距离最近且两者具有相同的类别标记c1，假定学习率）），则LVQ 更新民得到新原型向量</p>
<p>将p5 更新为p＇后，不断重复上述过程，不同轮数之后的聚类结果如图9.5 所示</p>
<h3 id="高斯混合聚类"><a href="#高斯混合聚类" class="headerlink" title="高斯混合聚类"></a>高斯混合聚类</h3><p>与k均值、LVQ 用原型向量来刻画聚类结构不同，高斯混合(Mixture-ofGaussian)聚类采用概率模型来表达聚类原型。</p>
<p>我们先简单回顾一下(多元)高斯分布的定义对n维样本空间X中的随机向量x，若x服从高斯分布，其概率密度函数为</p>
<p>其中μ 是n 维均值向量，∑ 是n × n 的协方差矩阵。由式(9.28)可看出，高斯分布完全由均值向量μ 和协方差矩阵∑ 这两个参数确定为了明确显示高斯分布与相应参数的依赖关系，将概率密度函数记为））。</p>
<p>我们可定义高斯混合分布</p>
<p>该分布共由k个混合成分组成，每个混合成分对应一个高斯分布。其中μi与∑i是第4个高斯混合成分的参数，而ai＞0 为相应的“混合系数”(mixture coefficient),））。</p>
<p>假设样本的生成过程由高斯混合分布给出：首先，根据a1，a2，…，ak 定义的先验分布选择高斯混合成分，其中ai为选择第i个混合成分的概率；然后，根据被选择的混合成分的概率密度函数进行采样，从而生成相应的样本</p>
<p>若训练集））由上述过程生成，令随机变量）） 表示生成样本xj的高斯混合成分，其取值未知，显然，Zj 的先验概率））对应于ai(i=l,2,.., k).根据贝叶斯定理，zj的后验分布对应于</p>
<p>换言之，））给出了样本叫由第i个高斯混合成分生成的后验概率。为方便钗述，将其简记为））。</p>
<p>当高斯混合分布(9.29)已知时，高斯混合聚类将把样本集D 划分为k个簇）），每个样本xj的簇标记λj 如下确定:</p>
<p>因此，从原型聚类的角度来看，高斯混合聚类是采用概率模型(高斯分布)对原型进行刻画，簇划分则由原型对应后验概率确定。</p>
<p>那么，对于式(9.29)，模型参数））如何求解呢？显然，给定样本集D，可采用极大似然估计，即最大化(对数似然</p>
<p>常采用EM算法进行迭代优化求解。下面我们做一个简单的推导。</p>
<p>若参数））能使式(9.32)最大化，则由）） 有</p>
<p>即各混合成分的均值可通过样本加权平均来估计，样本权重是每个样本属于该成分的后验概率类似的，由）） 可得</p>
<p>对于混合系数句，除了要最大化）），还需满足））.考虑）） 的拉格朗日形式</p>
<p>其中λ 为拉格朗日乘子。由式(9.36)对ai的导数为0，有</p>
<p>两边同乘以句，对所有混合成分求和可知λ=-m，有</p>
<p>即每个高斯成分的、混合系数由样本属于该成分的平均后验概率确定。</p>
<p>由上述推导即可获得高斯混合模型的EM算法：在每步迭代中，先根据当前参数来计算每个样本属于每个高斯成分的后验概率））(E步)，再根据式(9.34)、(9.35)和(9.38)更新模型参数））(M步)。</p>
<p>高斯混合聚类算法描述如图9.6 所示。算法第1行对高斯混合分布的模型参数进行初始化。然后，在第2-12 行基于EM算法对模型参数进行迭代更新。若EM算法的停止条件满足(例如已达到最大迭代轮数，或似然函数LL(D) 增长很少甚至不再增长，则在第14-17 行根据高斯混合分布确定簇划分，在第18行返回最终结果。</p>
<p>以表9.1 的西瓜数据集4.0 为例，令高斯混合成分的个数k=3.算法开始时，假定将高斯混合分布的模型参数初始化为：</p>
<p>在第一轮迭代中，先计算样本由各泪合成分生成的后验概率。以X1为例，由式(9.30算出后验概率））.所有样本的后验概率算完后，得到如下新的模型参数：<br>））</p>
<p>模型参数更新后，不断重复上述过程，不同轮数之后的聚类结果如图9.7 所示。</p>
<h2 id="-44"><a href="#-44" class="headerlink" title></a><br></h2><h2 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h2><p>密度聚类亦称“基于密度的聚类”(density-based clustering)，此类算法假设聚类结构能通过样本分布的紧密程度确定通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。</p>
<p>DBSCAN 是一种著名的密度聚类算法，它基于一组“邻域”(neigh-borhood)<br>参数））来刻画样本分布的紧密程度。给定数据集）），定义下面这几个概念：</p>
<p>• 𝜺-邻域）），其𝜺-邻域包含样本集D 中与））的距离不大于𝜺 的样<br>本，即））</p>
<p>• 核心对象(core object)：若xj的𝜺-邻域至少包含MinPts个样本，即）），则Xj 是一个核心对象；</p>
<p>• 密度直达(directly density-reachable)：若Xj 位于Xi的𝜺-邻域中，且Xi是核心对象，则称Xj由Xi密度直达；</p>
<p>• 密度可达(density-reachable)：对Xi 与）），若存在样本序列））其中）） 由）） 密度直达，则称Xj 由Xi 密度可达；</p>
<p>• 密度相连(density-connected)：对Xi 与）），若存在Xk 使得Xi 与Xj 均由Xk 密度可达，则称Xi 与Xj 密度相连。</p>
<p>图9.8 给出了上述概念的直观显示。</p>
<p>图9.8 DBSCAN 定义的基本概念(MinPts=3)：虚线显示出𝜺-邻域，X1 是核心对象，X2 由X1 密度直达，X3 由X1 密度可达，X3 与X4 密度相连。</p>
<p>基于这些概念，DBSCAN 将“簇”定义为：由密度可达关系导出的最大的密度相连样本集合。形式化地说，给定邻域参数(𝜺, MinPts)，簇））是满足以下性质的非空样本子集：</p>
<p>连接性(connectivity):））与Xj 密度相连<br>最大性(maximality):））由Xi 密度可达））</p>
<p>那么，如何从数据集D 中找出满足以上性质的聚类簇呢？实际上，若x为核心对象，由x 密度可达的所有样本组成的集合记为））x＇由x密度可达}，则不难证明X 即为满足连接性与最大性的簇。</p>
<p>于是，DBSCAN算法先任选数据集中的一个核心对象为“种子”(seed),再由此出发确定相应的聚类簇，算法描述如图9.9 所示。在第1～7 行中，算法先根据给定的邻域参数(𝜺, MinPts)找出所有核心对象，然后在第10～24 行中，以任一核心对象为出发点，找出由其密度可达的样本生成聚类簇，直到所有核心对象均被访问过为止。</p>
<p>以表9.1 的西瓜数据集4.0 为例，假定邻域参数(E，MinPts)设置为E =））DBSCAN 算法先找出各样本的E－ 邻域并确定核心对象集合））.然后，从。中随机选取一个核心对象作为种子，找出由它密度可达的所有样本，这就构成了第一个聚类簇。不失一般性，假定核心对象均被选中作为种子，则DBSCAN生成的第一个聚类簇为</p>
<p>然后，DBSCAN将C1中包含的核心对象从。中去除））再从更新后的集合。中随机选取一个核心对象作为种子来生成下一个聚类簇。上述过程不断重复，直至。为空图9.10 显示出DBSCAN 先后生成聚类簇的情况.C1 之后生成的聚类簇为</p>
<h2 id="-45"><a href="#-45" class="headerlink" title></a><br></h2><h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><p>层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用“自底向上”的聚合策略，也可采用“自顶向下”的分拆策略。</p>
<p>AGNES 是一种采用自底向上聚合策略的层次聚类算法。它先将数据集中的每个样本看作一个初始聚类簇然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直至达到预设的聚类簇个数。这里的关键是如何计算聚类簇之间的距离。实际上，每个族是一个样本集合，因此，只需采用关于集合的某种距离即可例如，给定聚类族Ci 与Cj，可通过下面的式子来计算距离：</p>
<p>最小距离：<br>最大距离：<br>平均距离：</p>
<p>显然，最小距离由两个簇的最近样本决定，最大距离由两个簇的最远样本决定，而平均距离则由两个簇的所有样本共同决定。当聚类簇距离由dmin 、dmax 或davg计算时，AGNES算法被相应地称为“单链接”(single-linkage) 、“ 全链接”(complete-linkage)或“均链接”(average-linkage)算法。</p>
<p>AGNES算法描述如图9.11所示。在第19行，算法先对仅含一个样本的初始聚类簇和相应的距离矩阵进行初始化；然后在第11-23行，AGNES不断合并距离最近的聚类簇，并对合并得到的聚类簇的距离矩阵进行更新；上述过程不断重复，直至达到预设的聚类簇数。</p>
<p>以西瓜数据集4.0 为例，令AGNES 算法一直执行到所有样本出现在同一个簇中，即k=l，则可得到图9.12 所示的“ 树状图” (dendrogram)，其中每层链接一组聚类簇。</p>
<p>在树状图的特定层次上进行分割，则可得到相应的簇划分结果。例如，以图9.12中所示虚线分割树状图，将得到包含7个聚类簇的结果。</p>
<p>将分割层逐步提升，则可得到聚类簇逐渐减少的聚类结果。例如图9.13显示出了从图9.12中产生7至4个聚类簇的划分结果</p>
<h2 id="阅读材料-8"><a href="#阅读材料-8" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>聚类也许是机器学习中“新算法”出现最多、最快的领域。一个重要原因是聚类不存在客观标准；给定数据集，总能从某个角度找到以往算法未覆盖的某种标准从而设计出新算法［Estivill-Castro, 2002］.相对于机器学习其他分支来说，聚类的知识还不够系统化，因此著名教科书［Mitchell, 1997］中甚至没有关于聚类的章节但聚类技术本身在现实任务中非常重要，因此本章勉强采用了“列举式”的叙述方式，相较于其他各章给出了更多的算法描述。关于聚类更多的内容，可参阅这方面的专门书籍和综述文章如［Jain and Dubes, 1988;Jamn et al., 1999; Xu and Wunsch II, 2005; Jamn, 2009］等。</p>
<p>聚类性能度量除9.2 节的内容外，常见的还有F值、互信息(mutual information)、平均廓宽(average silhouette width) ［Rousseeuw, 1987］等，可参阅［Jain and Dubes, 1988; Halkidi et al., 2001; Maulik and Bandyopadhy，2002］。</p>
<p>距离计算是很多学习任务的核心技术。闵可夫斯基距离提供了距离计算的一般形式。除闵可夫斯基距离之外，内积距离、余弦距离等也很常用，可参阅［Deza and Deza, 2009］.MinkovDM 在［Zhou and Yu, 2005］中正式给出。模式识别、图像检索等涉及复杂语义的应用中常会涉及非度量距离［Jacobs et al.,2000; Tan et al., 2009］.距离度量学习可直接嵌入到聚类学习过程中［Xing etal., 2003］。</p>
<p>k 均值算法可看作高斯混合聚类在混合成分方差相等、且每个样本仅指派给一个混合成分时的特例。该算法在历史上曾被不同领域的学者多次重新发明，如Steinhaus 在1956年、Lloyd 在1957年、McQueen 在1967年等［Jain and Dubes, 1988 ; Jain, 2009］.k 均值算法有大量变体，如k-medoids 算法［Kaufman and Rousseeuw, 1987］强制原型向量必为训练样本，k-modes 算法［Huang，1998］可处理离散属性，Fuzzy C-means (简称FCM) ［Bezdek, 1981］则是“软聚类”(soft clustering)算法，允许每个样本以不同程度同时属于多个原型。需注意的是，k 均值类算法仅在凸形簇结构上效果较好。最近研究表明，若采用某种Bregman 距离，则可显著增强此类算法对更多类型簇结构的适用性［Banerjee et al., 2005］.引入核技巧则可得到核k 均值(kernel k-means)算法［Scholkopf et al., 1998］，这与谱聚类(spectral clustering) ［von Luxburg, 2007］有密切联系［Dhillon et a l., 2004］，后者可看作在拉普拉斯特征映射(Laplacia nEigenmap降维后执行k 均值聚类。聚类簇数k 通常需由用户提供，有一些启发式用于自动确定k ［Pelleg and Moore, 2000; Tibshirani et al，2001］，但常用的仍是基于不同k 值多次运行后选取最佳结果</p>
<p>LVQ 算法在每轮迭代中仅更新与当前样本距离最近的原型向量。同时更新多个原型向量能显著提高收敛速度，相应的改进算法有LVQ2, LVQ3 等［Kohonen, 2001］.［McLachlan and Peel, 2000］详细介绍了高斯混合聚类，算法中EM 迭代优化的推导过程可参阅［Bilmes, 1998; Jain and Dubes, 1988］。</p>
<p>采用不同方式表征样本分布的紧密程度，可设计出不同的密度聚类算法，除DBSCAN ［Ester et al., 1996］外，较常用的还有OPTICS ［Ankerst et al.,1999］、DENCLUE ［Hinneburg and Keim., 1998］等.AGNES ［Kaufman and Rousseeuw, 1990］采用了自底向上的聚合策略来产生层次聚类结构，与之相反，DIANA ［Kaufman and Rousseeuw, 1990］则是采用自顶向下的分拆策略。AGNES 和DIANA 都不能对已合并或已分拆的聚类簇进行回溯调整，常用的层次聚类算法如BIRCH ［Zhang et al., 1996］ 、ROCK ［Guha et al., 1999］等对此进行了改进。</p>
<p>聚类集成(clustering ensemble)通过对多个聚类学习器进行集成，能有效降低聚类假设与真实聚类结构不符、聚类过程中的随机性等因素带来的不利影响，可参阅读［Zhou, 2012］第7章。</p>
<p>异常检测(anomaly detection) ［Hodge and Austin, 2004; Chandola et., 2009］常借助聚类或距离计算进行，如将远离所有簇中心的样本作为异常点，或将密度极低处的样本作为异常点最近有研究提出基于“隔离性”(isolation)可快速检测出异常点［Liu et al., 2012］。</p>
<h3 id="休息一会儿-7"><a href="#休息一会儿-7" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事： 曼哈顿距高与赫尔曼·闵可夫斯基</p>
<p>曼哈顿距离(Manhattan distance)亦称“出租车几何”(Taxicab geometry)，是德国大数学家赫尔曼·闵可夫斯基(Hermann Minkowski, 1864 1909)所创的词汇，其得名是由于该距离标明了几何度量空间中两点在标准坐标系上的绝对轴距总和，这恰是规划为方形区块的城市里两点之间的最短行程，例如从曼哈顿的第五大道与33街交点前往第三大道与23街交点，需走过(5-3)+(33-23)=12个街区。</p>
<p>闵可夫斯基出生于俄国亚力克索塔斯(Alexotas)的一个犹太人家庭，由于当时俄国政府迫害犹太人，他八岁时随全家移居普鲁士哥尼斯堡，与后来成为大数学家的希尔伯特一河之隔。闵可夫斯基从小就是著名神童，他熟读莎士比亚、席勒和歌德的作品，几乎能全文背诵《浮士德》；八岁进入预科学校，仅用五年半就完成了八年的学业；十七岁时建立了n元二次型的完整理论体系，解决了法国科学院公开悬赏的数学难题.1908年9月他在科隆的一次学术会议上做了《空间与时间》的著名演讲，提出了四维时空理论，为广义相对论的建立开辟了道路。不幸的是，三个月后他死于急性阑尾炎。</p>
<p>1896年闵可夫斯基在苏黎世大学任教期间，是爱因斯坦的数学老师。诺贝尔物理学奖得主玻恩曾说，在闵可夫斯基的数学工作中找到了“相对论的整个武器库”。闵可夫斯基去世后，其生前好友希尔伯特整理了他的遗作，于1911年出版了《闵可夫斯基全集》。闵可夫斯基的哥哥奥斯卡是“亮岛素之父侄”子鲁道夫是美国著名天文学家。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第10章-降维与度量学习"><a href="#第10章-降维与度量学习" class="headerlink" title="第10章 降维与度量学习"></a>第10章 降维与度量学习</h1><h2 id="k近邻学习"><a href="#k近邻学习" class="headerlink" title="k近邻学习"></a>k近邻学习</h2><p>k近邻(k-Nearest Neighbor，简称kNN)学习是一种常用的监督学习方法，其工作机制非常简单：给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个“邻居”的信息来进行预测。通常，在分类任务中可使用“投票法”，即选择这k个样本中出现最多的类别标记作为预测结果；在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。</p>
<p>与前面介绍的学习方法相比，k近邻学习有一个明显的不同之处：它似乎没有显式的训练过程！事实上，它是“懒惰学习”(lazy learning)的著名代表，此类学习技术在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到测试样本后再进行处理；相应的，那些在训练阶段就对样本进行学习处理的方法，称为“急切学习”(eager learning)。</p>
<p>图10.1给出了k近邻分类器的一个示意图。显然，k是一个重要参数，当k取不同值时，分类结果会有显著不同。另一方面，若采用不同的距离计算方式，则找出的“近邻”可能有显著差别，从而也会导致分类结果有显著不同。</p>
<p>暂且假设距离计算是“恰当”的，即能够恰当地找出k个近邻，我们来对“最近邻分类器”(1NN，即k=1)在二分类问题上的性能做一个简单的讨论。</p>
<p>给定测试样本x，若其最近邻样本为z，则最近邻分类器出错的概率就是x与z类别标记不同的概率，即</p>
<p>假设样本独立同分布，且对任意x 和任意小正数𝜹，在x 附近𝜹 距离范围内总能找到一个训练样本，换言之，对任意测试样本，总能在任意近的范围内找到式(10.1)中的训练样本z.令）） 表示贝叶斯最优分类器的结果，有</p>
<p>于是我们得到了有点令人惊讶的结论·最近邻分类器虽简单，但它的泛化错误率不超过贝叶斯最优分类器的错误率的两倍!</p>
<h2 id="-46"><a href="#-46" class="headerlink" title></a><br></h2><h2 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h2><p>上一节的讨论是基于一个重要假设。任意测试样本z 附近任意小的𝜹 距离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或称为“密采样”(dense sample).然而，这个假设在现实任务中通常很难满足，例如若0=0.001，仅考虑单个属性，则仅需1000个样本点平均分布在归一化后的属性取值范围内，即可使得任意测试样本在其附近0.001距离范围内总能找到一个训练样本，此时最近邻分类器的错误率不超过贝叶斯最优分类器的错误率的两倍。然而，这仅是属性维数为1的情形，若有更多的属性，则情况会发生显著变化例如假定属性维数为20，若要求样本满足密采样条件》则至少需10的60次方个样本。现实应用中属性维数经常成千上万，要满足密采样条件所需的样本数目是无法达到的天文数字。此外，许多学习方法都涉及距离计算，而高维空问会给距离计算带来很大的麻烦例如当维数很高时甚至连计算内积都不再容易。</p>
<p>事实上，在高维情形下出现的数据样本稀疏、距离计算困难等问题，是所有机器学习方法共同面临的严重障碍，被称为“维数灾难”(curse ofdimensionality)。</p>
<p>缓解维数灾难的一个重要途径是降维(dimension reduction)，亦称“维数约简”，即通过某种数学变换将原始高维属性空间转变为一个低维“子空间”(subspace)，在这个子空间中样本密度大幅提高，距离计算也变得更为容易。为什么能进行降维，这是因为在很多时候，人们观测或收集到的数据样本虽是高维的，但与学习任务密切相关的也许仅是某个低维分布，即高维空间中的一个低维“嵌入”(embedding).图10.2给出了一个直观的例子原始高维空间中的样本点，在这个低维嵌入子空间中更容易进行学习。</p>
<p>若要求原始空间中样本之间的距离在低维空间中得以保持，如图10.2所示，即得到“多维缩放”(Multiple Dimensional Scaling，简称MDS) ［Cox andCox, 2001］这样一种经典的降维方法下面做一个简单的介绍。</p>
<p>假定m个样本在原始空间的距离矩阵为）），其第i 行j 列的元素dist ij 为样本xi到xj的距离我们的目标是获得样本在d＇维空间的表示）），且任意两个样本在d＇ 维空间中的欧氏距离等于原始空间中的距离，即））。</p>
<p>令））其中B 为降维后样本的内积矩阵，）），有</p>
<p>为便于讨论，令降维后的样本Z 被中心化，即）） 显然，矩阵B的行与列之和均为零，即）） 易知</p>
<p>其中tr表示矩阵的迹(trace),</p>
<p>由此即可通过降维前后保持不变的距离矩阵D 求取内积矩阵B</p>
<p>对矩阵B 做特征值分解(eigenvalue decomposition), B=VAVT，其中）） 为特征值构成的对角矩阵，））为特征向量矩阵假定其中有d个非零特征值，它们构成对角矩阵）），令v＊表示相应的特征向量矩阵，则Z 可表达为</p>
<p>在现实应用中为了有效降维往往仅需降维后的距离与原始空间中的距离尽可能接近，而不必严格相等。此时可取d＇« d个最大特征值构成对角矩阵）），令V 表示相应的特征向量矩阵，则Z 可表达为</p>
<p>图10.3 给出了MDS 算法的描述。</p>
<p>一般来说，欲获得低维子空间，最简单的是对原始高维空间进行线性变换给定d维空间中的样本）），变换之后得到））维空间中的样本</p>
<p>其中））是变换矩阵，））是样本在新空间中的表达。</p>
<p>变换矩阵W可视为d＇个d维基向量，））第1个样本与这d＇个基向量分别做内积而得到的d＇维属性向量。换言之，码是原属性向量凯在新坐标系））中的坐标向量。若Wi 与）） 正交，则新坐标系是一个正交坐标系，此时W 为正交变换显然，新空间中的属性是原空间中属性的线性组合。</p>
<p>基于线性变换来进行降维的方法称为线性降维方法，它们都符合式(10.13)的基本形式，不同之处是对低维子空间的性质有不同的要求，相当于对W 施加了不同的约束。在下一节我们将会看到，若要求低维子空间对样本具有最大可分性，则将得到一种极为常用的线性降维方法。</p>
<p>对降维效果的评估，通常是比较降维前后学习器的性能，若性能有所提高则认为降维起到了作用。若将维数降至二维或三维，则可通过可视化技术来直观地判断降维效果。</p>
<h2 id="-47"><a href="#-47" class="headerlink" title></a><br></h2><h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>主成分分析(Principal Component Analysis，简称PCA)是最常用的一种降维方法。在介绍PCA 之前，不妨先考虑这样一个问题对于正交属性空间中的样本点，如何用一个超平面(直线的高维推广)对所有样本进行恰当的表达？</p>
<p>容易想到，若存在这样的超平面，那么它大概应具有这样的性质：</p>
<p>· 最近重构性：样本点到这个超平面的距离都足够近；<br>· 最大可分性。样本点在这个超平面上的投影能尽可能分开。</p>
<p>有趣的是，基于最近重构性和最大可分性，能分别得到主成分分析的两种等价推导。我们先从最近重构性来推导。</p>
<p>假定数据样本进行了中心化，即））；再假定投影变换后得到的新坐标系为）），其中Wi是标准正交基向量））.若丢弃新坐标系中的部分坐标，即将维度降低到d’＜d，则样本点Xi在低维坐标系中的投影是））其中））是Xi 在低到d’＜d，则样本点xi维坐标系下第j 维的坐标，若基于））来重构xi，则会得到））。</p>
<p>考虑整个训练集，原样本点Xi 与基于投影重构的样本点xi 之间的距离为</p>
<p>其中））· 根据最近重构性，式(10.14)应被最小化，考虑到Wj 是标准正交基，））是协方差矩阵，有</p>
<p>这就是主成分分析的优化目标。</p>
<p>从最大可分性出发，能得到主成分分析的另一种解释。我们知道，样本点凯在新空间中超平面上的投影是）），若所有样本点的投影能尽可能分开，则应该使投影后样本点的方差最大化，如图10.4 所示。</p>
<p>投影后样本点的方差是）），于是优化目标可写为</p>
<p>显然，式(10.16与(10.15)等价。</p>
<p>对式(10.15)或(10.16)使用拉格朗日乘子法可得<br>））</p>
<p>于是，只需对协方差矩阵xxT 进行特征值分解，将求得的特征值排序：<br>）），再取前d＇个特征值对应的特征向量构成））.这就是主成分分析的解.PCA 算法描述如图10.5 所示。</p>
<p>降维后低维空间的维数d＇通常是由用户事先指定，或通过在d＇值不同的低维空间中对k近邻分类器(或其他开销较小的学习器)进行交叉验证来选取较好的d＇值。对PCA，还可从重构的角度设置一个重构阈值，例如t=95%，然后选取使下式成立的最小d＇值：</p>
<p>PCA仅需保留W＊与样本的均值向量即可通过简单的向量减法和矩阵－向量乘法将新样本投影至低维空间中，显然，低维空间与原始高维空间必有不同，因为对应于最小的d-d＇个特征值的特征向量被舍弃了，这是降维导致的结果，但舍弃这部分信息往往是必要的：一方面舍弃这部分信息之后能使样本的采样密度增大，这正是降维的重要动机；另一方面，当数据受到噪声影响时，最小的特征值所对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到去噪的效果。</p>
<h2 id="-48"><a href="#-48" class="headerlink" title></a><br></h2><h2 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a>核化线性降维</h2><p>线性降维方法假设从高维空间到低维空间的函数映射是线性的，然而，在不少现实任务中，可能需要非线性映射才能找到恰当的低维嵌入。图10.6给出了一个例子，样本点从三维空间中的矩形区域采样后以S形曲面嵌入到三维空间，若直接使用线性阵维方法对三维空间观察到的样本点进行降维，则将丢失原本的低维结构。为了对“原本采样的”低维空间与降维后的低维空间加以区别，我们称前者为“本真”(intrinsic)低维空间。</p>
<p>图10.6 三维空间中观察到的3000个样本点，是从本真二维空间中矩形区域采样后以S形曲面嵌入，此情形下线性降维会丢失低维结构。图中数据点的染色显示出低维空间的结构。</p>
<p>非线性阵维的一种常用方法，是基于核技巧对线性降维方法进行“核化”(kernelized).下面我们以核主成分分析(Kernelized PCA，简称KPCA)［Scholkopf et al., 1998］为例来进行演示。</p>
<p>假定我们将在高维特征空间中把数据投影到由））确定的超平面上，则对于）），由式(10.17)有</p>
<p>其中Zi 是样本点Xi 在高维特征空间中的像，易知</p>
<p>其中））是ai的第j个分量假定Zi是由原始属性空间中的样本点Xi通过映射∅产生，即））.若∅能被显式表达出来，则通过它将样本映射至高维特征空间，再在特征空间中实施PCA 即可。</p>
<p>式(10.19)变换为</p>
<p>式(10.20)变换为</p>
<p>一般情形下，我们不清楚∅的具体形式，于是引入核函数</p>
<p>将式(10.22)和(10.23)代入式(10.21)后化简可得</p>
<p>其中K为κ对应的核矩阵(K)））·显然，式(10.24)是特征值分解问题，取K最大的d＇个特征值对应的特征向量即可。</p>
<p>对新样本x，其投影后的第）） 维坐标为</p>
<p>其中ai已经过规范化。式(10.25)显示出，为获得投影后的坐标，KPCA需对所有样本求和，因此它的计算开销较大。</p>
<h2 id="-49"><a href="#-49" class="headerlink" title></a><br></h2><h2 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h2><p>流形学习(manifold learning)是一类借鉴了拓扑流形概念的降维方法。“流形”是在周部与欧氏空间同胚的空间，换言之，它在局部具有欧氏空间的性质，能用欧氏距离来进行距离计算。这给降维方法带来了很大的启发：若低维流形嵌入到高维空间中，则数据样本在高维空间的分布虽然看上去非常复杂，但在局部上仍具有欧氏空间的性质，因此，可以容易地在局部建立降维映射关系，然后再设法将局部映射关系推广到全局。当维数被降至二维或三维时，能对数据进行可视化展示，因此流形学习也可被用于可视化。本节介绍两种著名的流形学习方法。</p>
<h3 id="等度量映射"><a href="#等度量映射" class="headerlink" title="等度量映射"></a>等度量映射</h3><p>等度量映射(Isometric Mapping，简称Isomap) ［Tenenbaum et al., 2000］的基本出发点，是认为低维流形嵌入到高维空间之后，直接在高维空间中计算直线距离具有误导性，因为高维空间中的直线距离在低维嵌入流形上是不可达的。如图10.7(a)所示，低维嵌入流形上两点间的距离是“测地线”(geodesic)距离·想象一只虫子从一点爬到另一点，如果它不能脱离曲面行走，那么图10.7(a)中的红色曲线是距离最短的路径，即S曲面上的测地线，测地线距离是两点之间的本真距离。显然，直接在高维空间中计算直线距离是不恰当的。</p>
<p>那么，如何计算测地线距离呢？这时我们可利用流形在局部上与欧氏空间同胚这个性质，对每个点基于欧氏距离找出其近邻点，然后就能建立一个近邻连接图，图中近邻点之间存在连接，而非近邻点之间不存在连接，于是，计算两点之间测地线距离的问题，就转变为计算近邻连接图上两点之间的最短路径问题。从图10.7(b)可看出，基于近邻距离逼近能获得低维流形上测地线距离很好的近似。</p>
<p>在近邻连接图上计算两点间的最短路径，可采用著名的D让kstra算法或Floyd算法，在得到任意两点的距离之后，就可通过10.2 节介绍的MDS 方法来获得样本点在低维空间中的坐标图10.8 给出了Isomap 算法描述</p>
<p>需注意的是，Isomap仅是得到了训练样本在低维空间的坐标，对于新样本，如何将其映射到低维空间呢？这个问题的常用解决方案，是将训练样本的高维空间坐标作为输入、低维空间坐标作为输出，训练一个回归学习器来对新样本的低维空间坐标进行预测。这显然仅是一个权宜之计，但目前似乎并没有更好的办法。</p>
<p>对近邻图的构建通常有两种做法，一种是指定近邻点个数，例如欧氏距离最近的k个点为近邻点，这样得到的近邻图称为k 近邻图；另一种是指定距离阈值E，距离小于E 的点被认为是近邻点，这样得到的近邻图称为E近邻图两种方式均有不足，例如若近邻范围指定得较大，则距离很远的点可能被误认为近邻，这样就出现“短路”问题，近邻范围指定得较小，则图中有些区域可能与其他区域不存在连接，这样就出现“断路”问题短路与断路都会给后续的最短路径计算造成误导。</p>
<h3 id="局部线性嵌入"><a href="#局部线性嵌入" class="headerlink" title="局部线性嵌入"></a>局部线性嵌入</h3><p>与Isomap 试图保持近邻样本之间的距离不同，局部线性嵌入(Locally Linear Embedding，简称LLE) ［Roweis and Saul, 2000］试图保持邻域内样本之间的线性关系。如图10.9 所示，假定样本点Xi 的坐标能通过它的邻域样本）），XL 的坐标通过线性组合而重构出来，即</p>
<p>LLE 希望式(10.26)的关系在低维空间中得以保持。</p>
<p>LLE 先为每个样本Xi 找到其近邻下标集合Qi，然后计算出基于Qi 中的样本点对Xi 进行线性重构的系数Wi:</p>
<p>其中Xi 和Xj 均为已知，令））有闭式解</p>
<p>LLE 在低维空间中保持w不变，于是Xi 对应的低维空间坐标均可通过下式求解：</p>
<p>式(10.27)与(10.29)的优化目标同形，唯一的区别是式(10.27)中需确定的是W而式(10.29)中需确定的是院对应的低维空间坐标码·</p>
<p>则式(10.29)可重写为</p>
<p>式(10.31)可通过特征值分解求解： M最小的d＇个特征值对应的特征向量组成的矩阵即为zT。</p>
<p>LLE的算法描述如图10.10所示。算法第4行显示出：对于不在样本xi邻域区域的样本Xj，无论其如何变化都对xi和Zi 没有任何影响；这种将变动限制在局部的思想在许多地方都有用。</p>
<h2 id="-50"><a href="#-50" class="headerlink" title></a><br></h2><h2 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h2><p>在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中进行学习能比原始空间性能更好。事实上，每个空间对应了在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一个合适的距离度量。那么，为何不直接尝试“学习”出一个合适的距离度量呢，这就是度量学习(metric learning)的基本动机。</p>
<p>欲对距离度量进行学习，必须有一个便于学习的距离度量表达形式.9.3节给出了很多种距离度量的表达式，但它们都是“固定的”、没有可调节的参数，因此不能通过对数据样本的学习来加以改善。为此，我们先来做一个推广。</p>
<p>对两个d 维样本Xi 和xj，它们之间的平方欧氏距离可写为<br>））</p>
<p>其中dist ij,k 表示Xi 与Xj 在第k 维上的距离。若假定不同属性的重要性不同，则可引入属性权重w，得到<br>））</p>
<p>其中））,））是一个对角矩阵，））</p>
<p>式(10.33)中的W 可通过学习确定，但我们还能再往前走一步：W 的非对角元素均为零，这意味着坐标轴是正交的，即属性之间无关；但现实问题中往往不是这样，例如考虑西瓜的“重量”和“体积”这两个属性，它们显然是正相关的，其对应的坐标轴不再正交。为此，将式(10.33)中的W 替换为一个普通的半正定对称矩阵M，于是就得到了马氏距离(Mahalanobis distance)<br>））</p>
<p>其中M亦称“度量矩阵”，而度量学习则是对M进行学习．注意到为了保持距离非负且对称，M必须是(半)正定对称矩阵，即必有正交基P 使得M 能写为M=PPT。</p>
<p>对M 进行学习当然要设置一个目标。假定我们是希望提高近邻分类器的性能，则可将M 直接嵌入到近邻分类器的评价指标中去，通过优化该性能指标相应地求得M.下面我们以近邻成分分析(Neighbourhood ComponentAnalysis，简称NCA) ［Goldberger et al., 2005］为例进行讨论。</p>
<p>近邻分类器在进行判别时通常使用多数投票法，邻域中的每个样本投1票，邻域外的样本投0票，不妨将其替换为概率投票法。对于任意样本xj，它对Xi分类结果影响的概率为</p>
<p>当i=j 时，P ij 最大。显然，xj对xi的影响随着它们之间距离的增大而减小。若以留一法(LOO)正确率的最大化为目标，则可计算xi的留一法正确率，即它被自身之外的所有样本正确分类的概率为</p>
<p>其中 wi 表示与Xi 属于相同类别的样本的下标集合。于是，整个样本集上的留一法正确率为<br>））</p>
<p>将式(10.35)代入(10.37)，再考虑到M=PPT，则NCA 的优化目标为<br>））</p>
<p>求解式(10.38)即可得到最大化近邻分类器LOO 正确率的距离度量矩阵M。</p>
<p>实际上，我们不仅能把错误率这样的监督学习目标作为度量学习的优化目标，还能在度量学习中引入领域知识。例如，若已知某些样本相似、某些样本不相似，则可定义“必连”(must-link)约束集合M 与“勿连” (cannot-link)约束集合C））表示Xi 与Xj 相似，）） 表示Xi 与Xk 不相似显然，我们希望相似的样本之间距离较小，不相似的样本之间距离较大，于是可通过求解下面这个凸优化问题获得适当的度量矩阵M ［Xing et al., 2003］:<br>））</p>
<p>其中约束M≽0表明M必须是半正定的。式(10.39)要求在不相似样本间的距离不小于1的前提下，使相似样本间的距离尽可能小。</p>
<p>不同的度量学习方法针对不同目标获得“好”的半正定对称距离度量矩阵M，若M 是一个低秩矩阵，则通过对M 进行特征值分解，总能找到一组正交基，其正交基数目为矩阵M的秩rank(M)，小于原属性数d.于是，度量学习学得的结果可衍生出一个降维矩阵P∈JR.d x rank(M)，能用于降维之目的。</p>
<h2 id="阅读材料-9"><a href="#阅读材料-9" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>懒惰学习方法主要有k 近邻学习器、懒惰决策树［Friedman et al., 1996］;朴素贝叶斯分类器能以懒惰学习方式使用，也能以急切学习方式使用关于懒惰学习的更多内容可参阅［Aha, 1997］。</p>
<p>主成分分析是一种无监督的线性降维方法，监督线性降维方法最著名的是线性判别分析(LDA) ［Fisher, 1936］，参见3.4节，其核化版本KLDA ［Baudatand Anouar, 2000］参见6.6节，通过最大化两个变量集合之间的相关性，则可得到“典型相关分析”(Canonical Correlation Analysis，简称CCA) ［Rotelling，1936］及其核化版本KCCA ［Harden et al., 2004］，该方法在多视图学习(multiviewlearning中有广泛应用。在模式识别领域人们发现，直接对矩阵对象(例如一幅图像进行降维操作会比将其拉伸为向量(例如把图像逐行拼接成一个向量再进行降维操作有更好的性能，于是产生了2DPCA ［Yang et al., 2004］、2DLDA ［Ye et al., 2005］、(2D)2PCA ［Zhang and Zhou, 2005］等方法，以及基于张量（tensor）的方法［Kolda and Bader, 2009］。</p>
<p>除了Isomap 和LLE，常见的流形学习方法还有拉普拉斯特征映射(Laplcian Eigenmaps，简称LE) ［Belkin and Niyogi, 2003］、局部切空间对齐(LocalTangent Space Alignment，简称LTSA) ［Zhang and Zha, 2004］等。局部保持投影(Locality Preserving Projections，简称LPP) ［He and Niyogi, 2004］是基于LE 的线性降维方法对监督学习而言，根据类别信息扭曲后的低维空间常比本真低维空间更有利［Geng et al., 2005］.值得注意的是，流形学习欲有效进行邻域保持则需样本密采样，而这恰是高维情形下面临的重大障碍，因此流形学习方法在实践中的降维性能往往没有预期的好；但邻域保持的想法对机器学习的其他分支产生了重要影响，例如半监督学习中有著名的流形假设、流形正则化［Belkin et al., 2006］.［Yan et al., 2007］从图嵌入的角度给出了降维方法的一个统一框架。</p>
<p>将必连关系、勿连关系作为学习任务优化目标的约束，在半监督聚类的研究中使用得更早［Wagstaff et al., 2001］.在度量学习中，由于这些约束是对所有样本同时发生作用［Xing et al., 2003］，因此相应的方法被称为全局度量学习方法。人们也尝试利用局部约束(例如邻域内的三元关系)，从而产生了周部距离度量学习方法［Weinberger and Saul, 2009］，甚至有一些研究试图为每个样本产生最合适的距离度量［Frome et al., 2007; Zhan et al., 2009］.在具体的学习与优化求解方面，不同的度量学习方法往往采用了不同的技术，例如［Yang et al., 2006］将度量学习转化为判别式概率模型框架下基于样本对的二分类问题求解，［Davis et al., 2007］ 将度量学习转化为信息论框架下的Bregman 优化问题，能方便地进行在线学习。</p>
<h3 id="休息一会儿-8"><a href="#休息一会儿-8" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：主成分分析与卡尔·皮尔逊</p>
<p>主成分分析(PCA)是迄今最常用的降维方法，它有许多名字，例如线性代数中的散度矩阵奇异值分解(SYD)、统计学中的因子分析(factor analysis)、信号处理中的离散Karhunen-Loeve 变换、图像分析中的Hotelling 变换、文本分析中的潜在语义分析(LSA)、机械工程中的本征正交分解(POD)、气象学中的经验直交函数(EOF)、结构动力学中的经验模分析(EMA)、心理测量学中的Schmidt-Mirsky 定理等。</p>
<p>卡尔· 皮尔逊(Karl Pearson, 1857-1936)在1901年发明了PCA.皮尔逊是一位罕见的百科全书式的学者，他是统计学家、应用数学家、哲学家、历史学家、民俗学家、宗教学家、人类学家、语言学家，还是社会活动家、教育改革家、作家.1879年他从剑桥大学国王学院数学系毕业，此后到德国海德堡大学、柏林大学等地游学：涉猎广泛.1884年他开始在伦敦大学学院(University College London，简称UCL)担任应用数学讲席教授，39岁时成为英国皇家学会会士。他在1892年出版的科学哲学经典名著《科学的规范》，为爱因斯坦创立相对论提供了启发。皮尔逊对统计学作出了极为重要的贡献，例如他提出了相关系数、标准差、卡方检验、矩估计等，并为假设检验理论、统计决策理论奠定了基础，被尊为“统计学之父”。</p>
<p>皮尔逊开展统计学研究是因受到了生物学家F.Galton 和W.Welton 的影响，希望使进化论能进行定量描述和分析.1901年他们三人创立了著名的统计学期刊Biometrika，皮尔逊担任主编直至去世。皮尔逊的独子Egon 也是著名统计学家，是著名的“奈曼－皮尔逊定理”中的皮尔逊，他子承父业出任UCL的统计学教授以及Biornetrika 主编，后来担任了英国皇家统计学会主席。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第11章-特征选择与稀疏学习"><a href="#第11章-特征选择与稀疏学习" class="headerlink" title="第11章 特征选择与稀疏学习"></a>第11章 特征选择与稀疏学习</h1><h2 id="子集搜索与评价"><a href="#子集搜索与评价" class="headerlink" title="子集搜索与评价"></a>子集搜索与评价</h2><p>我们能用很多属性描述一个西瓜，例如色泽、恨蒂、敲声、纹理、触感等；但有经验的人往往只需看看根蒂、昕昕敲声就知道是否好瓜。换言之，对一个学习任务来说，给定属性集，其中有些属性可能很关键、很有用，另一些属性则可能没什么用。我们将属性称为“特征”(feature)，对当前学习任务有用的属性称为“相关特征”(relevant feature)、没什么用的属性称为“无关特征”(irrelevant feature).从给定的特征集合中选择出相关特征子集的过程，称为“特征选择”(feature selection)。</p>
<p>特征选择是一个重要的“数据预处理”(data preprocessing)过程，在现实机器学习任务中，获得数据之后通常先进行特征选择，此后再训练学习器。那么，为什么要进行特征选择呢？</p>
<p>有两个很重要的原因： 首先，我们在现实任务中经常会遇到维数灾难问题，这是由于属性过多而造成的，若能从中选择出重要的特征，使得后续学习过程仅需在一部分特征上构建模型，则维数灾难问题会大为减轻。从这个意义上说，特征选择与第10章介绍的降维有相似的动机；事实上，它们是处理高维数据的两大主流技术。第二个原因是，去除不相关特征往往会降低学习任务的难度，这就像侦探破案一样，若将纷繁复杂的因素抽丝剥茧，只留下关键因素，则真相往往更易看清。</p>
<p>需注意的是，特征选择过程必须确保不丢失重要特征，否则后续学习过程会因为重要信息的缺失而无法获得好的性能。给定数据集，若学习任务不同，则相关特征很可能不同，因此，特征选择中所谓的“无关特征”是指与当前学习任务无关。有一类特征称为“冗余特征” (redundant feature)，它们所包含的信息能从其他特征中推演出来。例如：考虑立方体对象，若已有特征“底面长”“底面宽”，则“底面积”是冗余特征，因为它能从“底面长”与“底面宽”得到冗余特征在很多时候不起作用，去除它们会减轻学习过程的负担但有时冗余特征会降低学习任务的难度，例如若学习目标是估算立方体的体积，则“底面积”这个冗余特征的存在将使得体积的估算更容易；更确切地说，若某个冗余特征恰好对应了完成学习任务所需的“中间概念”，则该冗余特征是有益的为简化讨论，本章暂且假定数据中不涉及冗余特征，并且假定初始的特征集合包含了所有的重要信息。</p>
<p>欲从初始的特征集合中选取一个包含了所有重要信息的特征子集，若没有任何领域知识作为先验假设，那就只好遍历所有可能的子集了；然而这在计算上却是不可行的，因为这样做会遭遇组合爆炸，特征个数稍多就无法进行可行的做法是产生一个“候选子集”，评价出它的好坏，基于评价结果产生下一个候选子集，再对其进行评价，……这个过程持续进行下去，直至无法找到更好的候选子集为止显然，这里涉及两个关键环节：如何根据评价结果获取下一个候选特征子集，如何评价候选特征子集的好坏？</p>
<p>第一个环节是“子集搜索”(subset search)问题。给定特征集合）），我们可将每个特征看作一个候选子集，对这d个候选单特征子集进行评价，假定{a2}最优，于是将{a2}作为第一轮的选定集；然后，在上一轮的选定集中加入一个特征，构成包含两个特征的候选子集，假定在这d-1个候选两特征子集中{a2，a4}最优，且优于{a2}，于是将{a2，a4}作为本轮的选定集；……假定在第k+l轮时，最优的候选(k+l)特征子集不如上一轮的选定集，则停止生成候选子集，并将上一轮选定的k特征集合作为特征选择结果这样逐渐增加相关特征的策略称为“前向”(forward)搜索。类似的，若我们从完整的特征集合开始，每次尝试去掉一个无关特征，这样逐渐减少特征的策略称为“后向”(backward搜索。还可将前向与后向搜索结合起来，每一轮逐渐增加选定相关特征(这些特征在后续轮中将确定不会被去除)、同时减少无关特征，这样的策略称为“双句”(bidirectional)搜索。</p>
<p>显然，上述策略都是贪心的，因为它们仅考虑了使本轮选定集最优，例如在第三轮假定选择a5 优于a5，于是选定集为{a2，a4，a5}，然而在第四轮却可能是{a2，a4，a6，a8}比所有的{a2，a4，a5，ai}都更优。遗憾的是，若不进行穷举搜索，则这样的问题无法避免。</p>
<p>第二个环节是“子集评价”(subset evaluation)问题。给定数据集D，假定D中第i类样本所占的比例为））.为便于讨论，假定样本属性均为离散型。对属性子集A，假定根据其取值将D分成了V个子集）），每个子集中的样本在A上取值相同，于是我们可计算属性子集A 的信息增益</p>
<p>其中信息熵定义为</p>
<p>信息增益Gain(A)越大，意味着特征子集A包含的有助于分类的信息越多。于是，对每个候选特征子集，我们可基于训练数据集D 来计算其信息增益，以此作为评价准则。</p>
<p>更一般的，特征子集A 实际上确定了对数据集D 的一个划分，每个划分区域对应着A 上的一个取值，而样本标记信息Y 则对应着对D 的真实划分，通过估算这两个划分的差异，就能对A 进行评价与Y对应的划分的差异越小，则说明A越好。信息熵仅是判断这个差异的一种途径，其他能判断两个划分差异的机制都能用于特征子集评价。</p>
<p>将特征子集搜索机制与子集评价机制相结合即可得到特征选择方法。例如将前向搜索与信息熵相结合，这显然与决策树算法非常相似。事实上，决策树可用于特征选择，树结点的划分属性所组成的集合就是选择出的特征子集。其他的特征选择方法未必像决策树特征选择这么明显，但它们在本质上都是显式或隐式地结合了某种(或多种)子集搜索机制和子集评价机制。</p>
<p>常见的特征选择方法大致可分为三类： 过滤式(filter)、包裹式(wrapper)和嵌入式(embedding)。</p>
<h2 id="-51"><a href="#-51" class="headerlink" title></a><br></h2><h2 id="过滤式选择"><a href="#过滤式选择" class="headerlink" title="过滤式选择"></a>过滤式选择</h2><p>过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。这相当于先用特征选择过程对初始特征进行“过滤”，再用过滤后的特征来训练模型。</p>
<p>Relief(Relevant Features) ［Kira and Rendell, 1992］ 是一种著名的过滤式特征选择方法，该方法设计了一个“相关统计量”来度量特征的重要性。该统计量是一个向量，其每个分量分别对应于一个初始特征，而特征子集的重要性则是由子集中每个特征所对应的相关统计量分量之和来决定于是，最终只需指定一个阈值𝞽，然后选择比𝞽 大的相关统计量分量所对应的特征即可；也可指定欲选取的特征个数k 然后选择相关统计量分量最大的k个特征。</p>
<p>显然，Relief的关键是如何确定相关统计量。给定训练集）），对每个示例x，,Relief先在xi的同类样本中寻找其最近邻Xi,nh，称为“猜中近邻”(near-hit)，再从xi的异类样本中寻找其最近邻Xi,nh，称为“猜错近邻”(near-miss)，然后，相关统计量对应于属性j 的分量为</p>
<p>其中x表示样本x在属性j 上的取值，））取决于属性j 的类型：若属性j 为离散型，则）），否则为1；若属性j 为连续型，则）），注意））规范化到[0,1]区间。</p>
<p>从式(11.3)可看出，若Xi 与其猜中近邻Xi nh 在属性，上的距离小于Xi 与其猜错近邻Xi,nm 的距离，则说明属性j 对区分同类与异类样本是有益的，于是增大属性，所对应的统计量分量；反之，若Xi 与其猜中近邻Xi,nh在属性j上的距离大于Xi与其猜错近邻））的距离，则说明属性，起负面作用，于是减小属性j所对应的统计量分量。最后，对基于不同样本得到的估计结果进行平均，就得到各属性的相关统计量分量，分量值越大，则对应属性的分类能力就越强。</p>
<p>式(11.3)中的i 指出了用于平均的样本下标。实际上Relief只需在数据集的采样上而不必在整个数据集上估计相关统计量［Kira and Rendell, 1992］.显然，Relief的时间开销随采样次数以及原始特征数线性增长，因此是一个运行效率很高的过滤式特征选择算法。</p>
<p>Relief 是为二分类问题设计的，其扩展变体Relief-F ［Kononenko, 1994］能处理多分类问题假定数据集D 中的样本来自|y|个类别对示例酌，若它属于第k 类）），则Relief-F 先在第k 类的样本中寻找Xi 的最近邻示例Xi,nh并将其作为猜中近邻，然后在第k类之外的每个类中找到一个xi的最近邻示例作为猜错近邻，记为））.于是，相关统计量对应于属性j 的分量为。</p>
<p>其中P𝒍 为第𝒍类样本在数据集D 中所占的比例。</p>
<h2 id="-52"><a href="#-52" class="headerlink" title></a><br></h2><h2 id="包裹式选择"><a href="#包裹式选择" class="headerlink" title="包裹式选择"></a>包裹式选择</h2><p>与过滤式特征选择不考虑后续学习器不同，包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价准则换言之，包裹式特征选择的目的就是为给定学习器选择最有利于其性能、“ 量身定做”的特征子集。</p>
<p>一般而言，由于包裹式特征选择方法直接针对给定学习器进行优化，因此从最终学习器性能来看，包裹式特征选择比过滤式特征选择更好，但另一方面，由于在特征选择过程中需多次训练学习器，因此包裹式特征选择的计算开销通常比过滤式特征选择大得多。</p>
<p>LVW(Les Vegas Wrapper) ［Liu and Setiono, 1996］ 是一个典型的包裹式特征选择方法。它在拉斯维加斯方法(Las Vegas method)框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价准则算法描述如图11.1所示。</p>
<p>图11.1 算法第8 行是通过在数据集D 上使用交叉验证法来估计学习器ξ  的误差，注意这个误差是在仅考虑特征子集A＇时得到的，即特征子集A＇上的误差，若它比当前特征子集A上的误差更小，或误差相当但A＇中包含的特征数更少，则将A＇保留下来。</p>
<p>需注意的是，由于LVW 算法中特征子集搜索采用了随机策略，而每次特征子集评价都需训练学习器，计算开销很大，因此算法设置了停止条件控制参数T 然而，整个LVW 算法是基于拉斯维加斯方法框架，若初始特征数很多(即|A| 很大)、T 设置较大，则算法可能运行很长时间都达不到停止条件。换言之，若有运行时间限制，则有可能给不出解。</p>
<h2 id="-53"><a href="#-53" class="headerlink" title></a><br></h2><h2 id="嵌入式选择与L1正则化"><a href="#嵌入式选择与L1正则化" class="headerlink" title="嵌入式选择与L1正则化"></a>嵌入式选择与L1正则化</h2><p>在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明显的分别； 与此不同，嵌入式特征选择是将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动地进行了特征选择。</p>
<p>给定数据集D=）），其中））.我们考虑最简单的线性回归模型，以平方误差为损失函数，则优化目标为</p>
<p>当样本特征很多，而样本数相对较少时，式(11.5)很容易陷入过拟合。为了缓解过拟合问题，可对式(11.5)引入正则化项若使用L2 范数正则化，则有</p>
<p>其中正则化参数λ＞0.式(11.6)称为“岭回归”(ridge regression) ［Tikhonov and Arsenin, 1977］，通过引入L2 范数正则化，确能显著降低过拟合的风险。</p>
<p>那么3 能否将正则化项中的L2 范数替换为Lp 范数呢？答案是肯定的若令p=1，即采用L1 范数，则有</p>
<p>其中正则化参数λ＞0.式(11.7)称为LASSO (Least Absolute Shrinkage and Selection Operator) ［Tibshirani, 1996］)。</p>
<p>L1范数和L2范数正则化都有助于降低过拟合风险，但前者还会带来一个额外的好处它比后者更易于获得“稀疏”(sparse)解，即它求得的w 会有更少的非零分量。</p>
<p>为了理解这一点，我们来看一个直观的例子：假定x 仅有两个属性，于是无论式(11.6)还是(11.7)解出的W 都只有两个分量，即w1,w2，我们将其作为两个坐标轴，然后在图中绘制出式(11.6)与(11.7)的第一项的“等值线”，即在(w1, w2)空间中平方误差项取值相同的点的连线，再分别绘制出L1 范数与L2范数的等值线，即在(w1, w2)空间中L1 范数取值相同的点的连线，以及L2 范数取值相同的点的连线，如图11.2 所示式(11.6)与(11.7)的解要在平方误差项与正则化项之间折中，即出现在图中平方误差项等值线与正则化项等值线相交处。由图11.2 可看出，采用L1 范数时平方误差项等值线与正则化项等值线的交点常出现在坐标轴上，即W1 或W2 为0，而在采用L2 范数时，两者的交点常出现在某个象限中，即W1 或W2 均非0 ； 换言之，采用L1 范数比L2 范数更易于得到稀疏解。</p>
<p>注意到w 取得稀疏解意味着初始的d个特征中仅有对应着w 的非零分量的特征才会出现在最终模型中，于是，求解L1 范数正则化的结果是得到了仅采用一部分初始特征的模型；换言之，基于L1 正则化的学习方法就是一种嵌入式特征选择方法，其特征选择过程与学习器训练过程融为一体，同时完成。</p>
<p>L1正则化问题的求解可使用近端梯度下降(Proximal Gradient Descent,简称PGD) ［Combettes and Wajs, 2005］.具体来说，令∇表示微分算子，对优化目标</p>
<p>若f(x)可导，且∇f 满足 L-Lipschitz 条件，即存在常数L＞0 使得</p>
<p>则在Xk 附近可将f(x)通过二阶泰勒展式近似为</p>
<p>其中const 是与x 无关的常数，））表示内积。显然，式(11.10)的最小值在如下））获得：</p>
<p>于是，若通过梯度下降法对f(x)进行最小化，则每一步梯度下降迭代实际上等价于最小化二次函数））.将这个思想推广到式(11.8)，则能类似地得到其每一步迭代应为。</p>
<p>即在每一步对J(x)进行梯度下降迭代的同时考虑L1 范数最小化。</p>
<p>对于式(11.12)，可先计算）），然后求解</p>
<p>令xi表示x的第i个分量，将式(11.13)按分量展开可看出，其中不存在））这样的页，即x的各分量互不影响，于是式(11.13)有闭式解。</p>
<p>其中））与））分别是））与））的第i个分量因此，通过PGD 能使LASSO和其他基于L1范数最小化的方法得以快速求解。</p>
<h2 id="-54"><a href="#-54" class="headerlink" title></a><br></h2><h2 id="稀疏表示与字典学习"><a href="#稀疏表示与字典学习" class="headerlink" title="稀疏表示与字典学习"></a>稀疏表示与字典学习</h2><p>不妨把数据集D 考虑成一个矩阵，其每行对应于一个样本，每列对应于一个特征。特征选择所考虑的问题是特征具有“稀疏性”，即矩阵中的许多列与当前学习任务无关，通过特征选择去除这些列，则学习器训练过程仅需在较小的矩阵上进行，学习任务的难度可能有所降低，涉及的计算和存储开销会减少，学得模型的可解释性也会提高。</p>
<p>现在我们来考虑另一种稀疏性：D所对应的矩阵中存在很多零元素，但这些零元素并不是以整列、整行形式存在的在不少现实应用中我们会遇到这样的情形，例如在文档分类任务中，通常将每个文档看作一个样本，每个字(词)作为一个特征，字(词)在文档中出现的频率或次数作为特征的取值，换言之，D所对应的矩阵的每行是一个文档，每列是一个字(词)，行、列交汇处就是某字(词在某文档中出现的频率或次数。那么，这个矩阵有多少列呢？以汉语为例，《康熙字典》中有47035个汉字，这意味着该矩阵可有4万多列，即便仅考虑《现代汉语常用字表》中的汉字，该矩阵也有3500列然而，给定一个文档，相当多的字是不出现在这个文档中的，于是矩阵的每一行都有大量的零元素；对不同的文档，零元素出现的列往往恨不相同。</p>
<p>当样本具有这样的稀疏表达形式时，对学习任务来说会有不少好处，例如线性支持向量机之所以能在文本数据上有很好的性能，恰是由于文本数据在使用上述的字频表示后具有高度的稀疏性，使大多数问题变得线性可分。同时，稀疏样本并不会造成存储上的巨大负担，因为稀疏矩阵已有很多高效的存储方法。</p>
<p>那么，若给定数据集D 是稠密的，即普通非稀疏数据，能否将其转化为“稀疏表示”(sparse representation)形式，从而享有稀疏性所带来的好处呢？需注意的是，我们所希望的稀疏表示是“恰当稀疏”，而不是“过度稀疏”。仍以汉语文档为例，基于《现代汉语常用字表》得到的可能是恰当稀疏，即其稀疏性足以让学习任务变得简单可行，而基于《康熙字典》则可能是过度稀疏，与前者相比，也许并未给学习任务带来更多的好处。</p>
<p>显然，在一般的学习任务中(例如图像分类并没有《现代汉语常用字表》可用，我们需学习出这样一个“字典”。为普通稠密表达的样本找到合适的字典，将样本转化为合适的稀疏表示形式，从而使学习任务得以简化，模型复杂度得以降低，通常称为“字典学习”(dictionary learning)，亦称“稀疏编码”(sparse coding).这两个称谓稍有差别，“字典学习”更侧重于学得字典的过程，而“稀疏编码”则更侧重于对样本进行稀疏表达的过程。由于两者通常是在同一个优化求解过程中完成的，因此下面我们不做进一步区分，笼统地称为字典学习。</p>
<p>给定数据集）），字典学习最简单的形式为</p>
<p>其中））为字典矩阵，k 称为字典的词汇量，通常由用户指定））则是样本））的稀疏表示显然，式(11.15)的第一项是希望由ai 能很好地重构x，第二项则是希望ai尽量稀疏。</p>
<p>与LASSO 相比，式(11.15)显然麻烦得多，因为除了类似于式(11.7)中w 的句，还需学习字典矩阵B 不过，受LASSO 的启发，我们可采用变量交替优化的策略来求解式(11.15)。</p>
<p>首先在第一步，我们固定住字典B，若将式(11.15)按分量展开，可看出其中不涉及a））这样的交叉项，于是可参照LASSO 的解法求解下式，从而为每个样本Xi 找到相应的ai：<br>））</p>
<p>在第二步，我们以ai为初值来更新字典B，此时可将式(11.15)写为<br>））</p>
<p>其中））F 是矩阵的Frobenius 范数式(11.17)有多种求解方法，常用的有基于逐列更新策略的KSVD ［Aharon et al., 2006］.令bi 表示字典矩阵B 的第i 列，ai表示稀疏矩阵A 的第i 行，式(11.17)可重写为<br>））</p>
<p>在更新字典的第i列时，其他各列都是固定的，因此））是固定的，于是最小化式(11.18)原则上只需对Ei 进行奇异值分解以取得最大奇异值所对应的正交向量然而，直接对Ei 进行奇异值分解会同时修改队和ai,从而可能破坏A 的稀疏性。为避免发生这种情况，KSVD 对Ei 和ai 进行专门处理：ai仅保留非零元素, Ei 则仅保留bi 与ai 的非零元素的乘积项，然后再进行奇异值分解，这样就保持了第一步所得到的稀疏性。</p>
<p>初始化字典矩阵B之后反复迭代上述两步最终即可求得字典B和样本x的稀疏表示ai，在上述字典学习过程中，用户能通过设置词汇量k 的大小来控制字典的规模，从而影响到稀疏程度。</p>
<h2 id="-55"><a href="#-55" class="headerlink" title></a><br></h2><h2 id="压缩感知"><a href="#压缩感知" class="headerlink" title="压缩感知"></a>压缩感知</h2><p>在现实任务中，我们常希望根据部分信息来恢复全部信息。例如在数据通讯中要将模拟信号转换为数字信号，根据奈奎斯特(Nyquist)采样定理，令采样频率达到模拟信号最高频率的两倍，则采样后的数字信号就保留了模拟信号的全部信息：换言之，由此获得的数字信号能精确重构原模拟信号。然而，为了便于传输、存储，在实践中人们通常对采样的数字信号进行压缩，这有可能损失一些信息，而在信号传输过程中，由于信道出现丢包等问题，又可能损失部分信息那么，接收方基于收到的信号，能否精确地重构出原信号呢？压缩感知(compressed sensing)为解决此类问题提供了新的思路。</p>
<p>假定有长度为m 的离散信号x，不妨假定我们以远小于奈奎斯特采样定理要求的采样率进行采样，得到长度为n 的采样后信号y）），即<br>））</p>
<p>其中））是对信号x 的测量矩阵，它确定了以什么频率进行采样以及如何将采样样本组成采样后的信号。</p>
<p>在已知离散信号x和测量矩阵𝝫时要得到测量值y很容易，然而，若将测量值和测量矩阵传输出去，接收方能还原出原始信号x 吗？</p>
<p>一般来说，答案是“No”，这是由于n « m，因此y，x，𝝫组成的式(11.19)是一个欠定方程，无法轻易求出数值解。</p>
<p>现在不妨假设存在某个线性变换））使得x 可表示为s，于是ν可表示为<br>））</p>
<p>其中）） 于是，若能根据y 恢复出s，则可通过））来恢复出信号x。</p>
<p>粗看起来式(11.20)没有解决任何问题：因为式(11.20)中恢复信号s这个逆问题仍是欠定的。然而有趣的是，若s 具有稀疏性，则这个问题竟能很好地得以解决！这是因为稀疏性使得未知因素的影响大为减少。此时式(11.20)中的审称为稀疏基，而A 的作用则类似于字典，能将信号转换为稀疏表示。</p>
<p>事实上，在很多应用中均可获得具有稀疏性的s，例如图像或声音的数字信号通常在时域上不具有稀疏性但经过傅里叶变换、余弦变换、小波变换等处理后却会转化为频域上的稀疏信号。</p>
<p>显然，与特征选择、稀疏表示不同，压缩感知关注的是如何利用信号本身所具有的稀疏性，从部分观测样本中恢复原信号。通常认为，压缩感知分为“感知测量”和“重构恢复”这两个阶段。“感知测量”关注如何对原始信号进行处理以获得稀疏样本表示，这方面的内容涉及傅里叶变换、小波变换以及11.5节介绍的字典学习、稀疏编码等，不少技术在压缩感知提出之前就已在信号处理等领域有很多研究；“重构恢复”关注的是如何基于稀疏性从少量观测中恢复原信号，这是压缩感知的精髓，当我们谈到压缩感知时，通常是指该部分。</p>
<p>压缩感知的相关理论比较复杂，下面仅简要介绍一下“限定等距性”(Restricted I sometry Proper，简称RIP)。</p>
<p>对大小为））的矩阵A，若存在常数也））使得对于任意向量s 和A 的所有子矩阵））有</p>
<p>则称A 满足k 限定等距性(k-RIP).此时可通过下面的优化问题近乎完美地从y 中恢复出稀疏信号s，进而恢复出x：</p>
<p>然而，式(11.22)涉及L0 范数最小化，这是个NP 难题。值得庆幸的是，L1范数最小化在一定条件下与L0 范数最小化问题共解，于是实际上只需关注</p>
<p>这样，压缩感知问题就可通过L1范数最小化问题求解，例如式(11.23)可转化为LASSO 的等价形式再通过近端梯度下降法求解，即使用“基寻踪去噪”(Basis Pursuit De-Noising)基于部分信息来恢复全部信息的技术在许多现实任务中有重要应用。例如网上书店通过收集读者在网上对书的评价，可根据读者的读书偏好来进行新书推荐，从而达到定向广告投放的效果，显然，没有哪位读者读过所有的书，也没有哪本书被所有读者读过，因此，网上书店所搜集到的仅有部分信息例如表11.1 给出了四位读者的网上评价信息，这里评价信息经过处理，形成了“喜好程度”评分(5分最高)。由于读者仅对读过的书给出评价，因此表中出现了很多未知项“?”</p>
<p>那么，能否将表11.1 中通过读者评价得到的数据当作部分信号，基于压缩感知的思想恢复出完整信号呢？</p>
<p>我们知道，能通过压缩感知技术恢复欠采样信号的前提条件之一是信号有稀疏表示。读书喜好数据是否存在稀疏表示呢？答案是肯定的一般情形下，读者对书籍的评价取决于题材、作者、装帧等多种因素，为简化讨论，假定表11.l 中的读者喜好评分仅与题材有关。《笑傲江湖》和《云海玉弓缘》是武侠小说，《万历十五年》和《人类的战事》是历史读物，《人间词话》属于诗词文学。一般来说，相似题材的书籍会有相似的读者，若能将书籍按题材归类7则题材总数必然远远少于书籍总数，因此从题材的角度来看，表11.1 中反映出的信号应该是稀疏的于是，应能通过类似压缩感知的思想加以处理。</p>
<p>矩阵补全(matrix completion)技术可用于解决这个问题，其形式为<br>））</p>
<p>其中，x 表示需恢复的稀疏信号，rank(X)表示矩阵X 的秩，A 是如表11.1的读者评分矩阵这样的已观测信号：w是A 中非“ ？”元素(A)ij的下标(i,j)的集合。式(11.24)的约束项明确指出，恢复出的矩阵中(x)ij 应当与已观测到的对应元素相同。</p>
<p>与式(11.22)相似，式(11.24)也是一个NP 难题，注意到rank(X)在集合）） 上的凸包是X 的“核范数”(nuclear norm) :<br>））</p>
<p>其中σj(X)表示X的奇异值，即矩阵的核范数为矩阵的奇异值之和，于是可通过最小化矩阵核范数来近似求解式(11.24)，即<br>））</p>
<p>式(11.26)是一个凸优化问题，可通过半正定规划(Semi-Definite Programming,简称SDP)求解理论研究表明，在满足一定条件时，若A 的秩为）），则只需观察到））个元素就能完美恢复出A ［Recht, 2011］。</p>
<h2 id="阅读材料-10"><a href="#阅读材料-10" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>特征选择是机器学习中研究最早的分支领域之－，早期研究主要是按特征子集“生成与搜索－评价”过程进行在子集生成与搜索方面引入了很多人工智能搜索技术，如分支限界法、浮动搜索法等，在子集评价方面则采用了很多源于信息论的准则，如信息熵、AIC (Akaike Information Criterion) 等对子集评价准则进行了讨论，则进行了很多实验比较。</p>
<p>早期特征选择方法主要是过滤式的，包裹式方））法出现稍晚）），嵌入式方法事实上更晚）），但由于决策树算法在构建树的同时也可看作迸行了特征选择，因此嵌入式方法也可追溯到ID3））.有很多文献对特征选择方法的性能进行了实验比较）），更多关于特征选择的内容可参阅）），以及专门关于特征选择的书籍。</p>
<p>LARS (Least Angle RegresSion)是一种嵌入式特征选择方法，它基于线性回归平方误差最小化，每次选择一个与残差相关性最大的特征LASSO 可通过对LARS 稍加修改而实现。在LASSO 基础上进一步发展出考虑特征分组结构的Group LASSO ［Yuan andLin, 2006］、考虑特征序结构的Fused LASSO等变体。由于凸性不严格，LASSO 类方法可能产生多个解，该问题通过弹性网(Elastic Net)得以解决。</p>
<p>对字典学习与稀疏编码，除了通过控制字典规模从而影响稀疏性，有时还希望控制字典的“结构”，例如假设字典具有“分组结构”，即同一个分组内的变量或同为非零，或同为零。这样的性质称为“分组稀疏性”(group sparsity)，相应的稀疏编码方法则称为分组稀疏编码(groupsparse coding)，稀疏编码和分组稀疏编码在图像特征抽取方面有很多应用，可参阅。</p>
<p>压缩感知直接催生了人脸识别的鲁棒主成分分析和基于矩阵补全的协同过滤是关于压缩感知的一个简短介绍。将L1范数最小化转化为Li 范数最小化后，常用求解方法除了转化为LASSO 的基寻踪去噪，还可使用基寻踪(Basis Pursuit)、匹配寻踪(Matching Pursuit) 等使用投影法快速求解稀疏学习问题，并提供了一个稀疏学习程序包SLEP。</p>
<h3 id="休息一会儿-9"><a href="#休息一会儿-9" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：蒙特卡罗方法与斯坦尼斯拉夫·乌拉姆</p>
<p>斯坦尼斯拉夫·乌拉姆(Stanislaw Ulam, 1909-1984)是著名的波兰犹太裔数学家，在遍历论、数论、集合论等方面都有重要贡献，“乌拉姆数列”就是以他的名字命名的。</p>
<p>乌拉姆出生于奥匈帝国利沃夫，1933年在波兰利沃夫理工学院获得数学博士学位，然后于1935年应冯·诺伊曼的邀请到普林斯顿高等研究院访问，1940年他在威斯康星大学麦迪逊分校获得教职，翌年加入美国籍.1943年起他参与“曼哈顿计划”并做出重大贡献；当前世界上绝大部分核武器所使用的设计方案“泰勒－乌拉姆方案”就是以他和“氢弹之父”爱德华·泰勒的名字命名的。</p>
<p>世界上最早的通用电子计算机之一————ENIAC在发明后即被用于曼哈顿计划，乌拉姆敏锐地意识到在计算机的帮助下，可通过重复数百次模拟过程的方式来对概率变量进行统计估计。冯·诺伊曼立即认识到这个想法的重要性并给予支持.1947年乌拉姆提出这种统计方法并用于计算核裂变的连锁反应。由于乌拉姆常说他的叔叔又在蒙特卡罗赌场输钱了，因此他的同事Nicolas Metropolis 戏称该方法为“蒙特卡罗”，不料却流传开去。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第12章-计算学习理论"><a href="#第12章-计算学习理论" class="headerlink" title="第12章 计算学习理论"></a>第12章 计算学习理论</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p>顾名思义，计算学习理论(computational learning theory)研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。</p>
<p>给定样例集D=）），本章主要讨论二分类问题，若无特别说明，））.假设X 中的所有样本服从一个隐含未知的分布D，D中所有样本都是独立地从这个分布上采样而得，即独立同分布(independent and identically distributed，简称i.i.d) 样本。</p>
<p>令h 为从X 到y 的一个映射，其泛化误差为<br>））</p>
<p>h 在D 上的经验误差为<br>））</p>
<p>由于D 是D 的独立同分布采样，因此h 的经验误差的期望等于其泛化误差在上下文明确时，我们将）） 和）） 分别简记为）） 和）），令））为））的上限，即））；我们通常用E 表示预先设定的学得模型所应满足的误差要求，亦称“误差参数”。</p>
<p>本章后面部分将研究经验误差与泛化误差之间的逼近程度。若h 在数据集D 上的经验误差为0，则称h 与D 一致，否则称其与D 不一致。对任意两个映射）），可通过其“不合”(disagreement)来度量它们之间的差别：<br>））</p>
<p>我们会用到几个常用不等式：</p>
<p>• Jensen 不等式：对任意凸函数f(x)，有</p>
<p>• Hoeffding 不等式［Hoeffding, 1963］：若））为m个独立随机变量，且满足）），则对任意）），有</p>
<p>• McDiarmid 不等式：若）） 为m个独立随机变量，且对任意）），函数f满足</p>
<p>则对任意€＞0，有</p>
<h2 id="-56"><a href="#-56" class="headerlink" title></a><br></h2><h2 id="PAC学习"><a href="#PAC学习" class="headerlink" title="PAC学习"></a>PAC学习</h2><p>计算学习理论中最基本的是概率近似正确(Probably Approximately Correct，简称PAC学习理论［Valiant, 1984］.“概率近似正确”这个名字看起来有点古怪，我们稍后再解释。</p>
<p>令c 表示“概念”(concept)，这是从样本空间x到标记空间y 的映射，它决定示例x 的真实标记y，若对任何样例(x,y)有c(x)=y 成立，则称c 为目标概念; 所有我们希望学得的目标概念所构成的集合称为“概念类”(concept class)，用符号C 表示。</p>
<p>给定学习算法ξ，它所考虑的所有可能概念的集合称为“假设空间”(hypothesis space)，用符号H 表示。由于学习算法事先并不知道概念类的真实存在，因此H和C通常是不同的，学习算法会把自认为可能的目标概念集中起来构成H，对H，由于并不能确定它是否真是目标概念，因此称为“假设”(hypothesis).显然， 假设h 也是从样本空间X 到标记空间y 的映射。</p>
<p>若目标概念）），则H中存在假设能将所有示例按与真实标记一致的方式完全分开，我们称该问题对学习算法ξ是“可分的”(separable)，亦称“一致的”(consistent)；，若）），则H中不存在任何假设能将所有示例完全正确分开，称该问题对学习算法ξ 是“不可分的”(non-separable)，亦称“不一致的” (non-consistent ) 。</p>
<p>给定训练集D，我们希望基于学习算法ξ 学得的模型所对应的假设h 尽可能接近目标概念c.读者可能会问：为什么不是希望精确地学到目标概念c 呢？这是由于机器学习过程受到很多因素的制约，例如我们获得的训练集D 往往仅包含有限数量的样例，因此，通常会存在一些在D 上“等效”的假设，学习算法对它们无法区别，再如，从分布D采样得到D 的过程有一定偶然性，可以想象，即使对同样大小的不同训练集，学得结果也可能有所不同。因此，我们是希望以比较大的把握学得比较好的模型，也就是说，以较大的概率学得误差满足预设上限的模型；这就是“概率”“近似正确”的含义。形式化地说，令𝞭 表示置信度，可定义：</p>
<p>定义12.1 PAC 辨识(PAC Identify)：对）），所有））和分布D，若存在学习算法ξ，其输出假设））满足<br>））</p>
<p>则称学习算法ξ能从假设空间H中PAC 辨识概念类C。</p>
<p>这样的学习算法ξ能以较大的概率(至少1-b)学得目标概念c 的近似(误差最多为e).在此基础上司定义。</p>
<p>定义12.2 PAC 可学习(PAC Learnable)：令m 表示从分布D 中独立同分布采样得到的样例数目，）），对所有分布D，若存在学习算法ξ 和多项式函数）），使得对于任何））能从假设空间究中PAC 辨识概念类c，则称概念类C 对假设空间H 而言是PAC可学习的，有时也简称概念类C 是PAC 可学习的。对计算机算法来说，必然要考虑时间复杂度，于是：</p>
<p>定义12.3 PAC 学习算法(PAC Learning Algorithm)： 若学习算法ξ 使概念类C 为PAC 可学习的，且ξ的运行时间也是多项式函数））,））则称概念类C 是高效PAC 可学习(efficiently PAC learnable)的，称ξ 为概念类C 的PAC 学习算法。</p>
<p>假定学习算法ξ 处理每个样本的时间为常数，则ξ 的时间复杂度等价于样本复杂度，于是，我们对算法时间复杂度的关心就转化为对样本复杂度的关心。</p>
<p>定义12.4 样本复杂度(Sample Complexity)：满足PAC 学习算法ξ所需的））中最小的m，称为学习算法ξ 的样本复杂度。</p>
<p>显然，PAC 学习给出了一个抽象地刻画机器学习能力的框架，基于这个框架能对很多重要问题进行理论探讨，例如研究某任务在什么样的条件下可学得较好的模型，某算法在什么样的条件下可进行有效的学习，需多少训练样例才能获得较好的模型？</p>
<p>PAC 学习中一个关键因素是假设空间H的复杂度。H 包含了学习算法ξ所有可能输出的假设，若在PAC 学习中假设空间与概念类完全相同，即H=C,这称为“恰PAC可学习”(properly PAC learnable)；直观地看，这意味着学习算法的能力与学习任务“恰好匹配”。然而，这种让所有候选假设都来自概念类的要求看似合理，但却并不实际，因为在现实应用中我们对概念类C 通常一无所知，更别说获得一个假设空间与概念类恰好相同的学习算法。显然，更重要的是研究假设空间与概念类不同的情形，即））.一般而言，H 越大，其包含任意目标概念的可能性越大，但从中找到某个具体目标概念的难度也越大，｜H｜有限时，我们称H 为“有限假设空间”，否则称为“无限假设空间”。</p>
<h2 id="-57"><a href="#-57" class="headerlink" title></a><br></h2><h2 id="有限假设空间"><a href="#有限假设空间" class="headerlink" title="有限假设空间"></a>有限假设空间</h2><h3 id="可分情形"><a href="#可分情形" class="headerlink" title="可分情形"></a>可分情形</h3><p>可分情形意味着目标概念c 属于假设空间衍，即））。给定包含m个样例的训练集D，如何找出满足误差参数的假设呢？</p>
<p>容易想到一种简单的学习策略：既然D 中样例标记都是由目标概念c 赋予的，并且c 存在于假设空间H中，那么，任何在训练集D上出现标记错误的假设肯定不是目标概念c.于是，我们只需保留与D 一致的假设，剔除与D不一致的假设即可，若训练集D足够大，则可不断借助D中的样例剔除不一致的假设，直到究中仅剩下一个假设为止，这个假设就是目标概念c.通常情形下，由于训练集规模有限，假设空间究中可能存在不止一个与D 一致的“等效”假设，对这些等效假设，无法根据D 来对它们的优劣做进一步区分。</p>
<p>到底需多少样例才能学得目标概念c 的有效近似呢？对PAC 学习来说，只要训练集D 的规模能使学习算法ξ以概率1-𝛅 找到目标假设的E 近似即可。</p>
<p>我们先估计泛化误差大于E 但在训练集上仍表现完美的假设出现的概率。假定h 的泛化误差大于E，对分布D 上随机采样而得的任何样例(x,y)，的，有<br>））</p>
<p>由于D 包含m个从D 独立同分布采样而得的样例，因此，h 与D 表现一致的概率为<br>））</p>
<p>我们事先并不知道学习算法ξ会输出句中的哪个假设，但仅需保证泛化误差大于）），且在训练集上表现完美的所有假设出现概率之和不大于𝛅 即可<br>））</p>
<p>由此可知，有限假设空间H 都是PAC 可学习的，所需的样例数目如式(12.14)所示，输出假设h的泛化误差随样例数目的增多而收敛到0，收敛速率为））。</p>
<h3 id="不可分情形"><a href="#不可分情形" class="headerlink" title="不可分情形"></a>不可分情形</h3><p>对较为困难的学习问题，目标概念c往往不存在于假设空间H中。假定对于任何）），也就是说，H中的任意一个假设都会在训练集上出现或多或少的错误。由Hoeffding 不等式易知：</p>
<p>引理12.1 若训练集D 包含m个从分布D 上独立同分布采样而得的样例，Q ＜ E ＜ 1，则对任意）），有<br>））</p>
<p>推论12.1 若训练集D 包含m个从分布D 上独立同分布采样而得的样例，）），则对任意）），式(12.18)以至少1-𝛅 的概率成立：<br>））</p>
<p>推论12.1表明，样例数目m 较大时，h 的经验误差是其泛化误差很好的近似。对于有限假设空间坷，我们有</p>
<p>定理12.1 若对为有限假设空间，）），则对任意）），有<br>））</p>
<p>证明 令））表示假设空间句中的假设，有</p>
<p>显然，当））时，学习算法ξ无法学得目标概念c 的E 近似。但是，当假设空间H 给定时，其中必存在一个泛化误差最小的假设，找出此假设的E近{以也不失为一个较好的目标H 中泛化误差最小的假设是））于是，以此为目标可将PAC 学习推广到））的情况，这称为“不可知学习”(agnostic learning.相应的，我们有</p>
<p>定义12.5 不可知PAC 可学习(agnostic PAC learnable)： 令m 表示从分布D 中独立同分布采样得到的样例数目，））对所有分布D，若存在学习算法ξ 和多项式函数）），使得对于任何）），能从假设空间妇中输出满足式(12.20)的假设h:<br>））</p>
<p>则称假设空间H 是不可知PAC 可学习的。</p>
<p>与PAC 可学习类似，若学习算法ξ 的运行时间也是多项式函数）），则称假设空间对是高效不可知PAC 可学习的，学习算法ξ 则称为假设空间H的不可知PAC 学习算法，满足上述要求的最小m 称为学习算法ξ 的样本复杂度。</p>
<h2 id="-58"><a href="#-58" class="headerlink" title></a><br></h2><h2 id="VC维"><a href="#VC维" class="headerlink" title="VC维"></a>VC维</h2><p>现实学习任务所面临的通常是无限假设空间，例如实数域中的所有区间、Rd 空间中的所有线性超平面。欲对此种情形的可学习性进行研究，需度量假设空间的复杂度。最常见的办法是考虑假设空间的“vc维”(Vapnik-Chervonenkis dimension)。</p>
<p>介绍VC维之前，我们先引入几个概念：增长函数(growth function)、对分(dichotomy)和打散(shattering)。</p>
<p>给定假设空间H 和示例集）），H 中每个假设h 都能对D 中示例赋予标记，标记结果可表示为</p>
<p>随着m 的增大，H中所有假设对D 中的示例所能赋予标记的可能结果数也会增大</p>
<p>定义12.6 对所有m∈N，假设空间H的增长函数ΠH(m)为</p>
<p>增长函数ΠH(m)表示假设空间究对m个示例所能赋予标记的最大可能结果数。显然，H对示例所能赋予标记的可能结果数越大，H 的表示能力越强，对学习任务的适应能力也越强。因此，增长函数描述了假设空间句的表示能力，由此反映出假设空间的复杂度我们可利用增长函数来估计经验误差与泛化误差之间的关系：</p>
<p>定理12.2 对假设空间于））和任意m∈N有</p>
<p>假设空间H 中不同的假设对于D 中示例赋予标记的结果可能相同，也可能不同；尽管H 可能包含无穷多个假设，但其对D 中示例赋予标记的可能结果数是有限的对m个示例，最多有2m个可能结果。对二分类问题来说，H 中的假设对D 中示例赋予标记的每种可能结果称为对D 的一种“对分”。若假设空间H能实现示例集D 上的所有对分，即）），则称示例集D 能被假设空间H “打散”。</p>
<p>现在我们可以正式定义VC维了：</p>
<p>定义12.7 假设空间匀的VC维是能被冗打散的最大示例集的大小，即</p>
<p>））表明存在大小为d 的示例集能被假设空间冗打散注意：这并不意味着所有大小为d+1 的示例集都能被假设空间对打散细心的读者可能已发现， VC维的定义与数据分布D 无关！ 因此，在数据分布未知时仍能计算出假设空间H 的VC维。</p>
<p>通常这样来计算饨的VC维：若存在大小为d 的示例集能被H打散，但不存在任何大小为d+l 的示例集能被H打散，则妇的VC维是d.下面给出两个计算VC维的例子：</p>
<p>例12.1 实数域中的区间[a,b]： 令句表示实数域中所有闭区间构成的集合））对）），若）），则））,否则））.令）），则假设空间H对中存在假设））将））打散，所以假设空间对的VC维至少为2。对任意大小为，的示例集）），不妨设）），则对中不存在任何假设h[a,b] 能实现对分结果））.于是，H的VC维为2。</p>
<p>例12.2 二维实平面上的线性划分：令H表示二维实平面上所有线性划分构成的集合，））.由图12.l 可知，存在大小为3的示例集可被H打散，但不存在大小为4 的示例集可被H 打散。于是，二维实平面上所有线性划分构成的假设空间H的VC维为3。</p>
<p>图12.1 二维实平面上所有线性划分构成的假设空间的VC维为3</p>
<p>由定义12.7 可知，VC维与增长函数有密切联系，引理12.2 给出了二者之间的定量关系））:</p>
<p>引理12.2 若假设空间H的VC维为d，则对任意m∈N 有</p>
<p>证明 由数学归纳法证明。当））或））定理成立。假设定理对））和）） 成立。令</p>
<p>任何假设））对Xm 的分类结果或为+1，或为-1，因此任何出现在HD’中的串都会在于HD 中出现一次或两次。令于HD’|D 表示在于HD 中出现两次的，有HD’中串组成的集合：即<br>））</p>
<p>考虑到HD’|D 中的串在于HD 中出现了两次，但在HD’中仅出现了一次，有<br>））</p>
<p>D’的大小为）），由假设可得<br>））</p>
<p>令Q 表示能被）） 打散的集合，由））定义可知））必能被打散。由于H 的VC维为d，因此对））的VC维最大为d-l，于是有<br>））</p>
<p>由集合D 的任意性，引理12.2 得证。</p>
<p>从引理12.2 可计算出增长函数的上界：</p>
<p>推论12.2 若假设空间H的VC维为d，则对任意整数）） 有</p>
<p>根据推论12.2 和定理12.2 可得基于VC维的泛化误差界：</p>
<p>定理12.3 若假设空间H的VC维为d，则对任意）） 和））有<br>））<br>证明令）），解得<br>））<br>代入定理12.2，于是定理12.3 得证。。</p>
<p>由定理12.3 可知，式(12.29)的泛化误差界只与样例数目m 有关，收敛速率为））与数据分布D 和样例集D 无关因此，基于VC维的泛化误差界是分布无关(distribution-free)、数据独立(data-independent)的。</p>
<p>令h 表示学习算法ξ 输出的假设，若h 满足</p>
<p>则称ξ为满足经验风险最小化(Empirical Risk Minimization)，简称ERM原则的算法。我们有下面的定理。</p>
<p>定理12.4 任何VC维有限的假设空间H都是(不可知) PAC 可学习的。</p>
<p>证明 假设ξ为满足经验风险最小化原则的算法，h 为学习算法ξ输出的假设。令g 表示对中具有最小泛化误差的假设，即</p>
<p>以至少））的概率成立。由式(12.32)和(12.34)可以解出，再由H 的任意性可知定理12.4 得证。</p>
<h2 id="-59"><a href="#-59" class="headerlink" title></a><br></h2><h2 id="Rademacher复杂度"><a href="#Rademacher复杂度" class="headerlink" title="Rademacher复杂度"></a>Rademacher复杂度</h2><p>12.4 节提到，基于VC维的泛化误差界是分布无关、数据独立的，也就是说，对任何数据分布都成立。这使得基于VC维的可学习性分析结果具有一定的“普适性”；但从另－方面来说，由于没有考虑数据自身，基于VC维得到的泛化误差界通常比较“松”，对那些与学习问题的典型情况相差甚远的较“坏”分布来说尤其如此。</p>
<p>Rademacher 复杂度(Rademacher complexity)是另一种刻画假设空间复杂度的途径，与VC维不同的是，它在一定程度上考虑了数据分布。</p>
<p>给定训练集）），假设h 的经验误差为<br>））</p>
<p>其中））体现了预测值））与样例真实标记））之间的一致性，若对于所有））都有）），则））取最大值1，也就是说，经验误差最小的假设是<br>））</p>
<p>然而，现实任务中样例的标记有时会受到噪声影响，即对某些样例））,其Yi 或许已受到随机因素的影响，不再是xi的真实标记。在此情形下，选择假设空间H中在训练集上表现最好的假设有时还不如选择H 中事先已考虑了随机噪声影响的假设。</p>
<p>考虑随机变量）），它以0.5 的概率取值1, 0.5 的概率取值+1，称为Rademacher 随机变量。基于𝛔i，可将式(12.37)重写为</p>
<p>考虑H中的所有假设，对式(12.38)取期望可得</p>
<p>其中））。式(12.39)的取值范围是[0,1]，它体现了假设空间H 的表达能力，例如，当））时，H中仅有一个假设，这时可计算出式(12.39)的值为0；当））且））能打散D 时，对任意σ 总有一个假设使得）），这时可计算出式））的值为l。</p>
<p>考虑实值函数空间）），其中）），将式(12.39)中的X 和H 替换为Z 和F 可得</p>
<p>定义12.8 函数空间F 关于Z 的经验Rademacher 复杂度</p>
<p>经验Rademacher 复杂度衡量了函数空间F 与随机噪声在集合Z 中的相关性通常我们希望了解函数空间F 在Z 上关于分布D 的相关性，因此，对所有从D 独立同分布采样而得的大小为m 的集合Z 求期望可得</p>
<p>定义12.9 函数空间F 关于Z 上分布D 的Rademacher 复杂度<br>））</p>
<p>基于Rademacher 复杂度可得关于函数空间F 的泛化误差界；</p>
<p>定理12.5 对实值函数空间）），根据分布D 从Z 中独立同分布采样得到示例集）），对任意）），以至少））的概率有</p>
<p>同时，令Z’为只与Z 有一个示例不同的训练集，不妨设））和））为<br>不同示例，可得</p>
<p>根据McDiarmid 不等式(12.7)可知，对任意））,</p>
<p>以至少1-𝛅 的概率成立下面来估计））的上界：</p>
<p>至此，式(12.42)得证。由定义12.9 可知，改变Z 中的一个示例对））的值所<br>造成的改变最多为）），由McDiarmid 不等式(12.7)可知，</p>
<p>以至少））的概率成立。再由式(12.44)可知，</p>
<p>以至少））的概率成立。于是，</p>
<p>以至少））的概率成立。至此，式(12.43得证。</p>
<p>需注意的是，定理12.5 中的函数空间F 是区间[0,1]上的实值函数，因此定理12.5 只适用于回归问题。对二分类问题，我们有下面的定理：</p>
<p>定理12.6 对假设空间H：）），根据分布D 从X 中独立同分布采样得到示例集D=）），对任意）），以至少））的概率有</p>
<p>证明 对二分类问题的假设空间H，令）），则H中的假设h 变形为</p>
<p>于是就可将值域为））的假设空间H 转化为值域为[0,1]的函数空间））。由定义12.8，有</p>
<p>对式））求期望后可得</p>
<p>定理12.6 给出了基于Rademacher 复杂度的泛化误差界。与定理12.3 对比可知，基于VC维的泛化误差界是分布无关、数据独立的，而基于Rademacher复杂度的泛化误差界(12.47)与分布D 有关，式(12.48)与数据D 有关。换言之，基于Rademacher 复杂度的泛化误差界依赖于具体学习问题上的数据分布，有点类似于为该学习问题“量身定制”的，因此它通常比基于VC维的泛化误差界更紧一些。</p>
<p>值得一提的是，关于Rademacher 复杂度与增长函数，有如下定理</p>
<p>定理12.7 假设空间H 的Rademacher 复杂度Rm(H)与增长函数<br>ΠH(m)满足</p>
<p>由式(12.47), (12.52)和推论12.2 可得</p>
<p>也就是说，我们从Rademacher 复杂度和增长函数能推导出基于VC维的泛化误差界。</p>
<h2 id="-60"><a href="#-60" class="headerlink" title></a><br></h2><h2 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h2><p>无论是基于VC维还是Rademacher 复杂度来推导泛化误差界，所得到的结果均与具体学习算法无关，对所有学习算法都适用。这使得人们能够脱离具体学习算法的设计来考虑学习问题本身的性质，但在另一方面，若希望获得与算法有关的分析结果，则需另辟蹊径，稳定性(stability)分析是这方面一个值得关注的方向。</p>
<p>顾名思义，算法的“稳定性”考察的是算法在输入发生变化时，输出是否会随之发生较大的变化。学习算法的输入是训练集，因此下面我们先定义训练集的两种变化。</p>
<p>给定D=））是来自分布D 的独立同分布示例，对假设空间））和学习算法ξ，令））表示基于训练集D 从假设空间H中学得的假设。考虑D 的以下变化：</p>
<p>• D\i 表示移除D 中第i个样例得到的集合</p>
<p>• Di 表示替换D 中第i个样例得到的集合</p>
<p>其中））；服从分布D 并独立于D</p>
<p>损失函数））刻画了假设ξ d 的预测标记ξd(x)与真实标记y之间的差别，简记为））.下面定义关于假设ξd 的几种损失</p>
<p>• 泛化损失<br>• 经验损失<br>• 留一(leave-one-out)损失</p>
<p>下面定义算法的均匀稳定性(uniform stability):</p>
<p>定义12.10 对任何）），若学习算法ξ 满足</p>
<p>则称ξ 关于损失函数t 满足β- 均匀稳定性显然，若算法ξ 关于损失函数t 满足β- 均匀稳定性，则有</p>
<p>也就是说，移除示例的稳定性包含替换示例的稳定性。</p>
<p>若损失函数E 有界，即对所有D 和）），则有</p>
<p>定理12.8 给定从分布D上独立同分布采样得到的大小为m 的示例集D，若学习算法ξ 满足关于损失函数t 的β- 均匀稳定性，且损失函数e 的上界为）），则对任意）），以至少））的概率有</p>
<p>定理12.8 给出了基于稳定性分析推导出的学习算法ξ 学得假设的泛化误差界。从式(12.58可看出，经验损失与泛化损失之间差别的收敛率为））；若）），则可保证收敛率为）），与定理12.3 和定理12.6 比较可知，这与基于VC维和Rademacher 复杂度得到的收敛率一致</p>
<p>需注意，学习算法的稳定性分析所关注的是）），而假设空间复杂度分析所关注的是））；也就是说，稳定性分析不必考虑、假设空间中所有可能的假设，只需根据算法自身的特性(稳定性来讨论输出假设ξ，D 的泛化误差界。那么，稳定性与可学习性之间有什么关系呢？</p>
<p>首先，必须假设）），这样才能保证稳定的学习算法ξ 具有一定的泛化能力，即经验损失收敛于泛化损失，否则可学习性无从谈起。为便于计算，我们假定）），代入式(12.58)可得<br>））</p>
<p>对损失函数e，若学习算法ξ 所输出的假设满足经验损失最小化，则称算法ξ满足经验风险最小化(Empirical Risk Minimization)原则，简称算法是ERM的关于学习算法的稳定性和可学习性，有如下定理：</p>
<p>定理12.9 若学习算法ξ是ERM 且稳定的，则假设空间H可学习。</p>
<p>证明 令g 表示H中具有最小泛化损失的假设，即</p>
<p>由Hoeffding 不等式(12.6)可知，当））时，<br>））</p>
<p>以至少））的概率成立。令式</p>
<p>以至少））的概率成立。从而可得<br>））</p>
<p>以至少））的概率成立。定理12.9 得证。</p>
<p>对上面这个定理读者也许会纳闷为什么学习算法的稳定性能导出假设空间的可学习性，学习算法和假设空间是两码事呀。事实上，要注意到稳定性与假设空间并非无关，由稳定性的定义可知两者通过损失函数e 联系起来。</p>
<h2 id="阅读材料-11"><a href="#阅读材料-11" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>［Valiant, 1984］提出PAC 学习，由此产生了“计算学习理论”这个机器学习的分支领域.［Kearns and Vazirani, 1994］ 是一本很好的入门教材。该领域最重要的学术会议是国际计算学习理论会议(COLT)。</p>
<p>VC维由［Vapnik and Chervonenkis, 1971］ 提出，它的出现使研究无限假设空间的复杂度成为可能.Sauer 引理由于［Sauer, 1972］而命名，但［Vapnikand Chervonenkis，1971］和［Shelah，1972］也分别独立地推导出了该结果。本章主要讨论了二分类问题，对多分类问题，可将VC维扩展为Natarajan 维［Natarajan, 1989; Ben-David et al., 1995］。</p>
<p>Rademacher 复杂度最早被［Koltchinskii and Panchenko, 2000］引入机器学习，由［Bartlett and Mendelson, 2003］而受到重视.［Bartlett et al., 2002］提出了局部Rademacher 复杂度，对噪声数据可推导出更紧的泛化误差界。</p>
<p>机器学习算法稳定性分析方面的研究始于［Bousquet and Elisseeff, 2002］的工作，此后很多学者对稳定性与可学习性之间的关系进行了讨论，［Mukherjeeet al., 2006］和［Shalev-Shwartz et al., 2010］证明了ERM 稳定性与ERM 可学习性之间的等价关系；但并非所有学习算法都是ERM 的，因此［Shalev-Shwartzet al., 2010］进一步研究了AERM (Asymptotical Empirical Risk Minimization)稳定性与可学习性之间的关系。</p>
<p>本章介绍的内容都是关于确定性(deterministic)学习问题，即对于每个示例x 都有一个确定的标记y 与之对应；大多数监督学习都属于确定性学习问题但还有一种随机性(stochastic) 学习问题，其中示例的标记可认为是属性的后验概率函数，而不再是简单确定地属于某一类随机性学习问题的泛化误差界分析可参见［Devroye et al., 1996］。</p>
<h3 id="休息一会儿-10"><a href="#休息一会儿-10" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事： 计算学习理论之父莱斯利·维利昂特</p>
<p>计算机科学的绝大多数分支领域中都既有理论研究，也有应用研究，但当人们说到“理论计算机科学”时，通常是指一个特定的研究领域————TCS (Theoretical Computer Science)，它可看作计算机科学与数学的交叉，该领域中最著名的问题是“P?=NP”。</p>
<p>计算学习理论是机器学习的一个分支，它可认为是机器学习与理论计算机科学的交叉。提起计算学习理论，就必然要谈到英国计算机科学家莱斯利· 维利昂特））。维利昂特先后在剑桥大学国王学院、帝国理工学院学习，1974年在华威大学获计算机科学博士学位，此后曾在卡耐基梅隆大学、利兹大学和爱丁堡大学任教，1982年来到哈佛大学任计算机与应用数学讲席教授.1984年他在《ACM 通讯》发表了论文“ A theory of thelearnable ”。这篇论文首次提出了PAC 学习，从而开创了计算学习理论的研究。2010年ACM 投予维利昂特图灵奖，以表彰他对PAC 学习理论的开创性贡献，以及他对枚举和计算代数复杂性等其他一些理论计算机科学问题的重要贡献。颁奖词特别指出，维利昂特在1984年发表的论文创立了计算学习理论这个研究领域，使机器学习有了坚实的数学基础，扫清了学科发展的障碍。《ACM新闻》则以“ACM Turing Award Goes to Innovator in Machine Learning”为题对这位机器学习领域首位图灵奖得主的功绩大加褒扬。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第13章-半监督学习"><a href="#第13章-半监督学习" class="headerlink" title="第13章 半监督学习"></a>第13章 半监督学习</h1><h2 id="未标记样本"><a href="#未标记样本" class="headerlink" title="未标记样本"></a>未标记样本</h2><p>我们在丰收季节来到瓜田，满地都是西瓜，瓜农抱来三四个瓜说这都是好瓜，然后再指着地里的五六个瓜说这些还不好，还需再生长若干天基于这些信息，我们能否构建一个模型，用于判别地里的哪些瓜是已该采摘的好瓜，显然，可将瓜农告诉我们的好瓜、不好的瓜分别作为正例和反例来训练一个分类器。然而，只用这不到十个瓜做训练样本，有点太少了吧，能不能把地里的那些瓜也用上呢？</p>
<p>形式化地看，我们有训练样本集）），这l个样本的类别标记(即是否好瓜已知，称为“有标记”(labeled)样本；此外，还有）），这u个样本的类别标记未知(即不知是否好瓜，称为“未标记”(unlabeled)样本。若直接使用传统监督学习技术，则仅有D1能用于构建模型，Du所包含的信息被浪费了；另一方面，若D1较小，则由于训练样本不足，学得模型的泛化能力往往不佳。那么，能否在构建模型的过程中将Du 利用起来呢？</p>
<p>一个简单的做法，是将Du 中的示例全部标记后用于学习。这就相当于请瓜农把地里的瓜全都检查一遍，告诉我们哪些是好瓜，哪些不是好瓜，然后再用于模型训练。显然，这样做需耗费瓜农大量时间和精力有没有“便直” 一点的办法呢？</p>
<p>我们可以用D1 先训练一个模型，拿这个模型去地里挑一个瓜，询问瓜农好不好，然后把这个新获得的有标记样本加入D1 中重新训练一个模型，再去挑瓜，……这样，若每次都挑出对改善模型性能帮助大的瓜，则只需询问瓜农比较少的瓜就能构建出比较强的模型，从而大幅降低标记成本。这样的学习方式称为“主动学习”(active learning)，其目标是使用尽量少的“查询”(query)来获得尽量好的性能。</p>
<p>显然，主动学习引入了额外的专家知识，通过与外界的交互来将部分未标记样本转变为有标记样本。若不与专家交互，没有获得额外信息，还能利用未标记样本来提高泛化性能吗？</p>
<p>答案是“ Yes！”，有点匪夷所思？</p>
<p>事实上，未标记样本虽未直接包含标记信息，但若它们与有标记样本是从同样的数据源独立同分布采样而来，则它们所包含的关于数据分布的信息对建立模型将大有梅益图13.1 给出了一个直观的例示若仅基于图中的一个正例和一个反例，则由于待判别样本恰位于两者正中间，大体上只能随机猜测；若能观察到图中的未标记样本，则将很有把握地判别为正例。</p>
<p>图13.1 未标记样本效用的例示右边的灰色点表示未标记样本</p>
<p>让学习器不依赖外界交互、自动地利用未标记样本来提升学习性能，就是半监督学习(semi supervised learning).半监督学习的现实需求非常强烈，因为在现实应用中往往能容易地收集到大量未标记样本，而获取“标记”却需耗费人力、物力。例如，在进行计算机辅助医学影像分析时，可以从医院获得大量医学影像，但若希望医学专家把影像中的病灶全都标识出来则是不现实的。“有标记数据少，未标记数据多”这个现象在互联网应用中更明显，例如在进行网页推荐时需请用户标记出感兴趣的网页但很少有用户愿花很多时间来提供标记，因此，有标记网页样本少，但互联网上存在无数网页可作为未标记样本来使用。半监督学习恰是提供了一条利用“廉价”的未标记样本的途径。</p>
<p>要利用未标记样本，必然要做－些将未标记样本所揭示的数据分布信息与类别标记相联系的假设。最常见的是“聚类假设”(cluster assumption)，即假设数据存在簇结构，同一个簇的样本属于同一个类别。图13.1 就是基于聚类假设来利用未标记样本，由于待预测样本与正例样本通过未标记样本的“撮合”聚在一起，与相对分离的反例样本相比，待判别样本更可能属于正类。半监督学习中另一种常见的假设是“流形假设”(manifold assumption)，即假设数据分布在一个流形结构上，邻近的样本拥有相似的输出值。“邻近”程度常用“相似”程度来刻画，因此，流形假设可看作聚类假设的推广，但流形假设对输出值没有限制，因此比聚类假设的适用范围更广，可用于更多类型的学习任务。事实上，无论聚类假设还是流形假设，其本质都是“相似的样本拥有相似的输出”这个基本假设。</p>
<p>半监督学习可进一步划分为纯(pure)半监督学习和直推学习(transductive learning)，前者假定训练数据中的未标记样本并非待预测的数据，而后者则假定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的就是在这些未标记样本上获得最优泛化性能换言之，纯半监督学习是基于“开放世界”假设，希望学得模型能适用于训练过程中未观察到的数据；而直推学习是基于“封闭世界”假设，仅试图对学习过程中观察到的未标记数据进行预测图13.2 直观地显示出主动学习、纯半监督学习、直推学习的区别。需注意的是，纯半监督学习和直推学习常合称为半监督学习，本书也采取这一态度，在需专门区分时会特别说明。</p>
<h2 id="-61"><a href="#-61" class="headerlink" title></a><br></h2><h2 id="生成式方法"><a href="#生成式方法" class="headerlink" title="生成式方法"></a>生成式方法</h2><p>生成式方法(generative methods)是直接基于生成式模型的方法。此类方法假设所有数据(无论是否有标记)都是由同一个潜在的模型“生成”的这个假设使得我们能通过潜在模型的参数将未标记数据与学习目标联系起来，而未标记数据的标记则可看作模型的缺失参数，通常可基于EM算法进行极大似然估计求解此类方法的区别主要在于生成式模型的假设，不同的模型假设将产生不同的方法。</p>
<p>给定样本2，其真实类别标记为）），其中））为所有可能的类别。假设样本由高斯混合模型生成，且每个类别对应一个高斯混合成分。换言之，数据样本是基于如下概率密度生成·</p>
<p>其中，混合系数））是样本x 属于第i个高斯混合成分的概率；和））为该高斯混合成分的参数。</p>
<p>令））表示模型f 对x 的预测标记，））表示样本x隶属的高斯混合成分。由最大化后验概率可知</p>
<p>为样本x 由第i个高斯混合成分生成的后验概率，））为x 由第i个高斯混合成分生成且其类别为j 的概率。由于假设每个类别对应一个高斯混合成分，因此））仅与样本x 所属的高斯混合成分𝚹有关，可用））代替不失一般性，假定第i个类别对应于第i个高斯混合成分，即））当且仅当）），否则））。</p>
<p>不难发现，式(13.2)中估计））需知道样本的标记，因此仅能使用有标记数据；而））不涉及样本标记，因此有标记和未标记数据均可利用，通过引入大量的未标记数据，对这一项的估计可望由于数据量的增长而更为准确，于是式(13.2)整体的估计可能会更准确。由此可清楚地看出未标记数据何以能辅助提高分类模型的性能。</p>
<p>给定有标记样本集））和未标记样本集假设所有样本独立同分布，且都是由同一个高斯混合模型生成的。用极大似然法来估计高斯混合模型的参数））的对数似然是</p>
<p>式(13.4)由两项组成；基于有标记数据Dt 的有监督项和基于未标记数据Du 的无监督项。显然，高斯混合模型参数估计可用EM算法求解，迭代更新式如下：</p>
<p>• E 步：根据当前模型参数计算未标记样本Xj 属于各高斯混合成分的概率<br>））</p>
<p>• M 步：基于γji 更新模型参数，其中li 表示第i 类的有标记样本数目<br>））</p>
<p>以上过程不断迭代直至收敛，即可获得模型参数。然后由式(13.3)和(13.2)就能对样本进行分类。</p>
<p>将上述过程中的高斯混合模型换成混合专家模型［Miller and Uyar,1997］、朴素贝叶斯模型［Nigam et al., 2000］等即可推导出其他的生成式半监督学习方法此类方法简单，易于实现，在有标记数据极少的情形下往往比其他方法性能更好。然而，此类方法有一个关键。模型假设必须准确，即假设的生成式模型必须与真实数据分布吻合，否则利用未标记数据反倒会降低泛化性能［Cozman a nd Cohen, 2002］.遗憾的是，在现实任务中往往很难事先做出准确的模型假设，除非拥有充分可靠的领域知识。</p>
<h2 id="-62"><a href="#-62" class="headerlink" title></a><br></h2><h2 id="半监督SVM"><a href="#半监督SVM" class="headerlink" title="半监督SVM"></a>半监督SVM</h2><p>半监督支持向量机(Semi-Supervised Support Vector Machine，简称S3VM)是支持向量机在半监督学习上的推广。在不考虑未标记样本时，支持向量机试图找到最大间隔划分超平面，而在考虑未标记样本后，S3VM 试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面，如图13.3 所示，这里的基本假设是“低密度分隔”(low-density separation)，显然，这是聚类假设在考虑了线性超平面划分后的推广。</p>
<p>图13.3 半监督支持向量机与低密度分隔(“+” “-”分别表示有标记的正、反例，灰色点表示未标记样本)。</p>
<p>半监督支持向量机中最著名的是TSVM (Transductive Support Vector Machine).与标准SVM 一样，TSVM 也是针对二分类问题的学习方法.TSVM 试图考虑对未标记样本进行各种可能的标记指派(label assignment)，即尝试将每个未标记样本分别作为正例或反例，然后在所有这些结果中，寻求一个在所有样本(包括有标记样本和进行了标记指派的未标记样本)上间隔最大化的划分超平面。一旦划分超平面得以确定，未标记样本的最终标记指派就是其预测结果。</p>
<p>形式化地说，给定）） 和）），其中）） TSVM 的学习目标是为Du 中的样本给出预测标记）），使得</p>
<p>其中，））的确定了一个划分超平面；ξ为松弛向量，）） 对应于有标记样本，））对应于未标记样本，CL与CU也是由用户指定的用于平衡模型复杂度、有标记样本与未标记样本重要程度的折中参数。</p>
<p>显然，尝试未标记样本的各种标记指派是一个穷举过程，仅当未标记样本很少时才有可能直接求解。在一般情形下，必须考虑更高效的优化策略。</p>
<p>TSVM 采用局部搜索来迭代地寻找式(13.9)的近似解具体来说，它先利用有标记样本学得一个SVM，即忽略式(13.9)中涉及Cu 与y 的项及约束。然后，利用这个SVM 对未标记数据进行标记指R(label assignment)，即将SVM预测的结果作为“伪标记”(pseudo-label)赋予未标记样本。此时y 成为已知，将其代入式(13.9)即得到一个标准SVM 问题，于是可求解出新的划分超平面和松弛向量，注意到此时未标记样本的伪标记很可能不准确，因此Cu 要设置为比C1 小的值，使有标记样本所起作用更大。接下来，TSVM 找出两个标记指派为异类且很可能发生错误的未标记样本，交换它们的标记，再重新基于式(13.9求解出更新后的划分超平面和松弛向量，然后再找出两个标记指派为异类且很可能发生错误的未标记样本，……标记指派调整完成后，逐渐增大Cu 以提高未标记样本对优化目标的影响，进行下一轮标记指派调整，直至Cu=C1 为止。此时求解得到的SVM 不仅给未标记样本提供了标记，还能对训练过程中未见的示例进行预测.TSVM 的算法描述如图13.4 所示。</p>
<p>在对未标记样本进行标记指派及调整的过程中，有可能出现类别不平衡问题，即某类的样本远多于另一类，这将对SVM 的训练造成困扰。为了减轻类别不平衡性所造成的不利影响，可对图13.4 的算法稍加改进。将优化目标中的Cu项拆分为CU+ 与CU- 两项，分别对应基于伪标记而当作正、反例使用的未标记样本，并在初始化时令。</p>
<p>其中U+ 与U- 为基于伪标记而当作正、反例使用的未标记样本数。</p>
<p>在图13.4 算法的第6-10 行中，若存在一对未标记样本Xi 与xj，其标记指派yi与Yj 不同，且对应的松弛变量满足）），则意味着Yi与Yj 很可能是错误的，需对二者进行交换后重新求解式(13.9)，这样每轮迭代后均可使式(13.9)的目标函数值下降。</p>
<p>显然，搜寻标记指派可能出错的每一对未标记样本进行调整，是一个涉及巨大计算开销的大规模优化问题因此，半监督SVM 研究的一个重点是如何设计出高效的优化求解策略，由此发展出很多方法，如基于图核(graphkernel)函数梯度下降的LDS ［Chapelle and Zien, 2005］、基于标记均值估计的mean83VM ［Li et al., 2009］ 等。</p>
<h2 id="-63"><a href="#-63" class="headerlink" title></a><br></h2><h2 id="图半监督学习"><a href="#图半监督学习" class="headerlink" title="图半监督学习"></a>图半监督学习</h2><p>给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图中一个结点，若两个样本之间的相似度很高(或相关性很强，则对应的结点之间存在一条边，边的“强度”(strength)正比于样本之间的相似度(或相关性)。我们可将有标记样本所对应的结点想象为染过色，而来标记样本所对应的结点尚米染色。于是，半监督学习就对应于“颜色”在图上扩散或传播的过程。由于一个图对应了一个矩阵，这就使得我们能基于矩阵运算来进行半监督学习算法的推导与分析。</p>
<p>给定））和）），我们先基于））构建一个图G=(V,E)，其中结点集）），边集E 可表示为一个亲和矩阵(affinity matrix)，常基于高斯函数定义为</p>
<p>其中）），σ＞0 是用户指定的高斯函数带宽参数。</p>
<p>假定从图G=(V,E)将学得一个实值函数f:v→R，其对应的分类规则为：））.直观上看，相似的样本应具有相似的标记，于是可定义关于f 的“能量函数”(energy function):</p>
<p>其中））分别为函数f在有标记样本与未标记样本上的预测结果，））是一个对角矩阵，其对角元素））为矩阵w 的第z 行元素之和。</p>
<p>具有最小能量的函数f 在有标记样本上满足））在未标记样本上满足）），其中））为拉普拉斯矩阵(Laplacian matrix).以第l行与第l列为界，采用分块矩阵表示方式：</p>
<p>于是，将马上的标记信息作为）） 代入式(13.17)，即可利用求得的fu 对未标记样本进行预测。</p>
<p>上面描述的是一个针对二分类问题的标记传播(label propagation)方法，下面来看一个适用于多分类问题的标记传播方法［Zhou et al., 2004］。</p>
<p>假定）），仍基于））构建一个图G=(V,E)，其中结点集）），边集E 所对应的W 仍使用式(13.11)，对角矩阵）），此）） 的对角元素）），定义一个））的非负标记矩阵）），其第4 行元素））为示例Xi的标记向量，相应的分类规则为：）），将F 初始化为</p>
<p>显然，Y 的前l行就是l个有标记样本的标记向量。基于W 构造一个标记传播矩阵）），于是有迭代计算式））</p>
<p>其中a∈(0,1)为用户指定的参数，用于对标记传播项SF(t)与初始化项Y的重要性进行折中。基于式(13.19)迭代至收敛可得</p>
<p>由F＊可获得Du 中样本的标记））算法描述如图13.5 所示。</p>
<p>事实上，图13.5 的算法对应于正则化框架</p>
<p>其中μ＞0 为正则化参数。考虑到有标记样本通常很少而未标记样本很多，为缓解过拟合，可在式(13.21)中引入针对未标记样本的L2 范数项）），在μ=））时，式(13.21)的最优解恰为图13.5 算法的迭代收敛解F* 。</p>
<p>式(13.21)右边第二项是迫使学得结果在有标记样本上的预测与真实标记尽可能相同，而第一项则迫使相近样本具有相似的标记，显然，它与式(13.12)都是基于半监督学习的基本假设，不同的是式(13.21)考虑离散的类别标记，而式(13.12)则是考虑输出连续值。</p>
<p>图半监督学习方法在概念上相当清晰，且易于通过对所涉矩阵运算的分析来探索算法性质但此类算法的缺陷也相当明显。首先是在存储开销上，若样本数为O(m)，则算法中所涉及的矩阵规模为）），这使得此类算法很难直接处理大规模数据；另一方面，由于构图过程仅能考虑、训练样本集，难以判知新样本在图中的位置，因此，在接收到新样本时，或是将其加入原数据集对图进行重构并重新进行标记传播，或是需引入额外的预测机制，例如将矶和经标记传播后得到标记的Du合并作为训练集，另外训练一个学习器例如支持向量机来对新样本进行预测。</p>
<h2 id="-64"><a href="#-64" class="headerlink" title></a><br></h2><h2 id="基于分歧的方法"><a href="#基于分歧的方法" class="headerlink" title="基于分歧的方法"></a>基于分歧的方法</h2><p>与生成式方法、半监督SVM、图半监督学习等基于单学习器利用未标记数据不同，基于分歧的方法(disagreement - based methods)使用多学习器，而学习器之间的“分歧”(disagreement)对未标记数据的利用至关重要。</p>
<p>“协同训练”(co-training) 是此类方法的重要代表，它最初是针对“多视图”(multi-view)数据设计的，因此也被看作“多视图学习”(multi-view learning)的代表。在介绍协同训练之前，我们先看看什么是多视图数据。</p>
<p>在不少现实应用中，一个数据对象往往同时拥有多个“属性集”(attributeset)，每个属性集就构成了一个“视图”(view).例如对一部电影来说，它拥有多个属性集：图像画面信息所对应的属性集、声音信息所对应的属性集、字幕信息所对应的属性集、甚至网上的宣传讨论所对应的属性集等。每个属性集都可看作一个视图为简化讨论，暂且仅考虑图像画面属性集所构成的视图和声音属性集所构成的视图于是，一个电影片段可表示为样本）），其中xi 是样本在视图i 中的示例，即基于该视图属性描述而得的属性向量，不妨假定X1 为图像视图中的属性向量，x2 为声音视图中的属性向量；y是标记，假定是电影的类型，例如“动作片”、“爱情片”等））这样的数据就是多视图数据。</p>
<p>假设不同视图具有“相容性”(compatibility)，即其所包含的关于输出空间y 的信息是一致的：令y1 表示从图像画面信息判别的标记空间，y2 表示从声音信息判别的标记空间，则有y=y1=y2，例如两者都是{爱情片，动作片}，而不能是y1={爱情片，动作片}而y2={文艺片，惊悚片}。在此假设下，显式地考虑多视图有很多好处。仍以电影为例，某个片段上有两人对视，仅凭图像画面信息难以分辨其类型，但此时若从声音信息昕到“我爱你”，则可判断出该片段很可能属于“爱情片”另一方面，若仅凭图像画面信息认为“可能是动作片”，仅凭声音信息也认为“可能是动作片”，则当两者一起考虑时就有很大的把握判别为“动作片”显然，在“相容性”基础上，不同视图信息的“互补性”会给学习器的构建带来很多便利。</p>
<p>协同训练正是很好地利用了多视图的“相容互补性”。假设数据拥有两个充分(sufficient)且条件独立视图，“充分”是指每个视图都包含足以产生最优学习器的信息，“条件独立”则是指在给定类别标记条件下两个视图独立。在此情形下，可用一个简单的办法来利用未标记数据：首先在每个视图上基于有标记样本分别训练出一个分类器，然后让每个分类器分别去挑选自已“最有把握的”未标记样本赋予伪标记，并将伪标记样本提供给另一个分类器作为新增的有标记样本用于训练更新……这个“互相学习、共同进步”的过程不断迭代进行，直到两个分类器都不再发生变化，或达到预先设定的迭代轮数为止。算法描述如图13.6 所示。若在每轮学习中都考察分类器在所有未标记样本上的分类置信度，会有很大的计算开销，因此在算法中使用了未标记样本缓冲池.分类置信度的估计则因基学习算法ξ而异，例如若使用朴素贝叶斯分类器，则可将后验概率转化为分类置信度；若使用支持向量机，则可将间隔大小转化为分类置信度。</p>
<p>协同训练过程虽简单，但令人惊讶的是，理论证明显示出，若两个视图充分且条件独立，则可利用未标记样本通过协同训练将弱分类器的泛化性能提升到任意高.不过，视图的条件独立性在现实任务中通常很难满足，因此性能提升幅度不会那么大，但研究表明，即便在更弱的条件下，协同训练、仍可有效地提升弱分类器的性能。</p>
<p>协同训练算法本身是为多视图数据而设计的但此后出现了一些能在单视图数据上使用的变体算法，它们或是使用不同的学习算法，或使用不同的数据采样，甚至使用不同的参数设置来产生不同的学习器，也能有效地利用未标记数据来提升性能。后续理论研究发现，此类算法事实上无需数据拥有多视图，仅需弱学习器之间具有显著的分歧(或差异，即可通过相互提供伪标记样本的方式来提升泛化性能；不同视图、不同算法、不同数据采样、不同参数设置等，都仅是产生差异的渠道，而非必备条件。</p>
<p>基于分歧的方法只需采用合适的基学习器，就能较少受到模型假设、损失函数非凸性和数据规模问题的影H向，学习方法简单有效、理论基础相对坚实、适用范围较为广泛。为了使用此类方法需能生成具有显著分歧、性能尚可的多个学习器，但当有标记样本很少，尤其是数据不具有多视图时，要做到这一点并不容易，需有巧妙的设计。</p>
<h2 id="-65"><a href="#-65" class="headerlink" title></a><br></h2><h2 id="半监督聚类"><a href="#半监督聚类" class="headerlink" title="半监督聚类"></a>半监督聚类</h2><p>聚类是一种典型的无监督学习任务，然而在现实聚类任务中我们往往能获得一些额外的监督信息，于是可通过半监督聚类(semi-supervised clustering)来利用监督信息以获得更好的聚类效果。</p>
<p>聚类任务中获得的监督信息大致有两种类型。第一种类型是“必连”(must-link)与“勿连”(cannot-link)约束，前者是指样本必属于同一个簇，后者是指样本必不属于同一个簇；第二种类型的监督信息则是少量的有标记样本。</p>
<p>约束k 均值(Constrained k-means算法））是利用第一类监督信息的代表。给定样本集））以及“必连”关系集合M 和“勿连” 关系集合））表示Xi 与Xj 必属于同簇，））表示Xi 与Xj 必不属于同簇。该算法是k 均值算法的扩展，它在聚类过程中要确保M 与C 中的约束得以满足，否则将返回错误提示，算法如图13.7 所示。</p>
<p>以西瓜数据集4.0 为例，令样本X4 与X25, X12 与X20, X14 与X17 之间存在必连约束，x2 与X21, X13 与X23, X19 与X23 之间存在勿连约束，即</p>
<p>设聚类簇数k=3，随机选取样本X6, X12, X27 作为初始均值向量，图13.8显示出约束k 均值算法在不同迭代轮数后的聚类结果。经5 轮迭代后均值向量不再发生变化(与第4 轮迭代相同)，于是得到最终聚类结果。</p>
<p>第二种监督信息是少量有标记样本。给定样本集D={x1, x2,…, Xm} ,假定少量的有标记样本为）），其中））为隶属于第j个聚类簇的样本。这样的监督信息利用起来很容易： 直接将它们作为“种子它们初始化k 均值算法的k个聚类中心，并且在聚类簇迭代更新过程中不改变种子样本的簇隶属关系这样就得到了约束种子k 均值(Constrained Seedk-means)算法［Basu et al., 2002］，其算法描述如图13.9 所示。</p>
<p>仍以西瓜数据集4.0 为例，假定作为种子的有标记样本为。</p>
<p>以这三组种子样本的平均向量作为初始均值向量，图13.10 显示出约束种子k均值算法在不同迭代轮数后的聚类结果。经4 轮迭代后均值向量不再发生变化(与第3 轮迭代相同)，于是得到最终聚类结果。</p>
<p>图13.10 西瓜数据集4.0 上约束种子k 均值算法(k=3)在各轮迭代后的结采样本<br>点与均值向量分别用“·”与“十＂表示，种子样本点为红色，红色虚线显示出簇划分。</p>
<h2 id="阅读材料-12"><a href="#阅读材料-12" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>半监督学习的研究－般认为始于［Shahshahani and Landgrebe, 1994］，该领域在二十世纪末、二十一世纪初随着现实应用中利用禾标记数据的巨大需求涌现而蓬勃发展国际机器学习大会(ICML)从2008年开始评选“十年最佳论文”，在短短6 年中，半监督学习四大范型(paradigm)中基于分歧的方法、半监督SVM 、图半监督学习的代表性工作先后于2008年［Blum and Mitchell,1998］、2009年［Joachims, 1999］、2013年［Zhu et al., 2003］获奖。</p>
<p>生成式半监督学习方法出现最早［Shahshahani and Landgrebe, 1994］.由于需有充分可靠的领域知识才能确保模型假设不至于太坏，因此该范型后来主要是在具体的应用领域加以研究。</p>
<p>半监督SVM 的目标函数非凸，有不少工作致力于减轻非凸性造成的不利影响，例如使用连续统(continuation)方法，从优化一个简单的凸目标函数开始，逐步变形为非凸的S3VM 目标函数［Chapelle et al., 2006a］；使用确定性退火(deterministic annealing)过程，将非凸问题转化为一系列凸优化问题，然后由易到难地顺序求解［Sindhwani et al., 2006］；利用CCCP 方法优化非凸函数［Collobert et al., 2006］等。</p>
<p>最早的图半监督学习方法［Blum and Chawla, 2001］直接基于聚类假设，将学习目标看作找出图的最小割(mincut).对此类方法来说，图的质量极为重要， 13.4 节的高斯距离图以及k 近邻图、E 近邻图都较为常用，此外已有一些关于构图的研究［Wang and Zhang, 2006; Jebara et al., 2009］，基于图核(graphkernel)的方法也与此有密切联系［Chapelle et al., 2003］。</p>
<p>基于分歧的方法起源于协同训练，最初设计是仅选取一个学习器用于预测.三体训练(tri-training)使用三个学习器，通过“少数服从多数”来产生伪标记样本，并将学习器进行集成。后续研究进一步显示出将学习器集成起来更有助于性能提升，并出现了使用更多学习器的方法。更为重要的是，这将集成学习与半监督学习这两个长期独立发展的领域联系起来［Zhou, 2009］.此外，这些方法能容易地用于多视图数据，并可自然地与主动学习进行结合。</p>
<p>［Belkin et al., 2006］在半监督学习中提出了流形正则化(manifold regularization)框架，直接基于局部光滑性假设对定义在有标记样本上的损失函数进行正则化，使学得的预测函数具有局部光滑性。</p>
<p>半监督学习在利用未标记样本后并非必然提升泛化性能，在有些情形下甚至会导致性能下降。对生成式方法，其成因被认为是模型假设不准确［Gozmanand Cohen, 2002］，因此需依赖充分可靠的领域知识来设计模型。对半监督SVM，其成因被认为是训练数据中存在多个“低密度划分”而学习算法有可能做出不利的选择，S4VM ［Li and Zhou, 2015］通过优化最坏情形性能来综合利用多个低密度划分，提升了此类技术的安全性，更一般的“安全”(safe)半监督学习仍是一个未决问题。</p>
<p>本章主要介绍了半监督分类和聚类，但半监督学习已普遍用于各类机器学习任务，例如在半监督回归 、降维［Zhang et al., 2007］等方面都有相关研究更多关于半监督学习的内容可参见［Chapelle et al., 2006b;Zhu, 2006］, ［Zhou and Li, 2010 ；周志华，2013］专门介绍了基于分歧的方法。［Settles, 2009］是一个关于主动学习的介绍。</p>
<h3 id="休息一会儿-11"><a href="#休息一会儿-11" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：流形与伯恩哈德·黎曼</p>
<p>“流形”(manifold)这个名字源于德语Mannig-faltigkeit，是伟大的德国数学家伯恩哈德·黎曼(BernhardRiemann,1826-1866)提出的，其译名则是我国拓扑学奠基人江泽涵先生借鉴文天祥《正气歌》“天地有正气，杂然赋流形”而来，可能是由于光滑流形恰与“气”相似，整体上看可流动、变形。</p>
<p>黎曼出生于德国汉诺威的布列斯伦茨(Breselenz)，幼年时就展现出惊人的数学天赋1846年父亲送他到哥廷根大学攻读神学，在旁听了高斯关于最小二乘法的讲座后，他决定转攻数学，并在高斯指导下于1851 年获博士学位。期间有两年他在柏林大学学习，受到了雅可比、狄利克雷等大数学家的影响.1853年，高斯让黎曼在几何学基础方面准备一个报告，以便取得哥廷根大学的教职，1854年，黎曼做了“论作为几何基础的假设”的著名演讲，这个报告开创了黎曼几何，提出了黎曼积分，并首次使用了Mannigfaltigkeit 这个词。此后黎曼一直在哥廷根大学任教，并在1859年接替去世的狄利克雷担任数学教授。</p>
<p>黎曼是黎曼几何的创立者、复变函数论的奠基人，并对微积分、解析数论、组合拓扑、代数几何、数学物理方法均做出了开创性贡献，他的工作直接影响了近百年数学的发展，许多杰出的数学家前赴后继地努力论证黎曼断言过的定理.1900年希尔伯特列出的23个世纪数学问题与2000年美国克雷数学研究所列出的7个千禧年数学难题中，有一个问题是相同的，这就是黎曼1859年因当选院士而提交给柏林科学院的文章中提出的“黎曼猜想”。这是关于黎曼𝒞函数非平凡零点的猜想。目前已有不同数学分支的千余个数学命题以黎曼猜想为前提，若黎曼猜想正确，它们将全部升格为定理。一个猜想联系了如此多不同数学分支、如此多命题，在数学史上是极为罕见的，因此它被公认为当前最重要的数学难题。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第14章-概率图模型"><a href="#第14章-概率图模型" class="headerlink" title="第14章 概率图模型"></a>第14章 概率图模型</h1><h2 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h2><p>机器学习最重要的任务，是根据一些已观察到的证据(例如训练样本)来对感兴趣的未知变量(例如类别标记)进行估计和推测。概率模型(probabilistic model)提供了一种描述框架，将学习任务归结于计算变量的概率分布在概率模型中，利用已知变量推测未知变量的分布称为“推断”(inference)，其核心是如何基于可观测变量推测出未知变量的条件分布。具体来说，假定所关心的变量集合为Y，可观测变量集合为O，其他变量的集合为R，“生成式”(generative)模型考虑联合分布P(Y,R,O)，“判别式”(discriminative)模型考虑条件分布P(Y,R|O).给定一组观测变量值，推断就是要由P(Y,R,O)或P(Y,R|O)得到条件概率分布P(Y|O)。</p>
<p>直接利用概率求和规则消去变量R显然不可行，因为即便每个变量仅有两种取值的简单问题，其复杂度已至少是））.另一方面，属性变量之间往往存在复杂的联系，因此概率模型的学习，即基于训练样本来估计变量分布的参数往往相当困难。为了便于研究高效的推断和学习算法，需有一套能简洁紧凑地表达变量间关系的工具。</p>
<p>概率图模型(probab ilistic graphical model)是一类用图来表达变量相关关系的概率模型。它以图为表示工具，最常见的是用一个结点表示－个或一组随机变量，结点之间的边表示变量间的概率相关关系，即“变量关系图”。根据边的性质不同，概率图模型可大致分为两类：第一类是使用有向无环图表示变量间的依赖关系，称为有向图模型或贝叶斯网(Bayesian network)；第二类是使用无向图表示变量间的相关关系，称为无向图模型或马尔可夫网(Markovnetwork)。</p>
<p>隐马尔可夫模型(Hidden Markov Model)，简称HMM是结构最简单的动态<br>贝叶斯网(dynamic Bayesian network)，这是一种著名的有向图模型，主要用于<br>时序数据建模，在语音识别、自然语言处理等领域有广泛应用</p>
<p>如图14.l所示，隐马尔可夫模型中的变量可分为两组第一组是状态变量）），其中Yi∈y 表示第i 时刻的系统状态。通常假定状态变量是隐藏的、不可被观测的，因此状态变量亦称隐变量(hidden variable).第二组是观测变量{x1,x2，…，Xn}，其中Xi∈X 表示第i 时刻的观测值。在隐马尔可夫模型中，系统通常在多个状态{s1, s2，…，SN} 之间转换，因此状态变量切的取值范围Y (粉为状态空间通常是有N个可能取值的离散空间。观测变量Xi可以是离散型也可以是连续型，为便于讨论，我们仅考虑离散型观测变量，并假定其取值范围X 为{O1, O2,…, OM}。</p>
<p>图14.l中的箭头表示了变量间的依赖关系在任一时刻，观测变量的取值仅依赖于状态变量，即Xt 由Yt 确定，与其他状态变量及观测变量的取值无关。同时，t 时刻的状态Yt 仅依赖于t-1 时刻的状态Yt-1，与此前t-2个状态无关。这就是所谓的“马尔司夫链”(Markov chain)，即：系统下一时刻的状态仅由当前状态决定，不依赖于以往的任何状态。基于这种依赖关系，所有变量的联合概率分布为</p>
<p>除了结构信息，欲确定一个隐马尔可夫模型还需以下三组参数。</p>
<p>• 状态转移概率·模型在各个状态间转换的概率，通常记为矩阵）），其中））</p>
<p>表示在任意时刻t，若状态为句，则在下一时刻状态为Sj概率。</p>
<p>• 输出观测概率·模型根据当前状态获得各个观测值的概率，通常记为矩阵）），其中））</p>
<p>表示在任意时刻t，若状态为Si，则观测值Oj 被获取的概率</p>
<p>• 初始状态概率：模型在初始时刻各状态出现的概率，通常记为））</p>
<p>表示模型的初始状态为Si 的概率。</p>
<p>通过指定状态空间y、观测空间X 和上述三组参数，就能确定一个隐马尔可夫模型，通常用其参数））来指代。给定隐马尔可夫模型λ，它按如下过程产生观测序列）） :</p>
<p>(1)设置t=1，并根据初始状态概率𝛑选择初始状态的Y1，</p>
<p>(2)根据状态Yt 和输出观测概率B 选择观测变量取值Xt;</p>
<p>(3)根据状态仇丰IJ状态转移矩阵A 转移模型状态，即确定Yt+l ;</p>
<p>(4)若t ＜ n，设置t=t+l，并转到第(2)步，否则停止。</p>
<p>其中））和））分别为第t 时刻的状态和观测值。</p>
<p>在实际应用中，人们常关注隐马尔可夫模型的三个基本问题：</p>
<p>• 给定模型）），如何有效计算其产生观测序列x））的概率）），换言之，如何评估模型与观测序列之间的匹配程度？</p>
<p>• 给定模型λ 和观测序列）），如何找到与此观测序列最匹配的状态序列）），换言之，如何根据观测序列推断出隐藏的模型状态？</p>
<p>• 给定观测序列）），如何调整模型参数λ）），叫使得该序列出现的概率））最大，换言之，如何训练模型使其能最好地描述观测数据？</p>
<p>上述问题在现实应用中非常重要。例如许多任务需根据以往的观测序列））来推测当前时刻最有可能的观测值Xn，这显然可转化为求取概率）），即上述第一个问题； 在语音识别等任务中，观测值为语音信号，隐藏状态为文字，目标就是根据观测信号来推断最有可能的状态序列(即对应的文字)即上述第二个问题；在大多数现实应用中，人工指定模型参数已变得越来越不可行，如何根据训练样本学得最优的模型参数，恰是上述第三个问题。值得庆幸的是，基于式(14.1)的条件独立性，隐马尔可夫模型的这三个问题均能被高效求解。</p>
<h2 id="-66"><a href="#-66" class="headerlink" title></a><br></h2><h2 id="马尔可夫随机场"><a href="#马尔可夫随机场" class="headerlink" title="马尔可夫随机场"></a>马尔可夫随机场</h2><p>马尔可夫随机场(Markov Random Field)，简称MRF是典型的马尔可夫网，这是一种著名的无向图模型。图中每个结点表示一个或一组变量，结点之间的边表示两个变量之间的依赖关系。马尔可夫随机场有一组势函数(potentialfunctions)，亦称“因子”(factor)，这是定义在变量子集上的非负实函数，主要用于定义概率分布函数。</p>
<p>图14.2显示出一个简单的马尔可夫随机场。对于图中结点的一个子集，若其中任意两结点间都有边连接，则称该结点子集为一个“团”(clique).若在一个团中加入另外任何一个结点都不再形成团，则称该团为“极大团”(maximalclique)；换言之，极大团就是不能被其他团所包含的团例如，在图14.2 中，））都是团，并且除了））和））之外都是极大团； 但是，因为x2和X3 之间缺乏连接，））并不构成团。显然，每个结点至少出现在一个极大团中。</p>
<p>在马尔可夫随机场中，多个变量之间的联合概率分布能基于团分解为多个因子的乘积，每个因子仅与一个团相关具体来说，对于n个变量）），所有团构成的集合为C，与团Q∈C 对应的变量集合记为）），则联合概率））定义为<br>））</p>
<p>其中ψQ 为与团Q 对应的势函数，用于对团Q 中的变量关系进行建模，））为规范化因子，以确保P(x) 是被正确定义的概率。在实际应用中，精确计算Z 通常很困难，但许多任务往往并不需获得Z 的精确值。</p>
<p>显然，若变量个数较多，则团的数目将会很多(例如，所有相互连接的两个变量都会构成团)，这就意味着式(14.2)会有很多乘积项，显然会给计算带来负担。注意到若团Q 不是极大团，则它必被一个极大团Q<em> 所包含，即XQ ⊆ XQ</em>;这意味着变量XQ 之间的关系不仅体现在势函数ψQ 中，还体现在ψQ<em> 中。于是，联合概率P(x) 可基于极大团来定义。假定所有极大团构成的集合为C</em>，则<br>有<br>））</p>
<p>其中））为规范化因子。例如图14.2 中）），联合概率分布P(x 定义为<br>））</p>
<p>其中，势函数））定义在极大团））上，由于它的存在，使我们不再需为团））和））构建势函数。</p>
<p>在马尔可夫随机场中如何得到“条件独立性”呢？同样借助“分离”的概念，如图14.3 所示，若从结点集A 中的结点到B 中的结点都必须经过结点集C中的结点，则称结点集A 和B 被结点集C 分离，C 称为“分离集”(separatingset).对马尔可夫随机场，有</p>
<p>• “全局马尔可夫性”(global Markov property)： 给定两个变量子集的分离集，则这两个变量子集条件独立。</p>
<p>也就是说，图14.3 中若令A,B 和C 对应的变量集分别为XA,XB 和xc，则XA和XB 在给定xc 的条件下独立，记为））。</p>
<p>下面我们做一个简单的验证。为便于讨论，我们令图14.3 中的A,B 和C分别对应单变量XA,XB 和Xc，于是图14.3 简化为图14.4。</p>
<p>对于图14.4由式(14.2)可得联合概率</p>
<p>基于条件概率的定义可得</p>
<p>即XA和XB 在给定XC 时条件独立。</p>
<p>由全局马尔可夫性可得到两个很有用的推论：</p>
<p>• 局部马尔可夫性(local Markov property)： 给定某变量的邻接变量，则该变量条件独立于其他变量。形式化地说，令V 为图的结点集，n(v)为结点υ 在图上的邻接结点，）），有））。</p>
<p>• 成对马尔可夫性(pairwise Markov property)：给定所有其他变量，两个非邻接变量条件独立。形式化地说，令图的结点集和边集分别为V 和E，对图中的两个结点u 和u，若）），则））。</p>
<p>现在我们来考察马尔可夫随机场中的势函数。显然，势函数））的作用是定量刻画变量集XQ 中变量之间的相关关系，它应该是非负函数，且在所偏好的变量取值上有较大函数值。例如，假定图14.4 中的变量均为二值变量，若<br>势函数为。</p>
<p>））</p>
<p>则说明该模型偏好变量XA 与xc 拥有相同的取值，XB 与xc 拥有不同的取值；换言之，在该模型中XA 与xc 正相关，XB 与xc 负相关。结合式(14.2)易知，令XA 与xc 相同且XB 与XQ 不同的变量值指派将取得较高的联合概率。</p>
<p>为了满足非负性，指数函数常被用于定义势函数，即<br>））</p>
<p>））是一个定义在变量XQ 上的实值函数，常见形式为））</p>
<p>其中））和））是参数。上式中的第二项仅考虑单结点，第一项则考虑每一对结点的关系。</p>
<h2 id="-67"><a href="#-67" class="headerlink" title></a><br></h2><h2 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h2><p>条件随机场(Conditional Random Field，简称CRF)是一种判别式无向图模型，14.l 节提到过，生成式模型是直接对联合分布进行建模，而判别式模型则是对条件分布进行建模，前面介绍的隐马尔可夫模型和马尔可夫随机场都是生成式模型，而条件随机场则是判别式模型。</p>
<p>条件随机场试图对多个变量在给定观测值后的条件概率进行建模。具体来说，若令）） 为观测序列，）） 为与之相应的标记序列，则条件随机场的目标是构建条件概率模型））.需注意的是，标记变量y 可以是结构型变量，既其分量之间具有某种相关性。例如在自然语言处理的词性标注任务中，观测数据为语句(即单词序列)，标记为相应的词性序列，具有线性序列结构，如图14.5(a)所示；在语法分析任务中，输出标记则是语法树，具有树形结构，如图14.5(b)所示。</p>
<p>图14.5 自然语言处理中的词性标注和语法分析任务</p>
<p>令G=(V,E)表示结点与标记变量y 中元素一一对应的无向图，Yv 表示与结点u 对应的标记变量，n(v) 表示结点u 的邻接结点，若图G 的每个变量Yv都满足马尔可夫性，即<br>））</p>
<p>则(y,x)构成一个条件随机场。</p>
<p>理论上来说，图G 可具有任意结构，只要能表示标记变量之间的条件独立性关系即可。但在现实应用中，尤其是对标记序列建模时，最常用的仍是图14.6所示的链式结构，即“链式条件随机场”(chain-structured CRF).下面我们主要讨论这种条件随机场。</p>
<p>与马尔可夫随机场定义联合概率的方式类似条件随机场使用势函数和图结构上的团来定义条件概率））.给定观测序列x，图14.6 所示的链式条件随机场主要包含两种关于标记变量的团，即单个标记变量{yi} 以及相邻的标记变量））.选择合适的势函数，即可得到形如式(14.2)的条件概率定义。在条件随机场中，通过选用指数势函数并引入特征函数(feature function)，条件概率被定义为</p>
<p>其中））是定义在观测序列的两个相邻标记位置上的转移特征函数(transition feature function)，用于刻画相邻标记变量之间的相关关系以及观测序列对它们的影响，））是定义在观测序列的标记位置i 上的状态特征函数(status feature function)，用于刻画观测序列对标记变量的影响）） 和））为参数，Z 为规范化因子，用于确保式(14.11)是正确定义的概率。</p>
<p>显然，要使用条件随机场，还需定义合适的特征函数特征函数通常是实值函数，以刻画数据的一些很可能成立或期望成立的经验特性以图14.5(a)的词性标注任务为例，若采用转移特征函数<br>））</p>
<p>则表示第4个观测值Xi 为单词“knock”时，相应的标记Yi 和Yi+i 很可能分别为<br>））和））.若采用状态特征函数<br>））</p>
<p>则表示观测值均为单词“knock ”时，它所对应的标记很可能为V。</p>
<p>对比式(14.11)和(14.2)可看出，条件随机场和马尔可夫随机场均使用团上的势函数定义概率，两者在形式上没有显著区别；但条件随机场处理的是条件概率，而马尔可夫随机场处理的是联合概率。</p>
<h2 id="-68"><a href="#-68" class="headerlink" title></a><br></h2><h2 id="学习与推断"><a href="#学习与推断" class="headerlink" title="学习与推断"></a>学习与推断</h2><p>基于概率图模型定义的联合概率分布，我们能对目标变量的边际分布(marginal distribution)或以某些可观测变量为条件的条件分布进行推断。条件分布我们已经接触过很多，例如在隐马尔可夫模型中要估算观测序列x 在给定参数λ 下的条件概率分布边际分布则是指对无关变量求和或积分后得到结果，例如在马尔可夫网中，变量的联合分布被表示成极大团的势函数乘积，于是，给定参数θ求解某个变量x 的分布，就变成对联合分布中其他无关变量进行积分的过程，这称为“边际化”(marginalization)。</p>
<p>对概率图模型，还需确定具体分布的参数，这称为参数估计或参数学习问题，通常使用极大似然估计或最大后验概率估计求解但若将参数视为待推测的变量，则参数估计过程和推断十分相似，可以“吸收”到推断问题中。因此，下面我们只讨论概率图模型的推断方法。</p>
<p>具体来说，假设图模型所对应的变量集））能分为XE 和Xp 两个不相交的变量集，推断问题的目标就是计算边际概率P(xF)或条件概率）），由条件概率定义有<br>））</p>
<p>其中联合概率）） 可基于概率图模型获得，因此，推断问题的关键就是如何高效地计算边际分布，即<br>））</p>
<p>概率图模型的推断方法大致可分为两类。第一类是精确推断方法，希望能计算出目标变量的边际分布或条件分布的精确值；遗憾的是，一般情形下，此类算法的计算复杂度随着极大团规模的增长呈指数增长，适用范围有限。第二类是近似推断方法，希望在较低的时间复杂度下获得原问题的近似解；此类方法在现实任务中更常用本节介绍两种代表性的精确推断方法，下一节介绍近似推断方法</p>
<h3 id="变量消去"><a href="#变量消去" class="headerlink" title="变量消去"></a>变量消去</h3><p>精确推断的实质是一类动态规划算法它利用图模型所描述的条件独立性来削减计算目标概率值所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。</p>
<p>我们先以图14.7(a)中的有向图模型为例来介绍其工作流程</p>
<p>假定推断目标是计算边际概率））.显然，为了完成此目标，只需通过加法消去变量）），即</p>
<p>不难发现，若采用））的顺序计算加法，则有</p>
<p>其中））是求加过程的中间结果，下标i 表示此项是对Xi 求加的结果，下标j表示此项中剩下的其他变量显然，））是关于xj函数。不断执行此过程可得</p>
<p>显然，最后的））是关于x5的函数，仅与变量x5的取值有关。</p>
<p>事实上：上述方法对无向图模型同样适用不妨忽略图14.7(a)中的箭头，将其看作一个无向图模型，有</p>
<p>其中Z 为规范化因子。边际分布））可这样计算。</p>
<p>显然，通过利用乘法对加法的分配律，变量消去法把多个变量的积的求和问题，转化为对部分变量交替进行求积与求和的问题。这种转化使得每次的求和与求积运算限制在局部，仅与部分变量有关，从而简化了计算。变量消去法有一个明显的缺点：若需计算多个边际分布，重复使用变量消去法将会造成大量的冗余计算。例如在图14.7(a)的贝叶斯网上，假定在计算P(x5)之外还希望计算）），若采用））的顺序，））和））的计算是重复的</p>
<h3 id="信念传播"><a href="#信念传播" class="headerlink" title="信念传播"></a>信念传播</h3><p>信念传播(Belief Propagation)算法将变量消去法中的求和操作看作一个消息传递过程，较好地解决了求解多个边际分布时的重复计算问题。具体来说，变量消去法通过求和操作</p>
<p>消去变量x；，其中））表示结点功的邻接结点在信念传播算法中，这个操作被看作从Xi 向Xj 传递了一个消息））。这样，式(14.15)和(14.16)所描述的变量消去过程就能描述为图14.7(b)所示的消息传递过程。不难发现，每次消息传递操作仅与变量Xi 及其邻接结点直接相关，换言之，消息传递相关的计算被限制在图的局部进行</p>
<p>在信念传播算法中，一个结点仅在接收到来自其他所有结点的消息后才能向另一个结点发送消息，且结点的边际分布正比于它所接收的消息的乘积，即</p>
<p>例如在图14.7 (b)中，结点X3 要向X5 发送消息，必须事先收到来自结点X2 和X4 的消息，且传递到X5 的消息））恰为概率P(x5)。</p>
<p>若图结构中没有环，则信念传播算法经过两个步骤即可完成所有消息传递，进而能计算所有变量上的边际分布:</p>
<p>• 指定一个根结点，从所有叶结点开始向根结点传递消息，直到根结点收到所有邻接结点的消息；</p>
<p>• 从根结点开始向叶结点传递消息，直到所有叶结点均收到消息。</p>
<p>例如在图14.7 (a)中，令X1 为根结点，则X4 和X5 为叶结点。以上两步消息传递的过程如图14.8 所示此时图的每条边上都有方向不同的两条消息，基于这些消息和式(14.20)即可获得所有变量的边际概率。</p>
<h2 id="-69"><a href="#-69" class="headerlink" title></a><br></h2><h2 id="近似推断"><a href="#近似推断" class="headerlink" title="近似推断"></a>近似推断</h2><p>精确推断方法通常需要很大的计算开销，因此在现实应用中近似推断方法更为常用。近似推断方法大致可分为两大类： 第一类是采样(sampling)，通过使用随机化方法完成近似；第二类是使用确定性近似完成近似推断，典型代表为变分推断(variational inference)。</p>
<h3 id="MCMC采样"><a href="#MCMC采样" class="headerlink" title="MCMC采样"></a>MCMC采样</h3><p>在很多任务中，我们关心某些概率分布并非因为对这些概率分布本身感兴趣，而是要基于它们计算某些期望，并且还可能进一步基于这些期望做出决策。例如对图14.7(a)的贝叶斯网，进行推断的目的可能是为了计算变量x5的期望。若直接计算或逼近这个期望比推断概率分布更容易，则直接操作无疑将使推断问题的求解更为高效。</p>
<p>采样法正是基于这个思路具体来说，假定我们的目标是计算函数f(x)在概率密度函数p(x)下的期望</p>
<p>则可根据p(x)抽取一组样本）），然后计算f(x)在这些样本上的均值</p>
<p>以此来近似目标期望））.若样本））独立，基于大数定律，这种通过大量采样的办法就能获得较高的近似精度问题的关键是如何采样。对概率图模型来说，就是如何高效地基于图模型所描述的概率分布来获取样本。概率图模型中最常用的采样技术是马尔可夫链蒙特卡罗(Markov ChainMonte Carlo，简称MCMC)方法。给定连续变量z∈X 的概率密度函数p(x)，x在区间A 中的概率可计算为</p>
<p>若有函数）），则可计算））的期望</p>
<p>若z 不是单变量而是一个高维多元变量x，且服从一个非常复杂的分布，则对式(14.24)求积分通常很困难为此，MCMC 先构造出服从p 分布的独立同分布随机变量）），再得到式(14.24)的无偏估计</p>
<p>然而，若概率密度函数））很复杂，则构造服从p 分布的独立同分布样本也很困难.MCMC 方法的关键就在于通过构造“平稳分布为p的马尔可夫链”来产生样本。若马尔可夫链运行时间足够长(即收敛到平稳状态)，则此时产出的样本x 近似服从于分布p.如何判断马尔可夫链到达平稳状态呢？假定平稳马尔可夫链T 的状态转移概率(即从状态x 转移到状态x’的概率为T(x’|x)，t 时刻状态的分布为p(xt)，则若在某个时刻马尔可夫链满足平稳条件</p>
<p>则p(x) 是该马尔可夫链的平稳、分布，且马尔可夫链在满足该条件时已收敛到平稳状态。</p>
<p>也就是说，MCMC 方法先设法构造一条马尔可夫链，使其收敛至平稳分布恰为待估计参数的后验分布，然后通过这条马尔可夫链来产生符合后验分布的样本，并基于这些样本来进行估计。这里马尔可夫链转移概率的构造至关重要，不同的构造方法将产生不同的MCMC 算法。</p>
<p>Metropolis-Hastings (简称MH)算法是MCMC 的重要代表它基于“拒绝采样”(reject sampling)来逼近平稳分布p.如图14.9 所示，算法每次根据上一轮采样结果xt-1 来采样获得候选状态样本x＊，但这个候选样本会以一定的概率被“拒绝”掉假定从状态）） 到状态x＊ 的转移概率为）），其中））是用户给定的先验概率，））是x＊ 被接受的概率若x＊ 最终收敛到平稳状态，则根据式(14.26) 有</p>
<p>于是，为了达到平稳状态，只需将接受率设置为</p>
<p>吉布斯采样(Gibbs sampling)有时被视为MH 算法的特例，它也使用马尔可夫链获取样本，而该马尔可夫链的平稳分布也是采样的目标分布））.具体来说，假定）），目标分布为p(x)，在初始化x 的取值后，通过循环执行以下步骤来完成采样：</p>
<p>(1)随机或以某个次序选取某变量Xi;</p>
<p>(2)根据x 中除向外的变量的现有取值，计算条件概率p(xi|xi)，其中</p>
<p>(3)根据p(xi|xi)对变量xi采样，用采样值代替原值</p>
<h3 id="变分推断"><a href="#变分推断" class="headerlink" title="变分推断"></a>变分推断</h3><p>变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布。</p>
<p>在学习变分推断之前，我们先介绍概率图模型一种简洁的表示方法————盘式记法(plate notation)。图14.10 给出了一个简单的例子。图14.10(a)表示N个变量））均依赖于其他变量z.在图14.10(b)中，相互独立的、由相同机制生成的多个变量被放在一个方框(盘)内，并在方框中标出类似变量重复出现的个数N； 方框可以嵌套。通常用阴影标注出已知的、能观察到的变量，如图14.10 中的变量x.在很多学习任务中，对属性变量使用盘式记法将使得图表示非常简洁。</p>
<p>在图14.10(b)中，所有能观察到的变量z 的联合分布的概率密度函数是</p>
<p>所对应的对数似然函数为</p>
<p>其中））。是x 与z 服从的分布参数。</p>
<p>一般来说，图14.10 所对应的推断和学习任务主要是由观察到的变量x 来估计隐变量z 和分布参数变量θ，即求解））和θ。</p>
<p>概率模型的参数估计通常以最大化对数似然函数为手段。对式(14.30)可使用EM算法：在E 步，根据t 时刻的参数θt 对））进行推断，并计算联合似然函数））；，在M 步，基于E 步的结果进行最大化寻优，即对关于变量θ的函数θ；研进行最大化从而求取<br>））</p>
<p>式(14.31)中的））实际上是对数联合似然函数））在分布））下的期望，当分布））与变量z 的真实后验分布相等时，））近似于对数似然函数。于是，EM算法最终可获得稳定的参数。，而隐变量z 的分布也能通过该参数获得。</p>
<p>需注意的是，）） 未必是隐变量z 服从的真实分布，而只是一个近似分布若将这个近似分布用）） 表示，则不难验证</p>
<p>然而在现实任务中，E 步对））的推断很可能因z 模型复杂而难以进行，此时可借助变分推断通常假设z 服从分布</p>
<p>即假设复杂的多变量z 可拆解为一系列相互独立的多变量Z i· 更重要的是，可以令估分布相对简单或有很好的结构，例如假设的为指数族(exponential family)分布，此时有</p>
<p>我们关心的是旬，因此可固定的刮再对））进行最大化，可发现式(14.36)等于）），即当）） 最大。于是可知变量子集Zj 所服从的最优分布q；应满足</p>
<p>换言之，在式(14.35)这个假设下，变量子集Zj 最接近真实情形的分布由式(14.40)给出。</p>
<p>显然，基于式(14.35)的假设，通过恰当地分割独立变量子集Zj 并选择的服从的分布，））往往有闭式解，这使得基于式(14.40)能高效地对隐变量z 进行推断事实上，由式(14.38)可看出，对变量Zj 分布q；进行估计时融合了Zj 之外的其他））的信息，这是通过联合似然函数ln p(x,z)在Zj 之外的隐变量分布上求期望得到的，因此亦称“平均场”(mean field)方法</p>
<p>在实践中使用变分法时，最重要的是考虑如何对隐变量进行拆解，以及假设各变量子集服从何种分布，在此基础上套用式(14.40)的结论再结合EM算法即可进行概率图模型的推断和参数估计。显然，若隐变量的拆解或变量子集的分布假设不当，将会导致变分法效率低、效果差。</p>
<h2 id="-70"><a href="#-70" class="headerlink" title></a><br></h2><h2 id="话题模型"><a href="#话题模型" class="headerlink" title="话题模型"></a>话题模型</h2><p>话题模型(topic model)是一族生成式有向图模型，主要用于处理离散型的数据(如文本集合)，在信息检索、自然语言处理等领域有广泛应用。隐狄利克雷分配模型(Latent Dirichlet Allocation，简称LDA)是话题模型的典型代表。</p>
<p>我们先来了解一下话题模型中的几个概念： 词(word)、文档(document)和话题(topic).具体来说，“词”是待处理数据的基本离散单元，例如在文本处理任务中，一个词就是一个英文单词或有独立意义的中文词。“文档”是待处理的数据对象，它由一组词组成，这些词在文档中是不计顺序的，例如一篇论文、一个网页都可看作一个文档；这样的表示方式称为“词袋”(bag-of-words).数据对象只要能用词袋描述，就可使用话题模型。“话题”表示一个概念，具体表示为一系列相关的词，以及它们在该概念下出现的概率。</p>
<p>形象地说，如图14.11 所示，一个话题就像是一个箱子，里面装着在这个概念下出现概率较高的那些词。不妨假定数据集中一共包含K个话题和T 篇文档，文档中的词来自一个包含N个词的词典。我们用T个N 维向量））表示数据集(即文档集合，K个N 维向量β）） 表示话题，其中））的第n个分量问，n 表示文档t 中词η 的词频，β））的第n个分量））表示话题k 中词饨的词频。</p>
<p>在现实任务中可通过统计文档中出现的词来获得词频向量）），但通常并不知道这组文档谈论了哪些话题，也不知道每篇文档与哪些话题有关.LDA 从生成式模型的角度来看待文档和话题。具体来说，LDA 认为每篇文档包含多个话题，不妨用向量。）） 表示文档t 中所包含的每个话题的比例，））即表示文档t 中包含话题k 的比例，进而通过下面的步骤由话题“生成”文档t:</p>
<p>(1)根据参数为a 的狄利克雷分布随机采样一个话题分布θ，<br>(2)按如下步骤生成文档中的N个词:</p>
<p>图14.11 LDA 的文档生成过程示意图</p>
<p>(a)根据队进行话题指派，得到文档t 中词n 的话题Z；</p>
<p>(b)根据指派的话题所对应的词频分布战随机采样生成词。</p>
<p>图14.11 演示出根据以上步骤生成文档的过程。显然，这样生成的文档自然地以不同比例包含多个话题(步骤1)，文档中的每个词来自一个话题(步骤2b)，而这个话题是依据话题比例产生的(步骤2a)。</p>
<p>图14.12 描述了LDA 的变量关系，其中文档中的词频Wtn 是唯一的已观测变量，它依赖于对这个词进行的话题指派）），以及话题所对应的词频））；同时，话题指派））依赖于话题分布））依赖于狄利克雷分布的参数a，而话题词频则依赖于参数η。</p>
<p>于是，LDA 模型对应的概率分布为</p>
<p>其中））和））通常分别设置为以a 和η 为参数的K 维和N 维狄<br>利克雷分布，例如</p>
<p>其中f(·)是Gamma 函数。显然，a 和η 是模型式(14.41)中待确定的参数。</p>
<p>给定训练数据））, LDA 的模型参数可通过极大似然法估计，即寻找a 和η 以最大化对数似然</p>
<p>但由于））不易计算，式(14.43)难以直接求解，因此实践中常采用变分法来求取近似解</p>
<p>若模型已知，即参数a 和η 已确定，则根据词频Wtn 来推断文档集所对应的话题结构(即推断θ，βk 和z) ）） 可通过求解</p>
<p>然而由于分母上的））难以获取，式(14.44)难以直接求解，因此在实践中常采用吉布斯采样或变分法进行近似推断。</p>
<h2 id="阅读材料-13"><a href="#阅读材料-13" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>概率图模型方面已经有专门的书籍如［Koller and Friedman, 2009］ 。</p>
<p>［Pearl, 1982］倡导了贝叶斯网的研究，［Pearl, 1988］对这方面的早期研究工作进行了总结。马尔可夫随机场由［Geman and Geman, 1984］提出现实应用中使用的模型经常是贝叶斯网与马尔可夫随机场的结合。隐马尔可夫模型及其在语音识别中的应用可参阅［Rabiner, 1989］.条件随机场由［Lafferty et al., 2001］提出，更多的内容可参阅［Sutton and McCallum, 2012］。</p>
<p>信念传播算法最早由［Pearl, 1986］作为精确推断技术提出，后来衍生出多种近似推断算法。对一般的带环图，信念传播算法需在初始化、消息传递等环节进行调整，由此形成了迭代信念传播算法(Loopy Belief Propagation)［Murphy et al., 1999］，但其理论性质尚不清楚，这方面的进展可参阅［Mooijand Kappen, 2007; Weiss，2000］.有些带环图可先用“因子图”(factor graph)［Kschischang et al., 2001］描述，再转化为因子树(factor tree进行信念传播。对任意图结构的信念传播已有一些研究［Lauritzen and Spiegelhalter, 1988］.近来随着并行计算技术的发展，信念传播的并行加速实现受到关注，例如［Gonzalezet al., 2009］提出TE 近似推断的概念并设计出多核并行信念传播算法，其时间开销随内核数的增加而线性降低。</p>
<p>概率图模型的建模和推断，尤其是变分推断在20 世纪90年代中期逐步发展成熟，［Jordan, 1998］对这个阶段的主要成果进行了总结关于变分推断的更多内容可参阅［Wainw right and Jordan, 2008］。</p>
<p>图模型带来的一大好处是使得人们能直观、快速地针对具体任务定义模型.LDA ［Blei et al., 2003］是这方面的重要代表，由它产生了很多变体，关于这方面的内容可参阅［Blei, 2012］.概率图模型的一个发展方向是使得模型的结构能对数据有一定的自适应能力，即“非参数化”(non-parametric)方法，例如层次化狄利克雷过程模型［Teh et al. 2006］、无限隐特征模型［Ghahramani andGriffiths, 2006］等。</p>
<p>话题模型包含了多种模型，其中有些并不采用贝叶斯学习方法，例如PLSA(概率隐语义分析 ［Hofmann, 2006］，它是LSA (隐语义分析)的概率扩展。</p>
<p>蒙特卡罗方法是二十世纪四十年代产生的一类基于概率统计理论、使用随机数来解决问题的数值计算方法，MCMC 是马尔可夫链与蒙特卡罗方法的结合，最早由［Pearl, 1987］引入贝叶斯网推断。关于MCMC 在概率推断中的应用可参阅［Neal, 1993］，更多关于MCMC 的内容可参阅［A ndrieu et al., 2003;Gilks et al., 1996］。</p>
<h3 id="休息一会儿-12"><a href="#休息一会儿-12" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：概率图模型奠基人朱迪亚·珀尔</p>
<p>说起概率图模型，就必然要谈到犹太裔美国计算机科学家朱迪亚·珀尔(Judea Pearl, 1936-).地尔出生于特拉维夫，1960年他在以色列理工学院电子工程本科毕业后来到美国，在Rutgers 大学和布鲁克林理工学院分别获得物理学硕士和电子工程博士学位1965年博士毕业后进入RCA研究实验室从事超导存储方面的工作，1970年到加州大学洛杉矶分校任教至今。</p>
<p>早期的主流人工智能研究专注于以逻辑为基础来进行形式化和推理，但这样很难定量地对不确定性事件进行表达和处理。珀尔在二十世纪七十年代将概率方法引入人工智能，开创了贝叶斯网的研究，提出了信念传播算法，催生了概率图模型这一大类技术他还以贝叶斯网为工具开创了因果推理方面的研究。由于对人工智能中概率与因果推理的重大贡献，他获得2011年图灵奖，此前他已获ACM 与AAAI 联合颁发的2003年艾伦·纽厄尔奖，ACM 评价珀尔在人工智能领域的贡献已扩展到诸多学科领域“使统计学、心理学、医学以及社会科学中因果性的理解产生了革命性的变化”，2011年珀尔还获得科学哲学领域最高奖拉卡托斯奖。</p>
<p>珀尔之子丹尼尔是《华尔街日报》驻南亚记者“9•11” 事件后他在巴基斯坦追踪报道激进武装组织时被绑架审讯并残忍地斩首，此事震惊世界础尔此后筹办了丹尼尔。珀尔基金会，并参与了很多致力于促进世界民族和平共处的活动。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第15章-规则学习"><a href="#第15章-规则学习" class="headerlink" title="第15章 规则学习"></a>第15章 规则学习</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>机器学习中的“规则”(rule)通常是指语义明确、能描述数据分布所隐含的客观规律或领域概念、可写成“若……，则……”形式的逻辑规则［Furnkranz et al., 2012］.“规则学习”(rule learning)是从训练数据中学习出一组能用于对未见示例进行判别的规则。</p>
<p>形式化地看，一条规则形如：<br>））</p>
<p>其中逻辑蕴含符号“←”右边部分称为“规则体”(body)，表示该条规则的前提，左边部分称为“规则头”(head)，表示该条规则的结果规则体是由逻辑文字(literal)fk 组成的合取式(conjunction)，其中合取符号“∧”用来表示“并且” 。每个文字fk 都是对示例属性进行检验的布尔表达式，例如“(色泽=乌黑)”或“┐(根蒂=硬挺)”.L 是规则体中逻辑文字的个数，称为规则的长度。规则头的“⊕”同样是逻辑文字，一般用来表示规则所判定的目标类别或概念，例如“好瓜”，这样的逻辑规则也被称为“if-then 规则”。</p>
<p>与神经网络、支持向量机这样的“黑箱模型”相比，规则学习具有更好的可解释性，能使用户更直观地对判别过程有所了解。另一方面，数理逻辑具有极强的表达能力，绝大多数人类知识都能通过数理逻辑进行简洁的刻画和表达。例如“父亲的父亲是爷爷”这样的知识不易用函数式描述，而用一阶逻辑则可方便地写为“爷爷(X,Y)←父亲(X, Z) ∧ 父亲(Z,Y)”，因此，规则学习能更自然地在学习过程中引入领域知识。此外，逻辑规则的抽象描述能力在处理一些高度复杂的AI 任务时具有显著的优势，例如在问答系统中有时可能遇到非常多、甚至无穷种可能的答案，此时若能基于逻辑规则进行抽象表述或者推理，则将带来极大的便利。</p>
<p>假定我们从西瓜数据集学得规则集合R：</p>
<p>规则1：好瓜←(根蒂=蜷缩)∧(脐部=凹陷)；<br>规则2：┐好瓜←(纹理=模糊)。</p>
<p>规则1 的长度为2，它通过判断两个逻辑文字的赋值(valuation)来对示例进行判别。符合该规则的样本(例如西瓜数据集2.0 中的样本1)称为被该规则“覆盖”(cover).需注意的是，被规则1 覆盖的样本是好瓜，但没被规则1 覆盖的未必不是好瓜；只有被规则2 这样以“┐好瓜”为头的规则覆盖的才不是好瓜。</p>
<p>显然，规则集合中的每条规则都可看作一个子模型，规则集合是这些子模型的一个集成。当同一个示例被判别结果不同的多条规则覆盖时，称发生了“冲突”(conflict)，解决冲突的办法称为“冲突消解”(conflict resolution).常用的冲突消解策略有投票法、排序法、元规则法等。投票法是将判别相同的规则数最多的结果作为最终结果。排序法是在规则集合上定义一个顺序，在发生冲突时使用排序最前的规则；相应的规则学习过程称为“带序规则”(orderedrule)学习或“优先级规则”(priority rule)学习。元规则法是根据领域知识事先设定一些“元规则”(meta-rule)，即关于规则的规则，例如“发生冲突时使用长度最小的规则”然后根据元规则的指导来使用规则集。</p>
<p>此外，从训练集学得的规则集合也许不能覆盖所有可能的未见示例，例如前述规则集合冗无法对“根蒂=蜷缩”、“脐部=稍凹”且“纹理=清晰”的示例进行判别；这种情况在属性数目很多时常出现。因此，规则学习算法通常会设置一条“默认规则”(default rule)，由它来处理规则集合未覆盖的样本；例如为冗增加一条默认规则：“未被规则1, 2 覆盖的都不是好瓜” 。</p>
<p>从形式语言表达能力而言，规则可分为两类·“命题规则”(propositionalrule)和“ 一阶规则”(first-order rule).前者是由“原子命题”(propositionalatom)和逻辑连接词“与”、“或”、“非” 和“蕴含”(←构成的简单陈述句； 例如规则集冗就是一个命题规则集，“根蒂=蜷缩”“脐部=凹陷”都是原子命题。后者的基本成分是能描述事物的属性或关系的“原子公式”(atomic formula)，例如表达父子关系的谓词(predicate)“父亲(X,Y)” 就是原子公式，再如表示加一操作“σ”的函数“σ(X)”也是原子公式。如果进一步用谓词“自然数(X)”表示X 是自然数，））表示“对于任意X 成立”， “存在∃Y” 表示 “存在Y 使之成立”，那么“所有自然数加1 都是自然数”就可写作“））←自然数））”，或更简洁的“））← 自然数(X））” 这样的规则就是一阶规则，其中X 和Y 称为逻辑变量，“任意∀”“存在∃”分别表示“任意”和“存在”，用于限定变量的取值范围，称为“量词”(quant ifier).显然，一阶规则能表达复杂的关系，因此也被称为“关系型规则” (relational rule).以西瓜数据为例，若我们简单地把属性当作谓词来定义示例与属性值之间的关系，则命题规则集冗可改写为一阶规则集可。</p>
<p>规则1 ： 好瓜(X)←根蒂(X)，蜷缩∧脐部(X,凹陷)；<br>规则2 ：「好瓜(X)←纹理(X)，模糊 。</p>
<p>显然，从形式语言系统的角度来看，命题规则是一阶规则的特例，因此一阶规则的学习比命题规则要复杂得多。</p>
<h2 id="-71"><a href="#-71" class="headerlink" title></a><br></h2><h2 id="序贯覆盖"><a href="#序贯覆盖" class="headerlink" title="序贯覆盖"></a>序贯覆盖</h2><p>规则学习的目标是产生一个能覆盖尽可能多的样例的规则集。最直接的做法是“序贯覆盖”(sequential covering)，即逐条归纳。在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练、集重复上述过程。由于每次只处理一部分数据，因此也被称为“分治”(separate-and-conquer)策略。</p>
<p>我们以命题规则学习为例来考察序贯覆盖法。命题规则的规则体是对样例属性值进行评估的布尔函数，如“色泽=青绿” “含糖率≤0.2 ” 等，规则头是样例类别。序贯覆盖法的关键是如何从训练集学出单条规则。显然，对规则学习目标⊕，产生一条规则就是寻找最优的一组逻辑文字来构成规则体，这是一个搜索问题。形式化地说，给定正例集合与反例集合，学习任务是基于候选文字集合））来生成最优规则r.在命题规则学习中，候选文字是形如“R(属性i,属性值i,j)” 的布尔表达式，其中属性i 表示样例第i个属性，属性值i j表示属性i 的第j个候选值，R(x,y)则是判断x、y 是否满足关系R的二元布尔函数。</p>
<p>最简单的做法是从空规则“⊕←”开始，将正例类别作为规则头，再逐个遍历训练集中的每个属性及取值，尝试将其作为逻辑文字增加到规则体中，若能使当前规则体仅覆盖正例，则由此产生一条规则，然后去除已被覆盖的正例并基于剩余样本尝试生成下一条规则。</p>
<p>以西瓜数据集2.0 训练集为例首先根据第1个样例生成文字“好瓜”和“色泽=青绿” 加入规则，得到</p>
<p>好瓜←(色泽=青绿)</p>
<p>这条规则覆盖样例1, 6, 10 和17，其中有两个正例和两个反例，不符合“当前规则仅覆盖正例”的条件。于是，我们尝试将该命题替换为基于属性“色泽”形成的其他原子命题，例如“色泽=乌黑”；然而在这个数据集上，这样的操作能产生符合条件的规则。于是我们回到“色泽=青绿”，尝试增加一个基于其他属性的原子命题，例如“根蒂一蜷缩”:</p>
<p>好瓜←(色泽=青绿)∧(根蒂=蜷缩)</p>
<p>该规则仍覆盖了反例17.于是我们将第二个命题替换为基于该属性形成的其他<br>原子命题，例如“根蒂=稍蜷”：</p>
<p>好瓜←(色泽=青绿)∧(根蒂=稍蜷)</p>
<p>这条规则不覆盖任何反例，虽然它仅覆盖一个正例，但已满足“当前规则仅覆盖正例”的条件。因此我们保留这条规则并去除它覆盖的样例6，然后将剩下的9个样例用作训练集如此继续，我们将得到:</p>
<p>规则1 ：好瓜←(色泽=青绿)∧(根蒂=稍蜷)<br>））</p>
<p>这个规则集覆盖了所有正例，未覆盖任何反例，这就是序贯覆盖法学得的结果。上面这种基于穷尽搜索的做法在属性和候选值较多时会由于组合爆炸而不可行。现实任务中一般有两种策略来产生规则：第一种是“自顶向下”(top-down)，即从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足预定条件为止；亦称为“生成－测试”(generate-then-test)法，是规则逐渐“特化”(specialization)的过程。第二种策略是“自底向上”(bottom-up)，即从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围，直到满足条件为止，亦称为“数据驱动”(data-driven)法，是规则逐渐“泛化”(generalization)的过程第一种策略是覆盖范围从大往小搜索规则，第二种策略则相反，前者通常更容易产生泛化性能较好的规则，而后者则更适合于训练样本较少的情形，此外，前者对噪声的鲁棒性比后者要强得多。因此，在命题规则学习中通常使用第一种策略，而第二种策略在一阶规则学习这类假设空间非常复杂的任务上使用较多。</p>
<p>下面以西瓜数据集2.0 训练集为例来展示自顶向下的规则生成方法。首先从空规则“好瓜←”开始，逐一将“属性=取值”作为原子命题加入空规则进行考察假定基于训练集准确率来评估规则的优劣，n／m 表示加入某命题后新规则在训练集上的准确率，其中m 为覆盖的样例总数，n 为覆盖的正例数如图15.1 所示，经过第一轮评估，“色泽=乌黑”和“脐部=凹陷”都达到了最高准确率3/4。</p>
<p>图15.1在西瓜数据集2.0训练集上“自顶向下”生成单条规则</p>
<p>将属性次序最靠前的逻辑文字“色泽=乌黑”加入空规则，得到</p>
<p>好瓜←(色泽=乌黑)</p>
<p>然后，对上面这条规则覆盖的样例，通过第二轮评估可发现，将图15.1 中的五个逻辑文字加入规则后都能达到100% 准确率，我们将覆盖样例最多、且属性次序最靠前的逻辑文字“根蒂=蜷缩”加入规则，于是得到结果</p>
<p>好瓜←(色泽=乌黑)∧(根蒂=蜷缩)</p>
<p>规则生成过程中涉及一个评估规则优劣的标准，在上面的例子中使用的标准是：先考虑规则准确率，准确率相同时考虑覆盖样例数，再相同时考虑属性次序，现实应用中可根据具体任务情况设计适当的标准。</p>
<p>此外，在上面的例子中每次仅考虑一个“最优”文字，这通常过于贪心，易陷入局部最优。为缓解这个问题，可采用一些相对温和的做法，例如采用“集束搜索”(beam search)，即每轮保留最优的b个逻辑文字，在下一轮均用于构建候选集，再把候选集中最优的b个留待再下一轮使用。图15.1 中若采用b=2的集束搜索，则第一轮将保留准确率为3/4 的两个逻辑文字，在第二轮评估后就能获得下面这条规则，其准确率仍为100%，但是覆盖了3个正例：</p>
<p>好瓜←(脐部=凹陷)∧(根蒂=蜷缩)</p>
<p>由于序贯覆盖法简单有效，几乎所有规则学习算法都以它为基本框架。它能方便地推广到多分类问题上只需将每类分别处理即可·当学习关于第c 类的规则时，将所有属于类别c 的样本作为正例，其他类别的样本作为反例。</p>
<h2 id="-72"><a href="#-72" class="headerlink" title></a><br></h2><h2 id="剪枝优化"><a href="#剪枝优化" class="headerlink" title="剪枝优化"></a>剪枝优化</h2><p>规则生成本质上是一个贪心搜索过程需有一定的机制来缓解过拟合的风险，最常见的做法是剪枝(pruning).与决策树相似，剪枝可发生在规则生长过程中，即“预剪枝”也可发生在规则产生后，即“后剪枝” 。通常是基于某种性能度量指标来评估增／删逻辅文字前后的规则性能，或增/删规则前后的规则集性能，从而判断是否要进行剪枝。</p>
<p>剪枝还可借助统计显著性检验来进行例如CN2 算法［Clark and Niblett,1989］在预剪枝时，假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测。为便于计算，CN2 使用了似然率统计量(Likelihood Ratio Statistics，简称LRS).令m+, m- 分别表示训练样例集中的正、反例数目，m+，m- 分别表示规则(集)覆盖的正、反例数目，则有</p>
<p>这实际上是一种信息量指标，衡量了规则(集)覆盖样例的分布与训练集经验分布的差别：LRS 越大，说明采用规则(集进行预测与直接使用训练集正、反例比率进行猜测的差别越大； LRS 越小，说明规则(集 的效果越可能仅是偶然现象在数据量比较大的现实任务中，通常设置为在LRS 很大(例如0.99)时CN2算法才停止规则(集)生长。</p>
<p>后剪枝最常用的策略是“减错剪枝”(Reduced Error Pruning，简称REP)［Brunk and Pazzani, 1991］，其基本做法是：将样例集划分为训练集和验证集，从训练集上学得规则集R后进行多轮剪枝，在每一轮穷举所有可能的剪枝操作，包括删除规则中某个文字、删除规则结尾文字、删除规则尾部多个文字、删除整条规则等，然后用验证集对剪枝产生的所有候选规则集进行评估，保留最好的那个规则集进行下一轮剪枝，如此继续，直到无法通过剪枝提高验证集上的性能为止</p>
<p>REP 剪枝通常很有效［B runk and Pazzani, 1991］，但其复杂度是O(m)，m 为训练样例数目.IREP (Incremental REP) ［Furnkranz and Widmer, 1994］将复杂度降到）），其做法是· 在生成每条规则前，先将当前样例集划分为训练集和验证集，在训练集上生成一条规则r，立即在验证集上对其进行REP剪枝，得到规则r＇；将r＇覆盖的样例去除，在更新后的样例集上重复上述过程。显然，REP 是针对规则集进行剪枝，而IREP 仅对单条规则进行剪枝，因此后者比前者更高效</p>
<p>若将剪枝机制与其他一些后处理手段结合起来对规则集进行优化，则往往能获得更好的效果以著名的规则学习算法RIPPER［Cohen, 1995］为例，其泛化性能超过很多决策树算法，而且学习速度也比大多数决策树算法更快，奥妙就在于将剪枝与后处理优化相结合。</p>
<p>RIPPER 算法描述如图15.2 所示。它先使用IREP＊剪枝机制生成规则集RIREP* ［Cohen, 1995］ 是IREP 的改进，主要是以））取代了IREP 使用的准确率作为规则性能度量指标，在剪枝时删除规则尾部的多个文字，并在最终得到规则集之后再进行一次IREP 剪枝.RIPPER 中的后处理机制是为了在剪枝的基础上进一步提升性能对R中的每条规则ri, RIPPER 为它产生两个变体：</p>
<p>• ri＇ 基于ri 覆盖的样例，用IREP＊重新生成一条规则ri＇，该规则称为替换规则(replacement rule);</p>
<p>• ri” 对ri 增加文字进行特化，然后再用IREP ＊剪枝生成一条规则ri”，该规则称为修订规则(revised rule)</p>
<p>接下来，把ri＇和ri” 分别与R中除ri 之外的规则放在一起，组成规则集可和R” ，将它们与R一起进行比较，选择最优的规则集保留下来。这就是图15.2 中算法第4 行所做的操作</p>
<p>为什么RIPPER 的优化策略会有效呢，原因很简单。最初生成R的时候，规则是按序生成的，每条规则都没有对其后产生的规则加以考虑，这样的贪心算法本质常导致算法陷入局部最优，RIPPER 的后处理优化过程将R中的所有规则放在一起重新加以优化，恰是通过全局的考虑来缓解贪心算法的局部性，从而往往能得到更好的效果［Fiirnkranz et al., 2012］。</p>
<h2 id="-73"><a href="#-73" class="headerlink" title></a><br></h2><h2 id="一阶规则学习"><a href="#一阶规则学习" class="headerlink" title="一阶规则学习"></a>一阶规则学习</h2><p>受限于命题逻辑表达能力，命题规则学习难以处理对象之间的“关系”(relation)，而关系信息在很多任务中非常重要。例如，我们在现实世界挑选西瓜时，通常很难把水果摊上所有西瓜的特征用属性值描述出来，因为我们很难判断。色泽看起来多深才叫“色泽青绿”? 敲起来声音多低才叫“敲声沉闷”，比较现实的做法是将西瓜进行相互比较例如“瓜1的颜色比瓜2 更深，并且瓜1 的根蒂比瓜2 更蜷”，因此“瓜1 比瓜2 更好”，然而，这已超越了命题逻辑的表达能力，需用一阶逻辑表示，并且要使用一阶规则学习。</p>
<p>对西瓜数据2 我们不妨定义：</p>
<p>。色泽深度：乌黑＞青绿＞浅白；<br>。根蒂蜷度：蜷缩＞稍蜷＞硬挺；<br>。敲声沉度：沉闷＞浊响＞清脆；<br>。纹理清晰度：清晰＞稍糊＞模糊；<br>。脐部凹陷度：凹陷＞稍凹＞平坦；<br>。触感硬度：硬滑＞软粘。</p>
<p>于是，西瓜数据集2.0 训练集就转化为表15.1 的西瓜数据集5.0.这样的数据直接描述了样例间的关系，称为“关系数据”(relational data)，其中由原样本属性转化而来的“色泽更深”“根蒂更蜷”等原子公式称为“ 背景知识”(background knowledge)，而由样本类别转化而来的关于“更好”“┐更好”的原子公式称为关系数据样例(examples).从西瓜数据集5.0 可学出这样的一阶规则：</p>
<p>））</p>
<p>显然，一阶规则仍是式(15.1的形式：但其规则头、规则体都是一阶逻辑表达式，“更好”、“根蒂更蜷”、“脐部更凹”是关系描述所对应的谓词，个体对象“瓜1 ”、“瓜2 ”被逻辑变量“ X ”、“ Y ” 替换。全称量词“ 任意∀ ” 表示该规则对所有个体对象都成立；通常，在一阶规则中所有出现的变量都被全称量词限定，因此下面我们在不影响理解的情况下将省略量词部分一阶规则有强大的表达能力，例如它能简洁地表达递归概念，如</p>
<p>））</p>
<p>一阶规则学习能容易地引入领域知识，这是它相对于命题规则学习的另一大优势。在命题规则学习乃至一般的统计学习中，若欲引入领域知识，通常有两种做法： 在现有属性的基础上基于领域知识构造出新属性，或基于领域知识设计某种函数机制(例如正则化)来对假设空间加以约束。然而，现实任务中并非所有的领域知识都能容易地通过属性重构和函数约束来表达。例如，假定获得了包含某未知元素的化合物X，欲通过试验来发现它与已知化合物Y 的反应方程式我们可多次重复试验，测出每次结果中化合物的组分含量。虽然我们对反应中的未知元素性质一无所知，但知道一些普遍成立的化学原理，例如金属原子一般产生离子键、氢原子之间一般都是共价键等，并且也了解已知元素间可能发生的反应。有了这些领域知识，重复几次试验后就不难学出X 和Y 的反应方程式，还可能推测出X 的性质、甚至发现新的分子和元素。类似这样的领域知识充斥在日常生活与各类任务中，但在基于命题表示的学习中加以利用却非常困难</p>
<p>FOIL ( First-Order Inductive Learner) ［Quinlan, 1990］是著名的一阶规则学习算法，它遵循序贯覆盖框架且采用自顶向下的规则归纳策略，与15.2 节中的命题规则学习过程很相似。但由于逻辑变量的存在，FOIL 在规则生成时需考虑不同的变量组合。例如在西瓜数据集5.0 上，对“更好(X,Y)” 这个概念，最初的空规则是<br>））</p>
<p>接下来要考虑数据中所有其他谓词以及各种变量搭配作为候选文字。新加入的文字应包含至少一个已出现的变量，否则没有任何实质意义在这个例子中考虑下列候选文字：</p>
<p>FOIL使用“FOIL增益”(FOIL gain)来选择文字：</p>
<p>其中，m+，n-分别为增加候选文字后新规则所覆盖的正、反例数，m+，n-为原规则覆盖的正、反例数.FOIL 增益与决策树使用的信息增益不同，它仅考虑正例的信息量，并且用新规则覆盖的正例数作为权重这是由于关系数据中正例数往往远少于反例数，因此通常对正例应赋予更多的关注。</p>
<p>在西瓜数据集5.0 的例子中，只需给初始的空规则体加入“色泽更深(X,Y)”或“脐部更凹(X,Y)”，新规则就能覆盖16个正例和2个反例，所对应的FOIL 增益为候选最大值））.假定前者被选中，则得到</p>
<p>更好(X,Y)← 色泽更深(X,Y)。</p>
<p>该规则仍覆盖2个反例：“更好(15,1)” 与 “ 更好(15,6)” 。于是，FOIL 像命题规则学习那样继续增加规则体长度，最终生成合适的单条规则加入规则集。此后，FOIL 使用后剪枝对规则集进行优化。</p>
<p>若允许将目标谓词作为候选文字加入规则体，则FOIL 能学出递归规则；若允许将否定形式的文字┐f 作为候选，则往往能得到更简洁的规则集。</p>
<p>FOIL 可大致看作命题规则学习与归纳逻辑程序设计之间的过渡，其自顶向下的规则生成过程不能支持函数和逻辑表达式嵌套，因此规则表达能力仍有不足，但它是把命题规则学习过程通过变量替换等操作直接转化为一阶规则学习，因此比一般归纳逻辑程序设计技术更高效。</p>
<h2 id="-74"><a href="#-74" class="headerlink" title></a><br></h2><h2 id="归纳逻辑程序设计"><a href="#归纳逻辑程序设计" class="headerlink" title="归纳逻辑程序设计"></a>归纳逻辑程序设计</h2><p>归纳逻辑程序设计(Inductive Logic Programming，简称ILP)在一阶规则学习中引入了函数和逻辑表达式嵌套。一方面，这使得机器学习系统具备了更为强大的表达能力；另一方面，ILP 可看作用机器学习技术来解决基于背景知识的逻辑程序(logic program)归纳，其学得的“规则”可被PROLOG 等逻辑程序设计语言直接使用。</p>
<p>然而，函数和逻辑表达式嵌套的引入也带来了计算上的巨大挑战例如，给定一元谓词P 和一元函数f，它们能组成的文字有）））） 等无穷多个，这就使得规则学习过程中可能的候选原子公式有无穷多个，若仍采用命题逻辑规则或FOIL 学习那样自顶向下的规则生成过程，则在增加规则长度时将因无法列举所有候选文字而失败实际困难还不止这些，例如计算FOIL曾益需对规则覆盖的全部正反例计数，而在引入函数和逻辑表达式嵌套之后这也变得不可行。</p>
<h3 id="最小一般泛化"><a href="#最小一般泛化" class="headerlink" title="最小一般泛化"></a>最小一般泛化</h3><p>归纳逻辑：程序设计采用自底向上的规则生成策略，直接将一个或多个正例<br>所对应的具体事实(grounded fact)作为初始规则，再对规则逐步进行泛化以增<br>加其对样例的覆盖率。泛化操作可以是将规则中的常量替换为逻辑变量，也可<br>以是删除规则体中的某个文字。</p>
<p>以西瓜数据集5.0 为例，为简便起见，暂且假定“更好(X,Y)”仅决定于(X,Y)取值相同的关系：正例“更好(1,10)”和“更好(1,15)”所对应的初始规则分别为</p>
<p>更好(1,10)←根蒂更蜷(1,10)∧声音更沉(1,10)∧脐部更凹(1,10)∧触感更硬(1,10);</p>
<p>更好(1, 15)←根蒂更蜷(1,15)∧脐部更凹(1,15)∧触感更硬(1,15)</p>
<p>显然，这两条规则只对应了特殊的关系数据样例，难以具有泛化能力。因此，我们希望把这样的“特殊”规则转变为更“一般”的规则。为达到这个目的，最基础的技术是“最小一般泛化”(Least General Generalization，简称LGG) ［Plotkin, 1970］。</p>
<p>给定一阶公式r1 和r2, LGG 先找出涉及相同谓词的文字，然后对文字中每个位置的常量逐一进行考察，若常量在两个文字中相同则保持不变，记为LGG(t,t)=t；否则将它们替换为同一个新变量，并将该替换应用于公式的所有其他位置。假定这两个不同的常量分别为s, t，新变量为v，则记为LGG(s, t)=V，并在以后所有出现LGG(s,t)的位置用V 来代替。例如对上面例子中的两条规则，先比较“ 更好(1,10)”和“更好(1,15)”， 由于文字中常量“10”不等于≠“15” ，因此将它们都替换为Y，并在r1 和r2 中将其余位置上成对出现的＂10 ”和“15”都替换为Y，得到</p>
<p>更好(1,Y)←根蒂更蜷(1,Y)∧声音更沉(1,Y)∧脐部更凹(1,Y)∧触感更硬(1,Y);</p>
<p>更好(1,Y)←根蒂更蜷(1,15)∧脐部更凹(1,Y)∧触感更硬(1,Y)</p>
<p>然后： LGG 忽略r1 和r2 中不含共同谓词的文字，因为若LGG 包含某条公式所没有的谓词，则LGG 无法特化为那条公式。容易看出，在这个例子中需忽略“声音更沉(1,10)这个文字，于是得到的LGG 为</p>
<p>式(15.4)仅能判断瓜1 是否比其他瓜更好为了提升其泛化能力，假定另有一条关于瓜2 的初始规则</p>
<p>于是可求取式(15.4)与(15.5)的LGG.注意到文字“ 更好(2,10)”和“更好(1,Y)＂ 的对应位置同时出现了常量“10” 与变量“Y”，于是可令LGG(10,Y)=Y2，并将所有“ 10 ” 与“ Y ”成对出现的位置均替换为Y2，最后，令LGG(2,1)=X 并删去谓词不同的文字，就得到如下这条不包含常量的一般规则。</p>
<p>上面的例子中仅考虑了肯定文字，未使用“┐” 符号。实际上LGG 还能进行更复杂的泛化操作。此外，上面还假定“更好(X,Y)”的初始规则仅包含变量同为(X,Y)的关系，而背景知识中往往包含其他一些有用的关系，因此许多ILP 系统采用了不同的初始规则选择方法。最常用的是RLGG (Relative LeastGeneral Generali zation) ［Plotkin, 1971］，它在计算LGG 时考虑所有的背景知识，将样例巴的初始规则定义为e← K，其中K 是背景知识中所有原子的合取。</p>
<p>容易证明，LGG 是能特化为ri 和r2 的所有一阶公式中最特殊的一个：不存在既能特化为r1 和r2，也能泛化为它们的LGG 的一阶公式r’。</p>
<p>在归纳逻辑程序设计中，获得LGG 之后，可将其看作单条规则加入规则集，最后再用前几节介绍的技术进一步优化，例如对规则集进行后剪枝等，</p>
<h3 id="逆归结"><a href="#逆归结" class="headerlink" title="逆归结"></a>逆归结</h3><p>在逻辑学中，“演绎”(deduction)与“归纳”(induction)是人类认识世界的两种基本方式。大致来说，演绎是从一般性规律出发来探讨具体事物，而归纳则是从个别事物出发概括出一般性规律。一般数学定理证明是横绎实践的代表，而机器学习显然是属于归纳的范畴.1965年，逻辑学家J.A.Robinson 提出，一阶谓词演算中的演绎推理能用一条十分简洁的规则描述，这就是数理逻辑中著名的归结原理(resolution principle) ［Robinson, 1965］.二十多年后，计算机科学家S.Muggleton 和W.Buntine 针对归纳推理提出了“逆归结”(inverseresolution) ［Muggleton and Buntine, 1988］，这对归纳逻辑程序设计的发展起到了重要作用。</p>
<p>基于归结原理，我们可将貌似复杂的逻辑规则与背景知识联系起来化繁为简；而基于逆归结，我们可基于背景知识来发明新的概念和关系。下面我们先以较为简单的命题演算为例，来看看归结、逆归结是怎么回事。</p>
<p>假定两个逻辑表达式C1 和C2 成立，且分别包含了互补项L1 与L2 ；不失一般性，令））.归结原理告诉我们，通过演绎推理能消去L 而得到“归结项”.若定义析合范式的删除操作</p>
<p>与上面的过程相反，逆归结研究的是在已知C 和某个Ci 的情况下如何得到））.假定已知C 和C1 求C2，则由式(15.7)该过程可表述为</p>
<p>在逻辑推理实践中如何实现逆归结呢？ ［Muggleton，1995］定义了四种完备的逆归结操作。若以规则形式p ← q 等价地表达）），并假定用小写字母表示逻辑文字、大写字母表示合取式组成的逻辑子句，则这四种操作是。</p>
<p>吸收(absorption) :<br>辨识(identification) :<br>内构(intra-construction) :<br>互构(inter-construction) :</p>
<p>这里我们用））表示X 蕴含Y，在数理逻辑里写作X ← Y 上述规则中，X 的子句或是Y 的归结项，或是Y 的某个子句的等价项； 而Y 中出现的新逻辑文字则可看作通过归纳学到的新命题。</p>
<p>归结、逆归结都能容易地扩展为一阶逻辑形式；与命题逻辑的主要不同之处是，一阶逻辑的归结、逆归结通常需进行合一置换操作。</p>
<p>“置换” (substitution)是用某些项来替换逻辑表达式中的变量例如用）） 置换“C=色泽更深(X,Y)∧敲声更沉(X,Y)” 可得到“C’=C0=色泽更深(1,2)∧敲声更沉(1,2)”，其中{X,Y}称为θ 的作用域(domain）.与代数中的置换类似，一阶逻辑中也有“复合置换”和“逆置换” 例如先用））将X 替换为Y，再用））将Y 替换为1，这样的复合操作记为）） 的逆置换则记为））。</p>
<p>“合一”(unification)是用一种变量置换令两个或多个逻辑表达式相等。例如对“A=色泽更深(1,X)”和“B=色泽更深(Y,2)”，可用））使））； 此时称A 和B 是“可合一的”(unifiable)，称。为A 和B 的“合一化子”(unifier).若𝞭 是一组一阶逻辑表达式W 的合一化子，且对W 的任意合一化子θ均存在相应的置换λ 使）），则称𝜹 为W 的“最一般合一置换”或“最一般合一化子”(most general unifier，简记为MGU)，这是归纳逻辑程序中最重要的概念之一。例如“色泽更深(1,Y)”和“色泽更深(X,Y)”能被））合一，但仅有θ1 是它们的MGU。</p>
<p>一阶逻辑进行归结时，需利用合一操作来搜索互补项L1 和L2.对两个一阶逻辑表达式）），若存在合一化子θ使））,则可对其进行归结：</p>
<p>类似的，可利用合一化子对式(15.9)进行扩展得到一阶逻辑的逆归结基于式(15.8)，定义）） 为“归结商”(resolution quotient) ,于是，逆归结的目标就是在已知C 和C1 时求出归结商C2.对某个L1∈C1，假定如是一个置换，它能使</p>
<p>））</p>
<p>这里∅的作用域是C1中所有变量，记为）），其作用是使））与C中的对应文字能合一，令∅为作用域是））的置换，L2 为归结商C2 中将被消去的文字，θ2 是以vars(L2)为作用域的置换，））与））共同作用于L1，使得）），于是））的MGU.将前两步的复合置换））记为θ1，用）） 表示θ2 的逆置换，则有））于是，类似于式(15.9)，一阶逆归结是</p>
<p>））</p>
<p>在一阶情形下L1 、L2 、θ1 和θ2 的选择通常都不唯一这时需通过一些其他的判断标准来取舍，例如覆盖率、准确率、信息：摘等</p>
<p>以西瓜数据集5.0 为例，假定我们通过一些步骤已得到规则</p>
<p>））</p>
<p>容易看出它们是））和）） 的形式，于是可使用内构操作式(1 5.12)来进行逆归结。由于C1, C2 中的谓词都是二元的，为保持新规则描述信息的完整性，我们创造一个新的二元谓词q(M,N)，并根据式(15.12)得到</p>
<p>））</p>
<p>式(15.12)中横线下方的另两项分别是））的归结商。对））容易发现C＇中通过归结消去L1 的选择可以有“┐根蒂更蜡(1,Z)”和））q是新发明的谓词，迟早需学习一条新规则））来定义它；根据奥卡姆剃刀原则，同等描述能力下学得的规则越少越好，因此我们将））作为L1.由式(15.16)，存在解： L2.通过简单的演算即可求出归结商为）） ” 。类似地可求出C2 / C’的归结商。</p>
<p>逆归结的一大特点是能自动发明新谓词，这些新谓词可能对应于样例属性和背景知识中不存在的新知识，对知识发现与精化有重要意义。但自动发明的新谓词究竟对应于什么语义，例如“ q ” 意味着“更新鲜”?“更甜”?“更多日晒”?……这只能通过使用者对任务领域的进一步理解才能明确。</p>
<p>上面的例子中我们只介绍了如何基于两条规则进行逆归结在现实任务中，ILP 系统通常先自底向上生成一组规则，然后再结合最小一般泛化与逆归结做进一步学习。</p>
<h2 id="阅读材料-14"><a href="#阅读材料-14" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>规则学习是“符号主义学习”(symbolism learning)的主要代表，是最早开始研究的机器学习技术之一［Michalski, 1983］.［Fiirnkranz et al., 2012］对规则学习做了比较全面的总结。</p>
<p>序贯覆盖是规则学习的基本框架，最早在［Michalski, 1969］的AQ 中被提出，AQ 后来发展成一个算法族，其中比较著名的有AQ15 ［Michalski et al.,1986］、AQl7-HCI ［Wnek and Michalski, 1994］ 等。受计算能力的制约2 早期AQ 在学习时只能随机挑选一对正反例作为种子开始训练，样例选择的随机性导致AQ 学习效果不稳定.PRISM ［Cendrowska,1987］解决了这个问题，该算法最早采用自顶向下搜索，并显示出规则学习与决策树学习相比的优点： 决策树试图将样本空间划分为不重叠的等价类，而规则学习并不强求这一点，因此后者学得的模型能有更低的复杂度。虽然PRISM 的性能不如AQ，因此在当时反响不大，但今天来看：它是规则学习领域发展的重要一步。</p>
<p>CN2 ［Clark and Niblett, 1989］采用集柬搜索，是最早考虑过拟合问题的规则学习算法.［Fiirnkranz, 1994］显示出后剪枝在缓解规则学习过拟合中的优势－RIPPER ［Cohen, 1995］是命题规则学习技术的高峰，它融合了该领域的许多技巧，使规则学习在与决策树学习的长期竞争中首次占据上风，作者主页上的C语言RIPPER 版本至今仍代表着命题规则学习的最高水平。</p>
<p>关系学习的研究一般认为始于［Winston, 1970］；由于命题规则学习很难完成此类任务，一阶规则学习开始得以发展.FOIL 通过变量替换等操作把命题规则学习转化为一阶规则学习，该技术至今仍有使用，例如2010年卡耐基梅隆大学开展的“永动语言学习”(Never Ending Language Learning，简称NE LL计划即采用FOIL 来学习自然语言中的语义关系［Carlson et al., 2010］.很多文献将所有的一阶规则学习方法都划入归纳逻辑程序设计的范畴，本书则是作了更为严格的限定。</p>
<p>［Mugg leton, 1991］提出了“归纳逻辑程序设计”(ILP)这个术语？ 在GOLEM [Muggleton and Feng， 1990］中克服了许多从命题逻辑过渡到一阶逻辑学习的困难，并确立了自底向上归纳的ILP 框架．最小一般泛化(LGG)最早由［Plotkin , 1970］提出， GOLEM 则使用了RLGG . PROGOL [Muggleton ,1995 ］ 将逆归结改进为逆蕴含(inverse entailment)并取得了更好效果． 新谓词发明方面近年有一些新进展［Muggleton and Lin, 2013]. 由于ILP 学得的规则几乎能直接被PRO LOG 等逻辑程序解释器调用， 而PRO LOG 在专家系统中常被使用，因此ILP 成为连接机器学习与知识工程的重要桥梁. PROGOL［Muggleton, 1995］和ALEPH ［Srinivasan, 1999］是应用广泛的ILP系统，其基本思想已在本章关于ILP的部分有所体现.Datalog ［Ceri et al., 1989}则对数据库领域产生了很大影响，例如甚至影响了SQL 1999标准和IBM DB2.ILP。方面的重要读物有［Muggleton, 1992; Lavrac and Dzeroski, 1993］，并且有专门的国际归纳逻辑程序设计会议(ILP)。</p>
<p>ILP复杂度很高，虽在生物数据挖掘和自然语言处理等任务中取得一些成功［Bratko and Muggleton, 1995］，但问题规模稍大就难以处理，因此，这方面的研究在统计学习兴起后受到一定抑制。近年来随着机器学习技术进入更多应用领域，在富含结构信息和领域知识的任务中，逻辑表达的重要性逐渐凸显出来，因此出现了一些将规则学习与统计学习相结合的努力，例如试图在归纳逻辑程序设计中引入概率模型的“概率归纳逻辑程序设计”(probabilistic ILP) ［De Raedt et al., 2008］、给贝叶斯网中的结点赋予逻辑意义的“关系贝叶斯网”(relational Bayesian network) ［Jaeger, 2002］等。事实上，将关系学习与统计学习相结合是机器学习发展的一大趋势，而概率归纳逻辑程序设计是其中的重要代表，其他重要代表还有概率关系模型［Friedman et al., 1999］、贝叶斯逻辑程序(Bayesian Logic Program) ［Kersting et al., 2000］、马尔可夫逻辑网(Markov logic network) ［Richardson and Domingos, 2006］等，统称为“统计关系学习”(statistical relational learning) ［Getoor and Taskar, 2007］。</p>
<h3 id="休息一会儿-13"><a href="#休息一会儿-13" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：机器学习先驱雷萨德·迈克尔斯基</p>
<p>AQ 系列算法是规则学习研究早期的重要成果，主要发明人是机器学习先驱、美籍波兰裔科学家雷萨德·迈克尔斯基(Ryszard S.Michalski, 1937- 2007)。</p>
<p>迈克尔斯基出生在波兰卡鲁兹，1969年在波兰获得计算机科学博士学位，同年在南斯拉夫布莱德(Bled，现属斯洛文尼亚)举行的FCIP 会议上发表了AQ.1970年他前往美国UIUC 任教，此后在美国进一步发展了AQ 系列算法。迈克尔斯基是机器学习领域的主要奠基人之一.1980年他与J G.Carbonell 、T.Mitchell 一起在卡耐基梅隆大学组织了第一次机器学习研讨会，1983 、1985年又组织了第二、三次，这个系列研讨会后来发展成国际机器学习会议(ICML); 1983年，迈克尔斯基作为第一主编出版了《机器学习·一种人工智能途径》这本机器学习史上里程碑性质的著作；1986年Machine Learning创刊，迈克尔斯基是最初的三位编辑之一，1988年他将研究组迁到乔治梅森大学，使该校成为机器学习早期发展的一个重镇。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="第16章-强化学习"><a href="#第16章-强化学习" class="headerlink" title="第16章 强化学习"></a>第16章 强化学习</h1><h2 id="任务与奖赏"><a href="#任务与奖赏" class="headerlink" title="任务与奖赏"></a>任务与奖赏</h2><p>我们考虑一下如何种西瓜。种瓜有许多步骤，从一开始的选种，到定期浇水、施肥、除草、杀虫，经过一段时间才能收获西瓜通常要等到收获后，我们才知道种出的瓜好不好，若将得到好瓜作为辛勤种瓜劳动的奖赏，则在种瓜过程中当我们执行某个操作(例如，施肥)时，并不能立即获得这个最终奖赏，甚至难以判断当前操作对最终奖赏的影响，仅能得到一个当前反馈(例如，瓜苗看起来更健壮了)我们需多次种瓜，在种瓜过程中不断摸索，然后才能总结出较好的种瓜策略。这个过程抽象出来，就是“强化学习”(reinforcement learning)。</p>
<p>图1 6.1 强化学习图示</p>
<p>图16.l 给出了强化学习的一个简单图示。强化学习任务通常用马尔可夫决策过程(Markov Decision Process，简称MDP)来描述：机器处于环境E 中，状态空间为X，其中每个状态x∈X 是机器感知到的环境的描述，如在种瓜任务上这就是当前瓜苗长势的描述；机器能采取的动作构成了动作空间A，如种瓜过程中有混水、施不同的肥、使用不同的农药等多种可供选择的动作，若某个动作aEA 作用在当前状态z 上，则潜在的转移函数P 将使得环境从当前状态按某种概率转移到另一个状态，如瓜苗状态为缺水，若选择动作浇水，则瓜苗长势会发生变化，瓜苗有一定的概率恢复健康，也有一定的概率无法恢复i 在转移到另一个状态的同时，环境会根据潜在的“奖赏”(reward)函数R 反馈给机器一个奖赏，如保持瓜苗健康对应奖赏+1，瓜商调零对应奖赏-10，最终种出了好瓜对应奖赏+100.综合起来，强化学习任务对应了四元组））,其中））指定了状态转移概率，指定了奖赏；在有的应用中，奖赏函数可能仅与状态转移有关，即））。</p>
<p>图16.2给出了一个简单例子。给西瓜浇水的马尔可夫决策过程。该任务中只有四个状态(健康、缺水、溢水、凋亡)和两个动作(浇水、不浇水)，在每一步转移后，若状态是保持瓜苗健康则获得奖赏1，瓜苗缺水或溢水奖赏为-1，这时通过浇水或不浇水可以恢复健康状态当瓜苗凋亡时奖赏是最小值-100 且无法恢复。图中箭头表示状态转移，箭头旁的a，p,r 分别表示导致状态转移的动作、转移概率以及返回的奖赏。容易看出，最优策略在“健康”状态选择动作“浇水”、在“溢水”状态选择动作“不浇水”、在“缺水”状态选择动作“浇水”、在“凋亡”状态可选择任意动作。</p>
<p>图16.2给西瓜浇水问题的马尔可夫决策过程</p>
<p>需注意“机器”与“环境”的界限，例如在种西瓜任务中，环境是西瓜生长的自然世界，在下棋对弈中，环境是棋盘与对手； 在机器人控制中，环境是机器人的躯体与物理世界。总之，在环境中状态的转移、奖赏的返回是不受机器控制的，机器只能通过选择要执行的动作来影响环境也只能通过观察转移后的状态和返回的奖赏来感知环境。</p>
<p>机器要做的是通过在环境中不断地尝试而学得一个“策略”(policy)𝛑，根据这个策略，在状态x 下就能得知要执行的动作）），例如看到瓜苗状态是缺水时，能返回动作“浇水”。策略有两种表示方法：一种是将策略表示为函数）），确定性策略常用这种表示，另一种是概率表示））,随机性策略常用这种表示，））为状态x 下选择动作a 的概率，这里必须有））。</p>
<p>策略的优劣取决于长期执行这一策略后得到的累积奖赏，例如某个策略使得瓜苗枯死，它的累积奖赏会很小，另一个策略种出了好瓜，它的累积奖赏会很大，在强化学习任务中，学习的目的就是要找到能使长期累积奖赏最大化的策略长期累积奖赏有多种计算方式，常用的有“ T 步累积奖赏” ））和“ γ 折扣累积奖赏”））其中Tt 表示第t 步获得的奖赏值，E 表示对所有随机变量求期望。</p>
<p>读者也许已经感觉到强化学习与监督学习的差别。若将这里的“状态”对应为监督学习中的“示例”、“动作”对应为“标记”，则可看出，强化学习中的“策略”实际上就相当于监督学习中的“分类器”(当动作是离散的)或“回归器”(当动作是连续的)，模型的形式并无差别。但不同的是，在强化学习中并没有监督学习中的有标记样本(即“示例-标记”对)，换言之，没有人直接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过“反思”之前的动作是否正确来进行学习。因此，强化学习在某种意义上可看作具有“延迟标记信息”的监督学习问题。</p>
<h2 id="-75"><a href="#-75" class="headerlink" title></a><br></h2><h2 id="K-摇臂赌博机"><a href="#K-摇臂赌博机" class="headerlink" title="K-摇臂赌博机"></a>K-摇臂赌博机</h2><h3 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h3><p>与一般监督学习不同，强化学习任务的最终奖赏是在多步动作之后才能观察到，这里我们不妨先考虑比较简单的情形：最大化单步奖赏，即仅考虑一步操作。需注意的是，即便在这样的简化情形下，强化学习仍与监督学习有显著不同，因为机器需通过尝试来发现各个动作产生的结果，而没有训练数据告诉机器应当做哪个动作。</p>
<p>欲最大化单步奖赏需考虑两个方面：一是需知道每个动作带来的奖赏，二是要执行奖赏最大的动作。若每个动作对应的奖赏是一个确定值，那么尝试一遍所有的动作便能找出奖赏最大的动作。然而，更一般的情形是，一个动作的奖赏值是来自于一个概率分布，仅通过一次尝试并不能确切地获得平均奖赏值。</p>
<p>实际上，单步强化学习任务对应了一个理论模型，即“K-摇臂赌博机” (K-armed bandit).如图16.3 所示，K-摇臂赌博机有K个摇臂，赌徒在投入一个硬币后可选择按下其中一个摇臂，每个摇臂以一定的概率吐出硬币，但这个概率赌徒并不知道赌徒的目标是通过一定的策略最大化自已的奖赏，即获得最多的硬币。</p>
<p>若仅为获知每个摇臂的期望奖赏，则可采用“仅探索”(explorationonly)法：将所有的尝试机会平均分配给每个摇臂(即轮流按下每个摇臂)，最后以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计若仅为执行奖赏最大的动作，则可采用“仅利用”(exploitation-only)法：按下目前最优的(即到目前为止平均奖赏最大的摇臂，若有多个摇臂同为最优，则从中随机选取一个显然，“仅探索”法能很好地估计每个摇臂的奖赏，却会失去很多选择最优摇臂的机会；“仅利用”法则相反，它没有很好地估计摇臂期望奖赏，很可能经常选不到最优摇臂。因此，这两种方法都难以便最终的累积奖赏最大化。</p>
<p>事实上，“探索”(即估计摇臂的优劣和“利用”(即选择当前最优摇臂这两者是矛盾的，因为尝试次数(即总投币数有限)，加强了一方则会自然削弱另－方，这就是强化学习所面临的“探索玛利用窘境”(Exploration-Exploitationdilemma).显然，欲累积奖赏最大，则必须在探索与利用之间达成较好的折中。</p>
<h3 id="epsilon-贪心"><a href="#epsilon-贪心" class="headerlink" title="$\epsilon $-贪心"></a>$\epsilon $-贪心</h3><p>E-贪心法基于一个概率来对探索和利用进行折中:每次尝试时，以E 的概率进行探索，即以均匀概率随机选取一个摇臂；以1-E 的概率进行利用，即选择当前平均奖赏最高的摇臂(若有多个，则随机选取一个)。</p>
<p>令Q(k)记录摇臂k 的平均奖赏若摇臂k 被尝试了n 次，得到的奖赏为）），则平均奖赏为<br>））</p>
<p>若直接根据式(16.1)计算平均奖赏，则需记录η个奖赏值。显然，更高效的做法是对均值进行增量式计算，即每尝试一次就立即更新Q(k).不妨用下标来表示尝试的次数，初始时））.对于任意的n）），若第n-1 次尝试后的平均奖赏为）），则在经过第η 次尝试获得奖赏Vn 后，平均奖赏应更新为</p>
<p>这样，无论摇臂被尝试多少次都仅需记录两个值。已尝试次数n-1和最近平均奖赏））.E-贪心算法描述如图16.4 所示。</p>
<p>若摇臂奖赏的不确定性较大，例如概率分布较宽时，则需更多的探索，此时需要较大的E 值；若摇臂的不确定性较小，例如概率分布较集中时，则少量的尝试就能很好地近似真实奖赏此时需要的E 较小，通常令E取一个较小的常数7如0.1或0.01然而，若尝试次数非常大，那么在一段时间后，摇臂的奖赏都能很好地近似出来，不再需要探索，这种情形下可让E 随着尝试次数的增加而逐渐减小，例如令））。</p>
<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>Softmax算法基于当前已知的摇臂平均奖赏来对探索和利用进行折中。若各摇臂的平均奖赏相当则选取各摇臂的概率也相当； 若某些摇臂的平均奖赏明显高于其他摇臂，则它们被选取的概率也明显更高。</p>
<p>Softmax 算法中摇臂概率的分配是基于Boltzmann 分布</p>
<p>其中，Q(i)记录当前摇臂的平均奖赏，T＞0 称为“温度”，T越小则平均奖赏高的摇臂被选取的概率越高.T 趋于0 时Softmax 将趋于“仅利用”，T 趋于无穷大时Softmax 则将趋于“仅探索”.Softmax 算法描述如图16.5 所示。</p>
<p>E-贪心算法与Softmax算法孰优孰劣主要取决于具体应用。为了更直观地观察它们的差别，考虑一个简单的例子：假定2-摇臂赌博机的摇臂1 以0.4的概率返回奖赏1，以0.6 的概率返回奖赏0 ；摇臂2 以0.2 的概率返回奖赏1,以0.8 的概率返回奖赏0.图16.6 显示了不同算法在不同参数下的平均累积奖赏，其中每条曲线对应于重复1000 次实验的平均结果。可以看出，Softmax(T=0.01)的曲线与“仅利用”的曲线几乎重合。</p>
<p>对于离散状态空间、离散动作空间上的多步强化学习任务，一种直接的办法是将每个状态上动作的选择看作一个K-摇臂赌博机问题，用强化学习任务的累积奖赏来代替K-摇臂赌博机算法中的奖赏函数，即可将赌博机算法用于每个状态：对每个状态分别记录各动作的尝试次数、当前平均累积奖赏等信息，基于赌博机算法选择要尝试的动作。然而这样的做法有很多局限，因为它没有考虑强化学习任务马尔可夫决策过程的结构。在16.3 节将会看到，若能有效考虑马尔可夫决策过程的特性，则可有更聪明的办法。</p>
<h2 id="-76"><a href="#-76" class="headerlink" title></a><br></h2><h2 id="有模型学习"><a href="#有模型学习" class="headerlink" title="有模型学习"></a>有模型学习</h2><p>考虑多步强化学习任务，暂且先假定任务对应的马尔可夫决策过程四元组E=(X,A,P,R) 均为已知，这样的情形称为“模型已知”即机器已对环境进行了建模1 能在机器内部模拟出与环境相同或近似的状况。在已知模型的环境中学习称为“有模型学习”(model-based learning).此时，对于任意状态x, x’和动作a，在x 状态下执行动作a 转移到x＇ 状态的概率）），是已知的，该转移所带来的奖赏）），也是已知的。为便于讨论，不妨假设状态空间X 和动作空间A 均为有限。</p>
<h3 id="策略评估"><a href="#策略评估" class="headerlink" title="策略评估"></a>策略评估</h3><p>在模型已知时，对任意策略Π能估计出该策略带来的期望累积奖赏。令函数））表示从状态x 出发，使用策略Π所带来的累积奖赏；函数））表示从状态x 出发，执行动作a 后再使用策略何带来的累积奖赏这里的）） 称为“状态值函数”(state value function),称为“状态－动作值函数”(state-action value function)，分别表示指定“状态”上以及指定“状态－动作”上的累积奖赏。</p>
<p>由累积奖赏的定义，有状态值函数</p>
<p>为叙述简洁，后面在涉及上述两种累积奖赏时，就不再说明奖赏类别，读者从上下文应能容易地判知令x0 表示起始状态，a0表示起始状态上采取的第一个动作；对于T 步累积奖赏，用下标t 表示后续执行的步数我们有状态－动作值函数。</p>
<p>由于MDP 具有马尔可夫性质即系统下一时刻的状态仅由当前时刻的状态决定，不依赖于以往任何状态，于是值函数有很简单的递归形式对于T 步累积奖赏有</p>
<p>类似的，对于γ 折扣累积奖赏有</p>
<p>需注意的是，正是由于P 和R 已知，才可以进行全概率展开。</p>
<p>图16.7 基于T 步累积奖赏的策略评估算法</p>
<p>读者可能已发现，用上面的递归等式来计算值函数，实际上就是一种动态规划算法。对于）），可设想递归一直进行下去，直到最初的起点；换言之，从值函数的初始值可了出发，通过一次迭代能计算出每个状态的单步奖赏）），进而从单步奖赏出发，通过一次迭代计算出两步累积奖赏）），……图16.7 中算法遵循了上述流程，对于T 步累积奖赏，只需迭代T 轮就能精确地求出值函数。</p>
<p>对于）），由于乎在t 很大时趋于0，因此也能使用类似的算法，只需将图16.7 算法的第3 行根据式(16.8)进行替换此外，由于算法可能会迭代很多次3因此需设置一个停止准则。常见的是设置一个阈值θ，若在执行一次迭代后值函数的改变小于0 则算法停止；相应的，图16.7 算法第4 行中的t=T+1 需替换为</p>
<p>有了状态值函数V，就能直接计算出状态-动作值函数</p>
<h3 id="策略改进"><a href="#策略改进" class="headerlink" title="策略改进"></a>策略改进</h3><p>对某个策略的累积奖赏进行评估后，若发现它并非最优策略，则当然希望对其进行改进。理想的策略应能最大化累积奖赏</p>
<p>一个强化学习任务可能有多个最优策略，最优策略所对应的值函数V＊ 称为最优值函数，即</p>
<p>注意，当策略空间无约束时式(16.12)的V＊ 才是最优策略对应的值函数，例如对离散状态空间和离散动作空间，策略空间是所有状态上所有动作的组合，共有））种不同的策略。若策略空间有约束，则违背约束的策略是“不合法”的，即便其值函数所取得的累积奖赏值最大，也不能作为最优值函数。</p>
<p>由于最优值函数的累积奖赏值已达最大，因此可对前面的Bellman 等式(16.7)和(16.8)做一个改动，即将对动作的求和改为取最优。</p>
<p>代入式(16.10)可得最优状态－动作值函数</p>
<p>上述关于最优值函数的等式，称为最优Bellman 等式，其唯－解是最优值函数</p>
<p>最优Bellman 等式揭示了非最优策略的改进方式：将策略选择的动作改变为当前最优的动作显然这样的改变能使策略更好。不妨令动作改变后对应的策略为扩，改变动作的条件为）），以γ 折扣累积奖赏为例，由式(16.10)可计算出递推不等式</p>
<p>值函数对于策略的每一点改进都是单调递增的，因此对于当前策略π，可放心地将其改进为</p>
<p>直到𝛑’与𝛑一致、不再发生变化，此时就满足了最优Bellman 等式，即找到了最优策略。</p>
<h3 id="策略迭代与值迭代"><a href="#策略迭代与值迭代" class="headerlink" title="策略迭代与值迭代"></a>策略迭代与值迭代</h3><p>由前两小节我们知道了如何评估一个策略的值函数，以及在策略评估后如何改进至获得最优策略显然，将这两者结合起来即可得到求解最优解的方法：从一个初始策略(通常是随机策略出发，先进行策略评估，然后改进策略，评估改进的策略，再进一步改进策略，……不断迭代进行策略评估和改进，直到策略收敛、不再改变为止。这样的做法称为“策略迭代”(policy iteration)。</p>
<p>图16.8 给出的算法描述，就是在基于T 步累积奖赏策略评估的基础上，加入策略改进而形成的策略迭代算法。类似的，可得到基于γ 折扣累积奖赏的策略迭代算法策略迭代算法在每次改进策略后都需重新进行策略评估，这通常比较耗时。</p>
<p>由式(16.16)可知，策略改进与值函数的改进是一致的，因此可将策略改进视为值函数的改善，即由式(16.13)可得</p>
<p>于是可得到值迭代(value iteration)算法，如图16.9 所示。</p>
<p>图16.9 基于T 步累积奖赏的值迭代算法</p>
<p>若采用γ 折扣累积奖赏，只需将图16.9 算法中第3 行替换为<br>））</p>
<p>从上面的算法可看出，在模型已知时强化学习任务能归结为基于动态规划的寻优问题。与监督学习不同，这里并未涉及到泛化能力，而是为每一个状态找到最好的动作。</p>
<h2 id="-77"><a href="#-77" class="headerlink" title></a><br></h2><h2 id="免模型学习"><a href="#免模型学习" class="headerlink" title="免模型学习"></a>免模型学习</h2><p>在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚至很难知道环境中一共有多少状态。若学习算法不依赖于环境建模，则称为“免模型学习”(model-free learning)，这比有模型学习要困难得多。</p>
<h3 id="蒙特卡罗强化学习"><a href="#蒙特卡罗强化学习" class="headerlink" title="蒙特卡罗强化学习"></a>蒙特卡罗强化学习</h3><p>在免模型情形下，策略迭代算法首先遇到的问题是策略无法评估，这是由于模型未知而导致无法做全概率展开。此时，只能通过在环境中执行选择的动作，来观察转移的状态和得到的奖赏，受K 摇臂赌博机的启发，一种直接的策略评估替代方法是多次“采样”，然后求取平均累积奖赏来作为期望累积奖赏的近似，这称为蒙特卡罗强化学习由于采样必须为有限次数，因此该方法更适合于使用T 步累积奖赏的强化学习任务。</p>
<p>另一方面，策略迭代算法估计的是状态值函数V，而最终的策略是通过状态－动作值函数Q 来获得。当模型已知时，从V 到Q 有很简单的转换方法，而当模型未知时，这也会出现困难。于是，我们将估计对象从V 转变为Q，即估计每一对“状态-动作”的值函数</p>
<p>此外，在模型未知的情形下，机器只能是从一个起始状态(或起始状态集合)开始探索环境，而策略迭代算法由于需对每个状态分别进行估计，因此在这种情形下无法实现。例如探索种瓜的过程只能从播下种子开始，而不能任意选择种植过程中的一个状态开始。因此，我们只能在探索的过程中逐渐发现各个状态并估计各状态－动作对的值函数。</p>
<p>综合起来，在模型未知的情形下，我们从起始状态出发，使用某种策略进行采样，执行该策略T 步并获得轨迹<br>））</p>
<p>然后，对轨迹中出现的每一对状态－动作，记录其后的奖赏之和，作为该状态－动作对的一次累积奖赏采样值。多次采样得到多条轨迹后，将每个状态－动作对的累积奖赏采样值进行平均，即得到状态－动作值函数的估计。</p>
<p>可以看出，欲较好地获得值函数的估计，就需要多条不同的采样轨迹。然而，我们的策略有可能是确定性的，即对于某个状态只会输出一个动作，若使用这样的策略进行采样，则只能得到多条相同的轨迹这与K 摇臂赌博机的“仅利用”法面临相同的问题，因此可借鉴探索与利用折中的办法，例如使用←贪心法，以E 的概率从所有动作中均匀随机选取一个，以1-E的概率选取当前最优动作。我们将确定性的策略𝛑称为“原始策略”，在原始策略上使用E-贪心法的策略记为<br>））</p>
<p>对于最大化值函数的原始策略）），其））贪心策略扩中，当前最优动作被选中的概率是）），而每个非最优动作被选中的概率是由于是，每个动作都有可能被选取，而多次采样将会产生不同的采样轨迹。</p>
<p>与策略迭代算法类似，使用蒙特卡罗方法进行策略评估后，同样要对策略进行改进前面在讨论策略改进时利用了式(16.16)揭示的单调性，通过换入当前最优动作来改进策略。对于任意原始策略𝛑，其E-贪心策略扩仅是将E 的概率均匀分配给所有动作，因此对于最大化值函数的原始策略𝛑’，同样有）），于是式(16.16)仍成立，即可以使用同样方法来进行策略改进。</p>
<p>图16.10给出了上述过程的算法描述，这里被评估与被改进的是同一个策略，因此称为“同策略”(on-policy) 蒙特卡罗强化学习算法。算法中奖赏均值采用增量式计算，每采样出一条轨迹，就根据该轨迹涉及的所有“状态-动作”对来对值函数进行更新。</p>
<p>图16.10 同策略蒙特卡罗强化学习算法</p>
<p>同策略蒙特卡罗强化学习算法最终产生的是E-贪心策略。然而，引入E-贪心是为了便于策略评估，而不是为了最终使用；实际上我们希望改进的是原始(非E-贪心)策略那么，能否仅在策略评估时引入E-贪心，而在策略改进时却改进原始策略呢，</p>
<p>这其实是可行的。不妨用两个不同的策略𝛑和𝛑’来产生采样轨迹，两者的区别在于每个“状态-动作对”被采样的概率不同一般的，函数f 在概率分布p 下的期望可表达为<br>））</p>
<p>可通过从概率分布p 上的采样））来估计f 的期望，即<br>））</p>
<p>若引入另一个分布q，则函数f 在概率分布p 下的期望也可等价地写为<br>））</p>
<p>上式可看作）） 在分布q 下的期望，因此通过在q 上的采样））可估计为</p>
<p>回到我们的问题上来，使用策略𝛑的采样轨迹来评估策略𝛑，实际上就是对累积奖赏估计期望<br>））</p>
<p>其中Ri表示第i 条轨迹上自状态x 至结束的累积奖赏。若改用策略𝛑’的采样轨迹来评估策略𝛑，则仅需对累积奖赏加权，即<br>））</p>
<p>其中））和））分别表示两个策略产生第i 条轨迹的概率。对于给定的一条轨迹）），策略𝛑产生该轨迹的概率为</p>
<p>虽然这里用到了环境的转移概率）），但式(16.24)中实际只需两个策略概率的比值</p>
<p>若𝛑作为确定性策略而扩是作的E-贪心策略，则））对于））始终为））为））或））于是就能对策略作进行评估了图16.11 给出了“异策略”(off-policy)蒙特卡罗强化学习算法的描述</p>
<p>图16.11 异策略蒙特卡罗强化学习算法</p>
<h3 id="时序差分学习"><a href="#时序差分学习" class="headerlink" title="时序差分学习"></a>时序差分学习</h3><p>蒙特卡罗强化学习算法通过考虑采样轨迹，克服了模型未知给策略估计造成的困难，此类算法需在完成一个采样轨迹后再更新策略的值估计，而前面介绍的基于动态规划的策略迭代和值迭代算法在每执行一步策略后就进行值函数更新。两者相比，蒙特卡罗强化学习算法的效率低得多，这里的主要问题是蒙特卡罗强化学习算法没有充分利用强化学习任务的MDP 结构。时序差分(Temporal Difference)，简称TD学习则结合了动态规划与蒙特卡罗方法的思想，能做到更高效的免模型学习。</p>
<p>蒙特卡罗强化学习算法的本质，是通过多次尝试后求平均来作为期望累积奖赏的近似，但它在求平均时是“批处理式”进行的，即在一个完整的采样轨迹完成后再对所有的状态，动作对进行更新实际上这个更新过程能增量式进行对于状态-动作对(x,a)，不妨假定基于t个采样已估计出值函数）），则在得到第t+l个采样rt+l 时，类似式(16.3)，有<br>））</p>
<p>显然，只需给））加上增量击））即可，更一般的，将））替换为系数）），则可将增量项写作））。在实践中通常令at为一个较小的正数值a，若将））展开为每步累积奖赏之和，则可看出系数之和为1，即令at=a不会影响Qt是累积奖赏之和这一性质。更新步长a越大，则越靠后的累积奖赏越重要。</p>
<p>以γ折扣累积奖赏为例，利用动态规划方法且考虑到模型未知时使用状态－动作值函数更方便，由式(16.10)有</p>
<p>通过增量求和可得<br>））</p>
<p>其中x＇是前一次在状态x 执行动作a 后转移到的状态，a＇是策略霄在x＇上选择的动作。</p>
<p>使用式(16.31)，每执行一步策略就更新一次值函数估计，于是得到图16.12的算法。该算法由于每次更新值函数需知道前一步的状态(state)、前一步的动作(action)、奖赏值(reward) 、当前状态(state)、将要执行的动作(actio)时，由此得名为Sarsa 算法［Rummery and Niranjan, 1994］.显然： Sarsa 是一个同策略算法，算法中评估(第6 行)、执行(第5 行)的均为E-贪心策略。</p>
<p>将Sarsa 修改为异策略算法，则得到图16.13 描述的Q-学习(Q-learning) 算法［Watkins and Dayan, 1992］，该算法评估(第6 行)的是原始策略，而执行(第4 行)的是E-贪心策略。</p>
<h2 id="-78"><a href="#-78" class="headerlink" title></a><br></h2><h2 id="值函数近似"><a href="#值函数近似" class="headerlink" title="值函数近似"></a>值函数近似</h2><p>前面我们一直假定强化学习任务是在有限状态空间上进行，每个状态可用一个编号来指代；值函数则是关于有限状态的“表格值函数”(tabular valuef unction)，即值函数能表示为一个数组，输入i 对应的函数值就是数组元素i 的值，且更改一个状态上的值不会影响其他状态上的值然而，现实强化学习任务所面临的状态空间往往是连续的，有无穷多个状态，这该怎么办呢，</p>
<p>一个直接的想法是对状态空间进行离散化，将连续状态空间转化为有限离散状态空间，然后就能使用前面介绍的方法求解遗憾的是，如何有效地对状态空间进行离散化是一个难题，尤其是在对状态空间进行探索之前。</p>
<p>实际上，我们不妨直接对连续状态空间的值函数进行学习假定状态空间为n维实数空间X=IR飞此时显然无法用表格值函数来记录状态值先考虑简单情形，即值函数能表达为状态的线性函数［Busoniu et al., 2010］<br>））</p>
<p>其中x为状态向量，θ为参数向量由于此时的值函数难以像有限状态那样精确记录每个状态的值，因此这样值函数的求解被称为值函数近似(valuefunction approximation)。</p>
<p>我们希望通过式(16.32)学得的值函数尽可能近似真实值函数）），近似程度常用最小二乘误差来度量：<br>））</p>
<p>其中Ex～𝛑作表示由策略𝛑所采样而得的状态上的期望。</p>
<p>为了使误差最小化，采用梯度下降法，对误差求负导数<br>））</p>
<p>于是可得到对于单个样本的更新规则<br>））</p>
<p>我们并不知道策略的真实值函数V𝛑，但可借助时序差分学习，基于）） 用当前估计的值函数代替真实值函数，即</p>
<p>其中x＇是下一时刻的状态。</p>
<p>需注意的是，在时序差分学习中需要状态－动作值函数以便获取策略。这里一种简单的做法是令θ 作用于表示状态和动作的联合向量上，例如给状态向量增加一维用于存放动作编号，即将式(16.32)中的z 替换为(x;a)； 另一种做法是用0/1 对动作选择进行编码得到向量）），其中“1”表示该动作被选择，再将状态向量与其合并得到(x;a)，用于替换式(16.32)中的x 这样就使得线性近似的对象为状态－动作值函数。</p>
<p>基于线性值函数近似来替代Sarsa 算法中的值函数，即可得到图16.14 的线性值函数近似Sarsa 算法类似地可得到线性值函数近似Q-学习算法。显然3可以容易地用其他学习方法来代替式(16.32)中的线性学习器，例如通过引入核方法实现非线性值函数近似。</p>
<h2 id="-79"><a href="#-79" class="headerlink" title></a><br></h2><h2 id="模仿学习"><a href="#模仿学习" class="headerlink" title="模仿学习"></a>模仿学习</h2><p>在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后的累积奖赏，但在现实任务中，往往能得到人类专家的决策过程范例，例如在种瓜任务上能得到农业专家的种植过程范例。从这样的范例中学习，称为“模仿学习”(imitation learning)。</p>
<h3 id="直接模仿学习"><a href="#直接模仿学习" class="headerlink" title="直接模仿学习"></a>直接模仿学习</h3><p>强化学习任务中多步决策的搜索空间巨大，基于累积奖赏来学习很多步之前的合适决策非常困难，而直接模仿人类专家的“状态－动作对”可显著缓解这一困难，我们称其为“直接模仿学习”。</p>
<p>假定我们获得了一批人类专家的决策轨迹数据{T1, T2，…，Tm}，每条轨迹包含状态和动作序列<br>））</p>
<p>其中n为第i条轨迹中的转移次数。</p>
<p>有了这样的数据，就相当于告诉机器在什么状态下应选择什么动作，于是可利用监督学习来学得符合人类专家决策轨迹数据的策略。</p>
<p>我们可将所有轨迹上的所有“状态-动作对”抽取出来，构造出一个新的数据集合<br>））</p>
<p>即把状态作为特征，动作作为标记；然后，对这个新构造出的数据集合D 使用分类(对于离散动作)或回归(对于连续动作)算法即可学得策略模型。学得的这个策略模型可作为机器进行强化学习的初始策略，再通过强化学习方法基于环境反馈进行改进，从而获得更好的策略。</p>
<h3 id="逆强化学习"><a href="#逆强化学习" class="headerlink" title="逆强化学习"></a>逆强化学习</h3><p>在很多任务中，设计奖赏函数往往相当困难，从人类专家提供的范例数据中反推出奖赏函数有助于解决该问题，这就是逆强化学习(invers e reinforcementlearning) ［Abbeel and Ng, 2004］。</p>
<p>在逆强化学习中，我们知道状态空间X 、动作空间A，并且与直接模仿学习类似，有一个决策轨迹数据集））逆强化学习的基本思想是：欲使机器做出与范例一致的行为，等价于在某个奖赏函数的环境中求解最优策略，该最优策略所产生的轨迹与范例数据一致。换言之，我们要寻找某种奖赏函数使得范例数据是最优的，然后即可使用这个奖赏函数来训练强化学习策略。</p>
<p>不妨假设奖赏函数能表达为状态特征的线性函数，即））.于是，策略𝛑的累积奖赏可写为</p>
<p>即状态向量加权和的期望与系数w 的内积。</p>
<p>将状态向量的期望））简写为））注意到获得））需求取期望。我们可使用蒙特卡罗方法通过采样来近似期望，而范例轨迹数据集恰可看作最优策略的一个采样，于是，可将每条范例轨迹上的状态加权求和再平均，记为））对于最优奖赏函数））和任意其他策略产生的））有<br>））</p>
<p>若能对所有策略计算出））即可解出<br>））</p>
<p>显然，我们难以获得所有策略，一个较好的办法是从随机策略开始，迭代地求解更好的奖赏函数，基于奖赏函数获得更好的策略，直至最终获得最符合范例轨迹数据集的奖赏函数和策略。如图16.15 算法所示注意在求解更好的奖赏函数时，需将式(16.39)中对所有策略求最小改为对之前学得的策略求最小。</p>
<h2 id="阅读材料-15"><a href="#阅读材料-15" class="headerlink" title="阅读材料"></a>阅读材料</h2><p>强化学习专门书籍中最著名的是［Sutton and Barto, 1998］.［Gosavi, 2003］从优化的角度来讨论强化学习，［Whiteson, 2010］则侧重于介绍基于演化算法搜索的强化学习方法。［Mausam and Kolobov, 2012］从马尔可夫决策过程的视角介绍强化学习，［Sigaud and Buffet, 2010］覆盖了很多内容，包括本章未介绍的部分可观察马尔可夫决策过程(Partially Observable MDP，简称POMDP).。策略梯度法等。基于值函数近似的强化学习可参阅［Busoniu et al., 2010］。</p>
<p>欧洲强化学习研讨会(EWRL)是专门性的强化学习系列研讨会，多学科强化学习与决策会议(RLDM)则是从2013年开始的新会议。</p>
<p>［Kaelbling et al., 1996］是一个较早的强化学习综述，［Kober et al., 2013;Deisenroth et al., 2013］则综述了强化学习在机器人领域的应用。</p>
<p>［Vermorel and Mohri, 2005］介绍了多种K-摇臂赌博机算法并进行了比较。多摇臂赌博机模型在统计学领域有大量研究［Berry and Fristedt, 1985］，近年来在“在线学习”(online learning)、“对抗学习”(adversarial learning)等方面有广泛应用，［Bubeck and Cesa-Bianchi, 2012］对其“悔界”(regret bound)分析方面的结果进行了综述。</p>
<p>时序差分(TD)学习最早是A Samuel 在他著名的跳棋工作中提出，［Sutton, 1988］提出了TD(λ)算法，由于［Tesauro, 1995］ 基于TD(λ)研制的TD-Gammon 程序在西洋双陆棋上达到人类世界冠军水平而使TD 学习备受关注.Q-学习算法是［Watkins and Dayan, 1992］提出，Sarsa 则是在Q-学习算法基础上的改进［Rummery and Niranjan, 1994］.TD 学习近年来仍有改进和推广，例如广义TD 学习［Ueno et al., 2011］、使用资格迹(eligibi lity traces)的TD 学习［Geist and Scherrer, 2014］等.［Dann et al., 2014］对TD 学习中的策略评估方法进行了比较。</p>
<p>模仿学习被认为是强化学习提速的重要手段［Lin, 1992; Price and Boutilier,<br>2003］，在机器人领域被广泛使用［Argall et al., 2009］.［Abbeel and Ng, 2004;<br>Langford and Zadrozny，2005］提出了逆强化学习方法。</p>
<p>在运筹学与控制论领域，强化学习方面的研究被称为“近似动态规划”(approximate dynamic programming)，可参阅［Bertsekas, 2012］。</p>
<h3 id="休息一会儿-14"><a href="#休息一会儿-14" class="headerlink" title="休息一会儿"></a>休息一会儿</h3><p>小故事：马尔可夫决策过程与安德烈·马尔可夫</p>
<p>安德烈· 安德烈维奇· 马尔可夫(Andrey AndreyevichMarkov, 1856 -1922)是著名俄罗斯数学家、圣彼得堡数学学派代表性人物，在概率论、数论、函数逼近论、微分方程等方面有重要贡献。</p>
<p>马尔可夫出生在莫斯科东南的粱赞(Ryazan), 17 岁时独立发现了一种线性常微分方程的解法，引起了圣彼得堡大学几位数学家的注意.1874年他考入圣彼得堡大学数学系，1878年毕业并留校任教，1884年获博士学位，导师是圣彼得堡学派领袖、著名数学家切比雪夫。此后马尔可夫一直在圣彼得堡大学任教。马尔可夫在早期主要是沿着切比雪夫开创的方向，改进和完善了大数定律和中心极限定理但他最重要的工作无疑是开辟了随机过程这个领域他在1906-1912年间提出了马尔可夫链，开创了对马尔可夫过程的研究现实世界里小到分子的布朗运动、大到传染病流行过程，马尔可夫过程几乎无所不在。在他的名著《概率演算》中，马尔可夫是以普希金的长诗《叶甫根尼·奥涅金》中元、辅音字母变化的规律为例来展示马尔可夫链的性质。马尔可夫决策过程是马尔可夫过程与确定性动态规划的结合，基本思想在二十世纪五十年代出现，此时马尔可夫已去世三十多年了。</p>
<p>马尔可夫的儿子也叫安德烈· 安德烈维奇· 马尔可夫(1903-1979)，也是著名数学家，数理逻辑中的“马尔可夫原则”(Markov Principle)、“马尔可夫规则”(Markov Rule)，理论计算机科学中图灵完备的“马尔可夫算法”等，是以小马尔可夫的名字命名的。马尔可夫的弟弟弗拉基米尔。安德烈维奇·马尔可夫(1871-1897)也是一位数学家，“马尔可夫兄弟不等式”就是以他和哥哥安德烈的名字命名的。</p>
<p><br></p>
<hr>
<hr>
<hr>
<p><br></p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="A-矩阵"><a href="#A-矩阵" class="headerlink" title="A 矩阵"></a>A 矩阵</h2><p>A.1 基本演算<br>记实矩阵）） 第z 行第j 列的元素为））· 矩阵A 的转<br>置(transpose)记为AT,））,显然，<br>））</p>
<p>对于矩阵）），若m=n 则称为n 阶方阵。用In 表示n 阶单位阵，方阵<br>A 的逆矩阵A-1 满足AA⁻¹=A⁻¹=A=I.不难发现，<br>））</p>
<p>对于n 阶方阵A，它的迹(trace)是主对角线上的元素之和，即））·迹有如下性质：<br>））</p>
<p>n 阶方阵A 的行列式(determinant)定义为<br>））</p>
<p>其中Sn 为所有n 阶排列(permutation)的集合，par(σ)的值为-1 或+1 取决于σ）） 为奇排列或偶排列，即其中出现降序的次数为奇数或偶数，例如(1,3,2)中降序次数为1,(3,1,2)中降序次数为2.对于单位阵，有））对于2 阶方阵，有</p>
<p>矩阵）） 的Frobenius 范数定义为</p>
<p>容易看出，矩阵的Frobenius 范数就是将矩阵张成向量后的L2范数。</p>
<p>A.2 导数<br>向量a 相对于标量z 的导数(derivative)，以及x 相对于a 的导数都是向量，其第i个分量分别为</p>
<p>类似的，矩阵A 对于标量x 的导数，以及x 对于A 的导数都是矩阵，其第i 行第j 列上的元素分别为</p>
<p>对于函数f(x)，假定其对向量的元素可导，则f(x)关于x 的一阶导数是一个向量，其第i个分量为</p>
<p>f(x)关于x 的二阶导数是称为海森矩阵(Hessian matrix)的一个方阵，其第i行第j 列上的元素为<br>））</p>
<p>向量和矩阵的导数满足乘法法则 (product rule)<br>））</p>
<p>由））和式(A.23)，逆矩阵的导数可表示为<br>））</p>
<p>若求导的标量是矩阵A 的元素，则有</p>
<p>进而有</p>
<p>由式(A.15)和(A.29)有</p>
<p>链式法则(chain rule)是计算复杂导数时的重要工具简单地悦若函数f<br>是g 和h 的复合，即f(x)=g(h(x))，则有</p>
<p>例如在计算下式肘，将Ax-b 看作一个整体可简化计算:</p>
<p>A.3 奇异值分解</p>
<p>任意实矩阵））都可分解为</p>
<p>其中，））是满足））的m 阶酉矩阵(unitary matrix);是满足））的n 阶酉矩阵））是m × η 的矩阵，其中））且其他位置的元素均为0，σi为非负实数且满足σ））。</p>
<p>式(A.33)中的分解称为奇异值分解(Singular Value Decomposition)，简称SVD)，其中U 的列向量）） 称为A 的左奇异向量(left-singular vector),V 的列向量））称为A 的右奇异向量(right-singular vector)，σi 称为奇异值(singular value).矩阵A 的秩(rank)就等于非零奇异值的个数。</p>
<p>奇异值分解有广泛的用途，例如对于低秩矩阵近似(low-rank matrix approximation)<br>问题，给定一个秩为T 的矩阵A，欲求其最优k 秩近似矩阵A）），该问题可形式化为</p>
<p>奇异值分解提供了上述问题的解析解： 对矩阵A 进行奇异值分解后，将矩阵∑中的））个最小的奇异值置零获得矩阵）），即仅保留最大的k个奇异值，则</p>
<p>就是式(A.34)的最优解，其中）） 和）） 分别是式(A.33)中的前k 列组成的矩<br>阵。这个结果称为Eckart-Young-Mirsky 定理。</p>
<h2 id="B-优化"><a href="#B-优化" class="headerlink" title="B 优化"></a>B 优化</h2><p>B.l 拉格朗日乘子法</p>
<p>拉格朗日乘子法(Lagrange multipliers)是一种寻找多元函数在一组约束下的极值的方法通过引入拉格朗日乘子，可将有d个变量与k个约束条件的最优化问题转化为具有d+k个变量的无约束优化问题求解。</p>
<p>先考虑一个等式约束的优化问题假定x 为d 维向量，欲寻找x的某个取值x，使目标函数f(x)最小且同时满足））的约束。从几何角度看，该问题的目标是在由方程g(x)=0确定的d-1维曲面上寻找能使目标函数f(x)最小化的点此时不难得到如下结论：</p>
<p>• 对于约束曲面上的任意点x，该点的梯度））正交于约束曲面；</p>
<p>• 在最优点x，目标函数在该点的梯度））正交于约束曲面。</p>
<p>由此可知，在最优点）），如附图B.1 所示，梯度））和））的方向必相同或相反，即存在））使得</p>
<p>λ 称为拉格朗日乘子。定义拉格朗日函数</p>
<p>不难发现，将其对z 的偏导数）） 置零即得式(B.1)，同时，将其对λ 的偏导数））置零即得约束条件g(x)=0.于是，原约束优化问题可转化为对拉格朗日函数））的无约束优化问题。</p>
<p>现在考虑不等式约束）），如附图B.1 所示，此时最优点x或在g(x) ＜ 0 的区域中，或在边界g(x)=0 上对于g(x) ＜ 0 的情形，约束g(x) ＜ 0 不起作用，可直接通过条件））来获得最优点；这等价于将λ置零然后对））置零得到最优点g(x)=0 的情形类似于上面等式约束的分析，但需注意的是，此时））的方向必与））相反，即存在常数λ ＞ 0 使得））.整合这两种情形，必满足λg(x)=0.因此，在约束g(x)运0 下最小化f(x)，可转化为在如下约束下最小化式(B.2)的拉格朗日函数：<br>））</p>
<p>式(B.3)称为Karush-Kuhn-Tucker(简称KKT)条件。</p>
<p>上述做法可推广到多个约束。考虑具有m个等式约束和n个不等式约束，<br>且可行域））非空的优化问题<br>））</p>
<p>引入拉格朗日乘子λ））和μ）），相应的拉格朗日函数为</p>
<p>由不等式约束引入的KKT 条件(j=1, 2，… n)为</p>
<p>一个优化问题可以从两个角度来考察，即“主问题”(primal problem)和“对偶问题”(dual problem).对主问题(B.4)，基于式(B.5)，其拉格朗日“对偶函数”(dual function) ）） 定义为</p>
<p>若ξ∈D 为主问题(B.4)可行域中的点，则对任意 μ≽0 和λ 都有</p>
<p>进而有</p>
<p>若主问题(B.4)的最优值为p*，则对任意 μ≽0 和λ 都有</p>
<p>即对偶函数给出了主问题最优值的下界。显然，这个下界取决于μ 和λ 的值。于是，一个很自然的问题是·基于对偶函数能获得的最好下界是什么，这就引出了优化问题</p>
<p>式(B.11)就是主问题(B.4)的对偶问题，其中λ 和μ 称为“对偶变量”(dual variable).无论主问题(B.4)的凸性如何，对偶问题(B.11)始终是凸优化问题。</p>
<p>考虑式(B.11)的最优值d*，显然有）），这称为“弱对偶性”(weak duality)成立；若）），则称为“强对偶性”(strong duality)成立，此时由对偶问题能获得主问题的最优下界。对于一般的优化问题，强对偶性通常不成立。但是，若主问题为凸优化问题，如式(B.4)中f(x)和幻(x)均为凸函数，hi(x)为仿射函数，且其可行域中至少有一点使不等式约束严格成立，则此时强对偶性成立。值得注意的是，在强对偶性成立时，将拉格朗日函数分别对原变量和对偶变量求导，再并令导数等于零，即可得到原变量与对偶变量的数值关系。于是，对偶问题解决了，主问题也就解决了。</p>
<p>B.2 二次规划</p>
<p>二次规划(Quadratic Programming，简称QP)是一类典型的优化问题，包括凸二次优化和非凸二次优化。在此类问题中，目标函数是变量的二次函数，而约束条件是变量的线性不等式。</p>
<p>假定变量个数为d，约束条件的个数为m，则标准的二次规划问题形如<br>））</p>
<p>其中z 为d 维向量，））为实对称矩阵，为实矩阵，））和））为实向量，Ax 运b 的每一行对应一个约束。</p>
<p>若Q 为半正定矩阵，则式(B.12)目标函数是凸函数，相应的二次规划是凸二次优化问题；此时若约束条件Ax 运b 定义的可行域不为空，且目标函数在此可行域有下界，则该问题将有全局最小值若Q 为正定矩阵，则该问题有唯一的全局最小值。若Q 为非正定矩阵，则式(B.12)是有多个平稳点和局部极小点的NP 难问题</p>
<p>常用的二次规划解法有椭球法(ellipsoid method)、内点法(interiorpoint)、增广拉格朗日法(augmented Lagrangian)、梯度投影法(gradient projection)等。若Q 为正定矩阵，则相应的二次规划问题可由椭球法在多项式时间内求解。</p>
<p>B.3 半正定规划</p>
<p>半正定规划(Semi-Definite Programming，简称SDP)是一类凸优化问题，其中的变量可组织成半正定对称矩阵形式，且优化问题的目标函数和约束都是这些变量的线性函数。</p>
<p>给定d × d 的对称矩阵X、C ,</p>
<p>若））也是d × d 的对称矩阵，为m个实数，则半正定规划问题形如</p>
<p>半正定规划与线性规划都拥有线性的目标函数和约束，但半正定规划中的约束）） 是一个非线性、非光滑约束条件。在优化理论中，半正定规划具有一定的一般性，能将几种标准的优化问题(如线性规划、二次规划)统一起来。</p>
<p>常见的用于求解线性规划的内点法经过少许改造即可求解半正定规划问题，但半正定规划的计算复杂度较高，难以直接用于大规模问题。</p>
<p>B.4 梯度下降法</p>
<p>梯度下降法(gradient descent)是一种常用的一阶(first-order)优化方法，是求解无约束优化问题最简单、最经典的方法之一。</p>
<p>考虑无约束优化问题）），其中f(x)为连续可微函数。若能构造一个序列））满足<br>））</p>
<p>则不断执行该过程即可收敛到局部极小点欲满足式(B.15)，根据泰勒展式有于是，欲满足）），可选择<br>））</p>
<p>其中步长γ 是一个小常数。这就是梯度下降法。</p>
<p>若目标函数f(x)满足一些条件，则通过选取合适的步长，就能确保通过梯度下降收敛到局部极小点。例如若f(x)满足ξ-Lipschitz 条件，则将步长设置为1/(2L)即可确保收敛到局部极小点。当目标函数为凸函数时，局部极小点就对应着函数的全局最小点，此时梯度下降法可确保收敛到全局最优解。</p>
<p>当目标函数f(x)二阶连续可微时，可将式(B.16)替换为更精确的二阶泰勒展式，这样就得到了牛顿法(Newton’s method).牛顿法是典型的二阶方法，其地代轮数远小于梯度下降法。但牛顿法使用了二阶导数）），其每轮迭代中涉及到海森矩阵(A.21)的求逆，计算复杂度相当高，尤其在高维问题中儿乎不可行。若能以较低的计算代价寻找海森矩阵的近似逆矩阵，则可显著降低计算开销，这就是拟牛顿法(quasi-Newton method)。</p>
<p>B.5 坐标下降法</p>
<p>坐标下降法(coordinate descent)是一种非梯度优化方法，它在每步迭代中沿一个坐标方向进行搜索，通过循环使用不同的坐标方向来达到目标函数的局部极小值</p>
<p>不妨假设目标是求解函数f(x)的极小值，其中））是一个d 维向量。从初始点X0 开始，坐标下降法通过迭代地构造序列））, 来求解该问题，的第i个分量））构造为<br>））</p>
<p>通过执行此操作，显然有<br>））</p>
<p>与梯度下降法类似，通过迭代执行该过程，序列））.能收敛到所期望的局部极小点或驻点(stationary point)。</p>
<p>坐标下降法不需计算目标函数的梯度在每步迭代中仅需求解一维搜索问题，对于某些复杂问题计算较为简便。但若目标函数不光滑，则坐标下降法有可能陷入非驻点(non- stationary point)。</p>
<h2 id="C-概率分布"><a href="#C-概率分布" class="headerlink" title="C 概率分布"></a>C 概率分布</h2><p>C.1 常见概率分布<br>本节简要介绍几种常见概率分布对于每种分布，我们将给出概率密度函数以及期望E[·]、方差var[·]和协方差cov[·,·]等几个主要的统计量。</p>
<p>C.1.1 均匀分布</p>
<p>均匀分布(uniform distribution)是关于定义在区间[a,b] (a＜b)上连续变量的简单概率分布，其概率密度函数如附图C.1 所示。</p>
<p>附图c.1 均匀分布的概率密度函数</p>
<p>不难发现，若变量x 服从均匀分布））且）），则））服从均匀分布））。</p>
<p>C.1.2 伯努利分布</p>
<p>伯努利分布(Bernoulli distribution)是关于布尔变量z∈{0,1}的概率分布，其连续参数μ∈[0,1] 表示变量x=l 的概率。</p>
<p>C.1.3 二项分布</p>
<p>二项分布(binomial distribution)用以描述N 次独立的伯努利实验中有m次成功(即x=1)的概率，其中每次伯努利实验成功的概率为μ∈[0,1]。</p>
<p>当N=1时，二项分布退化为伯努利分布。</p>
<p>C.1.4 多项分布</p>
<p>若将伯努利分布由单变量扩展为d 维向量2，其中））且）），并假设Xi 取1 的概率为 μ∈[0,1]，）），则将得到离散概率分布</p>
<p>在此基础上扩展二项分布则得到多项分布(multinomial distribution)，它<br>描述了在N 次独立实验中有mi 次Xi=1 的概率。</p>
<p>C.1.5 贝塔分布</p>
<p>贝塔分布(Beta distribution)是关于连续变量 μ∈[0,1] 的概率分布，它由<br>两个参数a＞0 和 b＞0 确定，其概率密度函数如附图C.2 所示</p>
<p>其中r(a)为Gamma 函数</p>
<p>B(a,b) 为Beta 函数</p>
<p>当a=b=l 时，贝塔分布退化为均匀分布</p>
<p>C.1.6 狄利克雷分布</p>
<p>狄利克雷分布(Dirichlet distribution)是关于一组d个连续变量的 μ∈[0,1]的概率分布，</p>
<p>当d=2 时，狄利克雷分布退化为贝塔分布。</p>
<p>C.1.7 高斯分布</p>
<p>高斯分布(Gaussian distribution)亦称正态分布(normal distribution)，是应用最为广泛的连续概率分布。</p>
<p>对于单变量）），高斯分布的参数为均值））和方差））.附图C.3 给出了在几组不同参数下高斯分布的概率密度函数。</p>
<p>对于d 维向量2，多元高斯分布的参数为d 维均值向量μ 和d × d 的对称正定协方差矩阵∑。</p>
<p>C.2 共轭分布</p>
<p>假设变量x 服从分布））其中θ为参数，））为变量z 的观测样本，假设参数θ服从先验分布Π(θ)。若由先验分布Π(θ)和抽样分布））决定的后验分布））与Π(θ)是同种类型的分布，则称先验分布Π(θ)为分布））或））的共轭分布(conjugate distribution)。</p>
<p>例如，假设））为观测样本，））为观测样本的均值，）），其中a，b 为已知参数，则μ 的后验分布</p>
<p>亦为贝塔分布，其中）），这意味着贝塔分布与伯努利分布共轭。类似可知，多项分布的共轭分布是狄利克雷分布，而高斯分布的共轭分布仍是高斯分布。</p>
<p>先验分布反映了某种先验信息，后验分布既反映了先验分布提供的信息、又反映了样本提供的信息。当先验分布与抽样分布共轭时，后验分布与先验分布属于同种类型，这意味着先验信息与样本提供的信息具有某种同一性。于是，若使用后验分布作为进一步抽样的先验分布，则新的后验分布仍将属于同种类型因此，共轭分布在不少情形下会使问题得以简化例如在式(C.33)的例子中，对服从伯努利分布的事件X 使用贝塔先验分布，则贝塔分布的参数值a 和b 可视为对伯努利分布的真实情况(事件发生和不发生)的预估随着“证据”(样本)的不断到来，贝塔分布的参数值从a，b 变化为））,且）） 将随着m 的增大趋近于伯努利分布的真实参数值x.显然，使用共轭先验之后。只需调整a 和b 这两个预估值即可方便地进行模型更新。</p>
<p>C.3 K L散度</p>
<p>KL散度(Kullback-Leibler divergence)，亦称相对熵(relative entropy)或信息散度(information divergence)，可用于度量两个概率分布之间的差异。给定两个概率分布P 和Q，二者之间的KL散度定义为</p>
<p>其中p(x)和q(x)分别为P 和Q 的概率密度函数</p>
<p>KL散度满足非负性，即</p>
<p>当且仅当P=Q 时））.但是，KL散度不满足对称性，即</p>
<p>因此，KL散度不是一个度量(metric)。</p>
<p>若将KL散度的定义(C.34)展开，可得</p>
<p>其中H(P) 为熵(entropy), H(P,Q)为P 和Q 的交叉熵(cross entropy).在信息论中熵H(P) 表示对来自P 的随机变量进行编码所需的最小字节数，而交叉熵H(P,Q)则表示使用基于Q 的编码对来自P 的变量进行编码所需的字节数因此，KL散度可认为是使用基于Q 的编码对来自P 的变量进行编码所需的“额外”字节数，显然，额外字节数必然非负，当且仅当P=Q 时额外字节数为零。</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      <div>    
       
       
      <ul class="post-copyright">
        <li class="post-copyright-author">
            <strong>本文作者：</strong>hac_lang
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="/2016/12/25/book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01/" title="book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01">2016/12/25/book-《机器学习-周志华-人工智能入门》-西瓜书-2016-01-01/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          许可协议，请勿用于商业，转载注明出处！
        </li>
      </ul>
      
      </div>
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/计算机科学/" rel="tag"># 计算机科学</a>
          
            <a href="/tags/计算机/" rel="tag"># 计算机</a>
          
            <a href="/tags/人工智能/" rel="tag"># 人工智能</a>
          
            <a href="/tags/自评/" rel="tag"># 自评</a>
          
            <a href="/tags/books/" rel="tag"># books</a>
          
            <a href="/tags/更毕/" rel="tag"># 更毕</a>
          
            <a href="/tags/AI/" rel="tag"># AI</a>
          
            <a href="/tags/数据挖掘/" rel="tag"># 数据挖掘</a>
          
            <a href="/tags/数据分析/" rel="tag"># 数据分析</a>
          
            <a href="/tags/MachineLearning/" rel="tag"># MachineLearning</a>
          
            <a href="/tags/豆瓣8/" rel="tag"># 豆瓣8</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/12/20/book-《白话大数据与机器学习》/" rel="next" title="book_《白话大数据与机器学习》">
                <i class="fa fa-chevron-left"></i> book_《白话大数据与机器学习》
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/01/27/book-《刷脸背后：人脸检测-人脸识别-人脸检索》/" rel="prev" title="book_《刷脸背后：人脸检测 人脸识别 人脸检索》">
                book_《刷脸背后：人脸检测 人脸识别 人脸检索》 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="hac_lang">
  
  <p class="site-author-name" itemprop="name">hac_lang</p>
  <div class="site-description motion-element" itemprop="description">小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">82</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>







  <div class="links-of-author motion-element">
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/HACLANG" title="GitHub &rarr; https://github.com/HACLANG" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://stackoverflow.com/yourname" title="StackOverflow &rarr; https://stackoverflow.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://gitter.im" title="Gitter &rarr; https://gitter.im" rel="noopener" target="_blank"><i class="fa fa-fw fa-github-alt"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.jianshu.com/u/442ddccf3f32" title="简书 &rarr; https://www.jianshu.com/u/442ddccf3f32" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="Quora &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://plus.google.com/yourname" title="Google &rarr; https://plus.google.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:haclang.org@gmail.com" title="E-Mail &rarr; mailto:haclang.org@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="skype:haclang?call|chat" title="Skype &rarr; skype:haclang?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://twitter.com/haclang2" title="Twitter &rarr; https://twitter.com/haclang2" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="FaceBook &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a>
      </span>
    
  </div>








          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#主要符号表"><span class="nav-text">主要符号表</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第1章"><span class="nav-text">第1章</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#null"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#引言"><span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-1"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本术语"><span class="nav-text">基本术语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-2"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#假设空间"><span class="nav-text">假设空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-3"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归纳偏好"><span class="nav-text">归纳偏好</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-4"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#发展历程"><span class="nav-text">发展历程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-5"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#应用现状"><span class="nav-text">应用现状</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第2章-模型评估与选择"><span class="nav-text">第2章 模型评估与选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#-6"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#经验误差与过拟合"><span class="nav-text">经验误差与过拟合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-7"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估方法"><span class="nav-text">评估方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#留出法"><span class="nav-text">留出法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证法"><span class="nav-text">交叉验证法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自助法"><span class="nav-text">自助法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#调参与最终模型"><span class="nav-text">调参与最终模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-8"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#性能度量"><span class="nav-text">性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#错误率与精度"><span class="nav-text">错误率与精度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查准率、查全率与F1"><span class="nav-text">查准率、查全率与F1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROC与AUC"><span class="nav-text">ROC与AUC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代价敏感错误率与代价曲线"><span class="nav-text">代价敏感错误率与代价曲线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-9"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#比较检验"><span class="nav-text">比较检验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#假设检验"><span class="nav-text">假设检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证t检验"><span class="nav-text">交叉验证t检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#McNemar检验"><span class="nav-text">McNemar检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Friedma检验与Nemenyi后续检验"><span class="nav-text">Friedma检验与Nemenyi后续检验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-10"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#偏差与方差"><span class="nav-text">偏差与方差</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-1"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-1"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第3章-线性模型"><span class="nav-text">第3章 线性模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本形式"><span class="nav-text">基本形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-11"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归"><span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-12"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对数几率回归"><span class="nav-text">对数几率回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-13"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性判别分析"><span class="nav-text">线性判别分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-14"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多分类学习"><span class="nav-text">多分类学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-15"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类别不平衡问题"><span class="nav-text">类别不平衡问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-2"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-2"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第4章-决策树"><span class="nav-text">第4章 决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本流程"><span class="nav-text">基本流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-16"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#划分选择"><span class="nav-text">划分选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#信息增益"><span class="nav-text">信息增益</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#增益率"><span class="nav-text">增益率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基尼指数"><span class="nav-text">基尼指数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-17"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#剪枝处理"><span class="nav-text">剪枝处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预剪枝"><span class="nav-text">预剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后剪枝"><span class="nav-text">后剪枝</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-18"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#连续与缺失值"><span class="nav-text">连续与缺失值</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#连续值处理"><span class="nav-text">连续值处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺失值处理"><span class="nav-text">缺失值处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-19"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多变量决策树"><span class="nav-text">多变量决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-3"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-3"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第5章-神经网络"><span class="nav-text">第5章 神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#-20"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经元模型"><span class="nav-text">神经元模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-21"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感知机与多层网络"><span class="nav-text">感知机与多层网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-22"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#误差逆传播算法"><span class="nav-text">误差逆传播算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-23"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#全局最小与局部极小"><span class="nav-text">全局最小与局部极小</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-24"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他常见神经网络"><span class="nav-text">其他常见神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RBF网络"><span class="nav-text">RBF网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ART网络"><span class="nav-text">ART网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SOM网络"><span class="nav-text">SOM网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#级联相关网络"><span class="nav-text">级联相关网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Elman网络"><span class="nav-text">Elman网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Boltzmann机"><span class="nav-text">Boltzmann机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-25"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习"><span class="nav-text">深度学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-4"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-4"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第6章-支持向量机"><span class="nav-text">第6章 支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#间隔与支持向量"><span class="nav-text">间隔与支持向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-26"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对偶问题"><span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-27"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核函数"><span class="nav-text">核函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-28"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#软间隔与正则化"><span class="nav-text">软间隔与正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-29"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量回归"><span class="nav-text">支持向量回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-30"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核方法"><span class="nav-text">核方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-5"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-5"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第7章-贝叶斯分类器"><span class="nav-text">第7章 贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#-31"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#贝叶斯决策论"><span class="nav-text">贝叶斯决策论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-32"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#极大似然估计"><span class="nav-text">极大似然估计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-33"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯分类器"><span class="nav-text">朴素贝叶斯分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-34"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#半朴素贝叶斯分类器"><span class="nav-text">半朴素贝叶斯分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-35"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#贝叶斯网"><span class="nav-text">贝叶斯网</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#结构"><span class="nav-text">结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习"><span class="nav-text">学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#推断"><span class="nav-text">推断</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-36"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EM算法"><span class="nav-text">EM算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-6"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-6"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第8章-集成学习"><span class="nav-text">第8章 集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#个体与集成"><span class="nav-text">个体与集成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-37"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Boosting"><span class="nav-text">Boosting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-38"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bagging与随机森林"><span class="nav-text">Bagging与随机森林</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Bagging"><span class="nav-text">Bagging</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机森林"><span class="nav-text">随机森林</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-39"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结合策略"><span class="nav-text">结合策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#平均法"><span class="nav-text">平均法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#投票法"><span class="nav-text">投票法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习法"><span class="nav-text">学习法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-40"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多样性"><span class="nav-text">多样性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#误差———分歧分解"><span class="nav-text">误差———分歧分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多样性度量"><span class="nav-text">多样性度量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多样性增强"><span class="nav-text">多样性增强</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-7"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息－会儿"><span class="nav-text">休息－会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第9章-聚类"><span class="nav-text">第9章 聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类任务"><span class="nav-text">聚类任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-41"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#性能度量-1"><span class="nav-text">性能度量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-42"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#距离计算"><span class="nav-text">距离计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-43"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#原型聚类"><span class="nav-text">原型聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#k均值算法"><span class="nav-text">k均值算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习向量量化"><span class="nav-text">学习向量量化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯混合聚类"><span class="nav-text">高斯混合聚类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-44"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#密度聚类"><span class="nav-text">密度聚类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-45"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#层次聚类"><span class="nav-text">层次聚类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-8"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-7"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第10章-降维与度量学习"><span class="nav-text">第10章 降维与度量学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#k近邻学习"><span class="nav-text">k近邻学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-46"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#低维嵌入"><span class="nav-text">低维嵌入</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-47"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#主成分分析"><span class="nav-text">主成分分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-48"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核化线性降维"><span class="nav-text">核化线性降维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-49"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#流形学习"><span class="nav-text">流形学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#等度量映射"><span class="nav-text">等度量映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#局部线性嵌入"><span class="nav-text">局部线性嵌入</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-50"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#度量学习"><span class="nav-text">度量学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-9"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-8"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第11章-特征选择与稀疏学习"><span class="nav-text">第11章 特征选择与稀疏学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#子集搜索与评价"><span class="nav-text">子集搜索与评价</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-51"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#过滤式选择"><span class="nav-text">过滤式选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-52"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#包裹式选择"><span class="nav-text">包裹式选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-53"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#嵌入式选择与L1正则化"><span class="nav-text">嵌入式选择与L1正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-54"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#稀疏表示与字典学习"><span class="nav-text">稀疏表示与字典学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-55"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#压缩感知"><span class="nav-text">压缩感知</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-10"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-9"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第12章-计算学习理论"><span class="nav-text">第12章 计算学习理论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础知识"><span class="nav-text">基础知识</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-56"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PAC学习"><span class="nav-text">PAC学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-57"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#有限假设空间"><span class="nav-text">有限假设空间</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#可分情形"><span class="nav-text">可分情形</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不可分情形"><span class="nav-text">不可分情形</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-58"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VC维"><span class="nav-text">VC维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-59"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rademacher复杂度"><span class="nav-text">Rademacher复杂度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-60"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#稳定性"><span class="nav-text">稳定性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-11"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-10"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第13章-半监督学习"><span class="nav-text">第13章 半监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#未标记样本"><span class="nav-text">未标记样本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-61"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成式方法"><span class="nav-text">生成式方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-62"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#半监督SVM"><span class="nav-text">半监督SVM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-63"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图半监督学习"><span class="nav-text">图半监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-64"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于分歧的方法"><span class="nav-text">基于分歧的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-65"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#半监督聚类"><span class="nav-text">半监督聚类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-12"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-11"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第14章-概率图模型"><span class="nav-text">第14章 概率图模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#隐马尔可夫模型"><span class="nav-text">隐马尔可夫模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-66"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#马尔可夫随机场"><span class="nav-text">马尔可夫随机场</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-67"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#条件随机场"><span class="nav-text">条件随机场</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-68"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#学习与推断"><span class="nav-text">学习与推断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#变量消去"><span class="nav-text">变量消去</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信念传播"><span class="nav-text">信念传播</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-69"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#近似推断"><span class="nav-text">近似推断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MCMC采样"><span class="nav-text">MCMC采样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#变分推断"><span class="nav-text">变分推断</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-70"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#话题模型"><span class="nav-text">话题模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-13"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-12"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第15章-规则学习"><span class="nav-text">第15章 规则学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-71"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#序贯覆盖"><span class="nav-text">序贯覆盖</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-72"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#剪枝优化"><span class="nav-text">剪枝优化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-73"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一阶规则学习"><span class="nav-text">一阶规则学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-74"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归纳逻辑程序设计"><span class="nav-text">归纳逻辑程序设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#最小一般泛化"><span class="nav-text">最小一般泛化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逆归结"><span class="nav-text">逆归结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-14"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-13"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第16章-强化学习"><span class="nav-text">第16章 强化学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#任务与奖赏"><span class="nav-text">任务与奖赏</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-75"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K-摇臂赌博机"><span class="nav-text">K-摇臂赌博机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#探索与利用"><span class="nav-text">探索与利用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#epsilon-贪心"><span class="nav-text">$\epsilon $-贪心</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax"><span class="nav-text">Softmax</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-76"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#有模型学习"><span class="nav-text">有模型学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#策略评估"><span class="nav-text">策略评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#策略改进"><span class="nav-text">策略改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#策略迭代与值迭代"><span class="nav-text">策略迭代与值迭代</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-77"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#免模型学习"><span class="nav-text">免模型学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#蒙特卡罗强化学习"><span class="nav-text">蒙特卡罗强化学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#时序差分学习"><span class="nav-text">时序差分学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-78"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#值函数近似"><span class="nav-text">值函数近似</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-79"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模仿学习"><span class="nav-text">模仿学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#直接模仿学习"><span class="nav-text">直接模仿学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逆强化学习"><span class="nav-text">逆强化学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#阅读材料-15"><span class="nav-text">阅读材料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#休息一会儿-14"><span class="nav-text">休息一会儿</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#附录"><span class="nav-text">附录</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#A-矩阵"><span class="nav-text">A 矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#B-优化"><span class="nav-text">B 优化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C-概率分布"><span class="nav-text">C 概率分布</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hac_lang</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  





  
    
    
      
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="true"></script>









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  


  


  




  




  




  



<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>


  

  

  


  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false,"scale":0.5},"react":{"opacity":0.7},"log":false,"tagMode":false});</script></body>
</html>
