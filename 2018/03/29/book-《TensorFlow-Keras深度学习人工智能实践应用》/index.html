<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="作者: 林大贵出版社: 清华大学出版社出版年: 2018-1-1ISBN: 9787302493020 内容简介本书提供安装、上机操作指南，同时辅以大量范例程序介绍TensorFlow＋Keras深度学习方面的知识。本书分9部分，共21章，内容主要包括基本概念介绍、TensorFlow与Keras的安装、KerasMNIST手写数字识别、Keras CIFAR-10照片图像物体识别、Keras多层">
<meta name="keywords" content="机器学习,计算机,TensorFlow,自评,books,更毕,Keras,DeepLearning,Python,入门,tensorflow,豆瓣7">
<meta property="og:type" content="article">
<meta property="og:title" content="book_《TensorFlow+Keras深度学习人工智能实践应用》">
<meta property="og:url" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/index.html">
<meta property="og:site_name" content="Hac_lang">
<meta property="og:description" content="作者: 林大贵出版社: 清华大学出版社出版年: 2018-1-1ISBN: 9787302493020 内容简介本书提供安装、上机操作指南，同时辅以大量范例程序介绍TensorFlow＋Keras深度学习方面的知识。本书分9部分，共21章，内容主要包括基本概念介绍、TensorFlow与Keras的安装、KerasMNIST手写数字识别、Keras CIFAR-10照片图像物体识别、Keras多层">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00001.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00002.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00003.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00004.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00005.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00006.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00007.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00008.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00009.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00010.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00011.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00012.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00013.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00015.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00016.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00017.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00018.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00019.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00020.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00021.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00022.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00023.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00024.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00025.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00026.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00027.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00028.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00029.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00030.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00031.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00032.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00033.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00034.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00035.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00036.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00037.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00038.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00039.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00040.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00041.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00042.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00043.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00044.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00045.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00046.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00047.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00048.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00049.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00050.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00051.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00052.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00053.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00054.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00055.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00056.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00057.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00058.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00059.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00060.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00061.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00062.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00063.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00064.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00065.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00066.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00067.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00068.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00069.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00070.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00071.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00072.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00073.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00074.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00075.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00076.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00077.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00078.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00079.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00080.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00081.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00082.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00083.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00084.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00085.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00086.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00087.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00088.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00089.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00090.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00091.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00092.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00093.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00094.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00095.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00096.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00097.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00098.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00099.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00100.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00101.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00102.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00103.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00104.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00105.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00106.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00107.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00108.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00109.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00110.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00111.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00112.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00113.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00114.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00115.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00116.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00117.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00118.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00119.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00120.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00121.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00122.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00123.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00124.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00125.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00126.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00127.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00128.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00129.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00130.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00131.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00132.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00133.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00134.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00135.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00136.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00137.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00138.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00139.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00140.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00141.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00142.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00143.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00144.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00145.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00146.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00147.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00148.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00149.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00150.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00151.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00152.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00153.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00154.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00155.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00156.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00157.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00158.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00159.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00160.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00161.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00162.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00163.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00164.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00165.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00166.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00167.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00168.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00169.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00170.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00171.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00172.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00173.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00174.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00175.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00176.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00177.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00178.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00179.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00180.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00181.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00182.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00183.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00184.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00185.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00186.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00187.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00188.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00189.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00190.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00191.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00192.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00193.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00194.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00195.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00196.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00197.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00198.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00199.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00200.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00201.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00202.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00203.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00204.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00205.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00206.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00207.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00208.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00209.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00210.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00211.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00212.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00213.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00214.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00215.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00216.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00217.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00218.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00219.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00220.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00221.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00222.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00223.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00224.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00225.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00226.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00227.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00228.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00229.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00230.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00231.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00232.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00233.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00234.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00235.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00236.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00237.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00238.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00239.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00240.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00241.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00242.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00243.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00244.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00245.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00246.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00247.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00248.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00249.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00250.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00251.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00252.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00253.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00254.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00255.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00256.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00257.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00258.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00259.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00260.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00261.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00262.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00263.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00264.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00265.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00266.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00267.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00268.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00269.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00270.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00271.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00272.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00273.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00274.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00275.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00276.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00277.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00278.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00279.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00280.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00281.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00282.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00283.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00284.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00285.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00286.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00287.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00288.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00289.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00290.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00291.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00292.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00293.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00294.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00295.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00296.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00297.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00298.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00299.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00300.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00301.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00302.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00303.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00304.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00305.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00306.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00307.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00308.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00309.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00310.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00311.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00312.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00313.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00314.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00315.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00316.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00317.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00318.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00319.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00320.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00321.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00322.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00323.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00324.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00325.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00326.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00327.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00328.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00329.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00330.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00331.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00332.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00333.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00334.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00335.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00336.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00337.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00338.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00339.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00340.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00341.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00342.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00343.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00344.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00345.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00346.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00347.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00348.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00349.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00350.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00351.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00352.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00353.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00354.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00355.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00356.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00357.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00358.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00359.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00360.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00361.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00362.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00363.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00364.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00365.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00366.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00367.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00368.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00369.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00370.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00371.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00372.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00373.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00374.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00375.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00376.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00377.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00378.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00379.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00380.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00381.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00382.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00383.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00384.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00385.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00386.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00387.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00388.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00389.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00390.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00391.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00392.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00393.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00394.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00395.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00396.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00397.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00398.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00399.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00400.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00401.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00402.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00403.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00404.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00405.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00406.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00407.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00408.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00409.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00410.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00411.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00412.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00413.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00414.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00415.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00416.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00417.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00418.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00419.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00420.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00421.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00422.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00423.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00424.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00425.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00426.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00427.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00428.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00429.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00430.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00431.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00432.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00433.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00434.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00435.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00436.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00437.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00438.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00439.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00440.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00441.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00442.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00443.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00444.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00445.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00446.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00447.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00448.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00449.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00450.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00451.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00452.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00453.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00454.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00455.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00456.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00457.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00458.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00459.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00460.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00461.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00462.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00463.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00464.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00465.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00466.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00467.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00468.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00469.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00470.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00471.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00472.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00473.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00474.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00475.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00476.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00477.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00478.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00479.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00480.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00481.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00482.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00483.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00484.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00485.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00486.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00487.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00488.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00489.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00490.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00491.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00492.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00493.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00494.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00495.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00496.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00497.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00498.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00499.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00500.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00501.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00502.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00503.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00504.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00505.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00506.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00507.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00508.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00509.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00510.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00511.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00512.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00513.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00514.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00515.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00516.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00517.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00518.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00519.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00520.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00521.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00522.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00523.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00524.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00525.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00526.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00527.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00528.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00529.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00530.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00531.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00532.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00533.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00534.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00535.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00536.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00537.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00538.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00539.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00540.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00541.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00542.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00543.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00544.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00545.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00546.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00547.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00548.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00549.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00550.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00551.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00552.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00553.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00554.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00555.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00556.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00557.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00558.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00559.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00560.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00561.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00562.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00563.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00564.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00565.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00566.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00567.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00568.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00569.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00570.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00571.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00572.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00573.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00574.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00575.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00576.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00577.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00578.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00579.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00580.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00581.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00582.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00583.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00584.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00585.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00586.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00587.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00588.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00589.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00590.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00591.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00592.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00593.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00594.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00595.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00596.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00597.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00598.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00599.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00600.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00601.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00602.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00603.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00604.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00605.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00606.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00607.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00608.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00609.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00610.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00611.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00612.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00613.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00614.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00615.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00616.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00617.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00618.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00619.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00620.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00621.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00622.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00623.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00624.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00625.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00626.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00627.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00628.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00629.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00630.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00631.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00632.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00633.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00634.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00635.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00636.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00637.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00638.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00639.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00640.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00641.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00642.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00643.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00644.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00645.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00646.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00647.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00648.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00649.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00650.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00651.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00652.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00653.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00654.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00655.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00656.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00657.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00658.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00659.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00660.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00661.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00662.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00663.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00664.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00665.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00666.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00667.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00668.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00669.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00670.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00671.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00672.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00673.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00674.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00675.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00676.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00677.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00678.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00679.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00680.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00681.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00682.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00683.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00684.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00685.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00686.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00687.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00688.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00689.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00690.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00691.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00692.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00693.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00694.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00695.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00696.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00697.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00698.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00699.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00700.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00701.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00702.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00703.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00704.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00705.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00706.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00707.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00708.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00709.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00710.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00711.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00712.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00713.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00714.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00715.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00716.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00717.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00718.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00719.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00720.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00721.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00722.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00723.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00724.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00725.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00726.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00727.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00728.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00729.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00730.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00731.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00732.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00733.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00734.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00735.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00736.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00737.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00738.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00739.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00732.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00740.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00741.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00742.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00743.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00744.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00745.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00746.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00747.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00748.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00749.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00750.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00751.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00752.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00753.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00754.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00755.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00756.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00757.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00758.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00759.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00760.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00761.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00762.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00763.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00764.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00765.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00766.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00767.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00768.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00769.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00770.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00771.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00772.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00773.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00774.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00775.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00776.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00777.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00778.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00779.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00780.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00781.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00782.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00783.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00784.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00785.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00786.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00787.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00788.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00789.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00790.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00791.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00792.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00793.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00794.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00795.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00796.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00797.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00798.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00799.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00800.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00801.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00802.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00803.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00804.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00805.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00806.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00807.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00808.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00809.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00810.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00811.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00812.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00813.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00814.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00815.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00816.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00817.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00818.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00819.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00820.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00821.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00822.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00823.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00824.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00825.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00826.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00827.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00828.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00829.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00830.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00831.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00832.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00833.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00834.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00835.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00836.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00837.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00838.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00839.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00840.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00841.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00842.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00843.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00844.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00845.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00846.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00847.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00848.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00849.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00850.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00851.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00852.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00853.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00854.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00855.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00856.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00857.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00858.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00859.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00860.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00861.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00862.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00863.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00864.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00865.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00866.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00867.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00868.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00869.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00870.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00871.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00872.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00873.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00874.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00875.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00876.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00877.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00878.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00879.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00880.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00881.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00882.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00883.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00884.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00885.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00886.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00887.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00888.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00889.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00890.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00891.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00892.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00893.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00894.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00895.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00896.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00897.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00898.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00899.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00900.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00901.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00902.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00903.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00904.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00905.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00906.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00907.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00908.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00909.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00910.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00911.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00912.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00913.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00914.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00915.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00916.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00917.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00918.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00919.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00920.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00921.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00922.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00923.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00924.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00925.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00926.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00927.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00928.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00929.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00930.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00931.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00932.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00933.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00934.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00935.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00936.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00937.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00938.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00939.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00940.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00941.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00942.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00943.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00944.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00945.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00946.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00947.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00948.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00949.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00950.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00951.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00952.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00953.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00954.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00955.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00956.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00957.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00958.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00959.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00960.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00961.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00962.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00963.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00964.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00965.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00966.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00967.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00968.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00969.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00970.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00971.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00972.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00973.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00974.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00975.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00976.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00977.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00978.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00979.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00980.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00981.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00982.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00983.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00984.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00985.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00986.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00987.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00988.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00989.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00990.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00991.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00992.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00993.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00994.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00995.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00996.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00997.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00998.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00999.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01000.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01001.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01002.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01003.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01004.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01005.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01006.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01007.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01008.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01009.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01010.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01011.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01012.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01013.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01014.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01015.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01016.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01017.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01018.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01019.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01020.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01021.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01022.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01023.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01024.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01025.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01026.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01027.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01028.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01029.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01030.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01031.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01032.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01033.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01034.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01035.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01036.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01037.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01038.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01039.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01040.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01041.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01042.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01043.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01044.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01045.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01046.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01047.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01048.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01049.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01050.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01051.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01052.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01053.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01054.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01055.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01056.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01057.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01058.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01059.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01060.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01061.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01062.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01063.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01064.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01065.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01066.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01067.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01068.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01069.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01070.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01071.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01072.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01073.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01074.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01075.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01076.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01077.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01078.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01079.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01080.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01081.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01082.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01083.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01084.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01085.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01086.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01087.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01088.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01089.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01090.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01091.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01092.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01093.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01094.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01095.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01096.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01097.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01098.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01099.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01100.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01101.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01102.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01103.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01104.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01105.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01106.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01107.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01108.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01109.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01110.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01111.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01112.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01113.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01114.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01115.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01116.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01117.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01118.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01119.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01120.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01121.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01122.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01123.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01124.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01125.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01126.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01127.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01128.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01129.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01130.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01131.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01132.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01133.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01134.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01135.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01136.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01137.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01138.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01139.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01140.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01141.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01142.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01143.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01144.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01145.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01146.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01147.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01148.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01149.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01150.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01151.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01152.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01153.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01154.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01155.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01156.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01157.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01158.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01159.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01160.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01161.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01162.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01163.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01164.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01165.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01166.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01167.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01168.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01169.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01170.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01171.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01172.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01173.jpg">
<meta property="og:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image01174.jpg">
<meta property="og:updated_time" content="2020-08-20T13:37:52.028Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="book_《TensorFlow+Keras深度学习人工智能实践应用》">
<meta name="twitter:description" content="作者: 林大贵出版社: 清华大学出版社出版年: 2018-1-1ISBN: 9787302493020 内容简介本书提供安装、上机操作指南，同时辅以大量范例程序介绍TensorFlow＋Keras深度学习方面的知识。本书分9部分，共21章，内容主要包括基本概念介绍、TensorFlow与Keras的安装、KerasMNIST手写数字识别、Keras CIFAR-10照片图像物体识别、Keras多层">
<meta name="twitter:image" content="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/Image00001.jpg">





  
  
  <link rel="canonical" href="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>book_《TensorFlow+Keras深度学习人工智能实践应用》 | Hac_lang</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hac_lang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">小白hac_lang的笔记，涉及内容包含但不限于：人工智能   基因工程    信息安全   软件工程   嵌入式   天文物理</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-news">

    
    
      
    

    

    <a href="/news/" rel="section"><i class="menu-item-icon fa fa-fw fa-rss"></i> <br>news</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    
  
  

  

  <a href="https://github.com/HACLANG" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://haclang.github.io/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="hac_lang">
      <meta itemprop="description" content="小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hac_lang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">book_《TensorFlow+Keras深度学习人工智能实践应用》

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-03-29 01:50:09" itemprop="dateCreated datePublished" datetime="2018-03-29T01:50:09+08:00">2018-03-29</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者: 林大贵<br>出版社: 清华大学出版社<br>出版年: 2018-1-1<br>ISBN: 9787302493020</p>
<h1 id="内容简介"><a href="#内容简介" class="headerlink" title="内容简介"></a>内容简介</h1><p>本书提供安装、上机操作指南，同时辅以大量范例程序介绍TensorFlow＋Keras深度学习方面的知识。本书分9部分，共21章，内容主要包括基本概念介绍、TensorFlow与Keras的安装、KerasMNIST手写数字识别、Keras CIFAR-10照片图像物体识别、Keras多层感知器预测泰坦尼克号上旅客的生存概率、使用KerasMLP、RNN、LSTM进行IMDb自然语言处理与情感分析、以TensorFlow张量运算仿真神经网络的运行、TensorFlowMNIST手写数字识别、使用GPU大幅加快深度学习训练。</p>
<p>TensorFlow＋Keras深度学习方面的知识不需要具备高等数学模型、算法等专业知识，读者只需要具备基本的Python程序设计能力，按照本书的步骤循序渐进地学习，就可以了解深度学习的基本概念，进而实际运用深度学习的技术。</p>
<h1 id="序"><a href="#序" class="headerlink" title="序"></a>序</h1><p>深度学习是人工智能／机器学习研究中的一个新领域，它的概念源于人工神经网络的研究，目的在于建立含有多个隐含层的多层感知器的一种深度学习结构，以此来模拟人脑进行分析学习的神经网络。深度学习在视觉识别（人脸识别或面部表情识别）、图像识别、语音识别、文字识别和生物医学等方面的应用中具有优势，而且已经取得了非常好的效果。</p>
<p>对于具有人工智能和机器学习基本概念的读者或者开发者，想“更上一层楼”掌握深度学习理论和技术，并希望可以在实践中快速运用深度学习技术，那么本书就非常合适。对于开设了“深度学习”人工智能课程的高等院校，本书可以作为学生上机实践的实验用书。</p>
<p>本书介绍的TensorFlow＋Keras深度学习与类神经网络不需要读者具有高等数学建模的专业知识，也不需要具有计算机专业深厚的算法知识和精专的程序设计技能，读者只需要具有基本的Python程序设计能力，而后按照本书的章节循序渐进地学习，就可以了解深度学习的基本概念，而且可以按照书中的详细步骤来运用本书提供的大量范例程序，通过上机实践操作来实际实现深度学习技术。</p>
<p>本书的范例程序不需要修改就可以直接运行，而且同时支持Windows环境和LinuxUbuntu环境，读者只要按照书中的说明下载和安装好CUDA、cuDNN、TensorFlow GPU版本与Keras即可。</p>
<p>本书附录A提供了下载全部范例程序的网址和步骤，这些范例程序使用实际的数据集来实现各种深度学习的算法，并示范如何进行数据预处理、训练数据、建立模型、预测结果，展示如何把Keras与TensorFlow深度学习类神经网络运用到具体的应用中。</p>
<p>深度学习会用到大数据技术，而且本书的范例要用到Python程序设计语言，本书并未在这些方面深入讲解，建议需要学习这方面内容的读者去寻找相关出版物，以便能更好地结合本书来学习和实践深度学习技术，从而完善自己在人工智能知识方面的结构。</p>
<p>资深架构师 赵军</p>
<p>2017年11月</p>
<h1 id="前-言"><a href="#前-言" class="headerlink" title="前 言"></a>前 言</h1><p>近年来，人工智能（ArtificialIntelligence，AI）吸引了大众与媒体的目光，AlphaGo的成功更加让人工智能技术变得炙手可热，其实AI早已进入了我们的生活，如手机中的语音助理、人脸识别、影音平台每日的推荐等。然而，人工智能的发展才刚刚起步，未来人工智能的应用将会深入生活的每一个层面，也就是说未来一定是AI的时代。</p>
<p>深度学习是人工智能中成长最快的领域，深度学习就是仿真人类神经网络的工作方式，常见的深度学习架构有深度神经网络（DNN）、卷积神经网络（CNN）、递归神经网络（RNN）等。深度学习特别适用于视觉识别、语音识别、自然语言处理、识别癌细胞等领域，目前已经取得非常好的效果。</p>
<p>近年来，各大科技公司（如Google、Microsoft、Facebook、Amazon、Tesla等）都积极投入到深度学习领域进行研发。以Google公司为例，它在2014年以4亿美元并购了DeepMind公司。2016年，由DeepMind开发的人工智能围棋程序AlphaGo以4：1击败了世界级围棋冠军李世石，引起了网络与媒体的注目，让人们了解到深度学习的威力强大。</p>
<p>TensorFlow最初由Google BrainTeam团队开发，Google使用TensorFlow进行研究及开发自身产品，并于2015年公开了它的源代码，所有的开发者都可以免费使用。Google的很多产品早就使用了机器学习或深度学习，例如Gmail过滤垃圾邮件、Google语音识别、图像识别、翻译等。</p>
<p>TensorFlow功能强大，执行效率高，支持各种平台。但是，TensorFlow是比较底层的深度学习链接库，学习门槛高，对于从未接触过深度学习的初学者，如果一开始就学习TensorFlow，就要面对其特殊的“计算图”（computationalgraph）程序设计模式，还必须自行设计张量（Tensor）运算，可能会有很大的挫折感。</p>
<p>所以本书先介绍Keras，这是以TensorFlow为底层的、高级的深度学习链接库，可以很容易地建立深度学习模型，进行训练并使用模型预测，对初学者而言学习门槛较低。等读者熟悉了深度学习模型后，再去学习TensorFlow就很轻松了。</p>
<p>近年来，深度学习和人工智能技术快速发展的一个很重要的因素是，GPU提供了强大的并行运算架构，可以让深度学习训练比用CPU来进行要快数十倍。本书也特别介绍了GPU的安装与应用，读者只需要有NVIDIA显示适配器（显卡），然后按照本书的介绍依次安装CUDA、cuDNN、TensorFlowGPU版本与Keras，就可以使用GPU大幅加快深度学习的训练。</p>
<p>林大贵</p>
<h1 id="本书章节与范例程序介绍"><a href="#本书章节与范例程序介绍" class="headerlink" title="本书章节与范例程序介绍"></a>本书章节与范例程序介绍</h1><p><strong>本书的目标读者</strong></p>
<p>使用TensorFlow＋Keras深度学习与类神经网络不需要具备高等数学模型、算法等专业知识，读者只需要具有基本的Python程序设计能力，按照本书的步骤循序渐进地学习，就可以了解深度学习的基本概念，进而实际运用深度学习的技术。</p>
<p>本书的特色是提供安装、上机操作指南，同时辅以大量范例程序。</p>
<p>▶ 上机操作</p>
<p>本书详细介绍了如何在Windows与LinuxUbuntu系统上安装Anaconda、TensorFlow与Keras，用于深度学习的程序设计，并且详细介绍了安装CUDA、cuDNN、TensorFlowGPU版本与Keras的步骤，用于加快深度学习的训练速度。</p>
<p>▶ 范例程序</p>
<p>以实际范例程序来学习程序设计是最有效率的方式。因此本书使用实际的数据集配合范例程序代码来介绍各种深度学习算法，并示范如何进行数据预处理、训练数据、建立模型、预测结果，由浅入深地介绍Keras与TensorFlow深度学习类神经网络。</p>
<p><strong>本书章节内容及上机实践操作与范例程序介绍</strong></p>
<p>▶ 基本概念介绍</p>
<p><img src="Image00001.jpg" alt></p>
<p>▶ TensorFlow与Keras的安装</p>
<p><img src="Image00002.jpg" alt></p>
<p>▶ Keras MNIST手写数字识别</p>
<p><img src="Image00003.jpg" alt></p>
<p>▶ Keras CIFAR-10照片图像物体识别</p>
<p><img src="Image00004.jpg" alt></p>
<p>▶ Keras多层感知器预测泰坦尼克号上旅客的生存概率</p>
<p><img src="Image00005.jpg" alt></p>
<p>▶ 使用Keras MLP、RNN、LSTM进行IMDb自然语言处理与情感分析</p>
<p><img src="Image00006.jpg" alt></p>
<p>▶ 以TensorFlow张量运算仿真神经网络的运行</p>
<p><img src="Image00007.jpg" alt></p>
<p>▶ TensorFlow MNIST手写数字识别</p>
<p><img src="Image00008.jpg" alt></p>
<p>▶ 使用GPU大幅加快深度学习训练</p>
<p><img src="Image00009.jpg" alt></p>
<p>▶ 本书范例程序下载</p>
<p>下载网址：<a href="https://pan.baidu.com/s/1c2rXnH2（注意区分数字和英文字母大小写）。" target="_blank" rel="noopener">https://pan.baidu.com/s/1c2rXnH2（注意区分数字和英文字母大小写）。</a></p>
<p>如果下载有问题，请发送电子邮件至booksaga@126.com，邮件主题设置为“求TensorFlow＋Keras深度学习人工智能实践应用范例程序”。</p>
<p>▶ 指令整理</p>
<p>安装Tensor与Keras必须使用Windows或Linux指令。为了方便读者练习，将这些指令整理在与本书有关的微博中。读者可以从微博中复制这些指令，然后粘贴到Windows“命令提示符”窗口或Linux“终端”程序中，以节省打字的时间，避免输错字母或字符。微博网址如下：</p>
<p><a href="https://www.weibo.com/hadoopsparkbook" target="_blank" rel="noopener">https://www.weibo.com/hadoopsparkbook</a></p>
<h1 id="第1章-人工智能、机器学习与深度学习简介"><a href="#第1章-人工智能、机器学习与深度学习简介" class="headerlink" title="第1章 人工智能、机器学习与深度学习简介"></a>第1章 人工智能、机器学习与深度学习简介</h1><p>近年来，人工智能（ArtificialIntelligence，AI）吸引了大众与媒体的目光，AlphaGo的成功让人工智能技术变得更加炙手可热，其实AI早已进入你我的生活中，例如我们手机中的语音助理、人脸识别、影音平台的每日推荐等。然而，人工智能的发展才刚刚起步，未来人工智能的应用将会深入生活中的每一个层面，也就是说未来一定是AI的时代。</p>
<h3 id="1-1-人工智能、机器学习、深度学习的关系"><a href="#1-1-人工智能、机器学习、深度学习的关系" class="headerlink" title="1.1 人工智能、机器学习、深度学习的关系"></a>1.1 人工智能、机器学习、深度学习的关系</h3><p>人工智能、机器学习、深度学习的关系整理如图1-1所示。</p>
<p><img src="Image00010.jpg" alt></p>
<p>图1-1</p>
<p>▶ 人工智能</p>
<p>“人工智能”一词最早是在20世纪50年代提出的。人工智能的目标是让计算机像人一样思考与学习。被视为人工智能之父的图灵（Alan MathisonTuring）提出了著名的“图灵测试”（TuringTesting）：人类与机器通过电传设备对话，如果人类无法根据这个对话过程判断对方是机器或人，通过图灵测试就可以认定这台机器具有人工智能。</p>
<p>20世纪80年代，约翰•塞尔（John Searle）提出了对“人工智能”的分类方式。</p>
<ul>
<li>强人工智能（Strong AI）：机器具有与人类一样完整的认知能力。</li>
<li>弱人工智能（Weak AI）：机器不需要具有与人类一样完整的认知能力，只要设计得看起来像具有智慧即可。</li>
</ul>
<p>▶ 机器学习</p>
<p>机器学习（MachineLearning）是人工智能的分支。机器学习是通过算法，使用大量数据进行训练，训练完成后会产生模型。将来有新的数据时，我们可以使用训练产生的模型进行预测。机器学习可分为有监督的学习（SupervisedLearning）、无监督的学习（Unsupervised Learning）和增强式学习（Reinforcement Learning）。</p>
<p>机器应用相当广泛，例如推荐引擎、定向广告、需求预测、垃圾邮件过滤、医学诊断、自然语言处理、搜索引擎、诈骗侦测、证券分析、视觉识别、语音识别、手写识别，等等。</p>
<p>▶ 深度学习</p>
<p>深度学习（DeepLearning）也是机器学习的分支。深度学习是人工智能中成长最快的领域，深度学习仿真人类神经网络的工作方式，常见的深度学习架构有多层感知器（Multi-Layer Perceptron）、深度神经网络（Deep Neural Network，DNN）、卷积神经网络（Convolutional NeuralNetwork，CNN）、递归神经网络（Recurrent NeuralNetwork，RNN）。深度学习已经应用于视觉识别、语音识别、自然语言处理、生物医学等领域，并且取得了非常好的效果。</p>
<p>▶ 为何近年来人工智能发展加速</p>
<p>早在20世纪60年代及70年代，科学家就提出了各种机器学习的算法，然而受限于当时计算机的计算能力以及大量数据的获取也不容易，因而机器学习一直都没有很成功。</p>
<ul>
<li>大数据（Big Data）分布式存储与运算</li>
</ul>
<p>随着全球设备、机器和系统的相互连接，从而产生了大量数据，再加上分布式存储（例如Hadoop、NoSQL等）的发展，也提供了大量数据，而且大量服务器的并行计算功能（例如Spark等）提供了巨大的运算能力。大量数据与运算能力就像燃料，推动了机器学习与深度学习的加速发展。</p>
<ul>
<li>GPU、TPU并行计算</li>
</ul>
<p>GPU（Graphics Processing Unit，图形处理器）原本用来处理画面像素的运算，例如电脑游戏界面所需要的大量图形运算。</p>
<p>CPU与GPU架构上有着根本的不同：CPU含有数颗核心，为顺序处理进行优化，而GPU可以有高达数千个小型而且高效率的核心，可以发挥并行计算的强大功能，如图1-2所示。</p>
<p><img src="Image00011.jpg" alt></p>
<p>图1-2</p>
<p>深度学习以大量矩阵运算模拟神经元的工作方式，矩阵运算的特性是，单一运算都很简单，但是需要大量运算，特别适合采用并行计算。GPU通过大量核心进行并行计算，可让通过GPU进行深度学习训练比通过CPU进行深度学习训练快10～75倍，让训练的时间从数周缩短为数天。</p>
<p>而Google公司更在2016年宣布，研发人工智能专用芯片TPU（Tensor ProcessingUnit，张量处理单元或张量处理芯片）来进行并行计算。TPU是专为深度学习特定用途设计的特殊规格的逻辑芯片（IC），使得深度学习的训练速度更快。</p>
<h3 id="1-2-机器学习介绍"><a href="#1-2-机器学习介绍" class="headerlink" title="1.2 机器学习介绍"></a>1.2 机器学习介绍</h3><p>机器学习的训练数据是由features、label组成的。</p>
<ul>
<li><strong>features：</strong> 数据的特征，例如湿度、风向、风速、季节、气压。</li>
<li><strong>label：</strong> 数据的标签，也就是我们希望预测的目标，例如降雨（0：不会下雨、1：会下雨）、天气（1：晴天、2：雨天、3：阴天、4：下雪）、气温。</li>
</ul>
<p>如图1-3所示，机器学习可分为两个阶段：</p>
<ul>
<li>训练（Training）</li>
</ul>
<p>训练数据是过去累积的历史数据，可能是文本文件、数据库或其他来源的数据，经过FeatureExtraction（特征提取）产生features（数据特征）与label（真实的标签数据），然后经过机器学习算法训练后产生模型。</p>
<ul>
<li>预测（Predict）</li>
</ul>
<p>新输入数据，经过Feature Extraction（特征提取）产生features（数据特征），使用训练完成的模型进行预测，最后产生预测结果。</p>
<p><img src="Image00012.jpg" alt></p>
<p>图1-3</p>
<h3 id="1-3-机器学习分类"><a href="#1-3-机器学习分类" class="headerlink" title="1.3 机器学习分类"></a>1.3 机器学习分类</h3><p>前面介绍过，机器学习可分为有监督的学习、无监督的学习和增强式学习。以下详细介绍其分类。</p>
<p>▶ 有监督的学习</p>
<p>有监督的学习的数据具备特征（features）与预测目标（label），通过算法训练并建立模型。当有新的数据时，我们就可以使用模型进行预测。有下列分类：</p>
<ul>
<li>二元分类</li>
</ul>
<p>已知湿度、风向、风速、季节、气压等数据特征，希望预测当天是否会下雨（0：不会下雨、1：会下雨）。希望预测的目标label有两个选项，就好像在做是非题。</p>
<ul>
<li>多元分类</li>
</ul>
<p>已知湿度、风向、风速、季节、气压等数据特征，希望预测当天天气（1：晴天、2：雨天、3：阴天、4：下雪）。希望预测的目标label有多个选项，就好像在做选择题。</p>
<ul>
<li>回归分析</li>
</ul>
<p>已知湿度、风向、风速、季节、气压等数据特征，希望预测当天气温。希望预测的目标label是连续的值，就好像在做计算题。</p>
<p>▶ 无监督的学习</p>
<p>对于无监督的学习，从现有数据我们不知道要预测的答案，所以没有label（预测目标）。例如，cluster集群算法将数据分成几个差异性最大的群组，而群组内的则相似程度最高。</p>
<p>▶ 增强式学习</p>
<p>增强式学习的原理：借助定义动作（Actions）、状态（States）、奖励（Rewards）的方式不断训练机器循序渐进，学会执行某项任务的算法。例如，训练机器玩《超级玛丽》电子游戏，动作：左／右／跳，状态：当前游戏的界面，奖励：得分／受伤，借助不断地训练学会玩游戏。常见的算法有Q-Learning、TD（Temporal Difference）、Sarsa。</p>
<p>▶ 机器学习分类整理</p>
<p>机器学习分类整理见表1-1。</p>
<p>表1-1 机器学习分类整理</p>
<p><img src="Image00013.jpg" alt></p>
<p>（续表）</p>
<p><img src="Image00014.jpg" alt></p>
<p>▶ 机器学习分类</p>
<p>机器学习分类如图1-4所示。</p>
<p><img src="Image00015.jpg" alt></p>
<p>图1-4</p>
<p>本书主要介绍深度学习，如果你对机器学习与大数据有兴趣，可以参考笔者的另一本书《Python＋Spark 2.0＋Hadoop机器学习与大数据实战》。</p>
<h3 id="1-4-深度学习简介"><a href="#1-4-深度学习简介" class="headerlink" title="1.4 深度学习简介"></a>1.4 深度学习简介</h3><p>人脑的重量大约为一千多克，结构非常复杂，预估具有860亿个神经元以及超过100兆条神经相连，形成的网络比最先进的超级计算机还要强大。</p>
<p>因为人类神经网络太过复杂，为了方便用计算机来仿真神经网络，人们将神经元分为多个层次。通常会有一个输入层、一个输出层，隐藏层可以有非常多层（见图1-5），所以称为深度学习。</p>
<p><img src="Image00016.jpg" alt></p>
<p>图1-5</p>
<p>▶ 机器学习与深度学习的关系</p>
<p>如图1-6所示，深度学习的应用很广泛，你可以将深度学习技术应用在有监督的学习、无监督的学习和增强式学习等领域。</p>
<p><img src="Image00017.jpg" alt></p>
<p>图1-6</p>
<h3 id="1-5-结论"><a href="#1-5-结论" class="headerlink" title="1.5 结论"></a>1.5 结论</h3><p>本章我们介绍了人工智能、机器学习、深度学习的关系以及它们的基本概念，并且简明介绍了机器学习的分类，下一章将详细介绍深度学习的原理。</p>
<h1 id="第2章-深度学习的原理"><a href="#第2章-深度学习的原理" class="headerlink" title="第2章 深度学习的原理"></a>第2章 深度学习的原理</h1><p>本章将介绍深度学习与类神经网络的原理，并介绍如何以矩阵的数学公式来仿真类神经网络的运行。</p>
<h3 id="2-1-神经传导的原理"><a href="#2-1-神经传导的原理" class="headerlink" title="2.1 神经传导的原理"></a>2.1 神经传导的原理</h3><h5 id="1．神经元的信息传导"><a href="#1．神经元的信息传导" class="headerlink" title="1．神经元的信息传导"></a>1．神经元的信息传导</h5><p>神经传导的工作原理很复杂，在此我们只是简略介绍其概念，如图2-1所示。</p>
<p><img src="Image00018.jpg" alt></p>
<p>图2-1</p>
<ul>
<li><strong>轴突传送信息：</strong> 神经元长出一个细长条的轴突，以电流方式将信息传递给另一个神经元。轴突最长可达一米，最短只有几十分之一毫米。</li>
<li><strong>树突接收信息：</strong> 树突主要的功能是接收其他神经元传来的电化学信息，再传递给本身的细胞。</li>
<li><strong>突触是输入与输出的神经元传递的机制：</strong> 输入与输出的神经元之间发展出的特殊结构称为突触，神经元通过释放化学物质来传递信息，当电压达到临界值时，就会通过轴突传送电脉冲动作电位至接收神经元。</li>
</ul>
<h5 id="2．以数学公式仿真神经元的信息传导"><a href="#2．以数学公式仿真神经元的信息传导" class="headerlink" title="2．以数学公式仿真神经元的信息传导"></a>2．以数学公式仿真神经元的信息传导</h5><p>为了将神经元的传导用计算机来仿真，我们必须将神经元的传导以数学公式来表示。以图2-2来说明如何以数学公式模拟神经元的信息传导。</p>
<p><img src="Image00019.jpg" alt></p>
<p>图2-2</p>
<p><img src="Image00020.jpg" alt></p>
<p>图2-2（续）</p>
<p>图2-2可以整理为以下公式：</p>
<p>_y_ =activation function（ _x_ 1× _w_ 1+ _x_ 2× _w_ 2+ _x_ 3× _w_ 3+ _b_ 1）</p>
<p>详细说明如表2-1所示。</p>
<p>表2-1 以数学公式模拟神经元的信息传导参数说明</p>
<p><img src="Image00021.jpg" alt></p>
<h5 id="3．激活函数通常为非线性函数"><a href="#3．激活函数通常为非线性函数" class="headerlink" title="3．激活函数通常为非线性函数"></a>3．激活函数通常为非线性函数</h5><p>以上激活函数可以仿真神经传导的工作方式将上一层神经元信号传递到下一层。激活函数通常为非线性函数，加入激活函数能让神经网络处理比较复杂的非线性问题。表2-2所示为线性函数与非线性函数的图像。</p>
<p>表2-2 线性函数与非线性函数的图像</p>
<p><img src="Image00022.jpg" alt></p>
<p>Keras与TensorFlow支持很多激活函数，不过在此我们介绍最常用的两种：Sigmoid与ReLU。</p>
<h5 id="4．Sigmoid激活函数"><a href="#4．Sigmoid激活函数" class="headerlink" title="4．Sigmoid激活函数"></a>4．Sigmoid激活函数</h5><p>常用的激活函数Sigmoid公式如下：</p>
<p><img src="Image00023.jpg" alt></p>
<p>Sigmoid激活函数的图像如图2-3所示。</p>
<p><img src="Image00024.jpg" alt></p>
<p>图2-3</p>
<p>Sigmoid激活函数其实与人类感觉神经对信号的接收类似，例如，当接收神经元所接收刺激的总和：</p>
<ul>
<li><strong>小于临界值时，会忽略此刺激</strong> 当 _x_ ＜-5时，输出 _y_ 接近0。</li>
<li><strong>大于临界值时，开始接收神经刺激</strong> 当 _x_ 范围在－5与5之间时，随着 _x_ 数值加大， _y_ 的数值也加大。</li>
<li><strong>达到一定程度时，感觉会开始钝化</strong> 即使受到更大的刺激，感觉仍维持不变，即当 _x_ ＞5时， _y_ 的数值趋近于1。</li>
</ul>
<h5 id="5．ReLU激活函数"><a href="#5．ReLU激活函数" class="headerlink" title="5．ReLU激活函数"></a>5．ReLU激活函数</h5><p>另一个很常见的激活函数ReLU的图像如图2-4所示。</p>
<p>当接收神经元所接收刺激的总和：</p>
<ul>
<li><strong>小于临界值时，会忽略此刺激</strong> 输入 _x_ 小于0， _y_ 值是0。</li>
<li><strong>大于临界值时，开始接收神经刺激</strong> 输入 _x_ 大于0， _y_ 等于 _x_ 。</li>
</ul>
<p><img src="Image00025.jpg" alt></p>
<p>图2-4</p>
<h3 id="2-2-以矩阵运算仿真神经网络"><a href="#2-2-以矩阵运算仿真神经网络" class="headerlink" title="2.2 以矩阵运算仿真神经网络"></a>2.2 以矩阵运算仿真神经网络</h3><p>前面只是以数学运算模拟单个接收神经元，本节将介绍以矩阵模拟两个接收神经元。</p>
<h5 id="1．以矩阵运算仿真神经网络的信息传导"><a href="#1．以矩阵运算仿真神经网络的信息传导" class="headerlink" title="1．以矩阵运算仿真神经网络的信息传导"></a>1．以矩阵运算仿真神经网络的信息传导</h5><p>多个接收神经元的神经网络如图2-5所示。</p>
<p><img src="Image00026.jpg" alt></p>
<p>图2-5</p>
<p>▶ 以数学公式模拟输出与接收神经元的工作方式：</p>
<p>_y_ 1=activation function（ _x_ 1× _w_ 11+ _x_ 2× _w_ 21+ _x_ 3× _w_ 31+ _b_ 1）</p>
<p>_y_ 2=activation function（ _x_ 1× _w_ 12+ _x_ 2× _w_ 22+ _x_ 3× _w_ 32+ _b_ 2）</p>
<p>▶ 以上两个数学公式可以整合成一个矩阵运算公式：</p>
<p><img src="Image00027.jpg" alt></p>
<p>▶ 另一种形式的矩阵公式表示如下：</p>
<p>_y_ =activation（ _x_ × _w_ + _b_ ）</p>
<p>▶ 矩阵公式以中文表示如下：</p>
<p>输出＝激活函数（输入×权重＋偏差）</p>
<p>说明见表2-3。</p>
<p>表2-3 以数学公式模拟输出与接收神经元的工作方式参数说明</p>
<p><img src="Image00028.jpg" alt></p>
<h3 id="2-3-多层感知器模型"><a href="#2-3-多层感知器模型" class="headerlink" title="2.3 多层感知器模型"></a>2.3 多层感知器模型</h3><p>在20世纪80年代，多层感知器（MultilayerPerceptron，MLP）模型是一种受欢迎的机器学习解决方案，尤其是在语音识别、图像识别和机器翻译等多个领域。到20世纪90年代，MLP遇到来自更简单的模型（例如，支持向量机（SupportVector Machine，SVM））的强烈竞争。近年来，由于深度学习的成功，多层感知器又重新受到业界的重视。</p>
<h5 id="1．以多层感知器模型识别MNIST手写数字图像"><a href="#1．以多层感知器模型识别MNIST手写数字图像" class="headerlink" title="1．以多层感知器模型识别MNIST手写数字图像"></a>1．以多层感知器模型识别MNIST手写数字图像</h5><p>我们将以多层感知器模型识别MNIST手写数字图像说明多层感知器模型的工作方式，如图2-6所示。</p>
<p><img src="Image00029.jpg" alt></p>
<p>图2-6</p>
<h5 id="2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）"><a href="#2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）" class="headerlink" title="2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）"></a>2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）</h5><p><img src="Image00030.jpg" alt></p>
<p>图2-7</p>
<p>▶ 建立输入层与隐藏层的公式：</p>
<p>_h_ 1=ReLU（ _x_ × _w_ 1+ _b_ 1）</p>
<p>详细说明如表2-4所示。</p>
<p>表2-4 输入层与隐藏层的公式参数说明</p>
<p><img src="Image00031.jpg" alt></p>
<p>（续表）</p>
<p><img src="Image00032.jpg" alt></p>
<p>▶ 建立隐藏层与输出层公式：</p>
<p>_y_ =softmax（ _h_ 1× _w_ 2+ _b_ 2）</p>
<p>详细说明如表2-5所示。</p>
<p>表2-5 隐藏层与输出层的公式参数说明</p>
<p><img src="Image00033.jpg" alt></p>
<h3 id="2-4-使用反向传播算法进行训练"><a href="#2-4-使用反向传播算法进行训练" class="headerlink" title="2.4 使用反向传播算法进行训练"></a>2.4 使用反向传播算法进行训练</h3><p>当我们建立深度学习模型后，就必须进行训练。反向传播法（BackPropagation）是训练人工神经网络的常见方法，并且与优化器（Optimizer，例如梯度下降法）结合使用。反向传播是一种有监督的学习方法，必须输入features（特征值）与label（真实的值）。</p>
<p>简单来说，反向传播算法就是“从错误中学习”。多层感知器模型识别MNIST手写数字图像，过程整理如图2-8所示。</p>
<h5 id="1．训练前必须先进行“数据预处理”与“建立模型”"><a href="#1．训练前必须先进行“数据预处理”与“建立模型”" class="headerlink" title="1．训练前必须先进行“数据预处理”与“建立模型”"></a>1．训练前必须先进行“数据预处理”与“建立模型”</h5><p><strong>（1）数据预处理：</strong> MNIST数据集经过数据预处理产生features（数字图像的特征值）、label（数字图像真实的值），用于后续训练使用。</p>
<p><strong>（2）建立模型：</strong> 建立多层感知模型，并且以随机数初始化模型的权重（Weight）与偏差（Bias）： _w_ 1、 _b_ 1， _w_ 2、_b_ 2。</p>
<p><img src="Image00034.jpg" alt></p>
<p>图2-8</p>
<h5 id="2．反向传播算法训练多层感知器模型（见图2-9）"><a href="#2．反向传播算法训练多层感知器模型（见图2-9）" class="headerlink" title="2．反向传播算法训练多层感知器模型（见图2-9）"></a>2．反向传播算法训练多层感知器模型（见图2-9）</h5><p><img src="Image00035.jpg" alt></p>
<p>图2-9</p>
<p>图2-9说明如下：</p>
<p>进行训练时，数据分为多个批次，例如每一批次200项数据，然后每次读取一批次数据进行反向传播算法训练。</p>
<p>重复以下传播和权重更新（weight update），直到误差（loss）收敛。</p>
<p>▶ 传播</p>
<p><strong>（1）模型输入特征值：features</strong> （数字图像的特征值），输入到神经网络进行计算。</p>
<p><strong>（2）模型输出计算结果：</strong> 经过多个隐藏层网络进行计算，逐层向前传播，最后到达输出层，产生神经网络的输出。</p>
<p>▶ 权重更新</p>
<p><strong>（1）损失函数计算误差：</strong> 使用损失函数计算模型输出（预测的结果）与label（数字图像真实的值）之间的误差值。</p>
<p><strong>（2）优化器更新权重与偏差：</strong> 按照误差值更新神经元连接的权重与偏差，尽量使损失函数的误差值最小化。</p>
<h5 id="3．损失函数"><a href="#3．损失函数" class="headerlink" title="3．损失函数"></a>3．损失函数</h5><p>简单地说，反向传播算法就是“从错误中学习”，而损失函数就是帮我们计算误差。Cross Entropy是深度学习常用的损失函数，说明如图2-10所示。</p>
<p><img src="Image00036.jpg" alt></p>
<p>图2-10</p>
<p>以上损失函数计算模型输出（预测的结果）与label（数字图像真实的值）之间的误差值，都是以One-HotEncoding（一位有效编码）表示，例如预测数字7。</p>
<ul>
<li><strong>label（数字图像真实的值）：</strong> 由0算起第7个数字是1，其他都是0。</li>
<li><strong>模型输出（预测的结果）：</strong> 预测结果0的概率是0.1（10%），预测结果1的概率是0.3（30%），等等。预测结果7的概率是0.9，代表预测结果数字7有90%的概率，其他的概率都不高。</li>
</ul>
<h5 id="4．优化器"><a href="#4．优化器" class="headerlink" title="4．优化器"></a>4．优化器</h5><p>优化器就是使用某种数值方法在不断的批次训练中不断更新权重与偏差，使损失函数的误差值最小化，并最终找出误差值最小的“权重与偏差的组合”。</p>
<p>在深度学习中，通常使用随机梯度下降法（Stochastic GradientDescent，SGD）来对“权重与偏差的组合”进行优化。随机梯度下降法可以想象成在所有“权重与偏差的组合”组成的高维度空间中，每个训练批次沿着每个维度下降的方向走一小步，经过许多次步骤，就可以找到优化的“权重与偏差的组合”。</p>
<p>▶ 二维权重与损失函数</p>
<p>真实的深度学习中权重与偏差数量很多，会形成非常多维的空间。</p>
<p>为了方便说明，我们假设最简单的情况，即只有两个权重weight1（ _w_ 1）与weight2（ _w_ 2）。因为只有两个权重，所以可以把 _w_ 1与_w_ 2画成如图2-11所示的二维图形。</p>
<p><img src="Image00037.jpg" alt></p>
<p>图2-11</p>
<p>图2-11说明如下：</p>
<ul>
<li>_x_ 轴是weight1（ _w_ 1）。</li>
<li>_y_ 轴是weight2（ _w_ 2）。</li>
<li>损失函数输入两个参数： _w_ 1与 _w_ 2。</li>
</ul>
<p>按照Loss（ _w_ 1， _w_ 2）的数值可以画出由多个椭圆形所组成的等高线，颜色越深，代表Loss数值越小。</p>
<p>▶ SGD梯度下降法</p>
<p>SGD梯度下降法就是每次沿着Loss下降的方向每个训练批次走一小步，经过许多次训练步骤就能够下降到Loss＝0.1，损失函数的误差最小化，如图2-12所示。</p>
<p><img src="Image00038.jpg" alt></p>
<p>图2-12</p>
<p>梯度下降法，用比较通俗的说法就是：一个在山上的人正在寻找山谷最低点（试图找到损失函数Loss的极小值）。因为大雾能见度低，看不见下山的道路，所以他必须利用局部信息来找到极小值。他使用梯度下降法，观察当前位置处的陡峭程度（梯度），然后沿着（下降梯度）最大的方向前进。使用此方法不断前进，最终找到山谷最低点。</p>
<p>另外，还有许多随机梯度下降法的变形，如RMSprop、Adagrad、Adadelta、Adam等，适用于不同的深度学习模型。</p>
<p>不同的优化器具有不同的训练效果，你可以参考这个网页的说明：</p>
<p><a href="http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html" target="_blank" rel="noopener">http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html</a></p>
<p>此网页上的图以动态方式显示出不同的优化器，以不同的路径找到Loss的最小值。</p>
<h3 id="2-5-结论"><a href="#2-5-结论" class="headerlink" title="2.5 结论"></a>2.5 结论</h3><p>本章我们介绍了深度学习类神经网络原理，并介绍了如何以矩阵数学公式来仿真类神经网络的运行。接下来将介绍TensorFlow与Keras，可以让我们构建各种深度的学习模型。如果读者有些地方还看不懂，没有关系，只需要有基本概念，后续章节配合程序看就会清楚了。</p>
<h1 id="第3章-TensorFlow与Keras介绍"><a href="#第3章-TensorFlow与Keras介绍" class="headerlink" title="第3章 TensorFlow与Keras介绍"></a>第3章 TensorFlow与Keras介绍</h1><p>本章将介绍TensorFlow与Keras的概念和程序设计模式。TensorFlow功能强大，执行效率高，支持各种平台，然而属于低级的深度学习链接库，学习门槛高。所以本书先介绍Keras，它是高级的深度学习链接库，对初学者学习门槛低，可以很容易地建立深度学习模型，并且进行训练、预测。等读者熟悉深度学习模型概念之后，再来学习TensorFlow就比较轻松了。</p>
<p>在第2章中，我们学习了深度学习的核心概念，是以张量（矩阵）运算模拟神经网络的。因此TensorFlow的主要设计就是让矩阵运算达到最高性能，并且能够在各种不同的平台执行。TensorFlow最初由Google（谷歌）公司的BrainTeam团队开发，Google公司使用TensorFlow进行研究及自身产品开发，并于2015年11月公开了源代码，在Apache2.0与开放源代码规范下，所有的开发者都可以免费使用。Google的很多产品早就使用了机器学习或深度学习，例如Gmail过滤垃圾邮件、Google语音识别、Google图像识别、Google翻译等。</p>
<p>TensorFlow功能强大又好用，Google为什么要开放源代码呢？Google认为机器学习是创新技术，而且是未来技术的关键，这方面的研究是全球性而且增长快速的，但是缺乏共同的标准。Google希望通过开源社区的分享建立一个庞大的社区，并且建立共同的标准，这样可以扩展各种深度学习的应用领域，让TensorFlow更加完善。</p>
<h3 id="3-1-TensorFlow架构图"><a href="#3-1-TensorFlow架构图" class="headerlink" title="3.1 TensorFlow架构图"></a>3.1 TensorFlow架构图</h3><p>TensorFlow架构图说明如图3-1所示。</p>
<p><img src="Image00039.jpg" alt></p>
<p>图3-1</p>
<p>参照以上的架构图，我们自下而上进行说明。</p>
<p>▶ 处理器：TensorFlow可以在CPU、GPU、TPU中执行</p>
<ul>
<li><strong>CPU：</strong> 每一台计算机都有中央处理器（CPU），可以执行TensorFlow。</li>
<li><strong>GPU：</strong> 图形处理器，GPU含有高达数千个微小且高效率的计算内核，可以发挥并行计算的强大功能。</li>
<li><strong>TPU：</strong> TPU（Tensor Processing Unit）是Google为人工智能（AI）研发的专用芯片，比GPU的计算性能更佳，不过目前只部署在Google数据中心，也许未来会对外销售。</li>
</ul>
<p>▶ 平台：TensorFlow具备跨平台能力，可以在目前主流的平台执行</p>
<p>TensorFlow可以在不需修改程序代码的前提下，让深度学习模型在不同的平台上执行训练，以提升效率。</p>
<ul>
<li><strong>Windows：</strong> 个人计算机最常用的操作系统，让初学者也可以使用。</li>
<li><strong>Linux：</strong> TensorFlow可以在各种版本的Linux操作系统中执行。</li>
<li><strong>Android</strong> ：在Android上运行TensorFlow可以让深度学习进入移动端，Android设备已达到十几亿台，设备的执行性能也日益提升，越来越适合运行TensorFlow。</li>
<li><strong>iOS</strong> ：TensorFlow可以在iOS移动设备或Mac OS中执行。</li>
<li><strong>Raspberry Pi：</strong> 树莓派可以用于开发物联网或机器人，提供人工智能功能。</li>
<li><strong>云端执行：</strong> 可以通过云端大量的服务器加速深度学习模型的训练。</li>
</ul>
<p>▶ TensorFlow Distributed Execution Engine（分布式执行引擎）</p>
<p>在深度学习中，最花时间的就是模型的训练，尤其大型的深度学习模型必须使用大量数据进行训练，需要数天乃至数周之久，TensorFlow具备分布式计算能力，可同时在数百台机器上执行训练模型，大幅缩短模型训练的时间。</p>
<p>▶ 前端程序语言</p>
<p>TensorFlow可以使用多种前端程序语言，例如Python、C＋＋等，但对Python的支持是最好的，Python具有程序代码简明、易学习、高生产力的特质，面向对象、函数式的动态语言，应用非常广泛。</p>
<p>▶ 高级API</p>
<p>TensorFlow是比较低级的深度学习API，所以用程序设计模型时必须自行设计：张量乘积、卷积等底层操作，好处是我们可以自行设计各种深度学习模型，但是缺点是开发时需要编写更多程序代码，并且需要花更多时间。所以网上的开发社区以TensorFlow为底层开发很多高级的深度学习API，例如Keras、TF-Learn、TF-Slim、TF-Layer等。</p>
<p>这样让开发者使用更简洁、更可读性的程序代码就可以构建出各种复杂的深度学习模型。本书主要介绍Keras，因为Keras的功能最完整。</p>
<h3 id="3-2-TensorFlow简介"><a href="#3-2-TensorFlow简介" class="headerlink" title="3.2 TensorFlow简介"></a>3.2 TensorFlow简介</h3><p>TensorFlow是由Tensor与Flow所组成的，说明如下：</p>
<p>▶ Tensor（张量）</p>
<p>在数学里，张量是一种几何实体或广义上的“数量”，在此“数量”包含“标量、向量或矩阵”。零维的张量为标量，一维的张量是向量，二维以上的张量是矩阵，如图3-2所示。</p>
<p><img src="Image00040.jpg" alt></p>
<p>图3-2</p>
<p>▶ Flow（数据流）</p>
<p>想象当你到了一个陌生国度，你不会当地的语言，为了到达目的地，最好的方式是画一张地图，告诉司机你要去的目的地，司机则会按照你提供的地图载你前往。</p>
<p>TensorFlow也是相同的概念，为了让TensorFlow可以支持不同的程序设计语言接口，并且让TensorFlow程序可以在各种平台执行，所有的TensorFlow程序都是先建立“计算图”（computationalgraph），这是张量运算和数据处理的流程。</p>
<p>我们可以使用TensorFlow提供的模块以不同的程序设计语言建立“计算图”。TensorFlow提供的模块非常强大，我们可以设计张量运算流程，并且构建各种深度学习或机器学习模型。建立“计算图”完成后，我们就可以在不同的平台上执行“计算图”。</p>
<p>如图3-3所示，这是典型的“计算图”，功能很简单，其算式为 _y_ ＝MatMul（ _x_ ， _w_ ）＋ _b_ （ _x_ 、 _w_ 、 _b_都是张量， _w_ 与 _b_ 先使用随机数进行初始化，使用MatMul将 _x_ 与 _w_ 进行张量乘积，再加上 _b_ ，最后结果是 _y_ ）。</p>
<p><img src="Image00041.jpg" alt></p>
<p>图3-3</p>
<p>在上面的“计算图”中：节点（Node）代表运算，而边（Edge）代表张量的数据流。我们可以想象边就是管线，张量（数据）在管线中流动，以上虚线代表数据流的方向。经过节点运算后，转换为不同的张量（数据）。</p>
<p>图3-3是静态的，不太容易看到数据流动的情况，可以访问TensorFlow官方网站（<a href="https://www.TensorFlow.org/images/tensors_Flowing.gif），查看以动画显示的“计算图”数据的流动。" target="_blank" rel="noopener">https://www.TensorFlow.org/images/tensors_Flowing.gif），查看以动画显示的“计算图”数据的流动。</a></p>
<h3 id="3-3-TensorFlow程序设计模式"><a href="#3-3-TensorFlow程序设计模式" class="headerlink" title="3.3 TensorFlow程序设计模式"></a>3.3 TensorFlow程序设计模式</h3><p>如图3-4所示，TensorFlow程序设计模式的核心是“计算图”，可分为两部分：建立“计算图”与执行“计算图”。</p>
<p><img src="Image00042.jpg" alt></p>
<p>图3-4</p>
<p>图3-4说明如下：</p>
<p>（1）建立“计算图”</p>
<p>我们可以使用TensorFlow提供的模块建立“计算图”。TensorFlow提供的模块非常强大，我们可以设计张量运算流程，并且构建各种深度学习或机器学习模型。</p>
<p>（2）执行“计算图”</p>
<p>建立“计算图”后，我们就可以建立Session执行“计算图”了。在TensorFlow中，Session（原意为会话）的作用是在客户端和执行设备之间建立连接。有了这个连接，就可以将“计算图”在各种不同设备中执行，后续任何与设备之间的数据传输都必须通过Session来进行，并且最后获得执行后的结果。</p>
<h3 id="3-4-Keras介绍"><a href="#3-4-Keras介绍" class="headerlink" title="3.4 Keras介绍"></a>3.4 Keras介绍</h3><p>Keras是一个开放源码的高级深度学习程序库，使用Python编写，能够运行在TensorFlow或Theano之上。其主要作者和维护者是Google公司的工程师FrançoisChollet，以MIT开放源码方式授权。</p>
<p>▶ 为何需要使用Keras</p>
<p>Keras使用最少的程序代码、花费最少的时间就可以建立深度学习模型，进行训练、评估准确率，并进行预测。</p>
<p>相对而言，使用TensorFlow这样低级的链接库虽然可以完全控制各种深度学习模型的细节，但是需要编写更多的程序代码，花费更多时间进行开发。</p>
<p>▶ Keras的工作方式</p>
<p>Keras是一个模型级（model-level）的深度学习链接库，Keras只处理模型的建立、训练、预测等功能。深度学习底层的运行，例如张量（矩阵）运算，Keras必须配合“后端引擎”（backendengine）进行运算。目前Keras提供了两种后端引擎：Theano与TensorFlow。</p>
<p>如图3-5所示，Keras程序员只需要专注于建立模型，至于底层操作细节，例如张量（矩阵）运算，Keras会帮你转化为Theano或TensorFlow相对指令。</p>
<p><img src="Image00043.jpg" alt></p>
<p>图3-5</p>
<p>本书介绍的Keras范例都是使用TensorFlow作为后端引擎的，因为是以TensorFlow作为底层，所以之前章节中所介绍的TensorFlow的好处（例如跨平台与执行性能）就都具备了。</p>
<p>▶ Keras深度学习链接库特色</p>
<ul>
<li>简单快速地建立原型prototyping：Keras具备友好的用户界面、模块化设计、可扩充性。</li>
<li>已经内建各种类神经网络层级，例如卷积层CNN、RNN，可以帮助我们快速建立神经网络模型。</li>
<li>通过后端引擎Theano与TensorFlow，可以在CPU与GPU上运行。</li>
<li>以Keras开发的程序代码更简洁、可读性更高、更容易维护、更具生产力。</li>
<li>Keras的说明文件非常齐全，官方网站上提供的范例也非常浅显易懂。</li>
</ul>
<h3 id="3-5-Keras程序设计模式"><a href="#3-5-Keras程序设计模式" class="headerlink" title="3.5 Keras程序设计模式"></a>3.5 Keras程序设计模式</h3><p>英文成语“piece ofcake”的意思是“非常容易的事”，其实Keras的程序设计模式建立一个深度学习模型很简单，就好像做一个多层蛋糕。首先，建立一个蛋糕架。然后，我们不需要自己做每一层蛋糕，可以选择现成的蛋糕层，例如水果蛋糕层、巧克力蛋糕层等。我们可以指定每一层的“内容”，例如指定装饰水果种类与数量。只需要将每一层蛋糕加入蛋糕架上即可。最后就可以做出一个好吃又美观的多层蛋糕。</p>
<p>如图3-6所示，我们将建立多层感知器（Multilayer Perceptron）模型，输入层（ _x_ ）共有784个神经元，隐藏层（ _h_<br>）共有256个神经元，输出层（ _y_ ）共有10个神经元。建立这样的模型很简单，只需先建立一个蛋糕架，然后将神经网络层一层一层加上去即可。</p>
<p><img src="Image00044.jpg" alt></p>
<p>图3-6</p>
<p>如图3-7所示，我们可以很简单地使用下列程序代码将“输入层”“隐藏层”与“输出层”加入模型中。</p>
<p><img src="Image00045.jpg" alt></p>
<p>图3-7</p>
<p>可以看出，在Keras建立多层感知器很简单。</p>
<h5 id="1．建立Sequential模型"><a href="#1．建立Sequential模型" class="headerlink" title="1．建立Sequential模型"></a>1．建立Sequential模型</h5><p>Sequential模型是多个神经网络层的线性堆叠。我们可以想象Sequential模型是一个蛋糕架，接下来可以加入一层一层的蛋糕。</p>
<p><img src="Image00046.jpg" alt></p>
<h5 id="2．加入“输入层”与“隐藏层”到模型中"><a href="#2．加入“输入层”与“隐藏层”到模型中" class="headerlink" title="2．加入“输入层”与“隐藏层”到模型中"></a>2．加入“输入层”与“隐藏层”到模型中</h5><p>Keras已经内建各种神经网络层（例如Dense层、Conv2d层等），只要在之前建立的模型上加入我们选择的神经网络层就可以了（就好像在“蛋糕架”加入“蛋糕层”一样简单）。</p>
<p>以下程序代码加入“输入层”与“隐藏层”到模型中，就好像加入两层蛋糕。</p>
<p><img src="Image00047.jpg" alt></p>
<h5 id="3．加入“输出层”到模型"><a href="#3．加入“输出层”到模型" class="headerlink" title="3．加入“输出层”到模型"></a>3．加入“输出层”到模型</h5><p>以下程序代码加入“输出层”到模型中，就好像再加入一层蛋糕。</p>
<p><img src="Image00048.jpg" alt></p>
<p>以上基本就完成了多层感知器模型的建立，是不是很简单呢？这里只介绍了Keras程序设计的概念，详细程序代码的解说在后面章节会陆续介绍。</p>
<h3 id="3-6-Keras与TensorFlow比较"><a href="#3-6-Keras与TensorFlow比较" class="headerlink" title="3.6 Keras与TensorFlow比较"></a>3.6 Keras与TensorFlow比较</h3><p>Keras与TensorFlow比较见表3-1。</p>
<p>表3-1 Keras与TensorFlow比较</p>
<p><img src="Image00049.jpg" alt></p>
<p>▶ 轻松学会“深度学习”：先学Keras再学TensorFlow</p>
<p>初学者学习TensorFlow，就好像没有任何摄影经验的人一开始就使用单反相机且使用M（手动）模式，必须学习一大堆有关光圈、快门等的知识，研究了老半天，还是没办法拍出一张像样的照片，会有很大的挫感。</p>
<p>初学者学习Keras，就好像单反相机的初学者先以Auto自动模式来学习界面的构图等，这样就可以很容易地拍出一张张照片，再慢慢地使用P模式、A模式、S模式等，学习步骤自行设定，最后就可以使用M模式，完全掌控了。</p>
<p>本书希望能让初学者很轻松地学会“深度学习”，所以会先介绍Keras再介绍TensorFlow。</p>
<p>因为大部分读者没有接触过深度学习模型，如果一开始就学习TensorFlow，就要面对TensorFlow特殊的程序设计模式，并且还必须自行设计张量（矩阵）的运算，会有很大的挫折感。而先学习Keras可以让读者很容易地建立深度学习模型，并且训练模型，使用模型进行预测。等读者对深度学习模型有了一定认识后，再来学习TensorFlow就不会感觉那么困难了。</p>
<h3 id="3-7-结论"><a href="#3-7-结论" class="headerlink" title="3.7 结论"></a>3.7 结论</h3><p>本章我们介绍了TensorFlow与Keras的功能，并分别介绍了它们的程序设计模式。后续章节将介绍TensorFlow与Keras的安装，读者可以自行决定要使用Windows或Linux操作系统，我们将在第4章介绍Windows安装，在第5章介绍LinuxUbuntu安装。</p>
<h1 id="第4章-在Windows中安装TensorFlow与Keras"><a href="#第4章-在Windows中安装TensorFlow与Keras" class="headerlink" title="第4章 在Windows中安装TensorFlow与Keras"></a>第4章 在Windows中安装TensorFlow与Keras</h1><p>本章将介绍在Windows系统中安装TensorFlow与Keras，并且启动JupyterNotebook查看TensorFlow与Keras的版本。新版本的TensorFlow可以在Windows系统中安装，为用户带来很大的方便，毕竟大部分用户使用的都是Windows操作系统。</p>
<p>在TensorFlow官方网站介绍了很多安装TensorFlow的方式，网址如下：</p>
<p><a href="https://www.tensorFlow.org/versions/r0.10/get_started/os_setup" target="_blank" rel="noopener">https://www.tensorFlow.org/versions/r0.10/get_started/os_setup</a></p>
<p>本书只介绍最简单的安装方式，就是以Anaconda安装。安装TensorFlow必须安装Python。而安装Python最方便的方式就是使用软件包来安装。Anaconda是一个Python发行版，其中包含大量的标准数学和科学计算软件包。安装Anaconda软件包时会同时帮我们安装很多软件包，包括JupyterNotebook、NumPy、SciPy、Matplotlib、Pandas这5个用于数据分析、科学计算的常用软件包。</p>
<h3 id="4-1-安装Anaconda"><a href="#4-1-安装Anaconda" class="headerlink" title="4.1 安装Anaconda"></a>4.1 安装Anaconda</h3><p>安装Anaconda的步骤如下。</p>
<p><img src="Image00050.jpg" alt> 下载Anaconda网址。</p>
<p>先打开浏览器，输入下列网址，显示出如图4-1所示的网页：<a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">https://www.continuum.io/downloads</a></p>
<p><img src="Image00051.jpg" alt></p>
<p>图4-1</p>
<p><img src="Image00052.jpg" alt> 运行下载后的Anaconda，如图4-2所示。</p>
<p><img src="Image00053.jpg" alt></p>
<p>图4-2</p>
<p><img src="Image00054.jpg" alt> 单击Next按钮，如图4-3所示。</p>
<p><img src="Image00055.jpg" alt></p>
<p>图4-3</p>
<p><img src="Image00056.jpg" alt> 单击I Agree按钮，如图4-4所示。</p>
<p><img src="Image00057.jpg" alt></p>
<p>图4-4</p>
<p><img src="Image00058.jpg" alt> 单击Next按钮，如图4-5所示。</p>
<p><img src="Image00059.jpg" alt></p>
<p>图4-5</p>
<p><img src="Image00060.jpg" alt> 设置安装目录，如图4-6所示。</p>
<p><img src="Image00061.jpg" alt></p>
<p>图4-6</p>
<p><img src="Image00062.jpg" alt> 设置Anaconda，如图4-7所示。</p>
<p><img src="Image00063.jpg" alt></p>
<p>图4-7</p>
<p><img src="Image00064.jpg" alt> 安装完成，如图4-8所示。</p>
<p><img src="Image00065.jpg" alt></p>
<p>图4-8</p>
<h3 id="4-2-启动命令提示符"><a href="#4-2-启动命令提示符" class="headerlink" title="4.2 启动命令提示符"></a>4.2 启动命令提示符</h3><p>在Linux系统我们会使用“终端”程序输入命令，在Windows系统我们将使用“命令提示符”程序来输入命令。</p>
<p><img src="Image00066.jpg" alt> 启动命令提示符程序，如图4-9所示。</p>
<p><img src="Image00067.jpg" alt></p>
<p>图4-9</p>
<p><img src="Image00068.jpg" alt> 打开命令提示符窗口，如图4-10所示。</p>
<p>在命令提示符窗口中可以输入命令。注意，命令提示符界面默认的输入法是微软的拼音输入法，按Ctrl＋【空格】组合键可切换为英文输入法，再输入命令。</p>
<p><img src="Image00069.jpg" alt></p>
<p>图4-10</p>
<p><img src="Image00070.jpg" alt> 设置命令提示符窗口，如图4-11所示。</p>
<p>因为计算机屏幕上默认的“黑底白字”在书上印刷看起来不清楚，所以后续会改为“白底黑字”。单击菜单图标，选择“属性”选项开始进行设置。</p>
<p><img src="Image00071.jpg" alt></p>
<p>图4-11</p>
<p><img src="Image00072.jpg" alt> 设置命令提示符的背景颜色，如图4-12所示。</p>
<p><img src="Image00073.jpg" alt></p>
<p>图4-12</p>
<p><img src="Image00074.jpg" alt> 设置命令提示符的文字颜色，如图4-13所示。</p>
<p><img src="Image00075.jpg" alt></p>
<p>图4-13</p>
<p><img src="Image00076.jpg" alt> 设置完成后的命令提示符窗口，如图4-14所示。</p>
<p><img src="Image00077.jpg" alt></p>
<p>图4-14</p>
<p>上面的屏幕显示界面出现后，命令提示符就是用户的目录。我们可以在此输入命令。</p>
<h3 id="4-3-建立TensorFlow的Anaconda虚拟环境"><a href="#4-3-建立TensorFlow的Anaconda虚拟环境" class="headerlink" title="4.3 建立TensorFlow的Anaconda虚拟环境"></a>4.3 建立TensorFlow的Anaconda虚拟环境</h3><p>为什么要使用Anaconda虚拟环境安装TensorFlow？因为在一台计算机中，我们常常需要安装很多软件，但是每个软件所需要的Python的关联模块或版本都不相同。</p>
<p>例如，我们要使用Python开发网站系统，安装的网站框架可能需要Python 3.x的版本，但是要安装TensorFlow需要Python3.5的版本，此时就会发生版本不一致的问题。为了解决这个问题，我们可以使用Anaconda虚拟环境来安装，让网站框架与TensorFlow分别安装在不同的虚拟环境中，这样就不会有版本不一致的问题了。</p>
<p>另外，本书会分别介绍如何使用CPU与GPU执行TensorFlow与Keras。然而，CPU与GPU所需要安装的TensorFlow版本不一样，所以我们会分别建立CPU与GPU的虚拟环境，方便后续测试CPU与GPU的执行性能。</p>
<h5 id="1．建立工作目录"><a href="#1．建立工作目录" class="headerlink" title="1．建立工作目录"></a>1．建立工作目录</h5><p>在命令提示符窗口输入下列命令：</p>
<p>▶ 建立并且切换到工作目录</p>
<p><img src="Image00078.jpg" alt></p>
<p>执行后屏幕显示界面如图4-15所示。</p>
<p><img src="Image00079.jpg" alt></p>
<p>图4-15</p>
<h5 id="2．建立Anaconda虚拟环境"><a href="#2．建立Anaconda虚拟环境" class="headerlink" title="2．建立Anaconda虚拟环境"></a>2．建立Anaconda虚拟环境</h5><p>下面使用conda命令建立一个新的Python 3.5Anaconda虚拟环境，我们将虚拟环境命名为TensorFlow。这个虚拟环境将用来安装TensorFlow的CPU版本。在命令提示符窗口输入下列命令：</p>
<p>▶ 建立TensorFlow Anaconda虚拟环境</p>
<p><img src="Image00080.jpg" alt></p>
<p>以上命令说明见表4-1。</p>
<p>表4-1 命令说明</p>
<p><img src="Image00081.jpg" alt></p>
<p>执行后屏幕显示界面如图4-16所示。</p>
<p><img src="Image00082.jpg" alt></p>
<p>图4-16</p>
<p>按Y键之后，就会开始安装Anaconda虚拟环境，并且安装各个软件包。安装完成后屏幕显示界面如图4-17所示。</p>
<p><img src="Image00083.jpg" alt></p>
<p>图4-17</p>
<h5 id="3．启动Anaconda虚拟环境"><a href="#3．启动Anaconda虚拟环境" class="headerlink" title="3．启动Anaconda虚拟环境"></a>3．启动Anaconda虚拟环境</h5><p>建立TensorFlow的Anaconda虚拟环境后，就可以启动这个虚拟环境了。在命令提示符窗口输入下列命令：</p>
<p>▶ 启动Anaconda虚拟环境</p>
<p><img src="Image00084.jpg" alt></p>
<p>执行后屏幕显示界面如图4-18所示。</p>
<p><img src="Image00085.jpg" alt></p>
<p>图4-18</p>
<h5 id="4．关闭TensorFlow的Anaconda虚拟环境"><a href="#4．关闭TensorFlow的Anaconda虚拟环境" class="headerlink" title="4．关闭TensorFlow的Anaconda虚拟环境"></a>4．关闭TensorFlow的Anaconda虚拟环境</h5><p>当我们不再使用TensorFlow的Anaconda虚拟环境后，就可以关闭此虚拟环境。可在命令提示符窗口输入下列命令：</p>
<p>▶ 关闭Anaconda虚拟环境</p>
<p><img src="Image00086.jpg" alt></p>
<p>执行后屏幕显示界面如图4-19所示。</p>
<p><img src="Image00087.jpg" alt></p>
<p>图4-19</p>
<h3 id="4-4-在Anaconda虚拟环境安装TensorFlow与Keras"><a href="#4-4-在Anaconda虚拟环境安装TensorFlow与Keras" class="headerlink" title="4.4 在Anaconda虚拟环境安装TensorFlow与Keras"></a>4.4 在Anaconda虚拟环境安装TensorFlow与Keras</h3><p>之前已经建立了Anaconda虚拟环境，现在要在此虚拟环境中安装TensorFlow与Keras。</p>
<h5 id="1．启动Anaconda虚拟环境"><a href="#1．启动Anaconda虚拟环境" class="headerlink" title="1．启动Anaconda虚拟环境"></a>1．启动Anaconda虚拟环境</h5><p>安装TensorFlow与Keras前，先启动TensorFlow的Anaconda虚拟环境。在命令提示字符窗口输入下列命令：</p>
<p>▶ 启动Anaconda虚拟环境</p>
<p><img src="Image00088.jpg" alt></p>
<p>执行后屏幕显示界面如图4-20所示。</p>
<p><img src="Image00089.jpg" alt></p>
<p>图4-20</p>
<h5 id="2．安装TensorFlow"><a href="#2．安装TensorFlow" class="headerlink" title="2．安装TensorFlow"></a>2．安装TensorFlow</h5><p>在命令提示符窗口中输入下列命令：</p>
<p>▶ 安装TensorFlow CPU版本</p>
<p><img src="Image00090.jpg" alt></p>
<p>执行后屏幕显示界面如图4-21所示。</p>
<p><img src="Image00091.jpg" alt></p>
<p>图4-21</p>
<h5 id="3．安装Keras"><a href="#3．安装Keras" class="headerlink" title="3．安装Keras"></a>3．安装Keras</h5><p>在命令提示符窗口输入下列命令：</p>
<p>▶ 安装Keras</p>
<p><img src="Image00092.jpg" alt></p>
<p>执行后屏幕显示界面如图4-22所示。</p>
<p><img src="Image00093.jpg" alt></p>
<p>图4-22</p>
<h3 id="4-5-启动Jupyter-Notebook"><a href="#4-5-启动Jupyter-Notebook" class="headerlink" title="4.5 启动Jupyter Notebook"></a>4.5 启动Jupyter Notebook</h3><p>之前已经在Anaconda虚拟环境安装了TensorFlow与Keras，现在我们要在JupyterNotebook查看TensorFlow与Keras的版本。JupyterNotebook具备交互式界面，在Web界面输入Python命令后，可以立刻看到结果。我们还可以将数据分析的过程、执行后的命令与结果存储成笔记本。下次打开笔记本时，可以重新执行这些命令。JupyterNotebook笔记本可以包含文字、数学公式、程序代码、结果、图形和视频。</p>
<p>因为Jupyter Notebook是功能强大的交互式界面，所以在后续章节介绍的范例程序也会使用JupyterNotebook示范TensorFlow与Keras指令。</p>
<h5 id="1．启动Jupyter-Notebook"><a href="#1．启动Jupyter-Notebook" class="headerlink" title="1．启动Jupyter Notebook"></a>1．启动Jupyter Notebook</h5><p>在4.3节，当我们建立TensorFlow的Anaconda虚拟环境时，也同时安装了JupyterNotebook，所以不需要再安装，直接启动即可。启动Jupyter Notebook时先确认：</p>
<p>（1）切换至工作目录，后续Jupyter Notebook读取与存盘都会在此工作目录。</p>
<p>（2）确认已经启动TensorFlow的Anaconda虚拟环境，因为我们之前安装TensorFlow与Keras是在虚拟环境中，如果尚未启动这个虚拟环境就打开JupyterNotebook，那么执行TensorFlow与Keras程序时会出现ModuleNotFoundError错误。</p>
<p>在命令提示符窗口输入下列命令：</p>
<p>▶ 切换工作目录</p>
<p><img src="Image00094.jpg" alt></p>
<p>▶ 启动Anaconda虚拟环境</p>
<p><img src="Image00095.jpg" alt></p>
<p>▶ 启动Jupyter Notebook</p>
<p><img src="Image00096.jpg" alt></p>
<p>执行后屏幕显示界面如图4-23所示。</p>
<p>在图4-23所示的运行界面中，输入Jupyter Notebook并按Enter键后，就会自动打开Jupyter Notebook的Web界面。</p>
<p><img src="Image00097.jpg" alt></p>
<p>图4-23</p>
<h5 id="2．建立新的Notebook"><a href="#2．建立新的Notebook" class="headerlink" title="2．建立新的Notebook"></a>2．建立新的Notebook</h5><p>进入Jupyter Notebook界面后，可以按照如图4-24所示的步骤新建NoteBook。</p>
<p><img src="Image00098.jpg" alt></p>
<p>图4-24</p>
<p>新建JupyterNotebook后会打开浏览器新的页面，NoteBook默认的名称是Untitled，我们可以单击Untitled来修改NoteBook的名称，如图4-25所示。</p>
<p><img src="Image00099.jpg" alt></p>
<p>图4-25</p>
<p>输入新的名称，然后单击OK按钮，如图4-26所示。</p>
<p><img src="Image00100.jpg" alt></p>
<p>图4-26</p>
<h5 id="3．Jupyter-Notebook输入命令的方式"><a href="#3．Jupyter-Notebook输入命令的方式" class="headerlink" title="3．Jupyter Notebook输入命令的方式"></a>3．Jupyter Notebook输入命令的方式</h5><p>在JupyterNotebook的Cell（程序单元格）中输入程序代码，然后按Shift＋Enter或Ctrl＋Enter组合键来执行程序代码。这两种方式的差异如下。</p>
<ul>
<li>Shift＋Enter：执行后，光标会移到下一个程序单元格。</li>
<li>Ctrl＋Enter：执行后，光标仍在当前的程序单元格。</li>
</ul>
<h5 id="4．导入TensorFlow模块"><a href="#4．导入TensorFlow模块" class="headerlink" title="4．导入TensorFlow模块"></a>4．导入TensorFlow模块</h5><p>在程序单元格输入下列命令，然后按Shift＋Enter组合键，执行程序代码：</p>
<p>▶ 导入TensorFlow模块，后续以tf来引用这个模块</p>
<p><img src="Image00101.jpg" alt></p>
<p>执行结果如图4-27所示。</p>
<p><img src="Image00102.jpg" alt></p>
<p>图4-27</p>
<p>以上命令执行后，并没有任何输出（没有消息就是好消息），代表导入TensorFlow模块没有任何问题。</p>
<p>如果TensorFlow安装有问题，就会显示错误信息。</p>
<h5 id="5．查看TensorFlow版本"><a href="#5．查看TensorFlow版本" class="headerlink" title="5．查看TensorFlow版本"></a>5．查看TensorFlow版本</h5><p>接下来，我们就可以查看TensorFlow版本了。在程序单元格输入下列命令：</p>
<p>▶ 查看TensorFlow版本</p>
<p><img src="Image00103.jpg" alt></p>
<p>执行结果如图4-28所示。</p>
<p><img src="Image00104.jpg" alt></p>
<p>图4-28</p>
<p>Jupyter Notebook执行后屏幕显示界面如图4-29所示。</p>
<p><img src="Image00105.jpg" alt></p>
<p>图4-29</p>
<h5 id="6．导入Keras模块"><a href="#6．导入Keras模块" class="headerlink" title="6．导入Keras模块"></a>6．导入Keras模块</h5><p>在Jupyter Notebook的程序单元格输入程序代码。</p>
<p>▶ 导入Keras模块</p>
<p><img src="Image00106.jpg" alt></p>
<p>执行结果如图4-30所示。</p>
<p><img src="Image00107.jpg" alt></p>
<p>图4-30</p>
<p>因为已经同时安装了Keras与TensorFlow，所以导入Keras模块后，我们可以看到Keras自动以TensorFlow作为Backend（后端）。</p>
<h5 id="7．查看Keras版本"><a href="#7．查看Keras版本" class="headerlink" title="7．查看Keras版本"></a>7．查看Keras版本</h5><p>在Jupyter Notebook的程序单元格输入如图4-31所示的程序代码，查看Keras版本。</p>
<p><img src="Image00108.jpg" alt></p>
<p>图4-31</p>
<p>以上执行结果显示Keras版本是2.0.2。</p>
<h5 id="8．保存Notebook"><a href="#8．保存Notebook" class="headerlink" title="8．保存Notebook"></a>8．保存Notebook</h5><p>当要退出Notebook时，记得保存，如图4-32所示。</p>
<p><img src="Image00109.jpg" alt></p>
<p>图4-32</p>
<h5 id="9．关闭Notebook"><a href="#9．关闭Notebook" class="headerlink" title="9．关闭Notebook"></a>9．关闭Notebook</h5><p>保存完成后，就可以关闭Notebook网页，步骤如图4-33所示。</p>
<p><img src="Image00110.jpg" alt></p>
<p>图4-33</p>
<h5 id="10．打开之前保存的NoteBook"><a href="#10．打开之前保存的NoteBook" class="headerlink" title="10．打开之前保存的NoteBook"></a>10．打开之前保存的NoteBook</h5><p>回到Jupyter网页，我们可以看到之前保存的test.ipynb。如果要再次打开这个Notebook，单击即可，如图4-34所示。</p>
<p><img src="Image00111.jpg" alt></p>
<p>图4-34</p>
<h5 id="11．关闭Jupyter浏览器（见图4-35）"><a href="#11．关闭Jupyter浏览器（见图4-35）" class="headerlink" title="11．关闭Jupyter浏览器（见图4-35）"></a>11．关闭Jupyter浏览器（见图4-35）</h5><p><img src="Image00112.jpg" alt></p>
<p>图4-35</p>
<h5 id="12．关闭Jupyter-Notebook"><a href="#12．关闭Jupyter-Notebook" class="headerlink" title="12．关闭Jupyter Notebook"></a>12．关闭Jupyter Notebook</h5><p>关闭浏览器后，回到命令提示符窗口，按Ctrl＋C组合键即可关闭Jupyter Notebook程序，如图4-36所示。</p>
<p><img src="Image00113.jpg" alt></p>
<p>图4-36</p>
<h3 id="4-6-结论"><a href="#4-6-结论" class="headerlink" title="4.6 结论"></a>4.6 结论</h3><p>本章我们介绍了如何在Windows中安装TensorFlow与Keras，并且介绍了如何打开JupyterNotebook查看TensorFlow与Keras版本。我们将在第5章介绍如何在Linux Ubuntu中安装TensorFlow与Keras。</p>
<h1 id="第5章-在Linux-Ubuntu中安装TensorFlow与Keras"><a href="#第5章-在Linux-Ubuntu中安装TensorFlow与Keras" class="headerlink" title="第5章 在Linux Ubuntu中安装TensorFlow与Keras"></a>第5章 在Linux Ubuntu中安装TensorFlow与Keras</h1><p>Linux操作系统是大数据分析与机器学习很常用的平台。而Ubuntu是众多Linux操作系统版本中的一种，是一个开放源码、功能强大而且免费的操作系统。本书特别介绍在LinuxUbuntu操作系统中安装TensorFlow 1.0＋Keras 2.0。</p>
<p>本书假设读者已经安装了LinuxUbuntu操作系统，如果需要安装Ubuntu系统有关的资料，可以在网上找到详细的安装步骤，也可以参考笔者的另一本书《Python＋Spark2.0＋Hadoop机器学习与大数据实战》，书中有详细的安装说明。</p>
<h3 id="5-1-安装Anaconda"><a href="#5-1-安装Anaconda" class="headerlink" title="5.1 安装Anaconda"></a>5.1 安装Anaconda</h3><p>安装Anaconda的步骤如下。</p>
<p><img src="Image00114.jpg" alt> 复制安装Anaconda的下载网址。</p>
<p>在浏览器输入下列网址。</p>
<p>▶ 连接到continuum网址</p>
<p><img src="Image00115.jpg" alt></p>
<p>向下浏览，我们可以看到Anaconda for Linux，按照图5-1所示的步骤进行操作。</p>
<p><img src="Image00116.jpg" alt></p>
<p>图5-1</p>
<p><img src="Image00117.jpg" alt> 下载Anaconda3-4.2.0-Linux-x86_64.sh。</p>
<p>先在“终端”程序输入wget再按【空格】键，然后按Ctrl＋Shift＋V组合键来粘贴之前所复制的网址，如图5-2所示。</p>
<p><img src="Image00118.jpg" alt></p>
<p><img src="Image00119.jpg" alt></p>
<p>图5-2</p>
<p><img src="Image00120.jpg" alt> 安装Anaconda。</p>
<p>在“终端”程序输入下列命令，执行Anaconda3-4.2.0-Linux-x86_64.sh。</p>
<p><img src="Image00121.jpg" alt></p>
<p>执行后屏幕显示界面如图5-3所示。</p>
<p><img src="Image00122.jpg" alt></p>
<p>图5-3</p>
<p>以上指令加上“-b”是batch处理安装，会自动省略。阅读License条款，并自动安装到路径／home/hduser/anaconda2下。</p>
<p><img src="Image00123.jpg" alt> 编辑～／.bashrc加入模块路径。</p>
<p>可以在“终端”程序中输入下列命令编辑～/.bashrc：</p>
<p><img src="Image00124.jpg" alt></p>
<p>打开编辑器屏幕显示界面，输入如图5-4所示的内容，输入完成后单击“保存”按钮。</p>
<p><img src="Image00125.jpg" alt></p>
<p>图5-4</p>
<p><img src="Image00126.jpg" alt> 使得～／.bashrc的修改生效。</p>
<p>我们可以通过重新注销再登录，或使用下列命令让用户环境变量的设置生效（见图5-5）：</p>
<p><img src="Image00127.jpg" alt></p>
<p><img src="Image00128.jpg" alt></p>
<p>图5-5</p>
<p><img src="Image00129.jpg" alt> 查看Python版本。</p>
<p>可以在“终端”程序中输入下列命令：</p>
<p><img src="Image00130.jpg" alt></p>
<p>执行后屏幕显示界面如图5-6所示，我们可以看到版本是Anaconda 4.2.0。</p>
<p><img src="Image00131.jpg" alt></p>
<p>图5-6</p>
<p>5.2 安装TensorFlow与Keras</p>
<p>安装TensorFlow与Keras的步骤如下。</p>
<p><img src="Image00132.jpg" alt> 安装TensorFlow。</p>
<p>在“终端”程序中输入下列命令。</p>
<p>▶ 安装TensorFlow（见图5-7）</p>
<p><img src="Image00133.jpg" alt></p>
<p><img src="Image00134.jpg" alt></p>
<p>图5-7</p>
<p><img src="Image00135.jpg" alt> 安装Keras。</p>
<p>在“终端”程序中输入下列命令。</p>
<p>▶ 安装Keras（见图5-8）</p>
<p><img src="Image00136.jpg" alt></p>
<p><img src="Image00137.jpg" alt></p>
<p>图5-8</p>
<h3 id="5-3-启动Jupyter-Notebook"><a href="#5-3-启动Jupyter-Notebook" class="headerlink" title="5.3 启动Jupyter Notebook"></a>5.3 启动Jupyter Notebook</h3><p>之前已经在Ubuntu Linux系统中安装了TensorFlow与Keras，现在我们要在JupyterNotebook中查看TensorFlow与Keras的版本。</p>
<p>安装Anaconda时，也同时安装了Jupyter Notebook，所以不需要再单独安装，直接启动即可。</p>
<p><img src="Image00138.jpg" alt> 建立ipynotebook的工作目录。</p>
<p>可以在“终端”程序中输入下列命令，建立并切换到ipynotebook工作目录。</p>
<p><img src="Image00139.jpg" alt></p>
<p>按Enter键后，屏幕显示如图5-9所示。</p>
<p><img src="Image00140.jpg" alt></p>
<p>图5-9</p>
<p><img src="Image00141.jpg" alt> 进入Jupyter Notebook。</p>
<p>进入工作目录后，在“终端”程序中输入下列命令，进入Jupyter Notebook：</p>
<p><img src="Image00142.jpg" alt></p>
<p>按Enter键后，就会启动浏览器，默认的网址是<a href="http://localhost:8888，Jupyter" target="_blank" rel="noopener">http://localhost:8888，Jupyter</a> Notebook的界面如图5-10所示。</p>
<p><img src="Image00143.jpg" alt></p>
<p>图5-10</p>
<p><img src="Image00144.jpg" alt> 启动Jupyter Notebook。</p>
<p>进入Jupyter Notebook界面，如图5-11所示。关于Jupyter Notebook的简易使用说明，可参考4.5节的内容。</p>
<p><img src="Image00145.jpg" alt></p>
<p>图5-11</p>
<h3 id="5-4-结论"><a href="#5-4-结论" class="headerlink" title="5.4 结论"></a>5.4 结论</h3><p>本章介绍了如何在Linux Ubuntu中安装TensorFlow与Keras，并且介绍了如何打开JupyterNotebook来查看TensorFlow与Keras版本。从下一章开始，我们将开始使用Keras来设计程序。</p>
<h1 id="第6章-Keras-MNIST手写数字识别数据集"><a href="#第6章-Keras-MNIST手写数字识别数据集" class="headerlink" title="第6章 Keras MNIST手写数字识别数据集"></a>第6章 Keras MNIST手写数字识别数据集</h1><p>本章将介绍MNIST手写数字识别数据集，这是由Yann LeCun所搜集的，他也是Convolution NeuralNetworks的创始人。MNIST数字文字识别数据集数据量不会太多，而且是单色的图像，比较简单，很适合深度学习的初学者用来练习建立模型、训练、预测。</p>
<p>MNIST数据集共有训练数据60 000项、测试数据10000项。MNIST数据集中的每一项数据都由images（数字图像）与labels（真实的数字）所组成，如图6-1所示。</p>
<p><img src="Image00146.jpg" alt></p>
<p>图6-1</p>
<p>有关本章的完整程序代码参考范例程序Keras_Mnist_Introduce.ipynb。范例程序的下载与安装参考本书附录A。</p>
<h3 id="6-1-下载MNIST数据"><a href="#6-1-下载MNIST数据" class="headerlink" title="6.1 下载MNIST数据"></a>6.1 下载MNIST数据</h3><p>我们将创建以下Keras程序，下载并读取MNIST数据。</p>
<h5 id="1．导入Keras及相关模块"><a href="#1．导入Keras及相关模块" class="headerlink" title="1．导入Keras及相关模块"></a>1．导入Keras及相关模块</h5><p><img src="Image00147.jpg" alt></p>
<p>因为我们已经同时安装了Keras与TensorFlow，所以导入Keras模块后，可以看到Keras自动以TensorFlow作为Backend。</p>
<p>程序代码说明见表6-1。</p>
<p>表6-1 程序代码说明</p>
<p><img src="Image00148.jpg" alt></p>
<h5 id="2．导入Keras模块"><a href="#2．导入Keras模块" class="headerlink" title="2．导入Keras模块"></a>2．导入Keras模块</h5><p>Keras已经提供了现成的模块，可以帮我们下载并读取MNIST数据，所以先导入MNIST模块。</p>
<p><img src="Image00149.jpg" alt></p>
<h5 id="3．第一次进行MNIST数据的下载"><a href="#3．第一次进行MNIST数据的下载" class="headerlink" title="3．第一次进行MNIST数据的下载"></a>3．第一次进行MNIST数据的下载</h5><p>第一次执行mnist.load_data（）方法，程序会检查用户目录下是否已经有MNIST数据集文件，如果还没有，就会下载文件。以下是第一次下载文件的屏幕显示界面，因为必须要下载文件，所以运行时间会比较长。</p>
<p><img src="Image00150.jpg" alt></p>
<h5 id="4．查看下载的MNIST数据文件"><a href="#4．查看下载的MNIST数据文件" class="headerlink" title="4．查看下载的MNIST数据文件"></a>4．查看下载的MNIST数据文件</h5><p>查看下载的MNIST数据文件，根据所使用的环境是Windows或Linux Ubuntu会有所不同，说明如下。</p>
<p>▶ 在Windows下查看已下载的MNIST数据文件</p>
<p>MNIST数据文件下载后会存储在用户个人的文件夹中，因为笔者的用户名称是kevin，所以下载后会存储在目录C：\Users\kevin\.keras\datasets中，文件名是mnist.npz，如图6-2所示。我们也可以使用文件资源管理器来查看。</p>
<p><img src="Image00151.jpg" alt></p>
<p>图6-2</p>
<p>▶ 在Linux Ubuntu下查看已下载的MNIST数据文件</p>
<p>下载完成后，可以输入下列指令查看目录（见图6-3）：</p>
<p><img src="Image00152.jpg" alt></p>
<p><img src="Image00153.jpg" alt></p>
<p>图6-3</p>
<h5 id="5．读取MNIST数据"><a href="#5．读取MNIST数据" class="headerlink" title="5．读取MNIST数据"></a>5．读取MNIST数据</h5><p>当再次执行mnist.load_data（）时，由于之前已经下载了文件，因此不需要再进行下载，只需要读取文件，这样运行速度就会快很多。</p>
<p><img src="Image00154.jpg" alt></p>
<h5 id="6．查看MNIST数据"><a href="#6．查看MNIST数据" class="headerlink" title="6．查看MNIST数据"></a>6．查看MNIST数据</h5><p>下载后，可以使用下列指令查看MNIST数据集的数据项数。</p>
<p><img src="Image00155.jpg" alt></p>
<p>从以上执行结果可知，数据分为两部分：</p>
<ul>
<li>train训练数据60 000项。</li>
<li>test测试数据10 000项。</li>
</ul>
<h3 id="6-2-查看训练数据"><a href="#6-2-查看训练数据" class="headerlink" title="6.2 查看训练数据"></a>6.2 查看训练数据</h3><p>先查看训练数据。</p>
<h5 id="1．训练数据是由images与labels所组成的"><a href="#1．训练数据是由images与labels所组成的" class="headerlink" title="1．训练数据是由images与labels所组成的"></a>1．训练数据是由images与labels所组成的</h5><p><img src="Image00156.jpg" alt></p>
<p>images与labels共60000项，images是单色的数字图像，labels是数字图像的真实值，如图6-4所示。</p>
<p><img src="Image00157.jpg" alt></p>
<p>图6-4</p>
<h5 id="2．定义plot-image函数显示数字图像"><a href="#2．定义plot-image函数显示数字图像" class="headerlink" title="2．定义plot_image函数显示数字图像"></a>2．定义plot_image函数显示数字图像</h5><p>为了能够显示images数字图像，我们创建下列plot_image函数。</p>
<p><img src="Image00158.jpg" alt></p>
<p>以上程序代码说明见表6-2。</p>
<p>表6-2 程序代码说明</p>
<p><img src="Image00159.jpg" alt></p>
<h5 id="3．执行plot-image函数查看第0个数字图像"><a href="#3．执行plot-image函数查看第0个数字图像" class="headerlink" title="3．执行plot_image函数查看第0个数字图像"></a>3．执行plot_image函数查看第0个数字图像</h5><p>以下程序调用plot_image函数传入mnist.train.images［0］，也就是训练数据集的第0项数据，从显示结果可以看到这是一个数字5的图形。</p>
<p><img src="Image00160.jpg" alt></p>
<h5 id="4．查看第0项label数据"><a href="#4．查看第0项label数据" class="headerlink" title="4．查看第0项label数据"></a>4．查看第0项label数据</h5><p><img src="Image00161.jpg" alt></p>
<p>第0项label数据是第0个数字图像的真实值，所以是5。</p>
<h3 id="6-3-查看多项训练数据images与label"><a href="#6-3-查看多项训练数据images与label" class="headerlink" title="6.3 查看多项训练数据images与label"></a>6.3 查看多项训练数据images与label</h3><p>接下来，我们将创建plot_images_labels_prediction函数，可以显示多项MNIST数据的images与label。</p>
<h5 id="1．创建plot-images-labels-prediction（）函数"><a href="#1．创建plot-images-labels-prediction（）函数" class="headerlink" title="1．创建plot_images_labels_prediction（）函数"></a>1．创建plot_images_labels_prediction（）函数</h5><p>我们希望能很方便地查看数字图形、真实的数字与预测结果，因此创建了下列函数。</p>
<p><img src="Image00162.jpg" alt></p>
<p>▶ 导入pyplot模块，后续会使用plt来引用</p>
<p><img src="Image00163.jpg" alt></p>
<p>▶ 定义plot_images_labels_prediction（）函数</p>
<p><img src="Image00164.jpg" alt></p>
<p>定义plot_images_labels_prediction（）函数需要传入下列参数：</p>
<p>images（数字图像）、label（真实值）、prediction（预测结果）、idx（开始显示的数据index）、num（要显示的数据项数，默认是10，不超过25）。</p>
<p>▶ 设置显示图形的大小</p>
<p><img src="Image00165.jpg" alt></p>
<p>▶ 如果显示项数参数大于25，就设置为25，以免发生错误</p>
<p><img src="Image00166.jpg" alt></p>
<p>▶ for循环执行程序块内的程序代码，画出num个数字图形</p>
<p><img src="Image00167.jpg" alt></p>
<p>查看以上程序代码时可参考注释。</p>
<p>▶ 开始画图</p>
<p><img src="Image00168.jpg" alt></p>
<h5 id="2．查看训练数据前10项数据"><a href="#2．查看训练数据前10项数据" class="headerlink" title="2．查看训练数据前10项数据"></a>2．查看训练数据前10项数据</h5><p>执行plot_images_labels_prediction（）函数显示前10项训练数据。输入x_test_image和y_test_label，不过，目前还没有预测结果（prediction），所以传入空list［］，从第0项数据开始一直显示到第9项数据。</p>
<p><img src="Image00169.jpg" alt></p>
<h5 id="3．查看test测试数据"><a href="#3．查看test测试数据" class="headerlink" title="3．查看test测试数据"></a>3．查看test测试数据</h5><p>查看test测试数据项数，我们可以看到共计10000项数据。</p>
<p><img src="Image00170.jpg" alt></p>
<h5 id="4．显示test测试数据"><a href="#4．显示test测试数据" class="headerlink" title="4．显示test测试数据"></a>4．显示test测试数据</h5><p>执行plot_images_labels_prediction显示前10项测试数据。</p>
<p><img src="Image00171.jpg" alt></p>
<h3 id="6-4-多层感知器模型数据预处理"><a href="#6-4-多层感知器模型数据预处理" class="headerlink" title="6.4 多层感知器模型数据预处理"></a>6.4 多层感知器模型数据预处理</h3><p>在下一章，我们将建立多层感知器模型（MultilayerPerceptron），必须先将images与label的内容进行预处理，才能使用多层感知器模型进行训练与预测。数据预处理分为以下两部分。</p>
<ul>
<li>features（数字图像的特征值）数据预处理：将在6.5节说明</li>
<li>label（数字图像真实的值）数据预处理：将在6.6节说明。</li>
</ul>
<h3 id="6-5-features数据预处理"><a href="#6-5-features数据预处理" class="headerlink" title="6.5 features数据预处理"></a>6.5 features数据预处理</h3><p>features（数字图像的特征值）数据预处理可分为下列两个步骤：</p>
<p>（1）将原本28×28的数字图像以reshape转换为一维的向量，其长度是784，并且转换为Float。</p>
<p>（2）数字图像image的数字标准化。</p>
<p><img src="Image00172.jpg" alt> 查看image的shape。</p>
<p>可以用下列指令查看每一个数字图像的shape是28×28。</p>
<p><img src="Image00173.jpg" alt></p>
<p><img src="Image00174.jpg" alt> 将image以reshape转换。</p>
<p>下面的程序代码将原本28×28的二维数字图像以reshape转换为一维的向量，再以astype转换为Float，共784个浮点数。</p>
<p><img src="Image00175.jpg" alt></p>
<p><img src="Image00176.jpg" alt> 查看转换为一维向量的shape。</p>
<p>可以用下列指令查看每一个数字图像是784个浮点数。</p>
<p><img src="Image00177.jpg" alt></p>
<p><img src="Image00178.jpg" alt> 查看images图像的内容。</p>
<p>查看images第0项的内容。</p>
<p><img src="Image00179.jpg" alt></p>
<p>从以上执行结果可知，大部分都是0，少部分是数字。每一个数字都是从0到255的值，代表图形每一个点灰度的深浅。</p>
<p><img src="Image00180.jpg" alt> 将数字图像images的数字标准化。</p>
<p>images的数字标准化可以提高后续训练模型的准确率，因为images的数字是从0到255的值，所以最简单的标准化方式是除以255。</p>
<p><img src="Image00181.jpg" alt></p>
<p><img src="Image00182.jpg" alt> 查看数字图像images数字标准化后的结果。</p>
<p>使用下列指令查看数字图像images的数字标准化后的结果，都介于0与1之间。</p>
<p><img src="Image00183.jpg" alt></p>
<h3 id="6-6-label数据预处理"><a href="#6-6-label数据预处理" class="headerlink" title="6.6 label数据预处理"></a>6.6 label数据预处理</h3><p>label（数字图像真实的值）标签字段原本是0～9的数字，必须以One-HotEncoding（一位有效编码）转换为10个0或1的组合，例如数字7经过One-HotEncoding转换后是0000000100，正好对应输出层的10个神经元。</p>
<p><img src="Image00184.jpg" alt> 查看原本的label标签字段。</p>
<p>以下列指令来查看训练数据label标签字段的前5项训练数据，我们可以看到这是0～9的数字。</p>
<p><img src="Image00185.jpg" alt></p>
<p><img src="Image00186.jpg" alt> label标签字段进行One-Hot Encoding转换。</p>
<p>下面的程序代码使用np_utils.to_categorical分别传入参数y_train_label（训练数据）与y_test_label（测试数据）的label标签字段，进行One-Hot Encoding转换。</p>
<p><img src="Image00187.jpg" alt></p>
<p><img src="Image00188.jpg" alt> 查看进行One-Hot Encoding转换之后的label标签字段。</p>
<p>进行One-Hot Encoding转换之后，查看训练数据label标签字段的前5项数据，我们可以看到转换后的结果。</p>
<p><img src="Image00189.jpg" alt></p>
<p>参考上面的结果，例如第1项数据，原来的真实值是5，进行One-Hot Encoding转换后，只有第5个数字（由0算起）是1，其余都是0。</p>
<h3 id="6-7-结论"><a href="#6-7-结论" class="headerlink" title="6.7 结论"></a>6.7 结论</h3><p>在本章中，我们已经介绍了如何使用Keras下载并且读取MNIST数据集，并介绍了MNIST数据集的特色，也完成了数据的预处理。在下一章，我们可以使用Keras建立多层感知器模型进行训练，并且使用模型进行预测。</p>
<h1 id="第7章-Keras多层感知器识别手写数字"><a href="#第7章-Keras多层感知器识别手写数字" class="headerlink" title="第7章 Keras多层感知器识别手写数字"></a>第7章 Keras多层感知器识别手写数字</h1><p>本章将介绍用Keras建立多层感知器模型，然后训练模型、评估模型的准确率，最后使用训练完成的模型识别MNIST手写数字。</p>
<p>关于多层感知器模型的详细介绍，可参考第2章。</p>
<p>有关本章的完整程序代码可参考范例程序Keras_Mnist_MLP_h256.ipynb。范例程序的下载与安装可参考本书附录A。</p>
<h3 id="7-1-Keras多元感知器识别MNIST手写数字图像的介绍"><a href="#7-1-Keras多元感知器识别MNIST手写数字图像的介绍" class="headerlink" title="7.1 Keras多元感知器识别MNIST手写数字图像的介绍"></a>7.1 Keras多元感知器识别MNIST手写数字图像的介绍</h3><h5 id="1．多层感知器模型的介绍"><a href="#1．多层感知器模型的介绍" class="headerlink" title="1．多层感知器模型的介绍"></a>1．多层感知器模型的介绍</h5><p>为了能够识别MNIST手写数字图像，我们将建立如图7-1所示的多层感知器模型。</p>
<p><img src="Image00190.jpg" alt></p>
<p>图7-1</p>
<h5 id="2．多层感知器的训练与预测"><a href="#2．多层感知器的训练与预测" class="headerlink" title="2．多层感知器的训练与预测"></a>2．多层感知器的训练与预测</h5><p>建立如图7-2所示的多层感知器模型后，必须先训练模型才能够进行预测（识别）这些手写数字。</p>
<p><img src="Image00191.jpg" alt></p>
<p>图7-2</p>
<p>以多层感知器模型识别MNIST数字图像可分为训练与预测。</p>
<p>▶ 训练</p>
<p>MNIST数据集的训练数据共60000项，经过数据预处理后会产生Features（数字图像特征值）与Label（数字真实的值），然后输入多层感知器模型进行训练，训练完成的模型就可以作为下一阶段预测使用。</p>
<p>▶ 预测</p>
<p>输入数字图像，预处理后会产生Features（数字图像特征值），使用训练完成的多层感知器模型进行预测，最后产生预测结果是0～9的数字。</p>
<h5 id="3．建立多层感知器模型的步骤"><a href="#3．建立多层感知器模型的步骤" class="headerlink" title="3．建立多层感知器模型的步骤"></a>3．建立多层感知器模型的步骤</h5><p>多层感知器识别MNIST数据集中的手写数字的步骤说明如图7-3所示。</p>
<p><img src="Image00192.jpg" alt></p>
<p>图7-3</p>
<h3 id="7-2-进行数据预处理"><a href="#7-2-进行数据预处理" class="headerlink" title="7.2 进行数据预处理"></a>7.2 进行数据预处理</h3><p>有关读取MNIST数据集数据并且进行数据预处理的详细介绍可参考第6章。</p>
<p><img src="Image00193.jpg" alt> 导入所需模块。</p>
<p><img src="Image00194.jpg" alt></p>
<p><img src="Image00195.jpg" alt> 读取MNIST数据。</p>
<p><img src="Image00196.jpg" alt></p>
<p><img src="Image00197.jpg" alt> 将features（数字图像特征值）使用reshape转换。</p>
<p>下面的程序代码将原本28×28的数字图像以reshape转换成784个Float数。</p>
<p><img src="Image00198.jpg" alt></p>
<p><img src="Image00199.jpg" alt> 将features（数字图像特征值）标准化。</p>
<p>将features（数字图像特征值）标准化可以提高模型预测的准确度，并且更快收敛。</p>
<p><img src="Image00200.jpg" alt></p>
<p><img src="Image00201.jpg" alt> label（数字真实的值）以One-Hot Encoding进行转换。</p>
<p>使用np_utils.to_categorical将训练数据与测试数据的label进行One-Hot Encoding转换。</p>
<p><img src="Image00202.jpg" alt></p>
<h3 id="7-3-建立模型"><a href="#7-3-建立模型" class="headerlink" title="7.3 建立模型"></a>7.3 建立模型</h3><p>我们将建立下列多层感知器模型，输入层（ _x_ ）共有784个神经元，隐藏层（ _h_ ）共有256个神经元，输出层（ _y_<br>）共有10个神经元，如图7-4所示。我们将使用下面的程序代码建立多层感知器模型。</p>
<p><img src="Image00203.jpg" alt></p>
<p>图7-4</p>
<h5 id="1．导入所需模块"><a href="#1．导入所需模块" class="headerlink" title="1．导入所需模块"></a>1．导入所需模块</h5><p><img src="Image00204.jpg" alt></p>
<h5 id="2．建立Sequential模型"><a href="#2．建立Sequential模型" class="headerlink" title="2．建立Sequential模型"></a>2．建立Sequential模型</h5><p>建立一个线性堆叠模型，后续只需要使用model.add（）方法将各个神经网络层加入模型即可。</p>
<p><img src="Image00205.jpg" alt></p>
<h5 id="3．建立“输入层”与“隐藏层”"><a href="#3．建立“输入层”与“隐藏层”" class="headerlink" title="3．建立“输入层”与“隐藏层”"></a>3．建立“输入层”与“隐藏层”</h5><p>以下程序代码将“输入层”与“隐藏层”加入模型，使用model.add方法加入Dense神经网络层。Dense神经网络层的特色是：所有的上一层与下一层的神经元都完全连接。</p>
<p><img src="Image00206.jpg" alt></p>
<p>建立Dense神经网络层需输入表7-1中的参数。</p>
<p>表7-1 建立Dense神经网络层所需参数</p>
<p><img src="Image00207.jpg" alt></p>
<h5 id="4．建立“输出层”"><a href="#4．建立“输出层”" class="headerlink" title="4．建立“输出层”"></a>4．建立“输出层”</h5><p>使用下面的程序代码建立“输出层”，使用model.add方法加入Dense神经网络层，共有10个神经元，对应0～9十个数字。并且使用softmax激活函数进行转换，softmax可以将神经元的输出转换为预测每一个数字的概率。</p>
<p><img src="Image00208.jpg" alt></p>
<p>建立“输出层”输入表7-2中的参数。</p>
<p>表7-2 建立“输出层”所需参数</p>
<p><img src="Image00209.jpg" alt></p>
<p>以上建立Dense神经网络层不需要设置input_dim，因为Keras会自动按照上一层的units是256个神经元，设置这一层的input_dim为256个神经元。</p>
<h5 id="5．查看模型的摘要"><a href="#5．查看模型的摘要" class="headerlink" title="5．查看模型的摘要"></a>5．查看模型的摘要</h5><p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00210.jpg" alt></p>
<p>执行后屏幕显示界面如图7-5所示。</p>
<p><img src="Image00211.jpg" alt></p>
<p>图7-5</p>
<p>我们可以看到共有以下两层。</p>
<ul>
<li><strong>隐藏层：</strong> 共256个神经元，因为输入层与隐藏层是一起建立的，所以没有显示输入层。</li>
<li><strong>输出层：</strong> 共10个神经元。</li>
</ul>
<h5 id="6．查看模型的摘要Param"><a href="#6．查看模型的摘要Param" class="headerlink" title="6．查看模型的摘要Param"></a>6．查看模型的摘要Param</h5><p>模型的摘要还有Param字段，说明如图7-6所示。</p>
<p><img src="Image00212.jpg" alt></p>
<p>图7-6</p>
<p>以上每一层Param都是超参数（Hyper-Parameters）。我们需要通过反向传播算法更新神经元连接的权重与偏差。可参考第2章的公式。</p>
<p>建立输入层与隐藏层的公式如下：</p>
<p><img src="Image00213.jpg" alt></p>
<p>建立隐藏层与输出层的公式如下：</p>
<p><img src="Image00214.jpg" alt></p>
<p>所以每一层Param计算方式如下：</p>
<p><img src="Image00215.jpg" alt></p>
<ul>
<li>隐藏层的Param是200 960，这是因为：</li>
</ul>
<p><img src="Image00216.jpg" alt></p>
<ul>
<li>输出层的Param是2570，这是因为：</li>
</ul>
<p><img src="Image00217.jpg" alt></p>
<p>所以全部必须训练的超参数（Trainable Params）是每一层的Param的总和，计算方式如下：</p>
<p><img src="Image00218.jpg" alt></p>
<p>通常Trainable Param数值越大，代表此模型越复杂，需要更多时间进行训练。</p>
<h3 id="7-4-进行训练"><a href="#7-4-进行训练" class="headerlink" title="7.4 进行训练"></a>7.4 进行训练</h3><p>在我们建立好深度学习模型之后，就可以使用反向传播算法进行训练了，可参考第2章使用反向传播算法进行训练的说明。</p>
<h5 id="1．定义训练方式"><a href="#1．定义训练方式" class="headerlink" title="1．定义训练方式"></a>1．定义训练方式</h5><p>在训练模型之前，我们必须使用compile方法对训练模型进行设置，指令如下：</p>
<p><img src="Image00219.jpg" alt></p>
<p>compile方法需输入下列参数。</p>
<ul>
<li><strong>loss：</strong> 设置损失函数，在深度学习中使用cross_entropy（交叉熵）训练的效果比较好。</li>
<li><strong>optimizer：</strong> 设置训练时，在深度学习中使用adam优化器可以让训练更快收敛，并提高准确率。</li>
<li><strong>metrics：</strong> 设置评估模型的方式是准确率。</li>
</ul>
<h5 id="2．开始训练"><a href="#2．开始训练" class="headerlink" title="2．开始训练"></a>2．开始训练</h5><p>执行训练的程序代码如下：</p>
<p><img src="Image00220.jpg" alt></p>
<p>以上程序代码说明如下：</p>
<p>使用model.fit进行训练，训练过程会存储在train_history变量中，需输入下列参数。</p>
<p>（1）输入训练数据参数</p>
<ul>
<li>_x_ ＝ _x_ _Train_normalize（features数字图像的特征值）。</li>
<li>_y_ ＝ _y_ _Train_Onehot（label数字图像真实的值）。</li>
</ul>
<p>（2）设置训练与验证数据比例</p>
<ul>
<li>设置参数validation_split＝0.2。</li>
</ul>
<p>训练之前Keras会自动将数据分成：80%作为训练数据，20%作为验证数据。因为全部数据是60 000项，所以分成：60 000×0.8＝48000项作为训练数据，60 000×0.2＝12 000项作为验证数据。</p>
<p>（3）设置epoch（训练周期）次数与每一批次项数</p>
<ul>
<li>epochs＝10：执行10个训练周期。</li>
<li>batch_size＝200：每一批次200项数据。</li>
</ul>
<p>（4）设置显示训练过程</p>
<ul>
<li>verbose＝2：显示训练过程。</li>
</ul>
<p>以上程序代码共执行了10次训练周期，每一次训练执行下列功能：</p>
<ul>
<li>使用48 000项训练数据进行训练，分为每一批次200项，所以大约分为240个批次（48 000/200＝240）进行训练。</li>
<li>训练完成后，会计算这个训练周期的准确率与误差，并且在train_history中新增一项数据记录。</li>
</ul>
<p>▶ 以上程序代码执行后的结果如图7-7所示。</p>
<p><img src="Image00221.jpg" alt></p>
<p>图7-7</p>
<p>从以上执行结果可知，共执行了10个训练周期，并可以发现误差越来越小，准确率越来越高。</p>
<h5 id="3．建立show-train-history显示训练过程"><a href="#3．建立show-train-history显示训练过程" class="headerlink" title="3．建立show_train_history显示训练过程"></a>3．建立show_train_history显示训练过程</h5><p>之前的训练步骤会将每一个训练周期的准确率与误差记录在train_history变量中。我们可以使用下面的程序代码读取train_history，以图表显示训练过程。</p>
<p><img src="Image00222.jpg" alt></p>
<p>程序代码说明如见表7-3。</p>
<p>表7-3 程序代码说明</p>
<p><img src="Image00223.jpg" alt></p>
<h5 id="4．画出准确率执行结果"><a href="#4．画出准确率执行结果" class="headerlink" title="4．画出准确率执行结果"></a>4．画出准确率执行结果</h5><p>下面的程序代码画出了准确率评估的执行结果，如图7-8所示。</p>
<p><img src="Image00224.jpg" alt></p>
<p>图7-8</p>
<p>在以上执行后的屏幕显示界面中，“acc训练的准确率”是蓝色（深色）的，“val_acc验证的准确率”是黄色（浅色）的，（注意，本书是单色印刷，看不到蓝色和黄色，以深浅区分）。以上共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，准确率都越来越高。</li>
<li>在epoch训练后期，“acc训练的准确率”比“val_acc验证的准确率”高。</li>
</ul>
<p>▶ 为何“acc训练的准确率”比“val_acc验证的准确率”高？</p>
<p>这是因为计算准确率的数据不同。</p>
<ul>
<li>acc训练的准确率：以训练的数据来计算准确率，因为相同的数据已经训练过了，又拿来计算准确率，所以准确率会比较高（就好像老师上课后，又使用上课的题目进行考试，准确率会比较高）。</li>
<li>val_acc验证的准确率：以验证数据来计算准确率，这些验证数据在之前训练时并未拿来训练，所以计算的准确率会比较低。但是，这样计算出来的准确率比较客观，比较符合真实情况（就好像老师上课后，使用独立的题库进行考试，这样学生考试的准确率没有那么高，但是比较客观反映学生的真实水平）。</li>
</ul>
<p>如果“acc训练的准确率”一直增加，但是“val_acc验证的准确率”一直没有增加，就可能是过度拟合（overfitting）的现象。从以上的图形我们可以看到，“acc训练的准确率”比“val_acc验证的准确率”高，虽然差异不是很大，但仍有轻微过度拟合的现象。</p>
<p>▶ 过度拟合的现象</p>
<p>什么是过度拟合呢？</p>
<p>如图7-9所示，有两个分类圆形与星形，我们希望训练后找出一条线，可以将圆形与星形进行分类。实线是我们希望找到的最佳分类线，可是训练过程太久或范例太少会导致虚线过度适应训练数据中特化且随机的特征。其结果是虽然在训练时准确率高，但是使用未知数据时的准确率低。在后续章节介绍深度学习时，再讲述如何处理过度拟合现象。</p>
<p><img src="Image00225.jpg" alt></p>
<p>图7-9</p>
<p>▶ 以测试数据评估模型准确率</p>
<p>在完成所有训练周期之后，在7.4节我们还会以测试数据评估模型准确率，这是另一组独立的数据，所以计算准确率会更客观（就好像老师上了一个学期课之后，使用另一组独立的题库进行考试，就像期末考试一样，这样考试的结果才比较客观）。</p>
<h5 id="5．画出误差执行结果（见图7-10）"><a href="#5．画出误差执行结果（见图7-10）" class="headerlink" title="5．画出误差执行结果（见图7-10）"></a>5．画出误差执行结果（见图7-10）</h5><p><img src="Image00226.jpg" alt></p>
<p>图7-10</p>
<p>在上面执行结果的屏幕显示界面中，“loss训练的误差”是深色的，“val_loss验证的误差”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，验证的误差都越来越低。</li>
<li>在Epoch训练后期，“loss训练的误差”比“val_loss验证的误差”小。</li>
</ul>
<h3 id="7-5-以测试数据评估模型准确率"><a href="#7-5-以测试数据评估模型准确率" class="headerlink" title="7.5 以测试数据评估模型准确率"></a>7.5 以测试数据评估模型准确率</h3><p>之前我们已经完成了训练，现在要使用test测试数据来评估模型准确率。</p>
<h5 id="1．评估模型准确率"><a href="#1．评估模型准确率" class="headerlink" title="1．评估模型准确率"></a>1．评估模型准确率</h5><p>下面的程序代码用于评估模型准确率。</p>
<p><img src="Image00227.jpg" alt></p>
<p>以上程序代码的执行结果是准确率为0.97。程序代码的说明见表7-4。</p>
<p>表7-4 程序代码说明</p>
<p><img src="Image00228.jpg" alt></p>
<h3 id="7-6-进行预测"><a href="#7-6-进行预测" class="headerlink" title="7.6 进行预测"></a>7.6 进行预测</h3><p>通过之前的步骤，我们建立了模型，并且完成了模型训练，准确率达到还可以接受的0.97，接下来我们将使用此模型进行预测。</p>
<h5 id="1．执行预测"><a href="#1．执行预测" class="headerlink" title="1．执行预测"></a>1．执行预测</h5><p>我们可以用下列指令执行预测。</p>
<p><img src="Image00229.jpg" alt></p>
<p>上面的程序代码使用model.predict_classes输入参数x_Test（测试数据的数字图像）进行预测，预测结果存储在prediction变量中。</p>
<h5 id="2．预测结果"><a href="#2．预测结果" class="headerlink" title="2．预测结果"></a>2．预测结果</h5><p>我们可以用下列指令来查看预测结果的前10项数据。</p>
<p><img src="Image00230.jpg" alt></p>
<p>可以看到第1项预测的结果是7，第2项预测是2，诸如此类。</p>
<h5 id="3．显示10项预测结果"><a href="#3．显示10项预测结果" class="headerlink" title="3．显示10项预测结果"></a>3．显示10项预测结果</h5><p>使用上一章创建的plot_images_labels_prediction函数显示预测结果，输入参数：x_test_image（测试数据图像）、y_test_label（测试数据真实的值）、prediction（预测结果）和idx＝340（显示第340到349共10项）。</p>
<p><img src="Image00231.jpg" alt></p>
<p>执行后预测结果如图7-11所示。</p>
<p><img src="Image00232.jpg" alt></p>
<p>图7-11</p>
<p>我们可以看到有一项预测错误：label（真实值）是5，但predict（预测值）是3，这个手写数字图像确实挺潦草的，难怪会识别错误。</p>
<h3 id="7-7-显示混淆矩阵"><a href="#7-7-显示混淆矩阵" class="headerlink" title="7.7 显示混淆矩阵"></a>7.7 显示混淆矩阵</h3><p>在上一节中我们看到了一个预测错误：真实值是5，但是预测值是3。如果我们想要进一步知道在所建立的模型中哪些数字的预测准确率最高，哪些数字最容易混淆（例如真实值是5，但是预测值是3），就可以使用混淆矩阵（confusionmatrix）来显示。</p>
<p>在机器学习领域，特别是统计分类的问题，混淆矩阵也称为误差矩阵（errormatrix），是一种特定的表格显示方式，可以让我们以可视化的方式了解有监督的学习算法的结果，看出算法模型是否混淆了两个类（将某一个标签预测成为另一个标签）。</p>
<h5 id="1．使用pandas-crosstab建立混淆矩阵"><a href="#1．使用pandas-crosstab建立混淆矩阵" class="headerlink" title="1．使用pandas crosstab建立混淆矩阵"></a>1．使用pandas crosstab建立混淆矩阵</h5><p>Pandas提供了建立混淆矩阵的功能。</p>
<p><img src="Image00233.jpg" alt></p>
<p>程序代码说明见表7-5。</p>
<p>表7-5 程序代码说明</p>
<p><img src="Image00234.jpg" alt></p>
<p>执行后显示出混淆矩阵，如图7-12所示。</p>
<p><img src="Image00235.jpg" alt></p>
<p>图7-12</p>
<p>从以上混淆矩阵中，我们观察的结果如下：</p>
<ul>
<li><strong>对角线是预测正确的数字，我们发现：</strong> 真实值是“1”，被正确预测为“1”的项数有1125项，预测准确率最高，最不容易混淆。真实值是“5”，被正确预测为“5”的项数有852项最低，也就是说最容易混淆。</li>
<li><strong>其他非对角线的数字代表将某一个标签预测错误，成为另一个标签，我们发现：</strong> 真实值是“5”，但是预测值是“3”。</li>
</ul>
<h5 id="2．建立真实值与预测DataFrame"><a href="#2．建立真实值与预测DataFrame" class="headerlink" title="2．建立真实值与预测DataFrame"></a>2．建立真实值与预测DataFrame</h5><p>因为我们希望能找出真实值是“5”但预测值是“3”的数据，所以创建下列DataFrame。下面的程序代码用来创建DataFrame，包含label（真实值）与prediction（预测值）。</p>
<p><img src="Image00236.jpg" alt></p>
<p>以上执行的结果有两个字段，分别是label与predict。</p>
<h5 id="3．查询真实值是“5”但预测值是“3”的数据"><a href="#3．查询真实值是“5”但预测值是“3”的数据" class="headerlink" title="3．查询真实值是“5”但预测值是“3”的数据"></a>3．查询真实值是“5”但预测值是“3”的数据</h5><p>Pandas DataFrame可以很方便地让我们查询数据。例如下面的程序代码，可以找出真实值是“5”但预测值是“3”的数据。</p>
<p><img src="Image00237.jpg" alt></p>
<p>从以上执行结果可知共有17项，显示前7项结果。</p>
<h5 id="4．查看第340项数据"><a href="#4．查看第340项数据" class="headerlink" title="4．查看第340项数据"></a>4．查看第340项数据</h5><p>我们可以查看第340项结果，真实值是5但预测值为3。</p>
<p><img src="Image00238.jpg" alt></p>
<p>从执行结果来看，这个数字图形看起来像5又像3，所以预测错误。</p>
<h3 id="7-8-隐藏层增加为1000个神经元"><a href="#7-8-隐藏层增加为1000个神经元" class="headerlink" title="7.8 隐藏层增加为1000个神经元"></a>7.8 隐藏层增加为1000个神经元</h3><p>为了增加多层感知器模型的准确率，在本节的范例中将隐藏层原本256个神经元改为1000。有关本节的完整程序代码，请参考范例程序Keras_Mnist_MLP_h1_1000.ipynb。</p>
<p>我们将使用下列程序代码建立多层感知器模型，如图7-13所示。</p>
<p><img src="Image00239.jpg" alt></p>
<p>图7-13</p>
<p><img src="Image00240.jpg" alt> 将隐藏层原本256个神经元改为1000个神经元。</p>
<p><img src="Image00241.jpg" alt></p>
<p><img src="Image00242.jpg" alt> 查看模型的摘要。</p>
<p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00243.jpg" alt></p>
<p>执行后屏幕显示界面如图7-14所示。</p>
<p><img src="Image00244.jpg" alt></p>
<p>图7-14</p>
<p><img src="Image00245.jpg" alt> 开始训练。</p>
<p>从指令执行后的屏幕显示界面中可以看到共执行了10个训练周期，如图7-15所示，从中可以发现误差越来越小，准确率越来越高。</p>
<p><img src="Image00246.jpg" alt></p>
<p>图7-15</p>
<p><img src="Image00247.jpg" alt> 查看训练过程的准确率。</p>
<p>在执行结果界面，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，准确率都越来越高。</li>
<li>在Epoch训练后期，“acc训练的准确率”比“val_acc验证的准确率”高，过度拟合更严重。</li>
</ul>
<p><img src="Image00248.jpg" alt></p>
<p><img src="Image00249.jpg" alt> 预测准确率。</p>
<p><img src="Image00250.jpg" alt></p>
<p>由以上执行结果可知准确率是0.9794。</p>
<h3 id="7-9-多层感知器加入DropOut功能以避免过度拟合"><a href="#7-9-多层感知器加入DropOut功能以避免过度拟合" class="headerlink" title="7.9 多层感知器加入DropOut功能以避免过度拟合"></a>7.9 多层感知器加入DropOut功能以避免过度拟合</h3><p>为了解决过度拟合的问题，在本节的范例中会加入Dropout功能。有关本节的完整程序代码，请参考范例程序Keras_Mnist_MLP_h1_1000_｝DropOut.ipynb。</p>
<p>下面建立多层感知器模型。</p>
<p><img src="Image00251.jpg" alt> 隐藏层改为1000个神经元并且加入DropOut功能，如图7-16所示。</p>
<p><img src="Image00252.jpg" alt></p>
<p>图7-16</p>
<p><img src="Image00253.jpg" alt> 修改隐藏层加入DropOut功能。</p>
<p><img src="Image00254.jpg" alt></p>
<p><img src="Image00255.jpg" alt> 查看模型的摘要。</p>
<p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00256.jpg" alt></p>
<p>执行后界面如图7-17所示。</p>
<p><img src="Image00257.jpg" alt></p>
<p>图7-17</p>
<p><img src="Image00258.jpg" alt> 查看训练过程的准确率。</p>
<p><img src="Image00259.jpg" alt></p>
<p><img src="Image00260.jpg" alt> 图示训练过程的准确率。</p>
<p><img src="Image00261.jpg" alt></p>
<p>在执行界面中，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，准确率都越来越高。</li>
<li>在Epoch训练后期，虽然“acc训练的准确率”比“val_acc验证的准确率”高，但是“训练的准确率”与“验证的准确率”差距变小，过度拟合的程度已经减轻。</li>
</ul>
<p><img src="Image00262.jpg" alt> 查看准确率。</p>
<p><img src="Image00263.jpg" alt></p>
<p>从以上执行结果可知准确率是0.98。比之前未加入DropOut时还高，这代表加入了DropOut不但可以解决过度拟合的问题，还可以增加准确率。</p>
<h3 id="7-10-建立多层感知器模型包含两个隐藏层"><a href="#7-10-建立多层感知器模型包含两个隐藏层" class="headerlink" title="7.10 建立多层感知器模型包含两个隐藏层"></a>7.10 建立多层感知器模型包含两个隐藏层</h3><p>为了更进一步增加多层感知器模型的准确率，在本节的范例中将建立两个隐藏层。有关完整的程序码，请参考范例程序Keras_Mnist_MLP_h1000_DropOut_h1000_DropOut.ipynb。</p>
<p><img src="Image00264.jpg" alt> 加入两个隐藏层并且加入DropOut功能。</p>
<p>如图7-18所示，我们将加入两个隐藏层并且加入DropOut功能。</p>
<p><img src="Image00265.jpg" alt></p>
<p>图7-18</p>
<p>▶ 建立模型</p>
<p><img src="Image00266.jpg" alt></p>
<p>▶ 加入“输入层”与“隐藏层1”</p>
<p><img src="Image00267.jpg" alt></p>
<p>▶ 加入“隐藏层2”</p>
<p><img src="Image00268.jpg" alt></p>
<p>▶ 加入“输出层”</p>
<p><img src="Image00269.jpg" alt></p>
<p><img src="Image00270.jpg" alt> 查看模型的摘要。</p>
<p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00271.jpg" alt></p>
<p>执行后屏幕显示界面如图7-19所示。</p>
<p><img src="Image00272.jpg" alt></p>
<p>图7-19</p>
<p><img src="Image00273.jpg" alt> 查看训练过程的准确率。</p>
<p><img src="Image00274.jpg" alt></p>
<p>在执行界面中，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，准确率都越来越高。</li>
<li>在Epoch训练后期，虽然“acc训练的准确率”比“val_acc验证的准确率”高，但是“训练的准确率”与“验证的准确率”差距变小，这代表已经大致解决了过度拟合的问题。</li>
</ul>
<p><img src="Image00275.jpg" alt> 查看准确率。</p>
<p><img src="Image00276.jpg" alt></p>
<p>从以上执行结果可知准确率是0.9797，准确率并没有显著提升。</p>
<h3 id="7-11-结论"><a href="#7-11-结论" class="headerlink" title="7.11 结论"></a>7.11 结论</h3><p>在本章中，我们使用多层感知器模型来识别MNIST数据集中的手写数字，尝试将模型加宽、加深，以提高准确率，并且加入Drop层，以避免过度拟合，准确率接近0.98。不过，多层感知器有其极限，如果还要进一步提升准确率，就必须使用卷积神经网络。</p>
<h1 id="第8章-Keras卷积神经网络识别手写数字"><a href="#第8章-Keras卷积神经网络识别手写数字" class="headerlink" title="第8章 Keras卷积神经网络识别手写数字"></a>第8章 Keras卷积神经网络识别手写数字</h1><p>在本章中，我们将介绍使用Keras建立卷积神经网络（Convolutional NeuralNetwork，CNN），然后训练模型、评估模型准确率接近0.99，最后使用训练完成的模型来识别MNIST手写数字。</p>
<p>卷积神经网络是由一位计算机科学家Yann LeCun所提出的，他在机器学习、计算机视觉和计算神经科学等诸多领域都有贡献。</p>
<p>有关本章完整的程序代码，请参考范例程序Keras_Mnist_CNN.ipynb。范例程序下载与安装，请参考本书附录A中的“本书范例程序的下载与安装说明”。</p>
<h3 id="8-1-卷积神经网络简介"><a href="#8-1-卷积神经网络简介" class="headerlink" title="8.1 卷积神经网络简介"></a>8.1 卷积神经网络简介</h3><h5 id="1．多层感知器与卷积神经网络"><a href="#1．多层感知器与卷积神经网络" class="headerlink" title="1．多层感知器与卷积神经网络"></a>1．多层感知器与卷积神经网络</h5><p>如图8-1所示，多层感知器与卷积神经网络主要的差异是：卷积神经网络增加了卷积层1、池化层1、卷积层2、池化层2的处理来提取特征。</p>
<p><img src="Image00277.jpg" alt></p>
<p>图8-1</p>
<h5 id="2．卷积神经网络介绍"><a href="#2．卷积神经网络介绍" class="headerlink" title="2．卷积神经网络介绍"></a>2．卷积神经网络介绍</h5><p>从图8-1中可以看到卷积神经网络可分为两大部分。</p>
<ul>
<li>图像的特征提取</li>
</ul>
<p>通过卷积层1、池化层1、卷积层2、池化层2提取图像的特征。</p>
<ul>
<li>完全连接的神经网络</li>
</ul>
<p>包含平坦层、隐藏层、输出层，所组成的类神经网络，如图8-2所示。</p>
<p><img src="Image00278.jpg" alt></p>
<p>图8-2</p>
<p>从图8-2中，我们可以看到从这些图像中提取了“7”的图像特征，卷积运算的效果类似滤镜效果，即用于提取不同的特征。注：downsampling就是缩减像素采样，简称缩减采样。</p>
<h5 id="3．卷积运算"><a href="#3．卷积运算" class="headerlink" title="3．卷积运算"></a>3．卷积运算</h5><p>卷积层的意义是将原本一个图像经过卷积运算产生多个图像，就好像将相片叠加起来。</p>
<p>▶ 卷积运算的运算方式（见图8-3）</p>
<p>（1）先以随机的方式产生，filter weight大小是3×3。</p>
<p>（2）要转换的图像从左到右、自上而下，按序选取3×3的矩阵。</p>
<p>（3）图像选取的矩阵（3×3）与filter weight（3×3）乘积，计算产生第1行、第1列的数字。</p>
<p><img src="Image00279.jpg" alt></p>
<p>图8-3</p>
<p>再以相同的方式计算第1行、第2列的数字，如图8-4所示。</p>
<p><img src="Image00280.jpg" alt></p>
<p>图8-4</p>
<p>按照上面的相同方式，按序完成所有运算，就可以完成图像的处理。</p>
<h5 id="4．使用单个filter-weight卷积运算产生图像"><a href="#4．使用单个filter-weight卷积运算产生图像" class="headerlink" title="4．使用单个filter weight卷积运算产生图像"></a>4．使用单个filter weight卷积运算产生图像</h5><p>如图8-5所示，将大小为28×28的数字图像7，使用随机产生的5×5filter weight（ _w_ ）滤镜进行卷积运算。</p>
<p><img src="Image00281.jpg" alt></p>
<p>图8-5</p>
<p>卷积运算并不会改变图像大小，所以处理后的图像大小仍然是28×28。卷积运算后的效果很类似滤镜效果，这可以帮助我们提取输入的不同特征，例如边缘、线条和角等。</p>
<h5 id="5．使用多个filter-weight卷积运算产生多个图像"><a href="#5．使用多个filter-weight卷积运算产生多个图像" class="headerlink" title="5．使用多个filter weight卷积运算产生多个图像"></a>5．使用多个filter weight卷积运算产生多个图像</h5><p>接下来，我们将随机产生16个filter weight，也就是16个滤镜。</p>
<p>卷积运算使用16个滤镜（filter weight）产生16个图像，每个图像提取不同的特征，如图8-6所示。</p>
<p><img src="Image00282.jpg" alt></p>
<p>图8-6</p>
<h5 id="6．Max-Pool运算说明"><a href="#6．Max-Pool运算说明" class="headerlink" title="6．Max-Pool运算说明"></a>6．Max-Pool运算说明</h5><p>Max-Pool运算可以对图像缩减采样，如图8-7所示，原本图像是4×4的，经过Max-Pool运算转换后，图像大小为2×2。</p>
<p><img src="Image00283.jpg" alt></p>
<p>图8-7</p>
<p>以上Max-Pool运算详细说明如下。</p>
<ul>
<li><strong>在左上角4个数字：</strong> 5、2、4、1最大的是5，所以计算结果是5，如图8-8所示。</li>
</ul>
<p><img src="Image00284.jpg" alt></p>
<p>图8-8</p>
<ul>
<li><strong>在右上角4个数字：</strong> 3、1、1、6，最大的是6，所以计算结果是6，如图8-9所示。</li>
</ul>
<p><img src="Image00285.jpg" alt></p>
<p>图8-9</p>
<ul>
<li><strong>在左下角4个数字：</strong> 7、8、1、1，最大的是8，所以计算结果是8，如图8-10所示。</li>
</ul>
<p><img src="Image00286.jpg" alt></p>
<p>图8-10</p>
<ul>
<li><strong>在右下角4个数字：</strong> 2、9、1、1，最大的是9，所以计算结果是9，如图8-11所示。</li>
</ul>
<p><img src="Image00287.jpg" alt></p>
<p>图8-11</p>
<h5 id="7．使用Max-Pool转换手写数字图像"><a href="#7．使用Max-Pool转换手写数字图像" class="headerlink" title="7．使用Max-Pool转换手写数字图像"></a>7．使用Max-Pool转换手写数字图像</h5><p>使用Max-Pool缩减采样，进行手写数字图像转换，将16个28×28的图像缩小为16个14×14的图像，但是不会改变图像的数量（仍然是16个），如图8-12所示。</p>
<p><img src="Image00288.jpg" alt></p>
<p>图8-12</p>
<p>缩减采样会缩小图像，有下列好处。</p>
<p><strong>（1）减少需处理的数据点：</strong> 减少后续运算所需的时间。</p>
<p><strong>（2）让图像位置差异变小：</strong> 例如手写数字7，位置上下左右可能不同，位置的不同可能会影响识别。减小图像大小，让数字的位置差异变小。</p>
<p><strong>（3）参数的数量和计算量下降：</strong> 这在一定程度上也控制了过度拟合。</p>
<h5 id="8．建立卷积神经网络识别MNIST数据集"><a href="#8．建立卷积神经网络识别MNIST数据集" class="headerlink" title="8．建立卷积神经网络识别MNIST数据集"></a>8．建立卷积神经网络识别MNIST数据集</h5><p>建立卷积神经网络识别MNIST数据集的步骤如图8-13所示。</p>
<p><img src="Image00289.jpg" alt></p>
<p>图8-13</p>
<h3 id="8-2-进行数据预处理"><a href="#8-2-进行数据预处理" class="headerlink" title="8.2 进行数据预处理"></a>8.2 进行数据预处理</h3><p>卷积神经网络与多层感知器进行数据预处理的方式不同，说明见表8-1。</p>
<p>表8-1 卷积神经网络与多层感知器进行数据预处理对比</p>
<p><img src="Image00290.jpg" alt></p>
<p><img src="Image00291.jpg" alt> 导入所需模块。</p>
<p><img src="Image00292.jpg" alt></p>
<p><img src="Image00293.jpg" alt> 读取MNIST数据。</p>
<p><img src="Image00294.jpg" alt></p>
<p><img src="Image00295.jpg" alt> 将features（数字图像特征值）转换为四维矩阵。</p>
<p>将features（数字图像特征值）以reshape转换为6000×28×28×1的4维矩阵。</p>
<p><img src="Image00296.jpg" alt></p>
<p><img src="Image00297.jpg" alt> 将features（数字图像特征值）标准化。</p>
<p>将features（数字图像特征值）标准化可以提高模型预测的准确度，并且更快收敛。</p>
<p><img src="Image00298.jpg" alt></p>
<p><img src="Image00299.jpg" alt> label（数字真实的值）以One-Hot Encoding进行转换。</p>
<p>使用np_utils.to_categorical将训练数据与测试数据的label进行One-Hot Encoding（一位有效编码）转换。</p>
<p><img src="Image00300.jpg" alt></p>
<h3 id="8-3-建立模型"><a href="#8-3-建立模型" class="headerlink" title="8.3 建立模型"></a>8.3 建立模型</h3><p>我们将使用下列程序代码来建立卷积神经网络，如图8-14所示。</p>
<p><img src="Image00301.jpg" alt></p>
<p>图8-14</p>
<h5 id="1．导入所需模块-1"><a href="#1．导入所需模块-1" class="headerlink" title="1．导入所需模块"></a>1．导入所需模块</h5><p><img src="Image00302.jpg" alt></p>
<p>程序代码说明见表8-2。</p>
<p>表8-2 程序代码说明</p>
<p><img src="Image00303.jpg" alt></p>
<h5 id="2．建立keras的Sequential模型"><a href="#2．建立keras的Sequential模型" class="headerlink" title="2．建立keras的Sequential模型"></a>2．建立keras的Sequential模型</h5><p>建立一个Sequential线性堆叠模型，后续只需要使用model.add（）方法将各个神经网络层加入模型即可。</p>
<p><img src="Image00304.jpg" alt></p>
<h5 id="3．建立卷积层1与池化层1"><a href="#3．建立卷积层1与池化层1" class="headerlink" title="3．建立卷积层1与池化层1"></a>3．建立卷积层1与池化层1</h5><p>一个完整的卷积运算包含一个卷积层与一个池化层。</p>
<p>▶ 建立卷积层1</p>
<p>使用下列程序代码建立卷积层1。输入的数字图像大小为28×28，进行第1次卷积运算会产生16个图像，卷积运算并不会改变图像大小，所以图像大小仍然是28×28。</p>
<p><img src="Image00305.jpg" alt></p>
<p>以上程序代码把Conv2D层加入模型中，需输入表8-3中的参数。</p>
<p>表8-3 把Conv2D层加入模型中需输入的参数</p>
<p><img src="Image00306.jpg" alt></p>
<p>▶ 建立池化层1</p>
<p>下面的程序代码建立池化层1，输入参数pool_size＝（2，2），执行第1次缩减采样，将16个28×28的图像缩小为16个14×14的图像。</p>
<p><img src="Image00307.jpg" alt></p>
<h5 id="4．建立卷积层2与池化层2"><a href="#4．建立卷积层2与池化层2" class="headerlink" title="4．建立卷积层2与池化层2"></a>4．建立卷积层2与池化层2</h5><p>▶ 建立卷积层2</p>
<p>使用下面的程序代码建立卷积层2。执行第2次卷积运算：将原本的16个图像转换为36个图像，卷积运算不会改变图像大小，所以图像大小仍然是14×14。</p>
<p><img src="Image00308.jpg" alt></p>
<p>以上程序代码把Conv2D层加入模型中，需输入表8-4中的参数。</p>
<p>表8-4 把Conv2D层加入模型中需输入的参数</p>
<p><img src="Image00309.jpg" alt></p>
<p>▶ 建立池化层2，并且加入Dropout避免过度拟合</p>
<p>下面的程序代码建立池化层2，输入参数pool_size＝（2，2），执行第2次缩减采样，将36个14×14的图像缩小为36个7×7的图像。</p>
<p><img src="Image00310.jpg" alt></p>
<p>下面的程序代码把Dropout（0.25）层加入模型中。其功能是，每次训练迭代时，会随机在神经网络中放弃25%的神经元，以避免过度拟合。</p>
<p><img src="Image00311.jpg" alt></p>
<h5 id="5．建立神经网络（平坦层、隐藏层、输出层）"><a href="#5．建立神经网络（平坦层、隐藏层、输出层）" class="headerlink" title="5．建立神经网络（平坦层、隐藏层、输出层）"></a>5．建立神经网络（平坦层、隐藏层、输出层）</h5><p>▶ 建立平坦层</p>
<p>以下程序代码建立平坦层，将之前的步骤已经建立的池化层2，共有36个7×7的图像转换为一维的向量，长度是36×7×7＝1764，也就是1764个Float数，正好对应1764个神经元。</p>
<p><img src="Image00312.jpg" alt></p>
<p>▶ 建立隐藏层</p>
<p>下面的程序代码建立隐藏层，共有128个神经元。</p>
<p><img src="Image00313.jpg" alt></p>
<p>并且把Dropout层加入模型中。Dropout（0.5）的功能是，每次训练迭代时，会随机地在神经网络中放弃50%的神经元，以避免过度拟合。</p>
<p><img src="Image00314.jpg" alt></p>
<p>▶ 建立输出层</p>
<p>最后建立输出层，共有10个神经元，对应0～9共10个数字。并且使用softmax激活函数进行转换，softmax可以将神经元的输出转换为预测每一个数字的概率。</p>
<p><img src="Image00315.jpg" alt></p>
<h5 id="6．查看模型的摘要"><a href="#6．查看模型的摘要" class="headerlink" title="6．查看模型的摘要"></a>6．查看模型的摘要</h5><p>我们可以使用下列指令来查看模型的摘要，如图8-15所示。</p>
<p><img src="Image00316.jpg" alt></p>
<p><img src="Image00317.jpg" alt></p>
<p>图8-15</p>
<h3 id="8-4-进行训练"><a href="#8-4-进行训练" class="headerlink" title="8.4 进行训练"></a>8.4 进行训练</h3><p>当我们建立好深度学习模型后，就可以使用反向传播算法（参考第2章）进行训练。</p>
<h5 id="1．定义训练方式-1"><a href="#1．定义训练方式-1" class="headerlink" title="1．定义训练方式"></a>1．定义训练方式</h5><p>在训练模型之前，我们必须使用compile方法对训练模型进行设置，如下列指令：</p>
<p><img src="Image00318.jpg" alt></p>
<p>compile方法需输入3个参数：loss、optimizer和metrics，对这3个参数的解释说明可参考7.4节。</p>
<h5 id="2．开始训练-1"><a href="#2．开始训练-1" class="headerlink" title="2．开始训练"></a>2．开始训练</h5><p>执行训练的程序代码如下：</p>
<p><img src="Image00319.jpg" alt></p>
<p>使用model.fit进行训练，训练过程会存储在train_history变量中，这个训练需输入下列参数。</p>
<p>（1）输入训练数据参数</p>
<ul>
<li>x＝x_Train4D_normalize（features数字图像的特征值）。</li>
<li>y＝y_Train_OneHot（label数字图像真实的值）。</li>
</ul>
<p>（2）设置训练与验证数据比例</p>
<ul>
<li>设置参数validation_split＝0.2。</li>
</ul>
<p>训练之前Keras会自动将数据分成：80%作为训练数据，20%作为验证数据。因为全部是60 000项，所以分成：60 000×0.8＝48000作为训练数据，60 000×0.2＝12 000作为验证数据。</p>
<p>（3）设置训练周期次数与每一批次项数</p>
<ul>
<li>epochs＝10：执行10个训练周期。</li>
<li>batch_size＝300：每一批次300项数据。</li>
</ul>
<p>（4）设置显示训练过程</p>
<ul>
<li>verbose＝2：显示训练过程。</li>
</ul>
<p>以上程序代码共执行了10个训练周期，每一个训练周期执行下列功能：</p>
<ul>
<li>使用48 000项训练数据进行训练，分为每一批次300项，所以大约分为160批次（48 000/300＝160）进行训练。</li>
<li>Epoch（训练周期）训练完成后，会计算这个训练周期的准确率与误差，并且在train_history中新增一项数据记录。</li>
</ul>
<p>以上程序代码执行后的结果如图8-16所示。</p>
<p><img src="Image00320.jpg" alt></p>
<p>图8-16</p>
<p>从以上执行结果的屏幕显示界面中可以看到共执行了10个训练周期，从中可以发现误差越来越小，准确率越来越高。</p>
<h5 id="3．画出准确率执行结果"><a href="#3．画出准确率执行结果" class="headerlink" title="3．画出准确率执行结果"></a>3．画出准确率执行结果</h5><p>之前的训练步骤会将每一个训练周期的准确率与误差记录在train_history变量中。</p>
<p>我们可以使用下面的程序代码读取train_history，画出准确率的执行结果。有关show_train_history的细节可参考第7章的说明。</p>
<p><img src="Image00321.jpg" alt></p>
<p>在以上执行界面中，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现，无论是训练还是验证，准确率都越来越高。</p>
<h5 id="4．画出误差执行结果"><a href="#4．画出误差执行结果" class="headerlink" title="4．画出误差执行结果"></a>4．画出误差执行结果</h5><p><img src="Image00322.jpg" alt></p>
<p>在以上执行界面中，“loss训练的误差”是深色的，“val_loss验证的误差”是浅色的，总共执行了10个训练周期，我们可以发现，无论是训练还是验证，验证的误差都越来越低。</p>
<h3 id="8-5-评估模型准确率"><a href="#8-5-评估模型准确率" class="headerlink" title="8.5 评估模型准确率"></a>8.5 评估模型准确率</h3><p>在之前的步骤中，我们已经完成了训练，现在要使用test测试数据集来评估模型准确率。用下面的程序代码来评估模型的准确率。</p>
<p><img src="Image00323.jpg" alt></p>
<p>从以上的执行结果可知准确率是0.989。程序代码说明见表8-5。</p>
<p>表8-5 程序代码说明</p>
<p><img src="Image00324.jpg" alt></p>
<h3 id="8-6-进行预测"><a href="#8-6-进行预测" class="headerlink" title="8.6 进行预测"></a>8.6 进行预测</h3><p>之前的步骤我们建立了模型，并且完成了训练模型，准确率达到0.989，接下来将使用此模型进行预测。</p>
<p><img src="Image00325.jpg" alt> 执行预测。</p>
<p>我们可以使用下列指令执行预测。</p>
<p><img src="Image00326.jpg" alt></p>
<p>下面的程序代码使用model.predict_classes输入参数x_Test4D_normalize（已标准化测试数据的数字图像）进行预测。</p>
<p><img src="Image00327.jpg" alt> 预测结果。</p>
<p>我们可以使用下列指令查看预测结果的前10项数据。</p>
<p><img src="Image00328.jpg" alt></p>
<p>可以看到第1项预测结果是7，第2项是2……</p>
<p><img src="Image00329.jpg" alt> 显示前10项预测结果。</p>
<p>使用第6章创建的show_images_labels_prediction函数显示前10项预测结果，传入测试数据图像、label（真实值）及predict（预测结果）。</p>
<p><img src="Image00330.jpg" alt></p>
<h3 id="8-7-显示混淆矩阵"><a href="#8-7-显示混淆矩阵" class="headerlink" title="8.7 显示混淆矩阵"></a>8.7 显示混淆矩阵</h3><p>Pandas提供了建立混淆矩阵的功能。</p>
<p><img src="Image00331.jpg" alt></p>
<p>以上程序代码说明见表8-6。</p>
<p>表8-6 程序代码说明</p>
<p><img src="Image00332.jpg" alt></p>
<p>执行后显示如图8-17所示的混淆矩阵。</p>
<p><img src="Image00333.jpg" alt></p>
<p>图8-17</p>
<p>观察以上混淆矩阵的结果如下：</p>
<ul>
<li><strong>对角线是预测正确的数字，我们发现：</strong> 真实值是“1”，被正确预测为“1”的项数有1132项，最高，即最不容易混淆。真实值是“5”，被正确预测为“5”的项数有881项，最低，也就是说最容易混淆。</li>
<li><strong>其他非对角线的数字代表将某一个标签错误预测为另一个标签，我们发现：</strong> 真实值是“8”，但是预测值是“0”时最高，也就是最容易混淆。</li>
</ul>
<h3 id="8-8-结论"><a href="#8-8-结论" class="headerlink" title="8.8 结论"></a>8.8 结论</h3><p>在本章中，我们使用卷积神经网络来识别MNIST数据集中的手写数字，其分类精度接近0.99。不过，这只是单色手写数字的识别，相对来说比较简单，下一章我们将介绍更具挑战性的，使用卷积神经网络来识别CIFAR-10数据集，识别彩色图像共10个分类：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车。</p>
<h1 id="第9章-Keras-CIFAR-10图像识别数据集"><a href="#第9章-Keras-CIFAR-10图像识别数据集" class="headerlink" title="第9章 Keras CIFAR-10图像识别数据集"></a>第9章 Keras CIFAR-10图像识别数据集</h1><p>CIFAR-10是由Alex Krizhevsky、Vinod Nair与GeoffreyHinton收集的一个用于图像识别的数据集，共有10个分类：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车。CIFAR-10数据集与之前的MNIST数据集相比，它的色彩、颜色噪点较多，同一分类（如卡车）大小不一、角度不同、颜色不同。所以CIFAR-10图像识别的难度比MNIST数据集高很多。</p>
<p>我们可以在下列网址查看CIFAR-10数据集（见图9-1）：</p>
<p><a href="https://www.cs.toronto.edu／~kriz/cifar.html" target="_blank" rel="noopener">https://www.cs.toronto.edu／~kriz/cifar.html</a></p>
<p><img src="Image00334.jpg" alt></p>
<p>图9-1</p>
<p>CIFAR-10数据集共有60 000个32×32的彩色图像，有50 000个训练图像和10000个测试图像。共有10个分类，它们是：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车。每个分类有6000个图像。有关完整的程序代码，参考范例程序Keras_Cifar_CNN_Introduce.ipynb。有关范例程序下载与安装的细节，可参考本书附录A中的“本书范例程序的下载与安装说明”。</p>
<h3 id="9-1-下载CIFAR-10数据"><a href="#9-1-下载CIFAR-10数据" class="headerlink" title="9.1 下载CIFAR-10数据"></a>9.1 下载CIFAR-10数据</h3><p>我们将创建Keras程序，下载并读取CIFAR-10数据。</p>
<p><img src="Image00335.jpg" alt> 导入所需模块。</p>
<p><img src="Image00336.jpg" alt></p>
<p>程序代码说明见表9-1。</p>
<p>表9-1 程序代码说明</p>
<p><img src="Image00337.jpg" alt></p>
<p><img src="Image00338.jpg" alt> 下载并且解压缩CIFAR-10文件</p>
<p>Keras提供了cifar10.load_data（）用于下载或读取CIFAR-10数据。第一次执行cifar10.loaddata（）方法时，程序会检查是否有cifar-10-batches-py.tar文件，如果还没有，就会下载文件，并且解压缩下载的文件。以下是第一次下载文件时屏幕显示的界面，因为要下载文件，所以运行时间可能会比较长。</p>
<p><img src="Image00339.jpg" alt></p>
<p><img src="Image00340.jpg" alt> 查看CIFAR-10数据文件。</p>
<p>查看下载的CIFAR-10数据文件，这个文件会因我们使用的环境是Windows或Linux Ubuntu而有所不同，说明如下：</p>
<p>▶ 在Windows下查看下载文件的CIFAR-10数据文件</p>
<p>如图9-2所示，因为笔者的用户名称是kevin，所以下载后会存放在目录C：\Users\kevin\.keras\datasets中，文件名是cifar-10-batches-py.tar。</p>
<p><img src="Image00341.jpg" alt></p>
<p>图9-2</p>
<p>▶ 在Linux Ubuntu下查看已下载的MNIST数据文件</p>
<p>下载完成后，我们可以输入下列指令来查看“～／.keras/datasets/cifar-10-batches-py”下的CIFAR-10子目录，如图9-3所示。</p>
<p><img src="Image00342.jpg" alt></p>
<p><img src="Image00343.jpg" alt></p>
<p>图9-3</p>
<p><img src="Image00344.jpg" alt> 读取CIFAR-10数据。</p>
<p>再次执行cifar10.load_data（）时，由于之前已经下载了文件，不需要再下载了，只需要读取文件，因此运行时间不会太长。</p>
<p><img src="Image00345.jpg" alt></p>
<p><img src="Image00346.jpg" alt> 查看CIFAR-10数据。</p>
<p>下载后，我们可以使用下列指令来查看数据项数。</p>
<p><img src="Image00347.jpg" alt></p>
<p>从以上执行结果可知，第一维是项数，数据可分为两部分：</p>
<ul>
<li>train训练数据50 000项。</li>
<li>test测试数据10 000项。</li>
</ul>
<h3 id="9-2-查看训练数据"><a href="#9-2-查看训练数据" class="headerlink" title="9.2 查看训练数据"></a>9.2 查看训练数据</h3><p>先查看训练数据。</p>
<h5 id="1．训练数据是由images与label所组成的"><a href="#1．训练数据是由images与label所组成的" class="headerlink" title="1．训练数据是由images与label所组成的"></a>1．训练数据是由images与label所组成的</h5><p>y_label_train是图像数据的真实值，每一个数字代表一种图像类别的名称，共有10个类别：0：airplane 、1：automobile、2：bird 、3：cat 、4：deer 、5：dog 、6：frog 、7：horse 、8：ship 、9：truck，如图9-4所示。</p>
<p><img src="Image00348.jpg" alt></p>
<p>图9-4</p>
<h5 id="2．Images的shape形状"><a href="#2．Images的shape形状" class="headerlink" title="2．Images的shape形状"></a>2．Images的shape形状</h5><p>下面的程序代码使用.shape方法来查看x_img_train的shape。</p>
<p><img src="Image00349.jpg" alt></p>
<p>各维的说明如下：</p>
<p><img src="Image00350.jpg" alt></p>
<h5 id="3．第0项images图像的内容"><a href="#3．第0项images图像的内容" class="headerlink" title="3．第0项images图像的内容"></a>3．第0项images图像的内容</h5><p>下面的程序代码用来查看第0项images的内容，每一点都是由是RGB三原色所组成的，RGB共有3个数字，数字的范围从0到255，代表图像的RGB颜色。</p>
<p><img src="Image00351.jpg" alt></p>
<h5 id="4．y-label-train的shape形状"><a href="#4．y-label-train的shape形状" class="headerlink" title="4．y_label_train的shape形状"></a>4．y_label_train的shape形状</h5><p><img src="Image00352.jpg" alt></p>
<h3 id="9-3-查看多项images与label"><a href="#9-3-查看多项images与label" class="headerlink" title="9.3 查看多项images与label"></a>9.3 查看多项images与label</h3><p>之前只是显示数据，接下来将修改plot_images_labels_prediction（）函数以显示图像。</p>
<p><img src="Image00353.jpg" alt> 定义label_dict字典。</p>
<p>先以Python字典dict定义每一个数字所代表的图像类别的名称。</p>
<p><img src="Image00354.jpg" alt></p>
<p><img src="Image00355.jpg" alt> 修改plot_images_labels_prediction（）函数。</p>
<p>为了便于查看多项数据images与label，我们将修改第6章所创建的plot_images_labels_prediction（），并且使用label_dict字典将label与prediction的0～9数字转换为图像类别名称。</p>
<p><img src="Image00356.jpg" alt></p>
<p><img src="Image00357.jpg" alt> 查看训练数据前10项数据。</p>
<p>使用plot_images_labels_prediction（）显示训练数据前10项数据。因为还没有预测数据，所以prediction参数输入空的list［］。</p>
<p><img src="Image00358.jpg" alt></p>
<h3 id="9-4-将images进行预处理"><a href="#9-4-将images进行预处理" class="headerlink" title="9.4 将images进行预处理"></a>9.4 将images进行预处理</h3><p>为了将images的内容送入卷积神经网络模型进行训练与预测，必须先进行数据的预处理。</p>
<p><img src="Image00359.jpg" alt> 查看训练数据第1个图像的第1个点。</p>
<p>我们可以用下列指令来查看训练数据的第1个图像的第1个点。</p>
<p><img src="Image00360.jpg" alt></p>
<p>可以看到每一点共有3个数字，分别代表RGB ［59，62，63］。</p>
<p><img src="Image00361.jpg" alt> 将照片图像image的数字标准化。</p>
<p>image的数字标准化可以提高模型的准确率，因为image的数字是0到255，所以最简单标准化的方式是除以255，如下列程序代码：</p>
<p><img src="Image00362.jpg" alt></p>
<p><img src="Image00363.jpg" alt> 查看照片图像image的数字标准化后的结果。</p>
<p>使用下列指令查看照片图像image的数字标准化后的结果，全部的数值都在0与1之间。</p>
<p><img src="Image00364.jpg" alt></p>
<h3 id="9-5-对label进行数据预处理"><a href="#9-5-对label进行数据预处理" class="headerlink" title="9.5 对label进行数据预处理"></a>9.5 对label进行数据预处理</h3><p>对于CIFAR-10数据集，我们希望预测图像的类型，例如“船”的图像的label是8，经过一位有效编码（One-HotEncoding）转换为0000000010，10个数字正好对应输出层10个神经元。</p>
<p><img src="Image00365.jpg" alt> 查看label原来的shape形状。</p>
<p>使用下列指令来查看label原来的shape形状。</p>
<p><img src="Image00366.jpg" alt></p>
<p>我们可以看到以上执行的结果共计50 000项，每一项是1个0～9之间的数字。</p>
<p><img src="Image00367.jpg" alt> 查看前5项数据。</p>
<p>使用下列指令来查看前5项数据：我们可以看到都是0～9的数字，代表图像的分类。</p>
<p><img src="Image00368.jpg" alt></p>
<p><img src="Image00369.jpg" alt> 将label标签字段转换为一位有效编码（One-Hot Encoding）。</p>
<p>Keras提供了np_utils.to_categorical方法，可以进行One-HotEncoding转换。下面的程序代码将训练数据与测试数据的label标签字段进行One-Hot Encoding转换。</p>
<p><img src="Image00370.jpg" alt></p>
<p><img src="Image00371.jpg" alt> One-Hot Encoding转换之后的label标签字段。</p>
<p><img src="Image00372.jpg" alt></p>
<p>从以上执行结果可知，共计50 000项，每一笔是10个0或1的组合。</p>
<p><img src="Image00373.jpg" alt> 查看转换为One-Hot Encoding之后的结果。</p>
<p><img src="Image00374.jpg" alt></p>
<p>查看以上执行结果可知，第1项数据原来的真实值是6，执行One-Hot Encoding转换后变成0或1的组合，只有第6个数字（从0算起）是1，其余都是0。</p>
<h3 id="9-6-结论"><a href="#9-6-结论" class="headerlink" title="9.6 结论"></a>9.6 结论</h3><p>本章介绍了下载并且读取CIFAR-10数据集，还介绍了CIFAR-10数据集的特色，并且已经完成数据的预处理。在下一章，我们可以使用Keras建立卷积神经网络模型，训练模型并进行预测。</p>
<h1 id="第10章-Keras卷积神经网络识别CIFAR-10图像"><a href="#第10章-Keras卷积神经网络识别CIFAR-10图像" class="headerlink" title="第10章 Keras卷积神经网络识别CIFAR-10图像"></a>第10章 Keras卷积神经网络识别CIFAR-10图像</h1><p>在本章中，我们将介绍使用Keras建立卷积神经网络模型，并且训练模型、评估模型准确率，然后使用训练完成的模型来识别CIFAR-10图像数据集。由于CIFAR-10图像识别的难度比MNIST数据集识别的难度高很多，因此我们尝试以更多次的卷积与池化运算来提高识别的准确率。</p>
<h3 id="10-1-卷积神经网络简介"><a href="#10-1-卷积神经网络简介" class="headerlink" title="10.1 卷积神经网络简介"></a>10.1 卷积神经网络简介</h3><p><img src="Image00375.jpg" alt> 卷积神经网络介绍</p>
<p>我们将建立的卷积神经网络如图10-1所示。</p>
<p><img src="Image00376.jpg" alt></p>
<p>图10-1</p>
<p>如图10-1所示，我们可以看到卷积神经网络可分为以下两大部分。</p>
<ul>
<li><strong>图像的特征提取：</strong> 通过卷积层1、池化层1、卷积层2、池化层2的处理，提取图像的特征。</li>
<li><strong>完全连接神经网络（fully connected layer）：</strong> 包含平坦层、隐藏层、输出层所组成的类神经网络。</li>
</ul>
<p>本章完整的程序代码可参考范例程序Keras_Cifar_CNN.ipynb。范例程序下载与安装可参考本书附录A。</p>
<h3 id="10-2-数据预处理"><a href="#10-2-数据预处理" class="headerlink" title="10.2 数据预处理"></a>10.2 数据预处理</h3><p>关于CIFAR-10数据预处理的详细说明可参考第9章。</p>
<p><img src="Image00377.jpg" alt> 导入所需模块。</p>
<p><img src="Image00378.jpg" alt></p>
<p>程序代码说明见表10-1。</p>
<p>表10-1 程序代码说明</p>
<p><img src="Image00379.jpg" alt></p>
<p><img src="Image00380.jpg" alt> 读取CIFAR-10数据。</p>
<p><img src="Image00381.jpg" alt></p>
<p><img src="Image00382.jpg" alt> 显示训练与验证数据的shape。</p>
<p><img src="Image00383.jpg" alt></p>
<p><img src="Image00384.jpg" alt> 将features（照片图像特征值）标准化。</p>
<p>将features（照片图像特征值）标准化可以提高模型预测的准确度，并且更快收敛。</p>
<p><img src="Image00385.jpg" alt></p>
<p><img src="Image00386.jpg" alt> label（照片图像真实的值）以一位有效编码进行转换。</p>
<p>以下程序代码将训练数据与测试数据的label进行一位有效编码转换。</p>
<p><img src="Image00387.jpg" alt></p>
<h3 id="10-3-建立模型"><a href="#10-3-建立模型" class="headerlink" title="10.3 建立模型"></a>10.3 建立模型</h3><p>我们将使用下面的程序代码建立卷积神经网络。</p>
<h5 id="1．导入所需模块-2"><a href="#1．导入所需模块-2" class="headerlink" title="1．导入所需模块"></a>1．导入所需模块</h5><p><img src="Image00388.jpg" alt></p>
<p>▶ 导入keras的Sequential模块</p>
<p><img src="Image00389.jpg" alt></p>
<p>▶ 导入keras的layers模块</p>
<p><img src="Image00390.jpg" alt></p>
<p>▶ 导入keras的layers模块</p>
<p><img src="Image00391.jpg" alt></p>
<p>我们将使用下面的程序代码建立卷积神经网络，如图10-2所示。</p>
<p><img src="Image00392.jpg" alt></p>
<p>图10-2</p>
<h5 id="2．建立keras的Sequential模型-1"><a href="#2．建立keras的Sequential模型-1" class="headerlink" title="2．建立keras的Sequential模型"></a>2．建立keras的Sequential模型</h5><p>下面的程序代码建立一个Sequential线性堆叠模型，后续只需要将各个神经网络层加入模型即可。</p>
<p><img src="Image00393.jpg" alt></p>
<h5 id="3．建立卷积层1与池化层1-1"><a href="#3．建立卷积层1与池化层1-1" class="headerlink" title="3．建立卷积层1与池化层1"></a>3．建立卷积层1与池化层1</h5><p>一个完整的卷积运算包含一个卷积层与一个池化层。</p>
<p>▶ 建立卷积层1</p>
<p>使用下列程序代码建立卷积层1。输入图像的大小为32×32，会产生32个图像，卷积运算并不会改变图像大小，所以图像大小仍然是32×32。卷积运算的效果很类似滤镜效果，可以提取图像的特征。</p>
<p><img src="Image00394.jpg" alt></p>
<p>以上程序代码把Conv2D层加入模型中，需输入表10-2中的参数。</p>
<p>表10-2 把Conv2D层加入模型中需输入的参数</p>
<p><img src="Image00395.jpg" alt></p>
<p>▶ 加入Dropout避免过度拟合</p>
<p>以下程序代码把Dropout加入模型中，Dropout（0.25）的功能是，每次训练迭代时，会随机地在神经网络中放弃25%的神经元，以避免过度拟合。</p>
<p><img src="Image00396.jpg" alt></p>
<p>▶ 建立池化层1</p>
<p>下面的程序代码建立池化层1，输入参数pool_size＝（2，2），执行第一次缩减采样，将32×32的图像缩小为16×16的图像，缩减采样不会改变数量，所以仍然是32个。</p>
<p><img src="Image00397.jpg" alt></p>
<h5 id="4．建立卷积层2与池化层2-1"><a href="#4．建立卷积层2与池化层2-1" class="headerlink" title="4．建立卷积层2与池化层2"></a>4．建立卷积层2与池化层2</h5><p>▶ 建立卷积层2</p>
<p>使用下面的程序代码建立卷积层2。执行第2次卷积运算：将原本的32个图像转换为64个图像，卷积运算不会改变图像大小，所以图像大小仍然是16×16。</p>
<p><img src="Image00398.jpg" alt></p>
<p>以上程序代码把Conv2D层加入模型中，需输入表10-3中的参数。</p>
<p>表10-3 把Conv2D层加入模型中需输入的参数</p>
<p><img src="Image00399.jpg" alt></p>
<p>▶ 加入Dropout避免过度拟合</p>
<p>以下程序代码加入Dropout（0.25）的功能是，每次训练迭代时会随机地在神经网络中放弃25%的神经元，以避免过度拟合。</p>
<p><img src="Image00400.jpg" alt></p>
<p>▶ 建立池化层2</p>
<p>以下程序代码建立池化层2，输入参数pool_size＝（2，2），执行第二次缩减采样，将16×16的图像缩小为8×8的图像，缩减采样不会改变数量，所以仍然是64个。</p>
<p><img src="Image00401.jpg" alt></p>
<h5 id="5．建立神经网络（平坦层、隐藏层、输出层）-1"><a href="#5．建立神经网络（平坦层、隐藏层、输出层）-1" class="headerlink" title="5．建立神经网络（平坦层、隐藏层、输出层）"></a>5．建立神经网络（平坦层、隐藏层、输出层）</h5><p>▶ 建立平坦层</p>
<p>下面的程序代码建立平坦层，将前面的步骤建立的“池化层2”的64个8×8的图像转换为一维的向量，长度是64×8×8＝4096，也就是4096个Float数，正好对应4096个神经元。并且加入Dropout（0.25），每次训练迭代时，会随机地在神经网络放弃25%的神经元，以避免过度拟合。</p>
<p><img src="Image00402.jpg" alt></p>
<p>▶ 建立隐藏层</p>
<p>下面的程序代码建立隐藏层，共有1024个神经元，并且加入Dropout（0.25），随机去掉25%的神经元，以避免过度拟合。</p>
<p><img src="Image00403.jpg" alt></p>
<p>▶ 建立输出层</p>
<p>最后建立输出层，共有10个神经元，对应0～9共10个图像类别。并且使用softmax激活函数进行转换，softmax可以将神经元的输出转换为预测每一个图像类别的概率。</p>
<p><img src="Image00404.jpg" alt></p>
<h5 id="6．查看模型的摘要-1"><a href="#6．查看模型的摘要-1" class="headerlink" title="6．查看模型的摘要"></a>6．查看模型的摘要</h5><p>可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00405.jpg" alt></p>
<p><img src="Image00406.jpg" alt></p>
<p>图10-3</p>
<h3 id="10-4-进行训练"><a href="#10-4-进行训练" class="headerlink" title="10.4 进行训练"></a>10.4 进行训练</h3><p>当我们建立好深度学习模型后，就可以使用反向传播算法进行训练。详细说明可参考第2章。</p>
<h5 id="1．定义训练方式-2"><a href="#1．定义训练方式-2" class="headerlink" title="1．定义训练方式"></a>1．定义训练方式</h5><p>在训练模型之前，我们必须使用compile方法对训练模型进行设置，如下列指令：</p>
<p><img src="Image00407.jpg" alt></p>
<p>compile方法需输入3个参数：loss、optimizer和metrics（对这3个参数的解释说明可参考7.4节）。</p>
<h5 id="2．开始训练-2"><a href="#2．开始训练-2" class="headerlink" title="2．开始训练"></a>2．开始训练</h5><p><img src="Image00408.jpg" alt></p>
<p>以上程序代码说明如下：</p>
<p>使用model.fit进行训练，训练过程会存储在train_history变量中，需输入下列参数。</p>
<p>（1）输入训练数据参数</p>
<ul>
<li>_x_ ＝x_img_train_normalize（features照片图像的特征值，经过标准化处理）。</li>
<li>_y_ ＝y_label_train_OneHot（label照片图像真实的值，经过One-Hot Encoding转换）。</li>
</ul>
<p>（2）设置训练与验证数据比例</p>
<ul>
<li>设置参数validation_split＝0.2。</li>
</ul>
<p>训练之前Keras会自动将数据分成：80%作为训练数据，20%作为验证数据。因为总共50 000项数据，所以分成：50 000×0.8＝40000项作为训练数据，50 000×0.2＝10 000项作为验证数据，如图10-4所示。</p>
<p>（3）设置训练周期次数与每一批次项数</p>
<ul>
<li>epochs＝10：执行10个训练周期。</li>
<li>batch_size＝128：每一批次128项数据。</li>
</ul>
<p>（4）设置显示训练过程</p>
<ul>
<li>verbose＝2：显示训练过程。</li>
</ul>
<p>以上程序代码共执行了10个训练周期，每一个训练周期都执行下列功能：</p>
<ul>
<li>使用40 000项训练数据进行训练，分为每一批次128项，所以大约分为160批次（40 000/128＝313）进行训练。</li>
<li>Epoch（训练周期）训练完成后，会计算这个训练周期的准确率与误差，并且在train_history中新增一项数据记录。</li>
</ul>
<p>执行结果如图10-4所示。</p>
<p><img src="Image00409.jpg" alt></p>
<p>从以上执行结果的屏幕显示界面中，我们可以看到共执行了10个训练周期，同时可以发现误差越来越小，准确率越来越高。</p>
<h5 id="3．画出准确率执行的结果"><a href="#3．画出准确率执行的结果" class="headerlink" title="3．画出准确率执行的结果"></a>3．画出准确率执行的结果</h5><p>下面是程序代码画出准确率执行的结果。有关show_train_history可参考第7章的说明。</p>
<p><img src="Image00410.jpg" alt></p>
<p>在以上执行结果的屏幕显示界面中，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，准确率都越来越高。</li>
<li>在Epoch训练后期，“acc训练的准确率”比“val_acc验证的准确率”高。</li>
</ul>
<h5 id="4．画出误差的执行结果"><a href="#4．画出误差的执行结果" class="headerlink" title="4．画出误差的执行结果"></a>4．画出误差的执行结果</h5><p><img src="Image00411.jpg" alt></p>
<p>在以上执行结果的屏幕显示界面中，“loss训练的误差”是深色的，“val_loss验证的误差”是浅色的，总共执行了10个训练周期，我们可以发现：</p>
<ul>
<li>无论是训练还是验证，验证的误差都越来越低。</li>
<li>在Epoch训练后期，“loss训练的误差”比“val_loss验证的误差”小。</li>
</ul>
<h3 id="10-5-评估模型准确率"><a href="#10-5-评估模型准确率" class="headerlink" title="10.5 评估模型准确率"></a>10.5 评估模型准确率</h3><p>之前我们已经完成训练，现在要使用test测试数据集，评估模型准确率。</p>
<p>用下面的程序代码来评估模型准确率。</p>
<p><img src="Image00412.jpg" alt></p>
<p>从以上的执行结果可知准确率是0.71。以上程序代码说明见表10-3。</p>
<p>表10-3 程序代码说明</p>
<p><img src="Image00413.jpg" alt></p>
<h3 id="10-6-进行预测"><a href="#10-6-进行预测" class="headerlink" title="10.6 进行预测"></a>10.6 进行预测</h3><p>恭喜你，之前的步骤我们建立好了模型，并且完成了模型的训练，准确率达到了还可以接受的0.97，接下来我们将使用此模型进行预测。</p>
<h5 id="1．执行预测-1"><a href="#1．执行预测-1" class="headerlink" title="1．执行预测"></a>1．执行预测</h5><p>我们可以使用下列指令执行预测：</p>
<p><img src="Image00414.jpg" alt></p>
<p>下面的程序代码使用model.predict_classes，输入参数x_Test（测试数据的照片图像）来进行预测。</p>
<h5 id="2．预测结果-1"><a href="#2．预测结果-1" class="headerlink" title="2．预测结果"></a>2．预测结果</h5><p>可以使用下列指令来查看预测结果的前10项数据：</p>
<p><img src="Image00415.jpg" alt></p>
<p>可以看到第1项预测的结果是3，第2项是8……</p>
<h5 id="3．显示前10项预测结果"><a href="#3．显示前10项预测结果" class="headerlink" title="3．显示前10项预测结果"></a>3．显示前10项预测结果</h5><p>使用第9章修改的plot_images_labels_prediction函数显示前10项预测结果，传入测试数据图像、label（真实值）及prediction（预测结果）。</p>
<p><img src="Image00416.jpg" alt></p>
<h3 id="10-7-查看预测概率"><a href="#10-7-查看预测概率" class="headerlink" title="10.7 查看预测概率"></a>10.7 查看预测概率</h3><p>有时我们不只希望知道预测结果，还想要知道预测每一种类别的概率。</p>
<h5 id="1．使用测试数据进行预测"><a href="#1．使用测试数据进行预测" class="headerlink" title="1．使用测试数据进行预测"></a>1．使用测试数据进行预测</h5><p>我们使用model.predict输入测试数据，就可以预测概率。</p>
<p><img src="Image00417.jpg" alt></p>
<h5 id="2．建立show-Predicted-Probability函数"><a href="#2．建立show-Predicted-Probability函数" class="headerlink" title="2．建立show_Predicted_Probability函数"></a>2．建立show_Predicted_Probability函数</h5><p><img src="Image00418.jpg" alt></p>
<p>▶ 定义show_Predicted_Probability函数</p>
<p><img src="Image00419.jpg" alt></p>
<p>传入参数：y（真实值）、prediction（预测结果）、x_img（预测的图像）、Predicted_Probability（预测概率）、i（开始显示的数据index）。</p>
<p>▶ 显示 _y_ （真实值）与prediction（预测结果）</p>
<p><img src="Image00420.jpg" alt></p>
<p>▶ 设置显示图像的大小，并且显示出照片图像</p>
<p><img src="Image00421.jpg" alt></p>
<p>▶ 使用for循环读取Predicted_Probability显示预测概率</p>
<p><img src="Image00422.jpg" alt></p>
<p><img src="Image00423.jpg" alt></p>
<h5 id="3．查看第0项数据预测的概率（见图10-5）"><a href="#3．查看第0项数据预测的概率（见图10-5）" class="headerlink" title="3．查看第0项数据预测的概率（见图10-5）"></a>3．查看第0项数据预测的概率（见图10-5）</h5><p><img src="Image00424.jpg" alt></p>
<p>图10-5</p>
<p>从以上执行结果可知，这张照片图像预测为“猫”的概率最高，预测为“狗”的概率次高，所以最后预测的结果是“猫”预测正确。</p>
<h5 id="4．查看第3项数据预测的概率（见图10-6）"><a href="#4．查看第3项数据预测的概率（见图10-6）" class="headerlink" title="4．查看第3项数据预测的概率（见图10-6）"></a>4．查看第3项数据预测的概率（见图10-6）</h5><p><img src="Image00425.jpg" alt></p>
<p><img src="Image00426.jpg" alt></p>
<p>图10-6</p>
<p>从以上执行结果可知，这张照片图像预测为“船”的概率最高，预测为“飞机”的概率次高，所以最后预测的结果是“船”。但是真实值是“飞机”，所以此项预测是错误的。</p>
<h3 id="10-8-显示混淆矩阵"><a href="#10-8-显示混淆矩阵" class="headerlink" title="10.8 显示混淆矩阵"></a>10.8 显示混淆矩阵</h3><p>在上一节中我们看到了一个预测错误：真实值“飞机”预测成“船”了。如果我们想要进一步知道所建立的模型中哪些图像类别的预测准确率最高，哪些图像类别最容易混淆（预测错误），就可以使用混淆矩阵来显示。</p>
<h5 id="1．查看预测结果的形状"><a href="#1．查看预测结果的形状" class="headerlink" title="1．查看预测结果的形状"></a>1．查看预测结果的形状</h5><p>我们将使用pd.crosstab建立混淆矩阵，但是pd.crosstab的输入都必须是一维数组，所以要先确认prediction（预测结果）与y_label_test（真实值）是一维数组。如果不是一维数组，就必须先转换为一维数组。下列指令用于查看预测结果的shape形状。</p>
<p><img src="Image00427.jpg" alt></p>
<p>从以上执行结果可知预测结果是一维数组。</p>
<h5 id="2．查看y-label-test真实值的shape形状"><a href="#2．查看y-label-test真实值的shape形状" class="headerlink" title="2．查看y_label_test真实值的shape形状"></a>2．查看y_label_test真实值的shape形状</h5><p>用下列指令来查看y_label_test真实值的shape形状。</p>
<p><img src="Image00428.jpg" alt></p>
<p>从以上执行结果可知，y_label_test真实值的shape形状是二维数组，后面必须将它转换为一维数组。</p>
<h5 id="3．将y-label-test真实值转换为一维数组"><a href="#3．将y-label-test真实值转换为一维数组" class="headerlink" title="3．将y_label_test真实值转换为一维数组"></a>3．将y_label_test真实值转换为一维数组</h5><p>下面的程序代码使用reshape（-1）转换为一维数组。</p>
<p><img src="Image00429.jpg" alt></p>
<p>从以上执行结果可知已经转换为1维数组了。</p>
<h5 id="4．使用pandas-crosstab建立混淆矩阵"><a href="#4．使用pandas-crosstab建立混淆矩阵" class="headerlink" title="4．使用pandas crosstab建立混淆矩阵"></a>4．使用pandas crosstab建立混淆矩阵</h5><p>Pandas提供了用于建立混淆矩阵的功能。</p>
<p><img src="Image00430.jpg" alt></p>
<p>程序代码说明见表10-4。</p>
<p>表10-4 程序代码说明</p>
<p><img src="Image00431.jpg" alt></p>
<p>执行后显示混淆矩阵，如图10-7所示。</p>
<p><img src="Image00432.jpg" alt></p>
<p><img src="Image00433.jpg" alt></p>
<p>图10-7</p>
<p>从以上混淆矩阵，我们观察如下。</p>
<ul>
<li><strong>对角线是预测正确的，我们发现：</strong></li>
<li>真实值是6“蛙”，被正确预测为6“蛙”的项数有868项，最高，最不容易混淆。</li>
<li>真实值是3“猫”，被正确预测为3“猫”的项数有555项，最低，也就是说最容易混淆。</li>
<li><strong>其他非对角线的数字代表将某一个标签错误预测成为另一个标签，最容易混淆：</strong></li>
<li>真实值是5“狗”，但预测是3“猫”，项数有184项，最高，也就是说“狗”很容易被误认为“猫”。</li>
<li>真实值是3“猫”，但预测是5“狗”，项数有158项，次高，也就是说“狗”很容易被误认为“猫”。人类识别也很容易搞错“狗”与“猫”，难怪机器学习也预测错误。</li>
</ul>
<p>▶ 动物类不容易混淆为交通工具类</p>
<p>CIFAR-10的图像类别大约可以分为以下两大类。</p>
<ul>
<li><strong>动物类：</strong> 2（鸟）、3（猫）、4（鹿）、5（狗）、6（蛙）、7（马）。</li>
<li><strong>交通工具类：</strong> 0（飞机）、1（汽车）、8（船）、9（卡车）。</li>
</ul>
<p>我们还发现了一些有趣的现象：</p>
<ul>
<li>2、3、4、5、6、7预测为1的数量都是个位数。</li>
</ul>
<p>也就是说，2（鸟）、3（猫）、4（鹿）、5（狗）、6（蛙）、7（马）都是动物，不容易混淆为1（汽车）。</p>
<ul>
<li>但是8、9预测为1的数量都分别是十位数。</li>
</ul>
<p>也就是说，8（船）、9（卡车）属于交通工具，容易混淆为1（汽车），如图10-8所示。</p>
<p><img src="Image00434.jpg" alt></p>
<p>图10-8</p>
<h3 id="10-9-建立3次的卷积运算神经网络"><a href="#10-9-建立3次的卷积运算神经网络" class="headerlink" title="10.9 建立3次的卷积运算神经网络"></a>10.9 建立3次的卷积运算神经网络</h3><p>之前建立的卷积式神经网络执行结果的准确率只有0.738，我们希望能通过更多次的卷积运算提高准确率。下面的程序代码可参考范例程序Keras_Cifar_CNN_Deeper_Conv3.ipynb。</p>
<h5 id="1．建立3次的卷积运算的神经网络架构图（见图10-9）"><a href="#1．建立3次的卷积运算的神经网络架构图（见图10-9）" class="headerlink" title="1．建立3次的卷积运算的神经网络架构图（见图10-9）"></a>1．建立3次的卷积运算的神经网络架构图（见图10-9）</h5><h5 id="2．建立卷积层1与池化层1"><a href="#2．建立卷积层1与池化层1" class="headerlink" title="2．建立卷积层1与池化层1"></a>2．建立卷积层1与池化层1</h5><p>在下面的程序代码中，我们增加了一次Conv2D卷积运算。</p>
<p><img src="Image00435.jpg" alt></p>
<h5 id="3．建立卷积层2与池化层2"><a href="#3．建立卷积层2与池化层2" class="headerlink" title="3．建立卷积层2与池化层2"></a>3．建立卷积层2与池化层2</h5><p><img src="Image00436.jpg" alt></p>
<p><img src="Image00437.jpg" alt></p>
<p>图10-9</p>
<h5 id="4．新增加卷积层3与池化层3"><a href="#4．新增加卷积层3与池化层3" class="headerlink" title="4．新增加卷积层3与池化层3"></a>4．新增加卷积层3与池化层3</h5><p>下面再增加卷积层3与池化层3。</p>
<p><img src="Image00438.jpg" alt></p>
<h5 id="5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）"><a href="#5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）" class="headerlink" title="5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）"></a>5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）</h5><p>我们建立更宽、更深的神经网络，加入隐藏层1（2500个神经元）和隐藏层2（1500个神经元）。</p>
<p><img src="Image00439.jpg" alt></p>
<h5 id="6．训练模型"><a href="#6．训练模型" class="headerlink" title="6．训练模型"></a>6．训练模型</h5><p>为了增加准确率，我们执行了50个训练周期，需要花很长时间，如图10-10所示。</p>
<p><img src="Image00440.jpg" alt></p>
<p>图10-10</p>
<h5 id="7．评估模型的准确率"><a href="#7．评估模型的准确率" class="headerlink" title="7．评估模型的准确率"></a>7．评估模型的准确率</h5><p><img src="Image00441.jpg" alt></p>
<p>评估模型准确率从0.738提高到了0.788。</p>
<h3 id="10-10-模型的保存与加载"><a href="#10-10-模型的保存与加载" class="headerlink" title="10.10 模型的保存与加载"></a>10.10 模型的保存与加载</h3><p>上一节的Keras_Cifar_CNN_Deeper_Conv3.ipynb程序训练必须花很长时间，往往需要数小时。有时还可能因为某些原因导致计算机宕机，这样之前的训练就前功尽弃了，解决的方法是：每次程序执行完成训练后，将模型权重保存一下。下次程序执行训练之前，先加载模型权重，再继续训练。</p>
<p>下面的程序代码可参考范例程序Keras_Cifar_CNN_Continue_Train.ipynb。</p>
<p><img src="Image00442.jpg" alt> 设置训练周期。</p>
<p>每次训练周期不要设置得太多，例如下面的范例中，epochs设置为5。</p>
<p><img src="Image00443.jpg" alt></p>
<p><img src="Image00444.jpg" alt> 在执行训练之前加载模型权重。</p>
<p>在执行训练之前，先使用model.load_weights加载模型权重。</p>
<p><img src="Image00445.jpg" alt></p>
<p>从以上执行结果可知，因为第一次执行尚未保存模型权重，所以会显示“加载模型失败！开始训练一个新模型”。</p>
<p><img src="Image00446.jpg" alt> 在程序的最后保存模型权重。</p>
<p>将这次执行5个训练周期的结果使用model.save_weights保存在文件中。</p>
<p><img src="Image00447.jpg" alt></p>
<p><img src="Image00448.jpg" alt> 第2次执行程序。</p>
<p>第2次执行程序，在执行训练之前，一样先使用model.load_weights加载模型权重。</p>
<p><img src="Image00449.jpg" alt></p>
<p>从以上执行结果可知，因为第2次执行会加载之前保存的模型权重，所以会显示“加载模型成功！继续训练模型”，这样就可以接在第一次的执行结果之后继续训练。</p>
<h3 id="10-11-结论"><a href="#10-11-结论" class="headerlink" title="10.11 结论"></a>10.11 结论</h3><p>在本章中，我们介绍了使用Keras建立卷积神经网络识别CIFAR-10图像数据。后续章节我们将以多层感知器模型来预测泰坦尼克号乘客的生存概率。</p>
<h1 id="第11章-Keras泰坦尼克号上的旅客数据集"><a href="#第11章-Keras泰坦尼克号上的旅客数据集" class="headerlink" title="第11章 Keras泰坦尼克号上的旅客数据集"></a>第11章 Keras泰坦尼克号上的旅客数据集</h1><p>泰坦尼克号的沉没是历史悲剧。1912年4月15日泰坦尼克号在首航时，撞上冰山沉没，乘客和船员共2224人，其中1502人死亡。这场悲剧震撼了国际社会，之后船舶行业制定了更好的安全规定。泰坦尼克号的旅客数据集被完整地保留下来。我们在本章中先介绍数据的预处理，下一章将建立多层感知器模型来预测每一位乘客的存活率。</p>
<p>如图11-1所示，以多层感知器模型来预测泰坦尼克号乘客的生存概率，可分为训练与预测两部分。</p>
<p>▶ 训练</p>
<p>泰坦尼克号数据集的训练数据共有1309项，经过数据预处理后会产生feature，（共有9个特征字段，例如性别、年龄等）与label标签字段（是否生存？1：是，2：否），然后输入多层感知器模型进行训练，训练完成的模型就可以在下一阶段进行预测时使用。</p>
<p>▶ 预测</p>
<p>输入新的泰坦尼克号数据，预处理后会产生features（9个特征字段），使用训练完成的多层感知器模型进行预测，最后产生预测结果：生存概率。</p>
<p><img src="Image00450.jpg" alt></p>
<p>图11-1</p>
<p>本章完整的程序代码可参考范例程序Keras_Taianic_Introduce.ipynb。范例程序下载与安装可参考本书附录A。</p>
<h3 id="11-1-下载泰坦尼克号旅客数据集"><a href="#11-1-下载泰坦尼克号旅客数据集" class="headerlink" title="11.1 下载泰坦尼克号旅客数据集"></a>11.1 下载泰坦尼克号旅客数据集</h3><h5 id="1．导入下载所需模块"><a href="#1．导入下载所需模块" class="headerlink" title="1．导入下载所需模块"></a>1．导入下载所需模块</h5><p><img src="Image00451.jpg" alt></p>
<p>以上程序代码的说明见表11-1。</p>
<p>表11-1 程序代码说明</p>
<p><img src="Image00452.jpg" alt></p>
<h5 id="2．下载泰坦尼克号的旅客数据集"><a href="#2．下载泰坦尼克号的旅客数据集" class="headerlink" title="2．下载泰坦尼克号的旅客数据集"></a>2．下载泰坦尼克号的旅客数据集</h5><p>使用下面的程序代码来下载泰坦尼克号的旅客数据集。</p>
<p><img src="Image00453.jpg" alt></p>
<p>从以上执行结果可知，程序会下载titanic3.xls，并且存储在程序执行目录下的data目录中。</p>
<p>▶ 设置下载的网址</p>
<p><img src="Image00454.jpg" alt></p>
<p>▶ 设置存储文件的路径</p>
<p><img src="Image00455.jpg" alt></p>
<p>▶ 判断文件不存在就会下载文件</p>
<p><img src="Image00456.jpg" alt></p>
<p>以上程序代码在判断文件不存在之后，就会使用urllib.request.urlretrieve下载文件。输入参数：url（下载的网址）与filepath（存储文件的路径）。</p>
<h5 id="3．查看已下载的文件"><a href="#3．查看已下载的文件" class="headerlink" title="3．查看已下载的文件"></a>3．查看已下载的文件</h5><p>查看下载的数据文件，根据使用的环境是Windows或Linux Ubuntu而稍有不同，说明如下：</p>
<p>▶ 在Windows下查看已下载的数据文件</p>
<p>我们可以使用文件资源管理器来查看程序执行目录下的data目录，例如：我们的执行目录是C：\pythonwork\keras，就可以在C：\pythonwork\keras\data看到已下载的titanic3.xls文件，如图11-2所示。</p>
<p><img src="Image00457.jpg" alt></p>
<p>图11-2</p>
<p>▶ 在Linux Ubuntu下查看已下载的数据文件</p>
<p>在“终端”程序输入下列命令，先切换到程序执行目录，再查看目录。</p>
<p><img src="Image00458.jpg" alt></p>
<p>执行后屏幕显示的界面如图11-3所示，我们可以看到已下载的titanic3.xls文件。</p>
<p><img src="Image00459.jpg" alt></p>
<p>图11-3</p>
<h3 id="11-2-使用Pandas-DataFrame读取数据并进行预处理"><a href="#11-2-使用Pandas-DataFrame读取数据并进行预处理" class="headerlink" title="11.2 使用Pandas DataFrame读取数据并进行预处理"></a>11.2 使用Pandas DataFrame读取数据并进行预处理</h3><p>Pandas为Python提供了DataFrame功能，可以很方便地处理数据。</p>
<p><img src="Image00460.jpg" alt> 导入所需模块。</p>
<p><img src="Image00461.jpg" alt></p>
<p><img src="Image00462.jpg" alt> 读取titanic3.xls。</p>
<p>下面的程序代码使用Pandas所提供的read_excel（）方法把titanic3.xls文件读取到all_df DataFrame。</p>
<p><img src="Image00463.jpg" alt></p>
<p><img src="Image00464.jpg" alt> 查看前两项数据。</p>
<p>下面的程序代码用来查看前两项泰坦尼克号的旅客数据。</p>
<p><img src="Image00465.jpg" alt></p>
<p>以上各个字段说明见表11-2。</p>
<p>表11-2 字段说明</p>
<p><img src="Image00466.jpg" alt></p>
<p>（续表）</p>
<p><img src="Image00467.jpg" alt></p>
<p>以上字段中survival（是否生存）是label标签字段，也就是我们要预测的目标，其余都是特征字段。</p>
<p><img src="Image00468.jpg" alt> 把需要的字段选取到DataFrame中。</p>
<p>以上字段中的ticket（船票号码）、cabin（舱位号码），我们认为与要预测的结果survived（是否生存）关联不大，所以我们将其忽略，只选择下列字段到DataFrame中。</p>
<p><img src="Image00469.jpg" alt></p>
<p><img src="Image00470.jpg" alt> 选取字段后，显示前两项数据。</p>
<p><img src="Image00471.jpg" alt></p>
<p>在以上字段中，还有表11-3中的问题必须进行预处理，后续才能够进行机器学习训练。</p>
<p>表11-3 还需要处理的问题</p>
<p><img src="Image00472.jpg" alt></p>
<h3 id="11-3-使用Pandas-DataFrame进行数据预处理"><a href="#11-3-使用Pandas-DataFrame进行数据预处理" class="headerlink" title="11.3 使用Pandas DataFrame进行数据预处理"></a>11.3 使用Pandas DataFrame进行数据预处理</h3><p>使用Pandas DataFrame进行数据预处理，后续才能够进行深度学习训练。</p>
<p><img src="Image00473.jpg" alt> 将name字段删除。</p>
<p>下面的程序代码all_df使用drop方法删除name字段。</p>
<p><img src="Image00474.jpg" alt></p>
<p><img src="Image00475.jpg" alt> 找出含有null值的字段。</p>
<p>我们可以使用下列指令找出含有null值（无数据）的字段。</p>
<p><img src="Image00476.jpg" alt></p>
<p>因为在后续进行深度学习训练时字段数据必须是数字，不能是null值，所以必须将null字段填上数值。至于要填上什么数值，最简单的方法是填上0，但是0不符合实际状态，例如年龄应该不会是0岁，fare运费应该也不会是0，所以我们将null值替换为字段的平均值，这样比较符合实际情况。</p>
<p><img src="Image00477.jpg" alt> 将age字段为null的数据替换成平均值。</p>
<p>下面的程序代码先使用df［’age’］.mean（）方法计算age字段的平均值age_mean，然后使用df［’age’］.fillna（age_mean）将null值替换成平均值。</p>
<p><img src="Image00478.jpg" alt></p>
<p><img src="Image00479.jpg" alt> 将fare字段为null的数据替换成平均值。</p>
<p>下面的程序代码先使用df［’fare’］.mean（）方法计算fare字段的平均值fare_mean，然后使用df［’fare’］.fillna（fare_mean）将null值替换成平均值。</p>
<p><img src="Image00480.jpg" alt></p>
<p><img src="Image00481.jpg" alt> 转换性别字段为0与1。</p>
<p>原本性别字段是文字，我们必须转换为0与1，这样后续才能进行机器学习训练。以下程序代码使用map方法将’female’转换为0，’male’转换为1。</p>
<p><img src="Image00482.jpg" alt></p>
<p><img src="Image00483.jpg" alt> 将embarked字段进行一位有效编码转换。</p>
<p>Pandas提供了一个很方便的方法进行一位有效编码转换，使用get_dummies（）传入下列参数。</p>
<ul>
<li><strong>data：</strong> 要转换的DataFrame，在此输入df。</li>
<li><strong>columns：</strong> 要转换的字段，在此输入［“embarked“］。</li>
</ul>
<p><img src="Image00484.jpg" alt></p>
<p><img src="Image00485.jpg" alt> 查看转换后的DataFrame。</p>
<p><img src="Image00486.jpg" alt></p>
<h3 id="11-4-将DataFrame转换为Array"><a href="#11-4-将DataFrame转换为Array" class="headerlink" title="11.4 将DataFrame转换为Array"></a>11.4 将DataFrame转换为Array</h3><p>因为后续要进行深度学习训练，所以必须先将DataFrame转换为Array。</p>
<p><img src="Image00487.jpg" alt> DataFrame转换为Array。</p>
<p><img src="Image00488.jpg" alt></p>
<p><img src="Image00489.jpg" alt> 查看ndarray的shape。</p>
<p>可以使用下列指令来查看array的shape。</p>
<p><img src="Image00490.jpg" alt></p>
<p>从以上执行结果可知，ndarray共1309项10个字段。</p>
<p><img src="Image00491.jpg" alt> 查看ndarray的前两项数据。</p>
<p>可以使用下列指令来查看ndarray的前两项数据。</p>
<p><img src="Image00492.jpg" alt></p>
<p>从以上执行结果可知，第0个字段是label，第1个字段及之后的字段是features。</p>
<p><img src="Image00493.jpg" alt> 提取features与label。</p>
<p>可以使用下列Python slice语句来提取features与label。</p>
<p><img src="Image00494.jpg" alt></p>
<p>以上程序代码说明：ndarray共有二维，第一维是项数，第二维是字段。</p>
<p><img src="Image00495.jpg" alt></p>
<p><img src="Image00496.jpg" alt> 查看前两项label标签字段。</p>
<p><img src="Image00497.jpg" alt></p>
<p><img src="Image00498.jpg" alt> 查看前两项features特征字段。</p>
<p><img src="Image00499.jpg" alt></p>
<p>从以上执行结果可知，因为数值特征字段单位不同，例如年龄29岁、运费211元等，数字差异很大，没有一个共同的标准。这时就要使用标准化让所有数值都在0与1之间，使数值特征字段有共同的标准。进行标准化可以提高训练后模型的准确率。我们将在下一节介绍如何进行标准化。</p>
<h3 id="11-5-将ndarray特征字段进行标准化"><a href="#11-5-将ndarray特征字段进行标准化" class="headerlink" title="11.5 将ndarray特征字段进行标准化"></a>11.5 将ndarray特征字段进行标准化</h3><p>我们将使用sklearn提供的preprocessing数据预处理模块进行标准化。</p>
<p><img src="Image00500.jpg" alt> 导入sklearn的数据预处理模块。</p>
<p><img src="Image00501.jpg" alt></p>
<p><img src="Image00502.jpg" alt> 建立MinMaxScaler标准化刻度minmax_scale。</p>
<p>我们将使用preprocessing.MinMaxScaler来进行标准化，需输入参数feature_range设置标准化之后的范围在0和1之间。程序代码如下：</p>
<p><img src="Image00503.jpg" alt></p>
<p><img src="Image00504.jpg" alt> 使用minmax_scale.fit_transform进行标准化。</p>
<p>然后使用minmax_scale.fit_transform传入参数Features（特征字段）进行标准化。程序代码如下：</p>
<p><img src="Image00505.jpg" alt></p>
<p><img src="Image00506.jpg" alt> 查看标准化之后的特征字段前两项数据。</p>
<p><img src="Image00507.jpg" alt></p>
<p>从以上执行结果可知，标准化之后的数字都介于0与1之间。</p>
<h3 id="11-6-将数据分为训练数据与测试数据"><a href="#11-6-将数据分为训练数据与测试数据" class="headerlink" title="11.6 将数据分为训练数据与测试数据"></a>11.6 将数据分为训练数据与测试数据</h3><p>因为在后面要进行深度学习模型的训练，所以必须将数据分为训练数据（用于训练模型）与测试数据（用于计算“训练完成模型”的准确率）。</p>
<p><img src="Image00508.jpg" alt> 将数据以随机方式分为训练数据与测试数据。</p>
<p><img src="Image00509.jpg" alt></p>
<p>▶ 按照8：2的比例使用numpy.random.rand产生msk</p>
<p><img src="Image00510.jpg" alt></p>
<p>▶ 产生训练数据，为全部数据的80%</p>
<p><img src="Image00511.jpg" alt></p>
<p>▶ 产生测试数据，为全部数据的20%</p>
<p><img src="Image00512.jpg" alt></p>
<p><img src="Image00513.jpg" alt> 显示训练数据与测试数据项数。</p>
<p><img src="Image00514.jpg" alt></p>
<p><img src="Image00515.jpg" alt> 创建PreprocessData函数进行数据的预处理。</p>
<p>我们将之前数据预处理的命令全部收集在PreprocessData函数中，方便后续使用。</p>
<p><img src="Image00516.jpg" alt></p>
<p><img src="Image00517.jpg" alt> 对训练数据与测试数据进行预处理。</p>
<p><img src="Image00518.jpg" alt></p>
<p>数据预处理后的结果如下：</p>
<ul>
<li>train_Features（训练数据的特征字段），train_Label（训练数据的标签字段）。</li>
<li>test_Features（测试数据的特征字段），test_Label（测试数据的标签字段）。</li>
</ul>
<p><img src="Image00519.jpg" alt> 查看数据预处理后训练数据的特征字段。</p>
<p>数据预处理之后，查看train_Features（训练数据的特征字段）的前两项数据。</p>
<p><img src="Image00520.jpg" alt></p>
<p><img src="Image00521.jpg" alt> 查看数据预处理后训练数据的标签字段。</p>
<p>数据预处理之后，查看train_Label（训练数据的标签字段）的前两项数据。</p>
<p><img src="Image00522.jpg" alt></p>
<h3 id="11-7-结论"><a href="#11-7-结论" class="headerlink" title="11.7 结论"></a>11.7 结论</h3><p>在本章中，我们介绍了下载并且读取泰坦尼克号的旅客数据集，并介绍了泰坦尼克号数据集的特色，最后完成数据的预处理。在下一章，我们就可以使用Keras建立多层感知器模型，训练模型并进行预测。</p>
<h1 id="第12章-Keras多层感知器预测泰坦尼克号上旅客的生存概率"><a href="#第12章-Keras多层感知器预测泰坦尼克号上旅客的生存概率" class="headerlink" title="第12章 Keras多层感知器预测泰坦尼克号上旅客的生存概率"></a>第12章 Keras多层感知器预测泰坦尼克号上旅客的生存概率</h1><p>在本章中，我们将建立多层感知器模型，训练模型、评估模型的准确率，然后使用训练完成的模型来预测泰坦尼克号上旅客生存的概率，并预测《泰坦尼克号》电影中男女主角生存的概率，找出泰坦尼克号上其他旅客的感人故事。</p>
<p>我们将建立多层感知器模型，如图12-1所示。</p>
<p><img src="Image00523.jpg" alt></p>
<p>图12-1</p>
<p>本章完整的程序代码可参考范例程序Keras_Taianic_MLP.ipynb。范例程序下载与安装可参考本书附录A。</p>
<h3 id="12-1-数据预处理"><a href="#12-1-数据预处理" class="headerlink" title="12.1 数据预处理"></a>12.1 数据预处理</h3><p>以下数据预处理的详细说明可参考11章的内容。</p>
<p><img src="Image00524.jpg" alt> 导入所需模块。</p>
<p><img src="Image00525.jpg" alt></p>
<p><img src="Image00526.jpg" alt> 读取泰坦尼克号的数据集文件。</p>
<p><img src="Image00527.jpg" alt></p>
<p><img src="Image00528.jpg" alt> 把需要的字段选取到DataFrame中。</p>
<p><img src="Image00529.jpg" alt></p>
<p><img src="Image00530.jpg" alt> 依照8：2的比例将数据分为训练数据与测试数据。</p>
<p><img src="Image00531.jpg" alt></p>
<p><img src="Image00532.jpg" alt> 显示训练数据与测试数据的项数。</p>
<p><img src="Image00533.jpg" alt></p>
<p><img src="Image00534.jpg" alt> 将训练数据与测试数据进行预处理。</p>
<p><img src="Image00535.jpg" alt></p>
<p>使用上一章中创建的PreprocessData函数对训练数据与测试数据进行预处理：</p>
<ul>
<li>train_Features（训练数据的特征字段），train_Label（训练数据的标签字段）。</li>
<li>test_Features（测试数据的特征字段），test_Label（测试数据的标签字段）。</li>
</ul>
<h3 id="12-2-建立模型"><a href="#12-2-建立模型" class="headerlink" title="12.2 建立模型"></a>12.2 建立模型</h3><p>我们将使用下面的程序代码建立多层感知器模型：输入层（9个神经元）、隐藏层1（40个神经元）、隐藏层2（30个神经元）、输出层（1个神经元），如图12-2所示。</p>
<p><img src="Image00536.jpg" alt></p>
<p>图12-2</p>
<p><img src="Image00537.jpg" alt> 导入所需模块。</p>
<p><img src="Image00538.jpg" alt></p>
<p><img src="Image00539.jpg" alt> 建立keras Sequential模型。</p>
<p>下面的程序代码建立一个线性堆叠模型，后续只需要将各个神经网络层加入模型即可。</p>
<p><img src="Image00540.jpg" alt></p>
<p><img src="Image00541.jpg" alt> 建立输入层与隐藏层1。</p>
<p>下面的程序代码使用model.add方法加入Dense神经网络层。Dense神经网络层的特色是：所有的上一层与下一层的神经元都完全连接。</p>
<p><img src="Image00542.jpg" alt></p>
<p>model加入Dense层，需输入下列参数。</p>
<ul>
<li><strong>units＝40：</strong> 输出是“隐藏层1”共有40个神经元。</li>
<li><strong>input_dim＝9：</strong> 输入层有9个神经元的输入，因为数据预处理后有9个特征字段。</li>
<li><strong>kernel_initializer＝’uniform’：</strong> 使用uniform distribution分布的随机数初始化weight与bias。</li>
<li><strong>activation＝’relu’：</strong> 定义激活函数ReLU。</li>
</ul>
<p><img src="Image00543.jpg" alt> 建立隐藏层2。</p>
<p><img src="Image00544.jpg" alt></p>
<p>model加入Dense层需输入下列参数。</p>
<ul>
<li><strong>units＝30：</strong> 输出是“隐藏层2”共有30个神经元。</li>
<li><strong>kernel_initializer＝’uniform’：</strong> 使用uniform distribution分布的随机数初始化weight与bias。</li>
<li><strong>activation＝’relu’：</strong> 定义激活函数ReLU。</li>
</ul>
<p><img src="Image00545.jpg" alt> 建立输出层。</p>
<p><img src="Image00546.jpg" alt></p>
<p>model加入Dense层需输入下列参数。</p>
<ul>
<li><strong>units＝1：</strong> “输出层”共有一个神经元。</li>
<li><strong>kernel_initializer＝’uniform’：</strong> 使用uniform distribution分布初始化weight与bias。</li>
<li><strong>activation＝’relu’：</strong> 定义激活函数ReLU。</li>
</ul>
<h3 id="12-3-开始训练"><a href="#12-3-开始训练" class="headerlink" title="12.3 开始训练"></a>12.3 开始训练</h3><p>当我们建立好深度学习模型后，就可以使用反向传播算法进行训练。有关使用反向传播算法进行训练的说明可参考第2章。</p>
<h5 id="1．定义训练方式-3"><a href="#1．定义训练方式-3" class="headerlink" title="1．定义训练方式"></a>1．定义训练方式</h5><p>在训练模型之前，我们必须使用compile方法对训练模型进行设置，指令如下：</p>
<p><img src="Image00547.jpg" alt></p>
<p>compile方法需输入3个参数：loss、optimizer和metrics（对这3个参数的解释说明可参考7.4节）。</p>
<h5 id="2．开始训练-3"><a href="#2．开始训练-3" class="headerlink" title="2．开始训练"></a>2．开始训练</h5><p>执行训练的程序代码如下：</p>
<p><img src="Image00548.jpg" alt></p>
<p>以上程序代码说明如下：</p>
<p>使用model.fit进行训练，训练过程会存储在train_history变量中，这个训练需输入下列参数。</p>
<p>（1）输入训练数据的参数</p>
<ul>
<li>_x_ ＝train_Features，features共9个特征字段。</li>
<li>_y_ ＝train_Label，label标签字段（是否生存？是：1，否：0）。</li>
</ul>
<p>（2）设置训练与验证数据的比例</p>
<ul>
<li>设置参数validation_split＝0.1。</li>
</ul>
<p>训练之前Keras会自动将数据分成：90%作为训练数据，10%作为验证数据。因为全部是1034项，所以分成：1034×0.9＝930作为训练数据，1034×0.1＝104作为验证数据。</p>
<p>（3）设置训练周期次数与每一批次的项数</p>
<ul>
<li>epochs＝30：执行30个训练周期。</li>
<li>batch_size＝30：每一批次30项数据。</li>
</ul>
<p>共执行了30个训练周期，说明如下：</p>
<ul>
<li>每一个训练周期，使用930项训练数据进行训练，分为每一批次30项，所以大约分为31个批次（930/30＝31）进行训练。</li>
<li>这个训练周期完成后，计算此次训练周期后的准确率与误差。</li>
</ul>
<p>（4）设置显示训练过程</p>
<ul>
<li>verbose＝2：显示训练过程。</li>
</ul>
<p>▶ 以上程序代码执行后结果如图12-3所示。</p>
<p><img src="Image00549.jpg" alt></p>
<p>图12-3</p>
<h5 id="3．画出准确率的执行结果"><a href="#3．画出准确率的执行结果" class="headerlink" title="3．画出准确率的执行结果"></a>3．画出准确率的执行结果</h5><p>使用下面的程序代码画出准确率的执行结果。</p>
<p><img src="Image00550.jpg" alt></p>
<p>在以上执行结果的屏幕显示界面中，“acc训练的准确率”是深色的，“val_acc验证的准确率”是浅色的，总共执行了10个训练周期，我们可以发现：无论是训练还是验证，准确率都越来越高。</p>
<h5 id="4．画出误差的执行结果-1"><a href="#4．画出误差的执行结果-1" class="headerlink" title="4．画出误差的执行结果"></a>4．画出误差的执行结果</h5><p><img src="Image00551.jpg" alt></p>
<p>在以上执行结果的屏幕显示界面中，我们可以看到共执行了30个训练周期，“loss训练的误差”是深色的，“val_loss验证的误差”是浅色的，我们还可以发现，无论是训练还是验证，误差都越来越低。</p>
<h3 id="12-4-评估模型准确率"><a href="#12-4-评估模型准确率" class="headerlink" title="12.4 评估模型准确率"></a>12.4 评估模型准确率</h3><p>之前我们已经训练完模型，现在要使用test测试数据集来评估模型的准确率。</p>
<h5 id="1．评估模型的准确率"><a href="#1．评估模型的准确率" class="headerlink" title="1．评估模型的准确率"></a>1．评估模型的准确率</h5><p>下面的程序代码用来评估模型的准确率。</p>
<p><img src="Image00552.jpg" alt></p>
<p>以上程序代码说明见表12-1。</p>
<p>表12-1 程序代码说明</p>
<p><img src="Image00553.jpg" alt></p>
<h5 id="2．查看评估的准确率"><a href="#2．查看评估的准确率" class="headerlink" title="2．查看评估的准确率"></a>2．查看评估的准确率</h5><p><img src="Image00554.jpg" alt></p>
<p>从以上执行结果可知准确率是0.80。</p>
<h3 id="12-5-加入《泰坦尼克号》电影中Jack与Rose的数据"><a href="#12-5-加入《泰坦尼克号》电影中Jack与Rose的数据" class="headerlink" title="12.5 加入《泰坦尼克号》电影中Jack与Rose的数据"></a>12.5 加入《泰坦尼克号》电影中Jack与Rose的数据</h3><p>在《泰坦尼克号》电影中，男女主角Jack与Rose是虚构人物，我们希望能用所训练完成的模型预测男女主角的生存概率。以下这些数据是我们根据电影剧情所猜想的：</p>
<ul>
<li>Jack是3等舱，Rose是头等舱。</li>
<li>Jack是男性，Rose是女性。</li>
<li>Jack的票价是5，Rose的票价是100。</li>
<li>Jack的年龄是23，Rose的年龄是20。</li>
</ul>
<p><img src="Image00555.jpg" alt> 建立Jack与Rose的数据。</p>
<p>使用pd.Series建立Jack与Rose的数据如下：</p>
<p><img src="Image00556.jpg" alt></p>
<p><img src="Image00557.jpg" alt> 创建Jack与Rose的DataFrame。</p>
<p>使用pd.DataFrame创建Pandas DataFrame JR_df，加入Jack与Rose的数据。</p>
<p><img src="Image00558.jpg" alt></p>
<p><img src="Image00559.jpg" alt> 将JR_df加入all_df。</p>
<p>因为我们后续要使用all_df进行预测，所以我们将JR_df加入all_df。</p>
<p><img src="Image00560.jpg" alt></p>
<p><img src="Image00561.jpg" alt> 查看all_df最后两项数据。</p>
<p>将JR_df加入all_df后，最后两项数据就是Jack与Rose的数据。</p>
<p><img src="Image00562.jpg" alt></p>
<h3 id="12-6-进行预测"><a href="#12-6-进行预测" class="headerlink" title="12.6 进行预测"></a>12.6 进行预测</h3><p>在前面的步骤中我们建立了模型，并且完成了模型的训练，准确率达到还可以接受的0.80，接下来我们将使用此模型进行预测。</p>
<p><img src="Image00563.jpg" alt> 执行数据预处理。</p>
<p>因为Jack与Rose的数据是后来才加入的，所以必须再次执行数据预处理。</p>
<p><img src="Image00564.jpg" alt></p>
<p><img src="Image00565.jpg" alt> 执行预测。</p>
<p>使用model.predict传入参数all_Features（特征字段）执行预测，返回预测结果all_probability。</p>
<p><img src="Image00566.jpg" alt></p>
<p><img src="Image00567.jpg" alt> 预测结果。</p>
<p>使用下列指令来查看预测结果all_probability的前10项数据。</p>
<p><img src="Image00568.jpg" alt></p>
<p>以上预测结果其实就是每一位旅客的生存概率。</p>
<p><img src="Image00569.jpg" alt> 将all_df与all_probability整合。</p>
<p>接下来，我们将all_df（姓名与所有特征字段）与all_probability（预测结果）整合产生pd DataFrame。</p>
<p><img src="Image00570.jpg" alt></p>
<p><img src="Image00571.jpg" alt> 查看预测《泰坦尼克号》电影中Jack与Rose生存概率的结果。</p>
<p>我们可以使用pd［-2：］选取DataFrame最后两项数据，那就是Jack与Rose生存概率的结果。</p>
<p><img src="Image00572.jpg" alt></p>
<p>从以上执行结果可知，Jack的生存概率只有0.14，Rose的生存概率高达0.96，符合电影最后的结局。</p>
<h3 id="12-7-找出泰坦尼克号背后的感人故事"><a href="#12-7-找出泰坦尼克号背后的感人故事" class="headerlink" title="12.7 找出泰坦尼克号背后的感人故事"></a>12.7 找出泰坦尼克号背后的感人故事</h3><p>数据科学家在处理数据时，常常只会看到冷冰冰的数据，而忘记这些数据背后的故事，每一项数据都曾经是活生生的人，他们都有父母家人，有很多感人的故事。</p>
<h5 id="1．查看生存概率高，却没有存活的旅客"><a href="#1．查看生存概率高，却没有存活的旅客" class="headerlink" title="1．查看生存概率高，却没有存活的旅客"></a>1．查看生存概率高，却没有存活的旅客</h5><p>我们也许会好奇，根据模型，哪些旅客预测生存概率高，可是却没有存活？Pandas提供了很方便的功能，可以让我们按照条件查询所需要的数据。</p>
<p>使用下列pandas的语句来查询生存概率大于90%但是没有存活的数据，结果如图12-4所示。</p>
<ul>
<li>pd［’probability’］＞ 0.9：生存概率大于90%。</li>
<li>pd［’survived’］ ＝＝ 0：没有存活。</li>
</ul>
<p><img src="Image00573.jpg" alt></p>
<p><img src="Image00574.jpg" alt></p>
<p>图12-4</p>
<p>图12-4的数据中，Allison，Miss.Helen Loraine与Allison，Mrs.Hudson JC都是Allison家族的人，他们依照我们的模型生存概率高，可是却没有存活，到底发生了什么事呢？</p>
<h5 id="2．Allison家族的故事"><a href="#2．Allison家族的故事" class="headerlink" title="2．Allison家族的故事"></a>2．Allison家族的故事</h5><p>显示前5项预测结果（见图12-5）：</p>
<p><img src="Image00575.jpg" alt></p>
<p><img src="Image00576.jpg" alt></p>
<p>图12-5</p>
<p>真实沉船中Allison家族的故事是，Allison一家人共有4位成员，即爸爸（30岁）、妈妈（25岁）、一个两岁的女儿Loraine以及一个不满一岁的婴儿Trevor。他们全家加上一名护士（AliceCleaver）乘坐邮轮返回加拿大蒙特利尔。</p>
<p>因为搭乘救生艇女士优先，原本妈妈可以带着女儿与小婴儿上救生艇，但是因为找不到婴儿Trevor，所以坚持不愿意上救生艇，而在船上到处寻找婴儿，最后全家一起在船上沉没。</p>
<p>然而命运捉弄人的是，原来小婴儿Trevor早就被护士（AliceCleaver）带上救生艇，但是没有告知Allison家人，导致全家人都找不到婴儿。最后Allison全家只有不满一岁的小婴儿Trevor存活，但是失去了所有亲人。还好后来小婴儿Trevor回到加拿大，由他的叔叔婶婶抚养长大。</p>
<h5 id="3．爱狗女士的故事"><a href="#3．爱狗女士的故事" class="headerlink" title="3．爱狗女士的故事"></a>3．爱狗女士的故事</h5><p>查询生存概率大于90%却没有存活的数据，我们可以看到Ann Elizabeth Isham，如图12-6所示。</p>
<p><img src="Image00577.jpg" alt></p>
<p>图12-6</p>
<p>一位50岁的女乘客Ann ElizabethIsham，她住在巴黎，要搭船返回美国，带着她的爱狗搭乘泰坦尼克号，于是将自己心爱的大丹狗安置在船上的狗舍，并且每日探望。发生船难时，Ann问自己的狗是否可以上救生艇，但是被拒绝。然而Ann实在无法抛弃心爱的狗独自逃生，对Ann而言，狗是她的家人，于是舍弃生还机会，宁愿与爱狗共存亡。</p>
<h5 id="4．施特劳斯夫妇的故事"><a href="#4．施特劳斯夫妇的故事" class="headerlink" title="4．施特劳斯夫妇的故事"></a>4．施特劳斯夫妇的故事</h5><p>查询生存概率大于90%却没有存活的数据，我们还可以看到Struss Isidor，如图12-7所示。</p>
<p><img src="Image00578.jpg" alt></p>
<p>图12-7</p>
<p>伊思德·施特劳斯（Isidor Straus）是美国知名百货梅西百货（Macy’s）的共同创办人，与他的太太艾达·施特劳斯（IdaStraus）登上泰坦尼克号，准备从欧洲回到美国的家。然而发生船难时，得知轮船即将沉没，埃达本来有机会逃生，但是不愿意离开丈夫，拒绝独自乘坐救生船逃生。于是埃达将自己的皮大衣送给了女仆埃伦（Ellen），让埃伦登上了救生船。据救生艇上的目击者说，当时记得艾达对丈夫说：“我们已经一起生活这么多年了，无论你在哪，我就去哪（Whereyou go，I go）”。</p>
<h3 id="12-8-结论"><a href="#12-8-结论" class="headerlink" title="12.8 结论"></a>12.8 结论</h3><p>在本章中，我们建立了多层感知器模型，经过数据预处理、训练模型，使用训练完成的模型来预测泰坦尼克号上旅客的生存概率，并且找出泰坦尼克号背后的感人故事。在下一章我们将介绍IMDb网络电影数据库与自然语言处理。</p>
<h1 id="第13章-IMDb网络电影数据集与自然语言处理"><a href="#第13章-IMDb网络电影数据集与自然语言处理" class="headerlink" title="第13章 IMDb网络电影数据集与自然语言处理"></a>第13章 IMDb网络电影数据集与自然语言处理</h1><p>情感分析（sentiment analysis）又称为意见挖掘（opinionmining），是使用“自然语言处理”、文字分析等方法找出作者某些话题上的态度、情感、评价或情绪。情感分析的商业价值在于，可提早得知顾客对公司或产品的观感，以调整销售策略的方向。第13、14章我们将介绍IMDb网络电影数据集，使用词嵌入（WordEmbedding）自然语言处理的方法进行预处理，并且建立各种深度学习模型，进行情感分析。</p>
<p>IMDb网络电影数据库（Internet MovieDatabase）是一个与电影相关的在线数据库。IMDb开始于1990年，自1998年起成为亚马逊旗下的网站，至今已经累积了大量的电影信息。IMDb收录了共400多万部电影作品数据。IMDb的网址为<a href="http://www.imdb.com／。" target="_blank" rel="noopener">http://www.imdb.com／。</a></p>
<p>IMDb数据集共有50 000项“影评文字”，分为训练数据与测试数据各25 000项，每一项“影评文字”都被标记为“正面评价”或“负面评价”。</p>
<p>我们希望能建立一个模型，经过大量“影评文字”训练后，此模型可以用于预测“影评文字”是“正面评价”或“负面评价”。例如图13-1所示的深度学习模型识别IMDb“影评文字”，可分为训练与预测。</p>
<p><img src="Image00579.jpg" alt></p>
<p>图13-1</p>
<p>图13-1说明如下：</p>
<p>▶ 训练</p>
<p>IMDb数据集的训练数据共25000项，经过数据预处理后会产生features（特征值）与label（1：正面评价，0：负面评价），然后对深度学习模型进行训练，训练完成的模型就可以在下一阶段预测时使用。</p>
<p>▶ 预测</p>
<p>输入“影评文字”，预处理后会产生features（特征值），可以使用训练完成的多层感知器模型进行预测，最后产生预测结果（“正面评价”或“负面评价”）。</p>
<p>本章完整的程序代码参考keras_Imdb_Introduce.ipynb。范例下载与安装参考附录A。</p>
<h3 id="13-1-Keras自然语言处理介绍"><a href="#13-1-Keras自然语言处理介绍" class="headerlink" title="13.1 Keras自然语言处理介绍"></a>13.1 Keras自然语言处理介绍</h3><p>Keras自然语言处理IMDb影评文字步骤如图13-2所示。</p>
<p><img src="Image00580.jpg" alt></p>
<p>图13-2</p>
<p>图13-2的步骤说明如下：</p>
<p><img src="Image00581.jpg" alt> 读取IMDb数据集。</p>
<p>IMDb数据集分为训练数据与测试数据，说明见表13-1。</p>
<p>表13-1 训练数据与测试数据说明</p>
<p><img src="Image00582.jpg" alt></p>
<p>（续表）</p>
<p><img src="Image00583.jpg" alt></p>
<p><img src="Image00584.jpg" alt> 建立token。</p>
<p>因为深度学习模型只能接受数字，所以我们必须将“影评文字”转换为“数字列表”。</p>
<p>要如何转换呢？当我们要将一种语言翻译成另一种语言时，必须要有字典。相同的道理，我们要将文字转换成数字，也必须有字典。Keras提供了Tokenizer模块，就是类似字典的功能。建立token的方式如下：</p>
<ul>
<li>建立token时必须指定字典的字数，例如2000个字的字典。</li>
<li>然后读取训练数据25000项“影评文字”，依照每一个英文单词在所有影评中出现的次数进行排序，排序的前2000名的英文单词会列入字典中。</li>
<li>因为是按照出现次数排序所建立的字典，所以我们可以说，这是“影评文字”的常用字典。</li>
<li>建立的字典如图13-3所示，共有2000个单词。</li>
</ul>
<p><img src="Image00585.jpg" alt></p>
<p>图13-3</p>
<ul>
<li>我们可以用此字典进行转换，例如’the’转换为1、’is’转换为6。读者也许会好奇，只有2000个单词的字典，如果有单词不在字典中，那么会如何处理呢？答案是那个单词就不转换，我们只在乎“影评文字”在常用字典出现的单词，因为常用单词对于我们要预测的目标影响比较大，不常用单词对于我们后续的预测影响比较小。</li>
</ul>
<p><img src="Image00586.jpg" alt> 使用token将“影评文字”转换为“数字列表”。</p>
<p>建立token字典后，我们就可以使用token将“影评文字”转换为“数字列表”。</p>
<p>例如，将图13-4中的“影评文字”转换为“数字列表”。</p>
<p><img src="Image00587.jpg" alt></p>
<p>图13-4</p>
<p>我们会将25 000项“影评文字”训练数据转换为25 000项的“数字列表”。</p>
<p><img src="Image00588.jpg" alt> 截长补短让所有“数字列表”长度为100。</p>
<p>因为每一则“影评文字”的字数都不固定，例如有些可能有170个字，有些有80个字。转换成“数字列表”字数也不固定。因为后续要将“数字列表”转为“向量列表”，并送入深度学习模型进行训练，所以长度必须固定。如何让所有“数字列表”长度都固定呢？其实方法很简单，就是截长补短。</p>
<p>例如，我们要将“数字列表”的长度都设置为100。</p>
<ul>
<li>如果数字列表的长度是59，就在前面补上41个“0”，这样就变成长度为100的“数字列表”，如图13-5所示。</li>
<li>如果数字列表的长度是126，就将前面的26个数字截去，这样就变成长度为100的“数字列表”。</li>
</ul>
<p><img src="Image00589.jpg" alt></p>
<p>图13-5</p>
<p><img src="Image00590.jpg" alt> 使用嵌入层将“数字列表”转换为“向量列表”。</p>
<p>词嵌入是一种自然语言处理技术，其原理是将文字映射成多维几何空间的向量。语义类似的文字向量在多维的几何空间的距离也比较相近。前面我们将“影评文字”转换为数字，可是数字在语义上无任何关联。为了能让每一个文字有关联性，必须转换为向量。</p>
<p>▶ 文字转换为数字，数字在语义上无任何关联</p>
<p><img src="Image00591.jpg" alt></p>
<p>▶ 文字转换为向量，语义类似的文字，在向量空间也会比较接近（见图13-6）</p>
<p><img src="Image00592.jpg" alt></p>
<p><img src="Image00593.jpg" alt></p>
<p>图13-6</p>
<p>Keras提供了嵌入层可以用于将“数字列表”转换为“向量列表”。例如，将图13-7中的“影评文字”先转换为“数字列表”，再转换为“向量列表”</p>
<p><img src="Image00594.jpg" alt></p>
<p>图13-7</p>
<p><img src="Image00595.jpg" alt> 将“向量列表”送入“深度学习模型”进行训练。</p>
<p>在前面的步骤中，我们将“影评文字”先转换为“数字列表”，再转换为“向量列表”后，就可以将“向量列表”送入深度学习模型进行训练，下一章我们将介绍使用下列深度学习模型进行训练。</p>
<p><img src="Image00596.jpg" alt></p>
<p>“深度学习模型”训练完成后，就可以进行预测了，如图13-8所示。</p>
<p><img src="Image00597.jpg" alt></p>
<p>图13-8</p>
<p>以上步骤说明如下。</p>
<ul>
<li>步骤1～4：文字的预处理，将在本章中介绍。</li>
<li>步骤5和6：建立嵌入层，并且使用深度学习模型进行训练与预测，将在下一章介绍。</li>
</ul>
<h3 id="13-2-下载IMDb数据集"><a href="#13-2-下载IMDb数据集" class="headerlink" title="13.2 下载IMDb数据集"></a>13.2 下载IMDb数据集</h3><p>可以在下列网址下载IMDb数据集：</p>
<p><a href="http://ai.stanford.edu／～amaas/data/sentiment" target="_blank" rel="noopener">http://ai.stanford.edu／～amaas/data/sentiment</a></p>
<h5 id="1．导入所需模块-3"><a href="#1．导入所需模块-3" class="headerlink" title="1．导入所需模块"></a>1．导入所需模块</h5><p><img src="Image00598.jpg" alt></p>
<p>以上程序代码说明见表13-2。</p>
<p>表13-2 程序代码说明</p>
<p><img src="Image00599.jpg" alt></p>
<h5 id="2．下载IMDb数据集"><a href="#2．下载IMDb数据集" class="headerlink" title="2．下载IMDb数据集"></a>2．下载IMDb数据集</h5><p>使用下列程序代码下载IMDb数据集。</p>
<p><img src="Image00600.jpg" alt></p>
<p>从以上执行结果可知，下载了aclImdb_v1.tar.gz，并存储在程序执行目录下的data目录中。</p>
<p>▶ 设置下载的网址</p>
<p><img src="Image00601.jpg" alt></p>
<p>▶ 设置存储文件的路径</p>
<p><img src="Image00602.jpg" alt></p>
<p>▶ 判断文件不存在就会下载文件</p>
<p><img src="Image00603.jpg" alt></p>
<p>上面的程序代码在判断文件不存在时，就会使用urllib.request.urlretrieve下载文件。</p>
<p>输入参数：url（下载的网址）与filepath（存储文件的路径）。</p>
<h5 id="3．解压缩下载的文件"><a href="#3．解压缩下载的文件" class="headerlink" title="3．解压缩下载的文件"></a>3．解压缩下载的文件</h5><p><img src="Image00604.jpg" alt></p>
<p>以上程序代码说明如下：</p>
<p>▶ 判断解压缩目录是否存在</p>
<p><img src="Image00605.jpg" alt></p>
<p>▶ 打开压缩文件</p>
<p><img src="Image00606.jpg" alt></p>
<p>▶ 解压缩文件到data目录中</p>
<p><img src="Image00607.jpg" alt></p>
<p>解压缩完成后，产生了aclImdb目录，后文会介绍这个目录的内容。</p>
<h5 id="4．查看已下载的文件及解压缩目录"><a href="#4．查看已下载的文件及解压缩目录" class="headerlink" title="4．查看已下载的文件及解压缩目录"></a>4．查看已下载的文件及解压缩目录</h5><p>查看下载的数据文件，根据使用的环境是Windows或Linux Ubuntu而稍有不同，说明如下：</p>
<p>▶ 在Windows下查看已下载的数据文件</p>
<p>可以使用文件资源管理器来查看程序执行目录下的data目录，例如程序执行目录是C：\pythonwork\keras，就可以在C：\pythonwork\keras\data中看到已下载的aclImdb_v1.tar文件与解压缩目录aclImdb，如图13-9所示。</p>
<p><img src="Image00608.jpg" alt></p>
<p>图13-9</p>
<p>▶ 在Linux Ubuntu下查看已下载的数据文件</p>
<p>在“终端”程序输入下列命令，先切换到程序执行目录，再查看目录。</p>
<p><img src="Image00609.jpg" alt></p>
<p>执行后屏幕显示界面如图13-10所示，我们可以看到已下载的aclImdb_v1.tar文件与解压缩目录aclImdb。</p>
<p><img src="Image00610.jpg" alt></p>
<p>图13-10</p>
<h3 id="13-3-读取IMDb数据"><a href="#13-3-读取IMDb数据" class="headerlink" title="13.3 读取IMDb数据"></a>13.3 读取IMDb数据</h3><p>IMDb文件下载并解压缩后，共有50 000项文本文件，我们将以下列步骤来读取，并且把它们分为训练数据与测试数据。</p>
<h5 id="1．导入所需模块-4"><a href="#1．导入所需模块-4" class="headerlink" title="1．导入所需模块"></a>1．导入所需模块</h5><p><img src="Image00611.jpg" alt></p>
<p>程序代码说明见表13-3。</p>
<p>表13-3 程序代码说明</p>
<p><img src="Image00612.jpg" alt></p>
<h5 id="2．创建rm-tag函数删除文字中的HTML标签"><a href="#2．创建rm-tag函数删除文字中的HTML标签" class="headerlink" title="2．创建rm_tag函数删除文字中的HTML标签"></a>2．创建rm_tag函数删除文字中的HTML标签</h5><p>下列程序代码使用正则表达式删除HTML的标签。</p>
<p><img src="Image00613.jpg" alt></p>
<p>程序代码说明见表13-4。</p>
<p>表13-4 程序代码说明</p>
<p><img src="Image00614.jpg" alt></p>
<h5 id="3．创建read-files函数读取IMDb文件目录"><a href="#3．创建read-files函数读取IMDb文件目录" class="headerlink" title="3．创建read_files函数读取IMDb文件目录"></a>3．创建read_files函数读取IMDb文件目录</h5><p>创建read_files函数读取IMDb文件，解压缩后的目录如图13-11所示。</p>
<p><img src="Image00615.jpg" alt></p>
<p>图13-11</p>
<p><img src="Image00616.jpg" alt></p>
<p>以上程序代码的说明见表13-5。</p>
<p>表13-5 程序代码说明</p>
<p><img src="Image00617.jpg" alt></p>
<h5 id="4．读取IMDb数据集目录"><a href="#4．读取IMDb数据集目录" class="headerlink" title="4．读取IMDb数据集目录"></a>4．读取IMDb数据集目录</h5><p>▶ 使用read_files函数传入参数“train“读取训练数据</p>
<p><img src="Image00618.jpg" alt></p>
<p>▶ 使用read_files函数传入参数“test“读取测试数据</p>
<p><img src="Image00619.jpg" alt></p>
<p>读取完成后，将数据整理为表13-6。</p>
<p>表13-6 训练数据与测试数据说明</p>
<p><img src="Image00620.jpg" alt></p>
<h3 id="13-4-查看IMDb数据"><a href="#13-4-查看IMDb数据" class="headerlink" title="13.4 查看IMDb数据"></a>13.4 查看IMDb数据</h3><p>读取IMDb数据集后，我们就可以查看“影评文字”了。</p>
<h5 id="1．查看第0项“影评文字”"><a href="#1．查看第0项“影评文字”" class="headerlink" title="1．查看第0项“影评文字”"></a>1．查看第0项“影评文字”</h5><p>下面的指令用来查看第0项“影评文字”。</p>
<p><img src="Image00621.jpg" alt></p>
<h5 id="2．查看第0项label是1，也就是正面评价"><a href="#2．查看第0项label是1，也就是正面评价" class="headerlink" title="2．查看第0项label是1，也就是正面评价"></a>2．查看第0项label是1，也就是正面评价</h5><p><img src="Image00622.jpg" alt></p>
<h5 id="3．查看第12-501项影评文字"><a href="#3．查看第12-501项影评文字" class="headerlink" title="3．查看第12 501项影评文字"></a>3．查看第12 501项影评文字</h5><p><img src="Image00623.jpg" alt></p>
<h5 id="4．查看第12-501项label是0，也就是负面评价"><a href="#4．查看第12-501项label是0，也就是负面评价" class="headerlink" title="4．查看第12 501项label是0，也就是负面评价"></a>4．查看第12 501项label是0，也就是负面评价</h5><p><img src="Image00624.jpg" alt></p>
<h3 id="13-5-建立token"><a href="#13-5-建立token" class="headerlink" title="13.5 建立token"></a>13.5 建立token</h3><p>接下来将详细介绍如何建立token以及token的特性。</p>
<h5 id="1．建立token"><a href="#1．建立token" class="headerlink" title="1．建立token"></a>1．建立token</h5><p><img src="Image00625.jpg" alt></p>
<p>以上程序代码说明见表13-7。</p>
<p>表13-7 程序代码说明</p>
<p><img src="Image00626.jpg" alt></p>
<h5 id="2．查看token读取多少文章"><a href="#2．查看token读取多少文章" class="headerlink" title="2．查看token读取多少文章"></a>2．查看token读取多少文章</h5><p>通过查看token.document_count属性就可以知道token读取了多少文章。</p>
<p><img src="Image00627.jpg" alt></p>
<p>从以上执行结果可知，token共读取了25 000项影评数据。</p>
<h5 id="3．查看token-word-index属性"><a href="#3．查看token-word-index属性" class="headerlink" title="3．查看token.word_index属性"></a>3．查看token.word_index属性</h5><p>word_index属性也是dict字典数据类型，其内容是每一个单词在所有文章中出现的次数的排名，出现次数最多的“the”排在第1位，其次是“and”排在第2位。</p>
<p><img src="Image00628.jpg" alt></p>
<p>我们后续会使用这个word_index字典将英文单词转换为数字。例如，“the”转换成1、“and”转换成2、“a”转换成3，等等。</p>
<h3 id="13-6-使用token将“影评文字”转换成“数字列表”"><a href="#13-6-使用token将“影评文字”转换成“数字列表”" class="headerlink" title="13.6 使用token将“影评文字”转换成“数字列表”"></a>13.6 使用token将“影评文字”转换成“数字列表”</h3><p>建立token字典后，我们就可以使用token.word_index字典将文字转换为“数字列表”。</p>
<h5 id="1．使用token-texts-to-sequences将“影评文字”转换为“数字列表”"><a href="#1．使用token-texts-to-sequences将“影评文字”转换为“数字列表”" class="headerlink" title="1．使用token.texts_to_sequences将“影评文字”转换为“数字列表”"></a>1．使用token.texts_to_sequences将“影评文字”转换为“数字列表”</h5><p>下面的指令使用token.texts_to_sequences将训练数据与测试数据的“影评文字”转换成“数字列表”，将train_text转换为x_train_seq，并将test_text转换为x_test_seq。</p>
<p><img src="Image00629.jpg" alt></p>
<h5 id="2．查看转换为sequences之后的结果"><a href="#2．查看转换为sequences之后的结果" class="headerlink" title="2．查看转换为sequences之后的结果"></a>2．查看转换为sequences之后的结果</h5><p>先使用下面的指令来查看第0项“影评文字”与“数字列表”。</p>
<p><img src="Image00630.jpg" alt></p>
<p>以上“影评文字”已经转换为“数字列表”，例如前3个单词中的Sure转换成248、this转换成10、was转换成12。</p>
<h3 id="13-7-让转换后的数字长度相同"><a href="#13-7-让转换后的数字长度相同" class="headerlink" title="13.7 让转换后的数字长度相同"></a>13.7 让转换后的数字长度相同</h3><p>因为每一则“影评文字”的单词数都不固定，例如有些可能有170个单词，有些有80个单词。转换成“数字列表”的数字个数也就不固定。因为后续要将“数字列表”转为“向量列表”，并送入深度学习模型进行训练，所以长度必须固定。如何让所有“数字列表”长度都固定呢？其实方法很简单，就是截长补短。</p>
<p>例如，我们要将“数字列表”的长度都设置为100。</p>
<ul>
<li>如果数字列表的长度为126，就将前面的26个数字截去，这样就变成长度为100的“数字列表”。</li>
<li>如果数字列表的长度是59，就在前面补上41个“0”，这样就变成长度为100的“数字列表”。</li>
</ul>
<h5 id="1．使用sequence-pad-sequences（）方法截长补短"><a href="#1．使用sequence-pad-sequences（）方法截长补短" class="headerlink" title="1．使用sequence.pad_sequences（）方法截长补短"></a>1．使用sequence.pad_sequences（）方法截长补短</h5><p>在前面步骤中产生的“数字列表”：x_train_seq、x_test_seq，使用sequence.pad_sequences进行截长补短，让每一个“数字列表”长度都是100。</p>
<p><img src="Image00631.jpg" alt></p>
<h5 id="2．“影评文字”转成“数字列表”后，长度大于100的处理方式"><a href="#2．“影评文字”转成“数字列表”后，长度大于100的处理方式" class="headerlink" title="2．“影评文字”转成“数字列表”后，长度大于100的处理方式"></a>2．“影评文字”转成“数字列表”后，长度大于100的处理方式</h5><p>下面的第0项“影评文字”转成“数字列表”后，长度为126，大于100，使用pad_sequences处理之后会截去“数字列表”前面的数字，使处理后的长度为100。</p>
<p>▶ 显示第0项“数字列表”</p>
<p><img src="Image00632.jpg" alt></p>
<p>▶ 显示第0项“数字列表”，经过pad_sequences处理后的内容</p>
<p><img src="Image00633.jpg" alt></p>
<p>从以上执行结果可知，23之前的数字都被截去了，“数字列表”的长度变为100。</p>
<h5 id="3．“影评文字”转成“数字列表”后，长度小于100的处理方式"><a href="#3．“影评文字”转成“数字列表”后，长度小于100的处理方式" class="headerlink" title="3．“影评文字”转成“数字列表”后，长度小于100的处理方式"></a>3．“影评文字”转成“数字列表”后，长度小于100的处理方式</h5><p>下面第一项“影评文字”转成“数字列表”后，长度是59，小于100，使用pad_sequences处理之后会在“数字列表”前面，填上41个数字0，使处理后的长度为100。</p>
<p><img src="Image00634.jpg" alt></p>
<h3 id="13-8-结论"><a href="#13-8-结论" class="headerlink" title="13.8 结论"></a>13.8 结论</h3><p>在本章中，我们介绍了如何下载与读取IMDb数据集，并且完成了数据预处理。在下一章中，我们可以使用Keras建立多层感知器、RNN、LSTM的模型，并训练模型，然后使用训练完成的模型进行预测。</p>
<h1 id="第14章-Keras建立MLP、RNN、LSTM模型进行IMDb情感分析"><a href="#第14章-Keras建立MLP、RNN、LSTM模型进行IMDb情感分析" class="headerlink" title="第14章 Keras建立MLP、RNN、LSTM模型进行IMDb情感分析"></a>第14章 Keras建立MLP、RNN、LSTM模型进行IMDb情感分析</h1><p>在上一章我们已经完成了IMDb数据集的预处理。在本章我们使用Keras建立多层感知器、递归神经网络、长短时记忆模型，进行IMDb情感分析，并训练模型、进行预测，最后产生预测结果（“正面评价”或“负面评价”）。</p>
<h3 id="14-1-建立多层感知器模型进行IMDb情感分析"><a href="#14-1-建立多层感知器模型进行IMDb情感分析" class="headerlink" title="14.1 建立多层感知器模型进行IMDb情感分析"></a>14.1 建立多层感知器模型进行IMDb情感分析</h3><p>首先，我们将建立多层感知器模型，整理如图14-1所示。</p>
<p><img src="Image00635.jpg" alt></p>
<p>图14-1</p>
<p>图14-1的步骤1～4文字的预处理已经在第13章介绍了。本章将建立：</p>
<p><strong>（1）嵌入层</strong> 将“数字列表”转换为“向量列表”。</p>
<p><strong>（2）多层感知器</strong> 使用多层感知器模型处理“向量列表”。</p>
<ul>
<li><strong>平坦层：</strong> 共有3200个神经元，因为原本“数字列表”每一项有100个数字，每一个数字转换为32维的向量，所以转换为平坦层的神经元有3200个（32×100＝3200）。</li>
<li><strong>隐藏层：</strong> 共有256个神经元。</li>
<li><strong>输出层：</strong> 只有1个神经元，输出1代表正面评价，0代表负面评价。</li>
</ul>
<p>本章完整的程序代码可参考范例程序Keras_Imdb_MLP.ipynb。范例程序下载与安装可参考本书附录A。</p>
<h3 id="14-2-数据预处理"><a href="#14-2-数据预处理" class="headerlink" title="14.2 数据预处理"></a>14.2 数据预处理</h3><p>关于数据预处理，在第13章已经详细介绍过了，本章整理其中的主要步骤如下。</p>
<p><img src="Image00636.jpg" alt> 导入所需模块。</p>
<p><img src="Image00637.jpg" alt></p>
<p><img src="Image00638.jpg" alt> 读取IMDb数据集目录。</p>
<p>使用第13章所介绍的read_files函数读取IMDb数据，细节请参考第13章。</p>
<p>▶ 读取训练数据</p>
<p><img src="Image00639.jpg" alt></p>
<p>▶ 读取测试数据</p>
<p><img src="Image00640.jpg" alt></p>
<p><img src="Image00641.jpg" alt> 建立token。</p>
<p><img src="Image00642.jpg" alt></p>
<p><img src="Image00643.jpg" alt> 将“影评文字”转换成“数字列表”。</p>
<p><img src="Image00644.jpg" alt></p>
<p><img src="Image00645.jpg" alt> 截长补短让所有“数字列表”的长度都为100。</p>
<p><img src="Image00646.jpg" alt></p>
<p>以上“数字列表”都是由“影评文字”转换而来的，并且已经截长补短每一项“数字列表”，因而列表中都正好是100个数字。</p>
<p><img src="Image00647.jpg" alt> 数据预处理完成后的数据整理。</p>
<p>以上数据预处理完成后产生训练数据与测试数据。</p>
<ul>
<li><strong>训练数据：</strong> 我们将送入各种深度学习模型进行训练。</li>
</ul>
<p><img src="Image00648.jpg" alt></p>
<ul>
<li><strong>测试数据：</strong> 可以用于评估深度学习模型的准确率，并进行预测。</li>
</ul>
<p><img src="Image00649.jpg" alt></p>
<h3 id="14-3-加入嵌入层"><a href="#14-3-加入嵌入层" class="headerlink" title="14.3 加入嵌入层"></a>14.3 加入嵌入层</h3><p>Keras提供了嵌入层可以将“数字列表”转换为“向量列表”。关于词嵌入自然语言处理技术的说明可参考第13章。</p>
<p><img src="Image00650.jpg" alt> 导入所需模块。</p>
<p><img src="Image00651.jpg" alt></p>
<p><img src="Image00652.jpg" alt> 建立模型。</p>
<p>使用下面的程序代码建立一个线性堆叠模型，后续只需要将各个神经网络层加入模型即可。</p>
<p><img src="Image00653.jpg" alt></p>
<p><img src="Image00654.jpg" alt> 将“嵌入层”加入模型。</p>
<p>使用下面的程序代码将“嵌入层”加入模型。</p>
<p><img src="Image00655.jpg" alt></p>
<p>▶ 建立嵌入层需输入表14-1中的参数。</p>
<p>表14-1 建立嵌入层需输入的参数</p>
<p><img src="Image00656.jpg" alt></p>
<p>▶ 加入Dropout层以避免过度拟合</p>
<p>Dropout（0.2）的功能是，每次训练迭代时会随机地在神经网络中放弃20%的神经元，以避免过度拟合。</p>
<h3 id="14-4-建立多层感知器模型"><a href="#14-4-建立多层感知器模型" class="headerlink" title="14.4 建立多层感知器模型"></a>14.4 建立多层感知器模型</h3><p>嵌入层转换为“向量列表”后，就可以使用各种深度学习模型进行训练与预测了。本节先介绍建立多层感知器模型。</p>
<p><img src="Image00657.jpg" alt> 将“平坦层”加入模型。</p>
<p>使用下面的程序代码将“平坦层”加入模型。因为“数字列表”每一项有100个数字，每一个数字转换为32维的向量，所以转换为平坦层的神经元有3200个（100×32＝3200）。</p>
<p><img src="Image00658.jpg" alt></p>
<p><img src="Image00659.jpg" alt> 将“隐藏层”加入模型。</p>
<p><img src="Image00660.jpg" alt></p>
<p>▶ 建立“隐藏层”使用Dense神经网络层，需输入表14-2中的参数。</p>
<p>表14-2 建立“隐藏层”使用Dense神经网络层需输入的参数</p>
<p><img src="Image00661.jpg" alt></p>
<p>▶ 加入Dropout层以避免过度拟合</p>
<p>Dropout（0.35）的功能是，每次训练迭代时会随机地在神经网络中放弃25%的神经元，以避免过度拟合。</p>
<p><img src="Image00662.jpg" alt> 将“输出层”加入模型。</p>
<p><img src="Image00663.jpg" alt></p>
<p>▶ 建立“输出层”使用Dense神经网络层，需输入表14-3中的参数。</p>
<p>表14-3 建立“输出层”使用Dense神经网络层需输入的参数</p>
<p><img src="Image00664.jpg" alt></p>
<p><img src="Image00665.jpg" alt> 查看模型的摘要。</p>
<p>可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00666.jpg" alt></p>
<h3 id="14-5-训练模型"><a href="#14-5-训练模型" class="headerlink" title="14.5 训练模型"></a>14.5 训练模型</h3><p>当我们建立深度学习模型后，就可以使用反向传播算法进行训练。可参考第2章有关使用反向传播算法进行训练的说明。</p>
<h5 id="1．定义训练方式-4"><a href="#1．定义训练方式-4" class="headerlink" title="1．定义训练方式"></a>1．定义训练方式</h5><p>在训练模型之前，我们必须使用compile方法对训练模型进行设置，如下列指令：</p>
<p><img src="Image00667.jpg" alt></p>
<p>compile方法需输入3个参数：loss、optimizer和metrics（对这3个参数的解释说明可参考下7.4节）。</p>
<h5 id="2．开始训练-4"><a href="#2．开始训练-4" class="headerlink" title="2．开始训练"></a>2．开始训练</h5><p><img src="Image00668.jpg" alt></p>
<p>使用model.fit进行训练，训练过程会存储在train_history变量中，这个训练需输入下列参数。</p>
<p>（1）输入训练数据参数</p>
<ul>
<li>x＝x_train：features（“数字列表”）。</li>
<li>y＝y_train：测试数据的标签label（影评的真实值，正向：1，负向：0）。</li>
</ul>
<p>（2）设置训练与验证数据的比例</p>
<p>训练之前Keras会自动将数据分成：80%作为训练数据，20%作为验证数据。因为全部数据有25 000项，所以分成：25 000×0.8＝20000作为训练数据，25 000×0.2＝5 000作为验证数据。</p>
<p>（3）设置训练周期数与批次的项数</p>
<ul>
<li>epochs＝10：执行10个训练周期。</li>
<li>batch_size＝100：每一批次100项数据。</li>
</ul>
<p>（4）设置显示训练过程</p>
<ul>
<li>verbose＝2：显示训练过程。</li>
</ul>
<p>上面的程序代码共执行了10个训练周期，每一个训练周期中执行下列功能：</p>
<ul>
<li>使用20 000项训练数据进行训练，分为每一批次100项，所以大约分为200个批次（20 000/100＝200）进行训练。</li>
<li>Epoch（训练周期）训练完成后，会计算这个训练周期的准确率与误差，并且在train_history中新增一项数据记录。</li>
</ul>
<p>▶ 以上程序代码执行后的结果如图14-2所示。</p>
<p><img src="Image00669.jpg" alt></p>
<p>图14-2</p>
<p>从以上执行界面可知，共执行了10个训练周期，还可以发现误差越来越小，准确率越来越高。</p>
<h3 id="14-6-评估模型准确率"><a href="#14-6-评估模型准确率" class="headerlink" title="14.6 评估模型准确率"></a>14.6 评估模型准确率</h3><p>之前我们已经完成了模型的训练，现在要使用test测试数据集，评估模型的准确率。</p>
<p>下面的程序代码用来评估模型的准确率。</p>
<p><img src="Image00670.jpg" alt></p>
<p>从以上执行结果可知准确率是0.80。以上程序代码说明见表14-4。</p>
<p>表14-4 程序代码说明</p>
<p><img src="Image00671.jpg" alt></p>
<h3 id="14-7-进行预测"><a href="#14-7-进行预测" class="headerlink" title="14.7 进行预测"></a>14.7 进行预测</h3><p>在前面的步骤中，我们建立了模型，并且完成了模型的训练，准确率达到还可以接受的0.80，接下来我们将使用这个模型进行预测。</p>
<p><img src="Image00672.jpg" alt> 执行预测。</p>
<p>我们可以用下列指令执行预测：</p>
<p><img src="Image00673.jpg" alt></p>
<p>以上程序代码使用model.predict_classes进行预测，输入参数：测试数据的特征值features（数字列表）。</p>
<p><img src="Image00674.jpg" alt> 预测结果。</p>
<p>我们可以用下列指令来查看预测结果的前10项数据。</p>
<p><img src="Image00675.jpg" alt></p>
<p>从以上执行结果可知，0代表负面评价，1代表正面评价。</p>
<p><img src="Image00676.jpg" alt> 使用一维数组查看预测结果。</p>
<p>上一步的执行结果predict是二维数组，我们可以使用reshape把它转换为一维数组predict_class。</p>
<p><img src="Image00677.jpg" alt></p>
<h3 id="14-8-查看测试数据预测结果"><a href="#14-8-查看测试数据预测结果" class="headerlink" title="14.8 查看测试数据预测结果"></a>14.8 查看测试数据预测结果</h3><p>之前的预测结果是0与1，我们将创建display_test_Sentiment函数，可以显示负面评价或正面评价。</p>
<p><img src="Image00678.jpg" alt> 创建display_test_Sentiment函数。</p>
<p>创建display_test_Sentiment函数如下：</p>
<p><img src="Image00679.jpg" alt></p>
<p>程序代码说明见表14-5。</p>
<p>表14-5 程序代码说明</p>
<p><img src="Image00680.jpg" alt></p>
<p><img src="Image00681.jpg" alt> 显示第2项预测结果。</p>
<p>以下使用display_test_Sentiment函数来显示预测结果。</p>
<p><img src="Image00682.jpg" alt></p>
<p>从以上执行结果可知，第2项数据真实值是正面的，预测结果也是正面的。</p>
<p><img src="Image00683.jpg" alt> 显示第12 502项预测结果。</p>
<p><img src="Image00684.jpg" alt></p>
<p>从以上执行结果可知，第12502项数据真实值是负面的，预测结果也是负面的。</p>
<h3 id="14-9-查看《美女与野兽》的影评"><a href="#14-9-查看《美女与野兽》的影评" class="headerlink" title="14.9 查看《美女与野兽》的影评"></a>14.9 查看《美女与野兽》的影评</h3><p>之前的预测使用的是IMDb数据集的影评文字，接下来将使用热门电影《美女与野兽》的影评文字进行预测。</p>
<p><img src="Image00685.jpg" alt> 查看美女与野兽的影评。</p>
<p>可以在下列网址查看《美女与野兽》的影评：</p>
<p><a href="http://www.imdb.com/title/tt2771200/reviews" target="_blank" rel="noopener">http://www.imdb.com/title/tt2771200/reviews</a></p>
<p>在影评页面可以筛选影评，我们选择Chronological，即按时间顺序进行排序，如图14-3所示。</p>
<p><img src="Image00686.jpg" alt></p>
<p>图14-3</p>
<p><img src="Image00687.jpg" alt></p>
<p><img src="Image00688.jpg" alt> 执行预测。</p>
<p>将上一步网页上的影评文字剪贴到下列程序代码中，创建input_text变量。</p>
<p>上面的input_text影评文字将送入之前所建立的多层感知器模型中进行预测，不过必须先进行数据预处理，步骤如下。</p>
<p><img src="Image00689.jpg" alt> 将“影评文字”转换成“数字列表”。</p>
<p>以下程序代码使用token.texts_to_sequences将“影评文字”转换成“数字列表”，不过因为输入参数必须是字符串的列表，然而input_text是一个字符串，所以我们前后加上中括号［input_text］以便转换为字符串的列表。</p>
<p><img src="Image00690.jpg" alt></p>
<p><img src="Image00691.jpg" alt> 查看“数字列表”。</p>
<p>上一步的执行结果是“数字列表”的列表，因为只有一项数据，所以使用input_seq［0］查看第0项，也是唯一一项数据。</p>
<p><img src="Image00692.jpg" alt></p>
<p><img src="Image00693.jpg" alt> 查看“数字列表”的长度。</p>
<p>使用下列程序代码来查看“数字列表”的长度，执行结果是长度为204。</p>
<p><img src="Image00694.jpg" alt></p>
<p><img src="Image00695.jpg" alt> 截取“数字列表”使其长度为100。</p>
<p>下列程序代码使用sequence.pad_sequences截取“数字列表”，使其长度为100。</p>
<p><img src="Image00696.jpg" alt></p>
<p><img src="Image00697.jpg" alt> 截长补短后查看“数字列表”的长度。</p>
<p>再使用下列程序代码来查看“数字列表”的长度。</p>
<p><img src="Image00698.jpg" alt></p>
<p>从以上执行结果可以看到，经过sequence.pad_sequences处理后，长度变为100。</p>
<p><img src="Image00699.jpg" alt> 使用多层感知器模型进行预测。</p>
<p>下面的指令使用model.predict_classes传入参数pad_input_seq进行预测。</p>
<p><img src="Image00700.jpg" alt></p>
<p><img src="Image00701.jpg" alt> 查看预测结果。</p>
<p>用下列指令来查看预测结果：</p>
<p><img src="Image00702.jpg" alt></p>
<p>可以看到，预测结果有前后有两个中括号［［1］］，所以这是一个二维数组，它只有一个元素。</p>
<p><img src="Image00703.jpg" alt> 读取预测结果中的元素。</p>
<p>因为这是一个二维数组，所以我们使用predict_result［0］［0］来读取其中的元素。</p>
<p><img src="Image00704.jpg" alt></p>
<p>从以上执行结果可以看到这一则影评文字的预测结果是1，也就是正面的评价。</p>
<p><img src="Image00705.jpg" alt> 执行预测。</p>
<p>最后，我们可以使用之前定义的SentimentDict字典将结果1转换为文字。</p>
<p><img src="Image00706.jpg" alt></p>
<p>从以上执行结果可知，这是正面的评价。</p>
<h3 id="14-10-预测《美女与野兽》的影评是正面或负面的"><a href="#14-10-预测《美女与野兽》的影评是正面或负面的" class="headerlink" title="14.10 预测《美女与野兽》的影评是正面或负面的"></a>14.10 预测《美女与野兽》的影评是正面或负面的</h3><p>在本节中，我们将前面的命令全部整理成predict_review（）函数，以便于预测其他《美女与野兽》的影评。</p>
<p><img src="Image00707.jpg" alt> 创建predict_review（）函数。</p>
<p>创建predict_review（）函数如下：</p>
<p><img src="Image00708.jpg" alt></p>
<p>predict_review（）使用很简单，只需要传入参数input_text（影评文字）就可以预测此影评是“正面”的或“负面”的。</p>
<p><img src="Image00709.jpg" alt> 筛选Hated It影评。</p>
<p>我们可以在IMDb网站筛选Hated It（讨厌的）影评，这些影评应该大部分是负面的评价，如图14-4所示。我们可以使用这些影评来验证模型的准确率。</p>
<p><img src="Image00710.jpg" alt></p>
<p>图14-4</p>
<p><img src="Image00711.jpg" alt> 执行预测。</p>
<p>接下来使用之前创建的predict_review（）函数预测粘贴的“影评文字”。</p>
<p><img src="Image00712.jpg" alt></p>
<p>从以上执行结果可以看到结果是负面的评价。其他读者可以自己筛选Hated It影评试试看，会发现大部分都是负面的评价。</p>
<p><img src="Image00713.jpg" alt> 筛选Loved It影评。</p>
<p>我们可以在IMDb网站筛选Loved It（喜欢的）影评，这些影评大部分是正面的评价，如图14-5所示。我们可以使用这些影评来验证模型的准确率。</p>
<p><img src="Image00714.jpg" alt></p>
<p>图14-5</p>
<p><img src="Image00715.jpg" alt> 执行预测。</p>
<p>接下来使用之前所创建的predict_review（）函数来预测粘贴的“影评文字”。</p>
<p><img src="Image00716.jpg" alt></p>
<p>从以上执行结果可以看到结果是正面的评价。读者可以自己剪切试试筛选Loved It影评，就会发现大部分都是正面的评价。</p>
<h3 id="14-11-文字处理时使用较大的字典提取更多文字"><a href="#14-11-文字处理时使用较大的字典提取更多文字" class="headerlink" title="14.11 文字处理时使用较大的字典提取更多文字"></a>14.11 文字处理时使用较大的字典提取更多文字</h3><p>之前模型预测的准确率是0.80，我们希望能够再提高预测的准确率，方法如下。</p>
<ul>
<li><strong>建立字典的单词数：</strong> 原本是有1000个单词的字典，增加为建立有3800个单词的字典。</li>
<li><strong>“数字列表”截长补短的长度：</strong> 原本“数字列表”的长度都是100个数字，现在改为380个数字。</li>
</ul>
<p>这种方式就好像训练深度学习模型，多认识一些单词，并且增加读取影评文字的单词数，以增加准确率。以下可参考范例程序Keras_Imdb_MLP_Large.ipynb。此程序代码大部分与Keras_Imdb_MLP.ipynb相同，此处只说明修改的部分。</p>
<p><img src="Image00717.jpg" alt> 数据预处理。</p>
<p>数据预处理修改如下：</p>
<p><img src="Image00718.jpg" alt></p>
<p><img src="Image00719.jpg" alt> 建立模型。</p>
<p>建立模型修改如下：</p>
<p><img src="Image00720.jpg" alt></p>
<p><img src="Image00721.jpg" alt> 修改pad_sequences。</p>
<p><img src="Image00722.jpg" alt></p>
<p><img src="Image00723.jpg" alt> 修改predict_review函数。</p>
<p><img src="Image00724.jpg" alt></p>
<p><img src="Image00725.jpg" alt> 评估模型的准确率。</p>
<p><img src="Image00726.jpg" alt></p>
<p>经过修改模型后：把字典的单词数增加为3800，并且“数字列表”的长度增加为380。训练的时间比较长，但是这是值得的，准确率从0.80提高到0.85。</p>
<h3 id="14-12-RNN模型介绍"><a href="#14-12-RNN模型介绍" class="headerlink" title="14.12 RNN模型介绍"></a>14.12 RNN模型介绍</h3><p>接下来，我们将使用递归神经网络进行IMDb情感分析，并且训练模型、进行预测，最后产生预测结果（“正面评价”或“负面评价”）。</p>
<h5 id="1．为什么要使用RNN模型"><a href="#1．为什么要使用RNN模型" class="headerlink" title="1．为什么要使用RNN模型"></a>1．为什么要使用RNN模型</h5><p>之前我们介绍的MNIST数据集（识别数字图形）、Cifar数据集（识别照片）图像并不会随着时间而改变，所以使用多层感知器或卷积神经网络都能达到不错的效果。</p>
<p>然而，人工智能所要解决的问题很多是顺序性的，例如自然语言处理（同一时间只能听到一个字，之前的语言会影响之后语言的含义）、视频图像处理（视频是一张张的照片，依照时间顺序所组成的）、气象观测数据（气象信息随着时间不断改变）和股票交易数据（股市开盘后，股价随着时间不断变动）。</p>
<p>以自然语言处理为例，当我们在听人说话时，因为同一个时间只能听一个字，所以会根据之前的时间点、所听到的话语来理解当前时间点这句话的意义。例如，“我家住上海市”“我在市政府上班”。因为前一句话说已经说住在上海市，所以当我们理解后面那一句话“我在市政府上班”时，通常是指上海市的市政府，不会是其他城市的市政府。</p>
<p>因为多层感知器（MLP）或卷积神经网络（CNN）都只能依照当前的状态进行识别，如果要处理时间序列的问题，就必须使用RNN与LSTM模型。</p>
<h5 id="2．RNN模型原理"><a href="#2．RNN模型原理" class="headerlink" title="2．RNN模型原理"></a>2．RNN模型原理</h5><p>RNN模式的原理是将神经元的输出再接回神经元的输入。这样的设计使神经网络具备“记忆”功能，如图14-6所示。</p>
<p>说明如下：</p>
<ul>
<li>X是神经网络的输入。</li>
<li>O是神经网络的输出。</li>
<li>（U，V，W）都是神经网络的参数。</li>
<li>S是隐藏状态，代表着神经网络的“记忆”。</li>
</ul>
<p><img src="Image00727.jpg" alt></p>
<h5 id="3．以时间点展开RNN模型"><a href="#3．以时间点展开RNN模型" class="headerlink" title="3．以时间点展开RNN模型"></a>3．以时间点展开RNN模型</h5><p>为了让读者更容易理解，我们将之前的图以时间点展开，如图14-7所示。</p>
<p><img src="Image00728.jpg" alt></p>
<p>图14-7</p>
<p>上图共有3个时间点，按照顺序是：“ _t_ -1”“ _t_ ”“ _t_ ＋1”。</p>
<p>▶ 在 _t_ 时间点</p>
<ul>
<li>Xt 是 _t_ 时间点神经网络的输入。</li>
<li>Ot 是 _t_ 时间点神经网络的输出。</li>
<li>（U，V，W）都是神经网络的参数，W参数是 _t_ -1时间点的输出，但是作为 _t_ 时间点的输入。</li>
<li>St 是隐藏状态，代表着神经网络的“记忆”，是经过当前时间点的输入Xt ，再加上前一个时间点的状态St-1 和U、W的参数共同评估的结果，其公式如下：</li>
</ul>
<p>St = _f_ （［U］Xt +［W］St-1 ）</p>
<p>上面的 _f_ 函数是非线性函数，例如ReLU。</p>
<h3 id="14-13-使用Keras-RNN模型进行IMDb情感分析"><a href="#14-13-使用Keras-RNN模型进行IMDb情感分析" class="headerlink" title="14.13 使用Keras RNN模型进行IMDb情感分析"></a>14.13 使用Keras RNN模型进行IMDb情感分析</h3><p>在上一节，我们已经对RNN有了基本的了解，接下来将使用RNN模型进行IMDb情感分析，整理如图14-8所示。</p>
<p><img src="Image00729.jpg" alt></p>
<p>图14-8</p>
<p>以下完整的程序代码可参考范例程序Keras_Imdb_RNN.ipynb。此程序代码大部分与Keras_Imdb_MLP_Large.ipynb相同，以下只说明修改的部分。</p>
<p><img src="Image00730.jpg" alt> 建立模型。</p>
<p>以下程序代码使用SimpleRNN（unit＝16）建立16个神经元的RNN层。</p>
<p><img src="Image00731.jpg" alt></p>
<p><img src="Image00732.jpg" alt> 查看模型的摘要。</p>
<p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00733.jpg" alt></p>
<p><img src="Image00734.jpg" alt> 评估模型的准确率。</p>
<p><img src="Image00735.jpg" alt></p>
<p>使用RNN模型准确率大约为0.84。</p>
<h3 id="14-14-LSTM模型介绍"><a href="#14-14-LSTM模型介绍" class="headerlink" title="14.14 LSTM模型介绍"></a>14.14 LSTM模型介绍</h3><p>长短期记忆（Long Short Term Memory，LSTM）也是一种时间递归神经网络，专门设计来解决RNN的长期依赖问题。</p>
<h5 id="1．RNN的长期依赖问题"><a href="#1．RNN的长期依赖问题" class="headerlink" title="1．RNN的长期依赖问题"></a>1．RNN的长期依赖问题</h5><p>之前介绍的RNN在训练时会有长期依赖的问题，这是由于RNN模型在训练时会遇到梯度消失或爆炸的问题。训练时计算和反向传播，梯度倾向于在每一时刻递增或递减，经过一段时间后，会发散到无穷大或收敛到零。</p>
<p>简单来说，长期依赖的问题就是在每一个时间的间隔不断增大时，RNN会丧失学习到连接到远处的信息的能力。</p>
<p>如图14-9所示，随着时间点t不断递增，由0、1、2一直到 _t_ -1、 _t_ 、 _t_ ＋1。到了时间点的后期 _t_ ，隐藏状态（记忆）St已经丧失了学习连接到远处的信息X0 的能力。</p>
<p><img src="Image00736.jpg" alt></p>
<p>图14-9</p>
<p>假设X0 输入“我家住上海市”，中间插了很多其他的句子，然后在Xt 输入“我在市政府上班”，由于X0 与Xt 相差很远，当RNN输入到Xt时，隐藏状态（记忆）St 已经丧失了学习连接远处的信息X0 的能力。当神经网络Xt 输入“我在市政府上班”，由于已经忘记了X0输入“我家住上海市”，因此神经网络无法理解我是在哪一个城市的市政府上班。</p>
<h5 id="2．LSTM介绍"><a href="#2．LSTM介绍" class="headerlink" title="2．LSTM介绍"></a>2．LSTM介绍</h5><p>简单地说，RNN只有短期记忆，没有长期记忆，所以深度学习专家Schmidhuber提出了LSTM模型，专门设计来解决RNN的长期依赖问题，如图14-10所示。</p>
<p><img src="Image00737.jpg" alt></p>
<p>图14-10</p>
<p>在LSTM神经网络中，每一个神经元相当于一个记忆细胞（cell），说明如下。</p>
<ul>
<li>Xt ：输入向量。</li>
<li>Yt ：输出向量。</li>
<li>Ct ：cell是LSTM的记忆细胞的状态（cell state）。</li>
<li>LSTM通过一种名为“闸门”（Gate）的机制控制记忆细胞的状态，删减或增加其中的信息。</li>
</ul>
<p>■ It ：“输入闸门”（Input Gate）用于决定哪些信息要被增加到cell。</p>
<p>■ Ft ：“遗忘闸门”（Forget Gate）用于决定哪些信息要从cell删减。</p>
<p>■ Ot ：“输出闸门”（Output Gate）用于决定哪些信息要从cell输出。</p>
<p>有了“闸门”机制，LSTM就有了长期记忆。</p>
<h3 id="14-15-使用Keras-LSTM模型进行IMDb情感分析"><a href="#14-15-使用Keras-LSTM模型进行IMDb情感分析" class="headerlink" title="14.15 使用Keras LSTM模型进行IMDb情感分析"></a>14.15 使用Keras LSTM模型进行IMDb情感分析</h3><p>在上一节，我们已经对LSTM有了基本的了解，接下来将使用LSTM模型进行IMDb情感分析。下面完整的程序代码可参考范例程序Keras_Imdb_LSTM.ipynb。此程序代码大部分与Keras_Imdb_MLP_Large.ipynb相同，以下只说明修改的部分。</p>
<p><img src="Image00738.jpg" alt> 建立模型。</p>
<p>下面的程序代码使用LSTM（32）建立32个神经元的LSTM层。</p>
<p><img src="Image00739.jpg" alt></p>
<p><img src="Image00732.jpg" alt> 查看模型的摘要。</p>
<p>我们可以使用下列指令来查看模型的摘要。</p>
<p><img src="Image00740.jpg" alt></p>
<p><img src="Image00741.jpg" alt> 评估模型的准确率。</p>
<p><img src="Image00742.jpg" alt></p>
<p>使用LSTM模型准确率提升至约0.86。</p>
<h3 id="14-16-结论"><a href="#14-16-结论" class="headerlink" title="14.16 结论"></a>14.16 结论</h3><p>在前面的章节中我们已经介绍了使用Keras进行手写数字识别、照片图像识别、预测泰坦尼克号上旅客的生存概率、影评文字情感分析。读者已经熟悉了深度学习模型的建立、训练和预测，后面的章节我们将介绍使用TensorFlow建立深度学习模型、训练模型和进行预测。</p>
<h1 id="第15章-TensorFlow程序设计模式"><a href="#第15章-TensorFlow程序设计模式" class="headerlink" title="第15章 TensorFlow程序设计模式"></a>第15章 TensorFlow程序设计模式</h1><p>在第3章中已经大致介绍了TensorFlow程序设计模式的概念，本章我们将以简单的程序来示范TensorFlow程序设计模式。而TensorFlow与Keras最大的差别是，对于TensorFlow，我们必须自行设计张量（矩阵）运算，所以本章将介绍TensorFlow张量运算。</p>
<p>TensorFlow程序设计模式的核心是“计算图”，可分为两部分：建立“计算图”与执行“计算图”，如图15-1所示。</p>
<p><img src="Image00743.jpg" alt></p>
<p>图15-1</p>
<p>图15-1说明如下：</p>
<p>（1）建立“计算图”</p>
<p>我们可以使用TensorFlow提供的模块建立“计算图”。TensorFlow提供的模块非常强大，可以设计张量运算流程，并且构建各种深度学习或机器学习模型。</p>
<p>（2）执行“计算图”</p>
<p>建立“计算图”后，我们就可以建立Session执行“计算图”。在TensorFlow中，Session（原意是会话）的作用是在客户端和执行设备之间建立连接。有了这个连接，就可以将“计算图”在各种不同的设备中执行，后续任何与设备之间的数据传输都必须通过Session才能进行，执行“计算图”后会返回结果。</p>
<p>下面的程序代码可参考范例程序TensorFlow_Basic.ipynb。范例程序的下载与安装可参考本书附录A。</p>
<h3 id="15-1-建立“计算图”"><a href="#15-1-建立“计算图”" class="headerlink" title="15.1 建立“计算图”"></a>15.1 建立“计算图”</h3><p>为了示范TensorFlow程序设计模式，我们将建立简单的“计算图”，只有一个常数与一个变量。建立完成后再执行此“计算图”，如图15-2所示。</p>
<p><img src="Image00744.jpg" alt></p>
<p>图15-2</p>
<p><img src="Image00745.jpg" alt> 导入TensorFlow模块。</p>
<p><img src="Image00746.jpg" alt></p>
<p><img src="Image00747.jpg" alt> 建立TensorFlow常数。</p>
<p>建立TensorFlow常数命令如下：</p>
<p><img src="Image00748.jpg" alt></p>
<p>以上程序代码使用tf.constant建立TensorFlow常数，需输入表15-1中的参数。</p>
<p>表15-1 使用tf.constant建立TensorFlow常数需输入的参数</p>
<p><img src="Image00749.jpg" alt></p>
<p><img src="Image00750.jpg" alt> 查看TensorFlow常数。</p>
<p>查看TensorFlow常数指令如下：</p>
<p><img src="Image00751.jpg" alt></p>
<p>以上执行结果说明如下。</p>
<ul>
<li>tf.Tensor：代表这是TensorFlow张量。</li>
<li>shape＝（）：代表这是零维的tensor，也就是数值。</li>
<li>dtype＝int32：代表此张量数据类型是int32。</li>
</ul>
<p><img src="Image00752.jpg" alt> 建立TensorFlow变量。</p>
<p>建立TensorFlow变量的命令如下。</p>
<p><img src="Image00753.jpg" alt></p>
<p>以上程序代码使用tf.Variable建立TensorFlow变量，需输入表15-2中的参数。</p>
<p>表15-2 使用tf.Variable建立TensorFlow变量需输入的参数</p>
<p><img src="Image00754.jpg" alt></p>
<p>▶ 查看TensorFlow变量</p>
<p>要查看TensorFlow变量，只要输入名称即可，指令如下。</p>
<p><img src="Image00755.jpg" alt></p>
<p>从以上执行结果可以看到只显示这一个TensorFlow变量。这是因为TensorFlow变量必须要执行“计算图“之后，才能够看到结果。</p>
<h3 id="15-2-执行“计算图”"><a href="#15-2-执行“计算图”" class="headerlink" title="15.2 执行“计算图”"></a>15.2 执行“计算图”</h3><p>建立“计算图”后，我们就可以执行“计算图”。只是执行之前必须先建立Session（会话），在TensorFlow中Session代表在客户端和执行设备之间建立连接。有了这个连接，就可以在设备中执行“计算图”，后续任何与设备之间的沟通都必须通过这个Session，并且可取得执行后的结果。</p>
<p><img src="Image00756.jpg" alt> 建立Session。</p>
<p>使用tf.Session（）建立Session对象sess。</p>
<p><img src="Image00757.jpg" alt></p>
<p><img src="Image00758.jpg" alt> 执行TensorFlow来初始化变量。</p>
<p>必须使用下列指令初始化所有TensorFlow global变量。</p>
<p><img src="Image00759.jpg" alt></p>
<p><img src="Image00760.jpg" alt> 使用sess.run显示TensorFlow常数。</p>
<p>下面的程序代码使用sess.run执行TensorFlow的“计算图”，并且使用print显示TensorFlow常数的执行结果。</p>
<p><img src="Image00761.jpg" alt></p>
<p>从以上执行结果可以看到ts_c是常数，显示为2。</p>
<p><img src="Image00762.jpg" alt> 使用sess.run显示TensorFlow变量。</p>
<p>相同的方式也可以显示TensorFlow变量的执行结果。</p>
<p><img src="Image00763.jpg" alt></p>
<p>从以上执行结果可以看到ts_x是变量7，也就是ts_c是2，加5等于7。</p>
<p><img src="Image00764.jpg" alt> 使用.eval（）方法显示TensorFlow常数。</p>
<p>另一个执行TensorFlow“计算图”的方法是使用TensorFlow对象的eval（）方法，使用eval（）方法必须传入session参数。</p>
<p><img src="Image00765.jpg" alt></p>
<p><img src="Image00766.jpg" alt> 使用eval（）方法显示TensorFlow变量。</p>
<p>我们也可以使用TensorFlow对象的eval（）方法来显示TensorFlow变量。</p>
<p><img src="Image00767.jpg" alt></p>
<p><img src="Image00768.jpg" alt> 关闭TensorFlow Session。</p>
<p>当我们不需要再使用Session时，必须使用sess.close（）关闭Session。</p>
<p><img src="Image00769.jpg" alt></p>
<p><img src="Image00770.jpg" alt> 将以上指令全部一起执行。</p>
<p>下面的程序代码是将前面步骤介绍的指令全部一起执行。</p>
<p><img src="Image00771.jpg" alt></p>
<p><img src="Image00772.jpg" alt> With语句打开Session并且自动关闭。</p>
<p>在前面的步骤中，我们使用tf.Session（）建立Session，并且使用sess.close（）关闭Session。这种做法可能有以下问题：</p>
<p>（1）可能忘记关闭Session。</p>
<p>（2）当程序执行中发生异常时，可能导致没有关闭Session。</p>
<p>为了解决此问题，可以使用With语句：</p>
<p>with关键词后面是建立的命令tf.Session（），as关键词后面是Session的变量sess。</p>
<p>在with程序块中可使用sess变量与设备沟通，离开with程序块就自动关闭Session。</p>
<p><img src="Image00773.jpg" alt></p>
<h3 id="15-3-TensorFlow-placeholder"><a href="#15-3-TensorFlow-placeholder" class="headerlink" title="15.3 TensorFlow placeholder"></a>15.3 TensorFlow placeholder</h3><p>在前面的范例中，在建立“计算图”时，我们会设置ts_c常数值为2，并且设置变量ts_x为ts_c加5，这都是在建立“计算图”阶段就已经设置完成的。可是如果希望在执行“计算图”阶段才设置数值，那么就必须使用placeholder。</p>
<p><img src="Image00774.jpg" alt> 建立“计算图”。</p>
<p>以下建立两个placeholder，分别是width（宽）与height（高），然后使用tf.multiply将width与height相乘，相乘后的结果是area（面积）。</p>
<p><img src="Image00775.jpg" alt></p>
<p>执行后建立如图15-3所示的“计算图”。</p>
<p><img src="Image00776.jpg" alt></p>
<p>图15-3</p>
<p><img src="Image00777.jpg" alt> 执行“计算图”。</p>
<p>执行sess.run传入feed_dict参数｛width：6，height：8｝。</p>
<p><img src="Image00778.jpg" alt></p>
<p>从以上执行结果可知，返回area＝48，也就是width是6，height是8，相乘等于48，如图15-4所示。</p>
<p><img src="Image00779.jpg" alt></p>
<p>图15-4</p>
<h3 id="15-4-TensorFlow数值运算方法介绍"><a href="#15-4-TensorFlow数值运算方法介绍" class="headerlink" title="15.4 TensorFlow数值运算方法介绍"></a>15.4 TensorFlow数值运算方法介绍</h3><p>在上一节中，我们使用tf.multiply（）方法进行TensorFlow乘法运算。TensorFlow提供了很多数值运算，可以参考下列TensorFlow说明文件：</p>
<p><a href="https://www.tensorFlow.org/api_docs/python/math_ops/" target="_blank" rel="noopener">https://www.tensorFlow.org/api_docs/python/math_ops/</a></p>
<p>如果是双目数值运算，就输入两个参数：x、y。如果是单目数值运算（例如绝对值），就只传入参数x。name参数用于设置此运算名称。</p>
<p>表15-3所示为TensorFlow数值运算说明。</p>
<p>表15-3 TensorFlow数值运算说明</p>
<p><img src="Image00780.jpg" alt></p>
<p>注：文档中的数值运算方法很多，以上只列出常用的部分。</p>
<p>你也许会觉得只是简单的数值相乘，为什么要使用tf.multiply（）方法？这是因为TensorFlow特别的程序设计模式必须以TensorFlow模块（例如tf.multiply（）方法）来建立“计算图”，然后使用sess.run执行“计算图”，这样才能得到计算的结果。这样做的目的是让TensorFlow具备跨平台的能力。</p>
<h3 id="15-5-TensorBoard"><a href="#15-5-TensorBoard" class="headerlink" title="15.5 TensorBoard"></a>15.5 TensorBoard</h3><p>TensorFlow提供了TensorBoard，可以让我们以可视化的方式查看所建立的“计算图”。下面的程序代码请参考范例程序代码TensorFlow_Board_area.ipynb。</p>
<h5 id="1．建立TensorFlow-Variable变量"><a href="#1．建立TensorFlow-Variable变量" class="headerlink" title="1．建立TensorFlow Variable变量"></a>1．建立TensorFlow Variable变量</h5><p>以下程序代码与之前章节的内容类似。只是建立tf.placeholder与tf.mul时加入了name参数，name参数设置的名称会显示在TensorBoardGraph中，如图15-5所示。设置名称可以让“计算图”更易读。</p>
<p><img src="Image00781.jpg" alt></p>
<p>图15-5</p>
<h5 id="2．建立TensorFlow-Variable变量"><a href="#2．建立TensorFlow-Variable变量" class="headerlink" title="2．建立TensorFlow Variable变量"></a>2．建立TensorFlow Variable变量</h5><p>下面的程序代码将要显示在TensorBoard的数据中写入log文件。</p>
<p><img src="Image00782.jpg" alt></p>
<p>以上程序代码说明如下。</p>
<ul>
<li><strong>tf.summary.merge_all（）：</strong> 将所有要显示在TensorBoard的数据整合。</li>
<li><strong>tf.summary.FileWriter（）：</strong> 将所有要显示在TensorBoard的数据写入log文件。log文件会存储在当前程序执行目录下的log/area子目录中。</li>
</ul>
<h5 id="3．在Windows中启动TensorBoard"><a href="#3．在Windows中启动TensorBoard" class="headerlink" title="3．在Windows中启动TensorBoard"></a>3．在Windows中启动TensorBoard</h5><p>如果你使用的是Windows系统，就按照下列步骤启动TensorBoard。再启动新的命令提示符程序，并且输入下列命令。</p>
<p>▶ 先确认log目录文件是否已经产生</p>
<p>在Windows的“命令提示符”程序中使用dir显示目录，以下C：\pythonwork\TensorFlow是程序的执行目录，如果读者的执行目录不同，修改为自己的执行目录即可。</p>
<p><img src="Image00783.jpg" alt></p>
<p>▶ 启用TensorFlow的Anaconda虚拟环境</p>
<p><img src="Image00784.jpg" alt></p>
<p>▶ 启动TensorBoard</p>
<p>启动TensorBoard指令如下，需指定log文件目录，TensorBoard会读取此目录，并显示在TensorBoard上。</p>
<p><img src="Image00785.jpg" alt></p>
<p>执行后屏幕显示界面如图15-6所示。</p>
<p><img src="Image00786.jpg" alt></p>
<p>图15-6</p>
<p>以上<a href="http://192.168.56.1：6006是笔者个人计算机的内部IP，读者的IP可能不相同。读者也可以用浏览器输入此网址：http://localhost：6006／，因为localhost代表本机，就是读者当前正在使用的计算机。" target="_blank" rel="noopener">http://192.168.56.1：6006是笔者个人计算机的内部IP，读者的IP可能不相同。读者也可以用浏览器输入此网址：http://localhost：6006／，因为localhost代表本机，就是读者当前正在使用的计算机。</a></p>
<h5 id="4．在Linux-Ubuntu中启动TensorBoard"><a href="#4．在Linux-Ubuntu中启动TensorBoard" class="headerlink" title="4．在Linux Ubuntu中启动TensorBoard"></a>4．在Linux Ubuntu中启动TensorBoard</h5><p>如果读者使用的是Linux Ubuntu系统，就按照下列步骤启动TensorBoard。</p>
<p>▶ 先确认log目录文件是否已经产生</p>
<p>可以使用下列指令来查看log目录，以下～／pywork/TensorFlow是程序执行目录，如果读者的执行目录不同，就修改为自己的执行目录。</p>
<p><img src="Image00787.jpg" alt></p>
<p>执行后屏幕显示界面如图15-7所示，从中可以看到log文件。</p>
<p><img src="Image00788.jpg" alt></p>
<p>图15-7</p>
<p>▶ 启动TensorBoard</p>
<p>启动TensorBoard的指令如下，要先指定log文件目录，TensorBoard会读取此目录，并显示在TensorBoard上。</p>
<p><img src="Image00789.jpg" alt></p>
<p>执行后屏幕显示界面如图15-8所示。</p>
<p><img src="Image00790.jpg" alt></p>
<p>图15-8</p>
<p>我们也可以在浏览器中输入此网址：<a href="http://localhost:6006/，因为localhost代表本机，就是我们当前使用的计算机。" target="_blank" rel="noopener">http://localhost:6006/，因为localhost代表本机，就是我们当前使用的计算机。</a></p>
<h5 id="5．在TensorBoard查看计算图"><a href="#5．在TensorBoard查看计算图" class="headerlink" title="5．在TensorBoard查看计算图"></a>5．在TensorBoard查看计算图</h5><p>启动TensorBoard之后，再启动浏览器，并输入网址：<a href="http://localhost:6006/。" target="_blank" rel="noopener">http://localhost:6006/。</a></p>
<p>输入网址后，就会出现TensorBoard界面，在菜单中选择GRAPHS，之后就可以看到“计算图”，如图15-9所示。</p>
<p><img src="Image00791.jpg" alt></p>
<p>图15-9</p>
<h3 id="15-6-建立一维与二维张量"><a href="#15-6-建立一维与二维张量" class="headerlink" title="15.6 建立一维与二维张量"></a>15.6 建立一维与二维张量</h3><p>在前面的章节中，我们介绍了零维的张量，也就是标量（数值），接下来将介绍如何使用TensorFlow建立：一维的张量为向量，二维以上的张量为矩阵。</p>
<h5 id="1．建立一维张量（向量）"><a href="#1．建立一维张量（向量）" class="headerlink" title="1．建立一维张量（向量）"></a>1．建立一维张量（向量）</h5><p>建立一维的张量（tensor）只需要使用tf.Variable（）传入列表即可。</p>
<p><img src="Image00792.jpg" alt></p>
<p>从以上执行结果可知，建立的是一维张量，共有3个数值。</p>
<h5 id="2．查看一维张量"><a href="#2．查看一维张量" class="headerlink" title="2．查看一维张量"></a>2．查看一维张量</h5><p>可以使用shape查看数据的形状，因为一维张量共有3个数值，所以显示（3，）。</p>
<p><img src="Image00793.jpg" alt></p>
<h5 id="3．建立二维张量"><a href="#3．建立二维张量" class="headerlink" title="3．建立二维张量"></a>3．建立二维张量</h5><p>建立二维的张量也是使用tf.Variable（）传入二维的列表，所以我们传入列表的前后有两个中括号［［0.4，0.2，0.4］］，代表这是二维的列表。</p>
<p><img src="Image00794.jpg" alt></p>
<p>从以上执行结果可知，所建立的二维张量只有一项数据，每一项有3个数值。</p>
<h5 id="4．查看二维张量"><a href="#4．查看二维张量" class="headerlink" title="4．查看二维张量"></a>4．查看二维张量</h5><p>查看shape的结果是（1，3），说明如下：</p>
<p><img src="Image00795.jpg" alt></p>
<h5 id="5．再次建立二维张量"><a href="#5．再次建立二维张量" class="headerlink" title="5．再次建立二维张量"></a>5．再次建立二维张量</h5><p>接下来，同样建立二维张量，共有3项数据，每一项数据有两个数值。</p>
<p><img src="Image00796.jpg" alt></p>
<h5 id="6．查看新的二维张量"><a href="#6．查看新的二维张量" class="headerlink" title="6．查看新的二维张量"></a>6．查看新的二维张量</h5><p>查看shape结果是（3，2），说明如下：</p>
<p><img src="Image00797.jpg" alt></p>
<h3 id="15-7-矩阵基本运算"><a href="#15-7-矩阵基本运算" class="headerlink" title="15.7 矩阵基本运算"></a>15.7 矩阵基本运算</h3><p>接下来将介绍矩阵基本运算：乘法与加法。</p>
<h5 id="1．矩阵乘法"><a href="#1．矩阵乘法" class="headerlink" title="1．矩阵乘法"></a>1．矩阵乘法</h5><p>TensorFlow提供tf.matmul（）方法，可以进行矩阵乘法。当进行矩阵乘法时，两个矩阵的维数必须相同。范例如下：</p>
<ul>
<li>建立“计算图”先建立TensorFlow变量X与W，都是二维张量（矩阵），然后使用tf.matmul进行矩阵的相乘。</li>
<li>执行“计算图”使用sess.run（XW）执行计算图，并用print显示结果。</li>
</ul>
<p><img src="Image00798.jpg" alt></p>
<p>矩阵的运算公式为XW＝X×W，计算方式如下：</p>
<p><img src="Image00799.jpg" alt></p>
<p>大家也许会觉得奇怪，为什么程序执行结果是［［-1.299999950.40000001］］，这是因为矩阵运算是浮点运算，所以是近似值，与真实的计算结果会有误差。</p>
<h5 id="2．矩阵加法"><a href="#2．矩阵加法" class="headerlink" title="2．矩阵加法"></a>2．矩阵加法</h5><p>TensorFlow也可以进行矩阵加法，方法很简单，只需要使用加号即可。</p>
<p><img src="Image00800.jpg" alt></p>
<p>矩阵的运算公式为Sum＝XW＋b，计算方式如下：</p>
<p><img src="Image00801.jpg" alt></p>
<p>以上运算结果是［［-1.19999993 0.60000002］］，因为是浮点运算，所以是近似值。</p>
<h5 id="3．矩阵乘法与加法"><a href="#3．矩阵乘法与加法" class="headerlink" title="3．矩阵乘法与加法"></a>3．矩阵乘法与加法</h5><p>之前的步骤分别介绍了矩阵乘法与加法，接下来将乘法与加法一起运用。</p>
<p><img src="Image00802.jpg" alt></p>
<p>矩阵的运算公式为XWB＝X×W＋b，计算方式如下：</p>
<p><img src="Image00803.jpg" alt></p>
<p>以上运算结果为［［-1.19999993 0.60000002］］，因为是浮点运算，所以是近似值。</p>
<h3 id="15-8-结论"><a href="#15-8-结论" class="headerlink" title="15.8 结论"></a>15.8 结论</h3><p>本章介绍了TensoFlow的程序设计模式，并介绍了如何使用TensorFlow基本的张量运算，有了这些基础知识，下一章将介绍以TensorFlow张量（矩阵）运算来模拟类神经网络的运行。</p>
<h1 id="第16章-以TensorFlow张量运算仿真神经网络的运行"><a href="#第16章-以TensorFlow张量运算仿真神经网络的运行" class="headerlink" title="第16章 以TensorFlow张量运算仿真神经网络的运行"></a>第16章 以TensorFlow张量运算仿真神经网络的运行</h1><p>在第2章中，我们介绍了以矩阵数学公式来仿真类神经网络的运行。在本章中，我们将以TensorFlow张量（矩阵）运算来仿真类神经网络的运行。</p>
<p>下面的程序代码可参考范例程序TensorFlow_Tensor_neural.ipynb。有关范例程序下载与安装的细节可参考本书附录A中的“本书范例程序的下载与安装说明”。</p>
<h3 id="16-1-以矩阵运算仿真神经网络"><a href="#16-1-以矩阵运算仿真神经网络" class="headerlink" title="16.1 以矩阵运算仿真神经网络"></a>16.1 以矩阵运算仿真神经网络</h3><h5 id="1．以矩阵运算仿真神经网络的信息传导-1"><a href="#1．以矩阵运算仿真神经网络的信息传导-1" class="headerlink" title="1．以矩阵运算仿真神经网络的信息传导"></a>1．以矩阵运算仿真神经网络的信息传导</h5><p>可参考第2章以矩阵运算仿真神经网络的信息传导，如图16-1所示。</p>
<p><img src="Image00804.jpg" alt></p>
<p>图16-1</p>
<p>▶ 以数学公式模拟输出与接收神经元的工作方式：</p>
<p><img src="Image00805.jpg" alt></p>
<p>▶ 以上两个数学公式可以整合成一个矩阵运算公式：</p>
<p><img src="Image00806.jpg" alt></p>
<p>▶ 另一种形式的矩阵公式表示如下：</p>
<p><img src="Image00807.jpg" alt></p>
<p>▶ 矩阵公式以中文表示如下：</p>
<p><img src="Image00808.jpg" alt></p>
<p>说明见表16-1。</p>
<p>表16-1 以矩阵运算模拟神经网络参数说明</p>
<p><img src="Image00809.jpg" alt></p>
<h5 id="2．TensorFlow张量运算仿真神经网络"><a href="#2．TensorFlow张量运算仿真神经网络" class="headerlink" title="2．TensorFlow张量运算仿真神经网络"></a>2．TensorFlow张量运算仿真神经网络</h5><p>接下来，我们将以TensorFlow张量运算模拟以上公式。</p>
<p><img src="Image00810.jpg" alt></p>
<p>以上运算结果为 _y_ ＝［［0 0.28］］，矩阵的运算方式如下：</p>
<p><img src="Image00811.jpg" alt></p>
<p>在TensorFlow使用tf.nn.relu来引用ReLU激活函数。ReLU的特色是，如果小于0转换后是0，如果大于0输出等于输入。所以第1个元素－0.36经过ReLU转换后是0，第2个元素0.28经过ReLU转换后仍然是0.28。</p>
<h5 id="3．矩阵表达式加入Sigmoid激活函数"><a href="#3．矩阵表达式加入Sigmoid激活函数" class="headerlink" title="3．矩阵表达式加入Sigmoid激活函数"></a>3．矩阵表达式加入Sigmoid激活函数</h5><p>之前使用的是ReLU激活函数，我们也可以使用Sigmoid激活函数，程序代码如下：</p>
<p><img src="Image00812.jpg" alt></p>
<p>在TensorFlow使用tf.nn.sigmoid来引用Sigmoid激活函数，计算方式如下：</p>
<p><img src="Image00813.jpg" alt></p>
<h5 id="4．以正态分布的随机数生成权重与偏差的初始值"><a href="#4．以正态分布的随机数生成权重与偏差的初始值" class="headerlink" title="4．以正态分布的随机数生成权重与偏差的初始值"></a>4．以正态分布的随机数生成权重与偏差的初始值</h5><p>参考第2章，对于深度学习模型，我们会以反向传播算法进行训练，训练前必须先“建立模型”，建立多层感知模型必须以随机数初始化模型的权重与偏差。TensorFlow提供tf.random_normal可以用来产生正态分布的随机数的矩阵。</p>
<p><img src="Image00814.jpg" alt></p>
<h5 id="5．执行一次sess-run可以取得3个TensorFlow变量"><a href="#5．执行一次sess-run可以取得3个TensorFlow变量" class="headerlink" title="5．执行一次sess.run可以取得3个TensorFlow变量"></a>5．执行一次sess.run可以取得3个TensorFlow变量</h5><p>前面我们执行了sess.run（b）、sess.run（W）、sess.run（y），其实可以用另一种写法，只执行一次sess.run就可以取得3个TensorFlow变量，（_b，_W，_y）＝sess.run（（b，W，y））。</p>
<p><img src="Image00815.jpg" alt></p>
<h5 id="6．正态分布的随机数tf-random-normal"><a href="#6．正态分布的随机数tf-random-normal" class="headerlink" title="6．正态分布的随机数tf.random_normal"></a>6．正态分布的随机数tf.random_normal</h5><p>大家也许会好奇，什么是正态分布的随机数，我们将写个简单的程序代码来说明。</p>
<p>▶ 先使用tf.random_normal产生正态分布的随机数列表</p>
<p><img src="Image00816.jpg" alt></p>
<p>▶ 以plt.hist显示正态分布图形</p>
<p><img src="Image00817.jpg" alt></p>
<h3 id="16-2-以placeholder传入-X-值"><a href="#16-2-以placeholder传入-X-值" class="headerlink" title="16.2 以placeholder传入 _X_ 值"></a>16.2 以placeholder传入 _X_ 值</h3><p>_x_ 1、 _x_ 2、 _x_3是神经网络的输入，所以可能是任何数值，在实际运用时，会以placeholder传入神经网络进行运算。如图16-2所示，我们将 _x_ 1、 _x_ 2、_x_ 3改为place holder，后续以sess.run（）执行“数据流程图”时，可以使用feed_dict传入数组进行运算。</p>
<p><img src="Image00818.jpg" alt></p>
<p>图16-2</p>
<h5 id="1．以placeholder传入1×3的二维数组"><a href="#1．以placeholder传入1×3的二维数组" class="headerlink" title="1．以placeholder传入1×3的二维数组"></a>1．以placeholder传入1×3的二维数组</h5><p>以下程序代码使用placeholder传入二维数组X＝［［0.4，0.2，0.4］］。</p>
<p><img src="Image00819.jpg" alt></p>
<p><img src="Image00820.jpg" alt></p>
<p>以上传入的 _X_ 是1×3的二维数组［［0.4，0.2，0.4］］，输出的 _y_是1×2的二维数组［［0.52920794，0．］］，以上程序代码的说明如下：</p>
<p>▶ 先定义placeholder</p>
<p><img src="Image00821.jpg" alt></p>
<p>tf.placeholder共有两个参数：</p>
<ul>
<li>第1个参数设置为“Float“，是placeholder的数据类型。</li>
<li>第2个参数设置为［None，3］，placeholder矩阵的形状。第一维设置为None。因为传入的 _X_ 项数不限。第二维是每一项的数字个数，每一项有3个数字，所以设置为3。</li>
</ul>
<p>▶ 建立X_array</p>
<p><img src="Image00822.jpg" alt></p>
<p>使用np.array建立X_array。</p>
<p>▶ 执行sess.run</p>
<p><img src="Image00823.jpg" alt></p>
<p>sess.run执行“数据流程图”，以feed_dict传入 _X_ ：为X_array，执行结果返回_b、_W、_X、_y变量。</p>
<h5 id="2．以placeholder传入3×3的二维数组"><a href="#2．以placeholder传入3×3的二维数组" class="headerlink" title="2．以placeholder传入3×3的二维数组"></a>2．以placeholder传入3×3的二维数组</h5><p>之前placeholder的传入是1×3的二维数组，接下来将传入3×3的二维数组进行计算。</p>
<p><img src="Image00824.jpg" alt></p>
<p><img src="Image00825.jpg" alt></p>
<h3 id="16-3-创建layer函数以矩阵运算仿真神经网络"><a href="#16-3-创建layer函数以矩阵运算仿真神经网络" class="headerlink" title="16.3 创建layer函数以矩阵运算仿真神经网络"></a>16.3 创建layer函数以矩阵运算仿真神经网络</h3><p>前面的章节已经示范了以矩阵运算仿真神经网络，后续的章节我们将以相同的方式来建立类神经网络多层感知器，为了方便后续使用，我们将创建layer函数。</p>
<h5 id="1．layer函数"><a href="#1．layer函数" class="headerlink" title="1．layer函数"></a>1．layer函数</h5><p>我们将创建下面的layer函数，其功能是建立两层神经网络。</p>
<p><img src="Image00826.jpg" alt></p>
<p>以上程序代码的详细说明如下：</p>
<p>▶ 定义layer函数参数</p>
<p><img src="Image00827.jpg" alt></p>
<ul>
<li><strong>output_dim：</strong> 输出的神经元数量。</li>
<li><strong>input</strong> _ <strong>dim：</strong> 输入的神经元数量。</li>
<li><strong>input：</strong> 输入的二维数组placeholder。</li>
<li><strong>activation：</strong> 传入激活函数，默认是None。</li>
</ul>
<p>▶ 以正态分布的随机数建立并且初始化 _W_ （权重）</p>
<p><img src="Image00828.jpg" alt></p>
<p>以tf.random_normal函数传入［input_dim，output_dim］参数就可以产生维数是（input_dim，output_dim）的正态分布的随机数矩阵。</p>
<p>▶ 以正态分布的随机数建立 _b_ （偏差）</p>
<p><img src="Image00829.jpg" alt></p>
<p>以tf.random_normal函数传入［1，output_dim］参数就可以产生维数是（1，output_dim）的正态分布的随机数矩阵。</p>
<p>▶ 建立矩阵表达式 _XWb_ ＝（inputs× _W_ ）＋ _b_</p>
<p><img src="Image00830.jpg" alt></p>
<p>▶ 设置activation激活函数</p>
<p><img src="Image00831.jpg" alt></p>
<p>如果输入的参数activation是None，就不要使用激活函数，如果传入激活函数，就会使用传入的激活函数进行转换。</p>
<p>▶ 返回已建立的神经网络层</p>
<p><img src="Image00832.jpg" alt></p>
<h5 id="2．使用layer函数建立3层类神经网络"><a href="#2．使用layer函数建立3层类神经网络" class="headerlink" title="2．使用layer函数建立3层类神经网络"></a>2．使用layer函数建立3层类神经网络</h5><p>接下来，我们将以layer函数建立3层类神经网络，输入层有4个神经元，隐藏层有3个神经元，输出层有2个神经元，如图16-3所示。</p>
<p><img src="Image00833.jpg" alt></p>
<p>图16-3</p>
<p>建立的程序代码如下：</p>
<p><img src="Image00834.jpg" alt></p>
<p>从以上执行结果可知，输入的 _X_ 是1×4的张量，隐藏层（h）是1×3的张量，输出层（y）是1×2的张量，程序代码说明如下：</p>
<p>▶ 建立输入层（ _X_ ）</p>
<p><img src="Image00835.jpg" alt></p>
<p>建立输入层使用tf.placeholder方法，设置表16-2中的参数。</p>
<p>表16-2 使用tf.placeholder方法建立输入层需设置的参数</p>
<p><img src="Image00836.jpg" alt></p>
<p>▶ 建立隐藏层（ _h_ ）</p>
<p><img src="Image00837.jpg" alt></p>
<p>调用layer函数返回隐藏层需输入表16-3中的参数。</p>
<p>表16-3 调用layer层返回隐藏层需输入的参数</p>
<p><img src="Image00838.jpg" alt></p>
<p>▶ 建立输出层（ _y_ ）</p>
<p><img src="Image00839.jpg" alt></p>
<p>调用layer函数返回输出层需输入表16-4中的参数。</p>
<p>表16-4 调用layer层返回输出层需要输入的参数</p>
<p><img src="Image00840.jpg" alt></p>
<h3 id="16-4-建立layer-debug函数显示权重与偏差"><a href="#16-4-建立layer-debug函数显示权重与偏差" class="headerlink" title="16.4 建立layer_debug函数显示权重与偏差"></a>16.4 建立layer_debug函数显示权重与偏差</h3><p>之前layer函数只返回了output，并未返回 _W_ （Weight）与 _b_<br>（bias），为了让读者更容易了解神经网络的运行情况，我们特别把layer函数修改为layer_debug函数，可返回 _W_ 与 _b_ ，后续可显示_W_ 与 _b_ 。</p>
<h5 id="1．创建layer-debug函数"><a href="#1．创建layer-debug函数" class="headerlink" title="1．创建layer_debug函数"></a>1．创建layer_debug函数</h5><p>layer_debug函数与layer类似，只是除了返回output之外，它还返回 _W_ 与 _b_ 。</p>
<p><img src="Image00841.jpg" alt></p>
<h5 id="2．使用layer-debug函数建立3层类神经网络并显示-W-与-b"><a href="#2．使用layer-debug函数建立3层类神经网络并显示-W-与-b" class="headerlink" title="2．使用layer_debug函数建立3层类神经网络并显示 _W_ 与 _b_"></a>2．使用layer_debug函数建立3层类神经网络并显示 _W_ 与 _b_</h5><p>以下程序使用layer_debug函数建立3层类神经网络，并显示第一层的 _W_ 1与 _b_ 1，以及第2层的 _W_ 2与 _b_ 2。</p>
<p><img src="Image00842.jpg" alt></p>
<p>以上程序代码执行结果的详细说明如图16-4所示。</p>
<p><img src="Image00843.jpg" alt></p>
<p>图16-4</p>
<p>图16-4的说明如下：</p>
<ul>
<li>_X_ 模拟输入层，共有4个神经元，我们输入的x值是1×4的张量。</li>
<li>_h_ 模拟隐藏层，共有3个神经元，所以是1×3的张量。</li>
<li>_y_ 模拟输出层，共有2个神经元，所以是1×2的张量。</li>
<li>_W_ 1是权重，模拟神经元的轴突，因为输入层有4个神经元，隐藏层有3个神经元，为了让输入层与隐藏层神经元完全连接，所以 _W_ 1是4×3的张量。</li>
<li>_b_ 1是偏差值，仿真突触的结构，代表接收神经元容易被活化的程度，偏差值越高，越容易被活化并传递信息。因为隐藏层神经元有3个，所以 _b_ 1是1×3的张量。</li>
<li>_W_ 2是权重，因为隐藏层有3个神经元，输出层有2个神经元，为了让隐藏层与输出层神经元完全连接，所以 _W_ 2是3×2的张量。</li>
<li>_b_ 2是偏差值，因为输出层神经元有2个，所以 _b_ 2是1×2的张量。</li>
</ul>
<h3 id="16-5-结论"><a href="#16-5-结论" class="headerlink" title="16.5 结论"></a>16.5 结论</h3><p>在本章我们以TensorFlow张量（矩阵）运算来仿真类神经网络的运行，并且建立了layer函数，可用于构建神经网络层。接下来，第17章介绍用TensorFlow读取MNIST数据集，并且进行数据的预处理。</p>
<h1 id="第17章-TensorFlow-MNIST手写数字识别数据集"><a href="#第17章-TensorFlow-MNIST手写数字识别数据集" class="headerlink" title="第17章 TensorFlow MNIST手写数字识别数据集"></a>第17章 TensorFlow MNIST手写数字识别数据集</h1><p>MNIST手写数字识别数据集是由Yann LeCun所收集的，他也是Convolution Neural Networks的创始人。TensorFlowMNIST数据集共有训练数据55 000项、验证数据5 000项、测试数据10000项。每一项数据都由features（数字图像）与label（真实的数字）所组成，本章将介绍用TensorFlow读取MNIST数据集，并且进行数据的预处理。</p>
<p>本章的内容与第6章类似，都是下载并读取MNIST数据。只是第6章用Keras语句来执行，本章用TensorFlow语句执行，两种方式类似，但是有些地方又不相同。读者可以对照阅读，进而更加了解TensorFlow与Keras。以下程序代码请参考范例程序TensorFlow_Mnist_Introduce.ipynb。</p>
<h3 id="17-1-下载MNIST数据"><a href="#17-1-下载MNIST数据" class="headerlink" title="17.1 下载MNIST数据"></a>17.1 下载MNIST数据</h3><p>我们将建立以下TensorFlow程序下载并读取MNIST数据。</p>
<p><img src="Image00844.jpg" alt> 导入TensorFlow模块。</p>
<p><img src="Image00845.jpg" alt></p>
<p><img src="Image00846.jpg" alt> 导入TensorFlow读取MNIST数据集模块。</p>
<p>TensorFlow已经提供了现成模块，可以用于下载并读取MNIST数据。</p>
<p><img src="Image00847.jpg" alt></p>
<p><img src="Image00848.jpg" alt> 第一次执行会下载MNIST数据。</p>
<p>第一次执行input_data.read_data_sets方法，程序会检查当前执行的目录是否有“MNIST_data／“目录以及是否已经有文件，如果还没有，就会下载文件。以下是第一次执行下载文件的屏幕显示界面。因为必须要下载文件，所以运行时间会比较长。</p>
<p><img src="Image00849.jpg" alt></p>
<p><img src="Image00850.jpg" alt> 查看MNIST数据文件。</p>
<p>下载完成后，可以输入下列指令查看当前程序执行目录（～／pywork/TensorFlow）下的MNIST_data子目录。</p>
<p><img src="Image00851.jpg" alt></p>
<p>执行界面如图17-1所示。</p>
<p><img src="Image00852.jpg" alt></p>
<p>图17-1</p>
<p><img src="Image00853.jpg" alt> 读取MNIST数据。</p>
<p>当我们再次执行input_data.read_data_sets时，由于之前已经下载了文件，不需要再次下载，只需要读取文件，因此运行时间不会太长。</p>
<p><img src="Image00854.jpg" alt></p>
<p><img src="Image00855.jpg" alt> 查看MNIST数据。</p>
<p>下载后，可以使用下列指令来查看MNIST数据。</p>
<p><img src="Image00856.jpg" alt></p>
<p>从以上执行结果可以看到数据分为三部分。</p>
<ul>
<li><strong>train：</strong> 训练数据55 000项。</li>
<li><strong>validation：</strong> 验证数据5 000项。</li>
<li><strong>test：</strong> 测试数据10 000项。</li>
</ul>
<h3 id="17-2-查看训练数据"><a href="#17-2-查看训练数据" class="headerlink" title="17.2 查看训练数据"></a>17.2 查看训练数据</h3><p>先查看训练数据。</p>
<h5 id="1．训练数据是由images与labels所组成的（见图17-2）"><a href="#1．训练数据是由images与labels所组成的（见图17-2）" class="headerlink" title="1．训练数据是由images与labels所组成的（见图17-2）"></a>1．训练数据是由images与labels所组成的（见图17-2）</h5><p><img src="Image00857.jpg" alt></p>
<p><img src="Image00858.jpg" alt></p>
<p>较17-2</p>
<h5 id="2．查看第0项images图像的长度"><a href="#2．查看第0项images图像的长度" class="headerlink" title="2．查看第0项images图像的长度"></a>2．查看第0项images图像的长度</h5><p>用len函数来查看第0项images图像的长度，我们可以看到共有784个数字。</p>
<p><img src="Image00859.jpg" alt></p>
<h5 id="3．查看第0项images图像的内容"><a href="#3．查看第0项images图像的内容" class="headerlink" title="3．查看第0项images图像的内容"></a>3．查看第0项images图像的内容</h5><p>查看第0项images图像的内容，共有784个数值。TensorFlow已经进行标准化，数值都介于0～1之间，所以不需要再标准化。</p>
<p><img src="Image00860.jpg" alt></p>
<h5 id="4．定义plot-image函数显示图像"><a href="#4．定义plot-image函数显示图像" class="headerlink" title="4．定义plot_image函数显示图像"></a>4．定义plot_image函数显示图像</h5><p>为了能够显示图形，我们创建如下的plot_image函数。</p>
<p><img src="Image00861.jpg" alt></p>
<p>▶ 首先导入matplotlib.pyplot模块，后续用plt来引用</p>
<p><img src="Image00862.jpg" alt></p>
<p>▶ 定义plot_image函数，传入image作为参数</p>
<p><img src="Image00863.jpg" alt></p>
<p>▶ 使用plt.imshow显示图形</p>
<p><img src="Image00864.jpg" alt></p>
<p>使用plt.imshow显示图形，传入参数image原本是784个点，必须先使用reshape转换为28×28的图形，cmap参数设置为binary。</p>
<p>▶ 开始绘图</p>
<p><img src="Image00865.jpg" alt></p>
<h5 id="5．执行plot-image函数"><a href="#5．执行plot-image函数" class="headerlink" title="5．执行plot_image函数"></a>5．执行plot_image函数</h5><p>以下程序调用plot_image函数传入mnist.train.images［0］，也就是训练数据集的第0项数据，从显示结果中可以看到这是一个数字7的图形。</p>
<p><img src="Image00866.jpg" alt></p>
<h5 id="6．查看训练标签labels数据"><a href="#6．查看训练标签labels数据" class="headerlink" title="6．查看训练标签labels数据"></a>6．查看训练标签labels数据</h5><p>因为我们之前读取数据集时mnist＝input_data.read_data_sets（“MNIST_data／“，one_hot＝True），指定参数one_hot是True，所以产生的数据labels是One-Hot Encoding格式。One-Hot Encoding是由数字0与1所组成的，只有一个数字是1，其余都是0，例如：</p>
<p><img src="Image00867.jpg" alt></p>
<p>下列程序代码显示训练数据的第0项数据：从0算起第7个数字是1，其余都是0，所以此数字是7。</p>
<p><img src="Image00868.jpg" alt></p>
<p>使用One-Hot Encoding的原因是，后续我们要建立类神经网络的输出层，输出层共有10个神经元：y0～y9，分别对应0～9。</p>
<h5 id="7．使用argmax显示数字"><a href="#7．使用argmax显示数字" class="headerlink" title="7．使用argmax显示数字"></a>7．使用argmax显示数字</h5><p>One-HotEncoding格式阅读起来不太方便，我们可以使用np.argmax转换为0～9的数字。例如下面的程序代码，将mnist.train.labels［0］转换为数字7。</p>
<p><img src="Image00869.jpg" alt></p>
<h3 id="17-3-查看多项训练数据images与labels"><a href="#17-3-查看多项训练数据images与labels" class="headerlink" title="17.3 查看多项训练数据images与labels"></a>17.3 查看多项训练数据images与labels</h3><p><img src="Image00870.jpg" alt> 修改plot_images_labels_prediction（）函数。</p>
<p>为了便于查看多项数据images与labels，我们将修改第6章所创建的plot_images_labels_prediction（）函数，修改如下：</p>
<p><img src="Image00871.jpg" alt></p>
<p>主要修改了以下两部分。</p>
<p>（1） <strong>转换images字段：</strong>因为TensorFlow的MNIST数据集的image有764个数值，所以必须以np.reshape转换为二维28×28的图像才能显示出来。</p>
<p>（2） <strong>转换labels字段：</strong> 因为TensorFlow的MNIST数据集的labels字段已经是One-HotEncoding格式，所以必须使用np.argmax将One-Hot Encoding格式转换为数字才能显示0～9的数字。</p>
<p><img src="Image00872.jpg" alt> 查看训练数据前10项数据。</p>
<p>执行plot_images_labels_prediction（）显示训练数据前10项数据。</p>
<p><img src="Image00873.jpg" alt></p>
<p><img src="Image00874.jpg" alt> 查看validation数据项数。</p>
<p>通过下面的程序代码可以看到validation数据项数共5000项。</p>
<p><img src="Image00875.jpg" alt></p>
<p><img src="Image00876.jpg" alt> 查看validation数据。</p>
<p>执行plot_images_labels_prediction（）显示验证数据前10项数据。</p>
<p><img src="Image00877.jpg" alt></p>
<p><img src="Image00878.jpg" alt> 查看test数据项数。</p>
<p><img src="Image00879.jpg" alt></p>
<p><img src="Image00880.jpg" alt> 查看test数据。</p>
<p><img src="Image00881.jpg" alt></p>
<h3 id="17-4-批次读取MNIST数据"><a href="#17-4-批次读取MNIST数据" class="headerlink" title="17.4 批次读取MNIST数据"></a>17.4 批次读取MNIST数据</h3><p>在后续章节我们要进行深度学习网络的训练，每次训练时，并不是读取所有数据进行训练，而是读取批次数据（例如100项）进行训练。在TensorFlowMNIST模块中，已经提供了mnist.train.next_batch方法，可按批次读取数据。</p>
<p><img src="Image00882.jpg" alt> 读取批次数据。</p>
<p>下面的程序代码使用mnist.train.next_batch方法传入参数batch_size＝100，每次只读取100项批次训练数据。读取的结果会存储在batch_images_xs，batch_labels_ys中。</p>
<p><img src="Image00883.jpg" alt></p>
<p><img src="Image00884.jpg" alt> 查看批次数据项数。</p>
<p>使用以下指令可以看到批次训练数据的项数是100项。</p>
<p><img src="Image00885.jpg" alt></p>
<p><img src="Image00886.jpg" alt> 查看批次数据。</p>
<p>执行plot_images_labels_prediction（）显示批次训练数据前10项数据。</p>
<p><img src="Image00887.jpg" alt></p>
<h3 id="17-5-结论"><a href="#17-5-结论" class="headerlink" title="17.5 结论"></a>17.5 结论</h3><p>在本章中，我们介绍了使用TensorFlow下载并且读取MNIST数据集，还介绍了MNIST数据集的特色，并且完成了数据的预处理。在下一章，我们就可以使用TensorFlow建立多层感知器模型，并且进行训练和使用模型进行预测。</p>
<h1 id="第18章-TensorFlow多层感知器识别手写数字"><a href="#第18章-TensorFlow多层感知器识别手写数字" class="headerlink" title="第18章 TensorFlow多层感知器识别手写数字"></a>第18章 TensorFlow多层感知器识别手写数字</h1><p>本章将介绍如何使用TensorFlow建立多层感知器，训练模型、评估模型的准确率，然后使用训练完成的模型来识别MNIST手写数字，并且尝试将模型加宽、加深，以提高准确率。</p>
<p>本章在说明程序代码时，会比较Keras与TensorFlow在建立模型、训练模型时有哪些不同，让读者更了解这两种程序设计模式的差异。读者可以对照第7章Keras程序代码的说明。</p>
<p>本章完整的程序代码可参考范例程序TensorFlow_Mnist_MLP_h256.ipynb。范例程序的下载与安装可参考本书附录A。</p>
<h3 id="18-1-TensorFlow建立多层感知器辨识手写数字的介绍"><a href="#18-1-TensorFlow建立多层感知器辨识手写数字的介绍" class="headerlink" title="18.1 TensorFlow建立多层感知器辨识手写数字的介绍"></a>18.1 TensorFlow建立多层感知器辨识手写数字的介绍</h3><h5 id="1．多层感知器的训练与预测"><a href="#1．多层感知器的训练与预测" class="headerlink" title="1．多层感知器的训练与预测"></a>1．多层感知器的训练与预测</h5><p>建立如图18-1所示的多层感知器模型后，必须先训练才能够预测（识别）这些手写数字。</p>
<p><img src="Image00888.jpg" alt></p>
<p>图18-1</p>
<p>以多层感知器模型识别MNIST数字图像可分为训练与预测两个部分。</p>
<p>▶ 训练</p>
<p>MNIST训练数据集的训练数据共60000项，经过数据预处理后会产生features（数字图像特征值）与label（数字真实的值），然后输入多层感知器模型进行训练，训练完成的模型可以在下一阶段预测时使用。</p>
<p>▶ 预测</p>
<p>输入数字图像，预处理后会产生features（数字图像转换为特征），使用训练完成的多层感知器模型进行预测，最后产生预测结果。</p>
<h5 id="2．以多层感知器模型识别MNIST手写数字图像"><a href="#2．以多层感知器模型识别MNIST手写数字图像" class="headerlink" title="2．以多层感知器模型识别MNIST手写数字图像"></a>2．以多层感知器模型识别MNIST手写数字图像</h5><p>我们将以多层感知器模型识别MNIST手写数字图像来说明多层感知器模型的工作方式，如图18-2所示。</p>
<p><img src="Image00889.jpg" alt></p>
<p>图18-2</p>
<h5 id="3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）"><a href="#3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）" class="headerlink" title="3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）"></a>3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）</h5><p><img src="Image00890.jpg" alt></p>
<p>图18-3</p>
<h5 id="4．多层感知器模型的建立步骤"><a href="#4．多层感知器模型的建立步骤" class="headerlink" title="4．多层感知器模型的建立步骤"></a>4．多层感知器模型的建立步骤</h5><p>多层感知器识别MNIST数据集中的手写数字的步骤说明如图18-4所示。</p>
<p><img src="Image00891.jpg" alt></p>
<p>图18-4</p>
<h3 id="18-2-数据准备"><a href="#18-2-数据准备" class="headerlink" title="18.2 数据准备"></a>18.2 数据准备</h3><p>首先读取MNIST数据集数据，关于MNIST数据集的内容可参考第17章。</p>
<p><img src="Image00892.jpg" alt></p>
<h3 id="18-3-建立模型"><a href="#18-3-建立模型" class="headerlink" title="18.3 建立模型"></a>18.3 建立模型</h3><p>Keras与TensorFlow建立模型的方式有所不同，说明如下。</p>
<ul>
<li>Keras建立模型：只需要使用model＝Sequential（）建立线性堆叠模型，再使用model.add（）方法将各个神经网络层加入模型即可。</li>
<li>TensorFlow建立模型：必须自行定义layer函数（处理张量运算），然后使用layer函数构建多层感知器模型。</li>
</ul>
<p>后续的程序代码将以TensorFlow定义layer函数，然后构建多层感知器模型，如图18-5所示。</p>
<p><img src="Image00893.jpg" alt></p>
<p>图18-5</p>
<h5 id="1．建立layer函数"><a href="#1．建立layer函数" class="headerlink" title="1．建立layer函数"></a>1．建立layer函数</h5><p>我们将使用layer函数（详细说明请参考第16章）构建多层感知器模型。</p>
<p><img src="Image00894.jpg" alt></p>
<h5 id="2．建立输入层（-x-）"><a href="#2．建立输入层（-x-）" class="headerlink" title="2．建立输入层（ _x_ ）"></a>2．建立输入层（ _x_ ）</h5><p>下列程序代码使用tf.placeholder方法建立输入层（ _x_<br>），placeholder是TensorFlow“计算图”的输入，后续在训练时会传入数字图像数据。</p>
<p><img src="Image00895.jpg" alt></p>
<p>建立tf.placeholder方法需设置表18-1中的参数。</p>
<p>表18-1 建立tf.placeholder方法需设置的参数</p>
<p><img src="Image00896.jpg" alt></p>
<p>以上tf.placeholder方法会返回x输入层，可作为下一层的输入。</p>
<h5 id="3．建立隐藏层（-h-1）"><a href="#3．建立隐藏层（-h-1）" class="headerlink" title="3．建立隐藏层（ _h_ 1）"></a>3．建立隐藏层（ _h_ 1）</h5><p>使用下列程序代码来建立隐藏层（ _h_ 1）。</p>
<p><img src="Image00897.jpg" alt></p>
<p>建立隐藏层时，调用layer函数需输入表18-2中的参数。</p>
<p>表18-2 建立隐藏层时调用layer函数需输入的参数</p>
<p><img src="Image00898.jpg" alt></p>
<p>以上layer函数执行后会返回h1隐藏层，可作为下一层的输入。</p>
<h5 id="4．建立输出层（-y-）"><a href="#4．建立输出层（-y-）" class="headerlink" title="4．建立输出层（ _y_ ）"></a>4．建立输出层（ _y_ ）</h5><p>使用下列程序代码建立输出层（ _y_ ）。</p>
<p><img src="Image00899.jpg" alt></p>
<p>建立输出层y_predict时，调用layer函数需输入表18-3中的参数。</p>
<p>表18-3 建立输出层y_predict时调用layer函数需输入的参数</p>
<p><img src="Image00900.jpg" alt></p>
<h3 id="18-4-定义训练方式"><a href="#18-4-定义训练方式" class="headerlink" title="18.4 定义训练方式"></a>18.4 定义训练方式</h3><p>以下说明Keras与TensorFlow定义训练方式的不同。</p>
<ul>
<li><strong>Keras定义训练方式：</strong> 只需要使用model.compile设置损失函数、优化器，并用metrics设置评估模型的方式。</li>
<li><strong>TensorFlow定义训练方式：</strong> 必须自行定义损失函数的公式、优化器和设置参数，并定义评估模型准确率的公式。</li>
</ul>
<p><img src="Image00901.jpg" alt> 建立训练数据label真实值的placeholder。</p>
<p><img src="Image00902.jpg" alt></p>
<p>以上程序代码使用tf.placeholder方法来建立y_label，需设置表18-4中的参数。</p>
<p>表18-4 使用tf.placeholder方法来建立y_label需设置的参数</p>
<p><img src="Image00903.jpg" alt></p>
<p>placeholder是TensorFlow“计算图”的输入，后续在训练时会传入数字的label（真实值）。</p>
<p><img src="Image00904.jpg" alt> 定义损失函数。</p>
<p>在深度学习模型的训练中使用cross_entropy交叉熵训练的效果比较好。</p>
<p><img src="Image00905.jpg" alt></p>
<p>以上程序代码的说明见表18-5。</p>
<p>表18-5 程序代码说明</p>
<p><img src="Image00906.jpg" alt></p>
<p><img src="Image00907.jpg" alt> 定义优化器。</p>
<p><img src="Image00908.jpg" alt></p>
<p>以上程序代码的说明见表18-6。</p>
<p>表18-6 程序代码说明</p>
<p><img src="Image00909.jpg" alt></p>
<h3 id="18-5-定义评估模型准确率的方式"><a href="#18-5-定义评估模型准确率的方式" class="headerlink" title="18.5 定义评估模型准确率的方式"></a>18.5 定义评估模型准确率的方式</h3><p>训练模型完成后，我们希望能够评估模型的准确率。在TensorFlow必须定义评估模型准确率的方式。</p>
<p><img src="Image00910.jpg" alt> 计算每一项数据是否预测正确。</p>
<p>首先，计算每一项数据是否预测正确。</p>
<p><img src="Image00911.jpg" alt></p>
<p>以上程序代码的说明见表18-7。</p>
<p>表18-7 程序代码说明</p>
<p><img src="Image00912.jpg" alt></p>
<p><img src="Image00913.jpg" alt> 计算预测正确结果的平均值。</p>
<p>再将前一步的计算结果correct_prediction进行平均运算。</p>
<p><img src="Image00914.jpg" alt></p>
<p>程序代码说明见表18-8。</p>
<p>表18-8 程序代码说明</p>
<p><img src="Image00915.jpg" alt></p>
<h3 id="18-6-进行训练"><a href="#18-6-进行训练" class="headerlink" title="18.6 进行训练"></a>18.6 进行训练</h3><p>关于Keras与TensorFlow进行训练的比较如下。</p>
<ul>
<li><strong>Keras进行训练：</strong> 只需要使用model.fit就可以开始训练。</li>
<li><strong>TensorFlow进行训练：</strong> 必须编写程序代码来控制训练的每一个过程。</li>
</ul>
<p>▶ 使用TensorFlow进行训练</p>
<p>以下训练数据共55 000项，分为每一批次100项，要将所有数据训练完毕需执行550批次（55000/100＝550批次），当所有数据训练完毕，称为完成一个训练周期。我们将执行15个训练周期，尽量使误差降低，并且尽量提高准确率。整理训练过程流程图如图18-6所示。</p>
<p><img src="Image00916.jpg" alt></p>
<p>图18-6</p>
<h5 id="1．定义训练参数"><a href="#1．定义训练参数" class="headerlink" title="1．定义训练参数"></a>1．定义训练参数</h5><p><img src="Image00917.jpg" alt></p>
<p>程序代码说明见表18-9。</p>
<p>表18-9 程序代码说明</p>
<p><img src="Image00918.jpg" alt></p>
<h5 id="2．进行训练"><a href="#2．进行训练" class="headerlink" title="2．进行训练"></a>2．进行训练</h5><p><img src="Image00919.jpg" alt></p>
<p>以上程序代码的详细说明如下：</p>
<p>▶ 执行15个训练周期</p>
<p><img src="Image00920.jpg" alt></p>
<p>▶ 每一个训练周期执行550批次训练</p>
<p><img src="Image00921.jpg" alt></p>
<p>for i in range（totalBatchs）执行550批次训练。</p>
<p>① <strong>读取批次数据：</strong>使用mnist.train.next_batch方法读取批次数据，传入参数batchSize是100，每批次会读取100项数据，执行后返回。</p>
<ul>
<li>batch_x数字图像（特征值）共100项。</li>
<li>batch_y数字图像（真实值）共100项。</li>
</ul>
<p>② <strong>执行批次训练：</strong>sess.run（optimizer，feed_dict＝｛x：batch_x，y_label：batch_y｝）使用sess.run执行优化器，通过feed_dict把数据传送给两个placeholder，分别是：</p>
<ul>
<li>x placeholder传入batch_x。</li>
<li>y_label placeholder传入batch_y。优化器按照误差值更新神经元连接的权重与偏差，尽量使损失函数的误差值最小化。</li>
</ul>
<p>▶ 使用验证数据计算准确率</p>
<p><img src="Image00922.jpg" alt></p>
<p>使用sess.run（［loss_function，accuracy］计算准确率，并且通过feed_dict把数据传送给两个placeholder，分别是：</p>
<ul>
<li>x：mnist.validation.images验证数据的数字图像（特征值）。</li>
<li>y_label：mnist.validation.labels验证数据的数字图像（真实值）。</li>
</ul>
<p>执行后会返回误差与准确率。</p>
<p>▶ 显示训练结果，并存入列表用于后续显示图表</p>
<p><img src="Image00923.jpg" alt></p>
<p>epoch_list.append（epoch）加入训练周期列表，loss_list.append（loss）加入误差列表，accuracy_list.append（acc）加入准确率列表，这些列表后续可用于显示图表。</p>
<p>另外，使用print显示此训练周期的结果。</p>
<p>▶ 15个训练周期后，计算并且显示全部训练所需的时间</p>
<p><img src="Image00924.jpg" alt></p>
<p>执行后结果如图18-7所示。</p>
<p><img src="Image00925.jpg" alt></p>
<p>图18-7</p>
<p>从以上执行结果的屏幕显示界面可以看到共执行了15个训练周期，还可以发现误差越来越小，准确率越来越高。</p>
<h5 id="3．画出误差执行结果"><a href="#3．画出误差执行结果" class="headerlink" title="3．画出误差执行结果"></a>3．画出误差执行结果</h5><p>使用以下程序代码画出误差的执行结果。</p>
<p><img src="Image00926.jpg" alt></p>
<p>程序代码的说明见表18-10。</p>
<p>表18-10 程序代码说明</p>
<p><img src="Image00927.jpg" alt></p>
<p>（续表）</p>
<p><img src="Image00928.jpg" alt></p>
<p>显示后结果如图18-8所示，我们可以看到误差越来越小。</p>
<p><img src="Image00929.jpg" alt></p>
<p>图18-8</p>
<h5 id="4．画出准确率的执行结果"><a href="#4．画出准确率的执行结果" class="headerlink" title="4．画出准确率的执行结果"></a>4．画出准确率的执行结果</h5><p>使用下面的程序代码画出准确率的执行结果。</p>
<p><img src="Image00930.jpg" alt></p>
<p>上面的程序代码与上一步类似，只是多了plt.ylim（0.8，1），用于设置 _y_ 轴显示的范围，如图18-9所示。</p>
<p><img src="Image00931.jpg" alt></p>
<p>图18-9</p>
<h3 id="18-7-评估模型准确率"><a href="#18-7-评估模型准确率" class="headerlink" title="18.7 评估模型准确率"></a>18.7 评估模型准确率</h3><p>之前我们已经完成了训练，现在要使用test测试数据集，评估模型的准确率。</p>
<p><img src="Image00932.jpg" alt></p>
<p>下面的程序代码使用sess.run（accuracy）计算准确率，并使用feed_dict把数据传送给以下两个placeholder。</p>
<ul>
<li>x：mnist.test.images：测试数据的数字图像。</li>
<li>y_label：mnist.test.labels：测试数据的数字真实值。</li>
</ul>
<p>以上执行结果的准确率是0.94。</p>
<h3 id="18-8-进行预测"><a href="#18-8-进行预测" class="headerlink" title="18.8 进行预测"></a>18.8 进行预测</h3><p>在之前的步骤中我们建立了模型，并且完成了模型的训练，准确率达到还可以接受的0.94，接下来将使用此模型进行预测。</p>
<h5 id="1．执行预测-2"><a href="#1．执行预测-2" class="headerlink" title="1．执行预测"></a>1．执行预测</h5><p>我们可以用下列指令执行预测。</p>
<p><img src="Image00933.jpg" alt></p>
<p>以上程序代码使用sess.run（tf.argmax（y_predict，1）执行预测，因为y_predict预测结果为One-HotEncoding格式，所以必须使用tf.argmax转换为0～9的数字。执行时必须用feed_dict把数据传送给以下placeholder。</p>
<ul>
<li><strong>x：mnist.test.images：</strong> 测试数据的数字图像。</li>
</ul>
<p>以上程序代码执行后，会将预测结果存储在prediction_result中。</p>
<h5 id="2．预测结果-2"><a href="#2．预测结果-2" class="headerlink" title="2．预测结果"></a>2．预测结果</h5><p>可以用下列指令来查看预测结果prediction_result的前10项数据。</p>
<p><img src="Image00934.jpg" alt></p>
<p>我们可以看到第1项预测结果是7，第2项是2，等等。</p>
<h5 id="3．显示前10项预测结果-1"><a href="#3．显示前10项预测结果-1" class="headerlink" title="3．显示前10项预测结果"></a>3．显示前10项预测结果</h5><p>调用前一步创建的plot_images_labels_prediction函数显示前10项预测结果，传入测试数据图像、label及预测结果。</p>
<p><img src="Image00935.jpg" alt></p>
<p>执行后的预测结果如图18-10所示。</p>
<p><img src="Image00936.jpg" alt></p>
<p>图18-10</p>
<h3 id="18-9-隐藏层加入更多神经元"><a href="#18-9-隐藏层加入更多神经元" class="headerlink" title="18.9 隐藏层加入更多神经元"></a>18.9 隐藏层加入更多神经元</h3><p>为了增加多层感知器模型的准确率，在本节的范例中将隐藏层原本256个神经元改为1000。本节完整的程序代码可参考范例程序TensorFlow_Mnist_MLP_h1000.ipynb。</p>
<p>我们将使用下面的程序代码建立多层感知器模型。</p>
<p><img src="Image00937.jpg" alt> 修改隐藏层原本256个神经元为1000个神经元。</p>
<p><img src="Image00938.jpg" alt></p>
<p><img src="Image00939.jpg" alt> 预测准确率。</p>
<p><img src="Image00940.jpg" alt></p>
<p>以上执行结果的准确率是0.95，比上一节模型的准确率稍微提高了。</p>
<h3 id="18-10-建立包含两个隐藏层的多层感知器模型"><a href="#18-10-建立包含两个隐藏层的多层感知器模型" class="headerlink" title="18.10 建立包含两个隐藏层的多层感知器模型"></a>18.10 建立包含两个隐藏层的多层感知器模型</h3><p>为了更进一步增加多层感知器模型的准确率，在本节范例中将建立两个隐藏层。本节完整的程序代码可参考范例程序TensorFlow_Mnist_MLP_h1000-h1000.ipynb。</p>
<p>如图18-11所示，我们将使用下面的程序代码加入两个隐藏层。</p>
<p><img src="Image00941.jpg" alt></p>
<p>图18-11</p>
<p><img src="Image00942.jpg" alt> 建立多层感知器模型，包含两个隐藏层。</p>
<p><img src="Image00943.jpg" alt></p>
<p><img src="Image00944.jpg" alt> 预测准确率。</p>
<p><img src="Image00945.jpg" alt></p>
<p>以上执行结果的准确率是0.96，比上一节模型的准确率又稍微提高了。</p>
<h3 id="18-11-结论"><a href="#18-11-结论" class="headerlink" title="18.11 结论"></a>18.11 结论</h3><p>在本章中我们使用TensorFlow建立多层感知器模型，识别MNIST数据集中的手写数字，并且尝试将模型加深，以提高准确率。准确率大约为0.96。不过，多层感知器有极限，如果还要进一步提升准确率，就必须使用卷积神经网络。</p>
<h1 id="第19章-TensorFlow卷积神经网络识别手写数字"><a href="#第19章-TensorFlow卷积神经网络识别手写数字" class="headerlink" title="第19章 TensorFlow卷积神经网络识别手写数字"></a>第19章 TensorFlow卷积神经网络识别手写数字</h1><p>在前面的章节中，我们使用多元感知器识别MNIST数据集中的手写数字，准确率大约是0.96。在本章节中，我们将使用卷积神经网络（ConvolutionalNeural Network，CNN）来识别MNIST数据集中的手写数字，其分类精度接近0.99。</p>
<p>卷积神经网络是由一位计算机科学家Yann LeCun所提出的。他在机器学习、计算机视觉和计算神经科学等诸多领域都有不少贡献。</p>
<p>本章完整的程序代码可参考范例程序TensorFlow_Mnist_CNN.ipynb。有关范例程序的下载与安装可参考本书附录A中的“本书范例程序的下载与安装说明”。</p>
<h3 id="19-1-卷积神经网络简介"><a href="#19-1-卷积神经网络简介" class="headerlink" title="19.1 卷积神经网络简介"></a>19.1 卷积神经网络简介</h3><h5 id="1．卷积神经网络的介绍"><a href="#1．卷积神经网络的介绍" class="headerlink" title="1．卷积神经网络的介绍"></a>1．卷积神经网络的介绍</h5><p>卷积层的意义是，将原本一个图像经过卷积运算产生多个图像，就好像卷积起来。卷积神经网络可分为两大部分（见图19-1）：</p>
<p><img src="Image00946.jpg" alt></p>
<p>图19-1</p>
<ul>
<li>“卷积”与“缩减采样”提取图像的特征</li>
</ul>
<p>通过“第1次卷积”与“第1次缩减采样”、“第2次卷积”与“第2次缩减采样”的处理来提取图像的特征。通过以上这种方式可以提高识别的准确率。</p>
<ul>
<li>完全连接神经网络</li>
</ul>
<p>提取图像的特征后，reshape转换为一维的向量，送入由“平坦层”“隐藏层”“输出层”所组成的类神经网络进行处理。</p>
<p>本章在说明程序代码时，会比较Keras与TensorFlow建立模型、训练模型的不同，让读者更了解这两种程序设计模式的差异，可以对照第8章有关Keras程序代码的说明。</p>
<h5 id="2．建立卷积神经网络识别MNIST数据集的步骤"><a href="#2．建立卷积神经网络识别MNIST数据集的步骤" class="headerlink" title="2．建立卷积神经网络识别MNIST数据集的步骤"></a>2．建立卷积神经网络识别MNIST数据集的步骤</h5><p>建立卷积神经网络识别MNIST数据集的步骤如图19-2所示。</p>
<p><img src="Image00947.jpg" alt></p>
<p>图19-2</p>
<h3 id="19-2-进行数据预处理"><a href="#19-2-进行数据预处理" class="headerlink" title="19.2 进行数据预处理"></a>19.2 进行数据预处理</h3><p>使用下面的程序代码读取MNIST数据集，可参考第17章的说明。</p>
<p><img src="Image00948.jpg" alt></p>
<h3 id="19-3-建立共享函数"><a href="#19-3-建立共享函数" class="headerlink" title="19.3 建立共享函数"></a>19.3 建立共享函数</h3><p>为了便于后续建立模型，我们建立下面的共享函数。</p>
<h5 id="1．定义weight函数，用于建立权重张量"><a href="#1．定义weight函数，用于建立权重张量" class="headerlink" title="1．定义weight函数，用于建立权重张量"></a>1．定义weight函数，用于建立权重张量</h5><p>定义weight函数，输入参数shape，先以tf.truncated_normal随机方式初始化权重，然后使用tf.Variable建立TensorFlow变量。</p>
<p><img src="Image00949.jpg" alt></p>
<h5 id="2．定义bias函数，用于建立偏差张量"><a href="#2．定义bias函数，用于建立偏差张量" class="headerlink" title="2．定义bias函数，用于建立偏差张量"></a>2．定义bias函数，用于建立偏差张量</h5><p>定义bias函数，输入参数shape，先以tf.constant建立常数（输入参数：0.1与shape），然后使用tf.Variable建立TensorFlow张量变量，并且返回计算结果。</p>
<p><img src="Image00950.jpg" alt></p>
<h5 id="3．定义conv2d函数，用于进行卷积运算"><a href="#3．定义conv2d函数，用于进行卷积运算" class="headerlink" title="3．定义conv2d函数，用于进行卷积运算"></a>3．定义conv2d函数，用于进行卷积运算</h5><p>我们将使用下面的conv2d函数进行卷积运算，其效果相当于滤镜的功能。卷积运算的细节可参考第8章的说明。</p>
<p><img src="Image00951.jpg" alt></p>
<p>使用TensorFlow提供的tf.nn.conv2d函数进行卷积运算，并且返回运算结果，执行时需输入下列参数。</p>
<ul>
<li><strong>x是输入的图像：</strong> 后续我们会传入要处理的图像，必须是四维的张量。</li>
<li><strong>W是filter weight滤镜的权重：</strong> 后续我们会以随机方式产生filter weight并且传给此参数。</li>
<li><strong>strides：</strong> 滤镜的步长，设置为［1，1，1，1］，其格式是［1，stride，stride，1］，也就是滤镜每次移动时，从左到右、从上到下各一步。</li>
<li><strong>padding：</strong> 设置为’SAME’模式，此模式会在边界之外补0，在进行运算时，让输入与输出图像的大小相同。</li>
</ul>
<p>卷积运算的结果如图19-3所示。</p>
<p><img src="Image00952.jpg" alt></p>
<p>图19-3</p>
<h5 id="4．出具max-pool-2x2函数，用于建立池化层"><a href="#4．出具max-pool-2x2函数，用于建立池化层" class="headerlink" title="4．出具max_pool_2x2函数，用于建立池化层"></a>4．出具max_pool_2x2函数，用于建立池化层</h5><p>我们将创建max_pool_2x2函数，用于建立池化层进行图像的缩减采样。关于Max-Pool运算的细节，请参考第8章的说明。</p>
<p><img src="Image00953.jpg" alt></p>
<p>使用TensorFlow提供的tf.nn.max_pool函数建立池化层并且返回计算结果，执行时需输入下列参数。</p>
<ul>
<li><strong>x是输入的图像：</strong> 后续我们会传入要处理的图像，必须是四维的张量。</li>
<li><strong>ksize：</strong> 缩减采样窗口的大小，设置为［1，2，2，1］，其格式是［1，height，width，1］，也就是高度＝2、宽度＝2的窗口。</li>
<li><strong>strides：</strong> 缩减采样窗口的跨步，设置为［1，2，2，1］，其格式是［1，stride，stride，1］，也就是缩减采样窗口，从左到右、从上到下移动时的步长各两步。</li>
</ul>
<p>后续处理手写数字图像时，原本28×28的图像经过Max-Pool之后，缩小为14×14的图像，如图19-4所示。</p>
<p><img src="Image00954.jpg" alt></p>
<p>图19-4</p>
<h3 id="19-4-建立模型"><a href="#19-4-建立模型" class="headerlink" title="19.4 建立模型"></a>19.4 建立模型</h3><p>之前Keras建立卷积神经网络模型很简单，只需要建立Sequential模型，然后将各个神经网络层加入模型即可，但是，在TensorFlow中，必须自行设计每一层的张量运算。我们将使用下面的TensorFlow程序代码来建立卷积神经网络模型，如图19-5所示。</p>
<p><img src="Image00955.jpg" alt></p>
<p><strong>图</strong> 19-5</p>
<p>在下面的程序代码中，每一个层级都会加入“计算图”的层级名称。例如，输入层会加入withtf.name_scope（’Input_Layer’）的程序代码，其功能是设置输入层的名称为’Input_Layer’。</p>
<p>如果不设置“计算图”的层级名称，程序仍然可以正常运行，但是因为CNN的层级比较复杂而且层级很多，所以设置层级名称可以让程序代码比较易读。另外，后续当我们使用TensorBoard查看“计算图”时，可以很清楚地看到每一个层级，比较容易使用TensorBoard查看“计算图”，会在后面的章节介绍。</p>
<h5 id="1．输入层"><a href="#1．输入层" class="headerlink" title="1．输入层"></a>1．输入层</h5><p>使用下面的程序代码建立输入层。</p>
<p><img src="Image00956.jpg" alt></p>
<p>以上程序代码使用with tf.name_scope（’Input_Layer’）设置“计算图”输入层的名称，其余程序代码说明如下：</p>
<p>▶ 建立输入层（x）</p>
<p><img src="Image00957.jpg" alt></p>
<p>placeholder是TensorFlow“计算图”的输入，后续在训练时会传入数字图像数据。</p>
<p>建立tf.placeholder方法需设置下列参数。</p>
<ul>
<li><strong>“Float“：</strong> 数据类型是Float。</li>
<li><strong>shape＝［None，784］：</strong> 第一维设置为None，因为后续我们训练时会传送很多数字图像，项数不固定，所以设置为None。第二维设置为784，因为输入的数字图像像素是784。</li>
</ul>
<p>▶ x reshape为四维张量</p>
<p><img src="Image00958.jpg" alt></p>
<p>_x_ 原本是一维向量，因为后续要进行卷积与池化运算，所以必须转换为四维张量，说明如下。</p>
<ul>
<li><strong>第一维是－1：</strong> 因为后续训练时通过placeholder输入的项数不固定，所以设置为－1。</li>
<li><strong>第二、三维是28，28：</strong> 输入的数字图像大小是28×28。</li>
<li><strong>第四维是1：</strong> 因为是单色，所以设置为1，如果是彩色，就要设置为3。</li>
</ul>
<h5 id="2．建立卷积层1"><a href="#2．建立卷积层1" class="headerlink" title="2．建立卷积层1"></a>2．建立卷积层1</h5><p>卷积层的运算会以单个图像来产生多个图像，卷积运算后的效果类似于滤镜效果。这有助于提取输入的不同特征，例如边缘、线条和角等。</p>
<p>输入数字图像的大小为28×28，例如数字7的图像。卷积运算后会产生16个图像，卷积运算并不会改变图像大小，所以图像大小仍然是28×28。我们可以看到这些图像仍然像7，但是提取了不同的特征。</p>
<p>使用下面的程序代码建立卷积层1，计算图的层级名称是C1_Conv。</p>
<p><img src="Image00959.jpg" alt></p>
<p>以上程序代码的详细说明如下：</p>
<p>▶ 建立 _W_ 1权重</p>
<p><img src="Image00960.jpg" alt></p>
<p>使用之前建立的weight共享函数建立 _W_ 1权重，共有四维，说明如下。</p>
<ul>
<li><strong>第一、二维均是5：</strong> 代表滤镜（filter weight）的大小为5×5。</li>
<li><strong>第三维是1：</strong> 因为数字图像是单色的，所以设置为1，如果是彩色的，就要设置为3。</li>
<li><strong>第四维是16：</strong> 要产生16个图像。</li>
</ul>
<p>▶ 建立 _b_ 1偏差值</p>
<p><img src="Image00961.jpg" alt></p>
<p>使用之前建立的bias函数建立偏差值 _b_ 1。因为卷积层1要产生16个图像，所以输入参数shape＝［16］。</p>
<p>▶ 进行卷积运算</p>
<p><img src="Image00962.jpg" alt></p>
<p>使用之前建立的conv2d函数进行卷积计算，输入参数：x_image（要处理的图像）、 _W_ 1（滤镜的权重）、conv2d计算结果以及偏差值。</p>
<p>▶ ReLU激活函数</p>
<p><img src="Image00963.jpg" alt></p>
<p>以上卷积运算的结果再由ReLU激活函数转换，最后的结果是C1_Conv。</p>
<h5 id="3．建立池化层1"><a href="#3．建立池化层1" class="headerlink" title="3．建立池化层1"></a>3．建立池化层1</h5><p>池化层使用缩减采样会将图像由28×28缩小为14×14，不会改变图像数量（仍然是16）。</p>
<p>缩减采样会缩小图像，有下列好处。</p>
<p><strong>（1）减少所需处理的数据点：</strong> 减少后续运算所需的时间。</p>
<p><strong>（2）让图像位置差异变小：</strong> 例如手写数字7，位置上下左右可能不同，但是位置的不同可能会影响识别，减小图像的大小让数字的位置差异变小。</p>
<p><strong>（3）参数的数量和计算量下降：</strong> 这在一定程度上也控制了过度拟合。</p>
<p>下面的程序代码使用之前创建的max_pool_2x2函数传入卷积层C1_Conv进行缩减采样，建立池化层1，计算图的层级名称是C1_Pool。</p>
<p><img src="Image00964.jpg" alt></p>
<h5 id="4．建立卷积层2"><a href="#4．建立卷积层2" class="headerlink" title="4．建立卷积层2"></a>4．建立卷积层2</h5><p>第2次卷积运算将原本的16个图像转换为36个图像，卷积运算不会改变图像的大小，所以图像的大小仍然是14×14。使用下面的程序代码建立卷积层2，计算图的层级名称是C2_Conv。</p>
<p><img src="Image00965.jpg" alt></p>
<p>以上程序代码的详细说明如下：</p>
<p>▶ 建立 _W_ 2权重</p>
<p><img src="Image00966.jpg" alt></p>
<p>使用之前创建的weight共享函数建立 _W_ 2权重，共有四维，说明如下。</p>
<ul>
<li><strong>第一、二维均是5：</strong> 代表滤镜的大小为5×5。</li>
<li><strong>第三维是16：</strong> 因为卷积层1的图像数量是16个。</li>
<li><strong>第四维是36：</strong> 因为要将原本的16个图像转换为36个图像。</li>
</ul>
<p>▶ 建立偏差值向量</p>
<p><img src="Image00967.jpg" alt></p>
<p>使用之前创建的bias函数建立偏差值 _b_ 2。因为卷积层2要产生36个图像，所以输入参数shape＝［36］。</p>
<p>▶ 进行卷积运算</p>
<p><img src="Image00968.jpg" alt></p>
<p>使用之前创建的conv2d共享函数进行卷积计算，传入参数：C1_Pool（池化层1）、 _W_ 2（filter weight）以及偏差值向量 _b_ 2。</p>
<p>▶ ReLU激活函数</p>
<p><img src="Image00969.jpg" alt></p>
<p>最后由ReLU激活函数转换，ReLU会将原本是负数的点转换为0。</p>
<h5 id="5．建立池化层2"><a href="#5．建立池化层2" class="headerlink" title="5．建立池化层2"></a>5．建立池化层2</h5><p>下面的程序代码使用之前创建的max_pool_2x2函数传入C2_Conv（卷积层2）进行缩减采样，建立池化层2，计算图的层级名称是C2_Pool。</p>
<p><img src="Image00970.jpg" alt></p>
<h5 id="6．建立平坦层"><a href="#6．建立平坦层" class="headerlink" title="6．建立平坦层"></a>6．建立平坦层</h5><p>平坦层可以将池化层2的36个7×7的图像转换为一维的向量，长度是36×7×7＝1764，也就是1764个浮点数，作为神经元的输入。使用下面的程序代码建立平坦层，计算图的层级名称是D_Flat。</p>
<p><img src="Image00971.jpg" alt></p>
<p>以上程序代码使用tf.reshape传入下列参数。</p>
<ul>
<li><strong>C2</strong> _ <strong>Pool:</strong> 此参数设置为要进行reshape的张量。</li>
<li><strong>［-1, 1764］:</strong></li>
</ul>
<p>■第一维是－1，因为后续会传入不限定项数的训练数据——数字图像。</p>
<p>■第二维是1764，因为C2_Pool是36个7×7的图像，要转换为一维的向量，长度是36×7×7＝1764。</p>
<h5 id="7．建立隐藏层"><a href="#7．建立隐藏层" class="headerlink" title="7．建立隐藏层"></a>7．建立隐藏层</h5><p>使用下面的程序代码建立隐藏层，计算图的层级名称是D_Hidden_Layer。</p>
<p><img src="Image00972.jpg" alt></p>
<p>以上程序代码详细说明如下：</p>
<p>▶ 建立 _W_ 3权重</p>
<p><img src="Image00973.jpg" alt></p>
<p>使用weight共享函数建立 _W_ 3权重，输入shape参数，说明如下。</p>
<ul>
<li><strong>第一维是1764，</strong> 因为上一层D_Flat有1764个神经元。</li>
<li><strong>第二维是128，</strong> 因为要建立的隐藏层D_Hidden有128个神经元。</li>
</ul>
<p>▶ 建立偏差值向量</p>
<p><img src="Image00974.jpg" alt></p>
<p>使用之前创建的bias函数建立偏差值 _b_ 3。因为要建立的隐藏层D_Hidden有128个神经元，所以输入参数shape＝［128］。</p>
<p>▶ 建立隐藏层（D_Hidden_Layer）</p>
<p><img src="Image00975.jpg" alt></p>
<p>建立隐藏层的公式如下：</p>
<p><img src="Image00976.jpg" alt></p>
<p>先使用tf.matmul将D_Flat与W3矩阵相乘，再加上偏差值向量，最后使用tf.nn.relu激活函数转换后，就可以得到隐藏层D_Hidden。</p>
<p>▶ 加入Dropout避免过度拟合</p>
<p><img src="Image00977.jpg" alt></p>
<p>tf.nn.dropout的功能是，每次训练迭代时都会随机地在神经网络中放弃一些神经元，以避免过度拟合。输入的参数如下。</p>
<ul>
<li><strong>D_Hidden：</strong> 要执行dropout的神经网络层。</li>
<li><strong>keep</strong> _ <strong>prob＝0.8：</strong> 设置要保留的神经元比率，0.8代表要保留80%的神经元，随机去掉20%的神经元。</li>
</ul>
<h5 id="8．建立输出层"><a href="#8．建立输出层" class="headerlink" title="8．建立输出层"></a>8．建立输出层</h5><p>输出层共有10个神经元，对应数字0～9。建立隐藏层的公式如下：</p>
<p><img src="Image00978.jpg" alt></p>
<p>下面的程序代码建立隐藏层，计算图的层级名称是Output_Layer。</p>
<p><img src="Image00979.jpg" alt></p>
<p>以上程序代码的详细说明如下：</p>
<p>▶ 建立 _W_ 4权重</p>
<p><img src="Image00980.jpg" alt></p>
<p>使用weight共享函数建立 _W_ 4权重，输入shape参数，说明如下。</p>
<ul>
<li><strong>第一维是128，</strong> 因为上一层D_Hidden有128个神经元。</li>
<li><strong>第二维是10，</strong> 因为要建立的输出层（Output_Layer）有10个神经元。</li>
</ul>
<p>▶ 建立偏差值向量</p>
<p><img src="Image00981.jpg" alt></p>
<p>使用之前创建的bias函数建立偏差值 _b_ 4。因为要建立的输出层（Output_Layer）有10个神经元，所以输入参数shape＝［10］。</p>
<p>▶ 建立输出层（y_predict）</p>
<p><img src="Image00982.jpg" alt></p>
<p>先使用tf.matmul将D_Hidden_Dropout与W4矩阵相乘，再加上偏差值向量 _b_4，最后使用tf.nn.softmax激活函数转换后，就可以得到输出层y_predict。</p>
<h3 id="19-5-定义训练方式"><a href="#19-5-定义训练方式" class="headerlink" title="19.5 定义训练方式"></a>19.5 定义训练方式</h3><p>在之前的步骤中已经建立了卷积神经网络模型。接下来，使用反向传播算法训练多层感知器模型。</p>
<p>下面的程序代码与第18章的程序代码完全相同，详细说明可参考第18章。</p>
<p><img src="Image00983.jpg" alt></p>
<h3 id="19-6-定义评估模型准确率的方式"><a href="#19-6-定义评估模型准确率的方式" class="headerlink" title="19.6 定义评估模型准确率的方式"></a>19.6 定义评估模型准确率的方式</h3><p>当使用上一节的方法训练模型完成某一阶段后，我们希望能够评估模型的准确率。</p>
<p>下面的程序代码与第18章的程序代码完全相同，详细说明可参考第18章。</p>
<p><img src="Image00984.jpg" alt></p>
<h3 id="19-7-进行训练"><a href="#19-7-进行训练" class="headerlink" title="19.7 进行训练"></a>19.7 进行训练</h3><p>我们将使用反向传播算法训练，训练数据共55 000项，分为每一批次100项，要将所有数据训练完毕需执行550批次（55000/100＝550批次），当所有数据训练完毕后，完成一个训练周期。</p>
<p>我们将执行30个训练周期，尽量使误差降低，并且尽可能提高准确率。</p>
<p>下面的程序代码与第18章的程序代码完全相同，详细说明可参考第18章。</p>
<p><img src="Image00985.jpg" alt> 定义训练参数。</p>
<p><img src="Image00986.jpg" alt></p>
<p><img src="Image00987.jpg" alt> 进行训练。</p>
<p><img src="Image00988.jpg" alt></p>
<p>结果如图19-6所示。</p>
<p><img src="Image00989.jpg" alt></p>
<p>图19-6</p>
<p>从训练结果可知准确率达到了0.9864。</p>
<p><img src="Image00990.jpg" alt> 画出误差执行的结果，如图19-7所示。</p>
<p><img src="Image00991.jpg" alt></p>
<p>图19-7</p>
<p><img src="Image00992.jpg" alt> 画出准确率执行的结果，如图19-8所示。</p>
<p><img src="Image00993.jpg" alt></p>
<p>图19-8</p>
<h3 id="19-8-评估模型准确率"><a href="#19-8-评估模型准确率" class="headerlink" title="19.8 评估模型准确率"></a>19.8 评估模型准确率</h3><p>之前我们已经完成训练，现在要使用test测试数据集评估模型的准确率。评估模型的准确率与第18章的程序代码完全相同，可参考第18章的说明。以下仅列出执行的结果。</p>
<p><img src="Image00994.jpg" alt></p>
<h3 id="19-9-进行预测"><a href="#19-9-进行预测" class="headerlink" title="19.9 进行预测"></a>19.9 进行预测</h3><p>在之前的步骤中我们建立了模型，并且完成了模型的训练，准确率达到还可以接受的0.98，接下来将使用此模型进行预测。下面的程序代码与第18章的程序代码完全相同，详细说明可参考第18章。</p>
<h5 id="1．执行预测-3"><a href="#1．执行预测-3" class="headerlink" title="1．执行预测"></a>1．执行预测</h5><p>我们可以用下面的指令执行预测。</p>
<p><img src="Image00995.jpg" alt></p>
<p>这段程序代码使用了sess.run（tf.argmax（y_predict，1），因为y_predict是One-HotEncoding，所以必须先使用tf.argmax进行转换，再进行预测并使用feed_dict传入。</p>
<ul>
<li><strong>x：mnist.test.images：</strong> 测试数据的数字图像。</li>
</ul>
<h5 id="2．预测结果-3"><a href="#2．预测结果-3" class="headerlink" title="2．预测结果"></a>2．预测结果</h5><p>我们可以用下列指令来查看预测结果的前10项数据。</p>
<p><img src="Image00996.jpg" alt></p>
<p>可以看到第1项预测结果是7，第2项是2……</p>
<h5 id="3．显示前10项预测结果-2"><a href="#3．显示前10项预测结果-2" class="headerlink" title="3．显示前10项预测结果"></a>3．显示前10项预测结果</h5><p>在第18章中创建的show_images_labels_prediction函数中显示前10项预测结果，传入测试数据图像、label及预测结果。</p>
<p><img src="Image00997.jpg" alt></p>
<p>执行后预测结果如图19-9所示。</p>
<p><img src="Image00998.jpg" alt></p>
<p>图19-9</p>
<h3 id="19-10-TensorBoard"><a href="#19-10-TensorBoard" class="headerlink" title="19.10 TensorBoard"></a>19.10 TensorBoard</h3><p>TensorFlow提供了TensorBoard，可以让我们以可视化的方式来查看所建立的“计算流程图”，我们可按照下列步骤来查看卷积神经网络的“计算图”。</p>
<p>首先，使用程序代码将要显示在TensorBoard的计算图写入log文件。</p>
<p><img src="Image00999.jpg" alt></p>
<h5 id="1．在Windows中启动TensorBoard"><a href="#1．在Windows中启动TensorBoard" class="headerlink" title="1．在Windows中启动TensorBoard"></a>1．在Windows中启动TensorBoard</h5><p>如果读者使用的是Windows系统，就按照下列步骤启动TensorBoard。启动“命令提示符”程序，并且输入下列命令。</p>
<p>▶ 先确认log目录文件是否已经产生</p>
<p>在Windows的“命令提示符”程序中使用dir显示目录。</p>
<p><img src="Image01000.jpg" alt></p>
<p>▶ 启用TensorFlow的Anaconda虚拟环境</p>
<p><img src="Image01001.jpg" alt></p>
<p>▶ 启动TensorBoard</p>
<p>启动TensorBoard指令需指定log文件目录，TensorBoard会读取此目录，并显示在TensorBoard上。</p>
<p><img src="Image01002.jpg" alt></p>
<p>执行后屏幕显示界面如图19-10所示。</p>
<p><img src="Image01003.jpg" alt></p>
<p>图19-10</p>
<p>以上执行结果中的<a href="http://192.168.56.1：6006是笔者个人计算机的内部IP，读者的IP可能不相同。读者也可以用浏览器输入此网址：http://localhost：6006／，localhost代表本机，就是用户当前使用的计算机。" target="_blank" rel="noopener">http://192.168.56.1：6006是笔者个人计算机的内部IP，读者的IP可能不相同。读者也可以用浏览器输入此网址：http://localhost：6006／，localhost代表本机，就是用户当前使用的计算机。</a></p>
<h5 id="2．启动TensorBoard"><a href="#2．启动TensorBoard" class="headerlink" title="2．启动TensorBoard"></a>2．启动TensorBoard</h5><p>启动TensorBoard的指令如下，需指定log文件目录，TensorBoard会读取此目录，并显示在TensorBoard上。</p>
<p><img src="Image01004.jpg" alt></p>
<p>执行后屏幕显示界面如下：</p>
<p><img src="Image01005.jpg" alt></p>
<h5 id="3．在TensorBoard查看“计算图”"><a href="#3．在TensorBoard查看“计算图”" class="headerlink" title="3．在TensorBoard查看“计算图”"></a>3．在TensorBoard查看“计算图”</h5><p>启动TensorBoard之后，再启动浏览器，并输入网址：<a href="http://localhost：6006／。" target="_blank" rel="noopener">http://localhost：6006／。</a></p>
<p>输入网址后就会出现TensorBoard界面，在菜单中选择GRAPHS之后即可看到“计算图”，如图19-11所示。</p>
<p><img src="Image01006.jpg" alt></p>
<p>图19-11</p>
<p>从图19-11中可以清楚地看到卷积神经网络的每一个层级，可以单击相应层级来查看详细的内容。</p>
<h3 id="19-11-结论"><a href="#19-11-结论" class="headerlink" title="19.11 结论"></a>19.11 结论</h3><p>我们使用卷积神经网络来识别MNIST数据集中的手写数字，其分类精度接近0.99。不过，卷积神经网络训练需要很多时间，下一章我们将介绍如何使用GPU来进行训练，这样可以减少训练所需的时间。</p>
<h1 id="第20章-TensorFlow-GPU版本的安装"><a href="#第20章-TensorFlow-GPU版本的安装" class="headerlink" title="第20章 TensorFlow GPU版本的安装"></a>第20章 TensorFlow GPU版本的安装</h1><p>近年来深度学习和人工智能技术发展持续加速，很重要的因素是GPU提供了强大的并行计算架构，可让深度学习的训练比普通CPU快数十倍。本章将特别介绍GPU的安装与应用，读者只需要有NVIDIA显示适配器（即显卡），然后安装CUDA、cuDNN、TensorFlowGPU版本与Keras，就可以使用GPU大幅加快深度学习的训练。</p>
<p>TensorFlow主要是通过NVIDIA提供的CUDA和cuDNN来存取GPU的，而Keras是TensorFlow的高级API，所以必须通过TensorFlow存取GPU，整理如图20-1所示。</p>
<p><img src="Image01007.jpg" alt></p>
<p>图20-1 GPU具有数千个核心</p>
<p>CUDA是由NVIDIA所推出的整合技术，统一计算设备架构（Compute Unified DeviceArchitecture，CUDA），是NVIDIA的通用并行计算架构，就是运用图形处理单元（GPU）的强大处理能力大幅增加计算性能。NVIDIA已售出数百万颗CUDAGPU，应用于各种领域，如图像处理、视频处理、医学诊断等。</p>
<p>cuDNN（CUDA Deep Neural NetworkLibrary）是NVIDIA深度学习SDK的一部分，是GPU的深度学习程序库。cuDNN能为深度学习提供高性能神经网络层级，例如卷积、池化和激活层等。</p>
<p>我们可以从NVIDIA官方网站下载CUDA和cuDNN这两个软件。</p>
<p>Keras与TensorFlow GPU在Windows系统中的安装步骤如图20-2所示。</p>
<p><img src="Image01008.jpg" alt></p>
<p>图20-2</p>
<h3 id="20-1-确认显卡是否支持CUDA"><a href="#20-1-确认显卡是否支持CUDA" class="headerlink" title="20.1 确认显卡是否支持CUDA"></a>20.1 确认显卡是否支持CUDA</h3><p>确认现有的或预定要采购的独立显卡是否支持CUDA，可按照下列步骤操作。</p>
<h5 id="1．查看支持CUDA的显卡"><a href="#1．查看支持CUDA的显卡" class="headerlink" title="1．查看支持CUDA的显卡"></a>1．查看支持CUDA的显卡</h5><p>可到网站<a href="https://developer.nvidia.com/cuda-gpus查看支持CUDA的显卡，如图20-3所示。" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-gpus查看支持CUDA的显卡，如图20-3所示。</a></p>
<p><img src="Image01009.jpg" alt></p>
<p>图20-3</p>
<h5 id="2．查看系统信息（见图20-4）"><a href="#2．查看系统信息（见图20-4）" class="headerlink" title="2．查看系统信息（见图20-4）"></a>2．查看系统信息（见图20-4）</h5><p><img src="Image01010.jpg" alt></p>
<p>图20-4</p>
<h5 id="3．查看显卡（见图20-5）"><a href="#3．查看显卡（见图20-5）" class="headerlink" title="3．查看显卡（见图20-5）"></a>3．查看显卡（见图20-5）</h5><p><img src="Image01011.jpg" alt></p>
<p>图20-5</p>
<p>有了显卡名称就可以查看图20-3所介绍的网页，对照一下，看看是否支持CUDA。</p>
<h3 id="20-2-安装CUDA"><a href="#20-2-安装CUDA" class="headerlink" title="20.2 安装CUDA"></a>20.2 安装CUDA</h3><p>确认系统已经安装了支持CUDA的显卡之后，就可以安装CUDA了，步骤如下。</p>
<p><img src="Image01012.jpg" alt> 下载并安装CUDA</p>
<p>到NVIDIA网站下载CUDA：<a href="https://developer.nvidia.com/cuda-downloads。" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads。</a></p>
<p>安装步骤如图20-6所示。</p>
<p><img src="Image01013.jpg" alt></p>
<p>图20-6</p>
<p>Installer Type安装有以下两种方式可选。</p>
<ul>
<li><strong>exe（network）：</strong> 下载时文件比较小，后续执行安装时再下载其余部分。</li>
<li><strong>exe（local）：</strong> 下载时完整下载，后续执行安装时就不需要下载了。</li>
</ul>
<p><img src="Image01014.jpg" alt> 设置解压缩安装程序的暂存目录。</p>
<p>因为之前在Installer Type中选择了exe（network），所以安装过程需要下载与解压缩，必须设置解压缩目录，如图20-7所示。</p>
<p><img src="Image01015.jpg" alt></p>
<p>图20-7</p>
<p><img src="Image01016.jpg" alt> 同意协议并继续，如图20-8所示。</p>
<p><img src="Image01017.jpg" alt></p>
<p>图20-8</p>
<p><img src="Image01018.jpg" alt> 选择精简安装选项，如图20-9所示。</p>
<p><img src="Image01019.jpg" alt></p>
<p>图20-9</p>
<p><img src="Image01020.jpg" alt> 警告未安装Visual Studio。</p>
<p>CUDA可以用Visual Studio开发。图20-10所示的界面警告未安装VisualStudio。不过后续我们是使用Python来开发的，所以不需要事先安装Visual Studio。</p>
<p><img src="Image01021.jpg" alt></p>
<p>图20-10</p>
<p><img src="Image01022.jpg" alt> 下载CUDA界面。</p>
<p>因为之前在Installer Type中选择了exe（network），所以下载会比较久一些，下载过程如图20-11所示。</p>
<p><img src="Image01023.jpg" alt></p>
<p>图20-11</p>
<p><img src="Image01024.jpg" alt> 确认是否要安装此设备软件，如图20-12所示。</p>
<p><img src="Image01025.jpg" alt></p>
<p>图20-12</p>
<p><img src="Image01026.jpg" alt> 确认安装，如图20-13所示。</p>
<p><img src="Image01027.jpg" alt></p>
<p>图20-13</p>
<p><img src="Image01028.jpg" alt> 安装完成，如图20-14所示。</p>
<p><img src="Image01029.jpg" alt></p>
<p>图20-14</p>
<h3 id="20-3-安装cuDNN"><a href="#20-3-安装cuDNN" class="headerlink" title="20.3 安装cuDNN"></a>20.3 安装cuDNN</h3><p>接下来安装cuDNN，步骤如下。</p>
<p><img src="Image01030.jpg" alt> 下载cuDNN。</p>
<p>在浏览器中输入NVIDIA的网址（<a href="https://developer.nvidia.com/cudnn），出现如图20-15所示的页面。" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn），出现如图20-15所示的页面。</a></p>
<p><img src="Image01031.jpg" alt></p>
<p>图20-15</p>
<p><img src="Image01032.jpg" alt> 加入会员。</p>
<p>下载cuDNN必须先成为加速计算开发者计划的会员，如图20-16所示。</p>
<p><img src="Image01033.jpg" alt></p>
<p>图20-16</p>
<p><img src="Image01034.jpg" alt> 进入下载页面。</p>
<p>加入会员并且登录后，进入下载页面，如图20-17所示。</p>
<p><img src="Image01035.jpg" alt></p>
<p>图20-17</p>
<p><img src="Image01036.jpg" alt> 查看下载后的文件。</p>
<p>下载后的文件cudnn-8.0-windows10-x64-v5.1.zip是一个ZIP压缩文件，在Windows 10中可直接打开，如图20-18所示。</p>
<p><img src="Image01037.jpg" alt></p>
<p>图20-18</p>
<p><img src="Image01038.jpg" alt> 复制到其他目录。</p>
<p>打开ZIP压缩文件后的内容如图20-19所示，我们可以看到一个CUDA目录。</p>
<p><img src="Image01039.jpg" alt></p>
<p>图20-19</p>
<p><img src="Image01040.jpg" alt> 创建tools目录，并且粘贴之前复制的文件。</p>
<p>在本书中我们建立C：\tools目录（见图20-20），用于存储cuda目录，当然读者也可以放在其他目录下。</p>
<p><img src="Image01041.jpg" alt></p>
<p>图20-20</p>
<p><img src="Image01042.jpg" alt> 已复制／粘贴到tools目录，如图20-21所示。</p>
<p><img src="Image01043.jpg" alt></p>
<p>图20-21</p>
<p><img src="Image01044.jpg" alt> 查看cudnn64_5.dll。</p>
<p>复制／粘贴后，在C：\tools\cuda\bin目录可以看到cudnn64_5.dll，如图20-22所示。这是动态链接程序库，其他程序会通过此链接库来使用cuDNN的功能。</p>
<p><img src="Image01045.jpg" alt></p>
<p>图20-22</p>
<h3 id="20-4-将cudnn64-5-dll存放的位置加入Path环境变量"><a href="#20-4-将cudnn64-5-dll存放的位置加入Path环境变量" class="headerlink" title="20.4 将cudnn64_5.dll存放的位置加入Path环境变量"></a>20.4 将cudnn64_5.dll存放的位置加入Path环境变量</h3><p>为了让Windows系统知道所安装cuDNN的目录，必须设置Path环境变量，这样其他程序才可以通过这个设置来存取cudnn64_5.dll。</p>
<p><img src="Image01046.jpg" alt> 编辑系统环境变量，如图20-23所示。</p>
<p><img src="Image01047.jpg" alt></p>
<p>图20-23</p>
<p><img src="Image01048.jpg" alt> 单击“环境变量”按钮，如图20-24所示。</p>
<p><img src="Image01049.jpg" alt></p>
<p>图20-24</p>
<p><img src="Image01050.jpg" alt> 编辑环境变量，如图20-25所示。</p>
<p><img src="Image01051.jpg" alt></p>
<p>图20-25</p>
<p><img src="Image01052.jpg" alt> 编辑用户变量。</p>
<p>在Path环境变量中加入“C：\tools\cuda\bin；”，这是20.3节cudnn64_5.dll的安装目录，如图20-26所示。</p>
<p><img src="Image01053.jpg" alt></p>
<p>图20-26</p>
<h3 id="20-5-在Anaconda建立TensorFlow-GPU虚拟环境"><a href="#20-5-在Anaconda建立TensorFlow-GPU虚拟环境" class="headerlink" title="20.5 在Anaconda建立TensorFlow GPU虚拟环境"></a>20.5 在Anaconda建立TensorFlow GPU虚拟环境</h3><p>本书前面介绍了如何使用CPU与GPU来执行TensorFlow与Keras。然而CPU与GPU所需安装的TensorFlow版本不一样，所以我们要分别建立CPU与GPU的虚拟环境，以便在下一章测试CPU与GPU的执行性能。</p>
<p>在第4章中，我们已经介绍了如何在Anaconda中建立TensorFlow虚拟环境，并且安装了TensorFlow的CPU版本，本章将在Anaconda中建立TensorFlowGPU虚拟环境，并且安装TensorFlowGPU版本以及Keras。如果读者还没有在Windows中安装Anaconda，可先按照第4章的说明安装Anaconda。</p>
<p><img src="Image01054.jpg" alt> 重新启动“命令提示符”程序，并且切换到工作目录。</p>
<p>在“命令提示符”窗口中输入下列命令，以切换到工作目录：</p>
<p><img src="Image01055.jpg" alt></p>
<p>执行后屏幕显示界面如图20-27所示。</p>
<p><img src="Image01056.jpg" alt></p>
<p>图20-27</p>
<p><img src="Image01057.jpg" alt> 在Anaconda建立TensorFlow GPU虚拟环境。</p>
<p>现在我们要在Anaconda建立TensorFlow GPU虚拟环境，在此虚拟环境可以安装TensorFlow GPU版本，Python版本是3.5。</p>
<p><img src="Image01058.jpg" alt></p>
<p>以上命令说明见表20-1。</p>
<p>表20-1 命令说明</p>
<p><img src="Image01059.jpg" alt></p>
<p>执行后屏幕显示界面如图20-28所示。</p>
<p><img src="Image01060.jpg" alt></p>
<p>图20-28</p>
<p>按下Y键之后，就会开始安装Anaconda虚拟环境，并会安装软件包。</p>
<p>安装完成后的屏幕显示界面如图20-29所示。</p>
<p><img src="Image01061.jpg" alt></p>
<p>图20-29</p>
<p><img src="Image01062.jpg" alt> 启用TensorFlow GPU虚拟环境。</p>
<p>在“命令提示符”窗口输入下列命令。</p>
<p>▶ 启动Anaconda虚拟环境</p>
<p><img src="Image01063.jpg" alt></p>
<p>执行后屏幕显示界面如图20-30所示。</p>
<p><img src="Image01064.jpg" alt></p>
<p>图20-30</p>
<h3 id="20-6-安装TensorFlow-GPU版本"><a href="#20-6-安装TensorFlow-GPU版本" class="headerlink" title="20.6 安装TensorFlow GPU版本"></a>20.6 安装TensorFlow GPU版本</h3><p>接下来，在TensorFlow GPU虚拟环境中安装TensorFlow GPU版本。</p>
<p>在“命令提示符”窗口中输入下列命令。</p>
<p>▶ 安装TensorFlow CPU版本</p>
<p><img src="Image01065.jpg" alt></p>
<p>执行后屏幕显示界面如图20-31所示。</p>
<p><img src="Image01066.jpg" alt></p>
<p>图20-31</p>
<h3 id="20-7-安装Keras"><a href="#20-7-安装Keras" class="headerlink" title="20.7 安装Keras"></a>20.7 安装Keras</h3><p>在“命令提示符”窗口中输入下列命令来安装Keras：</p>
<p><img src="Image01067.jpg" alt></p>
<p>执行后屏幕显示界面如图20-32所示。</p>
<p><img src="Image01068.jpg" alt></p>
<p>图20-32</p>
<h3 id="20-8-结论"><a href="#20-8-结论" class="headerlink" title="20.8 结论"></a>20.8 结论</h3><p>在本章我们介绍了如何安装CUDA、cuDNN，建立了TensorFlow GPU虚拟环境，并且在虚拟环境下安装了TensorFlowGPU版本与Keras，下一章将在TensorFlow GPU虚拟环境中测试GPU的强大功能。</p>
<h1 id="第21章-使用GPU加快TensorFlow与Keras训练"><a href="#第21章-使用GPU加快TensorFlow与Keras训练" class="headerlink" title="第21章 使用GPU加快TensorFlow与Keras训练"></a>第21章 使用GPU加快TensorFlow与Keras训练</h1><p>本章我们将在TensorFlow GPU虚拟环境中测试GPU的强大功能，并且分别测试TensorFlow与Keras在CPU与GPU中执行速度的差异。</p>
<p>如果读者还没有安装TensorFlowGPU版本与Keras，就按照第20章的说明安装。本章完整的程序代码可参考范例程序Test_GPU.ipynb。本书范例程序的下载与安装说明可参考附录A。</p>
<h3 id="21-1-启动TensorFlow-GPU环境"><a href="#21-1-启动TensorFlow-GPU环境" class="headerlink" title="21.1 启动TensorFlow GPU环境"></a>21.1 启动TensorFlow GPU环境</h3><h5 id="1．启动TensorFlow-GPU"><a href="#1．启动TensorFlow-GPU" class="headerlink" title="1．启动TensorFlow GPU"></a>1．启动TensorFlow GPU</h5><p>▶ 切换工作目录</p>
<p><img src="Image01069.jpg" alt></p>
<p>▶ 启动TensorFlow GPU环境</p>
<p><img src="Image01070.jpg" alt></p>
<p>▶ 启动jupyter notebook</p>
<p><img src="Image01071.jpg" alt></p>
<p>执行后屏幕显示界面如图21-1所示。</p>
<p><img src="Image01072.jpg" alt></p>
<p>图21-1</p>
<p>执行后开启Jupyter，如图21-2所示。</p>
<p><img src="Image01073.jpg" alt></p>
<p>图21-2</p>
<p>参考第4章的说明建立新的Notebook。</p>
<h5 id="2．导入tensorflow模块"><a href="#2．导入tensorflow模块" class="headerlink" title="2．导入tensorflow模块"></a>2．导入tensorflow模块</h5><p>在jupyter notebook中输入下列程序代码。</p>
<p>▶ 导入tensorflow模块</p>
<p><img src="Image01074.jpg" alt></p>
<p>以上导入tensorflow模块的命令执行后，在“命令提示符”中的jupyternotebook界面可以同步看到TensorFlow自动打开了很多dll文件，这些dll是CUDA链接库，如图21-3所示。如果出现加载dll的错误信息，就代表之前在20.4节中设置的环境变量可能有错误。</p>
<p><img src="Image01075.jpg" alt></p>
<p>图21-3</p>
<h5 id="3．默认以GPU执行"><a href="#3．默认以GPU执行" class="headerlink" title="3．默认以GPU执行"></a>3．默认以GPU执行</h5><p>▶ 建立计算图</p>
<p>下面的程序主要是建立两个矩阵：W与X，矩阵的大小由size变量来设置，目前设置为size＝500，然后进行矩阵乘法matmul与矩阵元素的加总。</p>
<p><img src="Image01076.jpg" alt></p>
<p>程序代码的说明见表21-1。</p>
<p>表21-1 程序代码说明</p>
<p><img src="Image01077.jpg" alt></p>
<p>▶ 执行计算图</p>
<p><img src="Image01078.jpg" alt></p>
<p>TensorFlow会自动检查计算机中是否已安装了GPU，因为理论上GPU执行得比较快，TensorFlow默认会使用GPU。当我们执行上面的命令时，在“命令提示符”中的jupyternotebook界面会同步看到建立TensorFlow设备，／gpu：0使用GeForce GT 720显卡，如图21-4所示。</p>
<p><img src="Image01079.jpg" alt></p>
<p>图21-4</p>
<h5 id="4．设置Session的config参数，显示更多GPU设备信息"><a href="#4．设置Session的config参数，显示更多GPU设备信息" class="headerlink" title="4．设置Session的config参数，显示更多GPU设备信息"></a>4．设置Session的config参数，显示更多GPU设备信息</h5><p>在之前的步骤中显示的GPU设备相关信息比较少，我们可以用下列指令来显示更多设备相关信息。</p>
<p><img src="Image01080.jpg" alt></p>
<p>程序代码的说明如下：</p>
<p>▶ 建立Session的配置设置</p>
<p>使用tf.ConfigProto建立session的配置设置tfconfig，传入参数log_device_placement设置为True，代表要显示设备的相关信息。</p>
<p><img src="Image01081.jpg" alt></p>
<p>▶ 打开Session时传入配置设置</p>
<p>打开Session时传入之前建立的Session的配置tfconfig：</p>
<p><img src="Image01082.jpg" alt></p>
<p>当我们执行以上指令时，在“命令提示符”中的jupyter notebook界面会同步显示使用设备／gpu：0进行计算，如图21-5所示。</p>
<p><img src="Image01083.jpg" alt></p>
<p>图21-5</p>
<h5 id="5．以with-tf-device来指定使用CPU或GPU设备"><a href="#5．以with-tf-device来指定使用CPU或GPU设备" class="headerlink" title="5．以with tf.device来指定使用CPU或GPU设备"></a>5．以with tf.device来指定使用CPU或GPU设备</h5><p>之前的步骤TensorFlow默认使用／gpu：0。但是在某些情况下，我们希望能指定使用的计算设备，此时可以使用withtf.device语句来指定某一段程序使用哪一个计算设备，例如：</p>
<ul>
<li>计算机中有多个GPU，我们可以指定要使用哪一个具体的GPU。</li>
</ul>
<p>■ with tf.device（“／gpu：0“）：使用第0个GPU。</p>
<p>■ with tf.device（“／gpu：1“）：使用第1个GPU。</p>
<ul>
<li>指定用CPU来执行。</li>
</ul>
<p>■ with tf.device（“／cpu：0“）：使用第0个CPU。</p>
<h5 id="6．以with-tf-device来指定使用CPU"><a href="#6．以with-tf-device来指定使用CPU" class="headerlink" title="6．以with tf.device来指定使用CPU"></a>6．以with tf.device来指定使用CPU</h5><p>指定用CPU进行计算的程序代码。</p>
<p><img src="Image01084.jpg" alt></p>
<p>以上命令执行后，在“命令提示符”中的jupyter notebook界面会同步显示使用设备／cpu：0进行计算，如图21-6所示。</p>
<p><img src="Image01085.jpg" alt></p>
<p>图21-6</p>
<h5 id="7．以with-tf-device来指定使用GPU"><a href="#7．以with-tf-device来指定使用GPU" class="headerlink" title="7．以with tf.device来指定使用GPU"></a>7．以with tf.device来指定使用GPU</h5><p>指定以GPU进行计算的程序代码。</p>
<p><img src="Image01086.jpg" alt></p>
<p>以上命令执行后，在“命令提示符”中的jupyter notebook界面会同步显示使用设备／gpu：0进行计算，如图21-7所示。</p>
<p><img src="Image01087.jpg" alt></p>
<p>图21-7</p>
<h3 id="21-2-测试GPU与CPU执行性能"><a href="#21-2-测试GPU与CPU执行性能" class="headerlink" title="21.2 测试GPU与CPU执行性能"></a>21.2 测试GPU与CPU执行性能</h3><p>我们将创建performanceTest，用于测试GPU与CPU的执行性能。</p>
<h5 id="1．创建performanceTest函数"><a href="#1．创建performanceTest函数" class="headerlink" title="1．创建performanceTest函数"></a>1．创建performanceTest函数</h5><p><img src="Image01088.jpg" alt></p>
<p>程序代码的说明如下：</p>
<p>▶ 定义performanceTest函数需传入参数：</p>
<ul>
<li><strong>device_name</strong> 设置要执行计算的设备，例如／cpu：0或／gpu：0。</li>
<li><strong>size</strong> 设置要建立矩阵的大小。</li>
</ul>
<p><img src="Image01089.jpg" alt></p>
<p>▶ 使用with tf.device语句指定要使用的计算设备</p>
<p>使用with tf.device传入device_name参数，指定下列程序块中的程序代码要使用的计算设备。</p>
<p><img src="Image01090.jpg" alt></p>
<p>▶ 记录开始运行时间</p>
<p><img src="Image01091.jpg" alt></p>
<p>▶ 执行计算图</p>
<p><img src="Image01092.jpg" alt></p>
<p>▶ 计算运行时间</p>
<p>将当前的时间减去开始运行时间就是执行所需的时间。</p>
<p><img src="Image01093.jpg" alt></p>
<p>▶ 返回运行时间</p>
<p><img src="Image01094.jpg" alt></p>
<h5 id="2．执行performanceTest"><a href="#2．执行performanceTest" class="headerlink" title="2．执行performanceTest"></a>2．执行performanceTest</h5><p>以下程序代码执行performanceTest分别传入：</p>
<ul>
<li>g＝performanceTest（“／gpu：0“，100）用GPU执行计算，建立的矩阵大小为100。</li>
<li>c＝performanceTest（“／cpu：0“，100）用CPU执行计算，建立的矩阵大小为100。</li>
</ul>
<p><img src="Image01095.jpg" alt></p>
<p>我们可以看到以上执行结果GPU大约0.06秒，CPU大约0.08秒，GPU比较快。</p>
<h5 id="3．创建performanceTest"><a href="#3．创建performanceTest" class="headerlink" title="3．创建performanceTest"></a>3．创建performanceTest</h5><p>以下程序代码使用for循环执行performanceTest，使用不同的设备并设置产生矩阵的大小。</p>
<p><img src="Image01096.jpg" alt></p>
<p>程序代码的说明如下：</p>
<p>▶ 初始化gpu_set、cpu_set、i_set</p>
<p>我们将使用gpu_set、cpu_set、i_set记录GPU与CPU的运行时间。</p>
<p><img src="Image01097.jpg" alt></p>
<p>▶ 使用for循环重复执行程序块内的程序代码</p>
<p>使用for循环重复执行程序块内的程序代码，其中range（0，5001,500）会产生序列：从0到5001间隔500，也就是说会产生序列［0,500，1000，．．．，5000］，每次设置i值为产生的序列。分别用GPU及CPU执行performanceTest，并把矩阵大小设置为i。</p>
<p><img src="Image01098.jpg" alt></p>
<p>▶ 将每次的执行结果存储在gpu_set、cpu_set、i_set中</p>
<p><img src="Image01099.jpg" alt></p>
<p>执行后屏幕显示界面如图21-8所示。</p>
<p><img src="Image01100.jpg" alt></p>
<p>图21-8</p>
<p>从以上执行结果可以看到size是产生矩阵的大小，产生的矩阵越大，所需时间越多。矩阵越大，CPU与GPU的差距越大，也就是说矩阵越大，越能发挥使用GPU的性能。</p>
<h5 id="4．将GPU与CPU的运行时间用图形来查看"><a href="#4．将GPU与CPU的运行时间用图形来查看" class="headerlink" title="4．将GPU与CPU的运行时间用图形来查看"></a>4．将GPU与CPU的运行时间用图形来查看</h5><p>用下列程序代码以图形来显示GPU与CPU的运行时间，这样更容易看出GPU与CPU执行速度的差异。</p>
<p><img src="Image01101.jpg" alt></p>
<p>_x_ 轴是矩阵大小， _y_ 轴是运行时间，矩阵越大，CPU与GPU的差距越大。也就是说，矩阵越大，越能发挥使用GPU的性能。</p>
<h3 id="21-3-超出显卡内存的限制"><a href="#21-3-超出显卡内存的限制" class="headerlink" title="21.3 超出显卡内存的限制"></a>21.3 超出显卡内存的限制</h3><p>笔者所测试的GeForce GT720显卡经过测试发现矩阵大小超过6000，由于显卡内存不足，因此会发生错误。当然，如果显卡内存比较大，就可能较大的矩阵才会发生错误。</p>
<p><img src="Image01102.jpg" alt></p>
<p>出现NVIDIA显示驱动程序停止响应，出现错误时界面如图21-9所示。</p>
<p><img src="Image01103.jpg" alt></p>
<p>图21-9</p>
<p>接下来会显示Python已经停止运行，如图21-10所示。</p>
<p><img src="Image01104.jpg" alt></p>
<p>图21-10</p>
<p>遇到这种情况，可关闭再重新打开“命令提示符”窗口，然后按照21.1节的步骤重新启动TensorFlow GPU环境。</p>
<p>由以上测试得知，当我们选购显卡时，显卡内存也是选购考虑的重点，内存越大越好，当然成本也更高。</p>
<h3 id="21-4-以多层感知器的实际范例比较CPU与GPU的执行速度"><a href="#21-4-以多层感知器的实际范例比较CPU与GPU的执行速度" class="headerlink" title="21.4 以多层感知器的实际范例比较CPU与GPU的执行速度"></a>21.4 以多层感知器的实际范例比较CPU与GPU的执行速度</h3><p>接下来将以实际范例来比较CPU与GPU的执行速度，我们将之前第18章所创建的TensorFlow_Mnist_MLP_h1000.ipynb作为测试范例。</p>
<p><img src="Image01105.jpg" alt> 启动TensorFlow CPU环境。</p>
<p>我们将使用第3章所建立的Anaconda TensorFlow CPU虚拟环境。</p>
<p>▶ 启动TensorFlow环境并启动jupyter notebook</p>
<p><img src="Image01106.jpg" alt></p>
<p>执行后屏幕显示界面如图21-11所示。</p>
<p><img src="Image01107.jpg" alt></p>
<p>图21-11</p>
<p><img src="Image01108.jpg" alt> 在TensorFlow CPU环境中执行训练的程序代码及其执行结果如图21-12所示。</p>
<p><img src="Image01109.jpg" alt></p>
<p>图21-12</p>
<p>从以上执行结果可知，使用CPU执行共需106秒。</p>
<p><img src="Image01110.jpg" alt> 启动TensorFlow GPU环境。</p>
<p>▶ 启动TensorFlow GPU环境并执行jupyter notebook</p>
<p><img src="Image01111.jpg" alt></p>
<p>执行后屏幕显示界面如图21-13所示。</p>
<p><img src="Image01112.jpg" alt></p>
<p>图21-13</p>
<p><img src="Image01113.jpg" alt> 打开TensorFlow_Mnist_MLP_h1000.ipynb，如图21-14所示。</p>
<p><img src="Image01114.jpg" alt></p>
<p>图21-14</p>
<p><img src="Image01115.jpg" alt> 执行训练程序代码，如图21-15所示。</p>
<p><img src="Image01116.jpg" alt></p>
<p>图21-15</p>
<p>以上用GPU执行计算共需78秒，比起之前使用CPU执行运算所需的106秒少了28秒。大约计算了一下，（28÷106）×100＝26，也就是说GPU比CPU大约减少26%的时间。</p>
<h3 id="21-5-以CNN的实际范例比较CPU与GPU的执行速度"><a href="#21-5-以CNN的实际范例比较CPU与GPU的执行速度" class="headerlink" title="21.5 以CNN的实际范例比较CPU与GPU的执行速度"></a>21.5 以CNN的实际范例比较CPU与GPU的执行速度</h3><p>接下来，我们将以实际范例比较CPU与GPU的执行速度，将之前第19章所创建的TensorFlow_Mnist_CNN.ipynb作为测试范例。</p>
<p><img src="Image01117.jpg" alt> 启动TensorFlow CPU环境。</p>
<p>▶ 启动jupyter notebook</p>
<p><img src="Image01118.jpg" alt></p>
<p>执行后屏幕显示界面如图21-16所示。</p>
<p><img src="Image01119.jpg" alt></p>
<p>图21-16</p>
<p><img src="Image01120.jpg" alt> 在Anaconda TensorFlow CPU环境执行训练。</p>
<p>进入jupyter notebook界面后，打开并执行TensorFlow_Mnist_CNN.ipynb程序，执行训练的界面如图21-17所示。</p>
<p><img src="Image01121.jpg" alt></p>
<p>图21-17</p>
<p>从使用CPU执行训练后的结果可知，花费时间是395秒。</p>
<p><img src="Image01122.jpg" alt> 启动TensorFlow GPU环境。</p>
<p>关闭之前的“命令提示符”窗口，并打开新的“命令提示符”窗口，输入下列命令启动TensorFlow GPU环境，之后再启动jupyter notebook。</p>
<p><img src="Image01123.jpg" alt></p>
<p>执行后屏幕显示界面如图21-18所示。</p>
<p><img src="Image01124.jpg" alt></p>
<p>图21-18</p>
<p><img src="Image01125.jpg" alt> 打开TensorFlow_Mnist_CNN.ipynb，如图21-19所示。</p>
<p><img src="Image01126.jpg" alt></p>
<p>图21-19</p>
<p><img src="Image01127.jpg" alt> 修改评估模型的准确率。</p>
<p>当我们计算准确率时，测试数据共有10000项，当传入全部的测试数据mnist.test.images、mnist.test.labels时，因为显卡内存只有2GB，所以会发生错误，必须改为分两次执行，每次只传入5000项test数据。</p>
<ul>
<li><strong>传入前5000项数据：</strong> 分别是mnist.test.images［：5000］、mnist.test.labels［：5000］。</li>
<li><strong>传入后5000项数据：</strong> 分别是mnist.test.images［5000：］、mnist.test.labels［5000：］。</li>
</ul>
<p><img src="Image01128.jpg" alt></p>
<p><img src="Image01129.jpg" alt> 修改预测概率。</p>
<p>因为显卡内存只有2GB，所以我们在预测数据时，只能预测前5000项数据。</p>
<p><img src="Image01130.jpg" alt></p>
<p><img src="Image01131.jpg" alt> 执行训练后的结果如图21-20所示。</p>
<p><img src="Image01132.jpg" alt></p>
<p>图21-20</p>
<p>以上使用GPU执行训练所花费的时间是299秒，之前使用CPU执行训练所花费的时间是395秒，GPU比CPU运行时间减少了96秒。大约计算了一下，（96÷395）×100＝24，也就是说GPU比CPU大约减少24%的时间。</p>
<h3 id="21-6-以Keras-Cifar-CNN的实际范例比较CPU与GPU的执行速度"><a href="#21-6-以Keras-Cifar-CNN的实际范例比较CPU与GPU的执行速度" class="headerlink" title="21.6 以Keras Cifar CNN的实际范例比较CPU与GPU的执行速度"></a>21.6 以Keras Cifar CNN的实际范例比较CPU与GPU的执行速度</h3><p>之前测试的都是TensorFlow程序，接下来我们将测试Keras程序比较CPU与GPU的执行速度，将之前第10章所创建的Keras_Cifar_CNN.ipynb作为测试范例。</p>
<p><img src="Image01133.jpg" alt> 启动TensorFlow CPU环境。</p>
<p>▶ 启动jupyter notebook</p>
<p><img src="Image01134.jpg" alt></p>
<p>执行后屏幕显示界面如图21-21所示。</p>
<p><img src="Image01135.jpg" alt></p>
<p>图21-21</p>
<p><img src="Image01136.jpg" alt> 在TensorFlow CPU环境中执行训练。</p>
<p>进入jupyter notebook界面后，打开并执行Keras_Cifar_CNN.ipynb程序，执行训练的界面如图21-22所示。</p>
<p><img src="Image01137.jpg" alt></p>
<p>图21-22</p>
<p>以上每一个训练周期的运行时间大约为170秒。</p>
<p><img src="Image01138.jpg" alt> 启动TensorFlow GPU环境。</p>
<p>关闭之前的“命令提示符”窗口，再打开新的“命令提示符”窗口，输入下列命令启动TensorFlow GPU环境，再启动jupyter notebook。</p>
<p><img src="Image01139.jpg" alt></p>
<p>执行后屏幕显示界面如图21-23所示。</p>
<p><img src="Image01140.jpg" alt></p>
<p>图21-23</p>
<p><img src="Image01141.jpg" alt> 在Anaconda TensorFlow CPU环境中执行训练。</p>
<p>进入jupyter notebook界面后，打开并执行Keras_Cifar_CNN.ipynb程序，执行训练的界面如图21-24所示。</p>
<p><img src="Image01142.jpg" alt></p>
<p>图21-24</p>
<p>以上使用GPU执行每一个训练周期运行的时间大约是109秒，之前使用CPU执行每一个训练周期大约是170秒，GPU运行时间减少了大约61秒。大约计算了一下，（61÷170）×100＝35，也就是说GPU比CPU大约减少了35%的时间。</p>
<h3 id="21-7-结论"><a href="#21-7-结论" class="headerlink" title="21.7 结论"></a>21.7 结论</h3><p>经过测试CPU与GPU的运行时间，会发现GPU的运行时间比CPU大约减少了35%。你也许觉得节省这么一点时间实在微不足道，但是笔者测试的GPU独立显卡是最入门级的GeForceGT720，当时的价格不到450元，而使用的CPU是Intel Corei5（英特尔酷睿）中央处理器，同样的时间市价大约是1300元。也就是说在深度学习训练中，450元不到的GPU打败了1300元的CPU，所以还是很值得这么做的。如果安装了更好的Nvidia显卡，显卡内存再多一些，相信执行性能会好很多。</p>
<h1 id="附录A-本书范例程序的下载与安装说明"><a href="#附录A-本书范例程序的下载与安装说明" class="headerlink" title="附录A 本书范例程序的下载与安装说明"></a>附录A 本书范例程序的下载与安装说明</h1><p>本书范例程序的下载与安装说明将分别介绍在Windows与Linux系统中的安装方式。读者可以按照自己安装的操作系统来选择安装本书的范例程序。</p>
<h3 id="A-1-在Windows系统中下载与安装范例程序"><a href="#A-1-在Windows系统中下载与安装范例程序" class="headerlink" title="A.1 在Windows系统中下载与安装范例程序"></a>A.1 在Windows系统中下载与安装范例程序</h3><p>在Windows中下载与安装范例程序之前，先参照本书第4章的说明在Windows中安装TensorFlow与Keras。</p>
<p><img src="Image01143.jpg" alt> 下载范例程序。</p>
<p>在浏览器中输入下列网址来下载本书的范例程序（见图A-1）：</p>
<p><a href="https://pan.baidu.com/s/1c2rXnH2" target="_blank" rel="noopener">https://pan.baidu.com/s/1c2rXnH2</a></p>
<p><img src="Image01144.jpg" alt></p>
<p>图A-1</p>
<p><img src="Image01145.jpg" alt> 解压缩范例程序。</p>
<p>下载文件后，打开文件资源管理器，单击下载目录就可以看到MP21710_example范例程序压缩文件，如图A-2所示。在Windows文件资源管理器中，双击文件名即可打开压缩文件。如果安装了其他解压缩软件，也可以用其他解压缩软件来解压缩。</p>
<p><img src="Image01146.jpg" alt></p>
<p>图A-2</p>
<p><img src="Image01147.jpg" alt> 拖曳到D：磁盘驱动器。</p>
<p>打开压缩文件后，就可以看到MP21710_example的目录，将其拖曳到D：驱动器，就可以自动解压缩到D：驱动器（安装在D：驱动器只是示范，读者也可以安装在其他地方），如图A-3所示。</p>
<p><img src="Image01148.jpg" alt></p>
<p>图A-3</p>
<p><img src="Image01149.jpg" alt> 查看D：驱动器。</p>
<p>查看D：驱动器，我们可以看到已解压缩的范例程序目录，如图A-4所示。</p>
<p><img src="Image01150.jpg" alt></p>
<p>图A-4</p>
<p><img src="Image01151.jpg" alt> 启动TensorFlow的Anaconda虚拟环境。</p>
<p>打开“命令提示符”窗口，输入下列命令。</p>
<p>▶ 切换到D：驱动器</p>
<p><img src="Image01152.jpg" alt></p>
<p>▶ 切换到范例程序目录</p>
<p><img src="Image01153.jpg" alt></p>
<p>▶ 启动TensorFlow的Anaconda虚拟环境</p>
<p><img src="Image01154.jpg" alt></p>
<p>执行后屏幕显示界面如图A-5所示。</p>
<p><img src="Image01155.jpg" alt></p>
<p>图A-5</p>
<p>注意，以上启动TensorFlow的Anaconda虚拟环境是TensorFlow CPU版本。</p>
<p>如果读者参照本书第20章的介绍安装TensorFlow GPU版本，就使用下列指令。</p>
<p>▶ 启动Anaconda TensorFlow GPU虚拟环境</p>
<p><img src="Image01156.jpg" alt></p>
<p><img src="Image01157.jpg" alt> 打开jupyter notebook。</p>
<p>打开“命令提示符”窗口，输入下列命令进入jupyter notebook互动界面。</p>
<p>▶ 打开jupyter notebook</p>
<p><img src="Image01158.jpg" alt></p>
<p>按Enter键后就会打开浏览器，默认的网址是<a href="http://localhost:8888，即jupyter" target="_blank" rel="noopener">http://localhost:8888，即jupyter</a> notebook界面，如图A-6所示。</p>
<p><img src="Image01159.jpg" alt></p>
<p>图A-6</p>
<p><img src="Image01160.jpg" alt> 打开Jupyter查看本书的范例程序。</p>
<p>打开Jupyter后，可以看到本书范例程序分为两大部分，分别是Keras与TensorFlow范例程序，如图A-7所示。</p>
<p><img src="Image01161.jpg" alt></p>
<p>图A-7</p>
<p>关于范例程序的功能说明可参考“本书章节与范例程序介绍”。</p>
<p><img src="Image01162.jpg" alt> 查看本书范例程序目录。</p>
<p>打开Jupyter后，我们可以看到目录如图A-8所示。</p>
<p><img src="Image01163.jpg" alt></p>
<p>图A-8</p>
<p>以上目录都是空的，必须执行范例程序后才会产生数据，说明如下。</p>
<p>▶ data：Keras数据目录</p>
<p>用于存放Keras范例程序下载的数据文件，必须执行范例程序后，才会下载数据到此目录。</p>
<ul>
<li>执行Keras_Taianic_Introduce.ipynb下载Taianic数据集后，才能执行其他Taianic程序。</li>
<li>执行Keras_Imdb_Introduce.ipynb下载并且解压缩IMDb数据集后，才能执行其他IMDb程序。</li>
</ul>
<p>▶ log：TensorBoard log目录</p>
<p>用于存放TensorBoard的log目录，必须执行范例程序TensorFlow_Board_area.ipynb、TensorFlow_Mnist_CNN.ipynb后，才会产生log，并且在TensorBoard显示“计算图”。</p>
<p>▶ MNIST_data：TensorFlow MNIST data目录</p>
<p>用于存放TensorFlow MNIST的数据文件，必须执行TensorFlow_Mnist_Introduce.ipynb才会下载文件。</p>
<p>▶ SaveModel：Keras存储模型目录</p>
<p>用于存放Keras存储模型的目录，必须执行Keras_Cifar_CNN_Continue_Train.ipynb后才会产生。</p>
<p>以上范例的详细说明可参考本书对应的章节。</p>
<h3 id="A-2-在Ubuntu-Linux系统中下载与安装范例程序"><a href="#A-2-在Ubuntu-Linux系统中下载与安装范例程序" class="headerlink" title="A.2 在Ubuntu Linux系统中下载与安装范例程序"></a>A.2 在Ubuntu Linux系统中下载与安装范例程序</h3><p>在Ubuntu Linux下载与安装范例程序之前，先参照本书第5章的说明在Linux Ubuntu安装TensorFlow与Keras。</p>
<p><img src="Image01164.jpg" alt> 下载范例程序。</p>
<p>启动Ubuntu的“终端”程序，输入下列指令。</p>
<p>▶ 切换到用户home目录</p>
<p><img src="Image01165.jpg" alt></p>
<p>▶ 下载范例程序</p>
<p><img src="Image01166.jpg" alt></p>
<p>执行后屏幕显示界面如图A-9所示。</p>
<p><img src="Image01167.jpg" alt></p>
<p>图A-9</p>
<p><img src="Image01168.jpg" alt> 解压缩范例程序。</p>
<p>在“终端”程序中输入表A-1中的命令解压缩范例程序。</p>
<p>表A-1 解压缩程序命令说明</p>
<p><img src="Image01169.jpg" alt></p>
<p>执行后屏幕显示界面如图A-10所示。</p>
<p><img src="Image01170.jpg" alt></p>
<p>图A-10</p>
<p><img src="Image01171.jpg" alt> 打开 jupyter notebook。</p>
<p>在“终端”程序中输入下列命令进入jupyter notebook互动界面。</p>
<p>▶ 切换到范例程序目录</p>
<p><img src="Image01172.jpg" alt></p>
<p>▶ 打开jupyter notebook</p>
<p><img src="Image01173.jpg" alt></p>
<p>按Enter键后就会打开浏览器，默认的网址是<a href="http://localhost:8888，这是Jupyter界面，如图A-11所示。" target="_blank" rel="noopener">http://localhost:8888，这是Jupyter界面，如图A-11所示。</a></p>
<p><img src="Image01174.jpg" alt></p>
<p>图A-11</p>
<p>打开Jupyter后的目录与范例程序与在Windows系统下安装范例程序后的结果完全相同，可参考之前的说明。</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      <div>    
       
       
      <ul class="post-copyright">
        <li class="post-copyright-author">
            <strong>本文作者：</strong>hac_lang
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="/2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/" title="book_《TensorFlow+Keras深度学习人工智能实践应用》">2018/03/29/book-《TensorFlow-Keras深度学习人工智能实践应用》/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          许可协议，请勿用于商业，转载注明出处！
        </li>
      </ul>
      
      </div>
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/计算机/" rel="tag"># 计算机</a>
          
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
          
            <a href="/tags/自评/" rel="tag"># 自评</a>
          
            <a href="/tags/books/" rel="tag"># books</a>
          
            <a href="/tags/更毕/" rel="tag"># 更毕</a>
          
            <a href="/tags/Keras/" rel="tag"># Keras</a>
          
            <a href="/tags/DeepLearning/" rel="tag"># DeepLearning</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/入门/" rel="tag"># 入门</a>
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
            <a href="/tags/豆瓣7/" rel="tag"># 豆瓣7</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/26/book-《深度学习之TensorFlow入门、原理与进阶实战》-李金洪/" rel="next" title="book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪">
                <i class="fa fa-chevron-left"></i> book_《深度学习之TensorFlow入门、原理与进阶实战》_李金洪
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/26/book-《深度学习框架PyTorch：入门与实践》-陈云/" rel="prev" title="book_《深度学习框架PyTorch：入门与实践》_陈云">
                book_《深度学习框架PyTorch：入门与实践》_陈云 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
    <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="hac_lang">
  
  <p class="site-author-name" itemprop="name">hac_lang</p>
  <div class="site-description motion-element" itemprop="description">小白hac_lang的笔记，涉及内容包含但不限于<br>人工智能 &ensp; 信息安全 &ensp; 网络技术<br>软件工程 &ensp; 基因工程 &ensp; 嵌入式 &ensp; 天文物理</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">82</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>







  <div class="links-of-author motion-element">
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/HACLANG" title="GitHub &rarr; https://github.com/HACLANG" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://stackoverflow.com/yourname" title="StackOverflow &rarr; https://stackoverflow.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://gitter.im" title="Gitter &rarr; https://gitter.im" rel="noopener" target="_blank"><i class="fa fa-fw fa-github-alt"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.jianshu.com/u/442ddccf3f32" title="简书 &rarr; https://www.jianshu.com/u/442ddccf3f32" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="Quora &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://plus.google.com/yourname" title="Google &rarr; https://plus.google.com/yourname" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:haclang.org@gmail.com" title="E-Mail &rarr; mailto:haclang.org@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="skype:haclang?call|chat" title="Skype &rarr; skype:haclang?call|chat" rel="noopener" target="_blank"><i class="fa fa-fw fa-skype"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://twitter.com/haclang2" title="Twitter &rarr; https://twitter.com/haclang2" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://www.facebook.com/hac.lang.1675" title="FaceBook &rarr; https://www.facebook.com/hac.lang.1675" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i></a>
      </span>
    
  </div>








          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#内容简介"><span class="nav-text">内容简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#序"><span class="nav-text">序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#前-言"><span class="nav-text">前 言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#本书章节与范例程序介绍"><span class="nav-text">本书章节与范例程序介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第1章-人工智能、机器学习与深度学习简介"><span class="nav-text">第1章 人工智能、机器学习与深度学习简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-人工智能、机器学习、深度学习的关系"><span class="nav-text">1.1 人工智能、机器学习、深度学习的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-机器学习介绍"><span class="nav-text">1.2 机器学习介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-机器学习分类"><span class="nav-text">1.3 机器学习分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-深度学习简介"><span class="nav-text">1.4 深度学习简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-结论"><span class="nav-text">1.5 结论</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#第2章-深度学习的原理"><span class="nav-text">第2章 深度学习的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-神经传导的原理"><span class="nav-text">2.1 神经传导的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．神经元的信息传导"><span class="nav-text">1．神经元的信息传导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．以数学公式仿真神经元的信息传导"><span class="nav-text">2．以数学公式仿真神经元的信息传导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．激活函数通常为非线性函数"><span class="nav-text">3．激活函数通常为非线性函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．Sigmoid激活函数"><span class="nav-text">4．Sigmoid激活函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．ReLU激活函数"><span class="nav-text">5．ReLU激活函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-以矩阵运算仿真神经网络"><span class="nav-text">2.2 以矩阵运算仿真神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．以矩阵运算仿真神经网络的信息传导"><span class="nav-text">1．以矩阵运算仿真神经网络的信息传导</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-多层感知器模型"><span class="nav-text">2.3 多层感知器模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．以多层感知器模型识别MNIST手写数字图像"><span class="nav-text">1．以多层感知器模型识别MNIST手写数字图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）"><span class="nav-text">2．以矩阵公式仿真多层感知器模型的工作方式（见图2-7）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-使用反向传播算法进行训练"><span class="nav-text">2.4 使用反向传播算法进行训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．训练前必须先进行“数据预处理”与“建立模型”"><span class="nav-text">1．训练前必须先进行“数据预处理”与“建立模型”</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．反向传播算法训练多层感知器模型（见图2-9）"><span class="nav-text">2．反向传播算法训练多层感知器模型（见图2-9）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．损失函数"><span class="nav-text">3．损失函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．优化器"><span class="nav-text">4．优化器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-结论"><span class="nav-text">2.5 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第3章-TensorFlow与Keras介绍"><span class="nav-text">第3章 TensorFlow与Keras介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-TensorFlow架构图"><span class="nav-text">3.1 TensorFlow架构图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-TensorFlow简介"><span class="nav-text">3.2 TensorFlow简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-TensorFlow程序设计模式"><span class="nav-text">3.3 TensorFlow程序设计模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Keras介绍"><span class="nav-text">3.4 Keras介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-Keras程序设计模式"><span class="nav-text">3.5 Keras程序设计模式</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立Sequential模型"><span class="nav-text">1．建立Sequential模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．加入“输入层”与“隐藏层”到模型中"><span class="nav-text">2．加入“输入层”与“隐藏层”到模型中</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．加入“输出层”到模型"><span class="nav-text">3．加入“输出层”到模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-6-Keras与TensorFlow比较"><span class="nav-text">3.6 Keras与TensorFlow比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-7-结论"><span class="nav-text">3.7 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第4章-在Windows中安装TensorFlow与Keras"><span class="nav-text">第4章 在Windows中安装TensorFlow与Keras</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-安装Anaconda"><span class="nav-text">4.1 安装Anaconda</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-启动命令提示符"><span class="nav-text">4.2 启动命令提示符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-建立TensorFlow的Anaconda虚拟环境"><span class="nav-text">4.3 建立TensorFlow的Anaconda虚拟环境</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立工作目录"><span class="nav-text">1．建立工作目录</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立Anaconda虚拟环境"><span class="nav-text">2．建立Anaconda虚拟环境</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．启动Anaconda虚拟环境"><span class="nav-text">3．启动Anaconda虚拟环境</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．关闭TensorFlow的Anaconda虚拟环境"><span class="nav-text">4．关闭TensorFlow的Anaconda虚拟环境</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-在Anaconda虚拟环境安装TensorFlow与Keras"><span class="nav-text">4.4 在Anaconda虚拟环境安装TensorFlow与Keras</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．启动Anaconda虚拟环境"><span class="nav-text">1．启动Anaconda虚拟环境</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．安装TensorFlow"><span class="nav-text">2．安装TensorFlow</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．安装Keras"><span class="nav-text">3．安装Keras</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-启动Jupyter-Notebook"><span class="nav-text">4.5 启动Jupyter Notebook</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．启动Jupyter-Notebook"><span class="nav-text">1．启动Jupyter Notebook</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立新的Notebook"><span class="nav-text">2．建立新的Notebook</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．Jupyter-Notebook输入命令的方式"><span class="nav-text">3．Jupyter Notebook输入命令的方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．导入TensorFlow模块"><span class="nav-text">4．导入TensorFlow模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．查看TensorFlow版本"><span class="nav-text">5．查看TensorFlow版本</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．导入Keras模块"><span class="nav-text">6．导入Keras模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．查看Keras版本"><span class="nav-text">7．查看Keras版本</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8．保存Notebook"><span class="nav-text">8．保存Notebook</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#9．关闭Notebook"><span class="nav-text">9．关闭Notebook</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#10．打开之前保存的NoteBook"><span class="nav-text">10．打开之前保存的NoteBook</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#11．关闭Jupyter浏览器（见图4-35）"><span class="nav-text">11．关闭Jupyter浏览器（见图4-35）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#12．关闭Jupyter-Notebook"><span class="nav-text">12．关闭Jupyter Notebook</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-结论"><span class="nav-text">4.6 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第5章-在Linux-Ubuntu中安装TensorFlow与Keras"><span class="nav-text">第5章 在Linux Ubuntu中安装TensorFlow与Keras</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-安装Anaconda"><span class="nav-text">5.1 安装Anaconda</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-启动Jupyter-Notebook"><span class="nav-text">5.3 启动Jupyter Notebook</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-结论"><span class="nav-text">5.4 结论</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第6章-Keras-MNIST手写数字识别数据集"><span class="nav-text">第6章 Keras MNIST手写数字识别数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-下载MNIST数据"><span class="nav-text">6.1 下载MNIST数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入Keras及相关模块"><span class="nav-text">1．导入Keras及相关模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．导入Keras模块"><span class="nav-text">2．导入Keras模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．第一次进行MNIST数据的下载"><span class="nav-text">3．第一次进行MNIST数据的下载</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看下载的MNIST数据文件"><span class="nav-text">4．查看下载的MNIST数据文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．读取MNIST数据"><span class="nav-text">5．读取MNIST数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看MNIST数据"><span class="nav-text">6．查看MNIST数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-查看训练数据"><span class="nav-text">6.2 查看训练数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．训练数据是由images与labels所组成的"><span class="nav-text">1．训练数据是由images与labels所组成的</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．定义plot-image函数显示数字图像"><span class="nav-text">2．定义plot_image函数显示数字图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．执行plot-image函数查看第0个数字图像"><span class="nav-text">3．执行plot_image函数查看第0个数字图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看第0项label数据"><span class="nav-text">4．查看第0项label数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-查看多项训练数据images与label"><span class="nav-text">6.3 查看多项训练数据images与label</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．创建plot-images-labels-prediction（）函数"><span class="nav-text">1．创建plot_images_labels_prediction（）函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看训练数据前10项数据"><span class="nav-text">2．查看训练数据前10项数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看test测试数据"><span class="nav-text">3．查看test测试数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．显示test测试数据"><span class="nav-text">4．显示test测试数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-多层感知器模型数据预处理"><span class="nav-text">6.4 多层感知器模型数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-features数据预处理"><span class="nav-text">6.5 features数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-6-label数据预处理"><span class="nav-text">6.6 label数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-7-结论"><span class="nav-text">6.7 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第7章-Keras多层感知器识别手写数字"><span class="nav-text">第7章 Keras多层感知器识别手写数字</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-Keras多元感知器识别MNIST手写数字图像的介绍"><span class="nav-text">7.1 Keras多元感知器识别MNIST手写数字图像的介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．多层感知器模型的介绍"><span class="nav-text">1．多层感知器模型的介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．多层感知器的训练与预测"><span class="nav-text">2．多层感知器的训练与预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立多层感知器模型的步骤"><span class="nav-text">3．建立多层感知器模型的步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-进行数据预处理"><span class="nav-text">7.2 进行数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-建立模型"><span class="nav-text">7.3 建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入所需模块"><span class="nav-text">1．导入所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立Sequential模型"><span class="nav-text">2．建立Sequential模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立“输入层”与“隐藏层”"><span class="nav-text">3．建立“输入层”与“隐藏层”</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．建立“输出层”"><span class="nav-text">4．建立“输出层”</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．查看模型的摘要"><span class="nav-text">5．查看模型的摘要</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看模型的摘要Param"><span class="nav-text">6．查看模型的摘要Param</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4-进行训练"><span class="nav-text">7.4 进行训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练方式"><span class="nav-text">1．定义训练方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．开始训练"><span class="nav-text">2．开始训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立show-train-history显示训练过程"><span class="nav-text">3．建立show_train_history显示训练过程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．画出准确率执行结果"><span class="nav-text">4．画出准确率执行结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．画出误差执行结果（见图7-10）"><span class="nav-text">5．画出误差执行结果（见图7-10）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-5-以测试数据评估模型准确率"><span class="nav-text">7.5 以测试数据评估模型准确率</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．评估模型准确率"><span class="nav-text">1．评估模型准确率</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-6-进行预测"><span class="nav-text">7.6 进行预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．执行预测"><span class="nav-text">1．执行预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．预测结果"><span class="nav-text">2．预测结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．显示10项预测结果"><span class="nav-text">3．显示10项预测结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-7-显示混淆矩阵"><span class="nav-text">7.7 显示混淆矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．使用pandas-crosstab建立混淆矩阵"><span class="nav-text">1．使用pandas crosstab建立混淆矩阵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立真实值与预测DataFrame"><span class="nav-text">2．建立真实值与预测DataFrame</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查询真实值是“5”但预测值是“3”的数据"><span class="nav-text">3．查询真实值是“5”但预测值是“3”的数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看第340项数据"><span class="nav-text">4．查看第340项数据</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-8-隐藏层增加为1000个神经元"><span class="nav-text">7.8 隐藏层增加为1000个神经元</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-9-多层感知器加入DropOut功能以避免过度拟合"><span class="nav-text">7.9 多层感知器加入DropOut功能以避免过度拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-10-建立多层感知器模型包含两个隐藏层"><span class="nav-text">7.10 建立多层感知器模型包含两个隐藏层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-11-结论"><span class="nav-text">7.11 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第8章-Keras卷积神经网络识别手写数字"><span class="nav-text">第8章 Keras卷积神经网络识别手写数字</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-卷积神经网络简介"><span class="nav-text">8.1 卷积神经网络简介</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．多层感知器与卷积神经网络"><span class="nav-text">1．多层感知器与卷积神经网络</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．卷积神经网络介绍"><span class="nav-text">2．卷积神经网络介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．卷积运算"><span class="nav-text">3．卷积运算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．使用单个filter-weight卷积运算产生图像"><span class="nav-text">4．使用单个filter weight卷积运算产生图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．使用多个filter-weight卷积运算产生多个图像"><span class="nav-text">5．使用多个filter weight卷积运算产生多个图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．Max-Pool运算说明"><span class="nav-text">6．Max-Pool运算说明</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．使用Max-Pool转换手写数字图像"><span class="nav-text">7．使用Max-Pool转换手写数字图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8．建立卷积神经网络识别MNIST数据集"><span class="nav-text">8．建立卷积神经网络识别MNIST数据集</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-进行数据预处理"><span class="nav-text">8.2 进行数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-建立模型"><span class="nav-text">8.3 建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入所需模块-1"><span class="nav-text">1．导入所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立keras的Sequential模型"><span class="nav-text">2．建立keras的Sequential模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立卷积层1与池化层1"><span class="nav-text">3．建立卷积层1与池化层1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．建立卷积层2与池化层2"><span class="nav-text">4．建立卷积层2与池化层2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．建立神经网络（平坦层、隐藏层、输出层）"><span class="nav-text">5．建立神经网络（平坦层、隐藏层、输出层）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看模型的摘要"><span class="nav-text">6．查看模型的摘要</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-进行训练"><span class="nav-text">8.4 进行训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练方式-1"><span class="nav-text">1．定义训练方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．开始训练-1"><span class="nav-text">2．开始训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．画出准确率执行结果"><span class="nav-text">3．画出准确率执行结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．画出误差执行结果"><span class="nav-text">4．画出误差执行结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-评估模型准确率"><span class="nav-text">8.5 评估模型准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-6-进行预测"><span class="nav-text">8.6 进行预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-7-显示混淆矩阵"><span class="nav-text">8.7 显示混淆矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-8-结论"><span class="nav-text">8.8 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第9章-Keras-CIFAR-10图像识别数据集"><span class="nav-text">第9章 Keras CIFAR-10图像识别数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-下载CIFAR-10数据"><span class="nav-text">9.1 下载CIFAR-10数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-查看训练数据"><span class="nav-text">9.2 查看训练数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．训练数据是由images与label所组成的"><span class="nav-text">1．训练数据是由images与label所组成的</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．Images的shape形状"><span class="nav-text">2．Images的shape形状</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．第0项images图像的内容"><span class="nav-text">3．第0项images图像的内容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．y-label-train的shape形状"><span class="nav-text">4．y_label_train的shape形状</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-查看多项images与label"><span class="nav-text">9.3 查看多项images与label</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-4-将images进行预处理"><span class="nav-text">9.4 将images进行预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-5-对label进行数据预处理"><span class="nav-text">9.5 对label进行数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-6-结论"><span class="nav-text">9.6 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第10章-Keras卷积神经网络识别CIFAR-10图像"><span class="nav-text">第10章 Keras卷积神经网络识别CIFAR-10图像</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-卷积神经网络简介"><span class="nav-text">10.1 卷积神经网络简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-数据预处理"><span class="nav-text">10.2 数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-建立模型"><span class="nav-text">10.3 建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入所需模块-2"><span class="nav-text">1．导入所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立keras的Sequential模型-1"><span class="nav-text">2．建立keras的Sequential模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立卷积层1与池化层1-1"><span class="nav-text">3．建立卷积层1与池化层1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．建立卷积层2与池化层2-1"><span class="nav-text">4．建立卷积层2与池化层2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．建立神经网络（平坦层、隐藏层、输出层）-1"><span class="nav-text">5．建立神经网络（平坦层、隐藏层、输出层）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看模型的摘要-1"><span class="nav-text">6．查看模型的摘要</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-进行训练"><span class="nav-text">10.4 进行训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练方式-2"><span class="nav-text">1．定义训练方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．开始训练-2"><span class="nav-text">2．开始训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．画出准确率执行的结果"><span class="nav-text">3．画出准确率执行的结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．画出误差的执行结果"><span class="nav-text">4．画出误差的执行结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-5-评估模型准确率"><span class="nav-text">10.5 评估模型准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-6-进行预测"><span class="nav-text">10.6 进行预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．执行预测-1"><span class="nav-text">1．执行预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．预测结果-1"><span class="nav-text">2．预测结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．显示前10项预测结果"><span class="nav-text">3．显示前10项预测结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-7-查看预测概率"><span class="nav-text">10.7 查看预测概率</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．使用测试数据进行预测"><span class="nav-text">1．使用测试数据进行预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立show-Predicted-Probability函数"><span class="nav-text">2．建立show_Predicted_Probability函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看第0项数据预测的概率（见图10-5）"><span class="nav-text">3．查看第0项数据预测的概率（见图10-5）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看第3项数据预测的概率（见图10-6）"><span class="nav-text">4．查看第3项数据预测的概率（见图10-6）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-8-显示混淆矩阵"><span class="nav-text">10.8 显示混淆矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．查看预测结果的形状"><span class="nav-text">1．查看预测结果的形状</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看y-label-test真实值的shape形状"><span class="nav-text">2．查看y_label_test真实值的shape形状</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．将y-label-test真实值转换为一维数组"><span class="nav-text">3．将y_label_test真实值转换为一维数组</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．使用pandas-crosstab建立混淆矩阵"><span class="nav-text">4．使用pandas crosstab建立混淆矩阵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-9-建立3次的卷积运算神经网络"><span class="nav-text">10.9 建立3次的卷积运算神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立3次的卷积运算的神经网络架构图（见图10-9）"><span class="nav-text">1．建立3次的卷积运算的神经网络架构图（见图10-9）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立卷积层1与池化层1"><span class="nav-text">2．建立卷积层1与池化层1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立卷积层2与池化层2"><span class="nav-text">3．建立卷积层2与池化层2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．新增加卷积层3与池化层3"><span class="nav-text">4．新增加卷积层3与池化层3</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）"><span class="nav-text">5．建立神经网络（平坦层、隐藏层1、隐藏层2、输出层）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．训练模型"><span class="nav-text">6．训练模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．评估模型的准确率"><span class="nav-text">7．评估模型的准确率</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-10-模型的保存与加载"><span class="nav-text">10.10 模型的保存与加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-11-结论"><span class="nav-text">10.11 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第11章-Keras泰坦尼克号上的旅客数据集"><span class="nav-text">第11章 Keras泰坦尼克号上的旅客数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#11-1-下载泰坦尼克号旅客数据集"><span class="nav-text">11.1 下载泰坦尼克号旅客数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入下载所需模块"><span class="nav-text">1．导入下载所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．下载泰坦尼克号的旅客数据集"><span class="nav-text">2．下载泰坦尼克号的旅客数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看已下载的文件"><span class="nav-text">3．查看已下载的文件</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-2-使用Pandas-DataFrame读取数据并进行预处理"><span class="nav-text">11.2 使用Pandas DataFrame读取数据并进行预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-3-使用Pandas-DataFrame进行数据预处理"><span class="nav-text">11.3 使用Pandas DataFrame进行数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-4-将DataFrame转换为Array"><span class="nav-text">11.4 将DataFrame转换为Array</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-5-将ndarray特征字段进行标准化"><span class="nav-text">11.5 将ndarray特征字段进行标准化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-6-将数据分为训练数据与测试数据"><span class="nav-text">11.6 将数据分为训练数据与测试数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-7-结论"><span class="nav-text">11.7 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第12章-Keras多层感知器预测泰坦尼克号上旅客的生存概率"><span class="nav-text">第12章 Keras多层感知器预测泰坦尼克号上旅客的生存概率</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#12-1-数据预处理"><span class="nav-text">12.1 数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-2-建立模型"><span class="nav-text">12.2 建立模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-3-开始训练"><span class="nav-text">12.3 开始训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练方式-3"><span class="nav-text">1．定义训练方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．开始训练-3"><span class="nav-text">2．开始训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．画出准确率的执行结果"><span class="nav-text">3．画出准确率的执行结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．画出误差的执行结果-1"><span class="nav-text">4．画出误差的执行结果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-4-评估模型准确率"><span class="nav-text">12.4 评估模型准确率</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．评估模型的准确率"><span class="nav-text">1．评估模型的准确率</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看评估的准确率"><span class="nav-text">2．查看评估的准确率</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-5-加入《泰坦尼克号》电影中Jack与Rose的数据"><span class="nav-text">12.5 加入《泰坦尼克号》电影中Jack与Rose的数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-6-进行预测"><span class="nav-text">12.6 进行预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-7-找出泰坦尼克号背后的感人故事"><span class="nav-text">12.7 找出泰坦尼克号背后的感人故事</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．查看生存概率高，却没有存活的旅客"><span class="nav-text">1．查看生存概率高，却没有存活的旅客</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．Allison家族的故事"><span class="nav-text">2．Allison家族的故事</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．爱狗女士的故事"><span class="nav-text">3．爱狗女士的故事</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．施特劳斯夫妇的故事"><span class="nav-text">4．施特劳斯夫妇的故事</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-8-结论"><span class="nav-text">12.8 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第13章-IMDb网络电影数据集与自然语言处理"><span class="nav-text">第13章 IMDb网络电影数据集与自然语言处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#13-1-Keras自然语言处理介绍"><span class="nav-text">13.1 Keras自然语言处理介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-2-下载IMDb数据集"><span class="nav-text">13.2 下载IMDb数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入所需模块-3"><span class="nav-text">1．导入所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．下载IMDb数据集"><span class="nav-text">2．下载IMDb数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．解压缩下载的文件"><span class="nav-text">3．解压缩下载的文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看已下载的文件及解压缩目录"><span class="nav-text">4．查看已下载的文件及解压缩目录</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-3-读取IMDb数据"><span class="nav-text">13.3 读取IMDb数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．导入所需模块-4"><span class="nav-text">1．导入所需模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．创建rm-tag函数删除文字中的HTML标签"><span class="nav-text">2．创建rm_tag函数删除文字中的HTML标签</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．创建read-files函数读取IMDb文件目录"><span class="nav-text">3．创建read_files函数读取IMDb文件目录</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．读取IMDb数据集目录"><span class="nav-text">4．读取IMDb数据集目录</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-4-查看IMDb数据"><span class="nav-text">13.4 查看IMDb数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．查看第0项“影评文字”"><span class="nav-text">1．查看第0项“影评文字”</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看第0项label是1，也就是正面评价"><span class="nav-text">2．查看第0项label是1，也就是正面评价</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看第12-501项影评文字"><span class="nav-text">3．查看第12 501项影评文字</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看第12-501项label是0，也就是负面评价"><span class="nav-text">4．查看第12 501项label是0，也就是负面评价</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-5-建立token"><span class="nav-text">13.5 建立token</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立token"><span class="nav-text">1．建立token</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看token读取多少文章"><span class="nav-text">2．查看token读取多少文章</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看token-word-index属性"><span class="nav-text">3．查看token.word_index属性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-6-使用token将“影评文字”转换成“数字列表”"><span class="nav-text">13.6 使用token将“影评文字”转换成“数字列表”</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．使用token-texts-to-sequences将“影评文字”转换为“数字列表”"><span class="nav-text">1．使用token.texts_to_sequences将“影评文字”转换为“数字列表”</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看转换为sequences之后的结果"><span class="nav-text">2．查看转换为sequences之后的结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-7-让转换后的数字长度相同"><span class="nav-text">13.7 让转换后的数字长度相同</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．使用sequence-pad-sequences（）方法截长补短"><span class="nav-text">1．使用sequence.pad_sequences（）方法截长补短</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．“影评文字”转成“数字列表”后，长度大于100的处理方式"><span class="nav-text">2．“影评文字”转成“数字列表”后，长度大于100的处理方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．“影评文字”转成“数字列表”后，长度小于100的处理方式"><span class="nav-text">3．“影评文字”转成“数字列表”后，长度小于100的处理方式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-8-结论"><span class="nav-text">13.8 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第14章-Keras建立MLP、RNN、LSTM模型进行IMDb情感分析"><span class="nav-text">第14章 Keras建立MLP、RNN、LSTM模型进行IMDb情感分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#14-1-建立多层感知器模型进行IMDb情感分析"><span class="nav-text">14.1 建立多层感知器模型进行IMDb情感分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-2-数据预处理"><span class="nav-text">14.2 数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-3-加入嵌入层"><span class="nav-text">14.3 加入嵌入层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-4-建立多层感知器模型"><span class="nav-text">14.4 建立多层感知器模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-5-训练模型"><span class="nav-text">14.5 训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练方式-4"><span class="nav-text">1．定义训练方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．开始训练-4"><span class="nav-text">2．开始训练</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-6-评估模型准确率"><span class="nav-text">14.6 评估模型准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-7-进行预测"><span class="nav-text">14.7 进行预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-8-查看测试数据预测结果"><span class="nav-text">14.8 查看测试数据预测结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-9-查看《美女与野兽》的影评"><span class="nav-text">14.9 查看《美女与野兽》的影评</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-10-预测《美女与野兽》的影评是正面或负面的"><span class="nav-text">14.10 预测《美女与野兽》的影评是正面或负面的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-11-文字处理时使用较大的字典提取更多文字"><span class="nav-text">14.11 文字处理时使用较大的字典提取更多文字</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-12-RNN模型介绍"><span class="nav-text">14.12 RNN模型介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．为什么要使用RNN模型"><span class="nav-text">1．为什么要使用RNN模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．RNN模型原理"><span class="nav-text">2．RNN模型原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．以时间点展开RNN模型"><span class="nav-text">3．以时间点展开RNN模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-13-使用Keras-RNN模型进行IMDb情感分析"><span class="nav-text">14.13 使用Keras RNN模型进行IMDb情感分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-14-LSTM模型介绍"><span class="nav-text">14.14 LSTM模型介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．RNN的长期依赖问题"><span class="nav-text">1．RNN的长期依赖问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．LSTM介绍"><span class="nav-text">2．LSTM介绍</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-15-使用Keras-LSTM模型进行IMDb情感分析"><span class="nav-text">14.15 使用Keras LSTM模型进行IMDb情感分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-16-结论"><span class="nav-text">14.16 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第15章-TensorFlow程序设计模式"><span class="nav-text">第15章 TensorFlow程序设计模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#15-1-建立“计算图”"><span class="nav-text">15.1 建立“计算图”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-2-执行“计算图”"><span class="nav-text">15.2 执行“计算图”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-3-TensorFlow-placeholder"><span class="nav-text">15.3 TensorFlow placeholder</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-4-TensorFlow数值运算方法介绍"><span class="nav-text">15.4 TensorFlow数值运算方法介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-5-TensorBoard"><span class="nav-text">15.5 TensorBoard</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立TensorFlow-Variable变量"><span class="nav-text">1．建立TensorFlow Variable变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立TensorFlow-Variable变量"><span class="nav-text">2．建立TensorFlow Variable变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．在Windows中启动TensorBoard"><span class="nav-text">3．在Windows中启动TensorBoard</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．在Linux-Ubuntu中启动TensorBoard"><span class="nav-text">4．在Linux Ubuntu中启动TensorBoard</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．在TensorBoard查看计算图"><span class="nav-text">5．在TensorBoard查看计算图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-6-建立一维与二维张量"><span class="nav-text">15.6 建立一维与二维张量</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立一维张量（向量）"><span class="nav-text">1．建立一维张量（向量）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看一维张量"><span class="nav-text">2．查看一维张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立二维张量"><span class="nav-text">3．建立二维张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．查看二维张量"><span class="nav-text">4．查看二维张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．再次建立二维张量"><span class="nav-text">5．再次建立二维张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看新的二维张量"><span class="nav-text">6．查看新的二维张量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-7-矩阵基本运算"><span class="nav-text">15.7 矩阵基本运算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．矩阵乘法"><span class="nav-text">1．矩阵乘法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．矩阵加法"><span class="nav-text">2．矩阵加法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．矩阵乘法与加法"><span class="nav-text">3．矩阵乘法与加法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-8-结论"><span class="nav-text">15.8 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第16章-以TensorFlow张量运算仿真神经网络的运行"><span class="nav-text">第16章 以TensorFlow张量运算仿真神经网络的运行</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#16-1-以矩阵运算仿真神经网络"><span class="nav-text">16.1 以矩阵运算仿真神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．以矩阵运算仿真神经网络的信息传导-1"><span class="nav-text">1．以矩阵运算仿真神经网络的信息传导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．TensorFlow张量运算仿真神经网络"><span class="nav-text">2．TensorFlow张量运算仿真神经网络</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．矩阵表达式加入Sigmoid激活函数"><span class="nav-text">3．矩阵表达式加入Sigmoid激活函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．以正态分布的随机数生成权重与偏差的初始值"><span class="nav-text">4．以正态分布的随机数生成权重与偏差的初始值</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．执行一次sess-run可以取得3个TensorFlow变量"><span class="nav-text">5．执行一次sess.run可以取得3个TensorFlow变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．正态分布的随机数tf-random-normal"><span class="nav-text">6．正态分布的随机数tf.random_normal</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#16-2-以placeholder传入-X-值"><span class="nav-text">16.2 以placeholder传入 _X_ 值</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．以placeholder传入1×3的二维数组"><span class="nav-text">1．以placeholder传入1×3的二维数组</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．以placeholder传入3×3的二维数组"><span class="nav-text">2．以placeholder传入3×3的二维数组</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#16-3-创建layer函数以矩阵运算仿真神经网络"><span class="nav-text">16.3 创建layer函数以矩阵运算仿真神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．layer函数"><span class="nav-text">1．layer函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．使用layer函数建立3层类神经网络"><span class="nav-text">2．使用layer函数建立3层类神经网络</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#16-4-建立layer-debug函数显示权重与偏差"><span class="nav-text">16.4 建立layer_debug函数显示权重与偏差</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．创建layer-debug函数"><span class="nav-text">1．创建layer_debug函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．使用layer-debug函数建立3层类神经网络并显示-W-与-b"><span class="nav-text">2．使用layer_debug函数建立3层类神经网络并显示 _W_ 与 _b_</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#16-5-结论"><span class="nav-text">16.5 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第17章-TensorFlow-MNIST手写数字识别数据集"><span class="nav-text">第17章 TensorFlow MNIST手写数字识别数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#17-1-下载MNIST数据"><span class="nav-text">17.1 下载MNIST数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#17-2-查看训练数据"><span class="nav-text">17.2 查看训练数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．训练数据是由images与labels所组成的（见图17-2）"><span class="nav-text">1．训练数据是由images与labels所组成的（见图17-2）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看第0项images图像的长度"><span class="nav-text">2．查看第0项images图像的长度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看第0项images图像的内容"><span class="nav-text">3．查看第0项images图像的内容</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．定义plot-image函数显示图像"><span class="nav-text">4．定义plot_image函数显示图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．执行plot-image函数"><span class="nav-text">5．执行plot_image函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．查看训练标签labels数据"><span class="nav-text">6．查看训练标签labels数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．使用argmax显示数字"><span class="nav-text">7．使用argmax显示数字</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#17-3-查看多项训练数据images与labels"><span class="nav-text">17.3 查看多项训练数据images与labels</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#17-4-批次读取MNIST数据"><span class="nav-text">17.4 批次读取MNIST数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#17-5-结论"><span class="nav-text">17.5 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第18章-TensorFlow多层感知器识别手写数字"><span class="nav-text">第18章 TensorFlow多层感知器识别手写数字</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#18-1-TensorFlow建立多层感知器辨识手写数字的介绍"><span class="nav-text">18.1 TensorFlow建立多层感知器辨识手写数字的介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．多层感知器的训练与预测"><span class="nav-text">1．多层感知器的训练与预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．以多层感知器模型识别MNIST手写数字图像"><span class="nav-text">2．以多层感知器模型识别MNIST手写数字图像</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）"><span class="nav-text">3．以矩阵公式仿真多层感知器模型的工作方式（见图18-3）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．多层感知器模型的建立步骤"><span class="nav-text">4．多层感知器模型的建立步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-2-数据准备"><span class="nav-text">18.2 数据准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-3-建立模型"><span class="nav-text">18.3 建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．建立layer函数"><span class="nav-text">1．建立layer函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立输入层（-x-）"><span class="nav-text">2．建立输入层（ _x_ ）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立隐藏层（-h-1）"><span class="nav-text">3．建立隐藏层（ _h_ 1）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．建立输出层（-y-）"><span class="nav-text">4．建立输出层（ _y_ ）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-4-定义训练方式"><span class="nav-text">18.4 定义训练方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-5-定义评估模型准确率的方式"><span class="nav-text">18.5 定义评估模型准确率的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-6-进行训练"><span class="nav-text">18.6 进行训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义训练参数"><span class="nav-text">1．定义训练参数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．进行训练"><span class="nav-text">2．进行训练</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．画出误差执行结果"><span class="nav-text">3．画出误差执行结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．画出准确率的执行结果"><span class="nav-text">4．画出准确率的执行结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-7-评估模型准确率"><span class="nav-text">18.7 评估模型准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-8-进行预测"><span class="nav-text">18.8 进行预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．执行预测-2"><span class="nav-text">1．执行预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．预测结果-2"><span class="nav-text">2．预测结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．显示前10项预测结果-1"><span class="nav-text">3．显示前10项预测结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-9-隐藏层加入更多神经元"><span class="nav-text">18.9 隐藏层加入更多神经元</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-10-建立包含两个隐藏层的多层感知器模型"><span class="nav-text">18.10 建立包含两个隐藏层的多层感知器模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#18-11-结论"><span class="nav-text">18.11 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第19章-TensorFlow卷积神经网络识别手写数字"><span class="nav-text">第19章 TensorFlow卷积神经网络识别手写数字</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#19-1-卷积神经网络简介"><span class="nav-text">19.1 卷积神经网络简介</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．卷积神经网络的介绍"><span class="nav-text">1．卷积神经网络的介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立卷积神经网络识别MNIST数据集的步骤"><span class="nav-text">2．建立卷积神经网络识别MNIST数据集的步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-2-进行数据预处理"><span class="nav-text">19.2 进行数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-3-建立共享函数"><span class="nav-text">19.3 建立共享函数</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．定义weight函数，用于建立权重张量"><span class="nav-text">1．定义weight函数，用于建立权重张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．定义bias函数，用于建立偏差张量"><span class="nav-text">2．定义bias函数，用于建立偏差张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．定义conv2d函数，用于进行卷积运算"><span class="nav-text">3．定义conv2d函数，用于进行卷积运算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．出具max-pool-2x2函数，用于建立池化层"><span class="nav-text">4．出具max_pool_2x2函数，用于建立池化层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-4-建立模型"><span class="nav-text">19.4 建立模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．输入层"><span class="nav-text">1．输入层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．建立卷积层1"><span class="nav-text">2．建立卷积层1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．建立池化层1"><span class="nav-text">3．建立池化层1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．建立卷积层2"><span class="nav-text">4．建立卷积层2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．建立池化层2"><span class="nav-text">5．建立池化层2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．建立平坦层"><span class="nav-text">6．建立平坦层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．建立隐藏层"><span class="nav-text">7．建立隐藏层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#8．建立输出层"><span class="nav-text">8．建立输出层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-5-定义训练方式"><span class="nav-text">19.5 定义训练方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-6-定义评估模型准确率的方式"><span class="nav-text">19.6 定义评估模型准确率的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-7-进行训练"><span class="nav-text">19.7 进行训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-8-评估模型准确率"><span class="nav-text">19.8 评估模型准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-9-进行预测"><span class="nav-text">19.9 进行预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．执行预测-3"><span class="nav-text">1．执行预测</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．预测结果-3"><span class="nav-text">2．预测结果</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．显示前10项预测结果-2"><span class="nav-text">3．显示前10项预测结果</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-10-TensorBoard"><span class="nav-text">19.10 TensorBoard</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．在Windows中启动TensorBoard"><span class="nav-text">1．在Windows中启动TensorBoard</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．启动TensorBoard"><span class="nav-text">2．启动TensorBoard</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．在TensorBoard查看“计算图”"><span class="nav-text">3．在TensorBoard查看“计算图”</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#19-11-结论"><span class="nav-text">19.11 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第20章-TensorFlow-GPU版本的安装"><span class="nav-text">第20章 TensorFlow GPU版本的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#20-1-确认显卡是否支持CUDA"><span class="nav-text">20.1 确认显卡是否支持CUDA</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．查看支持CUDA的显卡"><span class="nav-text">1．查看支持CUDA的显卡</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．查看系统信息（见图20-4）"><span class="nav-text">2．查看系统信息（见图20-4）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．查看显卡（见图20-5）"><span class="nav-text">3．查看显卡（见图20-5）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-2-安装CUDA"><span class="nav-text">20.2 安装CUDA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-3-安装cuDNN"><span class="nav-text">20.3 安装cuDNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-4-将cudnn64-5-dll存放的位置加入Path环境变量"><span class="nav-text">20.4 将cudnn64_5.dll存放的位置加入Path环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-5-在Anaconda建立TensorFlow-GPU虚拟环境"><span class="nav-text">20.5 在Anaconda建立TensorFlow GPU虚拟环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-6-安装TensorFlow-GPU版本"><span class="nav-text">20.6 安装TensorFlow GPU版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-7-安装Keras"><span class="nav-text">20.7 安装Keras</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#20-8-结论"><span class="nav-text">20.8 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第21章-使用GPU加快TensorFlow与Keras训练"><span class="nav-text">第21章 使用GPU加快TensorFlow与Keras训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#21-1-启动TensorFlow-GPU环境"><span class="nav-text">21.1 启动TensorFlow GPU环境</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．启动TensorFlow-GPU"><span class="nav-text">1．启动TensorFlow GPU</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．导入tensorflow模块"><span class="nav-text">2．导入tensorflow模块</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．默认以GPU执行"><span class="nav-text">3．默认以GPU执行</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．设置Session的config参数，显示更多GPU设备信息"><span class="nav-text">4．设置Session的config参数，显示更多GPU设备信息</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5．以with-tf-device来指定使用CPU或GPU设备"><span class="nav-text">5．以with tf.device来指定使用CPU或GPU设备</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6．以with-tf-device来指定使用CPU"><span class="nav-text">6．以with tf.device来指定使用CPU</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#7．以with-tf-device来指定使用GPU"><span class="nav-text">7．以with tf.device来指定使用GPU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-2-测试GPU与CPU执行性能"><span class="nav-text">21.2 测试GPU与CPU执行性能</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1．创建performanceTest函数"><span class="nav-text">1．创建performanceTest函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2．执行performanceTest"><span class="nav-text">2．执行performanceTest</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3．创建performanceTest"><span class="nav-text">3．创建performanceTest</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4．将GPU与CPU的运行时间用图形来查看"><span class="nav-text">4．将GPU与CPU的运行时间用图形来查看</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-3-超出显卡内存的限制"><span class="nav-text">21.3 超出显卡内存的限制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-4-以多层感知器的实际范例比较CPU与GPU的执行速度"><span class="nav-text">21.4 以多层感知器的实际范例比较CPU与GPU的执行速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-5-以CNN的实际范例比较CPU与GPU的执行速度"><span class="nav-text">21.5 以CNN的实际范例比较CPU与GPU的执行速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-6-以Keras-Cifar-CNN的实际范例比较CPU与GPU的执行速度"><span class="nav-text">21.6 以Keras Cifar CNN的实际范例比较CPU与GPU的执行速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#21-7-结论"><span class="nav-text">21.7 结论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#附录A-本书范例程序的下载与安装说明"><span class="nav-text">附录A 本书范例程序的下载与安装说明</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-1-在Windows系统中下载与安装范例程序"><span class="nav-text">A.1 在Windows系统中下载与安装范例程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-2-在Ubuntu-Linux系统中下载与安装范例程序"><span class="nav-text">A.2 在Ubuntu Linux系统中下载与安装范例程序</span></a></li></ol></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hac_lang</span>

  

  
</div>









        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  





  
    
    
      
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="true"></script>









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  
  

  
  

  


  

  

  

  

  


  


  




  




  




  



<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>


  

  

  


  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":250,"height":500},"mobile":{"show":false,"scale":0.5},"react":{"opacity":0.7},"log":false,"tagMode":false});</script></body>
</html>
